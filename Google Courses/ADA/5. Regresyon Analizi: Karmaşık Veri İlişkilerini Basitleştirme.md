# Sıradan En Küçük Kareler (OLS) Yöntemini Keşfet

Daha önce belirtildiği gibi, regresyon modellemesinde en iyi uyum sağlayan doğruyu bulmanın bir yolu, farklı modelleri deneyip en iyi olanı seçmektir. Ancak basit doğrusal regresyonda, en iyi beta katsayılarının formülleri türetilmiştir. Bu bölümde, kareler toplamı artıkların (residuals) beta katsayıları β₀ ve β₁ değiştikçe nasıl değiştiğini daha iyi anlamanızı sağlayacak bir örnekten geçeceksiniz. Katsayı tahmini için sıradan en küçük kareler yönteminin formüllerini türetmeye ilgi duyuyorsanız, ileride daha fazla kaynak da bulacaksınız. Bu bölümde şu konular ele alınacak:

- Formül ve gösterimlerin gözden geçirilmesi  
- Kareler toplamı artıkların (SSR) en aza indirilmesi  
- Beta katsayılarının tahmini  

## Formül ve Gösterimlerin Gözden Geçirilmesi

Basit doğrusal regresyon, sürekli bir bağımlı değişken ile bir bağımsız değişken arasındaki doğrusal ilişkiyi tahmin etmek için kullanılan bir yöntemdir. Bu tahmin şu şekilde ifade edilir:

$$ŷ = β₀ + β₁ \cdot X$$


Burada şapkalı (^) simgesi, beta katsayılarının sadece tahmin olduğunu gösterir. Dolayısıyla regresyon modelinden elde edilen **ŷ** değerleri de sadece tahmindir.

Katsayıları hesaplamak için yaygın bir teknik, sıradan en küçük kareler (OLS) yöntemidir. Bu yöntem, gözlemlenen ve tahmin edilen değerler arasındaki hatayı (artıkları) karelerine alıp toplayarak (SSR) beta katsayılarını tahmin eder.

SSR şu formülle hesaplanabilir:

$$∑(Observed - Predicted)²$$

ya da matematiksel gösterimle:  

$$∑(yᵢ - ŷᵢ)²$$

Buradaki ∑ (sigma), toplamı ifade eder. Yani bu formül, gözlemlenen değerler ile modelin tahmin ettiği değerler arasındaki farkların karelerinin toplamını ifade eder.

## Kareler Toplamı Artıkların (SSR) En Aza İndirilmesi

6 gözlem içeren bir veri kümesi olduğunu varsayalım:

| **X (gözlemlenen)** | **Y (gözlemlenen)** |
|---------------------|---------------------|
| 0                   | -1                  |
| 1                   | 2                   |
| 2                   | 4                   |
| 3                   | 8                   |
| 4                   | 11                  |
| 5                   | 12                  |

![image](images/5001.png)

### Doğru 1: ŷ = -0.5 + 3x

İlk denemede β₀ = -0.5 ve β₁ = 3 olduğunu varsayalım. Bu durumda regresyon doğrusu:

$$ŷ = -0.5 + 3x$$

Şimdi X için her değeri yerine koyarak ŷ değerlerini ve artıkların karelerini hesaplayalım:

| X | Y (gerçek) | ŷ (tahmin) = -0.5 + 3x | Artık      | Artık² |
|---|------------|------------------------|------------|--------|
| 0 | -1         | -0.5                   | -0.5       | 0.25   |
| 1 | 2          | 2.5                    | -0.5       | 0.25   |
| 2 | 4          | 5.5                    | -1.5       | 2.25   |
| 3 | 8          | 8.5                    | -0.5       | 0.25   |
| 4 | 11         | 11.5                   | -0.5       | 0.25   |
| 5 | 12         | 14.5                   | -2.5       | 6.25   |

**Kareler toplamı (SSR) = 0.25 + 0.25 + 2.25 + 0.25 + 0.25 + 6.25 = 9.5**

### Doğru 2: ŷ = -0.5 + 2.5x

Şimdi sadece eğimi değiştiriyoruz. β₀ = -0.5 sabit, β₁ = 2.5 olsun. Doğru:

$$ŷ = -0.5 + 2.5x$$

| X | Y (gerçek) | ŷ (tahmin) = -0.5 + 2.5x | Artık | Artık² |
|---|------------|--------------------------|--------|--------|
| 0 | -1         | -0.5                     | -0.5   | 0.25   |
| 1 | 2          | 2                        | 0      | 0      |
| 2 | 4          | 4.5                      | -0.5   | 0.25   |
| 3 | 8          | 7                        | 1      | 1      |
| 4 | 11         | 9.5                      | 1.5    | 2.25   |
| 5 | 12         | 12                       | 0      | 0      |

**Kareler toplamı (SSR) = 0.25 + 0 + 0.25 + 1 + 2.25 + 0 = 3.75**

Bu tahmin çok daha iyi!

## Beta Katsayılarının Tahmini

Eğim ve kesişimi sürekli değiştirip SSR hesaplamak mümkün ama bu şekilde en iyi doğruyu bulduğunuzdan emin olamazsınız. Neyse ki, beta katsayılarını hata miktarını en aza indirecek şekilde hesaplayan matematiksel formüller vardır.

Basit doğrusal regresyon için bu formüller:

- $β₁ = ∑(Xᵢ - X̄)(Yᵢ - Ȳ) / ∑(Xᵢ - X̄)²$

- $β₀ = Ȳ - β₁X̄$

Bu hesaplamaları elle yapmanız beklenmez, ama mantığını anlamak önemlidir.

## Temel Çıkarımlar

Elinizde bir veri örneklemi varsa, bu veriye uyabilecek farklı doğrular deneyebilirsiniz. Her bir doğruda kareler toplamını hesaplayarak en uygun olanı belirleyebilirsiniz. Bir veri uzmanı olarak, kareler toplamı artıkların (SSR) neyi temsil ettiğini ve nasıl hesaplandığını anlamanız önemlidir. Neyse ki, bilgisayarlar ve programlama dilleri bu işlemleri sizin yerinize kolayca yapabilir. OLS ve SSR’nin matematiksel detaylarını daha fazla keşfetmek isterseniz, aşağıdaki kaynaklara göz atabilirsiniz.

## Kaynaklar

- [Parametre Tahmini - Sıradan En Küçük Kareler Yöntemi](https://www.geo.fu-berlin.de/en/v/soga-py/Basics-of-statistics/Linear-Regression/Simple-Linear-Regression/Parameter-Estimation/index.html): *Rudolph, A., Krois, J., Hartmann, K. (2023): Statistics and Geodata Analysis using Python (SOGA-Py). Freie Universitaet Berlin.*

# Korelasyon ve Basit Doğrusal Regresyonun Sezgisel Temeli

Şimdiye kadar, basit doğrusal regresyonun bir bağımsız değişken (X) ile bir sürekli bağımlı değişken (Y) arasındaki doğrusal ilişkiyi tahmin eden bir teknik olduğunu öğrendiniz. Ayrıca, regresyon doğrusunun katsayılarını belirlemenin yaygın bir yolu olan En Küçük Kareler Tahmini (OLS) hakkında bilgi edindiniz. Bu derste, korelasyonun ne anlama geldiğini keşfedecek; *r*, yani “korelasyon katsayısı” hakkında bilgi edinecek; ve regresyon denkleminin nasıl belirlendiğini öğreneceksiniz. Bu bilgiler, değişkenler arasındaki ilişkileri daha iyi anlamanıza ve böylece doğrusal regresyonun nasıl çalıştığını kavramanıza yardımcı olacaktır.

## Korelasyon

Korelasyon, iki değişkenin birlikte nasıl hareket ettiğinin bir ölçüsüdür. Değişkenler arasında güçlü bir korelasyon varsa, birini bilmek diğerini tahmin etmekte oldukça yardımcı olur. Ancak, iki değişken arasında zayıf bir korelasyon varsa, birinin değerini bilmek diğerinin değeri hakkında pek bilgi vermez. Doğrusal regresyon bağlamında korelasyon, **doğrusal** korelasyonu ifade eder: bir değişken değiştikçe, diğeri de sabit bir oranda değişir.

İstatistik dersinde, sürekli bir değişkenin bazı temel istatistiklerle özetlenebileceğini öğrenmiştiniz. Bu özet istatistiklerden ikisi şunlardır:

* **Ortalama:** Merkezi eğilim ölçüsüdür (aritmetik ortalama, medyan, mod)
* **Standart sapma:** Dağılımın bir ölçüsüdür

İki değişken birlikte özetlendiğinde, ***r*** adı verilen başka bir önemli istatistik vardır: **Pearson korelasyon katsayısı** (adını geliştiren kişiden alır) ya da sadece **doğrusal korelasyon katsayısı**. Korelasyon katsayısı, iki değişken arasındaki doğrusal ilişkinin gücünü nicel olarak ifade eder. Değeri her zaman $-1, 1$ aralığındadır.

* *r* negatifse, değişkenler arasında negatif bir ilişki vardır: biri artarken diğeri azalır.
* *r* pozitifse, değişkenler birlikte artar.
* *r* = 0 olduğunda, değişkenler arasında doğrusal bir ilişki yoktur.

Dikkat edin, değişkenler arasında doğrusal olmayan bir ilişki olsa bile (örneğin y = x² veya y = sin(x)), *r* düşük ya da sıfır olabilir.

Aşağıdaki grafikler, korelasyon katsayısı farklı olan iki değişkenin dağılımlarını göstermektedir:

![image](images/5002.png)

Görüldüğü gibi, *r* değeri 0’a yaklaştıkça veri noktaları daha dağınık görünür; -1 veya 1'e yaklaştıkça daha doğrusal hale gelir.

Ancak *r*, yalnızca değişkenler arasındaki **doğrusal ilişkinin gücünü** söyler; eğimin büyüklüğü hakkında bilgi vermez. Örneğin, *r* = 1 olsa bile, X'teki bir birim artışın Y’yi ne kadar artıracağına dair bilgi vermez.

![image](images/5003.png)


### *r* Nasıl Hesaplanır?

*r* formülü:

$$
r = \frac{covariance(X, Y)}{(SD_X \cdot SD_Y)}
$$

Burada:

$$
covariance(X, Y) = (1/n) * Σ(xᵢ - x̄)(yᵢ - ȳ)
$$

> **Not:** Bu formüller tüm popülasyon için geçerlidir. Örneklemler için payda *n - 1* olarak alınır.

Bir başka hesaplama yolu da şudur: her veri noktasını standart birime (ortalama çıkar, standart sapmaya böl) çevirin, ardından bu standart birimlerin çarpımlarının ortalamasını alın.

#### Örnek:

| **Çalışma Süresi (X)** | **Not (Y)** | **X’in Standart Birimi** | **Y’nin Standart Birimi** | **Çarpım** |
| ---------------------- | ----------- | ------------------------ | ------------------------- | ---------- |
| 2                      | 75          | -1.5                     | -0.5                      | 0.75       |
| 4                      | 65          | -0.5                     | -1.5                      | 0.75       |
| 5                      | 80          | 0                        | 0                         | 0          |
| 6                      | 95          | 0.5                      | 1.5                       | 0.75       |
| 8                      | 85          | 1.5                      | 0.5                       | 0.75       |

**Ortalama X = 5, SD X = 2**

**Ortalama Y = 80, SD Y = 10**

**Ortalama Çarpım (r) = 0.6**

Grafik üzerindeki dağılıma bakıldığında, noktaların pozitif eğilim gösterdiği görülür, bu da *r*’nin pozitif olmasıyla tutarlıdır.

Aşağıdaki grafik, noktaların ortalamalara göre hangi çeyrekte yer aldığını ve çarpımın pozitif/negatif olma durumunu gösterir:

![Quadrant diagram of data points.](...)

## Regresyon

Başka bir bilginiz olmasa, rastgele bir öğrencinin sınav notunu tahmin etmek için ortalama puanı tahmin etmek mantıklı olurdu. Ancak bu öğrencinin kaç saat çalıştığını biliyorsanız, daha iyi bir tahmin yapabilirsiniz: aynı süre çalışan öğrencilerin ortalama notunu kullanmak.

Örneğin, 7 saat çalışan bir öğrencinin notunu tahmin ederken, sadece 7 saat çalışanların ortalamasını almak hata oranını azaltır.

![Scatterplot of study hours and scores.](...)

### Regresyon Doğrusu

Regresyon doğrusu, her X değeri için Y'nin tahmini ortalama değerini verir. Gerçek değerler birebir bu doğru üzerinde olmayabilir. Bu doğrusal model, tüm veriler için en uygun doğruyu (en az hata ile) bulmaya çalışır.

### Regresyon Denklemi

Regresyon doğrusu denklemi şu iki temel kurala dayanır:

1. (*x̄*, *ȳ*) noktası her zaman regresyon doğrusu üzerindedir.
2. X’teki her bir standart sapma artışı için, Y’de ortalama olarak *r* standart sapmalık bir artış beklenir.

Bu durumda eğim (*m*) şöyle hesaplanır:

$$m = r * (SD_y / SD_x)$$

Regresyon doğrusu: 

$$y = mx + b$$

Bildiğimiz nokta (*x̄*, *ȳ*) olduğuna göre, *b* şöyle bulunur:

$$b = ȳ - m * x̄$$

#### Örnek:

|                     | **Çalışma Süresi (X)** | **Sınav Notu (Y)** |
| ------------------- | ---------------------- | ------------------ |
| **Ortalama:**       | 5                      | 80                 |
| **Standart Sapma:** | 2                      | 10                 |
| **r:**              | 0.6                    |                    |

1. Eğim (*m*):

```
m = 0.6 * (10 / 2) = 3
```

2. Y-Kesişim (*b*):

```
b = 80 - 3 * 5 = 65
```

3. Regresyon denklemi:

```
y = 3x + 65
```

![Regression line over data.](...)

Bu denkleme “Y’nin X’e göre regresyonu” denir.

Tüm 100 öğrenci için regresyon doğrusu:
**y = 4.2x + 49.6**

![Full regression line.](...)

## Özet Bilgiler

* Korelasyon, iki değişkenin birlikte nasıl değiştiğini ölçer.
* *r* (Pearson korelasyon katsayısı), doğrusal ilişkinin gücünü ifade eder.

  * Değeri her zaman $-1, 1$ aralığındadır.
  * Ortalamalarına göre birlikte değişen değişkenler pozitif korelasyonludur. Ters yönlü değişenler negatif korelasyonludur.
* Regresyon doğrusu, her *x* değeri için *y*’nin ortalama değerini tahmin eder. Hata oranını minimize etmeyi amaçlar.
* Doğrunun eğimi:
  $$
  m = \frac{r \cdot SD_y}{SD_x}
  $$
* Nokta (*x̄*, *ȳ*) her zaman regresyon doğrusu üzerindedir.
