# Sıradan En Küçük Kareler (OLS) Yöntemini Keşfet

Daha önce belirtildiği gibi, regresyon modellemesinde en iyi uyum sağlayan doğruyu bulmanın bir yolu, farklı modelleri deneyip en iyi olanı seçmektir. Ancak basit doğrusal regresyonda, en iyi beta katsayılarının formülleri türetilmiştir. Bu bölümde, kareler toplamı artıkların (residuals) beta katsayıları β₀ ve β₁ değiştikçe nasıl değiştiğini daha iyi anlamanızı sağlayacak bir örnekten geçeceksiniz. Katsayı tahmini için sıradan en küçük kareler yönteminin formüllerini türetmeye ilgi duyuyorsanız, ileride daha fazla kaynak da bulacaksınız. Bu bölümde şu konular ele alınacak:

- Formül ve gösterimlerin gözden geçirilmesi  
- Kareler toplamı artıkların (SSR) en aza indirilmesi  
- Beta katsayılarının tahmini  

## Formül ve Gösterimlerin Gözden Geçirilmesi

Basit doğrusal regresyon, sürekli bir bağımlı değişken ile bir bağımsız değişken arasındaki doğrusal ilişkiyi tahmin etmek için kullanılan bir yöntemdir. Bu tahmin şu şekilde ifade edilir:

$$ŷ = β₀ + β₁ \cdot X$$


Burada şapkalı (^) simgesi, beta katsayılarının sadece tahmin olduğunu gösterir. Dolayısıyla regresyon modelinden elde edilen **ŷ** değerleri de sadece tahmindir.

Katsayıları hesaplamak için yaygın bir teknik, sıradan en küçük kareler (OLS) yöntemidir. Bu yöntem, gözlemlenen ve tahmin edilen değerler arasındaki hatayı (artıkları) karelerine alıp toplayarak (SSR) beta katsayılarını tahmin eder.

SSR şu formülle hesaplanabilir:

$$∑(Observed - Predicted)²$$

ya da matematiksel gösterimle:  

$$∑(yᵢ - ŷᵢ)²$$

Buradaki ∑ (sigma), toplamı ifade eder. Yani bu formül, gözlemlenen değerler ile modelin tahmin ettiği değerler arasındaki farkların karelerinin toplamını ifade eder.

## Kareler Toplamı Artıkların (SSR) En Aza İndirilmesi

6 gözlem içeren bir veri kümesi olduğunu varsayalım:

| **X (gözlemlenen)** | **Y (gözlemlenen)** |
|---------------------|---------------------|
| 0                   | -1                  |
| 1                   | 2                   |
| 2                   | 4                   |
| 3                   | 8                   |
| 4                   | 11                  |
| 5                   | 12                  |

![image](images/5001.png)

### Doğru 1: ŷ = -0.5 + 3x

İlk denemede β₀ = -0.5 ve β₁ = 3 olduğunu varsayalım. Bu durumda regresyon doğrusu:

$$ŷ = -0.5 + 3x$$

Şimdi X için her değeri yerine koyarak ŷ değerlerini ve artıkların karelerini hesaplayalım:

| X | Y (gerçek) | ŷ (tahmin) = -0.5 + 3x | Artık      | Artık² |
|---|------------|------------------------|------------|--------|
| 0 | -1         | -0.5                   | -0.5       | 0.25   |
| 1 | 2          | 2.5                    | -0.5       | 0.25   |
| 2 | 4          | 5.5                    | -1.5       | 2.25   |
| 3 | 8          | 8.5                    | -0.5       | 0.25   |
| 4 | 11         | 11.5                   | -0.5       | 0.25   |
| 5 | 12         | 14.5                   | -2.5       | 6.25   |

**Kareler toplamı (SSR) = 0.25 + 0.25 + 2.25 + 0.25 + 0.25 + 6.25 = 9.5**

### Doğru 2: ŷ = -0.5 + 2.5x

Şimdi sadece eğimi değiştiriyoruz. β₀ = -0.5 sabit, β₁ = 2.5 olsun. Doğru:

$$ŷ = -0.5 + 2.5x$$

| X | Y (gerçek) | ŷ (tahmin) = -0.5 + 2.5x | Artık | Artık² |
|---|------------|--------------------------|--------|--------|
| 0 | -1         | -0.5                     | -0.5   | 0.25   |
| 1 | 2          | 2                        | 0      | 0      |
| 2 | 4          | 4.5                      | -0.5   | 0.25   |
| 3 | 8          | 7                        | 1      | 1      |
| 4 | 11         | 9.5                      | 1.5    | 2.25   |
| 5 | 12         | 12                       | 0      | 0      |

**Kareler toplamı (SSR) = 0.25 + 0 + 0.25 + 1 + 2.25 + 0 = 3.75**

Bu tahmin çok daha iyi!

## Beta Katsayılarının Tahmini

Eğim ve kesişimi sürekli değiştirip SSR hesaplamak mümkün ama bu şekilde en iyi doğruyu bulduğunuzdan emin olamazsınız. Neyse ki, beta katsayılarını hata miktarını en aza indirecek şekilde hesaplayan matematiksel formüller vardır.

Basit doğrusal regresyon için bu formüller:

- $β₁ = ∑(Xᵢ - X̄)(Yᵢ - Ȳ) / ∑(Xᵢ - X̄)²$

- $β₀ = Ȳ - β₁X̄$

Bu hesaplamaları elle yapmanız beklenmez, ama mantığını anlamak önemlidir.

## Temel Çıkarımlar

Elinizde bir veri örneklemi varsa, bu veriye uyabilecek farklı doğrular deneyebilirsiniz. Her bir doğruda kareler toplamını hesaplayarak en uygun olanı belirleyebilirsiniz. Bir veri uzmanı olarak, kareler toplamı artıkların (SSR) neyi temsil ettiğini ve nasıl hesaplandığını anlamanız önemlidir. Neyse ki, bilgisayarlar ve programlama dilleri bu işlemleri sizin yerinize kolayca yapabilir. OLS ve SSR’nin matematiksel detaylarını daha fazla keşfetmek isterseniz, aşağıdaki kaynaklara göz atabilirsiniz.

## Kaynaklar

- [Parametre Tahmini - Sıradan En Küçük Kareler Yöntemi](https://www.geo.fu-berlin.de/en/v/soga-py/Basics-of-statistics/Linear-Regression/Simple-Linear-Regression/Parameter-Estimation/index.html): *Rudolph, A., Krois, J., Hartmann, K. (2023): Statistics and Geodata Analysis using Python (SOGA-Py). Freie Universitaet Berlin.*

# Korelasyon ve Basit Doğrusal Regresyonun Sezgisel Temeli

Şimdiye kadar, basit doğrusal regresyonun bir bağımsız değişken (X) ile bir sürekli bağımlı değişken (Y) arasındaki doğrusal ilişkiyi tahmin eden bir teknik olduğunu öğrendiniz. Ayrıca, regresyon doğrusunun katsayılarını belirlemenin yaygın bir yolu olan En Küçük Kareler Tahmini (OLS) hakkında bilgi edindiniz. Bu derste, korelasyonun ne anlama geldiğini keşfedecek; *r*, yani “korelasyon katsayısı” hakkında bilgi edinecek; ve regresyon denkleminin nasıl belirlendiğini öğreneceksiniz. Bu bilgiler, değişkenler arasındaki ilişkileri daha iyi anlamanıza ve böylece doğrusal regresyonun nasıl çalıştığını kavramanıza yardımcı olacaktır.

## Korelasyon

Korelasyon, iki değişkenin birlikte nasıl hareket ettiğinin bir ölçüsüdür. Değişkenler arasında güçlü bir korelasyon varsa, birini bilmek diğerini tahmin etmekte oldukça yardımcı olur. Ancak, iki değişken arasında zayıf bir korelasyon varsa, birinin değerini bilmek diğerinin değeri hakkında pek bilgi vermez. Doğrusal regresyon bağlamında korelasyon, **doğrusal** korelasyonu ifade eder: bir değişken değiştikçe, diğeri de sabit bir oranda değişir.

İstatistik dersinde, sürekli bir değişkenin bazı temel istatistiklerle özetlenebileceğini öğrenmiştiniz. Bu özet istatistiklerden ikisi şunlardır:

* **Ortalama:** Merkezi eğilim ölçüsüdür (aritmetik ortalama, medyan, mod)
* **Standart sapma:** Dağılımın bir ölçüsüdür

İki değişken birlikte özetlendiğinde, ***r*** adı verilen başka bir önemli istatistik vardır: **Pearson korelasyon katsayısı** (adını geliştiren kişiden alır) ya da sadece **doğrusal korelasyon katsayısı**. Korelasyon katsayısı, iki değişken arasındaki doğrusal ilişkinin gücünü nicel olarak ifade eder. Değeri her zaman $-1, 1$ aralığındadır.

* *r* negatifse, değişkenler arasında negatif bir ilişki vardır: biri artarken diğeri azalır.
* *r* pozitifse, değişkenler birlikte artar.
* *r* = 0 olduğunda, değişkenler arasında doğrusal bir ilişki yoktur.

Dikkat edin, değişkenler arasında doğrusal olmayan bir ilişki olsa bile (örneğin y = x² veya y = sin(x)), *r* düşük ya da sıfır olabilir.

Aşağıdaki grafikler, korelasyon katsayısı farklı olan iki değişkenin dağılımlarını göstermektedir:

![image](images/5002.png)

Görüldüğü gibi, *r* değeri 0’a yaklaştıkça veri noktaları daha dağınık görünür; -1 veya 1'e yaklaştıkça daha doğrusal hale gelir.

Ancak *r*, yalnızca değişkenler arasındaki **doğrusal ilişkinin gücünü** söyler; eğimin büyüklüğü hakkında bilgi vermez. Örneğin, *r* = 1 olsa bile, X'teki bir birim artışın Y’yi ne kadar artıracağına dair bilgi vermez.

![image](images/5003.png)


### *r* Nasıl Hesaplanır?

*r* formülü:

$$r = \frac{covariance(X, Y)}{(SD_X \cdot SD_Y)}$$

Burada:

$$
covariance(X, Y) = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{n}
$$


> **Not:** Bu formüller tüm popülasyon için geçerlidir. Örneklemler için payda *n - 1* olarak alınır.

Bir başka hesaplama yolu da şudur: her veri noktasını standart birime (ortalama çıkar, standart sapmaya böl) çevirin, ardından bu standart birimlerin çarpımlarının ortalamasını alın.

#### Örnek:

| **Çalışma Süresi (X)** | **Not (Y)** | **X’in Standart Birimi** | **Y’nin Standart Birimi** | **Çarpım** |
| ---------------------- | ----------- | ------------------------ | ------------------------- | ---------- |
| 2                      | 75          | -1.5                     | -0.5                      | 0.75       |
| 4                      | 65          | -0.5                     | -1.5                      | 0.75       |
| 5                      | 80          | 0                        | 0                         | 0          |
| 6                      | 95          | 0.5                      | 1.5                       | 0.75       |
| 8                      | 85          | 1.5                      | 0.5                       | 0.75       |

**Ortalama X = 5, SD X = 2**

**Ortalama Y = 80, SD Y = 10**

**Ortalama Çarpım (r) = 0.6**

![image](images/5004.png)

Grafik üzerindeki dağılıma bakıldığında, noktaların pozitif eğilim gösterdiği görülür, bu da *r*’nin pozitif olmasıyla tutarlıdır.

Aşağıdaki grafik, noktaların ortalamalara göre hangi çeyrekte yer aldığını ve çarpımın pozitif/negatif olma durumunu gösterir:

![image](images/5005.png)

## Regresyon

Başka bir bilginiz olmasa, rastgele bir öğrencinin sınav notunu tahmin etmek için ortalama puanı tahmin etmek mantıklı olurdu. Ancak bu öğrencinin kaç saat çalıştığını biliyorsanız, daha iyi bir tahmin yapabilirsiniz: aynı süre çalışan öğrencilerin ortalama notunu kullanmak.

Örneğin, 7 saat çalışan bir öğrencinin notunu tahmin ederken, sadece 7 saat çalışanların ortalamasını almak hata oranını azaltır.

![image](images/5006.png)

### Regresyon Doğrusu

Regresyon doğrusu, her X değeri için Y'nin tahmini ortalama değerini verir. Gerçek değerler birebir bu doğru üzerinde olmayabilir. Bu doğrusal model, tüm veriler için en uygun doğruyu (en az hata ile) bulmaya çalışır.

### Regresyon Denklemi

Regresyon doğrusu denklemi şu iki temel kurala dayanır:

1. (*x̄*, *ȳ*) noktası her zaman regresyon doğrusu üzerindedir.
2. X’teki her bir standart sapma artışı için, Y’de ortalama olarak *r* standart sapmalık bir artış beklenir.

![image](images/5007.png)


Bu durumda eğim (*m*) şöyle hesaplanır:

$$m = r * \frac{SD_y}{SD_x}$$

Regresyon doğrusu: 

$$y = mx + b$$

Bildiğimiz nokta (*x̄*, *ȳ*) olduğuna göre, *b* şöyle bulunur:

$$b = ȳ - m * x̄$$

#### Örnek:

|                     | **Çalışma Süresi (X)** | **Sınav Notu (Y)** |
| ------------------- | ---------------------- | ------------------ |
| **Ortalama:**       | 5                      | 80                 |
| **Standart Sapma:** | 2                      | 10                 |
| **r:**              | 0.6                    |                    |

1. Eğim (*m*):

$$m = 0.6 * (10 / 2) = 3$$

2. Y-Kesişim (*b*):

$$b = 80 - 3 * 5 = 65$$

3. Regresyon denklemi:

$$y = 3x + 65$$

Bu denkleme “Y’nin X’e göre regresyonu” denir.

![image](images/5008.png)

Tüm 100 öğrenci için regresyon doğrusu:
$$y = 4.2x + 49.6$$

![image](images/5009.png)

## Özet Bilgiler

* Korelasyon, iki değişkenin birlikte nasıl değiştiğini ölçer.
* *r* (Pearson korelasyon katsayısı), doğrusal ilişkinin gücünü ifade eder.

  * Değeri her zaman $-1, 1$ aralığındadır.
  * Ortalamalarına göre birlikte değişen değişkenler pozitif korelasyonludur. Ters yönlü değişenler negatif korelasyonludur.
* Regresyon doğrusu, her *x* değeri için *y*’nin ortalama değerini tahmin eder. Hata oranını minimize etmeyi amaçlar.
* Doğrunun eğimi:
  $$m = \frac{r \cdot SD_y}{SD_x}$$
* Nokta (*x̄*, *ȳ*) her zaman regresyon doğrusu üzerindedir.

# Basit Doğrusal Regresyonun Dört Ana Varsayımı

Bu okumada, basit doğrusal regresyonun dört ana varsayımını, bu varsayımların nasıl kontrol edileceğini ve herhangi bir varsayım karşılanmazsa ne yapılması gerektiğini inceleyeceksiniz. Ek kaynakları kullanarak grafiklerin aynısını oluşturabilir ve varsayımları kendiniz keşfedebilirsiniz. Eğer bu okumada tanımlanmamış terimler varsa, kurs boyunca her modülün sonunda yer alan terimler sözlüğüne başvurabilirsiniz.

Bu okumada şunlar ele alınacaktır:

* Basit doğrusal regresyon varsayımları
* Varsayımların geçerliliğinin nasıl kontrol edileceği
* Bir varsayım ihlal edilirse ne yapılması gerektiği

---

## Basit Doğrusal Regresyon Varsayımları

Hatırlamak gerekirse, basit doğrusal regresyonun dört temel varsayımı vardır:

1. **Doğrusallık:** Her bir bağımsız değişken (Xi), bağımlı değişken (Y) ile doğrusal bir ilişkiye sahiptir.
2. **Normallik:** Hatalar normal dağılım gösterir.
3. **Bağımsız Gözlemler:** Veri kümesindeki her bir gözlem birbirinden bağımsızdır.
4. **Homoskedastisite:** Hata terimlerinin varyansı model boyunca sabittir ya da birbirine benzerdir.

---

### **Hatalar ve Artıklar Üzerine Not**

Bu kursta "hata" ve "artık" terimleri regresyon bağlamında birbirinin yerine kullanılmış olabilir. Veri bilimi kaynaklarında bu durumla sıkça karşılaşabilirsiniz. Ancak aralarında fark vardır:

* **Artıklar (residuals):** Tahmin edilen değerlerle gözlemlenen değerler arasındaki farktır. Regresyon modeli kurulduktan sonra tahmin edilen değerlerden gözlenen değerler çıkarılarak hesaplanır.
* **Hatalar (errors):** Modelde varsayılan doğal rastlantısal gürültüdür.
* Normallik ve homoskedastisite varsayımları kontrol edilirken, hataları tahmin etmek için artıklar kullanılır.

---

## Varsayımların Geçerliliği Nasıl Kontrol Edilir?

Daha önce de değinildiği gibi, basit doğrusal regresyon varsayımlarının çoğu veri görselleştirmeleriyle kontrol edilebilir. Bazı varsayımlar model kurulmadan önce kontrol edilebilirken, bazıları model kurulduktan ve tahminler elde edildikten sonra kontrol edilebilir.

---

### **Doğrusallık**

Bağımsız ve bağımlı değişkenler arasında doğrusal bir ilişki olup olmadığını değerlendirmek için en kolay yöntem veri kümesinin saçılım (scatter) grafiğini oluşturmaktır. Bağımsız değişken x eksenine, bağımlı değişken ise y eksenine yerleştirilir. Bu tür grafikler oluşturmak için Matplotlib, seaborn ve Plotly gibi Python kütüphaneleri kullanılabilir. Doğrusallık varsayımı model kurulmadan önce test edilmelidir.

```python
sns.pairplot(chinstrap_penguins)
# Chinstrap penguen verisiyle eşleşen grafikler
```
![image](images/5010.png)
---

### **Normallik**

Normallik varsayımı **hatalar** ile ilgilidir ve bu hatalar **artıklar** ile tahmin edilir. Bu nedenle normallik varsayımı **sadece model kurulduktan sonra** kontrol edilebilir. Model kurulduktan sonra artıkların normal dağılıp dağılmadığını kontrol etmek için:

* **QQ grafiği** (quantile-quantile plot)
* **Artıkların histogramı** oluşturulabilir.

#### **QQ Grafiği Nedir?**

QQ grafiği, iki olasılık dağılımının karşılaştırıldığı bir araçtır. Veri bilimciler, histogramlara kıyasla normalliği test etmek için QQ grafiğini daha uygun bulurlar çünkü grafik doğrusal bir çizgiye ne kadar uyduğunu görmek daha kolaydır.

QQ grafiğinin oluşturulması:

1. Artıkları sıralayın ve her biri için yüzdelik dilimi bulun.
2. Bu yüzdelikleri standart normal dağılımın z-skorlarıyla karşılaştırın.
3. Grafik oluşturun: x ekseninde standart normal dağılımın yüzde değerleri, y ekseninde sıralanmış artıklar yer alır. Eğer artıklar normal dağılıyorsa, bu noktalar düz bir çizgi oluşturur.

Standardizasyon (z-skora dönüştürme) opsiyoneldir ancak eksenlerin aynı ölçeğe getirilmesini sağlar.

![image](images/5011.png)

---

#### **QQ Grafiği Oluşturma (Kod)**

```python
import statsmodels.api as sm
import matplotlib.pyplot as plt

residuals = model.resid
fig = sm.qqplot(residuals, line='s')
plt.show()
```

![image](images/5012.png)

Artıkların histogramı için:

```python
fig = sns.histplot(residuals)
fig.set_xlabel("Artık Değeri")
fig.set_title("Artıkların Histogramı")
plt.show()
```

![image](images/5013.png)

---

### **Bağımsız Gözlemler**

Gözlemlerin bağımsız olup olmadığını anlamak, veriyi anlama süreciyle ilgilidir. Aşağıdaki soruları sormak faydalı olabilir:

* Veri nasıl toplandı?
* Her bir veri noktası neyi temsil ediyor?
* Bir gözlemin değeri diğerini etkileyebilir mi?

Bu sorulara objektif bir şekilde yanıt aramak, bağımsızlık varsayımının ihlal edilip edilmediğini belirlemenizi sağlar.

---

### **Homoskedastisite**

Bu varsayım da normallik gibi artıklarla ilgilidir, yani **model kurulduktan sonra** değerlendirilebilir. Modelin tahmin ettiği Y değerleri ile artıklar arasında bir saçılım grafiği oluşturularak kontrol edilir.

```python
fig = sns.scatterplot(x=fitted_values, y=residuals)
fig.axhline(0)
fig.set_xlabel("Tahmin Edilen Değerler")
fig.set_ylabel("Artıklar")
plt.show()
```

![image](images/5014.png)

Artıklar model boyunca rastgele ve sabit varyansa sahip olacak şekilde dağılmışsa, homoskedastisite varsayımı karşılanmıştır.

---

## Varsayımlar İhlal Edilirse Ne Yapılır?

Varsayımların nasıl kontrol edileceğini öğrendikten sonra, herhangi biri ihlal edilirse atılabilecek bazı yaygın adımlara bakalım. Unutmayın, veride yapılan dönüşümler modelin yorumlanmasını değiştirebilir. Ayrıca bu çözümler işe yaramazsa, farklı bir model türü düşünmelisiniz.

### **Doğrusallık**

* Değişkenleri dönüştürün (örneğin logaritmasını alın).

  * Örn: Eğitim yılı ile gelir arasındaki ilişki ölçülüyorsa, gelir değişkeninin logaritması alınarak doğrusal ilişki elde edilmeye çalışılabilir.

### **Normallik**

* Genellikle bağımlı değişkenin logaritması alınır.

  * Örneğin, gelir gibi sağa çarpık dağılımlar artıkların normalliğini bozabilir.
  * Dönüşüm sonrası model yeniden kurulur ve normallik yeniden kontrol edilir.

![image](images/5015.png)

---

### **Bağımsız Gözlemler**

* Verinin bir alt kümesi alınabilir.

  * Örn: Aynı evden gelen anket cevapları birbirini etkileyebilir. Her evden sadece bir kişiyi dahil etmek çözüm olabilir.
  * Zaman serisi verilerinde, veriler çok sık toplanıyorsa (örneğin her 15 dakikada bir), bağımlılık oluşabilir. Bunun yerine 2 saatte bir veri toplanması bağımsızlık sağlayabilir.

---

### **Homoskedastisite**

* Farklı bir bağımlı değişken tanımlanabilir.

  * Örn: Şehir nüfusu ile restoran sayısı yerine, kişi başına düşen restoran sayısı kullanılabilir.
* Y değişkenini dönüştürün (log vb.).

  * Bu dönüşüm, varyansta tutarlılık sağlayabilir.

---

## Temel Noktalar

* Basit doğrusal regresyonun 4 temel varsayımı vardır: doğrusallık, normallik, bağımsızlık, homoskedastisite.
* Her varsayımın geçerliliği farklı yollarla kontrol edilebilir.
* Varsayım ihlali durumunda veriler dönüştürülebilir.
* Değişkenleri dönüştürmek, sonuçların yorumunu da değiştirir.
* Dönüşümlere rağmen varsayımlar karşılanmıyorsa, farklı modeller düşünülmelidir.

---

## Ek Kaynaklar

* [Seaborn penguins veri kümesini buradan indirin](https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv)
* [Palmer penguenleri hakkında daha fazla bilgi](https://allisonhorst.github.io/palmerpenguins/articles/intro.html)
* \[QQ grafiklerine dair video (jbstatistics)]\([https://www.youtube](https://www.youtube.com/watch?v=X9\_ISJ0YpGw)

