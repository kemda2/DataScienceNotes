
# 1 Veri Biliminin Temelleri 

## PACE Aşamaları

Şimdiye kadar, PACE çerçevesi ile tanıştınız ve veri analizi projeleri
için nasıl net bir temel ve yapı sağladığını öğrendiniz. Ayrıca
PACE\'nin bir kısaltma olduğunu öğrendiniz; harflerin her biri bir
projede eyleme geçirilebilir bir aşamayı temsil eder: planlayın, analiz
edin, inşa edin ve uygulayın. Bu okumada, PACE iş akışı hakkında daha
fazla bilgi edinecek ve sürecin her aşamasının veri analizine nasıl
yardımcı olabileceğini keşfedeceksiniz.

### Neden bir iş akışı yapısı kullanıyoruz?

Genel bir kural olarak, veri profesyonelleri, veri projelerinin süresi
boyunca onlara rehberlik etmek için iş akışı yapılarına güvenir. Büyük
ölçekli bir proje içinde, belirli bir işlem sırası gerektiren bir dizi
görev olabilir. Karmaşıklıkları belirlemek ve birlikte çalışmanın
tutarlı yollarını bulmak, projeleri daha verimli hale getirebilir ve
daha üretken iletişim sağlayabilir. Bu ve diğer potansiyel engelleyici
türlerini erken belirlemek, bir projeyi olumsuz yönde etkilemeden önce
kaynakları önceden planlamanıza ve hazırlamanıza yardımcı olabilir.

Bu programın oluşturulmasına yardımcı olan veri uzmanlarından oluşan
ekibimiz, PACE\'i esnek bir model olarak geliştirdi; tüm iş akışını
kesintiye uğratmadan her aşamayı yeniden ziyaret etmeniz teşvik edilir.
PACE aracılığıyla, ne zaman dikkate alınması gerekeceği için eylem
alanlarını ve bağlamları belirleyeceksiniz. Sonuç olarak, PACE,
profesyonellere bir veri projesinin her aşamasında çalışırken çabalarını
destekleyebilecek özelleştirilebilir bir iskele sunar.

### PACE modeline daha yakından bir bakış

PACE modelinin her aşamasına daha yakından bakalım.

<img src="attachment:ebed4156-9c62-49ec-881b-f1a21f24c0fc.png" width="500" />

![image](./images/ebed4156-9c62-49ec-881b-f1a21f24c0fc.png)

#### **Plan**

Bir projenin başında başarı için sağlam bir temel oluşturmak önemlidir.
Burada projenizin kapsamını tanımlayacaksınız. Bu, kuruluşun
bilgilendirme ihtiyaçlarını belirleyerek başlayacağınız zamandır.
Planlama aşamasında bir projenin en geniş bakış açısına sahip
olacaksınız. İlgili tüm faktörleri ve süreçleri değerlendirerek, bir
eylem planını kavramsallaştırmak için yaratıcılığınızı kullanarak
tamamlamaya giden bir yolu haritalandırıyorsunuz. Burada, iş akışınızda
yenilikçi bir yaklaşım gerektirebilecek görevleri de özel olarak not
alacaksınız.

**Özet**: Planlama aşaması, projenin kapsamını kavramsallaştırdığınız ve
bir projeyi tamamlama sürecinde size rehberlik edecek adımları
geliştirdiğiniz yerdir.

İşte planlama aşaması görevlerinin türlerine birkaç örnek:

-   Araştırma iş verileri

-   Proje kapsamını tanımla

-   Bir iş akışı geliştirin

-   Proje ve/veya paydaş ihtiyaçlarını değerlendirin

#### **Analiz**

Analiz aşamasında ilk kez verilerle etkileşime gireceksiniz. Burada
proje için ihtiyaç duyacağınız tüm verileri edineceksiniz. Bazı veri
kümeleri kuruluşunuzdaki birincil kaynaklardan gelebilir. Diğerlerinin
şirketiniz dışındaki ikincil kaynaklardan toplanması gerekebilir.
Hükümet veya açık kaynaklı verilere ihtiyacınız olduğunu bile
görebilirsiniz. Analiz aşaması aynı zamanda keşifsel veri analizi veya
EDA ile ilgileneceğiniz yerdir. Bu, proje için gerekli tüm verilerin
temizlenmesini, yeniden düzenlenmesini ve analiz edilmesini içerir.

**Özet**: Analiz aşaması, projeniz için tüm verileri toplayacağınız,
hazırlayacağınız ve analiz edeceğiniz yerdir.

İşte aşama görevlerini analiz etme türlerine birkaç örnek:

-   Veritabanını biçimlendir

-   Verileri fırçala

-   Verileri kullanılabilir formatlara dönüştürün

#### **İnşaat** {#i̇nşaat}

Adından da anlaşılacağı gibi, inşaat aşaması tamamen bina ile ilgilidir.
AKPM\'nin bu aşamasında modeller inşa edecek, yorumlayacak ve revize
edeceksiniz. Bazı projeler, verilerinizdeki korelasyonları ortaya
çıkarmak için makine öğrenimi algoritmaları gerektirecektir. Aksi
takdirde kullanılmayacak olan verilerden bilgileri ortaya çıkarmak için
bu korelasyonları kullanacaksınız. Bu ilişkiler, kuruluşunuzun gelecek
hakkında bilinçli kararlar almasına yardımcı olabilir.

**Özet**: İnşaat aşamasında, veriler içinde kilitlenmiş gizli ilişkilere
erişmenizi sağlayacak modeller oluşturacaksınız.

İşte inşaat aşaması görev türlerine birkaç örnek:

-   Modelleme yaklaşımını seçin

-   Modeller oluştur

-   Makine öğrenimi algoritmaları oluşturun

#### **Yürüt**

Yürütme aşamasında, analizinizi ve inşanızı eyleme geçireceksiniz.
Burada bulgularınızı iç (kuruluşunuzun içinde) ve dış (kuruluşunuzun
dışında) paydaşlara ileteceksiniz. Oldukça sık, bu, birlikte
çalıştığınız şirketlerin iş tarafındaki paydaşları içerecektir.
Bulgularınızı sunmak, yürütme aşamasının sadece bir parçasıdır.
Paydaşlar geri bildirim sağlayacak, sorular soracak ve toplayıp dahil
edeceğiniz önerilerde bulunacaktır.

**Özet**: Yürütme aşamasında analizinizin bulgusunu sunacak, geri
bildirim alacak ve gerektiğinde revizyonlar yapacaksınız.

İşte yürütme aşaması görevlerine birkaç örnek:

-   Sonuçları paylaş

-   Bulguları diğer paydaşlara sunun

-   Geri bildirimi ele al

### İletişim ve PACE {#i̇letişim-ve-pace}

PACE iş akışının neresinde olursanız olun, çerçeveyi projenin
gerçekleştirilmesine taşımak için iletişim esastır. Bunu düşünmenin bir
yolu, PACE\'nin dört aşamasını tamamlanmış bir devre olarak
görselleştirmek ve iletişimin elektrik akışıyla temsil edilmesidir.

Her aşamada, iş akışını iyileştirmek için her zaman iletişime ihtiyaç
duyulacaktır. Bu, verileriniz hakkında sorular sormak, ek kaynaklar
toplamak, paydaşları ilerleme hakkında güncellemek veya bulguları sunmak
ve geri bildirim almak olabilir.

### PACE\'nin uyarlanabilirliği

Bir projenin başlangıcında, PACE modeli size rehberlik edecek iyi bir
yapı sunar. Başlangıçta, ihtiyaç duyacağınız bilgi ve araçları
topladığınız ve size rehberlik edecek bir çerçeve oluşturduğunuz
planlama aşamasına sahipsiniz. Verileri analiz ederken ve modeller
oluştururken, analiz ve yapım aşamaları size yardımcı olur. Bu
adımlardan sonra yürütme aşaması, sonuçları paylaştığınız ve geri
bildirim topladığınız aşamadır.

PACE modeli ilk olarak belirli bir sırayla aşamalar olarak sunulsa da,
açık iletişim akışının ihtiyacınız olan aşamalara kolayca geçmenizi
sağladığını keşfedeceksiniz. Yeni bilgi ve geri bildirimler sürecin
herhangi bir bölümüne dahil edilebilir. Verilerin bazı yönlerini
netleştirmek için analiz aşamasına geri dönmeniz ve ardından yeni
modeller oluşturmaya gerek kalmadan bu yönü paydaşlarınıza sunmak için
yürütme aşamasına geçmeniz gerekebilir. PACE çerçevesi herhangi bir
projeye uyacak şekilde uyarlanabilir. Uyarlanabilirliği sizi yüksek
derecede profesyonel esneklik ve iletişim gerektiren dinamik bir mesleğe
hazırlayacaktır.

### Key takeaways  {#key-takeaways-}

Veri profesyonelleri, veri projelerindeki çok sayıda görevi
yönetmelerine yardımcı olmak için yapılandırılmış iş akışlarına ihtiyaç
duyar. PACE profesyonel iş akışı, profesyonel yapılarınızı ve
uygulamalarınızı geliştirmenize yardımcı olmak için bu program için özel
olarak tasarlanmıştır. PACE, her aşama arasında akan iletişim ile
tamamlanmış bir devre gibi işlev görür. PACE\'nin tasarımı, gerektiğinde
aşamalar arasında serbest dolaşıma izin vererek esnekliği teşvik eder.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
# 2 Python\'u kullanmaya başlayın {#2-pythonu-kullanmaya-başlayın}
:::

::: {.cell .markdown}
## Kodlama
:::

::: {.cell .code execution_count="1"}
``` python
import pandas as pd
dataframe = pd.read_csv("https://storage.googleapis.com/kagglesdsdata/competitions/3136/26502/train.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1721564819&Signature=fPHv7fKX3DCqcfShmJ8XlQV0CAQHdID0JZRyHwzUaPPKqVVPDQ3aCDLx%2BF4KpaQP2SzD83KlPWZIxUSfte80K5adU%2FYDf9yjRMTQOBOvReTfO3aAnGgULCPGG1JFHAUoTTVe8XEFeQfnwf80%2BeNBNvmkXdiKDx5AWztbt04npcVfnpXZJhNBOdUIe%2Fz90jChG1%2Fo43JAWsGBg4YwzPqNb03d2RC5LcPvm1ANtGieIOo82DExb4meMCRycfh6nayDyG0Jj6Kj6gp9M3ny50u0sRFohu5A2vyXArKr0mtPIODVdAxVUlRnUIl2RLmQ7%2Fq9ZxiMEbVlcL0fREHgMF%2BbPA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv")
```
:::

::: {.cell .code execution_count="2"}
``` python
dataframe.head(5)
```

::: {.output .execute_result execution_count="2"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="3"}
``` python
dataframe[(dataframe['Age'] > 60) & (dataframe['Pclass'] == 3)]
```

::: {.output .execute_result execution_count="3"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>116</th>
      <td>117</td>
      <td>0</td>
      <td>3</td>
      <td>Connors, Mr. Patrick</td>
      <td>male</td>
      <td>70.5</td>
      <td>0</td>
      <td>0</td>
      <td>370369</td>
      <td>7.7500</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>280</th>
      <td>281</td>
      <td>0</td>
      <td>3</td>
      <td>Duane, Mr. Frank</td>
      <td>male</td>
      <td>65.0</td>
      <td>0</td>
      <td>0</td>
      <td>336439</td>
      <td>7.7500</td>
      <td>NaN</td>
      <td>Q</td>
    </tr>
    <tr>
      <th>326</th>
      <td>327</td>
      <td>0</td>
      <td>3</td>
      <td>Nysveen, Mr. Johan Hansen</td>
      <td>male</td>
      <td>61.0</td>
      <td>0</td>
      <td>0</td>
      <td>345364</td>
      <td>6.2375</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>483</th>
      <td>484</td>
      <td>1</td>
      <td>3</td>
      <td>Turkula, Mrs. (Hedwig)</td>
      <td>female</td>
      <td>63.0</td>
      <td>0</td>
      <td>0</td>
      <td>4134</td>
      <td>9.5875</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>851</th>
      <td>852</td>
      <td>0</td>
      <td>3</td>
      <td>Svensson, Mr. Johan</td>
      <td>male</td>
      <td>74.0</td>
      <td>0</td>
      <td>0</td>
      <td>347060</td>
      <td>7.7750</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="4"}
``` python
dataframe["2023 Fare"] = dataframe["Fare"] * 2
dataframe.head(5)
```

::: {.output .execute_result execution_count="4"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>2023 Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
      <td>14.5000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>142.5666</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
      <td>15.8500</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
      <td>106.2000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
      <td>16.1000</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="5"}
``` python
dataframe.iloc[1][3]
```

::: {.output .execute_result execution_count="5"}
    'Cumings, Mrs. John Bradley (Florence Briggs Thayer)'
:::
:::

::: {.cell .code execution_count="6"}
``` python
fare = dataframe.groupby(['Sex', 'Pclass']).agg({'Fare': ['count', 'sum']}) 
fare['fare avg'] = fare['Fare']['sum']/fare['Fare']['count'] 
fare
```

::: {.output .execute_result execution_count="6"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th colspan="2" halign="left">Fare</th>
      <th>fare avg</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>count</th>
      <th>sum</th>
      <th></th>
    </tr>
    <tr>
      <th>Sex</th>
      <th>Pclass</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">female</th>
      <th>1</th>
      <td>94</td>
      <td>9975.8250</td>
      <td>106.125798</td>
    </tr>
    <tr>
      <th>2</th>
      <td>76</td>
      <td>1669.7292</td>
      <td>21.970121</td>
    </tr>
    <tr>
      <th>3</th>
      <td>144</td>
      <td>2321.1086</td>
      <td>16.118810</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">male</th>
      <th>1</th>
      <td>122</td>
      <td>8201.5875</td>
      <td>67.226127</td>
    </tr>
    <tr>
      <th>2</th>
      <td>108</td>
      <td>2132.1125</td>
      <td>19.741782</td>
    </tr>
    <tr>
      <th>3</th>
      <td>347</td>
      <td>4393.5865</td>
      <td>12.661633</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="7"}
``` python
import pandas as pd

data = {'col1': [1, 2], 'col2': [3, 4]}
df = pd.DataFrame(data=data)
df
```

::: {.output .execute_result execution_count="7"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>col1</th>
      <th>col2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="8"}
``` python
import numpy as np

df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), columns=['a', 'b', 'c'], index=['x', 'y', 'z'])

df2
```

::: {.output .execute_result execution_count="8"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>a</th>
      <th>b</th>
      <th>c</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>x</th>
      <td>1</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>y</th>
      <td>4</td>
      <td>5</td>
      <td>6</td>
    </tr>
    <tr>
      <th>z</th>
      <td>7</td>
      <td>8</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="9"}
``` python
# Print class of first row 
print(type(dataframe.iloc[0]))

# Print class of "Same" column 
print(type(dataframe['Name']))
```

::: {.output .stream .stdout}
    <class 'pandas.core.series.Series'>
    <class 'pandas.core.series.Series'>
:::
:::

::: {.cell .code execution_count="10"}
``` python
dataframe[['Name','Age']]
```

::: {.output .execute_result execution_count="10"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Age</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Braund, Mr. Owen Harris</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>38.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Heikkinen, Miss. Laina</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Allen, Mr. William Henry</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>886</th>
      <td>Montvila, Rev. Juozas</td>
      <td>27.0</td>
    </tr>
    <tr>
      <th>887</th>
      <td>Graham, Miss. Margaret Edith</td>
      <td>19.0</td>
    </tr>
    <tr>
      <th>888</th>
      <td>Johnston, Miss. Catherine Helen "Carrie"</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>889</th>
      <td>Behr, Mr. Karl Howell</td>
      <td>26.0</td>
    </tr>
    <tr>
      <th>890</th>
      <td>Dooley, Mr. Patrick</td>
      <td>32.0</td>
    </tr>
  </tbody>
</table>
<p>891 rows × 2 columns</p>
</div>
```
:::
:::

::: {.cell .code execution_count="11"}
``` python
dataframe.iloc[0]
```

::: {.output .execute_result execution_count="11"}
    PassengerId                          1
    Survived                             0
    Pclass                               3
    Name           Braund, Mr. Owen Harris
    Sex                               male
    Age                               22.0
    SibSp                                1
    Parch                                0
    Ticket                       A/5 21171
    Fare                              7.25
    Cabin                              NaN
    Embarked                             S
    2023 Fare                         14.5
    Name: 0, dtype: object
:::
:::

::: {.cell .code execution_count="12"}
``` python
dataframe.iloc[[0]]
```

::: {.output .execute_result execution_count="12"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>2023 Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.25</td>
      <td>NaN</td>
      <td>S</td>
      <td>14.5</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="13"}
``` python
dataframe.iloc[0:3]
```

::: {.output .execute_result execution_count="13"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
      <th>2023 Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
      <td>14.5000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
      <td>142.5666</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
      <td>15.8500</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="14"}
``` python
dataframe.iloc[0:3,[3,4]]
```

::: {.output .execute_result execution_count="14"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Sex</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="15"}
``` python
dataframe.iloc[:,[3]]
```

::: {.output .execute_result execution_count="15"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Braund, Mr. Owen Harris</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Heikkinen, Miss. Laina</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Allen, Mr. William Henry</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>886</th>
      <td>Montvila, Rev. Juozas</td>
    </tr>
    <tr>
      <th>887</th>
      <td>Graham, Miss. Margaret Edith</td>
    </tr>
    <tr>
      <th>888</th>
      <td>Johnston, Miss. Catherine Helen "Carrie"</td>
    </tr>
    <tr>
      <th>889</th>
      <td>Behr, Mr. Karl Howell</td>
    </tr>
    <tr>
      <th>890</th>
      <td>Dooley, Mr. Patrick</td>
    </tr>
  </tbody>
</table>
<p>891 rows × 1 columns</p>
</div>
```
:::
:::

::: {.cell .code execution_count="16"}
``` python
dataframe.iloc[0,3]
```

::: {.output .execute_result execution_count="16"}
    'Braund, Mr. Owen Harris'
:::
:::

::: {.cell .code execution_count="17"}
``` python
dataframe.loc[0:3,['Name']]
```

::: {.output .execute_result execution_count="17"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Braund, Mr. Owen Harris</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Heikkinen, Miss. Laina</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .markdown}
  -------------------------------------------------------------------------------------------------------------------------------------------
  **Attribute**                                                                                                    **Description**
  ---------------------------------------------------------------------------------------------------------------- --------------------------
  [columns](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html#pandas.DataFrame.columns)   Returns the column labels
                                                                                                                   of the dataframe

  [dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes)      Returns the data types in
                                                                                                                   the dataframe

  [iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc)            Accesses a group of rows
                                                                                                                   and columns using
                                                                                                                   integer-based indexing

  [loc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc)               Accesses a group of rows
                                                                                                                   and columns by label(s) or
                                                                                                                   a Boolean array

  [shape](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape)         Returns a tuple
                                                                                                                   representing the
                                                                                                                   dimensionality of the
                                                                                                                   dataframe

  [values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html#pandas.DataFrame.values)      Returns a NumPy
                                                                                                                   representation of the
                                                                                                                   dataframe
  -------------------------------------------------------------------------------------------------------------------------------------------
:::

::: {.cell .markdown}
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  **Method**                                                                                                                        **Description**
  --------------------------------------------------------------------------------------------------------------------------------- ----------------------------------------
  [apply(*)*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply)                      Applies a function over an axis of the
                                                                                                                                    dataframe

  [copy()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html#pandas.DataFrame.copy)                           Makes a copy of the dataframe's indices
                                                                                                                                    and data

  [describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe)               Returns descriptive statistics of the
                                                                                                                                    dataframe, including the minimum,
                                                                                                                                    maximum, mean, and percentile values of
                                                                                                                                    its numeric columns; the row count; and
                                                                                                                                    the data types

  [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop)                           Drops specified labels from rows or
                                                                                                                                    columns

  [groupby()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby)                  Splits the dataframe, applies a
                                                                                                                                    function, and combines the results

  [head(*n=5*)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html#pandas.DataFrame.head)                      Returns the first *n* rows of the
                                                                                                                                    dataframe (default=5)

  [info()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html#pandas.DataFrame.info)                           Returns a concise summary of the
                                                                                                                                    dataframe

  [isna()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna)                           Returns a same-sized Boolean dataframe
                                                                                                                                    indicating whether each value is null
                                                                                                                                    (can also use isnull() as an alias)

  [sort_values()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values)      Sorts by the values across a given axis

  [value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts)   Returns a series containing counts of
                                                                                                                                    unique rows in the dataframe

  [where()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html#pandas.DataFrame.where)                        Replaces values in the dataframe where a
                                                                                                                                    given condition is false
  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------
:::

::: {.cell .code execution_count="18"}
``` python
data = {'planet': ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune'],
        'radius_km': [2440, 6052, 6371, 3390, 69911, 58232, 25362, 246221],
        'moons': [0, 0, 1, 2, 80, 83, 27, 14]}

planets = pd.DataFrame(data)

planets
```

::: {.output .execute_result execution_count="18"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius_km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uranus</td>
      <td>25362</td>
      <td>27</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Neptune</td>
      <td>246221</td>
      <td>14</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="19"}
``` python
mask = planets['moons'] < 20
mask
```

::: {.output .execute_result execution_count="19"}
    0     True
    1     True
    2     True
    3     True
    4    False
    5    False
    6    False
    7     True
    Name: moons, dtype: bool
:::
:::

::: {.cell .code execution_count="20"}
``` python
planets[mask]
```

::: {.output .execute_result execution_count="20"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius_km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Neptune</td>
      <td>246221</td>
      <td>14</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="21"}
``` python
planets[planets['moons']<20]
```

::: {.output .execute_result execution_count="21"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius_km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Neptune</td>
      <td>246221</td>
      <td>14</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="22"}
``` python
mask = (planets['moons'] < 10) | (planets['moons'] > 50)

mask
```

::: {.output .execute_result execution_count="22"}
    0     True
    1     True
    2     True
    3     True
    4     True
    5     True
    6    False
    7    False
    Name: moons, dtype: bool
:::
:::

::: {.cell .code execution_count="23"}
``` python
planets[mask]
```

::: {.output .execute_result execution_count="23"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius_km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="24"}
``` python
mask = (planets['moons'] > 20) & ~ (planets['moons'] == 80) & ~ (planets['radius_km'] < 50000)
planets[mask]
```

::: {.output .execute_result execution_count="24"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius_km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="25"}
``` python
data = {'planet': ['Mercury', 'Venus', 'Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune'],
        'radius_km': [2440, 6652, 6371, 3390, 69911, 58232, 25362, 24622], 
        'moons': [0, 0, 1, 2, 80, 83, 27, 14],
        'type': ['terrestrial', 'terrestrial', 'terrestrial', 'terrestrial', 'gas giant', 'gas giant', 'ice giant', 'ice giant'], 
        'rings': ['no', 'по', 'no', 'no', 'yes', 'yes', 'yes', 'yes'], 
        'mean_temp_c': [167, 464, 15, 65, 110, 140, 195, -200], 
        'magnetic_field': ['yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes']}

planets = pd.DataFrame(data)

planets
```

::: {.output .execute_result execution_count="25"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius_km</th>
      <th>moons</th>
      <th>type</th>
      <th>rings</th>
      <th>mean_temp_c</th>
      <th>magnetic_field</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>167</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6652</td>
      <td>0</td>
      <td>terrestrial</td>
      <td>по</td>
      <td>464</td>
      <td>no</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>15</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>65</td>
      <td>no</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>110</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>140</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uranus</td>
      <td>25362</td>
      <td>27</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>195</td>
      <td>yes</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Neptune</td>
      <td>24622</td>
      <td>14</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-200</td>
      <td>yes</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="26"}
``` python
planets.groupby(['type']).sum()
```

::: {.output .execute_result execution_count="26"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius_km</th>
      <th>moons</th>
      <th>rings</th>
      <th>mean_temp_c</th>
      <th>magnetic_field</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gas giant</th>
      <td>JupiterSaturn</td>
      <td>128143</td>
      <td>163</td>
      <td>yesyes</td>
      <td>250</td>
      <td>yesyes</td>
    </tr>
    <tr>
      <th>ice giant</th>
      <td>UranusNeptune</td>
      <td>49984</td>
      <td>41</td>
      <td>yesyes</td>
      <td>-5</td>
      <td>yesyes</td>
    </tr>
    <tr>
      <th>terrestrial</th>
      <td>MercuryVenusEarthMars</td>
      <td>18853</td>
      <td>3</td>
      <td>noпоnono</td>
      <td>711</td>
      <td>yesnoyesno</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="27"}
``` python
planets.groupby(['type']).sum()[['moons']]
```

::: {.output .execute_result execution_count="27"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>moons</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gas giant</th>
      <td>163</td>
    </tr>
    <tr>
      <th>ice giant</th>
      <td>41</td>
    </tr>
    <tr>
      <th>terrestrial</th>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="28"}
``` python
planets.groupby(['type','magnetic_field'])[['radius_km','moons','mean_temp_c']].mean()
```

::: {.output .execute_result execution_count="28"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>radius_km</th>
      <th>moons</th>
      <th>mean_temp_c</th>
    </tr>
    <tr>
      <th>type</th>
      <th>magnetic_field</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gas giant</th>
      <th>yes</th>
      <td>64071.5</td>
      <td>81.5</td>
      <td>125.0</td>
    </tr>
    <tr>
      <th>ice giant</th>
      <th>yes</th>
      <td>24992.0</td>
      <td>20.5</td>
      <td>-2.5</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">terrestrial</th>
      <th>no</th>
      <td>5021.0</td>
      <td>1.0</td>
      <td>264.5</td>
    </tr>
    <tr>
      <th>yes</th>
      <td>4405.5</td>
      <td>0.5</td>
      <td>91.0</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="29"}
``` python
planets.groupby(['type'])[['radius_km','moons','mean_temp_c']].agg(['mean', 'median'])
```

::: {.output .execute_result execution_count="29"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">radius_km</th>
      <th colspan="2" halign="left">moons</th>
      <th colspan="2" halign="left">mean_temp_c</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>median</th>
      <th>mean</th>
      <th>median</th>
      <th>mean</th>
      <th>median</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gas giant</th>
      <td>64071.50</td>
      <td>64071.5</td>
      <td>81.50</td>
      <td>81.5</td>
      <td>125.00</td>
      <td>125.0</td>
    </tr>
    <tr>
      <th>ice giant</th>
      <td>24992.00</td>
      <td>24992.0</td>
      <td>20.50</td>
      <td>20.5</td>
      <td>-2.50</td>
      <td>-2.5</td>
    </tr>
    <tr>
      <th>terrestrial</th>
      <td>4713.25</td>
      <td>4880.5</td>
      <td>0.75</td>
      <td>0.5</td>
      <td>177.75</td>
      <td>116.0</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="30"}
``` python
planets.groupby(['type'])[['radius_km','moons','mean_temp_c']].agg(['mean', 'min', 'max'])
```

::: {.output .execute_result execution_count="30"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="3" halign="left">radius_km</th>
      <th colspan="3" halign="left">moons</th>
      <th colspan="3" halign="left">mean_temp_c</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>min</th>
      <th>max</th>
      <th>mean</th>
      <th>min</th>
      <th>max</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gas giant</th>
      <td>64071.50</td>
      <td>58232</td>
      <td>69911</td>
      <td>81.50</td>
      <td>80</td>
      <td>83</td>
      <td>125.00</td>
      <td>110</td>
      <td>140</td>
    </tr>
    <tr>
      <th>ice giant</th>
      <td>24992.00</td>
      <td>24622</td>
      <td>25362</td>
      <td>20.50</td>
      <td>14</td>
      <td>27</td>
      <td>-2.50</td>
      <td>-200</td>
      <td>195</td>
    </tr>
    <tr>
      <th>terrestrial</th>
      <td>4713.25</td>
      <td>2440</td>
      <td>6652</td>
      <td>0.75</td>
      <td>0</td>
      <td>2</td>
      <td>177.75</td>
      <td>15</td>
      <td>464</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="31"}
``` python
planets.groupby(['type'])[['radius_km','moons','mean_temp_c']].agg({'radius_km': ['mean'], 'moons' : ['min', 'max']})
```

::: {.output .execute_result execution_count="31"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>radius_km</th>
      <th colspan="2" halign="left">moons</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>min</th>
      <th>max</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gas giant</th>
      <td>64071.50</td>
      <td>80</td>
      <td>83</td>
    </tr>
    <tr>
      <th>ice giant</th>
      <td>24992.00</td>
      <td>14</td>
      <td>27</td>
    </tr>
    <tr>
      <th>terrestrial</th>
      <td>4713.25</td>
      <td>0</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="32"}
``` python
def percentile_90(x):
    return x.quantile(0.9)

planets.groupby(['type'])[['radius_km','moons','mean_temp_c']].agg(['mean', percentile_90])
```

::: {.output .execute_result execution_count="32"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">radius_km</th>
      <th colspan="2" halign="left">moons</th>
      <th colspan="2" halign="left">mean_temp_c</th>
    </tr>
    <tr>
      <th></th>
      <th>mean</th>
      <th>percentile_90</th>
      <th>mean</th>
      <th>percentile_90</th>
      <th>mean</th>
      <th>percentile_90</th>
    </tr>
    <tr>
      <th>type</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>gas giant</th>
      <td>64071.50</td>
      <td>68743.1</td>
      <td>81.50</td>
      <td>82.7</td>
      <td>125.00</td>
      <td>137.0</td>
    </tr>
    <tr>
      <th>ice giant</th>
      <td>24992.00</td>
      <td>25288.0</td>
      <td>20.50</td>
      <td>25.7</td>
      <td>-2.50</td>
      <td>155.5</td>
    </tr>
    <tr>
      <th>terrestrial</th>
      <td>4713.25</td>
      <td>6567.7</td>
      <td>0.75</td>
      <td>1.7</td>
      <td>177.75</td>
      <td>374.9</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .markdown}
### agg()

[agg()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html)
işlevi, bir veri çerçevesine aynı anda birden fazla işlev uygulamak
istediğinizde kullanışlıdır. agg(), DataFrame sınıfına ait bir
yöntemdir. \"Toplam\" anlamına gelir. En önemli parametreleri şunlardır:

Func: Uygulanacak işlev

Eksen: Fonksiyonun uygulanacağı eksen (varsayılan= 0).

### Yerleşik toplama işlevleri

Önceki örnekler, groupby nesnelerine uygulanan mean(), min() ve size()
toplama işlevlerini göstermiştir. Birçok mevcut yerleşik toplama işlevi
vardır. Daha yaygın kullanılanlardan bazıları şunlardır:

Count(): Her gruptaki boş olmayan değerlerin sayısı

Sum(): Her gruptaki değerlerin toplamı

Mean(): Her gruptaki değerlerin ortalaması

Median(): Her gruptaki değerlerin medyanı

Min(): Her gruptaki minimum değer

Max(): Her gruptaki maksimum değer

Std(): Her gruptaki değerlerin standart sapması

Var(): Her gruptaki değerlerin varyansı
:::

::: {.cell .code execution_count="33"}
``` python
import numpy as np 
import pandas as pd

data = {'planet': ['Mercury', 'Venus', 'Earth', 'Mars'], 'radius km': [2440, 6052, 6371, 3390], 'moons': [0, 0, 1, 2],}

df1 = pd.DataFrame(data) 

df1
```

::: {.output .execute_result execution_count="33"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="34"}
``` python
data = {'planet': ['Jupiter', 'Saturn', 'Uranus', 'Neptune'], 'radius km': [69911, 58232, 25362, 24622], 'moons': [80, 83, 27, 14],} 

df2 = pd.DataFrame(data)

df2
```

::: {.output .execute_result execution_count="34"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Uranus</td>
      <td>25362</td>
      <td>27</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Neptune</td>
      <td>24622</td>
      <td>14</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="35"}
``` python
df3 = pd.concat([df1,df2], axis= 0)
df3
```

::: {.output .execute_result execution_count="35"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
    </tr>
    <tr>
      <th>0</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Uranus</td>
      <td>25362</td>
      <td>27</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Neptune</td>
      <td>24622</td>
      <td>14</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="36"}
``` python
df3 = df3.reset_index(drop=True)
df3
```

::: {.output .execute_result execution_count="36"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uranus</td>
      <td>25362</td>
      <td>27</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Neptune</td>
      <td>24622</td>
      <td>14</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="37"}
``` python
import pandas as pd
import numpy as np

data= {
    'planet': ['Earth', 'Mars', 'Jupiter', 'Saturn', 'Uranus', 'Neptune', 'Janssen', 'Tadmor'],
    'type': ['terrestrial', 'terrestrial', 'gas giant', 'gas giant', 'ice giant', 'ice giant', 'super earth', 'gas giant'],
    'rings': ['no', 'no', 'yes', 'yes', 'yes', 'yes', 'no', None],
    'mean_temp_c': [15.0, -65.0, -110.0, -140.0, -195.0, -200.0, np.nan, np.nan],
    'magnetic_field': ['yes', 'no', 'yes', 'yes', 'no', 'yes', None, None],
    'life': [1, 0, 0, 0, 0, 0, 1, 1]
}

df4 = pd.DataFrame(data)
df4
```

::: {.output .execute_result execution_count="37"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>type</th>
      <th>rings</th>
      <th>mean_temp_c</th>
      <th>magnetic_field</th>
      <th>life</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Earth</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>15.0</td>
      <td>yes</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Mars</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>-65.0</td>
      <td>no</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jupiter</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-110.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Saturn</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-140.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Uranus</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-195.0</td>
      <td>no</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Neptune</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-200.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Janssen</td>
      <td>super earth</td>
      <td>no</td>
      <td>NaN</td>
      <td>None</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Tadmor</td>
      <td>gas giant</td>
      <td>None</td>
      <td>NaN</td>
      <td>None</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Merge()
:::

::: {.cell .markdown}
`<img src="attachment:e4431cde-a4bf-4002-bb07-310345a405f6.png" width="500" />`{=html}

`<img src="attachment:8b26137f-69d0-4ae9-b889-0ef7573d19d5.png" width="500" />`{=html}

`<img src="attachment:7173f732-c8ec-4093-9cdb-64197bd35fee.png" width="500" />`{=html}

`<img src="attachment:4d43150c-3083-43d3-8d43-e74153aae593.png" width="500" />`{=html}

`<img src="attachment:2cd36048-5019-42ed-a55d-299098daf825.png" width="500" />`{=html}
:::

::: {.cell .code execution_count="39"}
``` python
inner = pd.merge(df3, df4, on="planet", how='inner')
inner
```

::: {.output .execute_result execution_count="39"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
      <th>type</th>
      <th>rings</th>
      <th>mean_temp_c</th>
      <th>magnetic_field</th>
      <th>life</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>15.0</td>
      <td>yes</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>-65.0</td>
      <td>no</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-110.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-140.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Uranus</td>
      <td>25362</td>
      <td>27</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-195.0</td>
      <td>no</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Neptune</td>
      <td>24622</td>
      <td>14</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-200.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="40"}
``` python
outer = pd.merge(df3, df4, on="planet", how='outer')
outer
```

::: {.output .execute_result execution_count="40"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
      <th>type</th>
      <th>rings</th>
      <th>mean_temp_c</th>
      <th>magnetic_field</th>
      <th>life</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371.0</td>
      <td>1.0</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>15.0</td>
      <td>yes</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390.0</td>
      <td>2.0</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>-65.0</td>
      <td>no</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jupiter</td>
      <td>69911.0</td>
      <td>80.0</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-110.0</td>
      <td>yes</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Saturn</td>
      <td>58232.0</td>
      <td>83.0</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-140.0</td>
      <td>yes</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uranus</td>
      <td>25362.0</td>
      <td>27.0</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-195.0</td>
      <td>no</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Neptune</td>
      <td>24622.0</td>
      <td>14.0</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-200.0</td>
      <td>yes</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Janssen</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>super earth</td>
      <td>no</td>
      <td>NaN</td>
      <td>None</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Tadmor</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>gas giant</td>
      <td>None</td>
      <td>NaN</td>
      <td>None</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="41"}
``` python
left = pd.merge(df3, df4, on="planet", how='left')
left
```

::: {.output .execute_result execution_count="41"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
      <th>type</th>
      <th>rings</th>
      <th>mean_temp_c</th>
      <th>magnetic_field</th>
      <th>life</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mercury</td>
      <td>2440</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Venus</td>
      <td>6052</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Earth</td>
      <td>6371</td>
      <td>1</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>15.0</td>
      <td>yes</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Mars</td>
      <td>3390</td>
      <td>2</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>-65.0</td>
      <td>no</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Jupiter</td>
      <td>69911</td>
      <td>80</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-110.0</td>
      <td>yes</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Saturn</td>
      <td>58232</td>
      <td>83</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-140.0</td>
      <td>yes</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Uranus</td>
      <td>25362</td>
      <td>27</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-195.0</td>
      <td>no</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Neptune</td>
      <td>24622</td>
      <td>14</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-200.0</td>
      <td>yes</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .code execution_count="42"}
``` python
right = pd.merge(df3, df4, on="planet", how='right')
right
```

::: {.output .execute_result execution_count="42"}
```{=html}
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>planet</th>
      <th>radius km</th>
      <th>moons</th>
      <th>type</th>
      <th>rings</th>
      <th>mean_temp_c</th>
      <th>magnetic_field</th>
      <th>life</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Earth</td>
      <td>6371.0</td>
      <td>1.0</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>15.0</td>
      <td>yes</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Mars</td>
      <td>3390.0</td>
      <td>2.0</td>
      <td>terrestrial</td>
      <td>no</td>
      <td>-65.0</td>
      <td>no</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jupiter</td>
      <td>69911.0</td>
      <td>80.0</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-110.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Saturn</td>
      <td>58232.0</td>
      <td>83.0</td>
      <td>gas giant</td>
      <td>yes</td>
      <td>-140.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Uranus</td>
      <td>25362.0</td>
      <td>27.0</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-195.0</td>
      <td>no</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Neptune</td>
      <td>24622.0</td>
      <td>14.0</td>
      <td>ice giant</td>
      <td>yes</td>
      <td>-200.0</td>
      <td>yes</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Janssen</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>super earth</td>
      <td>no</td>
      <td>NaN</td>
      <td>None</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Tadmor</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>gas giant</td>
      <td>None</td>
      <td>NaN</td>
      <td>None</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
```
:::
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
# 3 Go Beyond the numbers {#3-go-beyond-the-numbers}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## EDA Prosesi

## **Görsel örnek**
:::

::: {.cell .markdown}
Norveç\'teki iğne yapraklı bir ormandaki ağaçlar hakkında yalnızca 200
satır ve beş sütun veriye sahip bir veri kümesi atandığını hayal edin.
Tam analizinizi tamamlamak için 1.000\'den fazla satıra ve en az iki
sütuna daha ihtiyacınız olacağını biliyorsunuz. Bundan çok daha fazla
ayrıntı olmasa bile, tüm EDA süreciniz şöyle görünebilir:  
![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/e9fc0a44-250f-476e-b792-47823035da03.png)
`<img src="attachment:e9fc0a44-250f-476e-b792-47823035da03.png" width="1000"/>`{=html}

1.  **Keşfetme**: Veri kümesinin genel şeklini, boyutunu ve içeriğini
    kontrol edersiniz. Veri konusunda kısa olduğunu görüyorsunuz.

2.  **Katılma**: Daha fazla veri eklersiniz.

3.  **Doğrulama**: Yeni verilerde hatalar veya yazım hataları olmadığını
    hızlı bir şekilde kontrol edersiniz.

4.  **Yapılandırma**: Trendleri anlamak için verileri farklı zaman
    dilimlerinde ve segmentlerde yapılandırırsınız.

5.  **Doğrulama:** Yapılandırmada yaptığınız yeni sütunların doğru
    tasarlandığından emin olmak için başka bir hızlı kontrol yaparsınız.

6.  **Temizlik**: Aykırıları, eksik verileri ve dönüşüm veya dönüşüm
    ihtiyaçlarını kontrol edersiniz.

7.  **Doğrulama**: Temizledikten sonra, yaptığınız değişikliklerin doğru
    ve doğru olup olmadığını iki kez kontrol edersiniz.

8.  **Sunum**: Veri kümenizi bir eşle paylaşırsınız.

Verilerde yaptığınız değişikliklerin farkında olmadan hata vermediğinden
emin olmak için \"geçerli\" uygulamasını yinelemeli olarak veya birden
çok kez gerçekleştirdiğinize dikkat edin. Ayrıca, önceden daha fazla
veriye olan ihtiyacı fark ettiğiniz için, \"keşfetme\" uygulamasının
hemen ardından \"katılma\" uygulaması gerçekleştirildi.

Temizlenmiş veri kümenizi bir eşinize sunduktan sonra, daha fazla keşif
ve/veya temizlik için notlar veya fikirler alma şansınız yüksektir. Bu
nedenle, daha da fazla yineleme göreceksiniz.

**Profesyonel ipucu**: Veri bilimcileri, \"temiz\" ve modelleme veya
makine öğrenimi algoritmaları için hazır olduğunu ilan etmekte
kendilerini rahat hissetmeden önce bir veri kümesinde EDA uygulamalarını
birden çok kez gerçekleştirmeyi bekliyorlar.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Etik makine öğreniminde EDA\'nın önemi
:::

::: {.cell .markdown}
Algoritmalar ve makine öğrenimi ağları bireyler, şirketler ve hatta
hükümetler adına giderek daha fazla karar vermeye başladıkça, etik ve
düzenleme tartışması giderek daha önemli hale geliyor. [Etik Yapay Zeka
ve Makine Öğrenimi
Enstitüsü](https://ethical.institute/principles.html)\'ye göre, makine
öğrenimi sistemlerini sorumlu bir şekilde geliştirmek için sekiz ilke
vardır.

**EDA sürecinin temel ilkeleri**

Aşağıdaki iki ilke doğası gereği EDA sürecinin bir parçasıdır:

**İnsan büyütme**: Bu ilke, insanların gözetim için AI veya makine
öğrenimi algoritma sistemlerine eklenmesini sağlar. Veri bilimcileri
tarafından gerçekleştirilen kapsamlı EDA, bir algoritmaya beslenen
önyargıyı, dengesizliği ve yanlışlıkları sınırlamanın belki de en iyi
yollarından biridir.

**Önyargı değerlendirmesi**: İnsan müdahalesi olmadan, önyargı makine
öğrenimi modellerinde çok kolay enjekte edilir ve yeniden üretilir.
Metodik EDA süreçlerinin gerçekleştirilmesi, veri bilimcilerinin
verilerdeki önyargıların ve dengesizliklerin farkında olmalarını ve
bunlara göre hareket etmelerini sağlayacaktır.

**Profesyonal ipucu**: Veri kariyer alanında etik standartlara bağlılığı
sağlamanın önemi abartılamaz. Veri profesyonellerinin, EDA çalışmalarına
sürekli olarak etik bir zihniyet uygulayarak önyargı ve ayrımcılığı
tanımak için kapasitelerini sürekli olarak büyütmeleri gerekir.

Makine öğreniminin ötesinde, EDA neredeyse her önemli veritabanı
kararına uygulanabilir. İleride, EDA\'nın birçok uygulaması ve
yinelemeli ve sıralı olmayan bir yaklaşımın gerekliliği hakkında bilgi
edineceksiniz.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Şematik Gösterim
:::

::: {.cell .markdown}
``` python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime as dt

# Read in the 2018 lightning strike dataset
df = pd.read_csv('eda_using_basic_data_functions_in_python_dataset1.csv')
```

``` python
# Eğer tarih sütunu varsa
df['date'] = pd.to_datetime(df['date'])
```

``` python
# Inspect the first 10 rows 
df.head(10)
```

`<img src="attachment:97b20444-4f09-4e44-a9c8-356908ba5ff5.png" width="400"/>`{=html}

``` python
#Get more information about the data, including data types of each column 
df.info()
```

`<img src="attachment:b2abca2d-2483-4f3b-82b5-f8e59076e267.png" width="400"/>`{=html}

``` python
df['month'] = df['date'].dt.month
df.head()
```

`<img src="attachment:90c7659d-ff84-4331-8f99-b37a38e49465.png" width="400"/>`{=html}

``` python
# Create a new 'month txt' column 
df['month_txt'] = df['date'].dt.month_name().str.slice(stop=3)
```

``` python
# Create new helper dataframe for plotting
df_by_month = df.groupby(['month', 'month_txt']).sum().sort_values('month', ascending=True).head(12).reset_index()
df_by_month
```

`<img src="attachment:48244ae1-0822-4176-a992-4bdbdc4e36bc.png" width="300"/>`{=html}

``` python
plt.bar(x=df_by_month[ 'month_txt' ],height=df_by_month['number_of_strikes'],label="Number of strikes")

plt.xlabel ("months (2018)")
plt.ylabel ("Number of lightning strikes")
plt.title("Number of lightning strikes in 2018 by months")

plt.legend()
plt.show()
```

`<img src="attachment:5f4d3739-6f85-48e5-879a-5a1c10aeaeb4.png" width="500"/>`{=html}

------------------------------------------------------------------------

``` python
# Import statements
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# Read in the 2018 lightning strike dataset
df = pd.read_csv('eda_using_basic_data_functions_in_python_dataset1.csv')

# Convert 'date' column to datetime
df['date'] = pd.to_datetime(df['date'])
```

``` python
# Create four new columns
df('week'] = df['date'].dt.strftime('%Y-W%V') #2016-W27
df['month'] = df['date'].dt.strftime ('%Y-%m')
df['quarter'] = df['date'].dt.to_period('Q').dt.strftime('%Y-Q%q')
df['year'] = df['date'].dt.strftime('%Y')
```

``` python
df.head()
```

`<img src="attachment:a45bc50d-981d-4433-80fc-f2c060c8350e.png" width="600"/>`{=html}

``` python
# Create new dataframe view of just 2018 data, summed by week
df_by_week_2018 = df[df['year']=='2018'].groupby(['week']).sum().reset_index()
```

``` python
# Plot a bar chart of weekly strike totals in 2018
plt.bar(x df_by_week_2018['week'], height = df_by_week_2018['number_of_strikes']) 
plt.plot() 
plt.xlabel("Week number") 
plt.ylabel("Number of lightning strikes")
plt.title("Number of lightning strikes per week (2018)")
```

`<img src="attachment:0fe0ed60-e80a-44d5-af5b-fe90d7d2bbdf.png" width="500"/>`{=html}

``` python
# Plot a bar chart of weekly strike totals in 2018
plt.bar(x df_by_week_2018['week'], height = df_by_week_2018['number_of_strikes']) 
plt.plot() 
plt.xlabel("Week number") 
plt.ylabel("Number of lightning strikes")
plt.title("Number of lightning strikes per week (2018)")
plt.xticks(rotation = 45, fontsize = 8) # Rotate x-axis labels and decrease font size
```

`<img src="attachment:97b8385f-6fba-49b4-bacc-4fab0e1a778c.png" width="800"/>`{=html}
:::

::: {.cell .markdown}
``` python
df_by_quarter['number_strikes'].div(1000000)
# Group 2016-2018 data by quarter and sum
df_by_quarter = df.groupby(['quarter']).sum().reset_index()
# Format as text, in millions
df_by _quarter('number_of_strikes_formated'] = df_by_quarter['number_of_strikes'].div(1000000).round(1).astype(:
```

``` python
plt.figure(figsize = (15,5))
plt.bar(x = df_by_quarter['quarter'], height=df_by_quarter['number_of_strikes'])
```

``` python
def addlabels (x, y, labels):
    'Iterates over data and plots text labels above each bar of bar graph.'
    for i in range(len(x)):
        plt.text(i, y[i], labels[i], ha 'center', va = 'bottom')

plt.figure(figsize(15,5))
plt.bar(x=df_by_quarter['quarter'], height=df_by_quarter['number_of_strikes'])
addlabels(df_by_quarter['quarter'], df_by_quarter['number_of_strikes'], df_by_quarter['number_of_strikes_formated'])
plt.plot()
plt.xlabel('Quarter')
plt.ylabel('Number of lightning strikes')
plt.title('Number of lightning strikes per quarter (2016-2018)')
plt.show()
```
:::

::: {.cell .markdown}
`<img src="attachment:790f9cce-3dbd-4c6b-8df3-625799c72529.png" width="800"/>`{=html}
:::

::: {.cell .markdown}
``` python
# Create two new columns
df_by_quarter['quarter_number'] = df_by_quarter['quarter'].str[-2:]
df_by_quarter['year'] = df_by_quarter['quarter'].str[:4]
df_by_quarter.head()
plt.figure(figsize (15,5))
p=sns.barplot(data=df_by_quarter, X='quarter_number', y='number_of_strikes', hue='year')
for bin p.patches:
    p.annotate(str(round(b.get_height()/1000000, 1))+'M',
    (b.get_x() + b.get_width() / 2., b.get_height() + 1.2e6),
    ha='center', va='bottom',
    xytext (0, -12),
    textcoords = 'offset points')
plt.xlabel("Quarter")
plt.ylabel("Number of lightning strikes")
plt.title("Number of lightning strikes per quarter (2016-2018)")
plt.show()
```

`<img src="attachment:076688a1-5d2b-4892-a395-75af614551cb.png" width="800"/>`{=html}
:::

::: {.cell .markdown}
``` python
# Import statements
import pandas as pd
import numpy as np
import seaborn as sns
import datetime
from matplotlib import pyplot as plt

# Read in the 2018 lightning strike dataset
df = pd.read_csv('eda_using_basic_data_functions_in_python_dataset1.csv')

# Convert the `date` column to datetime 
df['date'] = pd.to_datetime(df['date']) df.head()
```

`<img src="attachment:5a81402d-c239-4a32-855e-8f709ba00290.png" width="500"/>`{=html}

``` python
df.shape
(3401012,3)
```

``` python
df.drop_duplicates().shape
(3401012,3)
```

``` python
# Sort by number of strikes in descending order
df.sort_values(by='number_of_strikes', ascending=False).head(10)
```

`<img src="attachment:d8eaf372-4f10-4275-bb8d-75e6d74ad5d2.png" width="500"/>`{=html}

``` python
# Identify locations that appear most in the dataset
df.center_point_geom.value_counts()
```

`<img src="attachment:db435b25-b15c-4545-a174-24044b8a029d.png" width="500"/>`{=html}

``` python
# Identify top 20 locations with most days of lightning
df.center_point_geom.value_counts()[20].rename_axis('unique_values').reset_index(name='counts').style.background_gradient()
```

`<img src="attachment:8e3fc4d3-5702-4d11-866f-e7bcd3014529.png" width="300"/>`{=html}

``` python
# Create two new columns
df['week'] = df.date.dt.isocalendar().week 
df['weekday']= df.date.dt.day_name()
df.head()
```

`<img src="attachment:3d60bd6a-7f55-4af7-91a9-cdc541adc8b1.png" width="500"/>`{=html}

``` python
# Calculate mean count of lightning strikes for each weekday
df[['weekday', 'number_of_strikes']].groupby(['weekday']).mean()
```

`<img src="attachment:aace389c-05cc-4ee1-ab43-581b18a2f97b.png" width="300"/>`{=html}

``` python
# Define order of days for the plot
weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')
```

``` python
# Create boxplots of strike counts for each day of week 
g=sns.boxplot(data=df, 
              x='weekday', 
              y='number_of strikes',
              order=weekday_order,
              showfliers=False );
g.set_title('Lightning distribution per weekday (2018)');
```

`<img src="attachment:a047245c-1951-4c83-84ef-8ad51189c248.png" width="300"/>`{=html}

``` python
# Create new dataframe combining 2016-2017 data with 2018 data
union_df = pd.concat([df.drop(['weekday', 'week'], axis=1), df_2], ignore_index=True)
union_df.head()
```

`<img src="attachment:9440c860-e3e0-4570-827b-09008b6bc135.png" width="500"/>`{=html}

``` python
# we had fewer lightning in 2017
union_df[['year', 'number_of_strikes']].groupby(['year']).sum()
```

`<img src="attachment:538e097f-fb90-4f36-ab23-3d1db024cdfd.png" width="200"/>`{=html}

``` python
#Calculate total lightning strikes for each month of each year 
lightning_by_month = union_df.groupby(['month_txt', 'year']).agg(number_of_strikes=pd.NamedAgg(column='number_of_strikes', agg_func=sum).reset_index()
lightning_by_month.head()
```

`<img src="attachment:dbc8ba36-b994-4953-9119-f46cbe14fa37.png" width="500"/>`{=html}

``` python
percentage_lightning = lightning_by_month.merge(lightning_by_year, on='year') 
percentage_lightning.head()
```

`<img src="attachment:4b66c3c7-f284-46a0-aa92-fe7940d0c8f8.png" width="500"/>`{=html}

``` python
# Create new percentage_lightning_per_month column
percentage_lightning['percentage_lightning_per_month'] = (percentage_lightning.number_of_strikes/ percentage_lightning.year_strikes * 100.0) 
percentage_lightning.head()
```

`<img src="attachment:b258e0d8-7dd1-40a8-ac31-667bf6fe3cd1.png" width="500"/>`{=html}

``` python
plt.figure(figsize=(10,6));
sns.barplot(
data = percentage_lightning,
X = 'month txt',
y = 'percentage_lightning_per_month',
hue = 'year',
order = month_order);

plt.xlabel("Month");
plt.ylabel("% of lightning strikes");
plt.title("% of lightning strikes each Month (2016-2018)");
```

`<img src="attachment:4d8c4331-8eda-40ab-b230-934936c2b999.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Histogramlar
:::

::: {.cell .markdown}
Öğrendiğiniz gibi, keşif veri analizinin (EDA) amacı tam da adının
söylediği şeydir: verileri araştırın ve analiz edin. Bir veri uzmanı
olarak, neredeyse her zaman yol gösterici bir soru veya hedefle
başlayacaksınız, örneğin, "En yüksek karbondioksit yayıcıları nerede
bulunur?" veya "X ürününü satın alma olasılığı en yüksek kişilerin
özelliklerini belirleyin." Süreciniz boyunca bunu sık sık düşünmek, sizi
yolda tutan bir itici güç yaratır.

Verileri keşfederken emrinizdeki en önemli araçlardan biri
**histogramdır**. Histogram, bir veri kümesindeki veya değişkendeki her
değerin ne sıklıkta meydana geldiğini gösteren bir frekans dağılımının
grafiksel bir gösterimidir. Veri profesyonellerinin verilerinin
dağılımlarını anlamaları çok önemlidir, çünkü bu bilgi deney tasarımı,
modelleme ve daha ileri analizler etrafında birçok aşağı yönlü kararı
yönlendirir. Bu okumada, histogramlar, ne olduklarını, nasıl
yapılacağını ve nasıl yorumlanacağını öğreneceksiniz.

### **Histogramlara giriş**

Histogramlar, herhangi bir aykırı değerlerin varlığı, dağılımın merkezi
ve verilerin yayılması dahil olmak üzere bir dağılımın şeklini göstermek
için yaygın olarak kullanılır. Histogramlar tipik olarak, her çubuğun
bir değer aralığını temsil ettiği bir dizi çubukla temsil edilir. Çubuk
yüksekliği, bu aralıktaki veri noktalarının sıklığını veya sayısını
temsil eder.

Aşağıdaki örnek, Wyoming, ABD\'deki Yellowstone Ulusal Parkı\'ndaki Old
Faithful şofben patlamaları arasındaki saniye sayısının histogramıdır.

`<img src="attachment:327eef53-556d-4ec7-9ea8-645d5012d8eb.png" width="500"/>`{=html}

X ekseni, patlamalar arasındaki saniye sayısını temsil eder. Y ekseni
patlama sayısını temsil eder. Bu nedenle, grafikteki ikinci çubuk
tarafından belirtildiği gibi, 45-49 saniyelik bir bekleme süresinden
sonra meydana gelen 20 patlama vardır.

### **Histogramların önemi**

Histogramlar, bir veri kümesinin özelliklerini anlamak için önemli bir
araçtır. Verilerin dağılımının görsel bir temsilini sağlar ve veri
profesyonellerinin verilerdeki kalıpları, eğilimleri veya aykırı
değerleri tanımlamasını sağlar. Histogramlar ayrıca veri
profesyonellerinin veriler için uygun istatistiksel testleri ve
modelleri seçmelerine ve verilerin analiz için gerekli varsayımları
karşılayıp karşılamadığını belirlemelerine yardımcı olabilir.
Histogramlar, finans, sağlık, mühendislik ve sosyal bilimler dahil olmak
üzere her türlü veri analizi gerektiren herhangi bir alanda ve her
durumda yaygın olarak kullanılmaktadır.

### **Histogramlar nasıl yorumlanır**

Histogramları yorumlamak, dağılımın şeklini, merkezini ve yayılmasını
anlamayı içerir. Aşağıdakiler de dahil olmak üzere birkaç yaygın
histogram şekli vardır:

1.  Simetrik: Simetrik bir histogram, ortasında bir tepe bulunan çan
    şeklinde bir eğriye sahiptir ve bu, verilerin ortalama etrafında
    eşit olarak dağıldığını gösterir. Bu aynı zamanda normal veya Gauss
    dağılımı olarak da bilinir.

`<img src="attachment:b304807c-c2ce-4951-a426-ba83750cd88f.png" width="500"/>`{=html}

1.  Eğri: Eğik bir histogramın bir tarafında diğerinden daha uzun bir
    kuyruğu vardır. Sağa eğik bir histogramın sağ tarafında daha uzun
    bir kuyruğu vardır, bu da histogramın sol tarafında daha fazla veri
    noktası olduğunu gösterir.

`<img src="attachment:5324d6a2-ca83-4411-baae-22bedd13b5e6.png" width="500"/>`{=html}

Sol eğri bir dağılım, sol tarafta daha uzun bir kuyruğa sahiptir ve sağ
tarafta daha fazla veri noktası gösterir.

`<img src="attachment:45fa3e07-efbe-4fec-9a5d-ae3724c09ef8.png" width="500"/>`{=html}

1.  Bimodal: İki modlu bir histogramın iki farklı tepe noktası vardır,
    bu da verilerin iki modu olduğunu gösterir.

`<img src="attachment:76f4eb50-75e5-43c5-982c-aac892118ac4.png" width="500"/>`{=html}

1.  Tek tip: Tek tip bir histogramın düz bir dağılımı vardır, bu da tüm
    veri noktalarının eşit olarak dağıldığını gösterir.

`<img src="attachment:5c88ffa8-b7de-4b13-b794-6d2e62308807.png" width="500"/>`{=html}

Sağlanan örnekler karşılaşacağınız tek dağıtım değildir, ancak en yaygın
olanlardan bazılarıdır. Yakında dağıtımlar hakkında daha fazla bilgi
edineceksiniz.

Şimdi, bu okumanın başlangıcındaki Old Faithful gayzer histogramına
dönün. Kendinize sorun: Bu grafik tarafından ne tür bir dağılım temsil
edilir? Şekle ek olarak, merkezi anlamak ve yayılmak önemlidir.
Dağılımın merkezi tipik olarak ortalama veya medyan ile temsil
edilirken, dağılım standart sapma veya verilerin aralığı ile temsil
edilir. Merkez ve yayılma, veri konsantrasyonu ve değişkenliği hakkında
içgörüler sağlayabilir.

### **Histogramlar nasıl oluşturulur**

Python\'un seaborn ve matplotlib kütüphaneleri, histogramlar oluşturmak
için basit ve güçlü seçenekler sunar.

#### [plt.hist (x, bins=10,\...)](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html#matplotlib-pyplot-hist) {#plthist-x-bins10}

Matplotlib\'de bir histogram oluşturmak için pyplot modülündeki hist()
işlevi kullanın. İşlev birçok farklı argüman alabilir, ancak birincil
olanlar şunlardır:

-   x: Çizmek istediğiniz verileri temsil eden bir değer dizisi. Bir
    liste, tüple, NumPy dizisi, panda serisi vb. Olabilir.

-   kutular: Verilerinizi sıralamak istediğiniz kutu sayısı. Varsayılan
    değer 10\'dur, ancak bu parametre bir int, dizi veya dize olabilir.
    Bir dizi kullanırsanız, ilk kutunun sol kenarı ve son kutunun sağ
    kenarı da dahil olmak üzere çöp kutusu kenarlarını tanımlar. Başka
    bir deyişle, eğer kutular = \[1, 3, 5, 7\], o zaman ilk kutu
    \[1---3) (1 dahil, ancak 3 hariç) ve ikincisi \[3---5). Son kutu,
    ancak, 7 içeren \[5---7\] \'dir. Bir dize, numpy tarafından
    desteklenen önceden tanımlanmış bir binning stratejisini ifade eder.
    Daha fazla bilgi için belgelere bakın.

Aşağıdaki örnek, işlevi kullanarak bu okumanın başlangıcından itibaren
Old Faithful gayzer histogramının nasıl oluşturulacağını
göstermektedir..

``` python
# Plot histogram with matplotlib pyplot
plt.hist(df['seconds'], bins=range(40, 101, 5))
plt.xticks(range(35, 101, 5))
plt.yticks(range(0, 61, 10))
plt.xlabel('seconds')
plt.ylabel('count')
plt.title('Old Faithful geyser - time between eruptions')
plt.show();
```

Bu durumda, çizilen veriler veri çerçevesinin saniye sütunudur. Kutular
40 saniyede başlar ve toplam 12 kutu için beşli adımlarla 100 saniyeye
gider.

#### [sns.histplot (x, kutular, binrange, binwidth\...)](https://seaborn.pydata.org/generated/seaborn.histplot.html) {#snshistplot-x-kutular-binrange-binwidth}

Seaborn\'da bir histogram oluşturmanın bir yolu işlevi kullanmaktır.
sns.histplot() Matplotlib işlevi gibi, birçok argü sns.histplot() man
alabilir. İşte bazı önemli olanlar:

-   x: Veri dizisi. Aynı plt.hist()

-   kutular: Aynı plt.hist()

-   binrange: Kutu kenarları için en düşük ve en yüksek değer; bins veya
    ile kullanılabilirbinwidth; varsayılan olarak veri uç noktalarıdır

-   binwidth: Her bölmenin genişliği, geçersiz kılar bins ancak birlikte
    kullanılabilir binrange

Aşağıdaki örnek, seaborn işlevini kullanarak Old Faithful gayzer
histogramını oluşturmak için kullanılan koddur.. histplot() Daha önce
bahsedilen parametrelerin tümünü kullanır. Bir histogram oluşturmak için
bu kod bloğunu çalıştırın.

Bu durumda 40 ila 100 binrange arasında tanımlanmış ve 5 olarak ayar
binwidth lanmış olduğuna dikkat edin. Bu ayar ile aynı sonuçları
verirbins=range(40, 101, 5). Bu örnek ayrıca, altıgen kod gösterimini
kullanarak belirli bir rengi belirterek ve parametre tarafından
belirtildiği gibi renk doygunluğu seviyesini% 100\'e ayarlayarak birkaç
stil alpha parametresini kullanır.

**Not:** Aşağıdaki kod bloğu etkileşimli değildir.

``` python
# Plot histogram with seaborn
ax = sns.histplot(df['seconds'], binrange=(40, 100), binwidth=5, color='#4285F4', alpha=1)
ax.set_xticks(range(35, 101, 5))
ax.set_yticks(range(0, 61, 10))
plt.title('Old Faithful geyser - time between eruptions')
plt.show();
```

`<img src="attachment:4a6ad72c-ddc4-40f0-b8dd-1df91b5e5185.png" width="500"/>`{=html}

### **Önemli çıkarımlar**

Histogramlar, veri uzmanlarının veri kümelerinin ve değişkenlerinin
frekans dağılımlarını anlamalarına yardımcı olur. Veri dağılımının şekli
ve türü hakkında bilgi, istatistiksel testler ve model mimarisi seçimi
gibi önemli alt kararları etkileyecektir. Ek olarak, verilerinizin
şeklini bilmek, verilerinizin dağıtım eğilimlerini anlamanıza yardımcı
olarak verilerinizin size anlattığı hikayeye ilişkin değerli bilgiler
sağlar.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Veri Temizleme
:::

::: {.cell .markdown}
Öğrendiğiniz gibi, veri temizleme ve doğrulama uygulamaları, eksik
verileri, aykırı değerleri ve etiket kodlamasını işleme; yazım
hatalarını kontrol etme ve kopyaları işleme dahil olmak üzere birkaç
farklı adımı içerir. Bir veri uzmanı olarak, bu kategorilerdeki veri
değerlerini en iyi nasıl ele alacağınızı bilmek sizin göreviniz
olacaktır. Bu okumada, kopyaları işleme hakkında daha fazla bilgi
edineceksiniz. Ayrıca, tekilleştirme işleminin bir veri kümesi için
doğru strateji olup olmadığını belirlemeyi ve karar vermeyi
öğreneceksiniz. Ek olarak, kopyaları işlemek için bazı yaygın Python
işlevlerini öğreneceksiniz.

### Yinelenenleri tanımlama

Yinelenen değerlerin kaldırılıp kaldırılmayacağına dair herhangi bir
karar vermeden önce, veri kümemizde yinelenen değerlerin olup olmadığını
belirlemeliyiz.

Kopyaları tanımlamanın basit bir yolu, Pandas duplicated() işlevini
kullanmaktır. duplicated()DataFramesınıfın bir yöntemidir.

Bu işlev, veri değerinin bir kopya olduğunu belirten "true" ve "false"
benzersiz bir değer olduğunu belirten bir dizi "doğru/yanlış" çıktı
döndürür.

İşte beş satırlı bir veri çerçevesi örneği:

``` python
df

     brand    style  rating
0   Wowyow  cistern     4.0
1   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
4  Pipplee    stock     3.0
```

duplicated() fonksiyonu kullanarak sonuç, birinin "Doğru" olarak
işaretlenmiş olması ve bunun bir kopya olduğunu gösterir.

``` python
print(df)
print()
print(df.duplicated())

     brand    style  rating
0   Wowyow  cistern     4.0
1   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
4  Pipplee    stock     3.0

0    False
1     True
2    False
3    False
4    False
dtype: bool
```

Tüm veri çerçevesi için kopyaları tanımlamak, tek bir sütundan veya
dizinden farklı olacaktır. Fonksi duplicated() yonu tüm veri çerçevesi
için kullandığınızda emin olun. İş duplicated() lev, yalnızca bir
sütunda *bulunan tek tek eşleşen değerleri değil, yalnızca tam olarak
eşleşen değerlere sahip tüm sat* ırları döndürür. Bir veri
çerçevesindeki yalnızca bir sütun veya bir dizi sütun için kopyaları
tanımlamak isterseniz, bunu işlevin bağımsız değişken alanının "alt
küme" kısmına eklemeniz gerekir. duplicated() Daha ileri giderek,
kopyaların hangisinin kopya yerine "orijinal" olarak saklanacağını
belirtmek isterseniz, bunu bağımsız değişken alanının keep bölümünde
belirtebilirsiniz.

Aşağıda, değerlerin yalnızca bir sütunundaki (alt kümesindeki) kopyaları
tanımlamaya ve son kopyaları "yanlış" olarak etiketlemeye ve
"saklanmaları" için bir örnek verilmiştir:

``` python
print(df)
print()
print(df.duplicated(subset=['type'], keep='last'))

    color  rating     type
0   olive     9.0    rinds
1   olive     9.0    rinds
2    gray     4.5  pellets
3  salmon    11.0  pellets
4  salmon     7.0  pellets

0     True
1    False
2     True
3     True
4    False
dtype: bool
```

### Karar zamanı: Düşmek mi düşmemek mi?

Öğrendiğiniz gibi, her veri kümesi benzersizdir ve her veri kümesini
aynı şekilde ele alamazsınız. Yinelenen değerleri ortadan kaldırıp
ortadan kaldırmamaya karar verirken, **veri kümesinin kendisi** ve
ulaşmak **istediğiniz hedef hakkında derinlemesine düşünün**. Yinelenen
kopyaları bırakmanın veri kümeniz ve hedefiniz üzerinde ne gibi bir
etkisi olacak?

**1. Düşmeye karar** vermek

**Yinelenen değerler açıkça hataysa veya veri kümesinde kalan benzersiz
değerleri yanlış temsil edecekse yinelenen değerleri bırakmalı veya
ortadan kaldırmalısınız.**

`<img src="attachment:09c30c04-6982-493f-b331-7e50a90d4025.png" width="500"/>`{=html}

Örneğin, bir veri uzmanının (çoğu durumda) ev adreslerini ve ev
fiyatlarını içeren bir veri kümesinin yinelenen değerlerini ortadan
kaldıracağından makul ölçüde emin olabilirsiniz. Aynı evi iki kez saymak
(çoğu durumda) ortalama ev fiyatı, toplam ev fiyatı ve hatta toplam ev
sayısı gibi veri kümesinden çıkarılan sonuçları bir bütün olarak yanlış
temsil edecektir. Böyle bir durumda, bir veri uzmanı, analiz ve
görselleştirme sırasında kalan verileri adil bir şekilde temsil etmek
için yinelenen verileri neredeyse kesinlikle ortadan kaldıracaktır.

**2. Düşmemeye karar vermek**

Yinelenen değerler açıkça hata **değilse** ve veri kümesini bir bütün
olarak temsil ederken dikkate alınmalıysanız, yinelenen verileri veri
kümenizde **tut** malısınız.

`<img src="attachment:710bd7a3-5fb4-420e-b121-80c1ce22a4e0.png" width="500"/>`{=html}

Örneğin, antrenmandaki bir Olimpiyat atış sporcunun atış sayısını ve
mesafelerini gösteren bir veri kümesi muhtemelen birkaç çift mesafe
içerecektir; sadece deneme sayısı ve bir kişinin ağırlıklı bir topa
sahip olabileceği sınırlar gereği, yinelenen değerler olacaktır -
özellikle mesafe ölçümleri yalnızca 1 veya 2 ondalık basamakla
etiketlenmişse. Böyle bir durumda, bir veri uzmanı, analiz ve
görselleştirme sırasında bir bütün olarak adil bir şekilde temsil etmek
için neredeyse kesinlikle tüm verileri saklar.

### Kandırılmayın - Tekilleştirme nasıl yapılır

Python\'a geri dönmeden ve kopyaları nasıl ortadan kaldıracağımızı
öğrenmeden önce, önce "tekilleştirme" terimini tanımlayalım:

-   **Tekilleştirme:** Bir veri kümesindeki eşleşen veri değerlerinin
    ortadan kaldırılması veya kaldırılması.

Python\'da eşleşen veri değerlerini kaldırmak için kullanabileceğiniz
bir dizi farklı kütüphane, işlev ve yöntem vardır.

Kullanılacak en yaygın işlevlerden biri Pandas\'dadır: drop_duplicates()

drop_duplicates()başka bir DataFrame yöntemdir. Tüm yinelenen satırların
kaldırıldığı yeni bir veri çerçevesi oluşturmak için kullanılır.

Örneğin, bu okumanın önceki bölümlerinden bir veri çerçevesi kullanın:

``` python
df

     brand    style  rating
0   Wowyow  cistern     4.0
1   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
4  Pipplee    stock     3.0
```

Şimdi kopyaları bırak işlevini uygulayın:

``` python
df.drop_duplicates()

     brand    style  rating
0   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
4  Pipplee    stock     3.0
```

Ortaya çıkan çıktıda, yinelenen veri satırının kaldırıldığını ve kalan
benzersiz değerlerin bozulmadan kaldığını fark edeceksiniz.

**Not:** Yukarıda yazıldığı gibi drop_duplicates() işlevin yalnızca
**tüm veri satırlarının tam eşleşmelerinin kopyalarını bırakacağını
unutmayın**. Yinelenenleri tek bir sütun içine bırakmak isterseniz,
subset anahtar kelime bağımsız değişkenini kullanarak hangi sütunların
kopyaları kontrol edeceğinizi belirtmeniz gerekir.

Bu örnek, style sütunda yinelenen değerlere sahip tüm satırları bırakır
(ilk oluşum hariç):

``` python
print(df)
df=df.drop_duplicates(subset='style')
print()
print(df)

     brand    style  rating
0   Wowyow  cistern     4.0
1   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
4  Pipplee    stock     3.0

     brand    style  rating
0   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
```

Ve bu örnek, *hem* de rating sütunlarda yinelenen *değerlere sahip tüm
satırları* (ilk oluşum hariç) style bırakır:

``` python
print(df)
df = df.drop_duplicates(subset=['style', 'rating'])
print()
print(df)

     brand    style  rating
0   Wowyow  cistern     4.0
1   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
4  Pipplee    stock     3.0

     brand    style  rating
0   Wowyow  cistern     4.0
2  Splaysh      jug     5.5
3  Splaysh    stock     3.3
4  Pipplee    stock     3.0
```

### Önemli Çıkarımlar {#önemli-çıkarımlar}

Bir veri kümesindeki yinelenen veri değerlerini belirlemek, özellikle
temizleme ve doğrulama olmak üzere EDA (veya "Keşif Veri Analizi")
uygulamalarının önemli bir parçasıdır. Yinelenenleri belirledikten
sonra, yinelenmeleri ortadan kaldırmayı veya kopyaları ortadan
kaldırmamayı seçerken veri kümesi üzerindeki etkiyi ve analiz hedefinizi
düşünün.

### Ek Kaynaklar

Çoğaltmalar ve tekilleştirme hakkında daha fazla bilgi edinmek ister
misiniz? Aşağıdaki ek bağlantılara göz atın.

-   [Argüman alanının parametreleri hakkında daha fazla bilgi edinmek
    için Pandas belgelerine
    bakın](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)

-   [W3 Okulları: Pandalar - kopyaları
    kaldırma](https://www.w3schools.com/python/pandas/pandas_cleaning_duplicates.asp "W3 Okulları - Pandalar: Kopyaları kaldırma")
:::

::: {.cell .markdown}
``` python
import pandas as pd 
import numpy as np
import seaborn as sns
import datetime
from matplotlib import pyplot as plt

df = pd.read_csv('../Datasets/1.csv')
df.head()
```

`<img src="attachment:569109a0-dbe8-42be-b701-51980b982ced.png" width="500"/>`{=html}

``` python
df.shape
(717530,5)

df_zip = pd.read_csv()
df_zip.head()
```

`<img src="attachment:caf62905-f6d8-46e1-b78a-b3381ab24d44.png" width="800"/>`{=html}

``` python
df_zip.shape
(323700, 7)
```

``` python
df_joined = df.merge(df_zip, how='left', on=['date', 'center_point_geom'])
df_joined.head()
```

`<img src="attachment:8ef4b3ea-c463-406b-a17d-f4ce8bbc0902.png" width="800"/>`{=html}

``` python
df_joined.describe()
```

`<img src="attachment:429eae24-f150-4ae4-a3c0-150e3e1303d1.png" width="800"/>`{=html}

``` python
df_null_geo = df_joined[pd.isnull(df_joined.state_code)]
df_null_geo.shape
(393830,10)

df_joined.info()
```

`<img src="attachment:2ba24f6a-ba95-4d1e-8e7d-f9b4bb44156a.png" width="500"/>`{=html}

``` python
df_null_geo.head()
```

`<img src="attachment:1c951240-d0c3-4367-8973-0368d3c59bb0.png" width="800"/>`{=html}

``` python
top_missing = if_null_geo[['latitude', 'longitude', 'number_of_strikes_x']
].groupby(['latitude', 'longitude'] ).sum().sort_values('number_of_strikes_x', ascending=False).reset_index()

top_missing.head(10)
```

`<img src="attachment:99283a5f-b763-4d55-afbc-a7bd6552c5e5.png" width="400"/>`{=html}

``` python
import plotly.express as px

fig = px.scatter_geo(top_missing[top_missing.number_of_strikes_x>=300],
                     lat "latitude",
                     lon="longitude",
                     size="number_of_strikes_x")

fig.update_layout(title_text= 'Missing data', )
fig.show()
```

`<img src="attachment:d9c1c872-2834-444f-8a2c-010a3ca7ae0f.png" width="800"/>`{=html}

``` python
import plotly.express as px

fig px.scatter_geo(top_missing[top_missing.number_of_strikes_x>=300],
                   lat="latitude",
                   lon="longitude",
                   size="number_of_strikes_x")

fig.update_layout(
    title_text = 'Missing data',
    geo_scope='usa',
)

fig.show()
```

`<img src="attachment:3758bbb8-b5d7-4b12-8922-e6a75fa98fa2.png" width="800"/>`{=html}
:::

::: {.cell .markdown}
``` python
# Import statements
import pandas as pd
import numpy as np
import seaborn as sns
import datetime
from matplotlib import pyplot as plt

#Print first 10 rows
df.head(10)
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/6421e958-c9de-4e47-87bd-9bf96d2ba880.png)

``` python
def readable_numbers(x):
    
    """takes a large number and formats it into K,M to make it more readable""" 
    if x >= le6:
        s='{:1.lf}M'.format(x*le-6)
    else: 
        s='{:1.0f)K'.format(x*1e-3)
    return s

#Use the readable_numbers() function to create a new column
df ['number_of_strikes_readable']=df ['number_of_strikes'].apply(readable_numbers)

df.head(10)
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/51d510c5-eaf3-431e-841e-162968c15ae0.png)

``` python
print("Mean:" + readable_numbers(np.mean(df['number_of_strikes'])))

print("Median:" + readable_numbers(np.median(df ['number_of_strikes'])))

Mean:26.8M

Median:28.3M
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/33baa811-9113-449c-bb90-0526bd5e437a.png)

``` python
# Create boxplot
box sns.boxplot(x=df ['number_of_strikes')) gplt.gca()

box.set_xticklabels (np.array([readable_numbers(x) for x in g.get_xticks()])) plt.xlabel('Number of strikes') plt.title('Yearly number of lightning strikes');
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/415c11e5-60c9-4ec1-b307-7936090110b4.png)

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/5610cb16-3c1f-499c-9a97-0c7ff03f8d5e.png)

``` python
# Calculate 25th percentile of annual strikes
percentile25 = df['number_of_strikes'].quantile (0.25)

#Calculate 75th percentile of annual strikes
percentile75 = df['number_of_strikes'].quantile(0.75)

#Calculate interquartile range
iqr = percentile75 - percentile25

#Calculate upper and lower thresholds for outliers
upper_limit = percentile75 + 1.5 * iqr
lower_limit percentile25 + 1.5 * iqr

print('Lower limit is: ' + readable_numbers(lower_limit))
Lower limit is: 8.6M

#Isolate outliers on low end
df[df['number_of_strikes'] < lower_limit]
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/ccbc6522-e9db-4cda-b81f-8d2bd44803ee.png)

``` python
def addlabels(x,y):
    for i in range(len(x)):
        plt.text(x[i]-0.5, y[i]+0.05,
                 s=readable_numbers(y[i]))


colors np.where(df['number of_strikes'] < lower_limit, 'r', 'b')

fig, ax = plt.subplots(figsize=(16,8))
ax.scatter(df['year'], df['number_of_strikes'),c=colors) ax.set_xlabel('Year')
ax.set_ylabel('Number of strikes')
ax.set_title('Number of lightning strikes by year')
addlabels(df['year'], df['number_of_strikes'])

for tick in ax.get_xticklabels():
    tick.set_rotation (45)

plt.show()
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/5a0e456a-717e-41c5-8dfc-bca7c509e7f9.png)

``` python
df_2019 = pd.read_csv('eda_outliers_dataset2.csv')
df_2019.head()

# Convert `date` column to datetime
df_2019['date']= pd.to_datetime(df_2019['date'])

# Create 2 new columns

df_2019['month'] = df_2019['date'].dt.month

df_2019['month_txt'] = df_2019['date'].dt.month_name().str.slice(stop=3)

# Group by month and month txt, sum it, and sort. Assign result new df 
df_2019_by_month = df_2019.groupby(['month', 'month_txt')).sum().sort_values('month', ascending=True).head()
df_2019_by_month
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/2181e905-2491-4bbe-a5e7-0e6f09fa6fd1.png)

``` python
#Read in 1987 data
df_1987=pd.read_csv('eda_outliers_dataset3.csv')

#Convert date column to datetime
df_1987['date'] = pd.todatetime(df_1987['date'])

#Create 2 new columns
df_1987['month'] = df_1987['date'].dt.month
df_1987['month_txt'] = df_1987['date'].dt.month_name().str.slice(stop=3)

#Group by month and `month_txt ', sum it, and sort. Assign result to new df
df_1987_by_month = df_1987.groupby(['month', 'month_txt']).sum().sort_values('month', ascending=True).head() 
df_1987_by_month
```

![image.png](vertopal_1b6b7baf2cd04281b8e1291066b3f885/dff3f335-850c-46ba-9301-aad2a322754e.png)

``` python
#Create new df that removes outliers
df_without_outliers=df[df['number_of_strikes']>=lower_limit]

#Recalculate mean and median values on data without outliers
print("Mean:"+readable_numbers(np.mean(df_without_outliers['number_of_strikes']))) print("Median:"+readable_numbers(np.median(df_without_outliers['number_of_strikes'])))

Mean:28.2M
Median:28.8M
```
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## getdummies() ve cat.codes() {#getdummies-ve-catcodes}
:::

::: {.cell .markdown}
``` python
# Load libraries.
import datetime
import matplotlib.pyplot as plt 
import pandas as pd 
import seaborn as sns

# Create a new data frame with the number of strikes per month.
df['date'] = pd.to_datetime(df['date'])
df['month'] = df['date'].dt.month_name().str.slice(stop = 3)

# Make the month names categorical so they are in calendar instead of alphabetic
# order when we plot them.
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

df['month'] = pd.Categorical(df['month'], categories = months, ordered
df['year'] = df['date'].dt.strftime('%Y')
df_by_month = df.groupby(['year', 'month']).sum().reset_index)
df_by_month. head()
```

`<img src="attachment:b9b82bb4-c2f7-460f-9bff-573777c0d5f9.png" width="300"/>`{=html}

``` python
# Create a categorical variable by bucketing the number of lightning strikes
# per month into severeness levels based on quantiles.
df_by_month['strike_level'] = pd.qcut(
df_by_month ['number_of_strikes'],
4,
labels = ['Mild', 'Scattered', 'Heavy', 'Severe'])
df_by_month.head()
```

`<img src="attachment:a7469599-1a4c-442a-82a4-9b9d5c99bb80.png" width="400"/>`{=html}

``` python
# Assign numerical values to the strike levels.

df_by_month['strike_level_code'] = df_by_month['strike_level'].cat.codes[df_by_month.head()]
```

`<img src="attachment:dca8a8c3-bdb2-4d52-a0c7-213c029f6271.png" width="400"/>`{=html}

``` python
# Create dummy variables from strike levels.
pd.get_dummies(df_by_month['strike_level'])
```

`<img src="attachment:bdc8a075-27d7-4b37-a216-a7fb83702481.png" width="300"/>`{=html}

``` python
# Format dataframe indices to prepare for plotting.
df_by_month_plot = df_by_month.pivot('year', 'month', 'strike_level_code') 
df_by_month_plot.head()
```

`<img src="attachment:3eb7914a-d28f-4f91-8f2a-d71c64fd0de9.png" width="600"/>`{=html}

``` python
# Make a heatmap showing which months over the years had most severe lightning.
ax = sns.heatmap(df_by_month_plot, cmap= 'Blues')
colorbar = ax.collections[0].colorbar
colorbar.set_ticks([0, 1, 2, 3])
colorbar.set_ticklabels (['Mild', 'Scattered', 'Heavy', 'Severe'])
plt.show()
```

`<img src="attachment:5dee67f0-1b2d-481f-a1f8-587df4007de6.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Veri Dönüşümünde Diğer Yaklaşımlar
:::

::: {.cell .markdown}
Bildiğiniz gibi, veriler bize birçok farklı biçimde geliyor. Kategorik
veya nitel veri türleri için, veri uzmanlarının analizlerini tamamlamak,
veri görselleştirmelerini tasarlamak veya makine öğrenimi
algoritmalarını oluşturmak için genellikle bu tür verileri sayısal
rakamlara dönüştürmeleri (veya kodlamaları) gerekir. Bu okumada, iki ana
kategorik veri kodlama türünü ve her türün ne zaman kullanılacağını
öğreneceksiniz.

### Etiket kodlama

Her veri değerine nitel bir değer yerine farklı bir sayı atandığı bir
tür veri dönüştürme tekniği olan **etiket kod** lamayı zaten öğrendiniz.

[Videodan hatırlıyorsanız, verilen örnek mantar türlerini kodlayan
etiket
idi:](https://www.coursera.org/learn/go-beyond-the-numbers-translate-data-into-insight/lecture/BrCPD/sort-numbers-versus-names)

  **Mantar Türü**    **Kod**
  ------------------ ---------
  Siyah trüf         0
  Düğme              1
  Cremini            2
  Kirpi              3
  Kral Trompet       4
  Morel              5
  Portobello         6
  Shiitake           7
  Kurbağa tabureti   8

Anlayabileceğiniz gibi, mantarlarla ilgili bu varsayımsal veri seti
için, her mantar türüne sıfırdan başlayarak kendi numarası atandı.

### Etiket kodlama ile ilgili bazı olası sorunlar

Müzik türleri kategorileri içeren bir veri kümesini analiz ettiğinizi
hayal edin. "Blues", "Elektronik Dans Müziği (EDM)", "Hip Hop", "Jazz",
"K-Pop", "Metal" ve "Rock" kodlarını aşağıdaki sayısal değerlerle
etiketlersiniz: "1, 2, 3, 4, 5, 6 ve 7."

Bu etiket kodlamasıyla, ortaya çıkan makine öğrenimi modeli sadece bir
sıralama değil, aynı zamanda Blues (1) ve EDM (2) arasında sayısal
olarak ne kadar yakın oldukları için Blues (1) ve Jazz (4) arasında daha
yakın oldukları için daha yakın bir bağlantı da türete **bilir**. Bu
varsayılan ilişkilere ek olarak (analizinizde isteyebilirsiniz veya
istemeyebilirsiniz), her kodun sayısal sırayla diğerinden eşit uzaklıkta
olduğunu da fark etmelisiniz, çünkü 1\'den 2\'ye 5 ila 6, vb. ile aynı
mesafedir, vb. Soru şu ki, bu eşit mesafeli ilişki veri kümenizdeki
müzik türleri arasındaki ilişkileri doğru bir şekilde temsil ediyor mu?
Başka bir soru sormak için, kodlamadan sonra, oluşturduğunuz
görselleştirme veya model kodlanmış etiketleri bir sıralama olarak ele
alacak mı?

Aynı şey yukarıdaki mantar örneği için de söylenebilir. Mantar türlerini
kodladıktan sonra, mantarların artık düğme mantarları birinci sırada ve
mantarların sekizinci sırada olduğu varsayılan bir sıralamada olmasından
memnun musunuz?

Özetle, etiket kod **laması**, veri kümenizdeki kategorik veriler
arasında istenmeyen ilişkiler oluşturabilir. Etiket kodlaması hakkında
karar verirken, verilere uygulayacağınız algoritmayı ve bunun etiket
kodlu kategorik verileri nasıl etkileyebileceğini veya etmeyebileceğini
göz önünde bulundurun.

Neyse ki, kategorik kodlama için bu potansiyel sorunlara yardımcı
olabilecek başka bir yöntem var.

### Tek kullanımda kodlama

Önceki bir
[video](https://www.coursera.org/learn/go-beyond-the-numbers-translate-data-into-insight/lecture/BrCPD/sort-numbers-versus-names)
da öğrendiğiniz gibi, Python\'da sahte değişkenler oluşturabilirsiniz.
Hatırlarsanız, sahte bir değişken, bir şeyin varlığını veya yokluğunu
gösteren 0 veya 1 değerlerine sahip bir değişkendir. Buradaki fikir, her
kategori türü için yeni bir sütun oluşturmaktır, ardından her değer için
0 veya 1 - 0 anlamı, hayır ve 1 anlamı evet belirtin.

Bu mankenlerin yaratılmasına **one-hot** kodlama denir. Bir hatırlatma
olarak, tek sıcak kodlamaya sahip bir tablo şu şekilde biter:

  **Yok**   **Hafif**   **Dağınık**   **Ağır**   **Şiddetli**
  --------- ----------- ------------- ---------- --------------
  **0**     1           0             0          0
  **1**     1           0             0          0
  **2**     0           1             0          0
  **3**     0           0             1          0
  **4**     0           0             0          1
  **5**     0           0             0          1
  **6**     0           0             0          1
  **7**     0           0             0          1
  **8**     0           0             1          0
  **9**     0           1             0          0
  **10**    1           0             0          0
  **11**    1           0             0          0
  **12**    0           1             0          0

[Video](https://www.coursera.org/learn/go-beyond-the-numbers-translate-data-into-insight/lecture/BrCPD/sort-numbers-versus-names)da
kapsanan yıldırım çarpması veri kümesindeki değerlerin "hafif" olarak
etiketlendiğini ve "1" olduğunu göreceksiniz. "Hafif", veri kümesindeki
yıldırım sayılarının en düşük çeyreğini ifade eder. "Hafif" sütundaki
hafif DEĞER DEĞİLDİR diğer değerler için o hücrede bir sıfır vardır. Bu
yöntemle etiket kodlamasının sunduğu istenmeyen ve sorunlu ilişkiler
sorununu çözüyoruz.

Ancak tek sıcak kodlama, özellikle lojistik ve doğrusal regresyon söz
konusu olduğunda, kendi problemlerini sunar. Gelecekteki bir kursta
bunun hakkında daha fazla bilgi edineceksiniz.

### **Etiket kodlaması veya tek sıcak kodlama: Nasıl karar verilir?**

Etiket kodlaması mı yoksa tek sıcak kodlama mı kullanmanız gerektiğine
dair basit bir cevap yoktur. Kararın duruma göre veya veri kümesi
bazında verilmesi gerekir. Ancak size yardımcı olacak bazı kurallar var.

Aşağıdaki durumlarda etiket kodlamasını kullanın:

-   Çok sayıda farklı kategorik değişken vardır - çünkü etiket
    kodlaması, tek bir sıcak kodlamadan çok daha az veri kullanır

-   Kategorik değerlerin kendilerine göre belirli bir sırası vardır
    (örneğin, yaş grupları en gençten en büyüğe veya en büyükten en
    küçüğe kadar gruplandırılabilir)

-   Bir karar ağacı veya rastgele orman makine öğrenme modeli kullanmayı
    planlıyorsunuz

Aşağıdaki durumlarda tek sıcak kodlama kullanın:

-   Nispeten az miktarda kategorik değişken vardır - çünkü tek sıcak
    kodlama, etiket kodlamasından çok daha fazla veri kullanır.

-   Kategorik değişkenlerin belirli bir sırası yoktur

-   Boyutsallık azaltma ile birlikte bir makine öğrenimi modeli
    kullanırsınız (Temel Bileşen Analizi (PCA) gibi)

### Önemli çıkarımlar {#önemli-çıkarımlar}

Etiket kodlaması ve tek sıcak kodlama, kategorik verileri sayısal
verilere dönüştürmek için kullanılan tekniklerdir. Etiket kodlaması, çok
sayıda farklı kategorik değişken ve kendilerine özgü bir düzene sahip
kategoriler için en iyisidir. Tek kullanımlı kodlama, daha küçük
miktarlarda kategorik değişken ve sırası olmayan kategoriler için en
iyisidir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Tarih Farkı ve Görselleştirme
:::

::: {.cell .markdown}
``` python
# Load libraries.
import datetime
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import seaborn as sns

df.head()
```

`<img src="attachment:b3c224d3-081a-4d3b-b623-9f3e3f892098.png" width="500"/>`{=html}

``` python
# Display the data type of the columns.
print(df.dtypes)

# Date is currently a string. Let's parse it into a datetime column. 
df['date'] = pd.to_datetime(df['date'])
```

`<img src="attachment:0466fe73-4847-4b61-9677-2958ebf8fd79.png" width="300"/>`{=html}

``` python
#Count the number of missing values in each column. 
df.isnull().sum()
```

`<img src="attachment:6fc32686-497b-4999-84b9-25970687ffc7.png" width="300"/>`{=html}

``` python
# Check ranges for all variables.
df.describe(include = 'all')
```

`<img src="attachment:1e69e0c3-51b5-4e7b-9ed2-7f55d8e6c6cc.png" width="700"/>`{=html}

``` python
# Find missing dates by comparing all dates in 2018 to dates in our date column.
full_date_range = pd.date_range(start = '2018-01-01', end = '2018-12-31')
full_date_range.difference(df['date'])
```

`<img src="attachment:49a7aec2-f05b-4b8a-8dfd-92af7ce71245.png" width="700"/>`{=html}

``` python
# Make a boxplot to see the range better.
sns.boxplot(y = df['number_of_strikes'])
```

`<img src="attachment:4953eeaf-628f-445a-b23d-8a78d7e90ba2.png" width="500"/>`{=html}

``` python
# Plot again without the outliers to see where the majority of data is. 
sns.boxplot(y = df['number_of_strikes'], showfliers = False)
```

`<img src="attachment:bd81e3ee-7126-45bf-9ecd-ff2daa748036.png" width="500"/>`{=html}

``` python
# Plot points on the map to verify data is all from US.
df_points df[['latitude', 'longitude']].drop_duplicates() # Get unique points.
df_points.head()
```

`<img src="attachment:68cc88ba-6379-4bb0-8119-eaa186578d30.png" width="200"/>`{=html}

``` python
# Plot points on the map to verify data is all from US.
df_points = df[['latitude', 'longitude']].drop_duplicates() # Get unique points. 
p = px.scatter_geo(df_points, lat = 'latitude', lon = 'longitude') 
p.show()
```
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Tableau'ya Genel Giriş
:::

::: {.cell .markdown}
Öğrendiğiniz gibi, Tableau dünyanın dört bir yanındaki veri uzmanları
tarafından kullanılan güçlü bir veri görselleştirme aracıdır. Google
Data Analytics Profesyonel Sertifikasını aldıysanız, Tableau\'ya zaten
aşina olmalısınız. Veri Analitiği Sertifikasını tamamlamadıysanız
aşağıdaki ve diğer videolarda bağlantılı kaynak materyallerini
inceleyebilirsiniz. Tableau yazılımı, sizin gibi öğrencilerin yazılımın
yeteneklerini sınırlı bir kapasitede test etmelerini sağlayan tarayıcı
sürümü aracılığıyla ücretsiz olarak mevcuttur. Bu okumada, bu
görselleştirme yazılımının ücretsiz kullanım, temel sürümü olan Tableau
Public\'e genel bir bakış verilecektir.

### Tableau Public\'in temellerini gözden geçirme

Bu okumada, Tableau Public\"de yer alan **veri kaynağının** ve **tasarım
ekranlarının** temel yapısı hakkında bilgi edineceksiniz. Veri kaynağı
sayfası verileri girmek veya veri bağlamak için kullanılır ve tasarım
sayfası veri görselleştirmeleri çizmek ve oluşturmak için kullanılır.
Etkili ve ilgi çekici veri görselleştirmelerini başarılı bir şekilde
tasarlamak için her ikisine de ihtiyaç vardır.

**Not:** Tableau Public kurulum sürecini gözden geçirmek için [Tableau
Public\'de oturum açma hakkındaki okumaya
bakın](https://www.coursera.org/learn/go-beyond-the-numbers-translate-data-into-insight/supplement/muYtK/how-to-sign-on-to-tableau-public).

#### **Veri kaynağı sayfası**

Görselleştirmeleri tasarlamaya başlamadan önce verilerinizi yüklemeniz
gerekir. Tableau Genel profilinizi zaten ayarladığınızdan, yapmanız
gereken tek şey oturum açmak ve gezinme çubuğunda Oluş **tur altında
Web** Yaz **ma seçen** eğini seçmek.

**Not:** Bu kursta Tableau için gereken her şey Web Yazma ile
tamamlanabilir; Tableau *yazıl* ımını indirmeniz gerekmez.

##### **Tableau Genel Web Oluşturma**

Web yazma, doğrudan bir web tarayıcısından görselleştirmeler
oluşturmanıza olanak tanır. Herhangi bir yazılım indirmeden bir viz
oluşturabilir misiniz? Evet! [Tableau Genel profilinizi zaten
ayarladığınızdan, yapmanız
gereken](https://www.tableau.com/community/blog/2022/9/beginners-guide-tableau-public)
tek şey oturum açmak ve gezinme çubuğunda Oluş **tur altında Web** Yaz
**ma seçen** eğini seçmek. Bu sertifika programının amaçları
doğrultusunda Tableau Public uygulamasında ihtiyacınız olan her şeyi
gerçekleştirebilirsiniz. Aşağıdaki kaynaklardaki talimatlar Tableau
Public sayfasına atıfta bulunur.

##### **Tableau Masaüstü Genel Sürümü**

[Yazılımı doğrudan Mac veya PC\'nize de
indirebilirsiniz.](https://www.tableau.com/products/public/download)
Public\'in web sitesindeki gezinme çubuğunda **Oluştur** altında
**Tableau Desktop Public Edition**\'ı seçin.

***Hatırlatma: Tableau Public yalnızca genel verileri analiz etmek ve
paylaşmak için kullanılmalıdır.*** *Yayınlanan tüm çalışma kitaplarına
ve veri kümelerine herkes tarafından ücretsiz olarak erişilebilir
olacaktır.*

Veri kümenizi yükledikten sonra, aşağıdaki resimde daire içine alınmış
sayıları eşleştirmek için özetlenen aşağıdaki adımları
uygulayabilirsiniz:

`<img src="attachment:8add54f3-c4af-4d08-bb6a-b74f984e050e.png" width="1000"/>`{=html}

Aşağıdaki açıklamalar yukarıdaki resme karşılık gelir.

1.  Bu sol bölme, veri bağlantılarınızı ve dosyalarınızı içerir. Burada
    yüklediğiniz tüm dosyaları bir listede bulacaksınız, böylece birden
    fazla dosyayı ve/veya farklı veritabanlarına birden fazla bağlantıyı
    takip edebilirsiniz.

2.  Veri bağlantıları penceresinin hemen sağında, Tableau Public\"in
    belirli bir dosyada algıladığı tüm alanların bir listesi bulunur..
    Yüklenen birden fazla dosyanız varsa, her dosyanın alanlarına
    erişmek için dosyayı açılır menüden seçebilirsiniz. Yaklaşan bir
    videoda öğreneceğiniz gibi, Tableau\'nun alanları dosyanızdaki veri
    sütunlarından alınır. Tableau bu alanları otomatik olarak boyutlar
    veya hesaplamalar ve ayrık veya sürekli değişkenler olarak sıralar.

3.  Sayfadaki en büyük bölme, sağ ortada, dosyanızın tüm sütunlarına
    birkaç veri satırı dahil Tableau alanları olarak erişmenizi sağlar.
    Soldaki bölmenin aksine, bu bölme yeni hesaplama alanları, gruplar,
    kümeler veya parametreler gibi halihazırda mevcut olanlara dayalı
    olarak yeni alanlar oluşturmanıza olanak tanır (gelecek videolarda
    bu özellikler hakkında daha fazla bilgi edineceksiniz). Bu bölmeyi
    verilerinizle doldurmak için "şimdi güncelle" veya "otomatik olarak
    güncelle" seçeneğini seçmeniz istenebilir. Durum buysa, güncel
    verilerle tutarlı bir şekilde çalıştığınızdan emin olmak için
    otomatik olarak güncelleme yapmak iyi bir uygulamadır. (Referans
    için - #5 \'dan sonra aşağıdaki resmi inceleyin.)

4.  Ekranın sağ üst köşesindeki mavi "Yayınla" düğmesi "kaydet" düğmeniz
    olarak işlev görür. Tableau Public tarayıcı tabanlı bir platform
    olduğundan, oluşturduğunuz ve kaydetmek istediğiniz her şey herkese
    açık hesabınızda yayınlanacaktır. İstenirse veri kaynaklarını ve
    veri görselleştirmelerini parolayla kilitlemenin veya gizlemenin
    yolları vardır, ancak Tableau Public yalnızca çalışmanızı kaydetmek
    için Yayınla alanını sunar. \'Yayınla\' düğmesine tıkladığınızda,
    tasarım ilerlemenize bağlı olarak boş olabilecek veri tasarım
    sayfanıza otomatik olarak yönlendirilebilirsiniz. Endişelenmeyin. En
    son veri kümesi yüklemeleriniz veya veri tasarımlarınız hala
    kaydedildi; en son bulunduğunuz yere geri dönün ve
    görselleştirmenizi düzenlemeye devam edin.

5.  Son olarak, veri tasarım sayfanıza gitmek için sayfanın sol alt
    köşesindeki düğmeler koleksiyonunu kullanacaksınız. Yeni bir çalışma
    sayfası, yeni bir gösterge tablosu ve yeni bir hikaye oluşturmak
    için düğme seçeneklerini bulacaksınız. Bu unsurlar bir sonraki
    bölümde tanıtılacaktır.

`<img src="attachment:c968b7ab-e00d-4dbd-a766-39be6f5eccc1.png" width="1000"/>`{=html}

#### **Veri tasarım sayfası**

Veri tasarımı sayfası, veri görselleştirmelerinizin oluşturulacağı
yerdir. Veri tasarımı sayfasına gitmek için, \'Sayfa 1\'e tıklayın veya
önceki ilgili resimde #5 \'de belirtildiği gibi yeni bir sayfa
oluşturun. Bir veri tasarım sayfasını açmak için ilk tıkladığınızda,
Tableau\'nun \'Çıkarma Oluşturmak\' olduğu sorulabilir. Bu, Tableau\'nun
görselleştirmelerde kullanılmak üzere sağlanan verileri çıkardığı
anlamına gelir. Bu işlem birkaç dakika sürebilir. Burada, istediğiniz
görselleştirme türünü oluşturmak için veri kaynağı alanlarınızı uygun
raflara taşıyacaksınız. Bu sayfadan veri görselleştirmeleri veya tüm
etkileşimli gösterge panoları oluşturabilirsiniz.

`<img src="attachment:2c98053e-164a-4216-a5ea-d20d2d56c2d3.png" width="1000"/>`{=html}

Aşağıdaki numaralandırılmış öğeler, yukarıdaki Tableau çalışma kitabı
görüntüsünde görüntülenen sayılara karşılık gelir.

1.  En soldaki bu bölmede, ayrık ve sürekli boyutlar ve hesaplamalar
    listenizi bulacaksınız. Görselleştirmeler oluşturmak için bu
    değişkenleri bu sayfadaki farklı bölmelere taşıyacaksınız. Bu
    değişkenler hakkında daha sonra daha fazla bilgi edineceksiniz.

2.  Hemen sağdaki bir sonraki bölmede "Sayfalar", "Filtreler" ve
    "İşaretler" i bulacaksınız. Veri görselleştirmesini değiştirmek için
    herhangi bir boyutu veya hesaplamayı bu farklı alanlara
    taşıyabilirsiniz. Bu özellikleri gelecek videolarda nasıl
    kullanacağınızı öğreneceksiniz.

3.  Sayfanın üst kısmında, menü çubuğunun hemen altında, değişken
    alanlarınızı taşımak için ana iki rafınız görevi gören iki boş satır
    vardır. "Sütunlar" ve "Satırlar" rafları, veri görselleştirmenizi
    istediğiniz gibi konumlandırmanıza yardımcı olur. Ayrıca bu
    satırların üzerinde, veri görselleştirmenizi değiştirmek için diğer
    seçeneklerle dolu bir araç çubuğu ve menü göreceksiniz.

4.  Ekranın ortasında görselleştirmeniz için ana görüntüleme paneli
    bulunur. Öğeler ekleyip boyutlarınızı ve hesaplamalarınızı farklı
    alanlara sürükledikçe, bu panelde veri görselleştirmeniz üzerindeki
    etkisini fark edeceksiniz. Sağ üst köşede, kaydetme düğmesi görevi
    gören "Yayınla" düğmenizi ve "Beni Göster" açılır menüsünü
    bulacaksınız. "Bana Göster" açılır menüsünün altında, her birini
    oluşturmak için çeşitli veri görselleştirme türleri ve kılavuzları
    bulacaksınız.

5.  Çalışmanızı [kaydetmeye ve paylaşmaya hazır
    olduğunuzda](https://help.tableau.com/current/pro/desktop/en-us/publish_workbooks_tableaupublic.htm),
    Tableau Genel profilinizde yayınlayın. Üst gezinme çubuğundaki
    "Yayınla" düğmesinin yanındaki aşağı oka tıklayarak çalışmanızı
    yayınlama seçeneklerini görüntüleyin.

### Tableau araçlarını incelemenin diğer yolları

#### **Google Veri Analitiği Profesyonel Sertifikası**

Daha önce de belirtildiği gibi, [Google Data Analytics Profesyonel
Sertifika
programı](https://www.coursera.org/professional-certificates/google-data-analytics)
nı aldıysanız, Tableau ve Tableau Public\'e zaten aşinasınız demektir.
Öğrendiklerinizi gözden geçirmek için o programdaki
[Tableau](https://www.coursera.org/learn/visualize-data/lecture/sLxV4/data-visualizations-with-tableau)
\'yu kullanmaya başlayın dersine gidin.

#### **TableAU.com** {#tableaucom}

[Tableauau.com\'u](https://www.tableau.com/) ziyaret ederek, Tableau
Public (ücretsiz olan) Tableau Desktop, Tableau Mobile ve Tableau
Server\'a kadar çok sayıda ürün teklifini fark edeceksiniz. Her ürünün
kendi kullanımı ve uzmanlığı vardır, ancak veri görselleştirme için ana
unsurlar aynıdır. Veri görselleştirmeleriyle ilgili hemen hemen her
konuda belirli makaleler bulmak için [Tableau Yardım
sayfası](https://www.tableau.com/support/help?_ga=2.3466357.45238129.1654614666-316280037.1654614666)nda
arama yapabilirsiniz.. Kullanıcıların ürünlerinin farklı özelliklerini
öğrenmelerine yardımcı olmak için Tableau\'da çeşitli eğitim kaynakları
mevcuttur. Tableau, farklı ürünlerini öğrenmeye yardımcı olmak için
çeşitli eğitim kaynakları sunar.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Tableau güçlü bir veri görselleştirme aracıdır, ancak bu, onu yetkin bir
şekilde kullanmanın çok fazla pratik ve deneyim gerektirdiği anlamına
gelir. Kullanacağınız iki ana sayfa veri kaynağı ve veri tasarım
sayfalarıdır. Tableau Yardımı ve Google Veri Analitiği Sertifika
Programı ile Büyüme dahil olmak üzere sürecin her adımında size yardımcı
olacak çok sayıda kaynak da mevcuttur.

### Daha fazla bilgi için kaynaklar

Sorun gidermenize yardımcı olmak veya daha fazla bilgi edinmek için
aşağıdaki bağlantıları kullanabilirsiniz:

-   Verilerinizi başarıya ayarlamak için Tableau kaynak sayfasını
    kullanın: [Veri kaynaklarını
    ayarlama](https://help.tableau.com/current/pro/desktop/en-us/datasource_prepare.htm)

-   Tableau Araçları ve Web Yazma Yardımı: [Grafikler tasarlayın ve
    verileri analiz
    edin](https://help.tableau.com/current/pro/desktop/en-us/design_and_analyze.htm)

-   "Günün Vizi\"ni ve platformda tasarlanan diğer güzel görüntüleri
    içeren Tableau Public "Keşfet" sayfası: [Tableau Public\'e Hoş
    Geldiniz](https://public.tableau.com/app/discover)

-   Tableau Public kullanmaya yeni başlayanlar için kılavuz: [Kendi
    verilerinize, yani yolculuğunuza başlamanıza yardımcı olacak adım
    adım
    kılavuz](https://www.google.com/url?q=https://www.tableau.com/blog/beginners-guide-tableau-public?_gl%3D1*uv0ojo*_ga*MjU5NjUyMzcuMTY1NDMwMDM4MQ..*_ga_8YLN0SNXVS*MTY5MTE4NzA1Mi4xMC4xLjE2OTExODcwNzcuMC4wLjA&sa=D&source=docs&ust=1691485449789685&usg=AOvVaw267xvonfqL2uCc_x_yXcip)

-   İlk Veri Görselleştirmenizi Yayınlamaya Hazırlanmak: [Verileri
    analiz etmek ve Tableau Genel profilinizde bir vizyon yayınlamak
    için adım adım
    kılavuz](https://www.tableau.com/blog/getting-ready-publish-your-first-data-visualization)
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
# 4 Power of statistic {#4-power-of-statistic}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Merkezi eğilim ölçüleri: Ortalama, medyan ve mod
:::

::: {.cell .markdown}
Son zamanlarda, **merkezi eğilim ölçümlerinin** bir veri kümesinin
merkezini temsil eden değerler olduğunu öğrendiniz. Yeni bir veri
kümesiyle çalışırken, verilerinizin merkezi konumunu belirlemek, temel
yapısını hızlı bir şekilde anlamanıza yardımcı olur.

Bu okumada, merkezi eğilimin üç ölçüsü hakkında daha fazla bilgi
edineceksiniz: ortalama, medyan ve mod. Her bir ölçümün nasıl
hesaplanacağını gözden geçireceğiz ve belirli verilerinize dayanarak
hangi ölçümün en iyi kullanılacağını tartışacağız.

### Merkezi eğilim ölçüleri

Ortalama, medyan ve modun tümü, bir veri kümesinin merkezini farklı
şekillerde tanımlar:

-   **Ortalama**, bir veri kümesindeki ortalama değerdir.

-   Med **yan**, bir veri kümesindeki orta değerdir.

-   **Mod, bir veri kümesinde en sık meydana gelen değerdir.**

Merkezi eğilimin her ölçüsünün nasıl hesaplanacağını keşfedelim.

#### Ortalamayı, medyanı ve modu hesaplayın

##### Ortalama

**Ortalama**, bir veri kümesindeki ortalama değerdir. Ortalamayı
hesaplamak için, veri kümenizdeki tüm değerleri toplar ve toplam değer
sayısına bölersiniz.

Örneğin, aşağıdaki değer kümesine sahip olduğunuzu varsayalım: 10, 5, 3,
50, 12. Ortalamayı bulmak için toplam 80 için tüm değerleri eklersiniz.
Ardından, toplam değer sayısı olan 5\'e bölersiniz.

(10+5+3+50+12)÷5=80÷5=16(10+5+3+50+12)÷5=80÷5=16

Ortalama veya ortalama değer 16\'dır.

##### Medyan

Med **yan**, bir veri kümesindeki orta değerdir. Bu, veri kümesindeki
değerlerin yarısının medyandan daha büyük olduğu ve değerlerin yarısının
medyandan daha küçük olduğu anlamına gelir.

Bir veri kümesindeki tüm değerleri en küçükten en büyüğe düzenleyerek
medyanı bulabilirsiniz. Beş değerinizi bu şekilde düzenlerseniz şunları
elde edersiniz: 3, 5, 10, 12, 50. Medyan veya orta değer 10\'dur.

Veri kümenizde çift sayıda değer varsa, medyan iki orta değerin
ortalamasıdır. Diyelim ki setinize başka bir değer, 8, eklediniz: 3, 5,
8, 10, 12, 50. Şimdi, iki orta değer 8 ve 10\'dur. Medyanı elde etmek
için ortalamalarını alın.

(8+10)÷2=18÷2=9(8+10)÷2=18÷2=9

Ortanca 9\'dur.

##### Modu

**Mod, bir veri kümesinde en sık meydana gelen değerdir.** Bir veri
kümesinin modu, bir modu veya birden fazla modu olamaz.

Örneğin, 1, 12, 33, 54, 75 sayı kümesinin modu yoktur çünkü hiçbir değer
tekrarlanmaz. 2, 7, 7, 11, 20 setinde mod 7\'dir, çünkü 7 bir kereden
fazla meydana gelen tek değerdir. 3, 12, 12, 40, 40 setinin iki modu
vardır: 12 ve 40.

#### Ortalama, medyan ve mod ne zaman kullanılır

Veri kümenizin merkezini tanımlamak için ortalama, medyan veya modu
kullanıp kullanmadığınız, üzerinde çalıştığınız belirli verilere ve
verilerinizden hangi içgörüleri elde etmek istediğinize bağlıdır. Her
merkezi eğilim ölçüsünü kullanmak için bazı genel yönergeleri
tartışalım.

##### Ortalama ve medyan

Hem ortalama hem de medyan, bir veri kümesinin merkezi konumunu
tanımlar. Bununla birlikte, merkezi eğilimin ölçümleri olarak, ortalama
ve medyan, farklı veri türleri için daha iyi çalışır.

Ortalamanın bir ana dezavantajı vardır: veri kümenizdeki aykırı
değerlere karşı çok hassastır. Bir aykırı değerin, verilerin geri
kalanından büyük ölçüde farklı bir değer olduğunu hatırlayın.

Veri kümenizde aykırı değerler varsa, medyan genellikle merkezin daha
iyi bir ölçüsüdür. Hiçbir aykırı değer yoksa, ortalama genellikle iyi
çalışır.

Örneğin, küçük bir başlangıç şirketindeki bir çalışanın yıllık ortalama
maaşını hesaplamak istediğinizi düşünün. Aşağıdaki maaş verilerine
sahipsiniz:

  -----------------------------------------------------------------------------
  **Çalışan**   #1       #2       #3       #4       #5       #6       #7
  ------------- -------- -------- -------- -------- -------- -------- ---------
  **Maaş**      40.000   45.000   45.000   45.000   45.000   50,000   500.000
                ABD      ABD      ABD      ABD      ABD      ABD      ABD
                doları   doları   doları   doları   doları   doları   doları

  -----------------------------------------------------------------------------

Veri kümenizdeki tüm değerleri toplayarak ve toplam değer sayısına
bölerek ortalama yıllık maaşı hesaplayabilirsiniz. Toplamda yedi maaş
var ve toplamı 770.000 dolar.

\\\$770,000÷7=\\\$110,000

Bu yedi çalışanın ortalama maaşı 110.000 dolar. Bununla birlikte,
veriler bu ortalama değerin bu şirketteki bir çalışanın tipik maaşını
doğru bir şekilde yansıtmadığını göstermektedir. Çoğu çalışanın maaşı
40.000 ila 50.000 dolar arasındadır. Aslında, yalnızca bir çalışanın
maaşı 50.000 dolardan fazladır. 500.000 dolarlık maaş, ortalamayı
artıran veya ortalamayı çarpıtan bir aykırıdır.

Bu durumda, bu aykırı değerin varlığı nedeniyle, medyan, ortalamadan
daha iyi bir merkezi eğilim ölçüsüdür. Bu veri kümesindeki medyan veya
orta değer 45.000 ABD dolarıdır. Medyan, bu şirketteki bir çalışanın
tipik maaşı hakkında size daha iyi bir fikir verir.

##### Modu

Mod, kategorik verilerle çalışırken kullanışlıdır, çünkü hangi
kategorinin en sık meydana geldiğini açıkça gösterir. Bir şirketin
çalışan memnuniyeti anketi yürüttüğünü varsayalım. Anketteki ana madde,
"Şirket içinde büyümek için sahip olduğum fırsattan memnunum" diyor.
Çalışanlar cevapları için dört kategori arasından seçim yaparlar:
kesinlikle katılıyorum, katılıyorum, katılmıyorum, kesinlikle
katılmıyorum. Bir çubuk grafik sonuçları özetler.

`<img src="attachment:56762a4f-c882-4a75-9693-45f7079ef460.png" width="500"/>`{=html}

Mod, "kesinlikle katılıyorum" derecesine atıfta bulunan çubuk grafikteki
en yüksek çubuğu temsil eder. Bu, veri kümesinde en sık meydana gelen
derecelendirmedir. Mod, şirkete çalışan memnuniyeti konusunda net geri
bildirim verir; bu durumda olumlu geribildirim.

#### Önemli çıkarımlar {#önemli-çıkarımlar}

Ortalama, medyan ve mod gibi merkezi eğilim ölçümleri, veri kümenizin
merkezini tek bir değer kullanarak tanımlamanıza izin verir. Bir veri
uzmanı olarak, veri kümenizin merkezini bilmek, temel yapısını hızlı bir
şekilde anlamanıza ve analizinizdeki sonraki adımları belirlemenize
yardımcı olur.

#### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Ortalama, medyan ve mod gibi merkezi eğilim ölçümleri hakkında daha
fazla bilgi edinmek için aşağıdaki kaynağı keşfedin:

-   [Avustralya İstatistik Bürosu\'nun bu
    makal](https://www.abs.gov.au/websitedbs/D3310114.nsf/Home/Statistical+Language+-+measures+of+central+tendency#:~:text=There%20are%20three%20main%20measures,central%20value%20in%20the%20distribution.)esi,
    ortalama, medyan ve moda yararlı bir genel bakış sunar ve aykırı
    değerlerin merkezi eğilim ölçümlerini nasıl etkilediğini tartışır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## 8, 10, 12 olan 3 bileşenli bir seri için standart sapma; {#8-10-12-olan-3-bileşenli-bir-seri-için-standart-sapma}
:::

::: {.cell .markdown}
`<img src="attachment:00747c40-f484-478a-ae9a-a52a62ca8685.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Dağılım ölçüleri: Menzil, varyans ve standart sapma
:::

::: {.cell .markdown}
Son zamanlarda, **dağılım ölçümlerinin veri kümen** izin yayılımını veya
veri değerlerinizdeki varyasyon miktarını tanımlamanıza izin verdiğini
öğrendiniz. Standart sapma gibi dağılım ölçümleri, verilerinizin
dağılımı hakkında ilk bilgi verebilir ve verilerinize hangi
istatistiksel yöntemlerin uygulanacağını belirlemenize yardımcı
olabilir.

Bu okumada, üç dağılım ölçüsü hakkında daha fazla bilgi edineceksiniz:
aralık, varyans ve standart sapma. Bu okuma, temel standart sapma
kavramına odaklanmaktadır. Bir veri uzmanı olarak, verilerinizin
standart sapmasını sık sık hesaplayacak ve standart sapmayı daha
karmaşık veri analizinin bir parçası olarak kullanacaksınız.

### Dağılım ölçüleri

Her dağılım ölçüsünün tanımını inceleyelim: aralık, varyans ve standart
sapma.

#### **Menzil**

Aralık, bir veri kümesindeki en büyük ve en küçük değer arasındaki
farktır.

Örneğin, bir biyoloji öğretmeni olduğunuzu ve final sınavı için
puanlarla ilgili verileriniz olduğunu hayal edin. En yüksek puan 99/100
veya% 99\'dur. En düşük puan 62/100 veya% 62\'dir. Aralığı hesaplamak
için en düşük puanı en yüksek puandan çıkarın.

99 - 62 = 37

Aralığı yüzde 37 puandır.

Menzil yararlı bir metriktir çünkü hesaplanması kolaydır ve veri
kümenizin genel yayılımını çok hızlı bir şekilde anlamanızı sağlar.

#### **Varyans**

Başka bir yayılma ölçüsüne**, her** veri noktasının ortalamadan kare
farkının ortalamadan ortalaması olan varyans denir. Temel olarak,
standart sapmanın karesidir. Daha sonraki bir kursta varyans ve nasıl
kullanılacağı hakkında daha fazla bilgi edineceksiniz.

#### **Standart sapma**

Standart sapma kavramını daha iyi anlamak için tanımını,
görselleştirmesini ve istatistiksel formülünü inceleyelim.

#### **Tanımı**

**Standart sapma**, değerlerinizin veri kümenizin ortalamasından ne
kadar yayıldığını ölçer. Bir veri noktasının ortalamadan tipik
mesafesini hesaplar. Standart sapma ne kadar büyükse, değerleriniz
ortalamadan o kadar yayılır. Standart sapma ne kadar küçükse,
değerleriniz ortalamadan o kadar az yayılır.

#### **Görselleştirme**

Yayılma hakkında daha iyi bir fikir edinmek için üç normal olasılık
dağılımının grafiklerini inceleyelim. Daha sonra, bir veri kümesindeki
tüm değerleri eşleyen dağıtımlar hakkında bilgi edineceksiniz. Şimdilik,
ortalamanın her eğrideki, tam merkezdeki en yüksek nokta olduğunu bilin.

`<img src="attachment:b9e9591a-9c65-4fd2-92cb-41a65a07ea3c.png" width="500"/>`{=html}

Her eğri aynı ortalamaya ve farklı bir standart sapmaya sahiptir. Mavi
noktalı eğrinin standart sapması 1, yeşil katı eğri 2 ve kırmızı kesikli
eğri 3\'tür. Veri değerlerinin çoğu ortalamaya yakın olduğu için mavi
noktalı eğri en az yayılmaya sahiptir. Bu nedenle, mavi noktalı eğri en
küçük standart sapmaya sahiptir. Veri değerlerinin çoğu ortalamadan daha
uzağa düştüğü için kırmızı kesikli eğri en fazla yayılmaya sahiptir. Bu
nedenle, kırmızı kesikli eğri en büyük standart sapmaya sahiptir.

#### **Formül**

Şimdi bir formül kullanarak standart sapmayı nasıl hesapladığınızı
tartışalım.

Bir popülasyon ve bir örnek için standart sapmayı hesaplamak için farklı
formüller vardır. Hatırlatma olarak, veri uzmanları tipik olarak örnek
verilerle çalışır ve örneğe dayalı olarak popülasyonlar hakkında
çıkarımlar yaparlar. Öyleyse, örnek standart sapma formülünü gözden
geçirelim:

`<img src="attachment:a244f210-c3a2-4821-ace9-9b228324d7a0.png" width="300"/>`{=html}

Formülde n, örneğinizdeki toplam veri değeri sayısıdır, x her bir veri
değeridir ve x( "x-bar" olarak telaffuz edilir) veri değerlerinizin
ortalamasıdır. Yunan harfi Sigma, toplam anlamına gelen bir semboldür.

**Not:** Bir veri uzmanı olarak, hesaplamalar için genellikle bir
bilgisayar kullanırsınız. Hesaplamaları yapabilmek gelecekteki
kariyeriniz için önemlidir, ancak hesaplamaların arkasındaki kavramlara
aşina olmak, işyeri sorunlarına istatistiksel yöntemler uygulamanıza
yardımcı olacaktır.

Formülün farklı bölümlerini daha iyi anlamak için, küçük bir veri
kümesinin örnek standart sapmasını hesaplayalım: 2, 3, 10.

Bunu beş adımda yapabilirsiniz:

**1. Veri değerlerinizin ortalamasını veya ortalamasını hesaplayın.**

(2 + 3 +10) ÷ 3 = 15 ÷ 3 = 5

**2. Her değerden ortalamayı çıkarın**.

2 - 5 = -3

3 - 5 = -2

10 - 5 = 5

**3. Her sonucu kare haline getirin.**

-3\*-3 = 9

-2\*-2 = 4

5\* 5 = 25

**4. Kareli sonuçları toplayın ve bu toplamı veri değerlerinin
sayısından bir taneye bölün. Bu varyans.**

(9 + 4 + 25) ÷ (3 -1) = 38 ÷ 2 = 19

**5. Son olarak, varyansın karekökünü bulun.**

√19 = 4.36

Örnek standart sapması 4.36\'dır.

Artık standart sapma kavramı hakkında daha fazla bilgi sahibi olduğunuza
göre, pratik uygulamasının bir örneğini inceleyelim.

#### **Örnek: Gayrimenkul fiyatları**

Bir emlak şirketi için çalışan bir veri uzmanı olduğunuzu hayal edin.
Ekibinizdeki emlakçılar, müşterilerini farklı yerleşim alanlarındaki
kira fiyatlarındaki değişimler hakkında bilgilendirmeyi sever. İşinizin
bir kısmı, belirli mahallelerdeki daireler için aylık kira fiyatlarının
standart sapmasını hesaplamak ve bu bilgileri ekibinizle paylaşmaktır.
Diyelim ki iki farklı mahallede tek yatak odalı daireler için aylık kira
fiyatları hakkında örnek verileriniz var: Emerald Woods ve Rock Park.
Her veri kümesi için ortalama ve standart sapmayı hesapladığınızı
varsayalım.

**Zümrüt Ormanları**

  **Daire**        #1        #2        #3          #4          #5
  ---------------- --------- --------- ----------- ----------- -----------
  **Aylık Kira**   \\\$900   \\\$950   \\\$1,000   \\\$1.050   1,100\\\$

Ortalama: \$1.000

Standart sapma: \$79.05

**Kaya Parkı**

  **Daire**        #1        #2        #3          #4          #5
  ---------------- --------- --------- ----------- ----------- -----------
  **Aylık Kira**   500\\\$   \\\$650   \\\$1,000   1.350\\\$   1,500\\\$

Ortalama: \$1.000

Standart sapma: \\\$431.56

Her iki mahalle de aylık 1.000 dolarlık aynı ortalama kira fiyatına
sahiptir. Ancak, Rock Park\'da kiralama fiyatlarındaki standart sapma
(\\\$431.56), Emerald Woods\'daki kiralama fiyatlarındaki standart
sapmadan çok daha yüksektir (\\\$79.05). Bu, Rock Park\'ta kiralama
fiyatlarında çok daha fazla değişiklik olduğu anlamına gelir. Bu,
temsilcileriniz için yararlı bir bilgidir. Örneğin, müşterilere Rock
Park\'ta ortalama 1.000 doların çok altında olan daha uygun fiyatlı bir
daire bulmalarının daha kolay olabileceğini söyleyebilirler. Standart
sapma, herhangi bir mahalledeki fiyatlardaki değişimi hızlı bir şekilde
anlamanıza yardımcı olur.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Veri uzmanları, reklam gelirleri, hisse senedi fiyatları, çalışan
maaşları ve daha fazlası gibi birçok veri türündeki değişimi ölçmek için
standart sapmayı kullanır. Standart sapma, varyans ve aralık gibi
dağılım ölçümleri, veri değerlerinizdeki değişimi hızlı bir şekilde
tanımlamanıza ve verilerinizin temel yapısını daha iyi anlamanıza olanak
tanır.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Menzil, varyans ve standart sapma gibi dağılım ölçümleri hakkında daha
fazla bilgi edinmek için aşağıdaki kaynakları keşfedin:

-   [Statistics Canada\"nın bu
    makal](https://www150.statcan.gc.ca/n1/edu/power-pouvoir/ch12/5214891-eng.htm)esi,
    varyans ve standart sapmanın yararlı bir özetini sağlar, ve standart
    sapmanın bir dağılım ölçüsü olarak kullanışlılığını tartışır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Konum ölçüleri: Yüzdelikler ve çeyrekler
:::

::: {.cell .markdown}
Son zamanlarda, **konum ölçümlerinin** bir veri kümesindeki diğer
değerlere göre bir değerin konumunu belirlemenize izin verdiğini
öğrendiniz. Merkez ve yayılma ile birlikte, değerlerinizin göreceli
konumunu bilmek faydalıdır. Örneğin, bir değerin diğerinden daha yüksek
veya daha düşük olup olmadığı veya bir değerin veri kümenizin alt, orta
veya üst kısmına düşüp düşmediği.

Bu okumada, en yaygın konum ölçüleri hakkında daha fazla bilgi
edineceksiniz: yüzdelikler ve çeyrekler. Ayrıca çeyrekler arası aralığı
nasıl hesaplayacağınızı öğrenecek ve verilerinizi özetlemek için beş
sayı özetini kullanacaksınız.

### Pozisyon ölçüleri

#### **Yüzdelik**

Yüz **delik**, bir veri yüzdesinin altına düştüğü değerdir. Yüzdelikler
verilerinizi 100 eşit parçaya böler. Yüzdelikler, bir veri kümesindeki
belirli bir değerin göreceli konumunu veya sırasını verir.

Örneğin, yüzdelikler genellikle okul sınavlarında test puanlarını
sıralamak için kullanılır. Diyelim ki bir test puanı 99. yüzdelik dilime
düşüyor. Bu, puanın tüm test puanlarının% 99\'undan daha yüksek olduğu
anlamına gelir. Bir puan 75. yüzdelik seviyeye düşerse, puan tüm test
puanlarının% 75\'inden daha yüksektir. Bir puan 50. yüzdelik seviyeye
düşerse, puan tüm test puanlarının yarısından veya %50\'sinden daha
yüksektir.

`<img src="attachment:641441db-4beb-414c-a5ff-d42f506e5774.png" width="500"/>`{=html}

***Not: Yüz*** *delikler ve yüzdeler farklı kavramlardır. Örneğin, bir
testte 90/100 veya% 90 puan aldığınızı varsayalım. Bu mutlaka %90\'lık
puanınızın 90. yüzdelik dilimde olduğu anlamına gelmez. Yüzdelik, tüm
sınava girenlerin göreceli performansına bağlıdır. Tüm sınava girenlerin
yarısı %90\'ın üzerinde puan alırsa,% 90\'lık bir puan 50. persentilde
olacaktır.*

Yüzdelikler, değerleri karşılaştırmak ve verileri bağlama koymak için
kullanışlıdır. Örneğin, yeni bir araba almak istediğinizi hayal edin.
Harika yakıt ekonomisine sahip orta boy bir sedan istersiniz. Amerika
Birleşik Devletleri\'nde yakıt ekonomisi, galon yakıt veya mpg başına
mil cinsinden ölçülür. Düşündüğünüz sedan 23 mpg alıyor. Bu iyi mi kötü
mü? Karşılaştırma için bir temel olmadan, bilmek zor. Bununla birlikte,
23 mpg\'nin tüm orta boy sedanların 25. yüzdesinde olduğunu
biliyorsanız, göreceli performansı hakkında çok daha net bir fikriniz
var. Bu durumda, tüm orta boy sedanların %75\'i satın almayı
düşündüğünüz arabadan daha yüksek mpg\'ye sahiptir.

#### **Çeyrek**

Değerlerin göreli konumu hakkında genel bir anlayış elde etmek için
çeyrekleri kullanabilirsiniz. Bir ç **eyrek, bir** veri kümesindeki
değerleri dört eşit parçaya böler.

Üç çeyrek verileri dört çeyreğe böler. Çeyreklikler, verilerin dördüncü
çeyreğine göre değerleri karşılaştırmanıza olanak tanır. Her çeyrek,
veri kümenizdeki değerlerin% 25\'ini içerir.

-   İlk çeyrek, Q1, veri kümesinin ilk yarısındaki orta değerdir.
    Q1, 25. yüzdelik anlamına gelir. Tüm veri kümesindeki değerlerin%
    25\'i Q1\'in altında ve% 75\'i bunun üzerindedir.

-   İkinci çeyrek, Q2, veri kümesinin medyanıdır. Q2, 50. yüzdelik
    değeri ifade eder. Tüm veri kümesindeki değerlerin% 50\'si Q2\'nin
    altında ve% 50\'si bunun üzerindedir.

-   Üçüncü çeyrek, Q3, veri kümesinin ikinci yarısındaki orta değerdir.
    Q3, 75. yüzdelik değeri ifade eder. Tüm veri kümesindeki değerlerin%
    75\'i Q3\'ün altında ve% 25\'i bunun üzerindedir.

`<img src="attachment:2467937e-aab6-4760-95c7-d3e643d3b431.png" width="500"/>`{=html}

#### Örnek: Araba satışları

Örneğin, bir otomobil bayisinde çalışan bir veri uzmanı olduğunuzu hayal
edin. Satış ekibinin yöneticisi, ekipteki her satış temsilcisinin
performansını karşılaştırmak ister. Yönetici, her satış temsilcisinin
geçen ay içinde kaç araba sattığını sağlayan verileri analiz etmenizi
ister.

  **Satış Temsilcisi**      #1   #2   #3   #4   #5   #6   #7   #8
  ------------------------- ---- ---- ---- ---- ---- ---- ---- ----
  **Satılan Otomobiller**   18   13   6    10   15   7    10   9

Verileriniz için çeyrekleri dört adımda hesaplayabilirsiniz:

1.  Veri kümenizdeki değerleri en küçükten en büyüğe doğru düzenleyin.

\[6, 7, 9, 10, 10, 13, 15, 18\]

1.  Tüm veri kümenizin medyanını veya orta değerini bulun. Bu Q2. Veri
    kümesinde çift sayıda değer vardır, bu nedenle medyan, iki orta
    değerin, 10 ve 10\'un ortalamasıdır.

**Q2** = (10 + 10) ÷ 2 = 20 ÷ 2 = 10

1.  Veri kümenizin alt yarısının medyanını bulun \[6, 7, 9, 10\]. Bu Q1.
    Medyan, iki orta değerin, 7 ve 9\'un ortalamasıdır.

**Q1** = (7 + 9) ÷ 2 = 16 ÷ 2 = 8

1.  Son olarak, veri kümenizin üst yarısının medyanını bulun \[10, 13,
    15, 18\]. Bu Q3. Medyan, 13 ve 15\'in iki orta değerin
    ortalamasıdır.

**Q3** = (13 + 15) ÷ 2 = 28 ÷ 2 = 14

Verileri çeyreğe bölmek size satış temsilcisi performansı hakkında net
bir fikir verir. Artık temsilcilerin alt çeyreğinin (Q1) 8 veya daha az
araba sattığını ve üst çeyreğin (Q3) 14 veya daha fazla araba sattığını
biliyorsunuz. Başka bir deyişle, temsilcilerin% 25\'i 8 veya daha az
araba sattı ve üstteki %25\'i 14 veya daha fazla araba sattı.
Temsilcilerin ortada% 50\'si 8 ila 14 araba sattı.

**Not:** Çeyrek değerleri hesaplamanın tek yolu bu değildir. Birçok
gözlemi olan veri kümeleri için, çeyrek hesaplama metodolojisi,
hesaplanan nihai değerler üzerinde ihmal edilebilir bir etkiye sahiptir.
Bununla birlikte, az gözlem içeren veri kümeleri için hesaplanan
çeyrekler önemsiz olmayabilir. Örneğin, Numpy [\'nin persentil
()](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)

işlevi, belirli bir yüzdelik değeri hesaplamak için dokuz farklı yola
sahiptir.

#### **Çeyrekler arası aralık (IQR)**

**Verilerinizin orta %50\'sine çeyrek** **arası aralık veya IQR denir.**
Çeyrekler arası aralık, birinci çeyrek (Q1) ile üçüncü çeyrek (Q3)
arasındaki mesafedir. Bu, 25. ve 75. yüzdelik arasındaki mesafe ile
aynıdır. IQR, veri değerlerinizin göreceli konumunu belirlemek için
kullanışlıdır. Örneğin, Q1 - (1.5 \* IQR) ve Q3 + (1.5 \* IQR)
aralığının dışındaki veri değerleri genellikle aykırı değerler olarak
kabul edilir.

***Not:*** *Teknik olarak, IQR bir dağılım ölçüsüdür çünkü verilerinizin
orta yarısının veya orta %50\'sinin yayılımını ölçer (Q1 ve Q3
arasında). IQR, veri kümenizdeki daha aşırı değerleri içermediğinden,
aykırı değerlere aralıktan daha az duyar* lıdır.

İQR = Q3 - Q1. Bu durumda, Q3 = 14 ve Q1 = 8.

**IQR** = 14 - 8 = 6

#### **Beş sayı özeti**

Son olarak, veri kümenizdeki ana bölümleri beş sayı özetle
özetleyebilirsiniz. Beş sayı şunları içerir:

-   Minimum

-   İlk çeyrek (Q1)

-   Medyan veya ikinci çeyrek (Q2)

-   Üçüncü çeyrek (Q3)

-   Maksimum

Beş sayı özeti kullanışlıdır çünkü verilerinizin aşırı değerlerden
merkeze dağılımı hakkında genel bir fikir verir. Bir kutu çizimi ile
görselleştirebilirsiniz.

Kutu grafiğinin kutu kısmı Q1\'den Q3\'e gider. Kutunun ortasındaki
dikey çizgi medyandır (Q2). Bıyık olarak bilinen kutunun her iki
tarafındaki yatay çizgiler Q1\'den minimuma ve Q3\'ten maksimuma gider.

Aşağıdaki kutu çizimi, araba satışlarıyla ilgili verileri
göstermektedir. Değerleri kutu grafiğinde bulabilir ve çeyrekler arası
aralığı (IQR) belirleyebilirsiniz. IQR, kutunun uzunluğu veya Q1 ile Q3
arasındaki mesafedir.

`<img src="attachment:8b46e4ec-1284-45e5-9ef4-46e34f86c5ab.png" width="500"/>`{=html}

### Önemli çıkarımlar {#önemli-çıkarımlar}

Veri uzmanları, ürün satışlarından hane gelirine kadar her tür veriyi
daha iyi anlamak için yüzdelik ve çeyrek gibi konum ölçümlerini
kullanır. Konum ölçümleri, veri değerlerinizin göreceli konumunu hızlı
bir şekilde belirlemenize yardımcı olur ve verilerinizin dağılımı
hakkında daha kesin bir fikir verir.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Yüzdelik ve çeyrek gibi konum ölçümleri hakkında daha fazla bilgi
edinmek için aşağıdaki kaynağa göz atın:

-   [Freie Universität Berlin\'in bu istatistik
    sözlüğü](https://www.geo.fu-berlin.de/en/v/soga-py/Basics-of-statistics/index.html),
    yüzdelikler, çeyrekler, beş sayı özeti ve daha fazlası gibi konum
    ölçümlerinin net tanımlarını ve yararlı örneklerini sağlar.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Ortalama Okuma Oranını Bulma
:::

::: {.cell .markdown}
``` python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

education_districtwise = pd.read_csv("education_districtwise.csv")
education_districtwise.head(10)
```

`<img src="attachment:cad96a56-b25f-45cc-b3bc-9f3e0f885413.png" width="500"/>`{=html}

``` python
education_districtwise['OVERALL_LI'].describe()
```

`<img src="attachment:ecdd9289-3004-41d8-ba9a-c2e395423ae2.png" width="500"/>`{=html}

``` python
education_districtwise['STATNAME'].describe()
```

`<img src="attachment:8721802d-d53e-4405-9889-40258e4a2738.png" width="400"/>`{=html}

``` python
range_overall_li = education_districtwise['OVERALL_LI'].max() - education_districtwise['OVERALL_LI'].min() 

range_overall_li
```

`<img src="attachment:78128c0f-9e44-481b-bdde-5688922d40e4.png" width="300"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Olasılığın Temel Kavramları
:::

::: {.cell .markdown}
Son zamanlarda, olasılığın belir **siz** liği ölçmek veya bir şeyin olma
olasılığını tanımlamak için matematiği kullandığını öğrendiniz. Örneğin,
yarın yağmur yağma ihtimali %80 veya belirli bir adayın seçimi kazanma
ihtimali %20 olabilir.

Bu okumada, olasılığın temel kavramları hakkında daha fazla bilgi
edineceksiniz. Rastgele bir deney kavramını, bir olayın olasılığının
nasıl temsil edileceğini ve hesaplanacağını ve temel olasılık
gösterimini tartışacağız.

### Olasılık temelleri

##### **Temel kavramlar: Rastgele deney, sonuç, olay**

Olasılık teorisinin temelindeki üç kavramla başlayalım:

-   Rastgele deney

-   Sonuç

-   Etkinlik

Olasılık, istatistikçilerin istatistiksel deneyler olarak da bilinen
rastgele deneyler dediği şeyle ilgilenir. R **astgele bir deney**,
sonucu kesin olarak tahmin edilemeyen bir süreçtir.

Örneğin, bir madeni para atmadan veya bir kalıbı yuvarlamadan önce,
fırlatmanın veya yuvarlanmanın sonucunu bilemezsiniz. Madeni para
atmanın sonucu kafalar veya kuyruklar olabilir. Kalıp rulosunun sonucu 3
veya 6 olabilir.

Tüm rastgele deneylerin üç ortak noktası vardır:

-   Deney birden fazla olası sonuca sahip olabilir.

-   Olası her sonucu önceden temsil edebilirsiniz.

-   Deneyin sonucu şansa bağlıdır.

İstatistikte, rastgele bir deneyin sonucuna sonuç denir. Örneğin, bir
kalıp atarsanız, altı olası sonuç vardır: 1, 2, 3, 4, 5, 6.

Bir olay, bir veya daha fazla sonuçtan oluşan bir kümedir. Bir kalıp
yuvarlama örneğini kullanarak, bir olay çift sayı yuvarlanıyor olabilir.
Çift bir sayının yuvarlanması olayı 2, 4, 6 sonuçlarından oluşur. Veya,
tek bir sayının yuvarlanması olayı 1, 3, 5 sonuçlarından oluşur.

Rastgele bir deneyde, bir olaya bir olasılık atanır. Rastgele bir olayın
olasılığını nasıl temsil edeceğimizi ve hesaplayacağımızı keşfedelim.

#### **Bir olayın olasılığı**

Bir olayın meydana gelme olasılığı, 0 ile 1 arasında bir sayı olarak
ifade edilir. Olasılık yüzde olarak da ifade edilebilir.

-   Bir olayın olasılığı 0\'a eşitse, olayın gerçekleşme ihtimali %0
    vardır.

-   Bir olayın olasılığı 1\'e eşitse, olayın gerçekleşme ihtimali %100
    vardır.

0 ile 1 arasında farklı olasılık dereceleri vardır. Bir olayın olasılığı
sıfıra yakınsa, diyelim ki %0.05 veya% 5, olayın gerçekleşme şansı
küçüktür. Bir olayın olasılığı 1\'e, örneğin 0.95 veya% 95\'e yakınsa,
olayın gerçekleşme şansı yüksektir. Bir olayın olasılığı 0,5\'e eşitse,
olayın gerçekleşmesi veya gerçekleşmemesi ihtimali %50\'dir.

Bir olayın olasılığını bilmek, belirsizlik durumlarında bilinçli
kararlar vermenize yardımcı olabilir. Örneğin, yarın yağmur olasılığı%
0.1 veya% 10 ise, açık hava pikniği planlarınızdan emin olabilirsiniz.
Ancak, yağmur olasılığı% 0.9 veya% 90 ise, pikniğinizi başka bir güne
yeniden planlamayı düşünebilirsiniz.

#### **Bir olayın olasılığını hesaplayın**

Tüm olası sonuçların eşit derecede muhtemel olduğu bir olayın
olasılığını hesaplamak için, istenen sonuçların sayısını toplam olası
sonuç sayısına bölersiniz. Bunun aynı zamanda klasik olasılığın formülü
olduğunu hatırlayabilirsiniz:

*İstenilen sonuç* ların sayısı ÷ *toplam olası sonuç sayısı*

Tek bir rastgele olayın olasılığını nasıl hesaplayacağınıza dair daha
iyi bir fikir edinmek için jeton atma ve die roll örneklerini
inceleyelim.

##### **Örnek: Madeni para fırlatma**

Adil bir madeni para fırlatmak, rastgele bir deneyin klasik bir
örneğidir:

-   Birden fazla olası sonuç var.

-   Olası her sonucu önceden temsil edebilirsiniz: kafalar veya
    kuyruklar.

-   Sonuç şansa bağlıdır. Fırlatma kafaları veya kuyrukları ortaya
    çıkarabilir.

Tek bir atışta kafa alma olasılığını hesaplamak istediğinizi varsayalım.
Herhangi bir madeni para atışı için, kafa alma olasılığı ikiden bir
şanstır. Bu 1 ÷ 2 = 0.5 veya% 50\'dir.

Şimdi, her iki tarafında kafaları olan özel olarak tasarlanmış bir
madeni para fırlatacağınızı hayal edin. Bu madeni parayı her attığınızda
kafaları yükselecek. Bu durumda kafa alma olasılığı% 100\'dür. Kuyruk
alma olasılığı% 0\'dır.

Başlık kazanma olasılığının% 50 olduğunu söylediğinizde, herhangi bir
gerçek jeton atma dizisinin tam olarak %50 kafa ile sonuçlanacağını
iddia etmediğinizi unutmayın. Örneğin, adil bir madeni para on kez
atarsanız, 4 kafa ve 6 kuyruk veya 7 kafa ve 3 kuyruk alabilirsiniz.
Bununla birlikte, madeni parayı atmaya devam ederseniz, uzun vadeli kafa
frekansının% 50\'ye yaklaşmasını bekleyebilirsiniz.

##### **Örnek: Kalıp rulosu**

Altı taraflı bir kalıbı yuvarlamak, rastgele bir deneyin başka bir
klasik örneğidir:

-   Birden fazla olası sonuç var.

-   Tüm olası sonuçları önceden temsil edebilirsiniz: 1, 2, 3, 4, 5 ve
    6.

-   Sonuç şansa bağlıdır. Rulo, herhangi bir sayı 1-6 olarak ortaya
    çıkabilir.

Diyelim ki 3 yuvarlanma olasılığını hesaplamak istiyorsunuz. Herhangi
bir kalıp rulosu için, 3 atma olasılığı altı üzerinden bir şanstır. Bu 1
÷ 6 = 0.1666 veya yaklaşık% 16.7\'dir.

#### **Olasılık gösterimi**

Genellikle eğitim ve teknik bağlamlardaki kavramları sembolize etmek
için kullanıldığı için olasılık gösterimine aşina olmaya yardımcı olur.

Notasyonda, P harfi bir olayın olasılığını gösterir. A ve B harfleri
bireysel olayları temsil eder.

Örneğin, iki olayla uğraşıyorsanız, bir olayı A ve diğer olayı B olarak
etiketleyebilirsiniz.

-   A olayı olasılığı P (A) olarak yazılır.

-   B olayı olasılığı P (B) olarak yazılır.

-   Herhangi bir olay için A, 0 ≤ P (A) ≤ 1. Başka bir deyişle, herhangi
    bir A olayının olasılığı her zaman 0 ile 1 arasındadır.

-   P (A) \> P (B) ise, A olayının meydana gelme şansı B olayından daha
    yüksektir.

-   P (A) = P (B) ise, o zaman A olayı ve B olayı eşit derecede meydana
    gelir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Veri uzmanları, paydaşların belirsiz olaylar hakkında bilinçli kararlar
almalarına yardımcı olmak için olasılığı kullanır. Temel olasılık
kavramları hakkındaki bilginiz, daha karmaşık olasılık hesaplamaları
için bir yapı taşı olarak faydalı olacaktır.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Temel olasılık kavramları hakkında daha fazla bilgi edinmek için
aşağıdaki kaynaklara bakın:

-   [Richland Community College\"dan alınan bu ders
    not](https://people.richland.edu/james/lecture/m116/sequences/probability.html)
    ları, temel kavramların ve temel olasılık kurallarının yararlı bir
    özetini sağlar..
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Çoklu olayların olasılığı
:::

::: {.cell .markdown}
Şimdiye kadar, tek olayların olasılığını hesaplamayı öğreniyorsunuz. Hem
günlük yaşamda hem de veri çalışmasında birçok durum birden fazla olayı
içerir. Gelecekteki bir veri uzmanı olarak, genellikle birden fazla olay
olasılığı ile ilgileneceksiniz.

Bu okumada, birden fazla olay hakkında daha fazla bilgi edineceksiniz.
Üç temel olasılık kuralı öğreneceksiniz: tamamlayıcı kuralı, toplama
kuralı ve çarpma kuralı. Bu kurallar, birden fazla olayın olasılığını
daha iyi anlamanıza yardımcı olur. İlk olarak, bu kuralların geçerli
olduğu iki farklı olay türünü tartışacağız: birbirini dışlayan ve
bağımsız. Ardından, her iki olay türü için olasılığın nasıl
hesaplanacağını öğreneceksiniz.

### İki tür olay {#i̇ki-tür-olay}

Üç temel olasılık kuralı, farklı olay türleri için geçerlidir. Hem
tamamlayıcı kuralı hem de ekleme kuralı, birbirini dışlayan olaylar için
geçerlidir. Çarpma kuralı bağımsız olaylar için geçerlidir.

#### **Karşılıklı dışlayan etkinlikler**

İki olay aynı **anda gerçekleş** emezlerse birbirini dışlar.

Örneğin, Dünya\'da ve ayda aynı anda olamazsınız veya aynı anda oturup
ayakta duramazsınız.

Veya olasılık teorisinin iki klasik örneğini alın. Madeni para
atarsanız, aynı anda kafa ve kuyruk alamazsınız. Bir kalıp
yuvarlarsanız, aynı anda 2 ve 4 alamazsınız.

#### **Bağımsız etkinlikler**

Bir olayın **meydana** gelmesi diğer olayın olasılığını değiştirmezse
iki olay bağımsızdır. Bu, bir olayın diğer olayın sonucunu etkilemediği
anlamına gelir.

Örneğin, sabahları bir film izlemek öğleden sonra havayı etkilemez.
Radyoda müzik dinlemek yeni buzdolabınızın teslimatını etkilemez. Bu
olaylar ayrı ve bağımsızdır.

Veya, ardışık iki jeton fırlatması veya iki ardışık kalıp rulosu yapın.
İlk atışta kafa almak ikinci atışın sonucunu etkilemez. Herhangi bir
madeni para atışı için, herhangi bir sonucun olasılığı her zaman 2
üzerinden 1 veya% 50\'dir. İlk ruloda 2 almak ikinci rulonun sonucunu
etkilemez. Herhangi bir kalıp atışı için, herhangi bir sonucun olasılığı
her zaman 6\'dan 1\'i veya% 16.7\'dir.

### Üç temel kural

Artık birbirini dışlayan ve bağımsız olaylar arasındaki fark hakkında
daha fazla bilgi sahibi olduğunuza göre, üç temel olasılık kuralını
gözden geçirelim:

-   Tamamlayıcı kuralı

-   Toplama kuralı

-   Çarpma kuralı

#### **Tamamlayıcı kuralı**

Tamamlayıcı kuralı, birbirini dışlayan olaylarla ilgilenir.
İstatistikte, bir olayın tamamlayıcısı gerçekleşmeyen olaydır. Örneğin,
ya kar yağar ya da kar yağmaz. Ya futbol takımınız şampiyonluğu kazanır
ya da şampiyonluğu kazanmaz. Karın tamamlayıcısı kar değildir.
Kazanmanın tamamlayıcısı kazanmak değildir.

Bir olayın meydana gelme olasılığı ve gerçekleşmemesi olasılığı 1\'e
kadar olmalıdır. 1 olasılığının% 100 ile aynı olduğunu hatırlayın.

Bunu düşünmenin başka bir yolu, bir olayın veya diğer olayın meydana
gelme olasılığın% 100 olmasıdır. Yarın %40 kar yağma ihtimali olabilir.
Ancak yarın kar yağma ya da kar yağmama ihtimali %100.

Tam **amlayıcı kur** alı, A olayının gerçekleşmemesi olasılığının 1 eksi
A olasılığı olduğunu belirtir: Olasılık gösteriminde bunu şu şekilde
yazabilirsiniz:

**Tamamlayıcı kuralı**

P (A) = 1 - P (A)

**Not: Olas** ılık gösteriminde, kesme işareti (\') olumsuzlamayı
sembolize eder. Başka bir deyişle, A olayının meydana gelmemesi
olasılığını belirtmek istiyorsanız, A: P (A\') harfinden sonra bir kesme
işareti ekleyin. Bunu "A olmaması olasılığı" olarak söyleyebilirsiniz.

Bu nedenle, yarın% 40 kar olasılığının veya 0.4 olasılığının olduğunu
biliyorsanız, yarın kar yağmama olasılığını hesaplamak için tamamlayıcı
kuralını kullanabilirsiniz. Kar olmaması olasılığı bir eksi kar
olasılığına eşittir.

P (kar yok) = 1 - P (kar) = 1 - 0.4 = 0.6.

Yani, yarın kar yağma olasılığı 0.6 veya% 60\'dır.

#### **Toplama kuralı (birbirini dışlayan olaylar için)**

Topl **ama kuralı**, eğer A ve B olayları birbirini dışlarsa, A veya
B\'nin meydana gelme olasılığının A ve B\'nin olasılıklarının toplamı
olduğunu belirtir: Olasılık gösteriminde, bunu şu şekilde
yazabilirsiniz:

P (A veya B) = P (A) +P (B)

Karşılıklı olarak kapsayan etkinlikler için de bir ekleme kuralı
olduğunu unutmayın. Bu derste, birbirini dışlayan olaylar için kurala
odaklanıyoruz.

Bir kalıp yuvarlama örneğimizi inceleyelim.

##### **Kalıp rulosu (2 veya 4 yuvarlama)**

Tek bir ruloda 2 veya 4 yuvarlanma olasılığını bulmak istediğinizi
varsayalım. Bu iki olay birbirini dışlar. 2 veya 4 yuvarlayabilirsiniz,
ancak her ikisini de aynı anda yapamazsınız.

Toplama kuralı, her iki olayın meydana gelme olasılığını bulmak için
olasılıklarını topladığınızı söyler. Bir kalıpta tek bir sayı atma
olasılığı 6\'dan 1\'i veya% 16.7\'dir.

P (haddeleme 2 veya haddeleme 4) = P (haddeleme 2) + P (haddeleme 4) = +
= ⅓

Yani, 2 veya 4 yuvarlanma olasılığı üçten biri veya% 33\'tür.

#### **Çarpma kuralı (bağımsız olaylar için)**

Ç **arpma kuralı**, eğer A ve B olayları bağımsızsa, o zaman hem A hem
de B\'nin meydana gelme olasılığının, A olasılığının B olasılığı ile
çarpılmasıdır. Olasılık gösteriminde, bunu şu şekilde yazabilirsiniz:

P (A ve B) = P (A) × P (B)

Bağımlı olaylar için de bir çarpma kuralı olduğunu unutmayın. Bu derste,
bağımsız etkinlikler için kurala odaklanıyoruz.

Bir kalıp yuvarlama örneğimizle devam edelim.

##### **Kalıp rulosu (1 yuvarlama ve ardından 6 yuvarlama)**

Şimdi arka arkaya iki kalıp rulosu hayal edin. Diyelim ki bir 1\'i
yuvarlama ve ardından bir 6\'yı yuvarlama olasılığını bilmek
istiyorsunuz. Bunlar bağımsız olaylardır, çünkü ilk rulo ikinci rulonun
sonucunu etkilemez.

Bir 1\'i ve ardından bir 6\'yı yuvarlama olasılığı, bir 1\'i yuvarlama
olasılığının 6 yuvarlanma olasılığıyla çarpılmasıdır. Her olayın
olasılığı veya% 16.7\'dir. Bunu şu şekilde yazabilirsiniz:

P (ilk ruloda 1 yuvarlama ve ikinci ruloda 6 yuvarlama) = P (ilk ruloda
1 yuvarlama) × P (ikinci ruloda 6 yuvarlama) = × = 1/36

Yani, bir 1 ve sonra bir 6\'yı yuvarlama olasılığı otuz altıdan biri
veya yaklaşık% 2.8\'dir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Temel olasılık kuralları, birbirini dışlayan veya bağımsız olan olayları
tanımlamanıza yardımcı olur. Temel olasılık kurallarını anlamak,
gelecekteki bir veri uzmanı olarak gerçekleştireceğiniz daha karmaşık
analizler için temel bir temeldir.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Olasılık hakkında daha fazla bilgi edinmek için, aşağıdaki etkileşimli
kılavuza bakın: [Görme
Teorisi](https://seeing-theory.brown.edu/index.html#secondPage).
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Koşullu olasılık
:::

::: {.cell .markdown}
Önceden, tek bir olay için ve iki veya daha fazla bağımsız olay için,
örneğin iki ardışık jeton çevirme olasılığı hesapladınız. Koşullu
olasılık, iki veya daha fazla bağımlı olay için geçerlidir.

### **Bağımlı olaylar**

Daha önce, ilk olay ikinci olayın sonucunu etkilemiyorsa veya
olasılığını değiştirmezse iki olayın **bağımsız** olduğunu öğrendiniz.
Örneğin, ardışık iki madeni para atışı bağımsız olaylardır. İlk atışta
kafa almak ikinci atışın sonucunu etkilemez.

Buna karşılık, bir olayın **meydana gelmesi diğer olayın olasılığını
değiştirirse iki olay bağım** lıdır. Bu, ilk olayın ikinci olayın
sonucunu etkilediği anlamına gelir.

Örneğin, bir sınavda iyi bir not almak istiyorsanız, önce ders
materyalini incelemeniz gerekir. İyi bir not almak çalışmaya bağlıdır.
Bir masa beklemeden popüler bir restoranda yemek yemek istiyorsanız,
erken gelmelisiniz. Beklemekten kaçınmak erken gelmeye bağlıdır. Her
durumda, ikinci olayın ilk olaya bağlı veya buna bağlı olduğunu
söyleyebilirsiniz.

Artık bağımlı olayları daha iyi anladığınıza göre, koşullu olasılığa
dönelim ve formülü gözden geçirelim.

### **Koşullu olasılık formülü**

Formül, iki bağımlı olay A ve B için, A olayının ve B olayının meydana
gelme olasılığının, A olayının meydana geldiği göz önüne alındığında, B
olayı meydana gelme olasılığı ile çarpıldığında, A olayının meydana
gelme olasılığına eşit olduğunu söylüyor.

**Koşullu olasılık**

P (A ve B) = P (A) \* P (B \| A)

Olasılık gösteriminde, B ve A harfleri arasındaki dikey çubuk
bağımlılığı gösterir veya B olayının meydana gelmesinin A olayının
meydana gelmesine bağlı olduğunu gösterir. Bunu "A verilen B olasılığı"
olarak söyleyebilirsiniz.

Formül ayrıca, A olayı verilen B olayının olasılığının, hem A hem de
B\'nin meydana gelme olasılığına eşit olarak ifade edilebilir. A
olasılığına bölünmesi.

**Koşullu olasılık**

P (B \| A) = P (A ve B)/P (A)

Bunlar aynı denklemi temsil etmenin sadece iki yoludur. Duruma veya
önceden hangi bilgilerin verildiğine bağlı olarak, birini veya diğerini
kullanmak daha kolay olabilir.

**Not: Ko** şullu olasılık formülü bağımsız olaylar için de geçerlidir.
A ve B bağımsız olaylar olduğunda, P (B\|A) = P (B). Böylece formül P (A
ve B) = P (A) \* P (B) olur. Bu formül aynı zamanda kursta daha önce
öğrendiğiniz çarpma kuralıdır.

### **Örnek: oyun kartları**

52 oyun kartından oluşan standart bir desteyle ilgilenen koşullu
olasılık örneğini inceleyelim.

İki olay hayal edin:

-   İlk olay, kart destesinden bir kalp çizmektir.

-   İkinci olay, aynı desteden başka bir kalp çekmektir.

Arka arkaya iki kalp çizme olasılığını öğrenmek istediğinizi varsayalım.
Bu iki olay bağımlıdır çünkü ilk çekilişte kalp almak ikinci çekilişte
kalp alma olasılığını değiştirir..

Standart bir güverte dört farklı takım içerir: kalpler, elmaslar,
kürekler ve sopalar. Her takımın 13 kartı vardır. İlk çekiliş için kalp
alma şansı 52 üzerinden 13 veya% 25\'tir. İkinci çekiliş için, ilk
çekilişte zaten bir kalp seçtiğiniz için kalp alma olasılığı değişir.
Şimdi, 51 kartlık bir destede 12 kalp var. İkinci çekiliş için kalp alma
şansı 51 üzerinden 12\'si veya yaklaşık% 23,5\'tir. Kalbe sahip olmak
artık daha az olasıdır - olasılık %25\'ten %23,5\'e çıktı.

Şimdi, koşullu olasılık formülünü uygulayalım:

**P (A ve B) = P (A) \* P (B \| A)**

Hem A olayının hem de B olayının meydana gelme olasılığını hesaplamak
istiyorsunuz. Etkinliğe *1. kalp diyelim,* ilk çekilişte kalp almayı
ifade eder. Olayı B *2. kalp diyelim*, ikinci çekilişte kalp almayı
ifade eder, ilk seferde bir kalp çizildiği göz önüne alındığında. A
olayı olasılığı 13/52 veya% 25\'tir. B olayı olasılığı 12/51 veya%
23.5\'tir.

Bu sayıları formüle girelim:

**P (1. kalp ve 2. kalp) = P (1. kalp) \* P (2. kalp \| 1. kalp)** =
13/52 \* 12/51 = 1/17 = 0.0588 veya yaklaşık% 5.9

Dolayısıyla, standart bir oyun kartı destesinden arka arkaya iki kalp
çekme şansı% 5,9\'dur.

### **Örnek: çevrimiçi satın alımlar**

Başka bir örneği inceleyelim. Bir çevrimiçi perakende mağazasında
çalışan bir veri uzmanı olduğunuzu hayal edin. Mağazanın web sitesini
ziyaret eden müşterilerin% 20\'sinin 100\$ veya daha fazla satın alma
yaptığını söyleyen verileriniz var. Bir müşteri 100\$ harcıyorsa,
ücretsiz hediye kartı almaya hak kazanır. Mağaza, en az 100\$ harcayan
müşterilerin% 10\'una rastgele hediye kartları verir.

Bir müşterinin 100\$ harcama ve hediye kartı alma olasılığını hesaplamak
istiyorsunuz. Hediye kartı almak, ilk 100\$ harcamanıza bağlıdır. Yani,
bu koşullu bir olasılıktır çünkü iki bağımlı olayla ilgilenir.

Koşullu olasılık formülünü uygulayalım:

**P (A ve B) = P (A) \* P (B \| A)**

Hem A olayının hem de B olayının meydana gelme olasılığını hesaplamak
istiyorsunuz. A etkinliğine *100\$ ve etkinlik* B *hediye kartı
diyelim*. A olayı olasılığı 0.2 veya% 20\'dir. B olayı olasılığı 0.1
veya% 10\'dur.

**P (100\\\$ ve hediye kartı) = P (100\\\$) \* P (hediye kartı 100\\\$
verilen)** = 0,2 \* 0,1 = 0,02 veya% 2

Dolayısıyla, bir müşterinin 100\$ veya daha fazla harcama ve ücretsiz
hediye kartı alma olasılığı 0,2 \* 0,1 = 0,02 veya% 2\'dir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Koşullu olasılık, bağımlı olaylar arasındaki ilişkiyi tanımlamanıza
yardımcı olur. Veri uzmanları genellikle bir iş bağlamında koşullu
olasılığı kullanır. Örneğin, yeni bir reklam kampanyası gibi bir
etkinliğin satış gelirini nasıl etkileyeceğini tahmin etmek için koşullu
olasılığı kullanabilirler. Bu, paydaşların şirketlerinin kaynaklarına
yatırım yapmanın en iyi yolu hakkında akıllı kararlar almalarına
yardımcı olur.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Koşullu olasılık hakkında daha fazla bilgi edinmek için aşağıdaki
kaynağa bakın:

-   [Investopedia\"nın bu makalesi, bir iş bağlamında koşullu olasılığı
    tartışıyor.](https://www.investopedia.com/terms/c/conditional_probability.asp#:~:text=Conditional%20probability%20is%20defined%20as,succeeding%2C%20or%20conditional%2C%20event.)
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Genişletilmiş Bayes Teoremi
:::

::: {.cell .markdown}
Son zamanlarda, **Bayes teore** minin koşullu olasılığı belirlemek için
bir matematik formülü olduğunu öğrendiniz. Teorem, adını Londra,
İngiltere\'den 18. yüzyıl matematikçisi Thomas Bayes\'in adını almıştır.
Koşul **lu olas** ılığın, başka bir olayın daha önce meydana geldiği göz
önüne alındığında meydana gelme olasılığını ifade ettiğini hatırlayın.
Örneğin, bir oyun kartı destesinden bir as çektiğinizde, bu aynı
desteden ikinci bir as çekme olasılığını değiştirir.

Bu okumada, Bayes teoreminin farklı bölümleri ve şartlı olasılığı
hesaplamak için teoremi nasıl kullanabileceğiniz hakkında daha fazla
bilgi edineceksiniz.

### Bayes teoremi

Bayes teoremi, olayla ilgili yeni bilgilere dayanarak bir olayın
olasılığını güncellemenin bir yolunu sağlar.

#### **Posterior ve önceki olasılık**

Bayes istatistiklerinde, **önceki olasılık**, yeni veriler toplanmadan
önce bir olayın olasılığını ifade eder. **Posterior olas** ılık, yeni
verilere dayalı bir olayın güncellenmiş olasılığıdır.

Bayes teoremi, verilerinize göre önceki olasılığı güncelleyerek arka
olasılığı hesaplamanıza olanak tanır.

Örneğin, tıbbi bir durumun yaşla ilgili olduğunu varsayalım. Bir kişinin
yaşa göre duruma sahip olma olasılığını daha doğru bir şekilde
belirlemek için Bayes teoremini kullanabilirsiniz. Önceki olasılık, bir
kişinin duruma sahip olma olasılığı olacaktır. Posterior veya
güncellenmiş olasılık, belirli bir yaş grubundaysa, bir kişinin duruma
sahip olma olasılığı olacaktır.

#### **Teorem**

Teoremin kendisini inceleyelim.

**Bayes teoremi**, herhangi iki A ve B olayı için, verilen B
olasılığının, A olasılığının, A verilen B olasılığının B olasılığının B
olasılığına bölünmesiyle eşit olduğunu belirtir.

**Bayes teoremi**

Teoremde, önceki olasılık olayın olasılığıdır A. Posterior olasılık veya
hesaplamaya çalıştığınız şey, A olayının olasılığıdır B olayının
olasılığıdır.

-   **P (A)**: Önceki olasılık

-   **P (A\|B): Arka olas** ılık

Bazen istatistikçiler ve veri uzmanları, A olayına verilen B olayının
olasılığını ifade etmek için "olasılık" terimini ve B olayının
olasılığını ifade etmek için "kanıt" terimini kullanırlar.

-   **P (B\|A): Olasılık**

-   **P (B)**: Kanıt

Bu terimleri kullanarak Bayes teoremini şu şekilde yeniden ifade
edebilirsiniz:

-   Posterior = Olasılık \* Önceki/ Kanıt

`<img src="attachment:3c69b7aa-eae2-47a5-919a-8a4e860c45ac.png" width="500"/>`{=html}

Hesaplamayı bu farklı perspektiflerden düşünmek ve probleminizi
denklemle eşlemeye yardımcı olabilir.

Bayes teoremi hakkında düşünmenin bir yolu, önceki bir inancı, P (A),
yeni verileri kullanarak arka bir olasılık olan P (A \| B) \'ye
dönüştürmenize izin vermesidir. Yeni veriler olasılık, P (B \| A) ve
kanıtlar, P (B).

***Not:*** *Bu okuma, Bayes teoremi ile ilişkili temel kavram ve
terimlere bir giriş sağlar. Bayes istatistiklerinin detaylı bir
incelemesi bu dersin kapsamı dışındadır. Kariyerinizde bir veri uzmanı
olarak ilerledikçe, Bayes teoremini ve çeşitli uygulamalarını daha fazla
keşfetme fırsatına sahip olacaksınız*.

Şimdilik hatırlanması gereken önemli bir nokta, Bayes teoreminin hem A
verilen B\'nin koşullu olasılığını hem de A verilen B\'nin koşullu
olasılığını içerdiğidir. Bu olasılıklardan birini biliyorsanız, Bayes
teoremi diğerini belirlemenize yardımcı olabilir.

Teoremin nasıl çalıştığını daha iyi anlamak için bir örneği inceleyelim.

#### **Örnek: spam filtresi**

Bayes teoreminin dijital dünyada iyi bilinen bir uygulaması spam
filtreleme veya bir e-postanın spam olup olmadığını tahmin etmektir.
Uygulamada, sofistike bir spam filtresi, e-postanın içeriği, başlığı,
eki olup olmadığı, gönderen adresinin etki alanı türü (.edu veya.org) ve
daha fazlası dahil olmak üzere birçok farklı değişkenle ilgilenir.
Ancak, örneğimiz için Bayes spam filtresinin basitleştirilmiş bir
sürümünü kullanabiliriz.

Diyelim ki e-postada belirli bir kelime göründüğü için bir e-postanın
spam olma olasılığını belirlemek istediğinizi varsayalım. Bu örnekte,
"para" kelimesini kullanalım.

Aşağıdaki bilgileri keşfedersiniz:

-   Bir e-postanın spam olma olasılığı% 20\'dir.

-   Bir e-postada "para" kelimesinin görünme olasılığı% 15\'tir.

-   Bir spam e-postada "para" kelimesinin görünme olasılığı% 40\'tır.

Bu örnekte, önceki olasılığınız, bir e-postanın spam olma olasılığıdır.
Sonradan olasılığınız veya nihayetinde öğrenmek istediğiniz şey, bir
e-postanın "para" kelimesini içerdiği göz önüne alındığında spam olma
olasılığıdır. Önceki olasılığınızı güncellemek için kullanacağınız yeni
veriler, "para" kelimesinin bir e-postada görünme olasılığı ve "para"
kelimesinin spam e-postada görünme olasılığıdır.

Bayes teoremiyle çalışırken, önce A olayının ne olduğunu ve B olayının
ne olduğunu bulmak yararlıdır - bu, olaylar arasındaki ilişkiyi anlamayı
ve formülü kullanmayı kolaylaştırır.

A etkinliğine spam e-posta ve B olayına bir e-postada "para" kelimesinin
görünüşü diyelim. Şimdi, Bayes teoremini A olayı için "spam" kelimesini
ve B olayı için "para" kelimesini kullanarak yeniden yazabilirsiniz.

P (A \| B) = P (B \| A) \* P (A)/P (B)

P (İstenmeyen İleti \| Para) = P (Para \| İstenmeyen İleti) \* P
(İstenmeyen İleti)/P (Para)

Aşağıdakileri öğrenmek istiyorsunuz:

-   **P (Spam\| Para) veya arka olasılık**: e-postada "para" kelimesinin
    görünmesi göz önüne alındığında bir e-postanın spam olma olasılığı

Şimdi, verilerinizi formüle girin:

-   **P (SpAM) veya önceki olas** ılık: bir e-postanın spam olma
    olasılığı = 0.2 veya% 20

-   **P (Para) veya kanıt:** "para" kelimesinin bir e-postada görünme
    olasılığı = 0.15 veya% 15

-   **P (Para \| SpAM) veya olasılık: e-postanın spam** olduğu göz önüne
    alındığında "para" kelimesinin bir e-postada görünme olasılığı = 0.4
    veya% 40

P (SpAM \| Para) = P (Para \| SpAM) \* P (SpAM)/P (Para) = 0.4 \*
0.2/0.15 = 0.53333 veya yaklaşık% 53.3%.

Dolayısıyla, e-postanın "para" kelimesini içerdiği göz önüne
alındığında, bir e-postanın spam olma olasılığı% 53.3\'tür.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Bayes teoremi, modern veri analitiğinde verileri analiz etmek ve
yorumlamak için güçlü bir yöntem olan Bayes çıkarımı olarak da bilinen
Bayes istatistik alanının temelidir. Veri uzmanları, Bayes teoremini
yapay zekadan tıbbi testlere kadar çok çeşitli alanlarda kullanır.

Bayes teoremi hakkında temel bir anlayışa sahip olmak, kariyerinizde bir
veri uzmanı olarak ilerledikçe Bayes istatistikleri hakkında daha fazla
bilgi edinmenizi sağlayacaktır.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Bayes Teoremi hakkında daha fazla bilgi edinmek için aşağıdaki kaynağa
bakın:

-   [Pennsylvania Eyalet Üniversitesi tarafından açıklanan Bayes
    teoremi](https://online.stat.psu.edu/stat500/lesson/2/2.7)

"Savcının yanılgısı" hakkında ilginç bir tartışma için bu sayfaya göz
atın:

-   [Amerikan Epidemiyoloji Dergisi tarafından savcının yanılgısının
    açıklaması](https://academic.oup.com/aje/article/179/9/1125/103523)
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Ayrık olasılık dağılımları
:::

::: {.cell .markdown}
Son zamanlarda, veri profesyonellerinin farklı veri kümelerini
modellemek ve verilerindeki önemli kalıpları belirlemek için olasılık
dağılımlarını kullandığını öğrendiniz. Bir olasılık **dağılımının**
rastgele bir olayın olası sonuçlarının olasılığını tanımladığını
hatırlayın. Ayrık olasılık dağılımları, ayrık rastgele değişkenleri veya
ayrık olayları temsil eder. Genellikle, ayrık olayların sonuçları
sayılabilen tam sayılar olarak ifade edilir. Örneğin, bir kalıbın
yuvarlanması 2 veya 3 ile sonuçlanabilir, ancak 2.575 veya 3.184 gibi
ondalık bir değerle sonuçlanamaz.

Bu okumada, dört ortak ayrık olasılık dağılımının ana özelliklerine
genel bir bakış elde edeceksiniz:

-   Uniform

-   Binom

-   Bernoulli

-   Poison

### Ayrık olasılık dağılımları {#ayrık-olasılık-dağılımları}

#### **Düzgün dağılım**

Tek tip dağılım, sonuçları eşit derecede olası veya eşit olasılığa sahip
olayları tanımlar.

Örneğin, bir kalıbı yuvarlamak altı sonuçla sonuçlanabilir: 1, 2, 3, 4,
5 veya 6. Her sonucun olasılığı aynıdır: 6\'dan 1\'i veya yaklaşık%
16.7.

Bir dağılımı histogram gibi bir grafikle görselleştirebilirsiniz. Ayrık
bir dağılım için, rastgele değişken x ekseni boyunca çizilir ve karşılık
gelen olasılık y ekseni boyunca çizilir. Bu durumda, x ekseni, tek bir
kalıp rulosunun olası her sonucunu temsil eder ve y ekseni her sonucun
olasılığını temsil eder.

`<img src="attachment:d03fdc0f-00a4-41dc-9447-2bf69b760951.png" width="500"/>`{=html}

***Not: Veri*** *uzmanları genellikle tek tip dağılımı Monte Carlo
simülasyonları gibi daha karmaşık istatistiksel yöntemlerin bir parçası
olarak kullanır. Bu yöntemlerin ayrıntılı bir tartışması bu dersin
kapsamı dışındadır.*

***Not: Düz*** *gün dağılım hem ayrık hem de sürekli rastgele
değişkenler için geçerlidir.*

#### **Binom dağılımı**

**Binom dağılımı,** olayların olasılığını yalnızca iki olası sonuçla
modeller: başarı veya başarısızlık. Bu sonuçlar birbirini dışlar ve aynı
anda gerçekleşemez.

Bu tanım aşağıdakileri varsayar:

-   Her olay bağımsızdır veya diğerlerinin olasılığını etkilemez.

-   Her olay aynı başarı olasılığına sahiptir.

Başarı ve başarısızlığın kolaylık sağlamak için kullanılan etiketler
olduğunu unutmayın. Örneğin, bir madeni para atarsanız, yalnızca iki
olası sonuç vardır: kafalar veya kuyruklar. Analizinizin ihtiyaçlarına
göre kafaları veya kuyrukları başarılı bir sonuç olarak etiketlemeyi
seçebilirsiniz.

Binom dağılımı, binom deneyi adı verilen bir rastgele olayı temsil eder.
Bir binom deneyi aşağıdaki özelliklere sahiptir:

-   Deney, bir dizi tekrarlanan denemeden oluşur.

-   Her denemenin sadece iki olası sonucu vardır.

-   Başarı olasılığı her deneme için aynıdır.

-   Ve, her duruşma bağımsızdır.

Bir binom deneyi örneği, arka arkaya 10 kez bir madeni para
fırlatmaktır. Bu, aşağıdaki özelliklere sahip olduğu için binom bir
deneydir:

-   Deney, tekrarlanan 10 denemeden veya madeni para fırlatmasından
    oluşur.

-   Her denemenin sadece iki olası sonucu vardır: kafalar veya
    kuyruklar.

-   Her deneme aynı başarı olasılığına sahiptir. Başarıyı kafa olarak
    tanımlarsanız, her atış için başarı olasılığı aynıdır: %50.

-   Her deneme bağımsızdır. Bir madeni para atmanın sonucu, diğer madeni
    para atışlarının sonucunu etkilemez.

Histogramda, x ekseni kafa sayısını gösterir ve y ekseni her sonucu alma
olasılığını gösterir.

`<img src="attachment:d52745fd-663e-48f6-b83f-9969fb7fd2af.png" width="500"/>`{=html}

Veri uzmanları, aşağıdakileri modellemek için binom dağılımını
kullanabilir:

-   Yeni bir ilaç yan etkiler yaratır

-   Kredi kartı işlemi dolandırıcılıktır

-   Bir hisse senedi fiyatının değeri yükselir

Makine öğreniminde, binom dağılımı genellikle verileri sınıflandırmak
için kullanılır. Örneğin, bir veri uzmanı, dijital bir görüntünün kedi
veya köpek gibi belirli bir hayvan türü olup olmadığını anlamak için bir
algoritma eğitebilir.

#### **Bernoulli dağılımı**

Bernoulli dağılımı, yalnızca iki olası sonucu olan olayları (başarı veya
başarısızlık) modellediği için binom dağılımına benzer. Tek fark,
Bernoulli dağılımının bir deneyin yalnızca tek bir denemesini ifade
ederken, binomun tekrarlanan denemeleri ifade etmesidir. Bernoulli
davasının klasik bir örneği, tek bir madeni para fırlatmasıdır.

Histogramda, x ekseni bir madeni para fırlatmanın olası sonuçlarını
temsil eder ve y ekseni her sonucun olasılığını temsil eder.

`<img src="attachment:77ecbeca-51da-4843-a0c4-321cc13a2958.png" width="500"/>`{=html}

#### **Poisson dağılımı**

Po **isson dağılımı**, belirli bir zaman diliminde belirli sayıda olayın
meydana gelme olasılığını modeller.

***Not:*** *Poisson dağılımı, mesafe, alan veya hacim gibi belirli bir
alanda meydana gelen olayların sayısını temsil etmek için de
kullanılabilir. Bu derste zamana odaklanıyoruz.*

Poisson dağılımı, Poisson deneyi adı verilen bir tür rastgele deneyi
temsil eder. Bir Poisson deneyi aşağıdaki özelliklere sahiptir:

-   Deneydeki olayların sayısı sayılabilir.

-   Belirli bir zaman diliminde meydana gelen ortalama olay sayısı
    bilinmektedir.

-   Her olay bağımsızdır.

Örneğin, içerik yayınladığınız çevrimiçi bir web siteniz olduğunu hayal
edin. Web siteniz saatte ortalama iki görüntüleme. Web sitenizin belirli
bir saatte belirli sayıda görüntülenme alma olasılığını belirlemek
istiyorsunuz.

Bu bir Poisson deneyidir çünkü:

-   Deneydeki olayların sayısı sayılabilir. Görüntülenme sayısını
    sayabilirsiniz.

-   Belirli bir zaman diliminde meydana gelen ortalama olay sayısı
    bilinmektedir. Saatte ortalama iki görüntüleme var.

-   Her sonuç bağımsızdır. Bir kişinin web sitenizi görüntüleme
    olasılığı, başka bir kişinin web sitenizi görüntüleme olasılığını
    etkilemez.

Histogramda, x ekseni saatte görüntüleme sayısını gösterir ve y ekseni
oluşma olasılığını gösterir.

`<img src="attachment:2c4f21ea-a92b-42ed-a722-83532d5255e3.png" width="500"/>`{=html}

Veri uzmanları, aşağıdakilerin sayısı gibi verileri modellemek için
Poisson dağılımını kullanır:

-   Müşteri hizmetleri çağrı merkezi için saatlik çağrı

-   Bir mağazada günlük müşteriler

-   Bir şehirde aylık gök gürültülü fırtınalar

-   Bir bankada saniyede finansal işlemler

### Önemli çıkarımlar {#önemli-çıkarımlar}

Verilerinizin dağılımını belirlemek, herhangi bir analizde önemli bir
adımdır ve gelecekteki sonuçlar hakkında bilinçli tahminler yapmanıza
yardımcı olur. Gelecekteki bir veri uzmanı olarak kariyerinizde,
verilerinizi daha iyi anlamak için binom ve Poisson gibi ayrık
dağılımları kullanacaksınız. Verilerinizin olasılık dağılımını bilmek,
analiziniz için en uygun istatistiksel yöntemi veya makine öğrenimi
modelini seçmenize de yardımcı olacaktır.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Ayrık olasılık dağılımları hakkında daha fazla bilgi edinmek için
aşağıdaki kaynaklara bakın:

-   [Statistics How To\'nun bu
    makal](https://www.statisticshowto.com/discrete-probability-distribution/)
    esi, ayrık olasılık dağılımı kavramına genel bir bakış sağlar ve
    binom ve Poisson gibi belirli dağılım türleri hakkında daha fazla
    bilgi edinmek için bağlantılar sunar..
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Normal dağılımlı model verileri
:::

::: {.cell .markdown}
Son zamanlarda, sürekli olasılık dağılımları ve veri profesyonellerinin
verilerini modellemesine nasıl yardımcı olduklarını öğreniyorsunuz.
Sürekli olasılık dağılımlarının, bir dizi sayı içindeki tüm olası
değerleri alabilen sürekli rastgele değişkenleri temsil ettiğini
hatırlayın. Tipik olarak, bunlar boy, ağırlık, zaman veya sıcaklık gibi
ölçülebilen ondalık değerlerdir. Örneğin, ölçüm süresini daha doğru bir
şekilde sürdürebilirsiniz: 1.1 saniye, 1.12 saniye, 1.1257 saniye vb.

Bu derste tek bir sürekli olasılık dağılımına odaklanıyoruz: normal
dağılım. Bu okumada, normal dağılımın temel özellikleri ve dağıtımın
verilerinizi modellemenize nasıl yardımcı olabileceği hakkında daha
fazla bilgi edineceksiniz.

### Sürekli olasılık dağılımları

Normal dağılımın belirli niteliklerine geçmeden önce, tüm sürekli
olasılık dağılımlarının bazı genel özelliklerini tartışalım.

#### **Olasılık Yoğunluğu ve Olasılık**

Olasılık fonksiyonu, rastgele bir değişkenin olası sonuçları için
olasılıklar sağlayan matematiksel bir fonksiyondur.

İki tür olasılık fonksiyonu vardır:

-   Olasılık Kütle Fonksiyonları (PMF\'ler) ayrık rastgele değişkenleri
    temsil eder

-   Olasılık Yoğunluk Fonksiyonları (PDF\'ler) sürekli rastgele
    değişkenleri temsil eder

Bir olasılık fonksiyonu bir denklem veya grafik olarak gösterilebilir.
Olasılık fonksiyonlarında yer alan matematik bu dersin kapsamı
dışındadır. Şimdilik, bir PDF\'nin grafiğinin bir eğri olarak
göründüğünü bilmek önemlidir. Normal dağılım grafiğine atıfta bulunan
çan eğrisini öğrendiniz.

Örnek olarak, rastgele bir kiraz ağacı örneği hakkında verileriniz
olduğunu hayal edin. Kiraz ağaçlarının yüksekliklerinin ortalama 15 fit
ve 2 fit standart sapma ile yaklaşık olarak normal olarak dağıldığını
varsayalım.

`<img src="attachment:004b97dd-70ad-4f8a-abf9-21653b905c3e.png" width="500"/>`{=html}

Sürekli bir dağılımda, x ekseni ölçtüğünüz değişkenin değerini ifade
eder - bu durumda kiraz ağacı yüksekliği. Y ekseni olasılık yoğunluğunu
ifade eder. Olasılık yoğunluğunun olasılık ile aynı şey olmadığını
unutmayın.

Sürekli bir rastgele değişken için olasılık dağılımı size yalnızca
değişkenin bir değer aralığı veya aralığı alma olasılığını söyleyebilir.
Bunun nedeni, sürekli bir rastgele değişkenin sonsuz sayıda olası değere
sahip olabilmesidir. Örneğin, rastgele seçilen bir kiraz ağacının
yüksekliği 15 fit veya 15,1 fit veya 15.175 fit veya 15.175245 fit vb.
Ölçülebilir.

Rastgele seçilen bir kiraz ağacının yüksekliğinin tam olarak 15,1 fit
olma olasılığını bilmek istediğinizi varsayalım. Ağacın yüksekliği
belirli bir aralıkta herhangi bir ondalık değer olabileceğinden, ağacın
tam olarak herhangi bir tek değer olma olasılığı esasen sıfırdır.

Bu nedenle, sürekli dağılımlar için, yalnızca 14,5 fit ile 15,5 fit
arasındaki aralık gibi aralıkların olasılığı hakkında konuşmak
mantıklıdır.

Bir aralığın olasılığını bulmak için, aralığa karşılık gelen eğrinin
altındaki alanı hesaplarsınız. Örneğin, bir kiraz ağacının 14,5 fit ile
15,5 fit arasında bir yüksekliğe sahip olma olasılığı, x eksenindeki
14.5 ve 15.5 değerleri arasındaki eğrinin altındaki alana eşittir. Bu
alan grafiğin ortasındaki gölgeli dikdörtgen olarak görünür.

`<img src="attachment:322d6296-8cfd-4765-a686-501ba34e771e.png" width="500"/>`{=html}

Bu durumda, dikdörtgenin alanı 0.20 civarındadır. Dolayısıyla, rastgele
seçilen bir kiraz ağacının yüksekliğinin 14,5 fit ile 15, 5 fit arasında
olma ihtimali %20 vardır.

**Not:** veri uzmanları genellikle sürekli bir dağılımdaki olasılıkları
hesaplamak için istatistiksel yazılım kullanır.

#### **Normal dağılım**

Normal dağılım, ortalama ve çan şeklinde simetrik olan sürekli bir
olasılık dağılımıdır. Formülünü ilk tanımlayan Alman matematikçi Carl
Gauss\'tan sonra Gauss dağılımı olarak da bilinir. Normal dağılım
genellikle çan eğrisi olarak adlandırılır çünkü grafiği merkezde bir
tepe ve iki aşağı eğimli kenarı olan bir çan şeklindedir.

Normal dağılım, istatistikteki en yaygın olasılık dağılımıdır çünkü pek
çok farklı veri kümesi çan şeklinde bir eğri gösterir. Örneğin, 100
kişiyi rastgele örneklerseniz, boy, kilo, kan basıncı, ayakkabı boyutu,
test puanları ve daha fazlası gibi sürekli değişkenler için normal bir
dağılım eğrisi keşfedeceksiniz.

Tüm normal dağılımlar aşağıdaki özelliklere sahiptir:

-   Şekil bir çan eğrisidir

-   Ortalama eğrinin merkezinde bulunur

-   Eğri, ortalamanın her iki tarafında simetriktir

-   Eğrinin altındaki toplam alan 1\'e eşittir

Normal dağılımın özelliklerini netleştirmek için kiraz ağacı örneğimizi
kullanalım. Ortalama yüksekliğin 2 fit standart sapma ile 15 fit
olduğunu hatırlayın.

`<img src="attachment:cb648116-cf02-4026-8f25-57665f4d9ff5.png" width="500"/>`{=html}

Normal eğrinin aşağıdaki özelliklerini fark edebilirsiniz:

-   Ortalama eğrinin merkezinde bulunur ve aynı zamanda eğrinin
    zirvesidir. Ortalama 15 fit yükseklik, veri kümesindeki en olası
    sonucu temsil eder

-   Eğri ortalama hakkında simetriktir. Verilerin% 50\'si ortalamanın
    üzerindedir ve verilerin% 50\'si ortalamanın altındadır.

-   Bir nokta ortalamadan ne kadar uzaksa, bu sonuçların olasılığı o
    kadar düşük olur. Ortalamadan en uzak noktalar, veri kümesindeki en
    az olası sonuçları temsil eder. Bunlar kısa veya uzun, daha aşırı
    yüksekliklere sahip ağaçlardır

-   Eğrinin altındaki alan 1\'e eşittir. Bu, eğrinin altındaki alanın
    dağılımdaki olası sonuçların% 100\'ünü oluşturduğu anlamına gelir.

#### **Ampirik kural**

Normal bir eğrideki değerlerin ortalamaya olan mesafelerine bağlı olarak
düzenli bir düzende dağıldığını da fark edebilirsiniz. Bu **ampirik
kural olarak bilinir.** Kural, normal dağılıma sahip belirli bir veri
kümesi için şunu belirtir:

-   Değerlerin% 68\'i ortalamanın 1 standart sapması dahilinde

-   Değerlerin% 95\'i ortalamanın 2 standart sapması dahilinde

-   Değerlerin% 99,7\'si ortalamanın 3 standart sapması içine düşer

`<img src="attachment:d51642cc-0b50-4737-bcb5-06b972a96185.png" width="500"/>`{=html}

Ampirik kuralı kiraz ağacı örneğimize uygularsanız, aşağıdakileri
öğrenirsiniz:

-   Çoğu ağaç veya% 68, ortalama 15 fit yüksekliğin 1 standart sapmasına
    düşecektir. Bu, ağaçların% 68\'inin 13 fit ile 17 fit arasında veya
    ortalamanın 2 fit altında ve ortalamanın 2 fit üzerinde olacağı
    anlamına gelir.

-   Ağaçların %95\'i 11 fit ile 19 fit arasında veya ortalamadan 2
    standart sapma içinde ölçülecektir.

-   Hemen hemen tüm ağaçlar veya% 99.7, 9 fit ile 21 fit arasında veya
    ortalamanın 3 standart sapması içinde ölçülecektir.

Ampirik kural, büyük bir veri kümesindeki değerlerin nasıl dağıtıldığına
dair hızlı bir tahmin verebilir. Bu zaman kazandırır ve verilerinizi
daha iyi anlamanıza yardımcı olur.

Değerlerinizin normal dağılımdaki konumunu bilmek, aykırı değerleri
tespit etmek için de yararlıdır. Bir aykırı değerin, verilerin geri
kalanından önemli ölçüde farklı bir değer olduğunu hatırlayın. Tipik
olarak, veri uzmanları, ortalamanın altında veya üzerinde 3\'ten fazla
standart sapma bulunan değerleri aykırı değerler olarak kabul eder. Bazı
aşırı değerler veri toplama veya veri işlemedeki hatalardan
kaynaklanabileceğinden ve bu yanlış değerler sonuçlarınızı
çarpıtabileceğinden, aykırı değerleri belirlemek önemlidir.

#### Önemli çıkarımlar {#önemli-çıkarımlar}

Bir veri uzmanı olarak, çok çeşitli veri kümelerinde önemli kalıpları
belirlemek için muhtemelen normal dağılımı kullanacaksınız. Normal
dağılımı anlamak, daha sonra öğreneceğiniz hipotez testi ve regresyon
analizi gibi daha gelişmiş istatistiksel yöntemler için de önemlidir.

#### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Sürekli olasılık dağılımları ve normal dağılım hakkında daha fazla bilgi
edinmek için aşağıdaki kaynaklara göz atın:

-   [Duke Üniversitesi\'nden bu makale, normal dağılımın temel
    özelliklerinin yararlı bir özetini
    sunmaktadır](https://sites.nicholas.duke.edu/statsreview/continuous-probability-distributions/)
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Standart Sapma ve Alt-Üst Limit Hesabı
:::

::: {.cell .markdown}
``` python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import stats
import statsmodels.api as sm

education_districtwise['OVERALL_LI'].hist()
```

`<img src="attachment:187b222a-48aa-4b08-aa72-25b3f201dd5b.png" width="500"/>`{=html}

``` python
mean_overall_li = education_districtwise['OVERALL_LI'].mean() 

mean_overall_li
73.39518927444797

std_overall_li = education_districtwise['OVERALL_LI'].std()

std_overall_li
10.098460413782469

upper_limit = mean_overall_li + 1 * std_overall_li 
lower_limit = mean_overall_li + 1 * std_overall_li 

(education_districtwise['OVERALL_LI'] >= lower_limit) & (education_districtwise['OVERALL_LI'] <= upper_limit)).mean()
0.6640378548895899

upper_limit = mean_overall_li + 2 * std_overall_li 
lower_limit = mean_overall_li + 2 * std_overall_li 

((education_districtwise['OVERALL_LI'] >= lower_limit) & (education_districtwise['OVERALL_LI'] <= upper_limit)).mean()
0.9542586750788643

upper_limit = mean_overall_li + 3 * std_overall_li 
lower_limit = mean_overall_li + 3 * std_overall_li 

((education_districtwise['OVERALL_LI'] >= lower_limit) & (education_districtwise['OVERALL_LI'] <= upper_limit)).mean()
0.996845425867507
```

Ampirik kural ile uyumlu olduğu için verilerin normal dağılım yaptığı
söylenebilir.

`<img src="attachment:f19d1d92-5f66-4809-b85e-9ea7108b240a.png" width="500"/>`{=html}

``` python
education_districtwise['Z_SCORE'] = stats.zscore(education_districtwise ['OVERALL_LI']) 
education_districtwise

education_districtwise[(education_districtwise['Z_SCORE'] > 3) | (education_districtwise ['Z_SCORE'] < -3)]
```

`<img src="attachment:50d17486-0aaf-42f2-aad2-7c6dfda540d0.png" width="800"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Örneklem ve popülasyon arasındaki ilişki
:::

::: {.cell .markdown}
Daha önce, çıkarımsal **istatistiklerin sonuç çıkarmak** veya daha büyük
bir popülasyon hakkında tahminlerde bulunmak için örnek verileri
kullandığını öğrendiniz. Veri uzmanları, verileri hakkında değerli
bilgiler edinmek için çıkarımsal istatistikleri kullanır.

Bu okumada, örneklem ve popülasyon arasındaki ilişkiyi daha ayrıntılı
olarak öğreneceksiniz. Ayrıca veri profesyonellerinin veri çalışmasında
örneklemeyi nasıl kullandığını ve popülasyonu temsil eden bir örnekle
çalışmanın önemini tartışacağız.

### Nüfus ve Örnek

#### **Nüfus ve örnek**

İstatistiklerde, bir pop **ülas** yon, ölçmek istediğiniz her olası
öğeyi veya hakkında sonuç çıkarmak istediğiniz tüm veri kümesini içerir.
İstatistiksel bir popülasyon, aşağıdakiler de dahil olmak üzere her tür
veriye atıfta bulunabilir:

-   İnsanlar

-   Kuruluşlar

-   Nesneler

-   Olaylar

-   Ve daha fazlası

Örneğin, bir popülasyon aşağıdakiler kümesi olabilir:

-   Bir üniversitedeki tüm öğrenciler

-   Şimdiye kadar bir şirket tarafından üretilen tüm cep telefonları

-   Yeryüzündeki tüm ormanlar

**Örnek, bir popülasyonun bir alt kümesidir.**

Yukarıdaki popülasyonlardan alınan örnekler şunlar olabilir:

-   Üniversitedeki matematik bölümleri

-   Şirket tarafından geçen hafta üretilen cep telefonları

-   Kanada\'daki ormanlar

Veri uzmanları, popülasyonlar hakkında çıkarımlar yapmak için örnekler
kullanır. Başka bir deyişle, nüfusun küçük bir bölümünden topladıkları
verileri bir bütün olarak nüfus hakkında sonuçlar çıkarmak için
kullanırlar.

`<img src="attachment:b12573e5-8c4a-46ca-af57-de919c3a8b01.png" width="500"/>`{=html}

#### **Örnekleme**

**Örnekleme**, bir popülasyondan bir veri alt kümesi seçme işlemidir.

Uygulamada, tüm popülasyonun her üyesi veya unsuru hakkında veri
toplamak genellikle zordur. Bir nüfus çok büyük olabilir, coğrafi olarak
dağılmış veya başka bir şekilde erişilmesi zor olabilir. Bunun yerine,
bir bütün olarak popülasyon hakkında sonuç çıkarmak, tahminler yapmak
veya hipotezleri test etmek için örnek verileri kullanabilirsiniz.

Veri uzmanları örneklemeyi kullanır çünkü:

-   Boyut, karmaşıklık veya erişilebilirlik eksikliği nedeniyle tüm
    nüfus hakkında veri toplamak genellikle imkansız veya pratik
    değildir.

-   Bir örnekten veri toplamak daha kolay, daha hızlı ve daha verimli

-   Örnek kullanmak para ve kaynak tasarrufu sağlar

-   Daha küçük veri kümelerini depolamak, düzenlemek ve analiz etmek
    genellikle son derece büyük veri kümeleriyle uğraşmaktan daha kolay,
    daha hızlı ve daha güvenilirdir

##### Örnek: seçim anketi

Hindistan, Endonezya, Amerika Birleşik Devletleri veya Brezilya gibi
büyük nüfusa sahip bir ülkede çalışan bir veri uzmanı olduğunuzu hayal
edin. Yaklaşan bir ulusal cumhurbaşkanı seçimi var. Hangi aday
seçmenlerin tercih ettiğini görmek için bir seçim anketi yapmak
istiyorsunuz. Diyelim ki uygun seçmenlerin nüfusu 100 milyon kişidir.
100 milyon insanı oy kullanma tercihleri konusunda anket yapmak, tüm
seçmenleri bulmanın ve iletişim kurmanın mümkün olacağını ve tüm
seçmenlerin katılmaya istekli olacağını varsayarsak bile, çok fazla
zaman, para ve kaynak gerektirecektir.

Bununla birlikte, tüm seçmenlerin daha büyük nüfusundan alınan 100 veya
1000 seçmenden oluşan bir örneği araştırmak gerçekçidir. Büyük bir
popülasyonla uğraşırken, örnekleme, bir bütün olarak popülasyon hakkında
geçerli çıkarımlar yapmanıza yardımcı olabilir.

`<img src="attachment:74c22a71-c4ec-4cd5-9446-17d528c7129b.png" width="500"/>`{=html}

#### **Temsili örnek**

Bir popülasyon hakkında geçerli çıkarımlar veya doğru tahminler yapmak
için, örneklemeniz popülasyonu bir bütün olarak temsil etmelidir.
Temsili bir **örneklemin bir pop** ülasyonun özelliklerini doğru bir
şekilde yansıttığını hatırlayın. Nüfusunuz hakkında yaptığınız
çıkarımlar ve tahminler, örnek verilerinize dayanmaktadır. Örneklemeniz
popülasyonunuzu doğru bir şekilde yansıtmıyorsa, çıkarımlarınız
güvenilir olmayacak ve tahminleriniz doğru olmayacaktır. Bu da paydaşlar
ve kuruluşlar için olumsuz sonuçlara yol açabilir.

Olasılık örneklemesi gibi istatistiksel yöntemler, bir popülasyon
içindeki çeşitli gruplardan rastgele örnekler toplayarak örneklemenizin
temsili olmasını sağlamaya yardımcı olur. Bu yöntemler örnekleme
yanlılığını azaltmaya ve sonuçlarınızın geçerliliğini artırmaya yardımcı
olur. Daha sonra örnekleme yöntemleri hakkında daha fazla bilgi
edineceksiniz.

##### Örnek: seçim anketi

İdeal olarak, seçim anketinizin örneği, genel seçmen nüfusunun
özelliklerini doğru bir şekilde yansıtacaktır. Büyük bir ülkedeki seçmen
nüfusu siyasi bakış açıları, coğrafi konum, yaş, cinsiyet, ırk, eğitim
düzeyi, sosyoekonomik durum vb. bakımından farklılık gösterecektir.
Yalnızca belirli gruplara ait kişilerden veri toplarsanız, diğerlerinden
değil, yalnızca belirli gruplara ait kişilerden veri toplarsanız
örneklemeniz temsili olmayacaktır. Örneğin, bir siyasi partiden veya
ileri dereceye sahip veya 70 yaşından büyük kişilerle anket yaparsanız.
Temsili olmayan bir örneğe dayalı bir seçim anketinin sonuçları doğru
olmayacaktır. Genel olarak, herhangi bir popülasyon hakkında yaptığınız
herhangi bir iddia veya çıkarım, temsili bir örneğe dayanıyorsa daha
fazla geçerliliğe sahip olacaktır.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Veri uzmanları, karmaşık veri kümelerini modelleyebilen ve değerli
içgörüler oluşturmaya yardımcı olabilecek güçlü istatistiksel araçlarla
çalışır. Ancak, üzerinde çalıştığınız örnek veriler popülasyonunuzu
doğru bir şekilde yansıtmıyorsa - yani, örneğiniz temsili değilse -
modelinizin ne kadar iyi olduğu önemli değildir. Tahmin modeliniz kötü
bir örneğe dayanıyorsa, tahminleriniz doğru olmayacaktır.

Sonuç olarak, numunenizin kalitesi, paydaşlarla paylaştığınız
içgörülerin kalitesini belirlemeye yardımcı olur. Bir popülasyon
hakkında güvenilir çıkarımlar yapmak için, örneklemenizin popülasyonu
temsil ettiğinden emin olun.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Örnekleme sürecinin aşamaları  {#örnekleme-sürecinin-aşamaları-}
:::

::: {.cell .markdown}
Son zamanlarda, örneklemeyi öğreniyorsunuz. Bir veri uzmanı olarak, her
zaman örnek verilerle çalışacaksınız. Genellikle, bu daha önce diğer
araştırmacılar tarafından toplanan örnek veriler olacaktır; bazen,
ekibiniz kendi verilerini toplayabilir. Her iki durumda da, örnekleme
sürecinin nasıl çalıştığını bilmek önemlidir, çünkü örneğinizin
popülasyonu temsil edip etmediğini ve örneğinizin tarafsız olup
olmadığını belirlemeye yardımcı olur.

Bu okumada, örnekleme sürecinin ana aşamalarını daha ayrıntılı olarak
gözden geçireceğiz. Bu, örnekleme sürecinin nasıl çalıştığını ve sürecin
her adımının örnek verilerinizi nasıl etkileyebileceğini daha iyi
anlamanızı sağlayacaktır..

### Örnekleme süreci

İlk olarak, örnekleme sürecinin ana adımlarını gözden geçirelim:

1.  Hedef popülasyonu belirleyin

2.  Örnekleme çerçevesini seçin

3.  Örnekleme yöntemini seçin

4.  Örnek boyutunu belirleyin

5.  Örnek verileri toplayın

Her adımı bir örnekle daha ayrıntılı olarak inceleyelim. Ev aletleri
üreten bir şirket için çalışan bir veri uzmanı olduğunuzu hayal edin.
Şirket, müşterilerin en yeni buzdolabı modellerindeki yenilikçi dijital
özellikler hakkında ne düşündüklerini öğrenmek istiyor. Buzdolabı iki
yıldır piyasada ve 10.000 kişi satın aldı. Yöneticiniz sizden bir
müşteri memnuniyeti anketi yapmanızı ve sonuçları paydaşlarla
paylaşmanızı ister.

#### **Adım 1: Hedef popülasyonu belirleyin**

Örnekleme sürecindeki ilk adım, hedef popülasyonunuzu tanımlamaktır. He
**def popülas** yon, hakkında daha fazla bilgi edinmek istediğiniz tüm
öğeler kümesidir. Araştırmanızın bağlamına bağlı olarak, popülasyonunuz
bireyleri, kuruluşları, nesneleri, olayları veya araştırmak istediğiniz
diğer verileri içerebilir.

İyi tanımlanmış bir popülasyon, araştırmanızın tam kapsamına uymayan
katılımcıları dahil etme olasılığını azaltır. Örneğin, şirketin tüm
müşterilerini veya şirketin diğer buzdolabı modellerini satın alan
müşterileri dahil etmek istemezsiniz.

Bu durumda hedef kitleniz şirketin en yeni buzdolabı modelini satın alan
10.000 müşteri olacaktır. Bunlar, en yeni modelle ilgili deneyimleri
hakkında bilgi edinmek için anket yapmak istediğiniz müşterilerdir.

`<img src="attachment:53be9d2c-1a1e-4cc0-ba15-8f2985c67533.png" width="500"/>`{=html}

#### **Adım 2: Örnekleme çerçevesini seçin**

Örnekleme işlemindeki bir sonraki adım, bir örnekleme çerçevesi
oluşturmaktır. Örne **kleme çerçevesi**, hedef popülasyonunuzdaki tüm
bireylerin veya öğelerin bir listesidir.

Hedef popülasyon ile örnekleme çerçevesi arasındaki fark, popülasyonun
genel ve çerçevenin spesifik olmasıdır. Yani, hedef popülasyonunuz
buzdolabını satın alan tüm müşteriler ise, örnekleme çerçeveniz tüm bu
müşterilerin adlarının alfabetik bir listesi olabilir. Örneğinizdeki
müşteriler bu listeden seçilecektir.

İdeal olarak, örnekleme çerçeveniz tüm hedef popülasyonu içermelidir.
Bununla birlikte, pratik nedenlerden dolayı, örnekleme çerçeveniz hedef
popülasyonunuzla tam olarak eşleşmeyebilir, çünkü popülasyonun her
üyesine erişiminiz olmayabilir. Örneğin, şirketin müşteri veritabanı
eksik olabilir veya veri işleme hataları içerebilir. Veya, bazı
müşteriler satın aldıklarından bu yana iletişim bilgilerini değiştirmiş
olabilir ve onları bulamayabilir veya onlarla iletişim
kuramayabilirsiniz. Ayrıca, bazen örnekleme çerçevesi, hedef
popülasyonun dışındaki unsurları sadece tesadüfen veya hedef popülasyonu
kesin olarak bilmek imkansız olduğu için içerebilir.

`<img src="attachment:5a359d78-036b-468f-bc94-b604b50ccc91.png" width="500"/>`{=html}

Bu nedenle, genellikle örnekleme çerçeveniz hedef *popülasyonunuzun
erişilebilir* kısmıdır, ancak bazen bu kümenin dışında öğeler
içerecektir.

#### **Adım 3: Örnekleme yöntemini seçin**

Örnekleme sürecindeki üçüncü adım, bir örnekleme yöntemi seçmektir.

İki ana örnekleme yöntemi türü vardır: olasılık örneklemesi ve **olas**
ılık **dışı örnekleme**. Daha sonra, belirli yöntemleri daha ayrıntılı
olarak inceleyeceğiz. Şimdilik, olasılık örneklemesinin [bir örnek
oluşturmak için rastgele seçim kullandığını
bilin](https://www.statisticshowto.com/sample/). Olasılıksız örnekleme,
rastgele seçimden ziyade genellikle rahatlığa veya araştırmacının
kişisel tercihlerine dayanır. Genellikle, olasılık örnekleme yöntemleri,
olasılık dışı örnekleme yöntemlerinden daha fazla zaman ve kaynak
gerektirir.

İdeal olarak, örneğiniz popülasyonu temsil edecektir. Numunenizin
temsili olmasını sağlamanın bir yolu, doğru örnekleme yöntemini
seçmektir. Olasılık örnekleme yöntemleri rastgele seçime dayandığından,
popülasyondaki her öğenin örneğe dahil edilme şansı eşittir. Bu size
temsili bir örnek almak için en iyi şansı verir, çünkü sonuçlarınızın
genel popülasyonu doğru bir şekilde yansıtması daha olasıdır.

Bu nedenle, bütçeniz, kaynaklarınız ve zamanınız olduğunu varsayarsak,
anketiniz için bir olasılık örnekleme yöntemi kullanmalısınız.

#### **Adım 4: Örnek boyutunu belirleyin**

Örnekleme sürecinin dördüncü adımı, örneklemeniz için en iyi boyutu
belirlemektir, çünkü örnekleme çerçevenizdeki herkesi araştıracak
kaynaklara sahip değilsiniz. İstatistikte, örneklem büyüklüğü, bir
çalışma veya deney için seçilen bireylerin veya öğelerin sayısını ifade
eder.

Örneklem büyüklüğü, popülasyon hakkında yaptığınız tahminlerin
kesinliğini belirlemeye yardımcı olur. Genel olarak, örneklem boyutu ne
kadar büyükse, tahminleriniz o kadar kesin olur. Bununla birlikte, daha
büyük örneklerin kullanılması tipik olarak daha fazla kaynak gerektirir.

Seçtiğiniz örneklem büyüklüğü, örnekleme yöntemi, hedef popülasyonun
büyüklüğü ve karmaşıklığı, kaynaklarınızın sınırları, zaman çizelgeniz
ve araştırmanızın amacı dahil olmak üzere çeşitli faktörlere bağlıdır.

Bu faktörlere dayanarak, numunenize kaç müşterinin dahil edileceğine
karar verebilirsiniz.

#### **Adım 5: Örnek verileri toplayın**

Şimdi, örnekleme sürecinin son adımı olan örnek verilerinizi toplamaya
hazırsınız.

Numuneniz için seçilen müşterilere müşteri memnuniyeti anketi
verirsiniz. Anket yanıtları, müşterilerin buzdolabının dijital
özellikleri hakkında ne düşündükleri hakkında faydalı veriler sağlar.
Ardından, bu buzdolabının gelecekteki sürümleri için bu özelliklere
yatırım yapmaya devam edip etmeyecekleri konusunda daha bilinçli
kararlar almalarına yardımcı olmak için sonuçlarınızı paydaşlarla
paylaşırsınız ve diğer modeller için benzer özellikler geliştirirsiniz.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Etkili örnekleme, örnek verilerinizin popülasyonunuzu temsil etmesini
sağlar. Ardından, popülasyon hakkında çıkarımlar yapmak için örnek
verileri kullandığınızda, çıkarımlarınızın güvenilir olduğundan makul
ölçüde emin olabilirsiniz.

Örnekleme işleminin her adımında verdiğiniz kararlar, örnek
verilerinizin kalitesini etkileyebilir. İster diğer araştırmacılar
tarafından toplanan verileri analiz ediyor olun, ister kendi başınıza
bir anket yapıyor olun, örnekleme sürecini anlamak sizi daha iyi bir
veri uzmanı haline getirecektir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Olasılık örnekleme yöntemleri
:::

::: {.cell .markdown}
Daha önce, iki ana örnekleme yöntemi türü olduğunu öğrendiniz: olasılık
örneklemesi ve olasılık dışı örnekleme. **Olasılık örne** klemesi, bir
[örnek](https://www.statisticshowto.com/sample/) oluşturmak için
rastgele seçimi kullanır. **Olasılıksız örnekleme**, rastgele seçimden
ziyade genellikle rahatlığa veya araştırmacının kişisel tercihlerine
dayanır. Kullandığınız örnekleme yöntemi, örneğinizin popülasyonunuzu
temsil edip etmediğini ve örneğinizin önyargılı olup olmadığını
belirlemeye yardımcı olur. Olasılık örneklemesi, popülasyonu temsil eden
bir örnek oluşturmak için size en iyi şansı verir.

Bu okumada, farklı olasılık örneklemesi yöntemleri ve her yöntemin
yararları ve dezavantajları hakkında daha fazla bilgi edineceksiniz.

### Olasılık Örnekleme Yöntemleri {#olasılık-örnekleme-yöntemleri}

Dört farklı olasılık örnekleme yöntemi vardır:

-   Basit rastgele örnekleme

-   Tabakalı rastgele örnekleme

-   Küme rastgele örnekleme

-   Sistematik rastgele örnekleme

Her yöntemi daha ayrıntılı olarak inceleyelim.

#### **Basit rastgele örnekleme**

**Basit bir rastgele örneklem** de, bir popülasyonun her üyesi rastgele
seçilir ve seçilme şansı eşittir. Üyeleri rastgele bir sayı üreteci
kullanarak veya başka bir rastgele seçim yöntemiyle seçebilirsiniz.

`<img src="attachment:517bd445-e87d-4538-98e8-54347412b64c.png" width="500"/>`{=html}

Örneğin, bir şirketin çalışanlarını iş deneyimleri hakkında anket yapmak
istediğinizi hayal edin. Şirket 10.000 kişiyi istihdamaktadır. Şirket
veritabanındaki her çalışana 1 ila 10.000 arasında bir sayı atayabilir
ve ardından örneğiniz için 100 kişi seçmek için rastgele bir sayı
üreteci kullanabilirsiniz. Bu senaryoda, çalışanların her birinin örnek
için seçilme şansı eşittir.

Basit rastgele örneklerin temel yararı, popülasyonun her üyesinin
seçilme şansı eşit olduğundan, genellikle oldukça temsili olmalarıdır.
Rastgele örnekler önyargıdan kaçınma eğilimindedir ve bunun gibi
anketler size daha güvenilir sonuçlar verir.

Bununla birlikte, pratikte, büyük basit rastgele örnekleri toplamak
genellikle pahalı ve zaman alıcıdır. Örneklem büyüklüğünüz yeterince
büyük değilse, popülasyondaki belirli bir grup insan örnekleminizde
yeterince temsil edilmeyebilir. Daha büyük bir örneklem boyutu
kullanırsanız, örneklemeniz popülasyonu daha doğru yansıtacaktır.

#### **Tabakalı rastgele örnekleme**

Tab **akalanmış rastgele bir örneklem** de, bir popülasyonu gruplara
bölersiniz ve örneklemde yer alacak her gruptan rastgele bazı üyeleri
seçersiniz. Bu gruplara katmanlar denir. Katmanlar yaş, cinsiyet, gelir
veya okumak istediğiniz kategoriye göre düzenlenebilir.

`<img src="attachment:61118c66-b078-4992-b1bb-4f0cd19b0eeb.png" width="500"/>`{=html}

Örneğin, yeni bir ürün için pazar araştırması yaptığınızı ve farklı yaş
gruplarındaki tüketicilerin tercihlerini analiz etmek istediğinizi hayal
edin. Hedef popülasyonunuzu yaşa göre katmanlara ayırabilirsiniz: 20-29,
30-39, 40-49, 50-59 vb. Daha sonra, her yaş grubundan eşit sayıda kişiye
anket yapabilir ve her yaş grubunun tüketici tercihleri hakkında
sonuçlar çıkarabilirsiniz. Sonuçlarınız, pazarlamacıların yeni ürün için
satışları optimize etmek için hangi yaş gruplarına odaklanacaklarına
karar vermelerine yardımcı olacaktır.

Tabakalı rastgele örnekler, popülasyondaki her gruptan üyelerin ankete
dahil edilmesini sağlamaya yardımcı olur. Bu yöntem, yeterince temsil
edilmeyen gruplar için eşit temsil sağlamaya yardımcı olur ve
katmanların her biri hakkında daha kesin sonuçlar çıkarmanıza olanak
tanır. 21 yaşındaki ve 51 yaşındaki birinin satın alma alışkanlıklarında
önemli farklılıklar olabilir. Tabakalı örnekleme, her iki perspektifin
de örnekte yakalanmasını sağlamaya yardımcı olur.

Tabakalı örneklemenin ana dezavantajlarından biri, bir popülasyon
hakkında bilgi sahibi değilseniz, bir çalışma için uygun katmanları
belirlemenin zor olabilmesidir. Örneğin, bir nüfus arasında medyan
geliri incelemek istiyorsanız, örneğinizi iş türüne, sektöre, konuma
veya eğitim düzeyine göre sınıflandırmak isteyebilirsiniz. Bu
kategorilerin medyan gelirle ne kadar alakalı olduğunu bilmiyorsanız,
çalışmanız için en iyisini seçmek zor olacaktır.

#### **Küme rastgele örnekleme**

Bir **küme rastgele örneği yürütürken**, bir popülasyonu kümelere böler,
belirli kümeleri rastgele seçer ve seçilen kümelerden tüm üyeleri örneğe
dahil edersiniz.

Küme örneklemesi tabakalı rastgele örneklemeye benzer, ancak tabakalı
örneklemede, örneklemde olmak için her gruptan rastgele *bazı* üyeleri
seçersiniz. Küme örneklemesinde, örnekte yer alacak gruptaki *tüm*
üyeleri seçersiniz. Kümeler yaş, cinsiyet, konum veya çalışmak
istediğiniz herhangi bir şey gibi tanımlayıcı ayrıntılar kullanılarak
bölünür.

`<img src="attachment:c85ba0b0-9f7d-4f05-9125-669a848f79a3.png" width="500"/>`{=html}

Örneğin, küme örneklemesini kullanarak küresel bir restoran
franchise\'da çalışan memnuniyeti anketi yapmak istediğinizi düşünün.
Franchise dünya çapında 40 restorana sahiptir. Her restoran, benzer iş
rollerinde yaklaşık aynı sayıda çalışana sahiptir. Kümeler olarak
rastgele 4 restoran seçersiniz. Numunenize 4 restorandaki tüm
çalışanları dahil edersiniz.

Bu yöntemin bir avantajı, bir küme örneğinin belirli bir kümeden her
üyeyi almasıdır; bu, her küme popülasyonu bir bütün olarak yansıttığında
yararlıdır. Bu yöntem, açıkça tanımlanmış alt gruplara sahip büyük ve
çeşitli popülasyonlarla uğraşırken faydalıdır. Araştırmacılar Auckland,
Yeni Zelanda\'nın banliyölerinde ev sahipliği hakkında daha fazla bilgi
edinmek istiyorlarsa, şehirdeki tüm banliyölerin temsili bir örneği
olarak iyi seçilmiş birkaç banliyöyü kullanabilirler.

Küme örneklemesinin ana dezavantajı, genel popülasyonu doğru bir şekilde
yansıtan kümeler oluşturmanın zor olabileceğidir. Örneğin, pratik
nedenlerle, İngiltere\'deki restoranlara yalnızca franchise\'ın dünyanın
her yerinde konumları olduğunda erişebilirsiniz. İngiltere\'deki
çalışanlar diğer ülkelerdeki çalışanlardan farklı özelliklere ve
değerlere sahip olabilir.

#### **Sistematik rastgele örnekleme**

Sistem **atik bir rastgele örneklem** de, bir popülasyonun her üyesini
sıralı bir diziye koyarsınız. Ardından, dizide rastgele bir başlangıç
noktası seçersiniz ve düzenli aralıklarla numuneniz için üyeler
seçersiniz.

`<img src="attachment:cd11231e-b6d3-4cbb-834f-4e2f73248112.png" width="500"/>`{=html}

Bir lisedeki öğrencilere çalışma alışkanlıkları hakkında araştırma
yapmak istediğinizi hayal edin. Sistematik bir rastgele örnek için,
öğrencilerin adlarını alfabetik sıraya koyar ve rastgele bir başlangıç
noktası seçersiniz: diyelim ki, sayı 4. 4 numaradan başlayarak, 100
öğrenciden oluşan bir örneğe sahip olana kadar listedeki her 10. ismi
(4, 14, 24, 34,\...) seçersiniz.

Sistematik rastgele örneklerin bir avantajı, her üyenin örneğe dahil
edilme şansı eşit olduğundan, genellikle popülasyonu temsil etmeleridir.
Öğrencinin soyadının L veya Q ile başlayıp başlaması özelliklerini
etkilemeyecektir. Nüfusunuzun üyelerinin tam bir listesine sahip
olduğunuzda sistematik örnekleme de hızlı ve kullanışlıdır.

Sistematik örneklemenin bir dezavantajı, başlamadan önce incelemek
istediğiniz popülasyonun büyüklüğünü bilmeniz gerektiğidir. Bu bilgilere
sahip değilseniz, tutarlı aralıklar seçmek zordur. Ayrıca, dizide gizli
bir desen varsa, temsili bir örnek alamayabilirsiniz. Örneğin,
listenizdeki her 10. isim bir onur öğrencisiyse, *tüm* öğrencilerin
değil, yalnızca onur öğrencilerinin çalışma alışkanlıkları hakkında geri
bildirim alabilirsiniz.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Ele aldığımız dört olasılık örneklemesi yönteminin (basit, tabakalı,
küme ve sistematik) tümü, çoğu veri uzmanı için tercih edilen örnekleme
yöntemi olan rastgele seçime dayanmaktadır. Olasılık örnekleme
yöntemleri, bir bütün olarak popülasyonu temsil eden bir örnek
oluşturmak için size en iyi şansı verir. Temsili bir örnekle çalışmak,
araştırdığınız popülasyon hakkında güvenilir çıkarımlar ve doğru
tahminler yapmanıza olanak tanır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Olasılıksız örnekleme yöntemleri
:::

::: {.cell .markdown}
Son zamanlarda, olasılık örnekleme yöntemlerinin rastgele seçim
kullandığını ve bu da örnekleme yanlılığını önlemeye yardımcı olduğunu
öğrendiniz. Rastgele seçilen bir örnek, popülasyonun tüm üyelerinin
dahil edilme şansının eşit olduğu anlamına gelir. Buna karşılık,
olasılık dışı örnekleme yöntemleri rastgele seçim kullanmazlar, bu
nedenle tipik olarak temsili örnekler oluşturmazlar. Aslında, olasılık
dışı yöntemler genellikle önyargılı örneklerle sonuçlanır. **Örnekleme
yanl** ılığı, popülasyonun bazı üyelerinin seçilme olasılığı diğer
üyelere göre daha yüksek olduğunda ortaya çıkar.

Bu okumada, olasılıksız örneklemenin dört yöntemi hakkında daha fazla
bilgi edinecek ve örnekleme yanlılığının her yöntemi nasıl
etkileyebileceğini öğreneceksiniz. Olasılıksız örneklemenin belirli
durumlarda neden yararlı olabileceğini de tartışacağız.

### Olasılıksız örnekleme yöntemleri {#olasılıksız-örnekleme-yöntemleri}

Olasılık dışı örnekler rastgele olmayan seçim yöntemlerini kullanır, bu
nedenle bir popülasyonun tüm üyelerinin seçilme şansı eşit değildir. Bu
nedenle olasılık dışı yöntemlerin örnekleme yanlılığı riski yüksektir.
Bununla birlikte, olasılık dışı yöntemler genellikle daha ucuzdur ve
araştırmacıların yürütmesi için daha uygundur. Bazen sınırlı zaman, para
veya diğer kaynaklar nedeniyle olasılık örneklemesini kullanmak mümkün
değildir. Ayrıca, olasılık dışı yöntemler, bir bütün olarak popülasyon
hakkında çıkarımlar yapmak yerine, bir popülasyonun ilk anlayışını
geliştirmeye çalışan keşif çalışmaları için yararlı olabilir.

Olasılıksız örneklemenin dört yöntemini gözden geçireceğiz:

-   Kolay örnekleme

-   Gönüllü yanıt örneklemesi

-   Kartopu örneklemesi

-   Amaçlı örnekleme

Her yöntemi daha ayrıntılı olarak inceleyelim.

#### **Kolay örnekleme**

Kolay örnekleme için, iletişim kurması veya ulaşılması kolay bir
popülasyonun üyelerini seçersiniz. Adından da anlaşılacağı gibi, uygun
bir örnek yapmak, işyeriniz, yerel bir okul veya halka açık bir park
gibi size uygun bir yerden örnek toplamayı içerir.

Örneğin, bir kamuoyu anketi yapmak için, bir araştırmacı gün boyunca bir
alışveriş merkezinin girişinde durabilir ve yanından geçen kişileri
anket yapabilir.

`<img src="attachment:04f5141a-dda6-436e-aeed-12aeb9e95669.png" width="500"/>`{=html}

Bu örnekler, popülasyonun daha geniş bir örneklemine değil,
araştırmacının rahatlığına dayandığından, uygun örnekler genellikle
yetersiz kapsama yanlılığından muzdariptir. Yetersiz kapsama yanlılığı,
bir popülasyonun bazı üyeleri örneklemde yetersiz temsil edildiğinde
ortaya çıkar. Örneğin, yukarıdaki örnek, alışveriş merkezlerinde
alışveriş yapmayı sevmeyen veya farklı bir alışveriş merkezinde
alışveriş yapmayı tercih eden veya ulaşım eksikliği olduğu için
alışveriş merkezini ziyaret etmeyen kişileri yeterince temsil edecektir.

Kolay örnekleme genellikle hızlı ve ucuzdur, ancak temsili bir örnek
almanın güvenilir bir yolu değildir.

#### **Gönüllü yanıt örneklemesi**

Gönüllü bir yanıt örneği, bir çalışmaya katılmak için gönüllü olan bir
popülasyonun üyelerinden oluşur. Uygun bir örnek gibi, gönüllü bir yanıt
örneği genellikle bir popülasyona uygun erişime dayanır. Ancak,
araştırmacının katılımcıları seçmesi yerine, katılımcılar kendi
başlarına gönüllü olurlar.

Örneğin, üniversite yöneticilerinin öğrencilerin kampüste servis edilen
yemekler hakkında ne düşündüklerini bilmek istediklerini varsayalım.
Öğrencilere yemeğin kalitesiyle ilgili çevrimiçi bir anketin
bağlantısını e-posta ile gönderirler ve öğrencilerden zamanları varsa
anketi doldurmalarını isterler.

`<img src="attachment:9946dfc7-170b-444e-bc64-f058d69017ce.png" width="500"/>`{=html}

Gönüllü yanıt örnekleri, belirli insan gruplarının yanıt verme
olasılığının daha düşük olduğunda ortaya çıkan yanıt dışı önyargıdan
muzdarip olma eğilimindedir. Gönüllü olarak yanıt veren insanlar
muhtemelen nüfusun geri kalanından olumlu veya olumsuz daha güçlü
görüşlere sahip olacaklardır. Bu durumda, yalnızca yiyecekleri gerçekten
seven veya gerçekten sevmeyen öğrenciler anketi doldurmak için motive
olabilir. Anket, yiyecek hakkında daha hafif görüşlere sahip olan veya
tarafsız olan birçok öğrenciyi ihmal edebilir. Bu, gönüllü öğrencileri
genel öğrenci popülasyonunu temsil etmez hale getirir.

#### **Kartopu örneklemesi**

Bir kartopu örneğinde, araştırmacılar ilk katılımcıları bir çalışmaya
dahil etmek için işe alır ve daha sonra çalışmaya katılmaları için diğer
insanları işe almalarını ister. Bir kartopu gibi, daha fazla katılımcı
katıldıkça örneklem büyüklüğü gittikçe büyür. Araştırmacılar, incelemek
istedikleri popülasyona erişmek zor olduğunda genellikle kartopu
örneklemesini kullanırlar.

Örneğin, bir araştırmacının nadir görülen bir tıbbi durumu olan
insanları incelediğini hayal edin. Gizlilik nedeniyle, araştırmacının bu
nüfusun üyeleri için hastanelerden veya diğer resmi kaynaklardan
iletişim bilgilerini alması zor olabilir. Bununla birlikte, araştırmacı
katılmaya istekli birkaç kişi bulabilirse, bu iki kişi aynı duruma sahip
başkalarını tanıyabilir. İlk katılımcılar daha sonra çalışmanın
potansiyel faydalarını paylaşarak başkalarını işe alabilirler.

`<img src="attachment:9d13dcda-423f-49c6-8af3-5bf394188cca.png" width="500"/>`{=html}

The first illustration shows two researchers sharing information with
two people. The second illustration shows those same researchers
standing near four people sharing information.

Kartopu örneklemesi çok zaman alabilir ve araştırmacılar, işe alım
sürecine başarılı bir şekilde devam etmek ve "kartopu" oluşturmak için
katılımcılara güvenmelidir. Bu tür işe alım, örnekleme yanlılığına da
yol açabilir. İlk katılımcılar kendi başlarına ek katılımcıları işe
aldıklarından, çoğunun benzer özellikleri paylaşması muhtemeldir ve bu
özellikler incelenen toplam popülasyonu temsil etmeyebilir.

#### **Amaçlı örnekleme**

Amaçlı örneklemede, araştırmacılar katılımcıları çalışmalarının amacına
göre seçerler. Katılımcılar çalışmanın ihtiyaçlarına göre örnek için
seçildiğinden profile uymayan başvuru sahipleri reddedilir.

Örneğin, bir oyun geliştirme şirketinin yeni bir video oyunu hakkında
halka açık piyasaya sürülmeden önce pazar araştırması yapmak istediğini
hayal edin. Araştırma ekibi sadece oyun uzmanlarını örneklerine dahil
etmek istiyor. Bu nedenle, potansiyel iyileştirmeler hakkında geri
bildirim sağlamak için bir grup profesyonel oyuncuyu araştırıyorlar.

`<img src="attachment:ff9a7f67-b8f6-45b0-af5d-936d11cee414.png" width="500"/>`{=html}

Amaçlı örneklemede, araştırmacılar genellikle çalışmalarıyla en alakalı
olduğunu düşündükleri belirli bir gruba odaklanmak için belirli grupları
örneklemden kasıtlı olarak dışlar. Bu durumda, araştırmacı amatör
oyuncuları hariç tutar. Amatör oyuncular yeni oyunu profesyonel
oyunculardan farklı nedenlerle satın alabilir ve profesyonellere hitap
etmeyen oyun özelliklerinin keyfini çıkarabilir. Bu, önyargılı sonuçlara
yol açabilir, çünkü örneklemdeki profesyonellerin genel oyuncu
popülasyonunu temsil etmesi muhtemel değildir.

Amaçlı örnekleme genellikle bir araştırmacının bir popülasyonun belirli
bir kısmı hakkında ayrıntılı bilgi edinmek istediğinde veya popülasyonun
çok küçük olduğu ve üyelerinin hepsinin benzer özelliklere sahip olduğu
durumlarda kullanılır. Amaçlı örnekleme, büyük ve çeşitli bir popülasyon
hakkında çıkarımlar yapmak için etkili değildir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Olasılıksız örnekleme, sınırlı zamanınız, bütçeniz ve diğer kaynakların
olduğu durumlarda veri toplamak için kullanışlıdır. Olasılıksız
örnekleme, bir bütün olarak popülasyon hakkında çıkarımlar yapmak
yerine, bir popülasyon hakkında ilk anlayışı elde etmek istediğinizde,
keşif araştırmaları için de yararlıdır. Bununla birlikte, olasılık dışı
örnekleme yöntemlerinin yüksek örnekleme yanlılığı riskine sahip
olduğunu hatırlamak önemlidir.

Bir veri uzmanı olarak, örnek verileri toplamaya başladığınız andan
sonuçlarınızı sunduğunuz ana kadar önyargı ve adalet hakkında
düşünmelisiniz. Bazı yaygın önyargı biçimlerinin farkına vardığınızda,
herhangi bir biçimde önyargı konusunda tetikte kalabilirsiniz.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Merkezi limit teoremi ile popülasyon parametrelerini çıkarma  {#merkezi-limit-teoremi-ile-popülasyon-parametrelerini-çıkarma-}
:::

::: {.cell .markdown}
Son zamanlarda, merkezi limit teoremini ve bunun çok çeşitli veri
kümeleriyle çalışmanıza nasıl yardımcı olabileceğini öğrendiniz. Veri
uzmanları, ekonomi, bilim, işletme ve diğer birçok alandaki veriler için
popülasyon parametrelerini tahmin etmek için merkezi sınır teoremini
kullanır.

Bu okumada, merkezi limit teoremi ve bunun farklı veri türleri için
popülasyon ortalamasını tahmin etmenize nasıl yardımcı olabileceği
hakkında daha fazla bilgi edineceksiniz. Teoremin tanımını, teoremi
uygulamak için yerine getirilmesi gereken koşulları gözden geçireceğiz
ve teoremin eylemdeki bir örneğini inceleyeceğiz.

### Merkezi limit teoremi

#### **Tanımı** {#tanımı}

**Merkezi limit teoremi,** örneklem büyüklüğü arttıkça ortalamanın
örnekleme dağılımının normal dağılıma yaklaştığını belirtir. Başka bir
deyişle, örnek boyutunuz arttıkça, örnekleme dağılımınız bir çan eğrisi
şeklini alır. Ve bir popülasyondan daha fazla gözlem örnekledikçe,
örneklem ortalaması popülasyon ortalamasına yaklaşır. Nüfusun yeterince
büyük bir örneğini alırsanız, örneklem ortalaması kabaca popülasyon
ortalamasına eşit olacaktır.

Örneğin, hafif kamyonetler gibi belirli bir araç sınıfının ortalama
ağırlığını tahmin etmek istediğinizi hayal edin. Milyonlarca kamyonet
tartmak yerine, temsili bir kamyonet örneği hakkında veri alabilirsiniz.
Örneklem büyüklüğünüz yeterince büyükse, örneğinizin ortalama ağırlığı
kabaca popülasyonun ortalama ağırlığına eşit olacaktır (büyük sayılar
yasasına bağlı kalarak).

`<img src="attachment:f0bb4637-b7ca-4814-9e3a-fa30c700a179.png" width="500"/>`{=html}

**Not:** Merkezi limit teoremi herhangi bir popülasyon için geçerlidir.
Teoremi uygulamak için nüfus dağılımınızın şeklini önceden bilmeniz
gerekmez - dağılım çan şeklinde olabilir, eğri veya başka bir şekle
sahip olabilir. Yeterli büyüklükte numune toplarsanız, araçlarının
dağılımının şekli normal bir dağılımı takip edecektir.

#### **Koşullar**

Merkezi limit teoremini uygulamak için aşağıdaki koşulların yerine
getirilmesi gerekir:

-   **Rastgel** *eştirme:* Örnek verileriniz rastgele seçimin sonucu
    olmalıdır. Rastgele seçim, popülasyondaki her üyenin örneklem için
    seçilme şansının eşit olduğu anlamına gelir.

-   **Bağımsızlık**\_:\_ Örnek değerleriniz birbirinden bağımsız
    olmalıdır. Bağımsızlık, bir gözlemin değerinin başka bir gözlemin
    değerini etkilemediği anlamına gelir. Tipik olarak, veri kümenizdeki
    bireylerin veya öğelerin rastgele seçildiğini biliyorsanız,
    bağımsızlık da varsayabilirsiniz.

    -   **%10**\_:\_ Bağımsızlık koşulunun karşılanmasını sağlamaya
        yardımcı olmak için, örnek *değiştirilmeden çekildiğinde*
        örneklem büyüklüğünüz toplam popülasyonun% 10\'undan büyük
        olmamalıdır (genellikle böyle olur).

        -   **Not**: Genel olarak, değiştirilmiş veya değiştirmeden
            örnekleme yapabilirsiniz. Bir popülasyon öğesi yalnızca bir
            kez seçilebildiğinde, değiştirilmeden örnekleme yaparsınız.
            Bir popülasyon öğesi birden fazla kez seçilebildiğinde,
            değiştirme ile örnekleme yapıyorsunuz. Kursun ilerleyen
            bölümlerinde bu konu hakkında daha fazla bilgi
            edineceksiniz.

-   **Örnek büyükl** üğü: Örnek büyüklüğünün yeterince büyük olması
    gerekir.

Örneklem büyüklüğü durumunu daha ayrıntılı olarak tartışalım. Merkezi
limit teoreminin uygulanabilmesi için bir örneklem büyüklüğünün ne kadar
büyük olması gerektiğine dair kesin bir kural yoktur. Cevap aşağıdaki
faktörlere bağlıdır:

-   H**assasiyet gereksinimleri**. Örneklem büyüklüğü ne kadar büyükse,
    örnekleme dağılımınız normal dağılıma o kadar çok benzeyecek ve
    popülasyon ortalaması tahmininiz o kadar kesin olacaktır.

-   **Nüfusun şekli**\_.\_ Popülasyon dağılımınız kabaca çan şeklindeyse
    ve zaten normal bir dağılıma benziyorsa, örnek ortalamasının
    örnekleme dağılımı, küçük bir örneklem büyüklüğünde bile normal
    dağılıma yakın olacaktır.

Genel olarak, birçok istatistikçi ve veri uzmanı, nüfus dağılımı kabaca
çan şeklinde veya yaklaşık olarak normal olduğunda 30\'luk bir örneklem
büyüklüğünün yeterli olduğunu düşünmektedir. Bununla birlikte, orijinal
popülasyon normal değilse - örneğin, aşırı derecede çarpıksa veya çok
sayıda aykırı değer varsa - veri uzmanları genellikle örneklem boyutunun
biraz daha büyük olmasını tercih eder. Keşif veri analizi, belirli bir
veri kümesi için ne kadar büyük bir numunenin gerekli olduğunu
belirlemenize yardımcı olabilir.

#### **Örnek: Yıllık maaş**

Merkezi limit teoreminin nasıl çalıştığı hakkında daha iyi bir fikir
edinmek için bir örneği inceleyelim.

Buenos Aires, Kahire, Delhi veya Seul gibi büyük bir şehirde çalışan
profesyoneller için yıllık maaş verilerini incelediğinizi hayal edin.
Diyelim ki ilgilendiğiniz profesyonel nüfus 10 milyon insanı içeriyor.
Şehirde yaşayan bir profesyonel için yıllık ortalama maaşı bilmek
istiyorsunuz. Ancak, her maaş hakkında eksiksiz veri almak için
milyonlarca profesyoneli araştırmak için zamanınız veya paranız yok.

Tüm popülasyonu araştırmak yerine, 100 profesyonelin tekrarlanan
rastgele örneklerinden anket verilerini toplarsınız. Bu verileri
kullanarak, ilk örneğiniz için ortalama yıllık maaşı dolar cinsinden
hesaplarsınız: 40.300\\\$. İkinci örneğiniz için ortalama maaş:
41.100\\\$. Üçüncü bir örneği araştırıyorsunuz. Ortalama maaş 39.700
dolar. Ve böyle devam ediyor. Örnekleme değişkenliği nedeniyle, her
numunenin ortalaması biraz farklı olacaktır.

`<img src="attachment:b43ac1a2-c94c-44d8-96b0-04da73d5358d.png" width="500"/>`{=html}

Teorik olarak, çok büyük bir örnek alabilir ve 10 milyon kişinin
tamamına maaşları hakkında anket yapana kadar örneklem boyutunu
artırabilirsiniz. Merkezi limit teoremi, örneklem büyüklüğünüz arttıkça,
örnekleme dağılımınızın şeklinin giderek bir çan eğrisine benzeyeceğini
söylüyor.

Popülasyondan yeterince büyük bir örnek alırsanız, örnekleme
dağılımınızın ortalaması kabaca popülasyon ortalamasına eşit olacaktır.
Nüfusun bu örnekleminden, tüm profesyonel nüfus için ortalama yıllık
maaşı kesin olarak tahmin edebilirsiniz.

**Not:** Uygulamada, veri uzmanları genellikle tek bir örnek alır.
Seçtikleri belirli örneklem büyüklüğü, bütçe, zaman, kaynaklar ve
tahminleri için istenen güven düzeyi gibi faktörlere bağlıdır.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Merkezi limit teoremi, popülasyonun yalnızca bir kısmı hakkında mevcut
verileriniz olsa bile ortalama gibi popülasyon parametrelerini
çıkarmanıza yardımcı olabilir. Örneklem büyüklüğünüz ne kadar büyükse,
popülasyon ortalaması tahmininizin o kadar kesin olması muhtemeldir.
İster araç ağırlığını ister yıllık maaşı ölçüyor olun, merkezi limit
teoremi verilerinizi daha iyi anlamak için yararlı bir yöntemdir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Ortalamanın örnekleme dağılımı
:::

::: {.cell .markdown}
Son zamanlarda, veri profesyonellerinin nüfus parametrelerini tahmin
etmek için örnek istatistikleri nasıl kullandığını öğrendiniz. Örneğin,
bir veri uzmanı, müşterilerin bir perakende web sitesinde geçirdikleri
ortalama süreyi veya eğlence endüstrisinde çalışan tüm kişilerin
ortalama maaşını tahmin edebilir.

Bu okumada, örnekleme dağılımı kavramı ve bunun rastgele bir örneklemin
olası sonuçlarını temsil etmenize nasıl yardımcı olabileceği hakkında
daha fazla bilgi edineceksiniz. Ayrıca, örnek ortalamasının örnekleme
dağılımının popülasyon ortalamasını tahmin etmenize nasıl yardımcı
olabileceğini tartışacağız.

### Örnek ortalamasının örnekleme dağılımı

Örne **kleme dağılımı**, bir örnek istatistiğin olasılık dağılımıdır.
Bir olasılık **dağılımının**, madeni para fırlatma veya kalıp atma gibi
rastgele bir değişkenin olası sonuçlarını temsil ettiğini hatırlayın.
Aynı şekilde, bir örnekleme dağılımı, bir örnek istatistiği için olası
sonuçları temsil eder. Örnek istatistikler rastgele örneklenmiş verilere
dayanır ve sonuçları kesin olarak tahmin edilemez. Ortalama, medyan,
standart sapma, aralık ve daha fazlası gibi istatistikleri temsil etmek
için bir örnekleme dağılımı kullanabilirsiniz.

Tipik olarak, veri uzmanları, karşılık gelen popülasyon parametrelerini
tahmin etmek için ortalama gibi örnek istatistikleri hesaplar.

Bir grup insanın, hayvanın veya bitkinin ortalama yüksekliği gibi bir
popülasyonun ortalamasını tahmin etmek istediğinizi varsayalım.
Örnekleme dağılımı kavramı hakkında düşünmenin iyi bir yolu,
popülasyondan her biri aynı örneklem büyüklüğüne sahip tekrarlanan
örnekler aldığınızı hayal etmek ve bu örneklerin her biri için
ortalamayı hesapladığınızı hayal etmektir. Örnekleme değişkenliği
nedeniyle, örnek ortalaması numuneden numuneye kesin olarak tahmin
edilemeyecek şekilde değişecektir. Tüm numune araçlarınızın dağılımı
esasen örnekleme dağılımıdır. Örnek ortalamaların dağılımını bir
histogramda görüntüleyebilirsiniz. İstatistikçiler buna ortalamanın
örnekleme dağılımı diyorlar.

**Not: Uygulam** ada, sınırlı zaman ve kaynaklar nedeniyle, veri
uzmanları tipik olarak tek bir örnek toplar ve popülasyon ortalamasını
tahmin etmek için bu örneğin ortalamasını hesaplar.

Ortalamanın örnekleme dağılımı hakkında daha somut bir fikir edinmek
için bir örneği inceleyelim.

#### **Örnek: Göl alabalığının ortalama uzunluğu**

Çevre bilimcilerinden oluşan bir ekiple çalışan bir veri uzmanısınız.
Ekibiniz su kirliliğinin balık türleri üzerindeki etkilerini inceler. Şu
anda ekibiniz, Kuzey Amerika\'daki Büyük Göllerden biri olan Superior
Gölü\'ndeki alabalık popülasyonu üzerindeki kirliliğin etkilerini
araştırıyor. Bu araştırmanın bir parçası olarak, sizden bir alabalığın
ortalama uzunluğunu tahmin etmenizi istiyorlar. Diyelim ki gölde 10
milyon alabalık var. Milyonlarca alabalık toplamak ve ölçmek yerine,
popülasyondan örnek veriler alırsınız.

Diyelim ki popülasyondan her biri 100 alabalıktan oluşan tekrarlanan
basit rastgele örnekler aldığınızı varsayalım. Başka bir deyişle, gölden
rastgele 100 alabalık seçersiniz, ölçersiniz ve ardından bu işlemi
farklı bir 100 alabalık seti ile tekrarlarsınız. İlk 100 alabalık
örneğiniz için ortalama uzunluğun 20,2 inç olduğunu görürsünüz. İkinci
numuneniz için ortalama uzunluk 20,5 inçtir. Üçüncü numuneniz için
ortalama uzunluk 19.7 inçtir. Ve böyle devam ediyor. Örnekleme
değişkenliği nedeniyle, ortalama uzunluk numuneden numuneye rastgele
değişecektir.

Bu örneğin amacı için, bu popülasyondaki bir alabalığın gerçek ortalama
uzunluğunun 20 inç olduğunu varsayalım. Bununla birlikte, pratikte,
göldeki her alabalığı ölçmediğiniz sürece bunu bilemezsiniz.

Her 100 alabalık örneği aldığınızda, örneğinizdeki alabalığın ortalama
uzunluğunun 20 inçlik popülasyon ortalamasına yakın olması muhtemeldir,
ancak tam olarak 20 inç değil. Arada bir, ortalama uzunluğu 16 inç veya
daha az olan, ortalamadan daha kısa alabalıklarla dolu bir örnek
alabilirsiniz. Veya ortalama uzunluğu 24 inç veya daha fazla olan,
ortalamadan daha uzun alabalıklarla dolu bir örnek alabilirsiniz.

Tüm farklı örnek araçlarınızın sıklığını temsil etmek için bir örnekleme
dağılımı kullanabilirsiniz. Örneğin, popülasyondan her biri 10
alabalıktan oluşan 10 basit rastgele örnek alırsanız, ortalamanın
örnekleme dağılımını bir histogram olarak gösterebilirsiniz. Örnek
verilerinizde en sık meydana gelen değer yaklaşık 20 inç olacaktır. En
az sık meydana gelen değerler, 16 inç veya 24 inç gibi daha aşırı
uzunluklar olacaktır.

`<img src="attachment:cc3c8e71-b1f6-489f-83cc-273ab1bea105.png" width="500"/>`{=html}

Bir örneklemin boyutunu artırdıkça, örnek verilerinizin ortalama
uzunluğu popülasyonun ortalama uzunluğuna yaklaşacaktır. Tüm popülasyonu
örneklediyseniz - başka bir deyişle, göldeki her bir alabalığı gerçekten
ölçseydiniz - örnek ortalamanız popülasyon ortalamasıyla aynı olacaktır.

Ancak, popülasyon ortalamasının doğru bir tahminini elde etmek için
milyonlarca balığı ölçmenize gerek yoktur. Popülasyondan yeterince büyük
bir örneklem büyüklüğü alırsanız - diyelim ki, 1000 alabalık - örneklem
ortalamanız popülasyon ortalamasının (20 inç) kesin bir tahmini
olacaktır.

`<img src="attachment:82ab106e-542a-4880-9958-1ae32291a5a8.png" width="500"/>`{=html}

#### **Standart hata**

Örnek verilerinizi, herhangi bir örneğin ortalama uzunluğunun popülasyon
ortalamasını ne kadar tam olarak temsil ettiğini tahmin etmek için de
kullanabilirsiniz.

Bunu bilmek yararlıdır çünkü örnek ortalaması örneklemden örneğe değişir
ve verilen herhangi bir örnek ortalamasının gerçek popülasyon
ortalamasından farklı olması muhtemeldir. Örneğin, alabalık
popülasyonunun ortalama uzunluğu 20 inç olabilir. Herhangi bir alabalık
örneği için ortalama uzunluk 20,2 inç, 20,5 inç, 19,7 inç vb. Olabilir.

Veri uzmanları, bu değişkenliği ölçmek için örnek araçların standart
sapmasını kullanır. İstatistikte, bir örnek istatistiğin standart
sapmasına **standart hata denir**. Standart hata, örnekleme
değişkenliğinin sayısal bir ölçüsünü sağlar. Ortalamanın standart
hatası, tüm örnek ortalamalarınız arasındaki değişkenliği ölçer. Daha
büyük bir standart hata, örnek ortalamalarının daha dağılmış olduğunu
veya daha fazla değişkenlik olduğunu gösterir. Daha küçük bir standart
hata, örnek ortalamalarının birbirine daha yakın olduğunu veya daha az
değişkenlik olduğunu gösterir.

Uygulamada, tek bir gözlem örneği kullanarak, örnek ortalamasının
tahmini standart hatasını hesaplamak için aşağıdaki formülü
uygulayabilirsiniz: s/√n Formülde, s örnek standart sapmasını ifade eder
ve n örnek boyutunu ifade eder.

Örneğin, alabalık uzunlukları çalışmanızda, 100 alabalık bir numunenin
ortalama uzunluğu 20 inç ve standart sapmayı 2 inç olduğunu hayal edin.
Örnek standart sapmayı, 2\'yi örnek boyutunun kareköküne, 100\'e bölerek
tahmini standart hatayı hesaplayabilirsiniz:

2 ÷ √100 = 2 ÷ 10 = 0,2

Bu, bir numuneden diğerine ortalama uzunluğun yaklaşık 0,2 inçlik bir
standart sapma ile değişeceğini beklemeniz gerektiği anlamına gelir.

Standart hata, tahmininizin kesinliğini anlamanıza yardımcı olur. Genel
olarak, örneklem boyutu büyüdükçe ve standart hata küçüldükçe
tahminlerinize daha fazla güvenebilirsiniz. Bunun nedeni, örneklem
büyüklüğünüz büyüdükçe, örneklem ortalamasının popülasyon ortalamasına
yaklaşmasıdır.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Örnekleme yoluyla popülasyon parametrelerini tahmin etmek, güçlü bir
istatistiksel çıkarım şeklidir. Örnekleme dağılımları, bir örnek
istatistikle ilişkili belirsizliği tanımlar ve uygun istatistiksel
çıkarımlar yapmanıza yardımcı olur. Bu önemlidir, çünkü paydaş kararları
genellikle sağladığınız tahminlere dayanır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Veri Numunesi Alma ve Tahminler Oluşturma
:::

::: {.cell .markdown}
``` python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
from scipy import stats
import statsmodels.api as sm

sampled_data = education_districtwise.sample(n = 50 replace=True, random_state=31208)

sampled_data
```

`<img src="attachment:848efbda-7373-422a-ae64-461aad088faf.png" width="800"/>`{=html}

``` python
estimate1 = sampled_data['OVERALL_LI'].mean() 

estimate1

74.22359999999999

estimate2 = education_districtwise['OVERALL_LI'].sample(n = 50, replace=True, random_state=56810).mean() 

estimate2

74.24780000000001


estimate_list = [] 

for i in range(10000):
    estimate_list.append(education_districtwise['OVERALL_LI'].sample(n=50, replace=True).mean()) 

estimate_df = pd.DataFrame(data={'estimate': estimate_list})

mean_sample_means = estimate_df['estimate'].mean() 

mean_sample_means
73.41124126000025
```
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Güven aralıkları: Doğru ve yanlış yorumlar  {#güven-aralıkları-doğru-ve-yanlış-yorumlar-}
:::

::: {.cell .markdown}
Son zamanlarda, veri profesyonellerinin bir tahmini çevreleyen
belirsizliği tanımlamaya yardımcı olmak için güven aralıklarını
kullandığını öğrendiniz. Verilerinizi daha iyi anlamak ve sonuçlarınızı
paydaşlara etkili bir şekilde iletmek için, bir güven aralığını nasıl
doğru yorumlayacağınızı bilmek önemlidir.

Bu okumada, bir güven aralığını yorumlamanın doğru yolunu gözden
geçireceğiz. Ayrıca bazı yaygın yanlış yorumlama biçimlerini ve
bunlardan nasıl kaçınılacağını tartışacağız.

### Doğru yorumlama

#### **Örnek: ortalama ağırlık**

Bir güven aralığının nasıl yorumlanacağını daha iyi anlamak için bir
örneği inceleyelim. 10.000 penguen popülasyonunun ortalama ağırlığını
tahmin etmek istediğinizi hayal edin. Her bir pengueni tartmak yerine,
100 penguenden oluşan bir örnek seçersiniz. Numunenizin ortalama
ağırlığı 30 pound. Örnek verilerinize dayanarak, 28 pound ile 32 pound
arasında% 95 güven aralığı oluşturursunuz.

95 Cl \[28, 32\]

#### **Güven aralığını yorumlayın**

Daha önce, güven seviyesinin tahmin sürecinin belirsizliğini ifade
ettiğini öğrendiniz. %95 güvenin ne anlama geldiğini daha teknik bir
bakış açısıyla tartışalım.

Teknik olarak,% 95 güven, bir popülasyondan tekrarlanan rastgele
örnekler alırsanız ve aynı yöntemi kullanarak her örnek için bir güven
aralığı oluşturursanız, bu aralıkların% 95\'inin popülasyon ortalamasını
yakalamasını bekleyebileceğiniz anlamına gelir. Ayrıca toplamın% 5\'inin
nüfus ortalamasını yak *alam* ayacağını da bekleyebilirsiniz.

Güven seviyesi, **yöntem** in uzun vadeli başarı oranını veya rastgele
örneklemeye dayalı tahmin sürecini ifade eder.

Örneğimizin amacı için, 10.000 penguenin ortalama ağırlığının 31 pound
olduğunu hayal edelim, ancak her pengueni gerçekten tartmadığınız sürece
bunu bilemezsiniz. Yani, nüfusun bir örneğini alıyorsunuz.

Penguen popülasyonundan her biri 100 penguenden oluşan 20 rastgele örnek
aldığınızı ve her örnek için% 95\'lik bir güven aralığı hesapladığınızı
hayal edin. 20 aralığın yaklaşık 19\'unun veya toplamın% 95\'inin gerçek
popülasyon ortalama ağırlığını 31 pound içermesini bekleyebilirsiniz.
Böyle bir aralık, 28 pound ile 32 pound arasındaki değerler aralığı
olacaktır.

`<img src="attachment:39bc5bc7-08ea-4dea-a60d-9cd3c3a1a21e.png" width="500"/>`{=html}

Uygulamada, veri uzmanları genellikle bir rastgele örnek seçer ve gerçek
popülasyon ortalamasını içerebilecek veya içermeyebilecek bir güven
aralığı oluşturur. Bunun nedeni, tekrarlanan rastgele örneklemenin
genellikle zor, pahalı ve zaman alıcı olmasıdır. Güven aralıkları, veri
uzmanlarına rastgele örneklemeden kaynaklanan belirsizliği ölçmenin bir
yolunu verir.

### Yanlış yorumlar

Artık bir güven aralığını nasıl doğru yorumlayacağınızı daha iyi
anladığınıza göre, bazı yaygın yanlış yorumları ve bunlardan nasıl
kaçınılacağını gözden geçirelim.

#### **Yanlış yorumlama 1: %95, popülasyon ortalamasının oluşturulmuş aralık içinde olma olasılığını ifade eder**

Genellikle %95 güven düzeyinde bir güven aralığı hakkında yapılan yanlış
bir ifade, popülasyon ortalamasının yapılandırılmış aralık içinde düşme
olasılığının% 95\'lik bir olasılığın olmasıdır.

Örneğimizde bu, penguen popülasyonunun ortalama ağırlığının 28 pound ile
32 pound arasında düşme olasılığının %95 olduğu anlamına gelir.

Bu yanlış. Nüfus ortalaması sabittir.

Herhangi bir popülasyon parametresi gibi, popülasyon ortalaması rastgele
bir değişken değil sabittir. Örnek ortalamasının değeri örneklemden
örneğe değişirken, popülasyon ortalamasının değeri değişmez. Bir sabitin
herhangi bir değer aralığına girme olasılığı her zaman% 0 veya%
100\'dür. Ya değerler aralığına girer, ya da değildir.

Örneğin, 100 penguenden oluşan herhangi bir rastgele örnek farklı bir
ortalama ağırlığa sahip olabilir: 32,8 pound, 27,3 pound, 29,6 pound vb.
Örnek ortalamalarınızın her birine belirli bir olasılık atamak için bir
örnekleme dağılımı kullanabilirsiniz çünkü bunlar rastgele
değişkenlerdir. Bununla birlikte, popülasyon ortalama ağırlığı sabit
olarak kabul edilir. Örneğimizde, 10.000 penguenin tümünü tartırsanız,
nüfus ortalamasının 31 pound olduğunu göreceksiniz. Bu değer sabittir ve
numuneden numuneye değişmez.

  **Örnek Ortalama (100 penguen)**   **Nüfus Ortalaması (10.000 penguen)**
  ---------------------------------- ---------------------------------------
  32,8 lbs                           31 lbs
  27,3 lbs                           31 lbs
  29,6 lbs                           31 lbs

Bu nedenle, güven aralığınızın popülasyon ortalamasını yakalama
olasılığın% 95 olduğunu söylemek kesinlikle doğru değildir çünkü bu,
popülasyon ortalamasının değişken olduğu anlamına gelir. Aralıklar
örnekten örneğe değişir, ancak popülasyonun değeri yakalamaya
çalıştığınız anlamına gelmez.

Söyleyebileceğiniz şey, popülasyondan tekrarlanan rastgele örnekler
alırsanız ve aynı yöntemi kullanarak her örnek için bir güven aralığı
oluşturursanız, aralıklarınızın% 95\'inin popülasyon ortalamasını
yakalamasını bekleyebilirsiniz.

**Profesyonel ipucu:** %95 güven seviyesinin tahmin sürecinin başarı
oranını ifade ettiğini unutmayın.

#### **Yanlış yorumlama 2: %95, aralığa giren veri değerlerinin yüzdesini ifade eder**

Diğer bir yaygın hata, %95\'lik bir güven aralığını, popülasyondaki tüm
veri değerlerinin% 95\'inin aralık içinde olduğunu söyleyerek
yorumlamaktır. Bu mutlaka doğru değildir. %95 güven aralığı, muhtemelen
gerçek popülasyon ortalamasını içeren bir değer aralığı gösterir. Bu,
*pop* ülasyondaki veri değerlerinin% 95\'ini içeren bir aralıkla aynı
değildir.

Örneğin, ortalama penguen ağırlığı için% 95 güven aralığınız 28 pound
ile 32 pound arasındadır. Tüm ağırlık değerlerinin% 95\'inin bu aralığa
düştüğünü söylemek doğru olmayabilir. Popülasyondaki penguen
ağırlıklarının% 5\'inden fazlasının bu aralığın dışında olması
mümkündür - ya 28 pounddan az veya 32 pounddan fazla.

`<img src="attachment:89ef5148-7a44-49ae-9376-c897ead78c61.png" width="200"/>`{=html}

#### **Yanlış yorumlama 3: %95, aralığa giren numune araçlarının yüzdesini ifade eder**

Üçüncü bir yaygın yanlış yorum, %95\'lik bir güven aralığının, tüm olası
numune ortalamasının% 95\' *inin* aralık aralığına girdiğini ima
etmesidir. Bu mutlaka doğru değildir. Örneğin, ortalama penguen ağırlığı
için% 95 güven aralığınız 28 pound ile 32 pound arasındadır. Tekrarlanan
100 penguenin örneklerini aldığınızı ve her numune için ortalama
ağırlığı hesapladığınızı hayal edin. Numunenizin \_%\_5\'inden
fazlasının 28 pounddan az veya 32 pounddan büyük olması mümkündür.

`<img src="attachment:70f99cc2-1df2-407b-8709-5affb3373cfe.png" width="500"/>`{=html}

### Önemli çıkarımlar {#önemli-çıkarımlar}

Güven aralıklarını nasıl doğru yorumlayacağınızı bilmek, tahmininizi
daha iyi anlamanıza ve faydalı ve doğru bilgileri paydaşlarla
paylaşmanıza yardımcı olacaktır. Yaygın yanlış yorumları ve neden yanlış
olduklarını da açıklamanız gerekebilir. Paydaşlarınızın kararlarını
yanlış yorumlamaya dayandırmasını istemezsiniz. Sonuçlarınızı paydaşlara
nasıl etkili bir şekilde ileteceğinizi anlamak, bir veri uzmanı olarak
işinizin önemli bir parçasıdır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Küçük bir örneklem boyutu için bir güven aralığı oluşturun
:::

::: {.cell .markdown}
Şimdiye kadar, genellikle 30 veya daha fazla öğenin örnek boyutları
olarak tanımlanan büyük örnek boyutları için güven aralıkları
oluşturdunuz. Örneğin, yeni bir cep telefonunun ortalama pil ömrünü
tahmin ettiğinizde, 100 telefondan oluşan rastgele bir örnek
kullandınız. Öte yandan, küçük örneklem boyutları genellikle 30\'dan az
maddeye sahip olarak tanımlanır. Tipik olarak, veri uzmanları daha kesin
tahminler verdikleri için büyük örneklem boyutlarıyla çalışmaya
çalışırlar. Ancak, büyük bir örnekle çalışmak her zaman mümkün değildir.
Uygulamada, veri toplamak genellikle pahalı ve zaman alıcıdır. Büyük bir
örnek almak için zamanınız, paranız veya kaynağınız yoksa, küçük bir
örnekle çalışmaya başlayabilirsiniz.

Bu okumada, küçük bir örneklem boyutu için bir güven aralığının nasıl
oluşturulacağını öğreneceksiniz. Yeni bir otomobil motoru için ortalama
emisyon seviyelerini içeren bir örneği adım adım inceleyeceğiz.

### Büyük ve küçük örneklem boyutları

İlk olarak, büyük ve küçük örnek boyutları için güven aralıkları
oluşturmak için kullandığınız farklı yöntemleri kısaca tartışalım.

#### **Büyük örnek: Z-puanları**

Büyük örneklem boyutları için, cep telefonları için ortalama pil ömrünü
tahmin etmek için daha önce yaptığınız gibi, hata payını hesaplamak için
z **pu** anlarını kullanırsınız. Bunun nedeni merkezi sınır teoremidir:
büyük örnek boyutları için, örnek ortalaması yaklaşık olarak normal
olarak dağılmıştır. **Z-dağılımı olarak da adlandırılan standart bir
normal dağılım için, veriler** iniz hakkında hesaplamalar yapmak için z
puanlarını kullanırsınız.

#### **Küçük örnek: T-puanları**

Küçük örnek boyutları için, **t-** dağılımı adı verilen farklı bir
dağıtım kullanmanız gerekir. İstatistiksel olarak konuşursak, bunun
nedeni, küçük örneklem boyutları için standart hatanın tahmin
edilmesinde daha fazla belirsizlik olmasıdır. Bu kursun kapsamı
dışındaki teknik detaylar hakkında endişelenmenize gerek yok. Şimdilik,
küçük bir örneklem boyutuyla çalışıyorsanız ve verileriniz yaklaşık
olarak normal dağılmışsa, standart normal dağılım yerine t dağılımını
kullanmanız gerektiğini bilin. Bir t dağılımı için, verileriniz hakkında
hesaplamalar yapmak için t-puanlarını kullanırsınız.

T-dağılımının grafiği, standart normal dağılıma benzer bir çan şekline
sahiptir. Ancak, t dağılımının standart normal dağılımdan daha büyük
kuyrukları vardır. Daha büyük kuyruklar, küçük bir veri kümesiyle gelen
aykırı değerlerin daha yüksek sıklığını gösterir. Örneklem büyüklüğü
arttıkça, t dağılımı normal dağılıma yaklaşır. Örneklem büyüklüğü 30\'a
ulaştığında, dağılımlar hemen hemen aynıdır ve hesaplamalarınız için
normal dağılımı kullanabilirsiniz.

`<img src="attachment:d6751bfb-c104-4548-8f3f-a3caeef4ad84.png" width="500"/>`{=html}

### Örnek: Ortalama emisyon seviyeleri

Artık t dağılımı ve t puanları hakkında biraz bilgi sahibi olduğunuza
göre, küçük bir örneklem boyutu için bir güven aralığı oluşturalım.

#### **Bağlam**

Bir otomobil üreticisi için çalışan bir veri uzmanı olduğunuzu düşünün.
Şirket, dünya çapında satılan yüksek performanslı otomobiller üretiyor.
Tipik olarak, bu arabalardaki motorlar, küresel ısınmaya katkıda bulunan
bir sera gazı olan yüksek karbondioksit veya CO 2 emisyon oranlarına
sahiptir. Mühendislik ekibi, şirketin en çok satan otomobili için
emisyonları azaltmak için yeni bir motor tasarladı.

#### **Hedef**

Amaç, emisyonları mil başına 460 gram CO 2 \'nin altında tutmaktır. Bu,
otomobilin satıldığı her ülkede emisyon standartlarını karşılamasını
sağlayacaktır. Ayrıca, daha düşük emisyon oranı çevre için iyidir ve bu
da yeni müşterilere hitap edecek.

#### **Sormak**

Mühendislik ekibi sizden yeni motor için emisyon oranının güvenilir bir
tahminini sağlamanızı ister. Üretim sorunları nedeniyle, test için
yalnızca sınırlı sayıda motor mevcuttur. Yani, küçük bir örneklem boyutu
ile çalışacaksınız.

#### **Örnek**

Mühendislik ekibi, 15 motordan oluşan rastgele bir örneği test eder ve
emisyonları hakkında veri toplar. Ortalama emisyon oranı mil başına 430
gram CO 2 \'dir ve standart sapma mil başına 35 gram CO 2 \'dir.

Tek numuneniz, *her motor için gerçek ortalama emisyon oranını sağlamay*
abilir. Emisyonlar için nüfus ortalaması mil başına 430 gram CO 2 \'nin
üzerinde veya altında olabilir. Yalnızca küçük bir motor örneğine sahip
olsanız bile, büyük bir motor popülasyonu için gerçek emisyon oranını
muhtemelen içeren bir güven aralığı oluşturabilirsiniz. Bu, yöneticinize
tahmininizdeki belirsizlik hakkında daha iyi bir fikir verecektir.
Ayrıca, mühendislik ekibinin emisyon oranını düşürmek için motor
üzerinde daha fazla çalışma yapmaları gerekip gerekmediğine karar
vermesine yardımcı olacaktır..

### Güven aralığını oluşturun

Bir güven aralığı oluşturma adımlarını gözden geçirelim:

1.  Örnek bir istatistik tanımlayın.

2.  Bir güven seviyesi seçin.

3.  Hata payını bulun.

4.  Aralığı hesaplayın.

#### **Adım 1: Örnek bir istatistik belirleyin**

İlk olarak, örnek istatistiğinizi tanımlayın. Numuneniz, 15 motor için
ortalama emisyon oranını temsil eder. Örnek bir ortalamayla çalış
*ıyorsun*.

#### **Adım 2: Bir güven seviyesi seçin**

Ardından, bir güven seviyesi seçin. Mühendislik ekibi sizden% 95 güven
seviyesi seçmenizi ister.

#### **Adım 3: Hata payını bulun**

Üçüncü adımınız hata payını bulmaktır. Küçük bir örneklem boyutu için, t
puanını standart hata ile çarparak hata payını hesaplarsınız.

T-dağılımı, serbestlik derecesi adı verilen bir parametre ile
tanımlanır. Bağlamımızda, özgürlük derecesi örneklem büyüklüğüdür - 1
veya 15-1 = 14. Özgürlük dereceniz ve güven seviyeniz göz önüne
alındığında, t-puanınızı hesaplamak için Python veya diğer istatistiksel
yazılımlar gibi bir programlama dili kullanabilirsiniz.

14 özgürlük derecesine ve% 95\'lik bir güven seviyesine bağlı olarak,
t-puanınız 2.145\'dir.

Artık örnek istatistiğinizin değişkenliğini ölçen standart hatayı
hesaplayabilirsiniz.

İşte daha önce kullandığınız ortalamanın standart hatasının formülü:

**Standart Hata (Ortam)**

SE(x)=s/√(n)SE(x)=s/√(n)

Formülde, s harfi örnek standart sapmayı ifade eder ve n harfi örnek
boyutunu ifade eder.

Örnek standart sapmanız 35 ve örneklem büyüklüğünüz 15\'tir. Hesaplama
size yaklaşık 9.04 standart bir hata verir.

Hata marjı, standart hatanızla çarpılan t-puanınızdır. Bu 2.145 \* 9.04
= 19.39\'dur.

#### **Adım 4: Aralığı hesaplayın**

Son olarak, güven aralığınızı hesaplayın. Aralığınızın üst sınırı, örnek
ortalaması artı hata payıdır. Bu, mil başına 430 + 19.39 = 449.39 gram
CO 2 \'dir.

Alt sınır, örnek ortalaması eksi hata payıdır. Bu, mil başına 430 −
19.39 = 410.61 gram CO 2 \'dir.

Mil başına 410.61 gram CO 2\'den mil başına 449,39 gram CO 2\'ye kadar
uzanan %95 güven aralığına sahipsiniz.

**95 CI \[410.61, 449.39\]**

Güven aralığı mühendislik ekibine önemli bilgiler verir. Aralığınızın
üst sınırı, mil başına 460 gram CO 2 hedefinin altındadır. Bu sonuç,
yeni motorun emisyon oranının emisyon standartlarını karşılayacağına
dair sağlam istatistiksel kanıtlar sağlar.

**Not**: Küçük örneklem büyüklükleri için güven aralıkları, popülasyon
oranlarıyla değil, yalnızca popülasyon ortalamalarını ilgilendirir. Bu
ayrımın istatistiksel nedeni oldukça tekniktir, bu yüzden şimdilik
endişelenmenize gerek yok.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Bir veri uzmanı olarak, hem büyük hem de küçük örnek boyutlarıyla
çalışacaksınız. Büyük numuneler küçük numunelerden daha kesin tahminler
verse de, küçük bir numuneyi toplamak genellikle büyük bir numune
toplamaktan daha ucuz ve zaman alıcıdır. Farklı örnek boyutları için
güven aralıklarının nasıl oluşturulacağını bilmek, gelecekteki
kariyerinizde karşılaşabileceğiniz herhangi bir veri kümesini
yönetmenize yardımcı olacaktır.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Farklı örnek boyutları için güven aralıkları oluşturma hakkında daha
fazla bilgi edinmek için aşağıdaki kaynaklara bakın:

-   [Scribbr\'in bu
    makalesi,](https://www.scribbr.com/statistics/t-distribution/) t
    dağılımına ve bir güven aralığı oluştururken nasıl kullanılacağına
    dair yararlı bir genel bakış içerir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Veri Numunesi Alma ve Tahmini Standart Hatayı Bulma
:::

::: {.cell .markdown}
``` python
import numpy as np 
import pandas as pd 
from scipy import stats

education_districtwise = pd.read_csv("../Datasets/education_districtwise.csv")

education_districtwise = education_districtwise.dropna() 

sampled_data = education_districtwise.sample(n = 50, replace=True, random_state=31208)

sampled_data
```

`<img src="attachment:ab753aa8-247d-4ce2-bf8c-b3c496a64833.png" width="500"/>`{=html}

``` python
sample_mean = sampled_data['OVERALL_LI'].mean() 

sample_mean

74.22359999999999

Estimated_standard_error = sampled_data['OVERALL_LI'].std() / np.sqrt(sampled_data.shape[0])

stats.norm.interval(alpha=0.95, loc=sample_mean, scale=estimated_standard_error)

(71.42241096968617, 77.02478903031381)
```
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Sıfır ve alternatif hipotezler arasındaki farklar
:::

::: {.cell .markdown}
Son zamanlarda, **hipotez test** inin bir popülasyon parametresi
hakkında bir varsayımı değerlendirmek için örnek verileri kullandığını
öğrendiniz. Veri uzmanları, örnek verilerinden elde edilen kanıtların
sıfır hipotezi mi yoksa alternatif hipotezi mi destekleyip
desteklemediğine karar vermek için bir hipotez testi yapar.

Bu okumada, sıfır hipotez ile alternatif hipotez arasındaki temel
farkları ve her bir hipotezin farklı senaryolarda nasıl formüle
edileceğini gözden geçireceğiz.

### İstatistiksel hipotezler {#i̇statistiksel-hipotezler}

Bir hipotez testi yürütme adımlarını gözden geçirelim:

1.  Sıfır hipotezi ve alternatif hipotezi belirtin.

2.  Bir önem seviyesi seçin.

3.  P değerini bulun.

4.  Sıfır hipotezini reddedin veya reddetmeyi başaramayın.

Herhangi bir hipotez testi için ilk adım, sıfır ve alternatif
hipotezleri belirtmektir. Sıfır ve alternatif hipotezler birbirini
dışlar, yani ikisi de aynı anda doğru olamazlar.

S **ıfır hipote** zi, aksini gösteren ikna edici kanıtlar olmadıkça
doğru olduğu varsayılan bir ifadedir. Sıfır hipotezi tipik olarak
popülasyonda hiçbir etki olmadığını ve gözlemlenen verilerinizin
tesadüfen meydana geldiğini varsayar.

**Alternatif hipotez**, sıfır hipotezle çelişen bir ifadedir ve ancak
bunun için ikna edici kanıtlar varsa doğru olarak kabul edilir.
Alternatif hipotez tipik olarak popülasyonda bir etki olduğunu ve
gözlemlenen verilerinizin tesadüfen *oluşmadığını* varsayar.

**Not: S** ıfır ve alternatif hipotezler her zaman popülasyonla ilgili
iddialardır. Bunun nedeni, hipotez testinin amacının bir örneğe dayalı
bir popülasyon hakkında çıkarımlar yapmak olmasıdır.

Örneğin, bir otomobil bayisinde çalışan bir veri uzmanı olduğunuzu hayal
edin. Şirket, çalışanları için yeni bir satış eğitim programı
uygulamaktadır. Programın etkinliğini değerlendirmenizi istiyorlar.

-   S **ıfır hipoteziniz (H** **0):** programın satış geliri üzerinde
    hiçbir etkisi olmadı.

-   **Alternatif hipoteziniz (H** **a)**: program satış gelirini
    artırdı.

Her hipotezi daha ayrıntılı olarak inceleyelim.

#### **Sıfır hipotezi**

Sıfır hipotezi aşağıdaki özelliklere sahiptir:

-   İstatistikte, sıfır hipotezi genellikle H sıfırın altında (H 0)
    olarak kısaltılır.

-   Matematiksel terimlerle yazıldığında, sıfır hipotezi her zaman bir
    eşitlik sembolü içerir (genellikle =, ancak bazen ≤ veya ≥).

-   Sıfır hipotezleri genellikle "etki yok", "fark yok", "ilişki yok"
    veya "değişiklik yok" gibi ifadeleri içerir.

#### **Alternatif hipotez**

Alternatif hipotez aşağıdaki özelliklere sahiptir:

-   İstatistikte, alternatif hipotez genellikle H sub a (H a) olarak
    kısaltılır.

-   Matematiksel terimlerle yazıldığında, alternatif hipotez her zaman
    bir eşitsizlik sembolü içerir (genellikle ≠, ancak bazen \< or \>).

-   Alternatif hipotezler genellikle "bir etki", "bir fark", "bir
    ilişki" veya "bir değişiklik" gibi ifadeleri içerir.

#### **Örnek senaryolar**

Tipik olarak, sıfır hipotez *statü* koyu veya olayların mevcut durumunu
temsil eder. Sıfır hipotezi, statükonun değişmediğini varsayar.
Alternatif hipotez, yeni bir olasılık veya farklı bir açıklama önerir.
Farklı senaryolar için boş ve alternatif hipotezlerin nasıl yazılacağı
hakkında daha iyi bir fikir edinmek için bazı örneklere göz atalım:

##### **Örnek #1: Ortalama ağırlık**

Organik bir gıda şirketi granola ile ünlüdür. Şirket, ürettikleri her
torbanın 300 gram granola içerdiğini iddia ediyor - ne daha fazla ne de
daha az. Bu iddiayı test etmek için bir kalite kontrol uzmanı, 40
torbalı rastgele bir numunenin ağırlığını ölçer.

-   **H** **0**: μ = 300 (üretilen tüm granola torbalarının ortalama
    ağırlığı 300 grama eşittir)

-   **H** **a:** μ ≠ 300 (üretilen tüm granola torbalarının ortalama
    ağırlığı 300 grama eşit değildir)

##### **Örnek #2: Ortalama yükseklik**

Belirli bir ağaç türünün ortalama yüksekliğinin 30 fit uzunluğunda
olduğu varsayıldığını varsayalım. Bununla birlikte, bir ekolojist,
gerçek ortalama yüksekliğin 30 fitten büyük olduğunu iddia ediyor. Bu
iddiayı test etmek için ekolojist, 50 ağaçtan oluşan rastgele bir
örneğin yüksekliğini ölçer.

-   **H** **0**: μ ≤ 30 (bu ağaç türünün ortalama yüksekliği 30 fit\'e
    eşit veya daha azdır)

-   **H** **a:** μ \> 30 (bu ağaç türünün ortalama yüksekliği 30 fitten
    büyüktür)

##### **Örnek #3: Çalışanların oranı**

Bir şirket, tüm çalışanların en az% 80\'inin işlerinden memnun olduğunu
iddia eder. Bununla birlikte, bağımsız bir araştırmacı, tüm
çalışanların% 80\'inden azının işlerinden memnun olduğuna inanmaktadır.
Bu iddiayı test etmek için araştırmacı, 100 çalışandan oluşan rastgele
bir örneği araştırıyor.

-   **H** **0**: p ≥ 0.80 (işlerinden memnun olan tüm çalışanların
    oranı% 80\'e eşit veya daha fazladır)

-   **H** **a:** p \< 0.80 (işlerinden memnun olan tüm çalışanların
    oranı% 80\'den azdır)

#### **Özet: Null ve alternatif**

Aşağıdaki tablo, sıfır ve alternatif hipotezler arasındaki bazı önemli
farklılıkları özetlemektedir:

  -----------------------------------------------------------------------
                          **Sıfır hipotezi (H**   **Alternatif hipotez
                          0**)**                  (H** a**)**
  ----------------------- ----------------------- -----------------------
  **İddialar**            Popülasyonda hiçbir     Popülasyonda bir etkisi
                          etkisi yoktur.          var.

  **Dil**                 \- Etkisi               \- Bir
                          yok`<br>`{=html}        etki`<br>`{=html}
                          `<br>`{=html}- Fark     `<br>`{=html}- Bir
                          yok`<br>`{=html}        fark`<br>`{=html}
                          `<br>`{=html}- İlişki   `<br>`{=html}- Bir
                          yok`<br>`{=html}        ilişki`<br>`{=html}
                          `<br>`{=html}-          `<br>`{=html}- Bir
                          Değişiklik yok          değişiklik

  **Semboller**           Eşitlik (=, ≤, ≥)       Eşitsizlik (≠, \<, \>)
  -----------------------------------------------------------------------

### Önemli çıkarımlar {#önemli-çıkarımlar}

Sıfır hipotez ve alternatif hipotez, hipotez testinde temel
kavramlardır. Etkili bir hipotez testi yapmak için, sıfır ve alternatif
hipotezler arasındaki farkları ve her bir hipotezin nasıl doğru bir
şekilde ifade edileceğini anlamak önemlidir.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Sıfır hipotez ve alternatif hipotez hakkında daha fazla bilgi edinmek
için aşağıdaki kaynaklara bakın:

-   [Statistics How To\'nun bu
    makalesi](https://www.statisticshowto.com/probability-and-statistics/null-hypothesis/),
    sıfır hipotezinin ayrıntılı bir tartışmasını içermektedir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Tip I ve tip II hataları
:::

::: {.cell .markdown}
Daha önce, sonuçlarınızın istatistiksel olarak anlamlı olup olmadığını
veya tesadüfen meydana gelip gelmediğini belirlemeye yardımcı olmak için
bir hipotez testi kullanabileceğinizi öğrendiniz. Bununla birlikte,
hipotez testi olasılığa dayandığından, sıfır hipotez hakkında yanlış
sonuç çıkarma şansı her zaman vardır. Hipotez testinde, sonuç çıkarırken
yapabileceğiniz iki tür hata vardır: Tip I hata ve Tip II hatası.

Bu okumada, Tip I ve Tip II hataları arasındaki farkı ve her bir hatayı
yapmanın içerdiği riskleri tartışacağız.

### İstatistiksel karar vermede hatalar {#i̇statistiksel-karar-vermede-hatalar}

Bir hipotez testi yürütme adımlarını gözden geçirelim:

1.  Sıfır hipotezi ve alternatif hipotezi belirtin.

2.  Bir önem seviyesi seçin.

3.  P değerini bulun.

4.  Sıfır hipotezini reddedin veya reddetmeyi başaramayın.

Sıfır hipotezini reddetmeye veya reddetmeyi reddetmeye karar
verdiğinizde, dört olası sonuç vardır - ikisi doğru seçenekleri, ikisi
hataları temsil eder. Şunları yapabilirsiniz:

-   Sıfır hipotezi gerçekte doğru olduğunda reddedin (**Tip I hatası)**

-   Sıfır hipotezini gerçekten yanlış olduğunda reddedin (Doğru)

-   Sıfır hipotezini gerçekten doğru olduğunda reddedememe (Doğru)

-   Aslında yanlış olduğunda sıfır hipotezi reddedilemez (**Tip II
    hatası**)

`<img src="attachment:2db68625-42bd-4a58-98b6-7505fdd3031c.png" width="500"/>`{=html}

#### **Örnek: Klinik deneme**

Tip I ve Tip II hatalarını daha iyi anlamak için bir örneği inceleyelim.
Hipotez testleri genellikle yeni bir ilacın hastalarda daha iyi
sonuçlara yol açıp sağlamadığını belirlemek için klinik çalışmalarda
kullanılır. Bir ilaç şirketinde çalışan bir veri uzmanı olduğunuzu hayal
edin. Şirket, soğuk algınlığı tedavisi için yeni bir ilaç icat ediyor.
Şirket, soğuk algınlığı semptomları olan 200 kişiden oluşan rastgele bir
örneği test ediyor. İlaç olmadan, tipik kişi 7.5 gün boyunca soğuk
algınlığı semptomları yaşar. İlacı alan kişiler için ortalama iyileşme
süresi 6.2 gündür.

İlacın iyileşme süresi üzerindeki etkisinin istatistiksel olarak anlamlı
olup olmadığını veya şans nedeniyle olup olmadığını belirlemek için bir
hipotez testi yaparsınız.

Bu durumda:

-   S **ıfır hipotez** iniz (H 0), ilacın hiçbir etkisinin olmadığıdır.

-   **Alternatif hipotez** iniz (H a) ilacın etkili olduğudur.

#### **Tip I hatası**

Yanlış pozitif olarak da bilinen **Tip 1 hatası**, gerçekte doğru olan
bir sıfır hipotezi reddettiğinizde ortaya çıkar. Başka bir deyişle,
sonucunuzun aslında tesadüfen meydana geldiği halde istatistiksel olarak
anlamlı olduğu sonucuna varırsınız.

Örneğin, klinik deneyinizde, sıfır hipotez doğruysa, bu ilacın hiçbir
etkisi olmadığı anlamına gelir. Tip I hata yaparsanız ve sıfır hipotezi
reddederseniz, ilacın aslında etkisiz olduğunda soğuk algınlığı
semptomlarını hafiflettiği sonucuna yanlış bir şekilde varırsınız.

Tip I hata yapma olasılığına alfa (α) denir. Anlamlılık seviyeniz veya
alfa (α), Tip I hatası yapma olasılığını temsil eder. Tipik olarak,
anlamlılık seviyesi 0.05 veya% 5 olarak ayarlanır. %5\'lik bir
anlamlılık seviyesi, sıfır hipotezini reddettiğinizde yanıldığınız
olasılığın% 5\'lik bir kabul etmeye istekli olduğunuz anlamına gelir.

##### **Riskinizi azaltın**

Tip I hatası yapma şansınızı azaltmak için, daha düşük bir önem seviyesi
seçin.

Örneğin, Tip I hata riskini en aza indirmek istiyorsanız, standart %5
yerine %1\'lik bir anlamlılık seviyesi seçebilirsiniz. Bu değişiklik Tip
I hata yapma şansını% 5\'ten% 1\'e düşürür.

  **Önemlilik seviyesi (α)**   **Tip I hata yapma şansı**
  ---------------------------- ----------------------------
  0.05                         %5
  0.01                         %1

#### **Tip II hatası**

Bununla birlikte, Tip I hata yapma riskinizi azaltmak, Tip II hatası
veya yanlış negatif yapma olasılığınızın daha yüksek olduğu anlamına
gelir. Aslında yanlış olan bir sıfır hipotezi reddedemediğinizde **Tip
II hatası** oluşur. Başka bir deyişle, sonucunuzun tesadüfen
gerçekleştiği sonucuna varırsınız, ancak aslında olmadı.

Örneğin, klinik çalışmanızda, sıfır hipotez yanlışsa, bu ilacın etkili
olduğu anlamına gelir. Tip II hata yaparsanız ve sıfır hipotezi
reddetmezseniz, ilacın soğuk algınlığı semptomlarını hafiflettiğinde
etkisiz olduğu sonucuna yanlış bir şekilde varırsınız.

Tip II hata yapma olasılığına beta (β) denir ve beta bir hipotez
testinin gücüyle ilişkilidir (güç = 1- β). Güç, bir testin olduğunda
gerçek bir etkiyi doğru bir şekilde tespit edebilme olasılığını ifade
eder.

##### **Riskinizi azaltın**

Testinizin yeterli güce sahip olduğundan emin olarak Tip II hata yapma
riskinizi azaltabilirsiniz. Veri çalışmasında, güç genellikle% 0.80
veya% 80 olarak ayarlanır. İstatistiksel güç ne kadar yüksek olursa, Tip
II hata yapma olasılığı o kadar düşük olur. Gücü artırmak için örneklem
boyutunuzu veya önem seviyenizi artırabilirsiniz.

**Not**: İstatistiksel güç kavramının ayrıntılı bir tartışması bu dersin
kapsamı dışındadır. Güç, kariyerinizde bir veri uzmanı olarak
ilerledikçe ve istatistik bilginizi geliştirdikçe daha fazla
öğreneceğiniz bir şeydir.

#### **Tip I ve Tip II hataların potansiyel riskleri**

Bir veri uzmanı olarak, iki tür veya hatanın yapılmasıyla ilgili
potansiyel risklerin farkında olmak önemlidir.

Tip I hatası, aslında doğru olan bir sıfır hipotezini reddetmek anlamına
gelir. Genel olarak, Tip I hatası yapmak genellikle gereksiz ve etkisiz
olan ve değerli zaman ve kaynakları boşa harcayan değişikliklerin
uygulanmasına yol açar.

Örneğin, klinik deneyinizde Tip I hata yaparsanız, yeni ilaç aslında
etkisiz olmasına rağmen etkili kabul edilecektir. Bu yanlış sonuca
dayanarak, çok sayıda insana etkisiz bir ilaç verilebilir. Ayrıca, diğer
tedavi seçenekleri yeni ilaç lehine reddedilebilir.

Tip II hatası, aslında yanlış olan bir sıfır hipotezini reddetmemek
anlamına gelir. Genel olarak, Tip II hata yapmak, olumlu değişim ve
yenilik için kaçırılan fırsatlara neden olabilir. İnovasyon eksikliği
insanlar ve kuruluşlar için maliyetli olabilir.

Örneğin, klinik deneyinizde Tip II hatası yaparsanız, yeni ilaç
gerçekten etkili olmasına rağmen etkisiz olarak kabul edilecektir. Bu,
yararlı bir ilacın bundan yararlanabilecek çok sayıda insana
ulaşamayabileceği anlamına gelir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Bir veri uzmanı olarak, hipotez testinde yer alan olası hataların ve
sonuçlarınızı nasıl etkileyebileceğinin farkında olmanıza yardımcı olur.
Özel duruma bağlı olarak, Tip I veya Tip II hata riskini en aza
indirmeyi seçebilirsiniz. Sonuçta, analizinizin hedeflerine göre hangi
tür hataların daha riskli olduğunu belirlemek bir veri uzmanı olarak
sizin sorumluluğunuzdadır.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

Tip I ve Tip II hataları hakkında daha fazla bilgi edinmek için
aşağıdaki kaynaklara bakın:

-   Sim [ply Psychology\'nin bu
    makal](https://www.simplypsychology.org/type_I_and_type_II_errors.html)
    esi, Tip I ve Tip II hataları arasındaki farkların yararlı bir
    özetini içermektedir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Verilerin istatistiksel önemi olup olmadığını belirleyin
:::

::: {.cell .markdown}
Son zamanlarda, **istatistiksel anlamlılığın**, bir testin veya deneyin
sonuçlarının yalnızca tesadüfen açıklanamayacağı iddiası olduğunu
öğrendiniz. Bir hipotez testi, gözlemlenen verilerinizin istatistiksel
olarak anlamlı mı yoksa muhtemelen tesadüfen mi olduğunu belirlemenize
yardımcı olabilir. Örneğin, yeni bir ilacın klinik denemesinde, bir
hipotez testi, ilacın bir örnek grubu üzerindeki olumlu etkisinin
istatistiksel olarak anlamlı olup olmadığını veya tesadüfen kaynaklanıp
kaynaklanmadığını belirlemeye yardımcı olabilir.

Bu okumada, istatistiksel anlamlılık kavramı ve hipotez testindeki rolü
hakkında daha fazla bilgi edineceksiniz.

### Hipotez testinde istatistiksel anlamlılık

Veri uzmanları, değişkenler arasındaki bir ilişkinin veya gruplar
arasındaki farkın istatistiksel olarak anlamlı olup olmadığını
belirlemek için hipotez testini kullanır.

Hipotez testinde istatistiksel anlamlılığın rolünü daha iyi anlamak için
bir örneği inceleyelim.

#### **Örnek: Ortalama pil ömrü**

Bir hipotez testi yürütme adımlarını gözden geçirelim:

1.  Sıfır hipotezi ve alternatif hipotezi belirtin.

2.  Bir önem seviyesi seçin.

3.  P değerini bulun.

4.  Sıfır hipotezini reddedin veya reddetmeyi başaramayın.

Bir bilgisayar şirketi için çalışan bir veri uzmanı olduğunuzu hayal
edin. Şirket, en çok satan dizüstü bilgisayarlarının ortalama pil
ömrünün 0.5 saat standart sapma ile 8.5 saat olduğunu iddia ediyor. Son
zamanlarda, mühendislik ekibi pil ömrünü uzatmak için dizüstü
bilgisayarı yeniden tasarladı. Ekip, yeniden tasarlanmış 40 dizüstü
bilgisayardan rastgele bir örnek alıyor. Örnek ortalaması 8.7 saattir.

Ekip, ortalama pil ömründeki artışın istatistiksel olarak anlamlı olup
olmadığını veya rastgele bir şansa bağlı olup olmadığını belirlemenizi
ister. Öğrenmek için bir z testi yapmaya karar verdiniz.

#### **Adım 1: Sıfır hipotezi ve alternatif hipotezi belirtin**

Sıfır hipotezi tipik olarak gözlemlenen verilerinizin tesadüfen meydana
geldiğini varsayar ve istatistiksel olarak anlamlı değildir. Bu durumda,
sıfır hipoteziniz, dizüstü bilgisayar popülasyonunda ortalama pil ömrü
üzerinde gerçek bir etkisi olmadığını söylüyor.

Alternatif hipotez tipik olarak gözlemlenen verilerinizin tesadüfen
*oluşmadığını* ve istatistiksel olarak anlamlı olduğunu varsayar. Bu
durumda, alternatif hipoteziniz dizüstü bilgisayar popülasyonunda
ortalama pil ömrü üzerinde bir etkisi olduğunu söylüyor.

Bu örnekte, aşağıdaki hipotezleri formüle edersiniz:

-   **H** 0: μ = 8.5 (yeniden tasarlanan tüm dizüstü bilgisayarların
    ortalama pil ömrü 8,5 saate eşittir)

-   **H** a**:** μ \> 8.5 (yeniden tasarlanan tüm dizüstü
    bilgisayarların ortalama pil ömrü 8,5 saatten fazladır)

#### **Adım 2: Bir önem seviyesi seçin**

An **lamlılık seviyesi** veya alfa (α), bir sonucu istatistiksel olarak
anlamlı olarak değerlendireceğiniz eşiktir. Anlamlılık seviyesi aynı
zamanda doğru olduğunda sıfır hipotezi reddetme olasılığıdır.

Tipik olarak, veri uzmanları anlamlılık seviyesini 0.05 veya% 5 olarak
ayarlar. Bu, en azından sizinki kadar aşırı sonuçların, sıfır hipotez
doğru olduğunda meydana gelme şansının yalnızca %5\'inin (veya daha az)
olduğu anlamına gelir.

**Not**: %5 geleneksel bir seçimdir ve sihirli bir sayı değildir.
İstatistiksel araştırma ve eğitimdeki geleneğe dayanmaktadır. Diğer
yaygın seçenekler% 1 ve% 10\'dur. Anlamlılık düzeyini analizinizin özel
gereksinimlerini karşılayacak şekilde ayarlayabilirsiniz. Daha düşük bir
anlamlılık seviyesi, bir etkinin istatistiksel olarak anlamlı kabul
edilebilmesi için daha büyük olması gerektiği anlamına gelir.

**Profesyonel ipucu:** En iyi uygulama olarak, sınava başlamadan önce
bir önem seviyesi belirlemelisiniz. Aksi takdirde, sonuçları rahatınıza
uyacak şekilde manipüle ettiğiniz bir duruma girebilirsiniz.

Bu örnekte, şirketin araştırma standardı olan %5\'lik bir anlamlılık
seviyesi seçersiniz.

#### **Adım 3: p değerini bulun**

**P-değeri**, sıfır hipotez doğru olduğunda gözlemlenenlerden daha aşırı
veya daha aşırı sonuçları gözlemleme olasılığını ifade eder.

P değeriniz, bir sonucun istatistiksel olarak anlamlı olup olmadığını
belirlemenize yardımcı olur. Düşük bir p değeri yüksek istatistiksel
anlamlılığı gösterirken, yüksek bir p değeri düşük veya hiç
istatistiksel anlamlılık olmadığını gösterir.

Her hipotez testinin özellikleri:

-   Verilerinizin sıfır hipotezle ne kadar yakından eşleştiğini gösteren
    bir test istatistiği. Z testi için, test istatistiğiniz bir z
    puanıdır; bir t-testi için, bu bir t puanıdır.

-   Sıfır hipotezi doğruysa, gözlenen sonuç kadar en az aşırı bir sonuç
    elde etme olasılığını söyleyen karşılık gelen bir p değeri.

Bir veri uzmanı olarak, Python veya diğer istatistiksel yazılımlar gibi
bir programlama dili kullanarak neredeyse her zaman bilgisayarınızda p
değerini hesaplayacaksınız. Bu örnekte, bir z testi yapıyorsunuz, yani
test istatistiğiniz 2.53\'lük bir z-puanıdır. Bu test istatistiğine
dayanarak, 0,0057 veya% 0,57\'lik bir p değeri hesaplarsınız.

#### **Adım 4: Sıfır hipotezini reddedin veya reddetmeyi başaramayın**

Bir hipotez testinde, sonuçlarınızın istatistiksel olarak anlamlı olup
olmadığına karar vermek için p değerinizi anlamlılık seviyenizle
karşılaştırırsınız.

Bir hipotez testi hakkında bir sonuç çıkarmak için iki ana kural vardır:

-   P değeriniz önem seviyenizden düşükse, sıfır hipotezini
    reddedersiniz.

-   P değeriniz önem seviyenizden büyükse, sıfır hipotezini
    reddedemezsiniz.

**Not: Veri** uzmanları ve istatistikçiler her zaman "kabul etmek"
yerine "reddetme" derler. Bunun nedeni, hipotez testlerinin kesinliğe
değil olasılığa dayanmasıdır - kabul, kesinlik anlamına gelir. Genel
olarak, veri uzmanları istatistiksel yöntemlere dayalı sonuçlar hakkında
kesinlik talep etmekten kaçınırlar.

Bu örnekte, %0,57\'lik p değeriniz% 5\'lik anlamlılık seviyenizden daha
azdır. Testiniz, yeniden tasarlanan tüm dizüstü bilgisayarların ortalama
pil ömrünün 8,5 saatten arttığı sonucuna varmak için yeterli kanıt
sağlar. Sıfır hipotezini reddediyorsunuz. Sonuçlarınızın istatistiksel
olarak anlamlı olduğunu belirlersiniz.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Bir veri uzmanı olarak, bir hipotez testi etkili bir şekilde yürütmek ve
sonuçları yorumlamak için istatistiksel anlamlılık kavramını anlamak
önemlidir. İstatistiksel olarak anlamlı sonuçlara dayanan içgörüler,
paydaşların daha bilinçli iş kararları vermelerine yardımcı olabilir.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

İstatistiksel anlamlılık hakkında daha fazla bilgi edinmek için
aşağıdaki kaynaklara bakın:

-   [Scribbr\"ün bu
    makalesi](https://www.scribbr.com/statistics/statistical-significance/),
    istatistiksel anlamlılığa yararlı bir genel bakış sağlar ve çağdaş
    araştırmalarda kavramın bazı eleştirilerini tartışır..
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Tek kuyruklu ve iki kuyruklu testler
:::

::: {.cell .markdown}
Daha önce, bir hipotez testinin tek kuyruklu veya iki kuyruklu
olabileceğini öğrendiniz. Hipotez testinde bir kuyruk, bir dağılım
eğrisinin her iki ucundaki kuyruğu ifade eder.

Bu okumada, tek kuyruklu ve iki kuyruklu testler arasındaki temel
farkları gözden geçireceğiz ve her testi yürütme prosedürünü
tartışacağız.

### Tek kuyruklu ve iki kuyruklu testler {#tek-kuyruklu-ve-iki-kuyruklu-testler}

İlk olarak, tek kuyruklu ve iki kuyruklu testler arasındaki farkları
tartışalım.

Alternatif hipotez, bir **popülasyon parametresinin gerçek değerinin
sıfır hipotezdeki değerden daha küçük veya daha büyük olduğunu
belirttiğinde tek kuyruklu bir test** ortaya çıkar.

Tek kuyruklu bir test sol kuyruklu veya sağ kuyruklu olabilir.
Alternatif hipotez, parametrenin gerçek değerinin sıfır hipotezdeki
değerden daha az olduğunu belirttiğinde sol kuyruklu bir test ortaya
çıkar. Alternatif hipotez, parametrenin gerçek değerinin sıfır
hipotezdeki değerden daha büyük olduğunu belirttiğinde sağ kuyruklu bir
test ortaya çıkar.

Alternatif hipotez, parametrenin gerçek değerinin sıfır hipotezdeki
değere eşit olmadığını belirttiğinde **iki kuyruklu bir test** ortaya
çıkar.

Örneğin, sıfır hipotezinin bir penguen popülasyonunun ortalama
ağırlığının 30 lbs\'ye eşit olduğunu belirttiği bir test hayal edin.

-   Sol kuyruklu bir testte, alternatif hipotez, penguen popülasyonunun
    ortalama ağırlığının ("\< ") 30 lbs\'den az olduğunu belirtebilir.

-   Sağ kuyruklu bir testte, alternatif hipotez, penguen popülasyonunun
    ortalama ağırlığının ("\>") 30 lbs\'den büyük olduğunu belirtebilir.

-   İki kuyruklu bir testte, alternatif hipotez, penguen popülasyonunun
    ortalama ağırlığının ("≠") 30 lbs\'ye eşit olmadığını belirtebilir.

Tek kuyruklu ve iki kuyruklu testler arasındaki farkı daha iyi anlamak
için daha ayrıntılı bir örneği inceleyelim.

#### **Örnek: Tek kuyruklu testler**

Bir çevrimiçi perakende şirketi için çalışan bir veri uzmanı olduğunuzu
hayal edin. Şirket, müşterilerinin *en az* %80\'inin alışveriş
deneyimlerinden memnun olduğunu iddia ediyor. 100 müşteriden oluşan
rastgele bir örneği araştırıyorsunuz. Ankete göre, müşterilerin% 73\'ü
memnun olduklarını söylüyor. Anket verilerine dayanarak, müşterilerin en
az% 80\'inin memnun olduğu iddiasını değerlendirmek *için* bir z testi
yaparsınız.

Bir hipotez testi yürütme adımlarını gözden geçirelim:

1.  Sıfır hipotezi ve alternatif hipotezi belirtin.

2.  Bir önem seviyesi seçin.

3.  P değerini bulun.

4.  Sıfır hipotezini reddedin veya reddetmeyi başarmayın.

İlk olarak, sıfır ve alternatif hipotezleri belirtirsiniz:

-   **H** 0: P \>= 0.80 (memnun müşterilerin oranı% 80\'den büyük veya
    buna eşittir)

-   **H** a: P \< 0.80 (memnun müşterilerin oranı% 80\'den az)

**Not:** Alternatif hipotez daha az işaretini içerdiğinden bu tek
kuyruklu bir testtir ("\< ").

Ardından, 0.05 veya% 5\'lik bir anlamlılık seviyesi seçersiniz.

Ardından, test istatistiğinize göre p değerinizi hesaplarsınız.
**P-değerinin, sıfır hipotez doğru olduğunda gözlemlenenlerden daha
aşırı veya daha aşırı sonuçları gözlemleme olasılığı olduğunu
hatırlayın.** Hipotez testi bağlamında, "aşırı", alternatif hipotezin
yönünde aşırı anlamına gelir.

Test istatistiğiniz 1,75 z puanıdır ve p değeriniz 0,04\'tür.

Bu sol kuyruklu bir test olduğundan, p değeri z puanının soldaki
ortalamadan 1,75 standart birimden az olma olasılığıdır. Başka bir
deyişle, z puanının -1.75\'ten az olma olasılığıdır. -1.75 z-puanınızdan
daha düşük bir değer alma olasılığı, z-puanının solundaki dağılım
eğrisinin altındaki alan alınarak hesaplanır. Buna sol kuyruklu test
denir, çünkü p değeriniz dağılımın sol kuyruğunda bulunur. Eğrinin bu
bölümünün altındaki alan p değerinizle aynıdır: 0.04.

`<img src="attachment:3f786dd0-6e38-4914-9cab-84aa7feae04a.png" width="400"/>`{=html}

Son olarak, bir sonuç çıkarırsınız. 0.04 p değeriniz 0,05 anlamlılık
seviyenizden az olduğundan, sıfır hipotezini *reddedi* yorsunuz.

**Not:** Farklı bir test senaryosunda, test istatistiğiniz pozitif 1.75
olabilir ve z-puanı 1.75\'ten büyük veya daha büyük değerlerle
ilgilenebilirsiniz. Bu durumda, p değeriniz dağılımın sağ kuyruğunda yer
alacak ve sağ kuyruklu bir test yapıyor olacaksınız.

`<img src="attachment:12c73f1c-5a4e-4e85-8849-5b75dab45593.png" width="400"/>`{=html}

#### **Örnek: İki kuyruklu testler** {#örnek-i̇ki-kuyruklu-testler}

Şimdi, önceki örneğimizin biraz farklı bir kuruluma sahip olduğunu hayal
edin. Şirketin müşterilerinin% 80\'inin alışveriş deneyimlerinden memnun
olduğunu iddia ettiğini varsayalım. Bu iddiayı test etmek için 100
müşteriden oluşan rastgele bir örnekle anket yaparsınız. Ankete göre,
müşterilerin% 73\'ü memnun olduklarını söylüyor. Anket verilerine
dayanarak, müşterilerin %80\'inin memnun olduğu iddiasını değerlendirmek
için bir z testi yaparsınız.

İlk olarak, sıfır ve alternatif hipotezleri belirtirsiniz:

-   **H** 0: P = 0.80 (memnun müşterilerin oranı% 80\'e eşittir)

-   **H** a: P ≠ 0.80 (memnun müşterilerin oranı% 80\'e eşit değil)

**Not:** Alternatif hipotez eşit olmayan işaretini ("≠") içerdiğinden,
bu iki kuyruklu bir testtir.

Ardından, 0.05 veya% 5\'lik bir anlamlılık seviyesi seçersiniz.

Ardından, test istatistiğinize göre p değerinizi hesaplarsınız. Test
istatistiğiniz 1,75 z puanıdır. *Bu iki kuyruklu bir test olduğundan, p
değeri z puanının -1.75\'ten az veya 1.75\'ten büyük olma olasılığıdır.*
İki kuyruklu bir test için *p* değerinin her zaman tek kuyruklu bir test
için *p* -değerinin iki katı olduğuna dikkat edin. Yani, bu durumda, p
değeriniz = 0.04 + 0.04 = 0.08. İki kuyruklu bir testte, p değeriniz
dağılımın hem sol kuyruğundaki *hem de sağ kuyruğ* undaki eğrinin
altındaki alana karşılık gelir.

`<img src="attachment:3a040299-ad04-4dc1-a3cf-fc33405a6925.png" width="400"/>`{=html}

Son olarak, bir sonuç çıkarırsınız. 0.08 p değeriniz 0.05 anlamlılık
seviyenizden büyük olduğundan, sıfır hipotez **ini reddedemez** siniz.

### Tek kuyruklu ve iki kuyruklu

Farklı etkileri incelemek için tek kuyruklu ve iki kuyruklu testleri
kullanabilirsiniz.

Genel olarak, tek kuyruklu bir test, tek bir yönde bir etkiyi tespit
etmek için daha fazla güç sağlayabilir. Bununla birlikte, tek kuyruklu
bir test yapmadan önce, diğer yönde bir etkiyi kaçırmanın sonuçlarını
göz önünde bulundurmalısınız. Örneğin, bir ilaç şirketinin mevcut bir
ilaçtan daha etkili olduğuna inandıkları yeni bir ilaç geliştirdiğini
hayal edin. Klinik çalışmanın sonuçlarını analiz eden bir veri uzmanı
olarak, iyileşmeyi tespit etme yeteneğinizi en üst düzeye çıkarmak için
tek kuyruklu bir test seçmek isteyebilirsiniz. Bunu yaparken, yeni
ilacın mevcut ilaçtan daha az etkili olma olasılığını test edemezsiniz.
Ve elbette, şirket halka daha az etkili bir ilaç yayınlamak istemiyor.

Test edilmemiş yönde bir etkinin kaçırılmasının olumsuz sonuçları
minimum ise, tek kuyruklu bir test uygun olabilir. Örneğin, şirketin en
az mevcut ilaç kadar etkili olduğuna inandıkları yeni, daha ucuz bir
ilaç geliştirdiğini hayal edin. Düşük fiyat, yeni ilaca piyasada bir
avantaj sağlar. Bu nedenle, yeni ilacın mevcut ilaçtan *daha az* etkili
olmadığından emin olmak istiyorlar. *Daha* etkili olup olmadığını test
etmek bir öncelik değildir. Bu durumda, tek kuyruklu bir test uygun
olabilir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Tek kuyruklu ve iki kuyruklu bir test arasındaki farkları anlamak, bir
hipotez testi yürütmenin önemli bir parçasıdır. Analizinizin bağlamına
bağlı olarak, etkileri tek bir yönde incelemek için tek kuyruklu bir
test veya etkileri her iki yöndeki incelemek için iki kuyruklu bir test
kullanmak isteyebilirsiniz.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## A/B testi  {#ab-testi-}
:::

::: {.cell .markdown}
Daha önce, A/B testinin hangi sürümün daha iyi performans gösterdiğini
bulmak için bir şeyin iki versiyonunu karşılaştırmanın bir yolu olduğunu
öğrendiniz. Örneğin, bir veri uzmanı, bir web sayfasının iki sürümünü
veya bir çevrimiçi reklamın iki sürümünü karşılaştırmak için A/B testini
kullanabilir. Ayrıca A/B testinin örnekleme ve hipotez testi gibi
istatistiksel yöntemleri kullandığını öğrendiniz.

Bu okumada, bir A/B testinin genel amacı ve tasarımı ve A/B testinin
verileri analiz etmek için istatistiksel yöntemleri nasıl kullandığı
hakkında daha fazla bilgi edineceksiniz.

### İş bağlamı {#i̇ş-bağlamı}

Veri uzmanları, paydaşların pazarlamayı optimize etmek, geliri artırmak
veya müşteri deneyimini geliştirmek için bir web sitesi veya uygulama
için en iyi tasarımı seçmelerine yardımcı olmak için genellikle A/B
testini kullanır. Uygulamada, A/B testi rastgele bir kullanıcı örneğini
seçmeyi ve bunları iki gruba (A ve B) ayırmayı içerir. İki grup, bir
şirketin web sitesinin farklı versiyonlarını ziyaret eder. Tek bir
tasarım özelliği dışında iki versiyon aynıdır. Örneğin, Grup A\'nın
sürümündeki "Satın Al" düğmesi, Grup B\'nin sürümündeki "Satın Al"
düğmesinden farklı bir boyut, şekil veya renge sahip olabilir. Bir A/B
testi, özellikteki değişikliğin (örneğin, daha büyük bir düğme) belirli
bir metrik için kullanıcı davranışını etkileyip etkilemediğini
belirlemek için istatistiksel analiz kullanır. Bir veri uzmanı,
aşağıdaki metriklerden birini analiz etmek için A/B testi kullanabilir:

-   *Kullanıcı başına ortalama gelir: Bir kullanıcı* bir web sitesi için
    ne kadar gelir elde eder?

-   *Ortalama oturum süresi*: Bir kullanıcı bir web sitesinde ne kadar
    süre kalır?

-   *Tıklama oranı:* Bir kullanıcıya reklam gösterilirse, kullanıcı
    reklamı tıklar mı?

-   *Dönüşüm oranı*: Bir kullanıcıya reklam gösterilirse, bu kullanıcı
    müşteriye dönüşecek mi?

A/B testinin nasıl çalıştığını daha iyi anlamak için bir örneği
inceleyelim.

### Örnek: Kullanıcı başına ortalama gelir

Çevrimiçi bir ayakkabı perakendecisi için çalışan bir veri uzmanı
olduğunuzu hayal edin. Şirket işini büyütmeye çalışıyor ve web sitesinde
kullanıcı başına ortalama geliri araştırıyor. Ekip lideriniz sizden
"Satın Al" düğmesinin boyutunu artırmanın ortalama gelir üzerinde
herhangi bir etkisi olup olmadığını belirlemek için bir A/B testi
yapmanızı ister. Rastgele bir kullanıcı örneği seçersiniz ve onları iki
gruba ayırırsınız, A ve B. Grup A, şirket web sitesinin standart
sürümünü ziyaret eder. B Grubu, daha büyük "Satın Al" düğmesi dışında,
web sitesinin standart sürümüyle aynı olan bir sürümünü ziyaret eder.
Testi çevrimiçi olarak çalıştırır ve örnek verilerinizi toplarsınız.
Sonuçlar, B Grubu için kullanıcı başına ortalama gelirin daha yüksek
olduğunu göstermektedir. Son olarak, ortalama gelirde gözlemlenen farkın
istatistiksel olarak anlamlı olup olmadığını veya şansa bağlı olup
olmadığını belirlemek için iki örnekli bir hipotez testi yaparsınız.

`<img src="attachment:b1a5f964-eca2-434b-8b05-11d655dda87a.png" width="800"/>`{=html}

Tipik bir A/B testi en az üç ana özelliğe sahiptir:

1.  Test tasarımı

2.  Örnekleme

3.  Hipotez testi

Örneğimizi kullanarak her özelliği daha ayrıntılı olarak inceleyelim.

### **Test tasarımı**

İlk olarak, bir A/B testinin temel tasarımını tartışalım.

#### Rastgele kontrollü deney

A/B testi, randomize kontrollü deney olarak bilinen şeyin temel bir
versiyonudur. **Randomize kontrollü bir deneyde, test den** ekleri
rastgele bir kontrol grubuna ve bir tedavi grubuna atanır. **Tedavi**,
deneyde test edilen yeni değişikliktir. **Kontrol** **grubu** tedaviye
maruz kalmaz. **Tedavi grubu** tedaviye maruz kalır. İki grup arasındaki
metrik değerlerdeki fark, tedavinin test denekleri üzerindeki etkisini
ölçer.

**Not**: İdeal olarak, tedaviye maruz kalma iki grup arasındaki tek
önemli farktır. Bu test tasarımı, araştırmacıların test sonuçlarını
etkileyebilecek diğer faktörleri kontrol etmesine ve tedavinin etkisi
hakkında nedensel sonuçlar çıkarmasına olanak tanır.

Örneğimizde, grup A kontrol grubudur, grup B tedavi grubudur ve tedavi
daha büyük bir "Satın Al" düğmesi gösteriyor. Kontrol grubundaki
kullanıcılar (A) şirketin web sitesinin standart sürümünü ziyaret eder.
Tedavi grubundaki kullanıcılar (B) daha büyük bir "Satın Al" düğmesiyle
alternatif bir sürümü ziyaret eder (yani tedaviye maruz kalırlar).
"Satın Al" düğmesinin boyutu dışında A ve B için web sitesi sürümlerini
aynı hale getirerek, ortalama gelirde gözlemlenen herhangi bir farkın
sayfa düzeni veya arka plan gibi diğer özelliklerden kaynaklanma
olasılığını en aza indirirsiniz. Bu, A grubu ve B grubu için kullanıcı
başına ortalama gelirdeki farkı karşılaştırarak daha büyük düğmenin
etkisini ölçmenize olanak tanır.

Randomizasyon veya test deneklerinin kontrol grubuna veya tedavi grubuna
rastgele atanması, diğer faktörlerin deneyin sonucu üzerindeki
potansiyel etkisini kontrol etmeye de yardımcı olur. Uygulamada, bir
kullanıcının "Satın Al" düğmesini tıklayıp tıklamadığını birçok farklı
faktör etkileyebilir. Örneğin, belki de süper zengin kullanıcıların
düğme boyutundan bağımsız olarak genel olarak alışveriş yapma olasılığı
çok daha yüksektir. Tedavi grubunuz *yalnızca* süper zengin
kullanıcılardan oluşuyorsa, geçerli test sonuçları alamazsınız. Ortalama
gelirde gözlemlenen herhangi bir artış, "Satın Al" düğmesinin (test
etmek istediğiniz faktör) daha büyük boyutundan değil, zenginlikten
kaynaklanıyor olabilir. Rastgeleştirme, servet gibi diğer faktörlerin
sonuçlarınızı ortalama olarak önemli ölçüde etkileme olasılığını en aza
indirmeye yardımcı olur.

### Örnekleme {#örnekleme}

Rastgele seçim, genel kullanıcı popülasyonunun özelliklerini yansıtan
temsili bir örnek oluşturmanıza yardımcı olur. Örneğimizde, bu,
çalıştığınız şirketin çevrimiçi müşterilerinin popülasyonudur. A/B
testiniz için temsili bir örnek kullanmak size genellenebilir veya genel
popülasyon için geçerli olan geçerli sonuçlar verecektir.

Ayrıca A/B testinize uygun bir örnek boyutu seçmeniz gerekecektir.
Örneklem büyüklüğü ne kadar büyükse, sonuçlar o kadar kesin olur ve A
grubu ile B grubu arasında bir fark olduğunda istatistiksel olarak
anlamlı sonuçlar elde etme olasılığınız o kadar yüksek. Bununla
birlikte, büyük örneklerle çalışmak pahalı ve zaman alıcı olabilir. Veri
uzmanları, hem analizin amacına hem de mevcut bütçelerine göre örneklem
büyüklüğünü belirler.

### Hipotez testi

Örneğimizin amacı doğrultusunda, çevrimiçi testi çalıştırdığınızı,
verilerinizi topladığınızı ve B grubunun kullanıcı başına A grubundan
daha yüksek bir ortalama gelire sahip olduğunu keşfettiğinizi
varsayalım. B grubunun tedavi grubu olduğunu hatırlayın (daha büyük
"Satın Al" düğmesi) ve A grubunun kontrol grubu olduğunu hatırlayın. Bir
sonraki adım, verilerinizdeki gözlemlenen farkın istatistiksel olarak
anlamlı mı yoksa tesadüfen mi olduğunu belirlemektir. A/B testleri,
istatistiksel anlamlılık hakkında sonuçlar çıkarmak için iki örnekli
hipotez testleri kullanır. Kullanıcı başına ortalama gelirde gözlemlenen
farkın istatistiksel olarak anlamlı olup olmadığını belirlemek için iki
örnekli bir t-testi yaparsınız. Hipotezlerinizi şu şekilde formüle
edersiniz:

-   **H** 0: A ve B arasında kullanıcı başına ortalama gelirde fark
    yoktur

-   **H** a: Kullanıcı başına ortalama gelirde A ve B arasında bir fark
    vardır

### Sonuçlar

T-testinizin sonuçlarına dayanarak, sıfır hipotezini reddediyorsunuz ve
kullanıcı başına ortalama gelirde gözlemlenen artışın istatistiksel
olarak anlamlı olduğu sonucuna varıyorsunuz.

A/B testinizin sonuçları, şirketinizin web sitesi için bir tasarım
değişikliği önerilip önermeyeceğinize karar vermenize yardımcı olur. Bu
durumda, sonuçlarınızı şirket paydaşlarına sunduğunuzda, ileriye dönük
olarak kullanıcı başına ortalama geliri artırmak için daha büyük "Satın
Al" düğmesini uygulamanızı öneriyorsunuz.

### Önemli çıkarımlar {#önemli-çıkarımlar}

A/B testi, iş amaçlı istatistiklerin en popüler uygulamalarından
biridir. Veri uzmanları, iş liderlerinin ürün performansını optimize
etmelerine, müşteri deneyimini iyileştirmelerine ve çevrimiçi işlerini
büyütmelerine yardımcı olmak için A/B testini kullanır. Bir A/B testinin
genel amacını ve tasarımını anlamak, bir veri uzmanı olarak gelecekteki
kariyerinizde faydalı olacaktır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Deneysel Tasarım
:::

::: {.cell .markdown}
Bu kurs boyunca, veri profesyonellerinin bir deneyin sonuçlarının
istatistiksel olarak anlamlı olup olmadığını belirlemek için hipotez
testini nasıl kullandıklarını tartıştık. Önceki senaryolarda, klinik
denemeler ve A/B testleri gibi deneylerin sonuçlarını analiz ettik.
Örneğin, yeni bir ilacın etkinliğini test eden bir klinik çalışma ve bir
web sayfasının tasarımının değiştirilmesinin müşterilerin sayfada
geçirdiği ortalama süreyi nasıl etkilediğini inceleyen bir A/B testi
hayal ettik.

Veri uzmanları genellikle daha önce diğer araştırmacılar tarafından
toplanan deneysel verilerle çalışır. Ancak, belirli bir proje için doğru
veriler her zaman mevcut olmayabilir veya erişilebilir olmayabilir. Bu
durumda, veri uzmanları kendi deneylerini tasarlayabilir ve kendi
verilerini toplayabilir.

Bu okumada, veri profesyonellerinin veri toplamak, hipotezleri test
etmek ve değişkenler arasındaki ilişkileri keşfetmek için deneyleri
nasıl tasarladığını tartışacağız. Deneysel tasarımın temel kavramları ve
prosedürleri hakkında daha fazla bilgi edineceksiniz.

### Bağlam: Deneysel tasarım

**Deneysel tasarım**, araştırma sorunuzu yanıtlamak için veri toplamak
için bir deney planlamayı ifade eder.

Araştırmacılar birçok alanda deneyler yaparlar: tıp, fizik, psikoloji,
üretim, pazarlama ve daha fazlası. Bir deneyin tipik amacı, değişkenler
arasında bir neden-sonuç ilişkisini keşfetmektir. Örneğin, bir veri
uzmanı aşağıdakileri keşfetmek için bir deney tasarlayabilir:

-   Yeni bir ilaç daha hızlı iyileşme süresine yol açar

-   Yeni bir web sitesi tasarımı ürün satışlarını artırır

-   Yeni bir gübre mahsul büyümesini artırır

-   Yeni bir antrenman programı atletik performansı artırır

Deneysel tasarımı anlamak önemlidir, çünkü verilerinizin kalitesini ve
sonuçlarınıza dayanarak çıkardığınız sonuçların geçerliliğini etkiler.
Kötü bir tasarım, şirketler ve tüketiciler için maliyetli olabilecek
geçersiz sonuçlara yol açabilir. Kusurlu bir deneyin sonuçlarına
dayanarak, bir şirket etkisiz olan bir ilaç geliştirmek için yıllarını
harcayabilir veya verimsiz bir üretim sürecine büyük yatırım yapabilir.
İyi tasarlanmış bir deney, araştırma sorunuzu cevaplamanıza yardımcı
olacak güvenilir veriler sağlayacaktır.

Deneysel tasarımı daha iyi anlamak için bir örneği keşfedebilirsiniz.

### Örnek: Klinik deneme {#örnek-klinik-deneme}

Bir ilaç şirketi için çalışan bir veri uzmanı olduğunuzu hayal edin.
Şirket, soğuk algınlığı tedavisi için yeni bir ilaç icat ediyor. Ekip
lideriniz sizden ilacın etkinliğini test etmek için bir deney
tasarlamanızı ister. İlacın alınmasının daha hızlı iyileşme süresine yol
açıp açmadığını öğrenmek istiyorsunuz.

`<img src="attachment:2a31dfc4-f1a9-47ec-ba12-7047a1cec825.png" width="500"/>`{=html}

Bir deney tasarlamanın en az üç temel adımı vardır:

1.  Değişkenlerinizi tanımlayın

2.  Hipotezinizi formüle edin

3.  Test deneklerini tedavi ve kontrol gruplarına atayın

**Not**: Bunlar kontrollü deneyler için geçerli olan temel adımlardır
(daha fazlası aşağıda). Deneysel tasarım karmaşık bir konudur ve daha
ayrıntılı bir tartışma bu dersin kapsamı dışındadır.

Ardından, örneğimizi kullanarak her adımı daha ayrıntılı olarak
inceleyin.

#### **Adım 1: Değişkenlerinizi tanımlayın**

Veri uzmanları genellikle deneylerinde bağımsız ve bağımlı değişkenleri
tanımlayarak başlarlar. Bu, değişkenler arasındaki ilişkiyi
netleştirmeye yardımcı olur.

-   Bağım **sız değişken**, araştırmakla ilgilendiğiniz nedeni ifade
    eder. Bir araştırmacı, bağımlı değişkeni nasıl etkilediğini
    belirlemek için bağımsız değişkeni değiştirir veya kontrol eder.
    "Bağımsız", deneydeki diğer değişkenlerden etkilenmediği anlamına
    gelir.

-   **Bağımlı değişken**, ölçmek istediğiniz etkiyi ifade eder.
    "Bağımlı", değerinin bağımsız değişkenden etkilendiği anlamına
    gelir.

Klinik deneyinizde, ilacın iyileşme süresini nasıl etkilediğini öğrenmek
istiyorsunuz. Bu nedenle:

-   Bağımsız değişkeniniz ilaçtır - araştırmak istediğiniz nedendir.

-   Bağımlı değişkeniniz kurtarma süresidir - ölçmek istediğiniz
    etkidir.

Daha karmaşık bir deneyde, farklı ilaçların iyileşme süresi üzerindeki
etkisini veya aynı ilacın farklı dozlarını test edebilirsiniz. Her
durumda, bağımlı değişkeniniz (iyileşme süresi) üzerindeki etkisini
ölçmek için bağımsız değişkeninizi (ilaç) manipüle edersiniz.

**Not**: Bu sertifika programının ilerleyen kısımlarında, regresyon
analizini tartıştığımızda, bağımsız ve bağımlı değişkenler hakkında daha
ayrıntılı bilgi edinme şansınız olacak.

#### **Adım 2: Hipotezinizi formüle edin**

Bir sonraki adım bir hipotez formüle etmektir. Hipoteziniz, bağımsız ve
bağımlı değişkenleriniz arasındaki ilişkiyi belirtir ve deneyinizin
sonucunu tahmin eder. Daha önce, veri profesyonellerinin istatistiksel
testleri içeren araştırmalar yürütürken hem sıfır hem de alternatif
hipotezler formüle ettiklerini öğrendiniz. Sıfır hipotezinin tipik
olarak popülasyon üzerinde hiçbir etkisi olmadığını varsaydığını ve
alternatif hipotezin tam tersini varsaydığını hatırlayın. Klinik
denemeniz için:

-   Sıfır hipoteziniz (H 0) ilacın hiçbir etkisinin olmadığıdır.

-   Alternatif hipoteziniz (H a) ilacın etkili olduğudur.

#### **Adım 3: Test deneklerini tedavi ve kontrol gruplarına atayın**

##### **Tedavi ve kontrol grupları**

Klinik deneyler ve A/B testleri gibi deneyler kontrollü deneylerdir.
Kontro **llü bir deneyde, den** ekler bir tedavi grubuna ve bir kontrol
grubuna atanır. **Tedavi**, deneyde test edilen yeni değişikliktir.
**Tedavi grubu** tedaviye maruz kalır. **Kontrol grubu** tedaviye maruz
kalmaz. İki grup arasındaki metrik değerlerdeki fark, tedavinin test
denekleri üzerindeki etkisini ölçer.

Klinik denemenizde tedavi, tedavi grubundaki deneklere verilen ilaçtır.
Kontrol grubundaki deneklere ilaç verilmez. Sonuçlarınızın tedavi
grubunda (6.2 gün) ortalama iyileşme süresinin kontrol grubuna (7.5 gün)
göre daha düşük olduğunu gösterdiğini hayal edin. İki grup arasındaki
fark, 7.5 - 6.2 = 1.3 gün, tedavinin etkisini ölçer. Başka bir deyişle,
ilaç ortalama iyileşme süresini 1.3 gün azaltır.

**Not**: Bir veri uzmanı deneylerini tasarladıktan ve çalıştırdıktan
sonra, sonuçları analiz etmek için istatistiksel testleri kullanır. Bir
sonraki adım olarak, iyileşme süresinde gözlemlenen farkın istatistiksel
olarak anlamlı mı yoksa tesadüfen mi olduğunu belirlemek için iki
örnekli bir t testi yapabilirsiniz.

İdeal olarak, tedaviye maruz kalma iki grup arasındaki tek önemli
farktır. Bu tasarım, araştırmacıların test sonuçlarını etkileyebilecek
diğer faktörleri kontrol etmesine ve tedavinin etkisi hakkında nedensel
sonuçlar çıkarmasına olanak tanır.

Örneğin, tedavi grubunuzdaki deneklerin kontrol grubunuzdaki deneklerden
çok daha sağlıklı bir diyete sahip olduğunu hayal edin. Tedavi grubu
için iyileşme süresinde gözlenen herhangi bir azalma, ilaca değil, daha
sağlıklı diyetlerinden kaynaklanıyor olabilir. Bu durumda, ilacın tek
başına daha hızlı iyileşme süresinin *nedeni* olduğunu güvenle
söyleyemezsiniz.

##### **Rastgele**

Tipik olarak, veri uzmanları rastgele test deneklerini tedavi ve kontrol
gruplarına atar. Randomizasyon, diğer faktörlerin bir deneyin sonucu
üzerindeki etkisini kontrol etmeye yardımcı olur. Denekleri tedavi ve
kontrol gruplarına atamak için iki yaygın yöntem, tamamen randomize
tasarım ve randomize blok tasarımıdır.

Tam **amen randomize bir tasarımda**, test denekleri rastgele bir süreç
kullanılarak tedavi ve kontrol gruplarına atanır. Örneğin, bir klinik
denemede, her deneği bir sayı ile etiketlemek için bir bilgisayar
programı kullanabilir ve ardından her grup için rastgele sayılar
seçebilirsiniz.

Ancak bazen tamamen rastgele bir tasarım en etkili yaklaşım olmayabilir.
Bir deney tasarlarken, veri uzmanları rahatsız edici faktörleri hes
**aba katmalıdır.** Bunlar, bir deneyin sonucunu etkileyebilecek, ancak
araştırmacının birincil ilgisini çekmeyen faktörlerdir.

Araştırmacılar, bilinen rahatsız edici **faktörlerin etkisini en aza
indirmek için rastgele bir blok tasarımı** kullanabilirler. **Eng**
elleme, test deneklerinin birbirine benzer gruplar veya bloklar halinde
düzenlenmesidir. Bir blok tasarımında, önce denekleri bloklara
bölersiniz ve ardından her bloktaki denekleri rastgele tedavi ve kontrol
gruplarına atarsınız.

Örneğin, yaşın soğuk algınlığından iyileşme süresinde önemli bir faktör
olduğunu bildiğinizi varsayalım. Özellikle, 35 yaşın altındaki kişilerin
yaşlılardan daha hızlı iyileşme eğiliminde olduğunu biliyorsunuz. Bu
senaryoda, yaş rahatsız edici bir faktördür çünkü deneyinizin
sonuçlarını etkileyebilir. Örneğin, tamamen randomize bir tasarıma ve
daha küçük bir örneklem büyüklüğüne sahip bir klinik çalışmada, tedavi
grubundaki gençlerin büyük bir bölümünü rastgele alabilirsiniz. Bu,
iyileşme süresinde gözlenen herhangi bir azalmanın tedaviden (ilaç) mı
yoksa rahatsız edici faktörden (yaş) mı kaynaklandığını belirlemeyi daha
zor hale getirecektir.

Bu durumda, yaş faktörü için engelleme, deneyinizi tasarlamanın daha
etkili bir yoludur. İlk olarak, test deneklerini 21-35, 36-50 ve 51-65
gibi yaşa göre bloklara ayırırsınız. Daha sonra, her bloktaki denekleri
rastgele tedavi ve kontrol gruplarına atarsınız. Bu şekilde, belirli bir
blok içinde iyileşme süresinde önemli bir fark varsa, bu sonucun
rahatsız edici faktörden (yaş) değil tedaviden (ilaç) kaynaklandığından
daha emin olabilirsiniz.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Veri uzmanları, deneyleri planlamak ve araştırma sorularını cevaplamaya
yardımcı olan verileri toplamak için deneysel tasarımı kullanır. Bir
deneyin tasarımı, verilerinizin kalitesini ve sonuçlarınızın
geçerliliğini etkiler. İster kendi deneyinizi tasarlıyor olun, ister
başkaları tarafından toplanan verileri kullanıyor olun, deneysel
tasarımın temel ilkelerini anlamak önemlidir. Bu bilgi, klinik
denemeler, A/B testleri ve daha fazlası gibi deneylerden elde edilen
verileri analiz etmenize yardımcı olacaktır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Örnek olay incelemesi: Ipsos: Bir pazar araştırması şirketi, reklamverenlerin daha etkili reklamlar oluşturmasına yardımcı olmak için A/B testini nasıl kullandı?  {#örnek-olay-incelemesi-ipsos-bir-pazar-araştırması-şirketi-reklamverenlerin-daha-etkili-reklamlar-oluşturmasına-yardımcı-olmak-için-ab-testini-nasıl-kullandı-}
:::

::: {.cell .markdown}
Daha önce, A/B testinin hangi sürümün daha iyi performans gösterdiğini
bulmak için bir şeyin iki versiyonunu karşılaştırmanın bir yolu olduğunu
öğrendiniz. Örneğin, bir veri uzmanı, bir web sayfasının iki sürümünü
veya bir çevrimiçi reklamın iki sürümünü karşılaştırmak için A/B testini
kullanabilir. Ayrıca A/B testinin örnekleme ve hipotez testi gibi
istatistiksel yöntemleri kullandığını öğrendiniz. Bu vaka çalışması,
Ipsos\'un iki farklı çevrimiçi reklam biçimini karşılaştırmak için A/B
testini nasıl kullandığını açıklamaktadır: sıralı bir anlatıda sunulan
reklamlar ve birden çok kez sunulan geleneksel 30 saniyelik bir reklam.
Veri odaklı pazar araştırmasının, farklı reklam biçimlerinin bir dijital
reklam kampanyasının etkinliği üzerindeki etkisine ilişkin önemli
bilgileri nasıl ortaya çıkardığını öğreneceksiniz.

`<img src="attachment:fbba95a2-c668-46cd-a940-47c6e5eb7c68.png" width="500"/>`{=html}

### Şirket geçmişi

Ipsos tam hizmet sunan bir pazar araştırma şirketidir. 1975 yılında
Fransa\'da kurulan Ipsos, şu anda 90 ülkede faaliyet gösteren 18.000
personeli ile küresel bir şirkettir. Ipsos, çok sayıda özel ve kamu
sektörü alanında araştırma hizmetleri sunmaktadır. Bu hizmetler arasında
marka oluşturma; reklam etkinliği; ürün geliştirme; itibar; müşteri ve
kullanıcı deneyimi; ve kamuoyu, seçim ve kriz yönetimi yer alır. Ipsos,
araştırmaları için birincil veri toplamadan sosyal dinleme, mobilite ve
uydu görüntülerine kadar veri kaynaklarının bir kombinasyonunu kullanır.

`<img src="attachment:fe7ec4b9-7911-49b3-be92-fd0561dd1550.png" width="700"/>`{=html}

### Proje arka planı

Ipsos\'un bu proje için müşterisi, kullanıcıların kendi video
içeriklerini yayınlamalarına izin veren bir çevrimiçi medya şirketiydi.
Medya şirketi kendi müşterilerine - platformlarındaki reklamverenlere -
en etkili reklamları oluşturmalarına yardımcı olmak istedi. Özellikle,
sıralı reklamlara yatırım yapmanın izleyicilerin bir reklamı hatırlama
ve bir ürün satın alma olasılığını artırıp artırmayacağını öğrenmek
istediler. Video reklam sıralaması, reklamverenlerin reklamları en ilgi
çekici ve akılda kalıcı hikaye yapılarına göre bir sırayla
göstermelerini sağlar. Medya şirketi, beş farklı dizi yapısının marka
kaldırma üzerindeki etkisini ölçmek için araştırma yapması için Ipsos\'u
görevlendirdi.

**Not**: Bu vaka çalışmasının amacı doğrultusunda, yalnızca bir dizi
yapısına odaklanacağız: Tease, Amplify, Echo. Bu dizi, izleyicilerin
merakını uyandırmak için kısa bir reklamla başlar (Tease); daha sonra
izleyici etkileşimini sağlamak için daha fazla bilgi içeren daha uzun
bir reklama geçer (Amplify); son olarak, hikayeyi özetleyen ve
izleyicileri harekete geçmeye teşvik eden daha kısa bir reklamla sona
erer (Echo).

`<img src="attachment:f7d4b748-3c7d-4ac9-aa45-d99983c5592b.png" width="500"/>`{=html}

Graph with three overlapping curves represents the structure of the
Tease, Amplify, Echo ad sequence: first, short video; second, long
video; third, short video.

### Proje çerçevesi

Ipsos, projelerine rehberlik etmek için şu araştırma sorusunu
geliştirdi: Tease, Amplify, Echo yapısına sahip bir reklam dizisi,
geleneksel 30 saniyelik bir reklamın tekrarlanan görüntülemelerine
kıyasla reklam hatırlama ve satın alma niyetini artırıyor mu?

Ipsos\'un ilk hipotezi, sıralı bir anlatıda sunulan reklamların
geleneksel bir reklamın tekrarlanan görüntülemelerinden daha etkili
olacağıydı. Bu iki reklam yaklaşımı için bu hipotezi test etmek için
Ipsos bir A/B testi yaptı. A/B testi iki kullanıcı grubu için bir deney
oluşturdu: bir gruba Tease, Amplify, Echo reklamları gösterildi ve diğer
gruba birçok kez geleneksel bir reklam gösterildi. Her durumda, farklı
reklam biçimleri aynı marka içeriğine dayanıyordu. Aşağıda test
sürecinin ayrıntıları hakkında daha fazla bilgi edineceksiniz.

### Zorluklar

Projenin başlangıcında, Ipsos iki ana zorluğu belirledi. İlk zorluk A/B
testinin uygun şekilde tasarlanmasını içeriyordu. İkinci zorluk, test
reklamlarını uygun test ortamında oluşturmayı içeriyordu.

#### **Test tasarımı** {#test-tasarımı}

Ipsos\'un birincil kaygısı, A/B testinin sonuçlarının genellenebilir
olması veya medya şirketinin kullanıcılarının genel nüfusu için geçerli
olmasıydı. Başka bir deyişle, Ipsos, daha küçük test katılımcıları
örneklemine dayalı olarak daha büyük kullanıcı popülasyonu hakkında
geçerli çıkarımlar yapmak istedi. Geçerli test sonuçları elde etmek için
Ipsos\'un aşağıdakileri yapması gerekiyordu;

1.  Medya şirketinin kullanıcılarının genel popülasyonunu yansıtan
    temsili bir test katılımcısı örneği oluşturun.

2.  Medya şirketinin çevrimiçi ortamını yansıtan bir çevrimiçi test
    ortamı oluşturun. Bu aynı zamanda medya şirketinin platformunda yer
    alan reklamların çeşitliliğini yeniden üretmek için birden fazla
    markadan test reklamları oluşturmayı da ima etti.

### Yaklaşım

Bu zorluklara rağmen, Ipsos A/B testini gerçekleştirdi ve araştırma
hedeflerine ulaştı. Ipsos\'un projelerine yönelik başarılı yaklaşımı
aşağıdaki unsurları içeriyordu:

-   Takım

-   Örnekleme

-   Test süreci

-   Hipotez testi

#### **Takım**

Etkili bir ekip oluşturmak için Ipsos, gerçekçi bir çevrimiçi test
ortamı oluşturmak için Tease, Amplify, Echo yapısına ve teknolojiye
dayalı test reklamları oluşturmak için video prodüksiyonu da dahil olmak
üzere işlevler arası bir operasyon oluşturdu.

Proje katılımcıları arasında işbirliğini kolaylaştırmak için Ipsos, net
bir dizi düzenleme kuralı belirledi ve videolara bağlantılar barındırmak
ve notları düzenlemek için paylaşılan bir site düzenledi. Bu, geliştirme
süreci boyunca hızlı geri bildirim ve ayarlamaya izin verdi. Son olarak,
Ipsos, proje tasarımının ve iş akışının başından sonuna kadar yönetilen
üst düzey müşteri hizmetleri proje yöneticilerine sahipti ve bunları
izledi.

#### **Örnekleme** {#örnekleme}

Ipsos, genel kullanıcı popülasyonunun özelliklerini doğru bir şekilde
yansıtan temsili bir örnek oluşturmak için tüketici panellerinden
rastgele seçim yaptı. Ipsos ayrıca, her test grubunun yaş ve cinsiyet
gibi kilit kategoriler için aynı katılımcı oranını içerdiğinden emin
oldu. Ayrıca, Ipsos, daha kesin sonuçlar elde etmek için nispeten büyük
bir 7.500 katılımcıdan oluşan bir örneklem büyüklüğü kullandı.

#### **Test süreci**

Geçerli test sonuçları elde etmek için Ipsos, katılımcıların medya
şirketinin platformunu günlük yaşamlarında olduğu gibi kullandıkları
çevrimiçi bir ortamda A/B testi gerçekleştirdi. Platformdaki reklam
çeşitliliğini yansıtmak için Ipsos, uçak biletlerinden fast food\'a ve
çamaşır deterjanına kadar 30 marka kategorisinde test reklamları
geliştirdi.

Test süreci aşağıdaki şekilde organize edildi:

Anketler, katılımcıların akıllı telefonları aracılığıyla Kasım ve Aralık
2018\'de çevrimiçi olarak yönetildi. İlk taramadan sonra, katılımcılar
normalde yaptıkları gibi videoları aramakta ve izlemekte özgür oldukları
platformun tarayıcı tabanlı bir sürümüne götürüldü. Ipsos, canlı test
ortamında yanıtlayanlar tarafından seçilen videoların başına dinamik
olarak test reklamları ekledi. Göz atma oturumundan sonra yanıtlayanlar,
reklam geri çağırma ve ürün amacı açısından marka artışını ölçmek üzere
bir anket tamamladı.

#### **Hipotez testi** {#hipotez-testi}

Anket verileri, Tease, Amplify, Echo reklam dizisinin, yanıtlayanlar
arasında geleneksel bir reklamın tekrarlanan görüntülemelerine göre daha
yüksek düzeyde reklam hatırlama ve satın alma niyetine yol açtığını
gösterdi. Gözlemlenen sonuçların istatistiksel olarak anlamlı olup
olmadığını belirlemek için Ipsos, her kategori için iki örnekli bir t
testi gerçekleştirdi: biri reklam geri çağırma ve diğeri satın alma
amacı için. Hipotezlerini şu şekilde formüle ettiler:

-   **H** 0: Sıralı reklamlar ile tekrarlanan geleneksel reklam arasında
    reklam hatırlamada fark yoktur.

-   **H** a: Sır alı reklamlar ile tekrarlanan geleneksel reklam
    arasında reklam geri çağırma amacında bir fark vardır.

-   **H** 0: Sıralı reklamlar ile tekrarlanan geleneksel reklam arasında
    satın alma niyetinde bir fark yoktur.

-   **H** a: Sır alı reklamlar ile tekrarlanan geleneksel reklam
    arasında satın alma niyetinde bir fark vardır.

Her iki test için de Ipsos sıfır hipotezini reddetti. Sıralı reklamlar
ile tekrarlanan geleneksel bir reklam arasında reklam geri çağırma ve
satın alma niyetinde istatistiksel olarak anlamlı ve önemli ölçüde
anlamlı farklılıklar olduğu sonucuna vardılar..

### Sonuçlar {#sonuçlar}

A/B testinin sonuçları, reklam sıralamanın işe yaradığını gösterdi!

Tease, Amplify, Echo reklam dizisi, reklam geri çağırma ve satın alma
niyeti üzerinde geleneksel bir reklamın tekrarlanan görüntülemelerine
göre önemli ölçüde daha büyük bir etkiye sahipti. Örneğin, tüm ürün
kategorilerinde, izleyicilerin %54\'ü "Tease, Amplify, Echo" dizisine
maruz kaldıktan sonra reklamı hatırladı ve tekrarlanan geleneksel
reklamlarda %42\'ye kıyasla. Ayrıca, izleyicilerin %30\'u "Tease,
Amplify, Echo" reklam dizisine maruz kaldıktan sonra satın alma niyetini
ifade ederken, tekrarlanan geleneksel reklamlarda %25\'e kıyasla.

`<img src="attachment:347078c6-aacd-4fec-ab23-96f7d244ee8d.png" width="500"/>`{=html}

Tekrarlanan 30 saniyelik bir reklamla karşılaştırıldığında Tease,
Amplify, Echo reklam dizisi için reklam hatırlama ve satın alma
amacındaki artışı gösteren çubuk grafik.

Genel olarak, sonuçlar, reklamverenlerin marka artışını artırmak için
dijital kampanyaları için reklam sıralamasına yatırım yapmaları
gerektiğini göstermektedir.

### Sonuç

Ipsos\'un A/B testine ilişkin bu vaka çalışması, veri odaklı
araştırmanın temel iş içgörüleri üretme gücünü göstermektedir. A/B
testinin sonuçları, reklam sıralamasının geleneksel bir reklamın
tekrarlanan görüntülemelerine kıyasla reklam geri çağırma ve satın alma
amacını nasıl artırdığını açıkça göstermektedir. Ipsos\'un reklam
sıralamasının faydaları üzerine yaptığı araştırma, medya şirketinin
reklamverenlerin platformlarındaki deneyimini ve performansını
iyileştirmesine ve medya şirketinin markasına değer katmasına yardımcı
oldu.

### Kaynaklar

Bu vaka çalışmasına ilham veren araştırma projesi hakkında daha fazla
bilgi edinmek için aşağıdaki kaynakları keşfedin:

-   Th [ink With Google\'ın bu web
    sitesi](https://www.thinkwithgoogle.com/feature/youtube-ad-sequencing-and-ad-recall/ad-sequencing?lang=en_US),
    araştırma projesinde yer alan beş sıralama yapısını sergiliyor.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## State21 ve State28 için filtreleme ve okuma yazma oranlarının ttest ve p değerini inceleme
:::

::: {.cell .markdown}
``` python
import pandas as pd 
from scipy import stats

education_districtwise = pd.read_csv("../Datasets/education_districtwise.csv") 
education_districtwise = education_districtwise.dropna()

state21 = education_districtwise[education_districtwise['STATNAME'] == "STATE21"]

state28 = education_districtwise[education_districtwise['STATNAME'] == "STATE28"]

sampled_state21 = state21.sample(n=20, random_state=13490, replace = True) 

sampled_state28 = state28.sample(n=20, random_state=39103, replace True)

sampled_state21['OVERALL_LI'].mean()
70.82900000000001

sampled_state28['OVERALL_LI'].mean()
64.60100000000001

sampled_state21['OVERALL_LI'].mean() - sampled_state28['OVERALL_LI'].mean()
6.2

stats.ttest_ind(a=sampled_state21['OVERALL_LI'], b=sampled_state28['OVERALL_LI'].mean(), equal_var=False)
```

`<img src="attachment:b3d9690a-22a7-44d5-b203-4d51eff30da1.png" width="900"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
# 5 Regresyon Analizi {#5-regresyon-analizi}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Sıradan en küçük kareleri keşfedin
:::

::: {.cell .markdown}
Daha önce de belirtildiği gibi, regresyon modellemesinde en uygun
çizgiyi bulmanın bir yolu, en iyisini bulana kadar farklı modelleri
denemektir. Ancak basit doğrusal regresyon için, en iyi beta
katsayılarının formülleri türetilmiştir. Bu okumada, kareli artıkların
toplamının nasıl değişebileceğini ve değişebileceğini daha iyi anlamak
için bir örnekten geçeceksiniz. Sıradan en küçük kareler kullanarak β\^0
ve β\^​1​ katsayıları tahmin etmek için formülleri türetmekle
ilgileniyorsanız, daha fazla araştırma için kaynaklar olacaktır. Bu
okumada şunları ele alacağız:

-   Formül ve notasyon incelemesi

-   Kare artıkların toplamını en aza indirmek (SSR)

-   Beta katsayılarının tahmin edilmesi

### Formül ve notasyon incelemesi

Daha önce, sürekli bir bağımlı değişken ile bir bağımsız değişken
arasındaki doğrusal ilişkiyi tahmin etmek için bir yöntem olarak basit
doğrusal regresyonu öğrendiniz. Basit doğrusal regresyona dayalı bir
tahmin matematiksel olarak şu şekilde temsil edilebilir:

`<img src="attachment:043d4f20-af30-4a2e-ae8d-ebe21debc96c.png" width="200"/>`{=html}

Şapka sembolünün beta katsayılarının sadece tahmin olduğunu gösterdiğini
unutmayın. Sonuç olarak, regresyon modelinden türetilen y değerleri de
sadece tahminlerdir.

Doğrusal regresyon modelinin katsayılarını hesaplamak için yaygın bir
teknik, sıradan en küçük kareler veya OLS olarak adlandırılır. Sıradan
en küçük kareler, artıkların karesi toplamı adı verilen bir hata
ölçüsünü en aza indirerek doğrusal bir regresyon modelinde beta
katsayılarını tahmin eder.

Bu formülle kareli artıkların toplamını hesaplayabilirsiniz:

`<img src="attachment:5ef45ff5-f226-4ab7-a82b-3aed61a63451.png" width="400"/>`{=html}

matematiksel gösterim kullanılarak yeniden yazılabilir:

`<img src="attachment:cee8c2de-18f0-49f2-94b9-521c2dfef739.png" width="400"/>`{=html}

Büyük E şeklindeki sembol, büyük Yunan harfi olan sigma\'dır ve bir
toplamı ifade eder. Dolayısıyla, kareli artıkların toplamı, gözlemlenen
değerler ile regresyon modeli tarafından tahmin edilen değerler
arasındaki kare farkların toplamıdır.

### Kare artıkların toplamını en aza indirmek (SSR)

Bu okumanın amaçları doğrultusunda, 6 gözlemden oluşan bir veri kümesine
sahip olduğunuzu varsayın: (0, -1), (1, 2), (2, 4), (3, 8), (4, 11) ve
(5, 12). Bunlar 2 boyutlu X-Y koordinat düzleminde çizilebilir.

  **X (gözlemlendi)**   **Y (gözlemlendi)**
  --------------------- ---------------------
  0                     -1
  1                     2
  2                     4
  3                     8
  4                     11
  5                     12

`<img src="attachment:15471e94-012d-4006-9add-7d0cb3da27dc.png" width="600"/>`{=html}

`Satır 1: y^=−0.5+3x`

Ardından, bazı değerleri varsayalım β\^​0​ β\^​1​ ve kareli artıkların
toplamını hesaplayalım. İlk deneme için, varsayalım β\^0​=−0.5 ve β\^​1​=3.
O zaman doğrusal denklem olacaktır y\^=−0.5+3x. Artık denklemin olduğu
için y, her bir değeri koyarak tahmin edilen değerleri
hesaplayabilirsiniz.

Örneğin, eğer x=0, o zaman y\^=−0.5+3∗0=−0.5. Eğer x=1, o zaman
y\^=−0.5+3∗1=2.5. Böylece, tahmin edilen tüm değerleri hesapladıktan
sonra, her veri noktası için kalıntıyı hesaplayabilirsiniz.

  X (gözlemlendi)   Y (güncel)   Y (tahmin edilen) = -0.5 + 3x   Kalıntı
  ----------------- ------------ ------------------------------- -----------------------------
  0                 -1           -0.5                            -1 - (-0,5) = -1+0,5 = -0,5
  1                 2            2.5                             2 - 2,5 = -0,5
  2                 4            5.5                             4 - 5.5 = -1.5
  3                 8            8.5                             8 - 8.5 = -0.5
  4                 11           11.5                            11 - 11.5 = -0.5
  5                 12           14.5                            12 - 14.5 = -2.5

Ardından, artıkların her birini kendileriyle çarparak ve ardından
artıkların karesinin toplamını hesaplamak için hepsini bir araya
getirebilirsiniz.

  Kalıntı                       Kare Kalıntı
  ----------------------------- --------------
  -1 - (-0,5) = -1+0,5 = -0,5   0.5
  2 - 2,5 = -0,5                0.5
  4 - 5.5 = -1.5                2.25
  8 - 8.5 = -0.5                0.5
  11 - 11.5 = -0.5              0.5
  12 - 14.5 = -2.5              6.25

Kalıntıların karesi toplamı = 0.25+0.25+2.25+0.25+0.25+6.25=9.5

`Satır 2: y^=−0.5+2.5x`

Ardından, önceki örnekteki eğimi ayarlayalım. Yani β\^0=−0.5 ama
β\^1=2.5. O zaman doğrusal denklem y\^=−0.5+2.5x olacaktır. Tahmin
edilen değerleri hesaplamak x ve artıkları karesini almak için son
seferki gibi değerleri ekleyebilirsiniz.

  ---------------------------------------------------------------------------
  X (gözlemlendi) Y (güncel)     Y (tahmin      Kalıntı        Kare
                                 edilen) =                     Kalıntılar
                                 -0.5 + 2.5x                   
  --------------- -------------- -------------- -------------- --------------
  0               -1             -0.5           -0.5           0.25

  1               2              2              0              0

  2               4              4.5            -0.5           0.25

  3               8              7              1              1

  4               11             9.5            1.5            2.25

  5               12             12             0              0
  ---------------------------------------------------------------------------

Kalıntıların karesi
toplamı=0.25+0+0.25+1+2.25+0=3.75=0.25+0+0.25+1+2.25+0=3.75.

Harika! Bu tahmin çok daha iyi!

### Beta katsayılarının tahmin edilmesi

Eğimi ve kesişmeyi ayarlamaya devam edebilir ve ardından tahmin edilen
değerleri, artıkları ve kareli artıkları hesaplamaya devam
edebilirsiniz. Ancak en uygun çizgiyi bulduğunuzdan emin olmanın hiçbir
yolu yok. Gelişmiş matematik yoluyla, hatayı en aza indiren beta
katsayılarını bulmak için bazı formüller türetilmiştir.

Beta katsayılarını bulmak için formülleri yazmanın birden fazla yolu
vardır. Basit doğrusal regresyon için, formülleri yazmanın bir yolu
aşağıdaki gibidir:

`<img src="attachment:01154b9d-5ff8-4b69-95d5-26e30fb52a70.png" width="400"/>`{=html}

Bir bilgisayardan yardım almadan beta katsayılarını hesaplamanız
istenmeyecek, ancak isterseniz keşfetmek ilginç olabilir. İlgilenmeniz
durumunda ek kaynaklar sağladık.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Bir veri örneği verildiğinde, verilerinize uyabilecek farklı satırları
deneyebilirsiniz. Hangisinin verilerinize en uygun olduğunu belirlemek
için her satır için kareli artıkların toplamını hesaplayabilirsiniz. Bir
veri uzmanı olarak, kareli artıkların toplamının neyi temsil ettiğini ve
bunu kendi başınıza nasıl hesaplayacağınızı anlamak önemlidir. Neyse ki,
artıkların karesini hesaplayabilen ve bizim için OLS gerçekleştirebilen
bilgisayarlarımız ve programlama dillerimiz var. İsterseniz OLS ve
SSR\'nin arkasındaki daha derin matematiği kendi başınıza
keşfedebilirsiniz!

### Kaynaklar {#kaynaklar}

-   [Parametre Tahmini - Sıradan En Küçük Kareler
    Yön](https://www.geo.fu-berlin.de/en/v/soga-py/Basics-of-statistics/Linear-Regression/Simple-Linear-Regression/Parameter-Estimation/index.html)
    [*temi:* *Rudolph, A., Krois, J., Hartmann, K. (2023): Python
    (SOGA-py) kullanarak İstatistik ve Coğrafi Veri Analiz*
    *i.*](https://www.geo.fu-berlin.de/soga-py) *Yer Bilimleri Bölümü,
    Freie Universitaet Berlin*.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Korelasyon ve basit doğrusal regresyonun arkasındaki sezgi
:::

::: {.cell .markdown}
Şimdiye kadar basit doğrusal regresyonun bir bağımsız değişken olan X
ile bir sürekli bağımlı değişken Y arasındaki doğrusal ilişkiyi tahmin
eden bir teknik olduğunu öğrendiniz, ayrıca regresyon çizgisinin
katsayılarını, veriler aracılığıyla "en iyi uyum" çizgisini belirlemenin
yaygın bir yolu olan sıradan en küçük kareler tahminini (OLS)
öğrendiniz. Bu okumada, korelasyonun anlamını keşfedeceksiniz; *r* veya
"korelasyon katsayısı" hakkında bilgi edineceksiniz; ve regresyon
denkleminin nasıl belirleneceğini keşfedeceksiniz. Bu bilgi, değişkenler
arasındaki ilişkileri ve dolayısıyla doğrusal regresyonun nasıl
çalıştığını daha iyi anlamanıza yardımcı olacaktır.

### **Korelasyon**

Korelasyon, iki değişkenin birlikte hareket etme şeklinin bir ölçümüdür.
Değişkenler arasında güçlü bir korelasyon varsa, birini bilmek diğerini
tahmin etmek için çok yardımcı olacaktır. Bununla birlikte, iki değişken
arasında zayıf bir korelasyon varsa, birinin değerini bilmek size
diğerinin değeri hakkında fazla bir şey söylemeyecektir. Doğrusal
regresyon bağlamında korelasyon *doğrusal korelasyonu* ifade eder: bir
değişken değiştikçe, diğeri de sabit bir oranda değişir.

İstatistik kursunda, sürekli bir değişkenin bazı temel sayılar
kullanılarak özetlenebileceğini öğrendiniz. Bu özet istatistiklerden
ikisi şunlardır:

-   **Ortalama:** Merkezi eğilimin bir ölçümü (ortalama, medyan veya
    mod)

-   **Standart sapma:** Yayılma ölçümü

İki değişken birlikte özetlendiğinde, ***r*** adı verilen başka bir
ilgili istatistik vardır, **Pearson korelasyon katsayısı** (adını
geliştirmeye yardımcı olan kişinin adını alır) veya basitçe doğrusal
**korelasyon katsayısı**. Korelasyon katsayısı, iki değişken arasındaki
doğrusal ilişkinin gücünü ölçer. Her zaman \[-1, 1\] aralığına düşer.
*R* negatif olduğunda, değişkenler arasında negatif bir korelasyon
vardır: biri arttıkça diğeri azalır. *R* pozitif olduğunda, değişkenler
arasında pozitif bir korelasyon vardır: biri arttıkça diğeri de artar.
*r* = 0 olduğunda, değişkenler arasında *doğrusal* bir korelasyon
yoktur. Bir değişkenin bir diğeri tarafından kesin olarak
belirlenebileceği durumlar olduğuna dikkat edin - y=x 2 veya y=sin (x)
gibi - ancak X ve Y arasındaki *doğrusal korelasyonun değerinin,
ilişkileri doğrusal* olmadığı için yine de düşük veya sıfır olacaktır.

Aşağıdaki şekil, her değişkenin aynı ortalama ve standart sapmaya sahip
olduğu ve yalnızca korelasyon katsayısının değiştiği iki değişkenli (bi
= "iki", değişken = "değişkenler") verilerinin dağılım grafiklerini
göstermektedir.

`<img src="attachment:8a8eaaa4-9abd-4675-88b6-9866b9032e87.png" width="500"/>`{=html}

-1 veya 1 r\'ye ne kadar yakınsa, *verilerin* o kadar doğrusal
göründüğüne dikkat edin. *R* tam olarak 1 veya tam olarak -1 olduğunda,
değişkenler mükemmel bir şekilde ilişkilidir ve grafikleri bir çizgidir.
*R* sıfır olduğunda, değişkenler arasında bir korelasyon yoktur ve bu
örnekte veriler şekilsiz bir nokta bulutu olarak görünür.

Bununla birlikte, *r* size yalnızca değişkenler arasındaki doğrusal
korelasyonun gücünü söyler; işareti dışında değişkenler arasındaki
ilişkinin eğiminin büyüklüğü hakkında size hiçbir şey söylemez. Örneğin,
*r* = 1 olan değişkenler, X\'i bir artırmanın Y\'nin 10, 100, 0.1 veya
başka bir şey artmasına neden olup olmayacağını söylemez. Sadece
artacağından emin olabileceğinizi *söyler*. Bu gerçek, çizgilerin
eğimlerinin hepsi farklı olsa da, r\'nin yalnızca -1 veya *1* olduğu
aşağıdaki şekilde gösterilmektedir. Çizgi tamamen yatay veya tamamen
dikey ise, *r* tanımsızdır. (Nedenini merak ediyorsanız, aşağıdaki
denkleme bakın. Paydadaki terimlerden biri sıfıra eşit olur, bu da
paydanın tamamını sıfıra eşit yapar ve bu da tanımlanmamış bir çözümle
sonuçlanır.)

`<img src="attachment:908efe6c-0dde-439c-b8c8-a50c803eb296.png" width="1000"/>`{=html}

#### *r* hesapla

*R* formülü şöyledir:

r=covariance(X ⁣,Y)(S ⁣D X)(S ⁣D Y)r=(SD X)(SD Y)covariance(X,Y)​

nerede:

covariance(X ⁣,Y)=∑i=1n(xi−xˉ)(yi−yˉ)ncovariance(X,Y)=ni=1∑n​(xi​−xˉ)(yi​−yˉ​)​

**Not:** Burada verilen *r* ve kovaryans formülleri, tüm popülasyonlar
için kullanılanları temsil eder. Örnekler için, kovaryans formülünün
paydası *n -* 1\'dir ve benzer şekilde, *r* formülündeki standart
sapmalar n yerine *n - 1* kullanılarak hesaplanır.Basitlik için, bu
okuma gösterimlerinde popülasyon formüllerini kullanacaktır\_.\_

Bu hesaplama hakkında düşünmenin daha kolay bir yolu şudur: paylayıcı -
kovaryans - X ve Y\'nin kendi ortalamalarından ne ölçüde farklılık
gösterdiğini temsil eder. Bu değer pozitif olduğunda, yüksek X
değerlerinin yüksek Y değerleriyle ilişkili olma eğiliminde olduğunu ve
pozitif bir korelasyon olduğunu gösterir. Tersine, değer negatifse,
yüksek X değerlerinin düşük Y değerleri ile ilişkili olma eğiliminde
olduğunu ve bunun tersi de olumsuz bir korelasyon olduğunu gösterir.

Payı - standart sapmaların çarpımı - payı birimlerini standartlaştırır.
Bireysel değişkenlerin doğal değişkenliğini ayarlar. Bu, r *\'yi*
birimsiz bir istatistik yapar. Boyut içermeyen saf bir sayıdır.

*R* \'yi hesaplamanın eşdeğer bir yolu, her değişkendeki her veri
noktasını standart birimlere dönüştürmektir (ortalamayı çıkarın,
standart sapmaya bölün), ardından ürünlerin ortalamasını almaktır.

İşte bir örnek. Beş öğrencinin bir sınava girdiğini ve kaç saat ders
çalıştıklarını ve notlarını kaydettiğinizi varsayalım. Aşağıdaki tablo
*r hesaplamasını ortaya koymaktadır.*

  ---------------------------------------------------------------------------------------------------------------------
  **Çalışma saatleri (X)**            **Sınav notu (Y)**                   **Standart     **Standart     **Standart
                                                                           birimlerde X** birimlerde Y** birimlerin
                                                                                                         ürünü**
  ----------------------------------- ------------------------------------ -------------- -------------- --------------
  2                                   75                                   -1.5           -0.5           0.75

  4                                   65                                   -0.5           -1.5           0.75

  5                                   80                                   0              0              0

  6                                   95                                   0.5            1.5            0.75

  8                                   85                                   1.5            0.5            0.75

  **ortalama X =                      **ortalama Y =                                                     **ürünlerin
  5**`<br>`{=html}`<br>`{=html}**SD X 80**`<br>`{=html}`<br>`{=html}**SD Y                               ortalaması (r)
  = 2**                               = 10**                                                             = 0.6**
  ---------------------------------------------------------------------------------------------------------------------

Korelasyon katsayısı 0.6\'dır. İşte bu verilerin bir grafiği:

`<img src="attachment:24d4ed27-212c-4d73-ace6-fd9386254594.png" width="500"/>`{=html}

Nokta bulutunun yukarı doğru eğimli olduğuna dikkat edin. Bu, r\'nin
poziti *f* olmasına karşılık gelir. Korelasyon katsayısı, her değişkenin
ortalamasından sapmasının çarpımını kullandığı için bir ilişki
göstergesi olarak çalışır. Ürün pozitif olduğunda, hem X *hem* de Y
değerlerinin ilgili ortalamalarının altında (negatif standart birimler)
veya ilgili ortalamalarının (pozitif standart birimler) üzerinde olduğu
anlamına gelir. Birlikte farklılık gösterirler. Bununla birlikte, bu
ürün negatif olduğunda, değerlerden birinin ortalamasının üzerinde,
diğerinin altında olduğu anlamına gelir. Kendi araçlarına göre zıt
yönlerde farklılık gösterirler.

Aşağıdaki şekil bu fikri göstermektedir. Şekil çeyreklere ayrılmıştır.
Dikey çizgi ortalama X değerini ve yatay çizgi ortalama Y değerini
temsil eder. Her nokta, standartlaştırılmış puanlarının çarpımı ile
etiketlenir (yukarıdaki tabloya bakın). Bu puanların ortalaması r
*\'dir*. *R* pozitif olduğunda, daha fazla puan pozitif kadranlarda olma
eğiliminde olacaktır ve bunun tersi de geçerlidir.

`<img src="attachment:8fa4f227-8798-42e4-bbe9-ed21bbc81ce2.png" width="500"/>`{=html}

### **Regresyon**

Başka herhangi bir bilginin yokluğunda, rastgele seçilen bir öğrencinin
sınav puanını tahmin etmeniz gerekiyorsa, hatanızı en aza indirmenin en
iyi yolu tüm öğrencilerin puanlarının ortalamasını tahmin etmektir. Peki
ya o öğrencinin kaç saat çalıştığını da bilseydiniz? Şimdi, en iyi
tahmininiz, yalnızca bu kadar saatler boyunca okuyan öğrencilerin
ortalama puanı olabilir.

İşte çalışma süreleri en yakın yarım saate yuvarlatılmış 100 öğrenciden
oluşan bir örnek. Diyelim ki size bir öğrencinin yedi saat çalıştığı
söylendi. Sınav puanlarını tahmin etmek için, hatayı en aza indirmenin
bir yolu, yalnızca yedi saat boyunca okuyan öğrencilerin ortalamasını
tahmin etmektir.

`<img src="attachment:dd786085-891a-425f-8b28-b0e56b77e32b.png" width="500"/>`{=html}

Bu dağılım grafiğinde, yedi saat boyunca çalışan tüm öğrenciler iki
dikey çizgi arasına düşer. Ortalama sınav puanları bir X ile temsil
edilir. Doğrusal regresyon bu kavramı genişletir. Bir regresyon çizgisi,
doğrusal bir modelin varsayımları ve sınırlamaları göz önüne
alındığında, X\'in her değeri için tahmini ortalama Y değerini temsil
eder. Başka bir deyişle, X ve Y arasındaki ilişki tamamen doğrusal
değilse veya Y\'yi etkileyen modele dahil edilmeyen başka faktörler
varsa, her X için gerçek ortalama Y değerleri tam olarak regresyon
çizgisinde olmayabilir. Regresyon çizgisi, bir bütün olarak verilere en
uygun düz çizgi ilişkisini bulmak için bu etkileri dengelemeye çalışır.
X göz önüne alındığında, Y\'nin merkezi eğiliminin bir tahminidir.

#### Regresyon denklemi

Artık r\'yi bildiğinize *ve* regresyon kavramını daha iyi anladığınıza
göre, veriler arasında en uygun çizgiyi bulmak için her şeyi bir araya
getirmeye hazırsınız. Bu çizginin formülü regresyon denklemi olarak
bilinir. Bu adımın iki anahtarı vardır.

Birincisi:

-   *X\'in ortalama değeri ve Y\'nin ortalama değeri (yani nokta
    (**x**,)) her zaman regresyon çizgisine düşecektir.*

İkincisi, r\'nin ne anlama gel *diğini* anlamaktır:

-   X\'deki bir standart sapmanın her artışı için, Y\'de ortalama olarak
    X üzerinde beklenen bir *r* standart sapması artışı vardır.

Aşağıdaki şekil, bu kavramların regresyon çizgisini belirlemek için
nasıl birlikte çalıştığını göstermektedir.

`<img src="attachment:f5777644-e7cf-429f-b491-b0bccd4fd68d.png" width="500"/>`{=html}

Başka bir deyişle, regresyon çizgisinin eğimi:

m=r(S ⁣D y)S ⁣D xm=SD xr(SD y)​

*Bu, bir satırın formülünde m\'dir:* *y* *=* *mx* *+* \_b\_\_.\_ Bu
nedenle *b ile temsil edilen kesiş* me noktası: *b* = *y* - *mx*.
*Noktanın (**x**,) her zaman regresyon çizgisinde olduğunu bildiğiniz
için, kesişmeyi hesaplamak için bu noktadan* *x* *ve* *y* *değerlerini
ekleyebilirsiniz.* İşte beş öğrencinin orijinal örneğini kullanan bir
örnek.

                        **Çalışma saatleri (X)**   **Sınav notu (Y)**
  --------------------- -------------------------- --------------------
  **anlamına gelir:**   5                          80
  **SD:**               2                          10
  **r:**                **0.6**                    

Adımlara ayrılmış:

1.  Eğimi hesaplayın:
    m=r(S ⁣D y)S ⁣D x=0.6(10)2=3.m=SD xr(SD y)​=20.6(10)​=3.

2.  *Kesişmeyi hesaplayın:* *y* *=* *mx* *+* *b: 80 = 3 (5) + b →* *b*
    *=* *65 denklemine* \_x\_\_, ve\_ *m* *değiştirin.*

3.  Regresyon denklemini elde etmek için genelleme *yapın: y* = 3 *x* +
    65.

İşte verilerin üzerine bindirilmiş regresyon çizgisi:

`<img src="attachment:784017ca-3554-4cb7-b4f1-60b8d4294690.png" width="500"/>`{=html}

Buna "Y\'nin X üzerindeki gerilemesi" denir. İşte 100 öğrencinin tamamı
için regresyon çizgisi:

`<img src="attachment:febf462c-536b-4281-ac0a-3d8901084425.png" width="500"/>`{=html}

### **Önemli Çıkarımlar** {#önemli-çıkarımlar}

Doğrusal regresyon, veri profesyonellerinin verileri analiz etmek için
kullandıkları en önemli araçlardan biridir. Basit doğrusal regresyonun
temel yapı taşlarını anlamak, daha karmaşık regresyon analizi yöntemleri
hakkında bilgi edinmeye devam ederken size yardımcı olacaktır. İşte
akılda tutulması gereken bazı önemli noktalar:

-   Korelasyon, iki değişkenin birlikte hareket etme şeklinin bir
    ölçümüdür.

-   *r (diğer adıyla Pear* son korelasyon katsayısı, diğer adıyla
    korelasyon katsayısı), iki değişken arasındaki doğrusal ilişkinin
    gücünü ölçer.

    -   Her zaman \[-1, 1\] aralığına düşer.

    -   Ortalarından birlikte farklılık gösterme eğiliminde olan
        değişkenler pozitif olarak ilişkilidir. Tersine, ilgili
        araçlarına zıt şekillerde değişme eğiliminde olan değişkenler
        negatif ilişkilidir.

-   Regresyon çizgisi, her *x değeri için ortalama y değerini tahmin*
    eder. X verildiğinde *y* tahmin edilirken hatayı en aza indirir.

-   Regresyon çizgisinin eğimir(S ⁣D y)S ⁣D xSD xr(SD y)​.

-   Nokta (*x,*) *her* zaman regresyon çizgisindedir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Basit doğrusal regresyonun dört ana varsayımı
:::

::: {.cell .markdown}
Bu okumada, basit doğrusal regresyonun dört ana varsayımını,
varsayımların karşılanıp karşılanmadığını nasıl kontrol edeceğinizi ve
bir varsayım karşılanmazsa ne yapacağınızı gözden geçireceksiniz.
Grafikleri çoğaltmak ve varsayımları kendi başınıza keşfetmek için ek
kaynakları kullanabilirsiniz. Bu okumada tanımlanmamış herhangi bir
terim varsa, her modülün sonunda kurs boyunca bulunan terimler sözlüğüne
bakın. Bu okuma şunları kapsayacaktır:

-   Basit doğrusal regresyon varsayımları

-   Varsayımların geçerliliği nasıl kontrol edilir

-   Bir varsayım ihlal edilirse ne yapmalı

### Basit doğrusal regresyon varsayımları

Özetlemek gerekirse, basit doğrusal regresyonun dört varsayımı vardır:

1.  **Doğrusallık:** Her öngörücü değişken (Xi), sonuç değişkeni (Y) ile
    doğrusal olarak ilişkilidir.

2.  **Normallik:** Hatalar normal olarak dağıtılır. \*\*\*\*\*

3.  **Bağımsız Gözlemler:** Veri kümesindeki her gözlem bağımsızdır.

4.  **Homoscedastisite: Hataların** varyansı model boyunca sabit veya
    benzerdir. \*\*\*\*\*

#### \*\*\* Hatalar ve artıklar hakkında not\*\*\* {#-hatalar-ve-artıklar-hakkında-not}

Bu ders, regresyon ile bağlantılı olarak "hatalar" ve "artıklar"
terimlerini birbirinin yerine kullanmıştır. Bunu, bir veri uzmanı olarak
geçirdiğiniz süre boyunca diğer çevrimiçi kaynaklarda ve materyallerde
görebilirsiniz.. Gerçekte, bir fark var:

-   **Kalıntılar**, tahmin edilen ve gözlemlenen değerler arasındaki
    farktır. Bir regresyon modeli oluşturduktan sonra, tahmin edilen
    değerleri gözlemlenen değerlerden çıkararak kalıntıları
    hesaplayabilirsiniz.

-   **Hatalar**, modelde olduğu varsayılan doğal gürültüdür.

-   Kalıntılar, doğrusal regresyonun normallik ve homoskedastiklik
    varsayımlarını kontrol ederken hataları tahmin etmek için
    kullanılır.

### Varsayımların geçerliliği nasıl kontrol edilir

Daha önce gözden geçirildiği gibi, basit doğrusal regresyon
varsayımlarının çoğu veri görselleştirmeleri yoluyla kontrol edilebilir.
Bazı varsayımlar bir model oluşturulmadan önce kontrol edilebilir ve
diğerleri yalnızca model oluşturulduktan ve tahmin edilen değerler
hesaplandıktan sonra kontrol edilebilir.

#### **Doğrusallık**

Bağımsız ve bağımlı değişkenler arasında doğrusal bir ilişki olup
olmadığını değerlendirmek için, veri kümesinin bir dağılım grafiğini
oluşturmak en kolay yoldur. Bağımsız değişken x ekseninde ve bağımlı
değişken y ekseninde olacaktır. Verileri okumak ve bir dağılım grafiği
oluşturmak için kullanabileceğiniz bir dizi farklı Python işlevi vardır.
Veri görselleştirmeleri için kullanılan bazı paketler arasında
Matplotlib, seaborn ve Plotly bulunur. Doğrusallık varsayımının test
edilmesi, model oluşturulmadan önce yapılmalıdır.

``` python
# Create pairwise scatterplots of Chinstrap penguins data

sns.pairplot(chinstrap_penguins)
```

`<img src="attachment:1e80dd47-68de-41e5-ba03-5d904578deda.png" width="500"/>`{=html}

#### **Normallik**

Normallik varsayımı, art **ıklarla tahmin edilebilen hatalara veya
verilerde gözlemlenen değerler ile regresyon modeli tarafından tahmin
edilen değerler arasındaki farka odak** lanır. Bu nedenle normallik
varsayımı ancak bir model oluşturulduktan ve tahmin edilen değerler
hesaplandıktan **sonra** doğrulanabilir. Model oluşturulduktan sonra,
artıkların normal dağıldığını kontrol etmek için bir QQ grafiği
oluşturabilir veya artıkların bir histogramını oluşturabilirsiniz.
Varsayımın karşılanıp karşılanmadığı bir düzeyde yorumlamaya bağlıdır.

##### **Kuantil-kuantil grafik**

Ku **antil-kuantil grafiği (Q-Q grafiği**), iki olasılık dağılımını
kuantillerini birbirine karşı çizerek karşılaştırmak için kullanılan
grafik bir araçtır. Veri uzmanları genellikle bir dağılımın normalliğini
ölçmek için Q-Q grafiklerini histogramlara tercih eder, çünkü bir
grafiğin düz bir çizgiye yapışıp yapışmadığını ayırt etmek, bir
histogramın normal bir eğriyi ne kadar yakından takip ettiğini
belirlemekten daha kolaydır. Bir modelin artıklarının normalliğini
değerlendirirken Q-Q grafiklerinin nasıl çalıştığı aşağıda
açıklanmıştır:

1.  **Kalıntıları sıralayın**. *N artıklarınızı en küç* ükten en büyüğe
    doğru sıralayın. Her biri için, verilerin yüzde kaçının bu
    sıralamaya veya altına düştüğünü hesaplayın. Bunlar veriler *inizin
    n* miktarıdır.

2.  **Normal dağılımla karşılaştırın.** Standart bir normal dağılımı *n*
    +1 eşit alana bölün (yani, *n kez dilim* leyin). Kalıntılar normal
    olarak dağılmışsa, her bir kalıntının kuantili (yani, verilerin
    yüzde kaçı her sıralı kalıntının altına düşer), standart normal
    dağılımdaki *n* kesimin her birinin karşılık gelen z puanları ile
    yakından hizalanacaktır (bunlar normal bir z-puan tablosunda veya
    daha yaygın olarak istatistiksel yazılım kullanılarak bulunabilir).

3.  **Bir arsa inşa et.** Bir Q-Q grafiği, x ekseni boyunca standart bir
    normal dağılımın bilinen kuantil değerlerine ve y ekseninde sıra
    sıralı kalıntı değerlerine sahiptir. Kalıntılar normal olarak
    dağılmışsa, artıkların kuantil değerleri standartlaştırılmış normal
    dağılımınkilere karşılık gelecektir ve her ikisi de doğrusal olarak
    artacaktır. Kalıntılarınızı ilk önce standartlaştırırsanız
    (ortalamayı çıkarıp standart sapmaya bölerek z puanlarına
    dönüştürün), iki eksen aynı ölçeklerde olacaktır ve artıklar
    gerçekten normal dağılmışsa, çizgi 45° açıda olacaktır. Bununla
    birlikte, artıkları standartlaştırmak, bir Q-Q grafiğinin bir
    gerekliliği değildir. Her iki durumda da, ortaya çıkan grafik
    doğrusal değilse, artıklar normal olarak dağıtılmaz.

Aşağıdaki şekilde, ilk Q-Q grafiği, normal bir dağılımdan alınan
verileri göstermektedir. Standart bir normal dağılımın miktarlarına
karşı çizildiğinde bir çizgi oluşturur. İkinci çizim, üstel bir
dağılımdan alınan verileri gösterir. Üçüncü çizim, tek tip bir
dağılımdan alınan verileri kullanır. İkinci ve üçüncü çizimlerin bir
çizgiye nasıl uymadığına dikkat edin.

`<img src="attachment:1f552eca-bc02-48ae-96ed-b0ce2f391fed.png" height="400"/>`{=html}

##### **Q-Q grafiği nasıl kodlanır**

Neyse ki, daha önce belirtilen adımları manuel olarak gerçekleştirmeniz
gerekmez. Bunu halletmek için bilgisayar kütüphaneleri var. Bir Q-Q
grafiği oluşturmanın bir yolu, statmodels kütüphanesini kullanmaktır.
İçe aktarırsanızstatsmodels.api, [qqplot
()](https://www.statsmodels.org/stable/generated/statsmodels.graphics.gofplots.qqplot.html)
işlevini doğrudan kullanabilirsiniz. Aşağıdaki örnek, bir statsmodels
ols model nesnesindeki artıkları kullanır. Model, penguenlerin palet
uzunluğunu gaga derinliklerine göre geri çeker (X üzerinde Y).

``` python
import statsmodels.api as sm

import matplotlib.pyplot as plt

residuals = model.resid

fig = sm.qqplot(residuals, line = 's')

plt.show()
```

`<img src="attachment:99fd4765-31cc-4e55-a3a1-47dceaa219aa.png" width="500"/>`{=html}

Ve işte aynı verilerin bir histogramı:

``` python
fig = sns.histplot(residuals)

fig.set_xlabel("Residual Value")

fig.set_title("Histogram of Residuals")

plt.show()
```

`<img src="attachment:7bbaf486-6f54-49a7-af76-7ffbee388458.png" width="500"/>`{=html}

#### **Bağımsız Gözlemler**

Gözlemlerin bağımsız olup olmadığı, verilerinizi anlamanıza bağlıdır.
Gibi sorular sormak:

-   Veriler nasıl toplandı?

-   Her veri noktası neyi temsil eder?

-   Veri toplama sürecine bağlı olarak, bir veri noktasının değerinin
    başka bir veri noktasının değerini etkilemesi muhtemel midir?

Sizin fark etmediğiniz şeyleri fark edebilecek başkalarından içgörü
almayı içeren bu soruların nesnel bir incelemesi, bağımsız gözlem
varsayımının ihlal edilip edilmediğini belirlemenize yardımcı olabilir.
Bu da eldeki veri kümesiyle çalışırken sonraki adımlarınızı
belirlemenizi sağlayacaktır.

#### **Homoscedastisite**

Normallik varsayımı gibi, homoskedastiklik varsayımı bir modelin
artıklarıyla ilgilidir, bu nedenle ancak bir regresyon modeli
oluşturulduktan sonra değerlendirilebilir. Takılan değerlerin (yani
modelin öngörülen Y değerleri) artıklara karşı bir dağılım grafiği,
homoskedastiklik varsayımının ihlal edilip edilmediğini belirlemeye
yardımcı olabilir.

``` python
import matplotlib.pyplot as plt

fig = sns.scatterplot(fitted_values, residuals)

fig.axhline(0)

fig.set_xlabel("Fitted Values")

fig.set_ylabel("Residuals")

plt.show()
```

`<img src="attachment:671e25f0-7b78-436e-b35e-cd78aa5728b3.png" width="500"/>`{=html}

### Bir varsayım ihlal edilirse ne yapmalı

Artık dört varsayımı ve ihlallerini nasıl test edeceğinizi
incelediğinize göre, bir varsayım ihlal edildiğinde atabileceğiniz bazı
yaygın sonraki adımları tartışmanın zamanı geldi. Verileri
dönüştürürseniz, bunun sonuçları yorumlama şeklinizi değiştirebileceğini
unutmayın. Ek olarak, bu potansiyel çözümler verileriniz için işe
yaramazsa, farklı bir model denemeyi düşünmelisiniz.

Şimdilik, başlamanız için birkaç temel yaklaşıma odaklanın!

#### **Doğrusallık**

-   Logaritmayı almak gibi değişkenlerden birini veya her ikisini de
    dönüştürün.

    -   Örneğin, eğitim yılları ile gelir arasındaki ilişkiyi
        ölçüyorsanız, gelir değişkeninin logaritmasını alabilir ve bunun
        doğrusal ilişkiye yardımcı olup olmadığını kontrol
        edebilirsiniz.

#### **Normallik**

-   Değişkenlerden birini veya her ikisini de dönüştürün. En yaygın
    olarak, bu sonuç değişkeninin logaritmasını almayı içerir.

    -   Sonuç değişkeni gelir gibi doğru çarpık olduğunda, artıkların
        normalliği etkilenebilir. Dolayısıyla, sonuç değişkeninin
        logaritmasını almak bazen bu varsayıma yardımcı olabilir.

    -   Bir değişkeni dönüştürürseniz, modeli yeniden yapılandırmanız ve
        ardından emin olmak için normallik varsayımını yeniden kontrol
        etmeniz gerekir. Varsayım hala yerine getirilmezse, sorunu
        gidermeye devam etmeniz gerekir.

`<img src="attachment:fdbfb44c-1772-4fb3-96f1-f5a3525b3d71.png" width="500"/>`{=html}

#### **Bağımsız gözlemler**

-   Mevcut verilerin sadece bir alt kümesini alın.

    -   Örneğin, bir anket yürütüyorsanız ve aynı hanedeki kişilerden
        yanıt alıyorsanız, yanıtları ilişkili olabilir. Her hanede
        sadece bir kişinin verilerini saklayarak bunu düzeltebilirsiniz.

    -   Başka bir örnek, belirli bir süre boyunca veri toplamanızdır.
        Diyelim ki bisiklet kiralamayla ilgili verileri
        araştırıyorsunuz. Verilerinizi her 15 dakikada bir toplarsanız,
        sabah 8:00\'de kiralanan bisiklet sayısı sabah 8:15 \'de
        kiralanan bisiklet sayısıyla ilişkili olabilir. Ancak, veriler
        her 15 dakikada bir yerine 2 saatte bir alınırsa kiralanan
        bisiklet sayısı bağımsızdır.

#### **Homoscedastisite**

-   Farklı bir sonuç değişkeni tanımlayın.

    -   Bir şehrin nüfusunun bir şehirdeki restoran sayısıyla nasıl
        ilişkili olduğunu anlamakla ilgileniyorsanız, bazı şehirlerin
        diğerlerinden çok daha kalabalık olduğunu bilirsiniz. Daha sonra
        sonuç değişkenini nüfusun restoranlara oranı olarak yeniden
        tanımlayabilirsiniz.

-   Y değişkenini dönüştürün.

    -   Yukarıdaki varsayımlarda olduğu gibi, bazen logaritmayı almak
        veya Y değişkenini başka bir şekilde dönüştürmek,
        homoskedastiklik varsayımıyla tutarsızlıkları potansiyel olarak
        düzeltebilir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   Basit doğrusal regresyon için dört temel varsayım vardır:
    doğrusallık, normallik, bağımsız gözlemler ve homoskedastiklik.

-   Her varsayımın geçerliliğini kontrol etmenin farklı yolları vardır.
    Bazı varsayımlar model oluşturulmadan önce kontrol edilebilirken,
    bazıları model oluşturulduktan sonra kontrol edilebilir.

-   Model varsayımlarının ihlallerini düzeltebilecek verilerle
    çalışmanın yolları vardır.

-   Değişkenlerin değiştirilmesi yorumlamayı değiştirecektir.

-   Varsayımlar ihlal edilirse, veri dönüşümlerinden sonra bile,
    verileriniz için diğer modelleri göz önünde bulundurmalısınız.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

-   [Denizdeki penguenler veri kümesini buradan
    indirin](https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv "Seaborn GitHub deposundan penguens veri kümesi")

-   Penguenler veri kümesi hakkında daha fazla bilgi: [Palmer
    penguenlerine
    giriş](https://allisonhorst.github.io/palmerpenguins/articles/intro.html)

-   Q-Q grafikleri hakkında daha fazla bilgi: [Normal Nicel-Kuantil
    Grafikler (jbstatistik\'ten
    video)](https://www.youtube.com/watch?v=X9_ISJ0YpGw)
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Normal Dağılımın Doğrulanması
:::

::: {.cell .markdown}
``` python
import pandas as pd
import seaborn as sns

# Load dataset
penguins = sns.load_dataset ("penguins")

# Examine first 5 rows of dataset 
penguins.head()
```

`<img src="attachment:703390ef-3546-4af9-bc80-ef264499d66d.png" width="700"/>`{=html}

``` python
#Keep Adelie and Gentoo penguins, drop NAS
penguins_sub = penguins[penguins["species"] != "Chinstrap"]
penguins_final = penguins_sub.dropna()
penguins_final.reset_index(inplace=True, drop=True)

sns.pairplot(penguins_final)

#Subset Data
ols_data = penguins_final[["bill_length_mm", "body_mass_g"]]
```

`<img src="attachment:7883b62a-c6c5-471b-ac98-06e34000ee12.png" width="700"/>`{=html}

``` python
# Write out formula
ols_formula = "body_mass_g ~ bill_length_mm"

# Import ols function 
from statsmodels.formula.api import ols

# Build OLS, fit model to data
OLS = ols(formula = ols_formula, data ols_data) 
model = OLS.fit()

model.summary()
```

`<img src="attachment:7dcb3bfa-f365-41b0-a3ef-80a29b591e1b.png" width="500"/>`{=html}

`<img src="attachment:6385e76b-e74a-4a7c-ab16-a67b9a70e0fb.png" width="500"/>`{=html}

``` python
# Subset X variable
x = ols_data["bill_length_mm"]

# Get predictions from model
fitted_values = model.predict(X)

# Calculate residuals
residuals = model.resid

sns.regplot(x = "bill_length_mm", y = "body_mass_g", data = ols_data)
```

(Doğrusal)

`<img src="attachment:b52a31c5-76dc-4204-91ea-8d408b0c18c7.png" width="500"/>`{=html}

``` python
import matplotlib.pyplot as plt
fig = sns.scatterplot(fitted_values, residuals)
fig.axhline(0)
fig.set_xlabel("Fitted Values") fig.set_ylabel("Residuals")
plt.show()
```

(Homojen Dağılım)

`<img src="attachment:b001d204-ba5f-4afc-9b87-95b50ad64599.png" width="500"/>`{=html}

``` python
fig = sns.histplot(residuals)
fig.set_xlabel ("Residual Value")
fig.set_title("Histogram of Residuals")
plt.show()
```

(çan şeklinde)

`<img src="attachment:6672a1ac-57f2-4029-ad58-2c2064351f69.png" width="500"/>`{=html}

Bu üç adım aynı gerçekleşirse normal dağılım diyebiliriz. Ama doğrulamak
için;

``` python
import statsmodels.api as sm
fig = sm.qqplot(model.resid, line = 's')
plt.show()
```

`<img src="attachment:274cc4b1-9570-4d66-b777-f3bd055a98fd.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Kod işlevleri ve dokümantasyon
:::

::: {.cell .markdown}
Bu okumada, penguen verilerinin farklı bir alt kümesini kullanarak
videolardaki bazı kodları inceleyeceksiniz. Bu okuma, statmodels
belgelerine yaklaşırken bazı ipuçlarını da paylaşacaktır.. Bu, Python
işlevselliğini keşif veri analizi, temel veri temizleme ve model
oluşturma ile birlikte gözden geçirmek için iyi bir fırsattır.

### Videodaki işlevleri inceleyin

#### **Veri kümesini yükleyin**

İlk birkaç kod satırı kodlama ortamını kurar ve verileri yükledi. Aşina
olabileceğiniz gibi, gerekli paketleri içe aktarmak için import işlevi
çağırabilirsiniz. Gerektiğinde geleneksel takma adları kullanmalısınız.
Aşağıdaki örnek, seaborn paket aracılığıyla bulunan penguenlerle ilgili
bir veri kümesine atıfta bulunur.

``` python
# Import packages
import pandas as pd
import seaborn as sns

# Load dataset
penguins = sns.load_dataset("penguins")

# Examine first 5 rows of dataset
penguins.head()
```

#### **Temiz veri**

Veriler yüklendikten sonra, kursumuzun amaçları için bir veri alt kümesi
oluşturmak üzere veriler temizlendi. Örnek, yalnızca Chinstrap
penguenlerini veri kümesinden izole eder ve eksik veri içeren satırları
bırakır.

Veri çerçevesinin dizini işlev kullanılarak sıfırlanır.
[reset_index()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html)
Bir veri çerçevesini alt ayarladığınızda, orijinal satır dizinleri
korunur. Örneğin, 2. ve 3. satırlarda Adelie veya Gentoo penguenleri
olduğunu varsayalım. Verileri yalnızca Chinstrap penguenleri için alt
ayarlayarak, yeni veri çerçeveniz satır 1 ve ardından satır 4 olarak
listelenir, çünkü 2. ve 3. satır kaldırılır. Veri çerçevesinin dizini
sıfırlayarak satır numaraları 1, 2, 3 vb. Satır haline gelir. Veri
çerçevesinin gelecekte çalışması daha kolay hale gelir.

Aşağıdaki kodu inceleyin. Kodu kendi not defterinizde çalıştırmanız
önerilir.

``` python
# Subset just Chinstrap penguins from data se
chinstrap_penguins = penguins[penguins["species"] == "Chinstrap"]

# Reset index of dataframe
chinstrap_penguins.reset_index(inplace = True, drop = True)
```

#### **Model yapımı için kurulum**

Artık veriler temiz olduğuna göre, verileri çizebilir ve doğrusal bir
regresyon modeli oluşturabilirsiniz. İlk olarak, hedeflediğiniz bir X
değişkenini flipper_length_mm ve Y değişkenini bill_depth_mm çıkarın.

``` python
# Subset Data
ols_data = chinstrap_penguins[["bill_depth_mm", "flipper_length_mm"]]
```

Bu örnek statsmodels kullandığından, sıradan en küçük kareler formülünü
bir dize olarak kaydedin, böylece bilgisayar regresyonun nasıl
çalıştırılacağını anlayabilir. Önce Y değişkeni flipper_length_mm gelir,
ardından bir tilde ve X değişkeninin adı bill_depth_mm gelir.

``` python
# Write out formula
ols_formula = "flipper_length_mm ~ bill_depth_mm"
```

#### **Modeli oluşturun**

Modeli oluşturmak için önce ols işlevi statsmodels.formula.api arayüzden
içe aktarmanız gerekir.

``` python
# Import ols function
from statsmodels.formula.api import ols
```

Ardından, formülü ve kaydedilen verileri işleve tak ols ın. Ardından,
modeli verilere uydurmak için fit yöntemi kullanın. Son olarak,
regresyon modelinden sonuçları almak için summary yöntemi kullanın.

``` python
# Build OLS, fit model to data
OLS = ols(formula = ols_formula, data = ols_data)
model = OLS.fit()
model.summary()
```

`<img src="attachment:d9aea0c3-526c-4ee1-a9c3-064f64620e24.png" width="700"/>`{=html}

#### **Model tahminleri ve artıklar**

Takılan bir
[StatsModels.Regression.LINEAR_MODEL.OLS](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLSResults.html)
veya
[StatsModels.Regression.LINEAR_MODEL.OLSRESULTS](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html)
nesnesinden tahminlere ve artıklara aşağıdaki gibi erişebilirsiniz.

##### Tahminler

Modelin
[OLS.predict()](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.predict.html#statsmodels.regression.linear_model.OLS.predict)
yöntemini kullanın ve ona bağımsız değişken(ler)in değerlerini içeren
bir dizi iletin:

``` python
predictions = model.predict(chinstrap_penguins[["bill_depth_mm"]])
```

##### Kalıntılar

Modelin resid özelliğini kullanın:

``` python
residuals = model.resid
```

### Statsmodels belgelerinde gezinme

Özellikle ilk kodlama sırasında yeni bir Python paketine veya yeni bir
Python işlevlerine yaklaşmak için önemli çalışmalar gerektirebilir.
Python\'un açık kaynaklı bir programlama dili olmasının yararı, soru
soran ve yanıtlayan güçlü bir Python topluluğunun olmasıdır. Başarılı
bir veri uzmanı olmanın bir parçası, kodunuzun nasıl çalışmasını
sağlayacağınızı bilmek ve kodunuz kırıldığında sorun gidermektir. Bunu
yapmanın bir yolu doğrudan kaynağına veya belirli bir paketin resmi
belgelerine gitmektir.

statsmodelsPaketi basit doğrusal regresyon modelleri oluşturmak için
kullanıyorsunuz. [Statsmodels
belgeleri](https://www.statsmodels.org/devel/api.html) çevrimiçi olarak
mevcuttur ve düzenli olarak güncellenir. Özellikle, sıradan en küçük
kareler tahmini gerçekleştirmek için [statsmodels.formula.api
arayüzünü](https://www.statsmodels.org/devel/api.html#statsmodels-formula-api)
kullanıyorsunuz.

[İşlevdeki sayfayı ols veya OLS tahminini gerçekleştiren işlevi
inceleyerek, izin verilen farklı işlev parametrelerini, her biri
hakkında bazı notlarla
gözlemleyeceksiniz.](https://www.statsmodels.org/devel/generated/statsmodels.formula.api.ols.html#statsmodels.formula.api.ols)

Ne yazık ki, şu anda, statsmodels belgeleri, işlevin nasıl
kullanılacağına dair kod örnekleri içermiyor. İhtiyacınız olduğu kadar
örnek sağlamayan belgeler veya kodunuzda sorun gidermeniz için gereken
örnekleri sağlamayan belgeler bulursanız, kullanmaya çalıştığınız işlevi
çevrimiçi olarak arayabileceğinizi ve Python topluluğundaki diğer
kişilerin benzer sorunları nasıl ele aldığını keşfedebileceğinizi
unutmayın.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   İlgili videodaki kodla ilgili hafızanızı yenilemek için bu okumayı
    inceleyebilirsiniz.

-   Statsmodels (veya başka bir paketin) belgelerini gerektiği gibi
    görüntüleyebilirsiniz.

-   Belgeler aradığınız cevabı içermiyorsa, başkalarının çalışmalarını
    kontrol etmek için her zaman internete başvurabilirsiniz.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Regresyondaki belirsizlik ölçülerini yorumlayın
:::

::: {.cell .markdown}
Bu okumada, özellikle güven aralıkları, güven bantları ve p-değerleri
aracılığıyla regresyon analizindeki belirsizliği keşfetmeye devam
edeceğiz. Birlikte yapacağız:

-   Anahtar kavramları gözden geçirin

-   Belirsizlik ölçümlerinin nasıl yorumlanacağını tartışın

-   Örnek grafikleri gözden geçirin

### Kavramların Gözden Geçirilmesi

Basit bir doğrusal regresyon çizgisini şu şekilde temsil edebileceğimizi
hatırlayın.

**Regresyon analizi tahmin tekniklerini** kullandığından, regresyon
modelleri tarafından yapılan tahminleri çevreleyen her zaman bir
belirsizlik seviyesi vardır. Hatayı temsil etmek için, denklemi harfle
temsil edilen bir hata terimi içerecek şekilde yeniden yazabiliriz
("epsilon" olarak telaffuz edilir):.

Modeli oluşturmak için kullanılan veri kümesindeki her veri noktası için
tahmin edilen ve gerçek değer arasındaki fark olarak da bilinen bir
kalıntı vardır. Daha sonra, birkaç belirsizlik ölçüsüyle tüm modelin ne
kadar belirsiz olduğunu ölçebiliriz:

-   **Beta katsayıları etrafındaki güven aralıkları**

-   **Beta katsayıları için P-değerleri**

-   **Regresyon çizgisinin etrafındaki güven bandı**

Anahtar terimleri ve tanımları kontrol etmek için terimler sözlüğüne
başvurabilirsiniz, ancak burada iki anahtar terimi sağladık:

-   **Güven aralığı:** bir tahmini çevreleyen belirsizliği tanımlayan
    bir değer aralığı

-   **P-değeri:** sıfır hipotez doğru olduğunda gözlemlenenler kadar
    aşırı sonuçları gözlemleme olasılığı

### Belirsizliği Yorumlama

Önce önceki videolarda birlikte oluşturduğumuz doğrusal regresyon
modelinden elde edilen sonuçların özetini tekrar gözden geçirelim:

![image.png](f2dd6ab7-c0a8-4c7f-a47f-7a40b674b69a.png)

Oluşturduğumuz basit line er regresyon modeline göre 141.1904\'tür. Bu
nedenle, bir penguenin gaga uzunluğundaki her bir milimetre artış için,
bir penguenin vücut kütlesinde yaklaşık 141.1904 gram daha fazla
olmasını beklerdik. Tahminin 0,000\'den az p değeri 0,000\'dir, bu da
katsayının "istatistiksel olarak anlamlı" olduğu anlamına gelir. Ek
olarak, tahminimiz% 95 güven aralığına sahiptir: 131.788 ve 150.592. Bu
kısa cümleleri biraz daha gözden geçirelim.

Daha önce hipotez testi bağlamında p-değerleri ve güven aralıkları
hakkında bilgi edinmiş olabilirsiniz. Sezgisel görünmese de, regresyon
analizinde bile hipotezleri test ediyoruz.

#### P değerleri

Regresyon analizi çalıştırırken, X\'in gerçekten y ile ilişkili olup
olmadığını bilmek istersiniz. Bu yüzden regresyon sonuçları üzerinde bir
hipotez testi yapıyoruz. Regresyon analizinde, her beta katsayısı için
aşağıdaki sıfır ve alternatif hipotez kümesini test ediyoruz:

-   H0 (sıfır hipotez):

-   H1 (alternatif hipotez):

Örneğimizde, p değeri 0,05\'ten az olduğu için, 0\'a eşit olan sıfır
hipotez ini reddedebilir ve katsayının istatistiksel olarak anlamlı
olduğunu söyleyebiliriz, bu da bir penguenin gaga uzunluğundaki bir
farkın vücut kütlesindeki bir farkla gerçekten ilişkili olduğu anlamına
gelir.

#### Güven Aralıkları

Her beta katsayısı ayrıca tahmini ile ilişkili bir güven aralığına
sahiptir. %95\'lik bir aralık, aralığın kendisin% 95 katsayının gerçek
parametre değerini içerme şansına sahip olduğu anlamına gelir.
Dolayısıyla, güven aralığımızın \[131.788, 150.592\] gerçek değerini
içermemesi ihtimali %5 vardır. Daha doğrusu, bu, bu deneyi birçok kez
tekrarlarsanız, güven aralıklarının% 95\'inin gerçek değerini içereceği
anlamına gelir.

Ancak, tahmini beta katsayılarının her ikisinde de belirsizlik
olduğundan, tahmini y değerleri de belirsizliğe sahiptir. Güven
bantlarının kullanışlı hale geldiği yer burasıdır.

### Örnek Grafik

-   **Güven bandı:** Öngörülen sonuç etrafındaki belirsizliği tanımlayan
    çizgiyi çevreleyen alan. Güven bandını, y\'nin her nokta tahminini
    çevreleyen güven aralığını temsil ettiğini düşünebilirsiniz.
    çizginin her noktasında belirsizlik olduğundan, regresyon
    modelindeki güven aralıklarını özetlemek için güven bandını
    kullanırız. Güven bandı her zaman numunenin ortalamasına doğru en
    dar ve ekstremitelerde en geniştir.

![image.png](0aa54837-9987-4ef4-b4fe-a60c7a77ca04.png)

### Önemli Çıkarımlar {#önemli-çıkarımlar}

-   Regresyon analizi **tahmin** tekniklerini kullanır, bu nedenle
    tahminler etrafında her zaman belirsizlik vardır.

-   Belirsizliği güven aralıklarını, p-değerlerini ve güven bantlarını
    kullanarak ölçebiliriz.

-   Her katsayı tahmini için, katsayının 0\'a eşit olduğu hipotezini
    test ediyoruz.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Basit doğrusal regresyon için değerlendirme metrikleri
:::

::: {.cell .markdown}
Bu okumada, basit doğrusal regresyon için değerlendirme metrikleri
hakkında daha kapsamlı bir genel bakış sağlayacağız. Önceki bir videoda
R²\'yi ele aldık ve birkaç başka ölçümden, MAE ve MSE\'den bahsettik. Bu
okumada, daha önce bahsettiğimiz metrikleri gözden geçireceğiz ve bir
veri uzmanı olarak kariyeriniz boyunca karşılaşabileceğiniz birkaç
ölçümü daha tanıtacağız.

### **R², MSE ve MAE\'nin gözden geçirilmesi**

Doğrusal regresyon için ana değerlendirme metriği R² veya belirleme
katsayısıdır.

### R²: Belirleme katsayısı

**R²**, bağımsız değişken (ler) X tarafından açıklanan bağımlı değişken
Y\'deki varyasyon oranını ölçer.

-   Bu, kareli artıkların toplamının 1\'den toplam karelerin toplamına
    bölünmesiyle hesaplanır.

`<img src="attachment:6530d4b0-31b4-4a18-bf51-f794834a83a4.png" width="300"/>`{=html}

R² 0 ile 1 arasında değişir. Dolayısıyla, bir modelin R²\'si 0,85 ise,
bu, X değişkenlerinin Y değişkenindeki varyasyonun yaklaşık% 85\'ini
açıkladığı anlamına gelir. R² oldukça yorumlanabilir ve yaygın olarak
kullanılan bir metrik olmasına rağmen, R² model performansını
değerlendirmede yetersiz olduğunda ortalama kare hata (MSE) ve ortalama
mutlak hata (MAE) ile de karşılaşabilirsiniz.

### MSE: Ortalama kare hatası

**MSE (ortalama kare hata)**, tahmin edilen ve gerçek değerler
arasındaki kareli farkın ortalamasıdır.

-   MSE\'nin nasıl hesaplandığı nedeniyle, MSE büyük hatalara karşı çok
    hassastır.

### MAE: Ortalama mutlak hata

**MAE (ortalama mutlak hata)**, tahmin edilen ve gerçek değerler
arasındaki mutlak farkın ortalamasıdır.

-   Verilerinizde göz ardı etmek istediğiniz aykırı değerler varsa,
    büyük hatalara duyarlı olmadığı için MAE\'yi kullanabilirsiniz.

### Diğer değerlendirme metrikleri

Yukarıda listelenen üç metriğin ötesinde, [**AIC (Akaike bilgi kriteri)
ve BIC (Bayes bilgi
kriteri)**](https://machinelearningmastery.com/probabilistic-model-selection-measures/)
ile de karşılaşabilirsiniz.

Son olarak, gelecek videolarda daha ayrıntılı olarak ele alınacak olan
**ayarlanmış R²** var. Doğrusal bir regresyon modelinde birden fazla
bağımsız değişkene sahip olmayı açıklayan bir R² varyasyonudur.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   Basit doğrusal regresyon ile ilgili olarak aralarından seçim
    yapabileceğiniz birçok değerlendirme metriği vardır.

-   Karşılaşacağınız en yaygın değerlendirme metriği muhtemelen R²\'dir.
    Ancak, R²\'nin yetersiz veya kullanımının uygun olmadığı zamanlar
    vardır.

-   Deneyimlerinize ve bir metriğin ayrıntılarına dayanarak, bir
    regresyon modelini değerlendirmek için uygun bir metrik seçmek için
    en iyi kararınızı kullanabilirsiniz.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Korelasyona karşı nedensellik: Regresyon sonuçlarını yorumlayın
:::

::: {.cell .markdown}
Önceki videolarda, korelasyonun nedensellik olmadığını öğrendiniz. Bu
okumada, korelasyon ve nedensellik arasındaki farkları keşfetmeye devam
edeceksiniz, böylece regresyon sonuçlarını sorumlu, dürüst ve etkili bir
şekilde rapor etmeye hazır olacaksınız.

### Korelasyon nedir?

İki ana korelasyon türü olduğunu hatırlayabilirsiniz: pozitif ve negatif
korelasyon.

-   **Pozitif korelasyon**, birlikte artma veya azalma eğiliminde olan
    iki değişken arasındaki ilişkidir.

-   **Negatif korelasyon**, iki değişken arasındaki ters bir ilişkidir;
    burada bir değişken arttığında, diğer değişken düşme eğilimindedir
    ve bunun tersi de geçerlidir.

Genellemek için **korelasyon**, iki değişkenin birlikte değişme
eğilimini ölçer. İki değişken arasındaki ilişkiyi ölçebilen -1 ile 1
arasında değişen [Pearson korelasyon
katsayısı](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html)
adı verilen bir metrik vardır.

Korelasyonun sadece gözlemsel olduğunu unutmayın. İki değişken
ilişkilendirilebilir - bir değişken diğer değişkenin değişmesine neden
olmadan birlikte değişme eğilimindedirler. Aslında, değişkenler
arasındaki ilginç ve beklenmedik korelasyonları belgel [*emeye adanmış
bir web sitesi ve kitap olan Sahte
Korel*](https://www.tylervigen.com/spurious-correlations) asyonlar var.

Örneğin, oyun salonlarının elde ettiği toplam gelir ile Amerika Birleşik
Devletleri\'nde verilen bilgisayar bilimi doktoraları arasındaki
korelasyonu gösteren bir grafik burada. Zamanla, bilgisayar bilimleri
doktoraları ve arcade geliri yaklaşık aynı oranda artıyor. Yani, grafik
kesinlikle iki değişken arasında bir korelasyon gösteriyor, ancak
birinin diğerine neden olduğunu iddia etmek oldukça zor.

`<img src="attachment:dd808303-75d6-41ff-8455-374553a1133a.png" width="800"/>`{=html}

### Nedensellik iddiasında bulunmak zor

Daha önce **nedenselliğin, bir değişkenin** doğrudan diğerinin belirli
bir şekilde değişmesine neden olduğu bir neden-sonuç ilişkisini
tanımladığını öğrendiniz. Bu sezgisel bir tanım olmasına rağmen,
nedenselliği kanıtlamak, karşılanması için birçok özel koşul gerektirir.

Değişkenler arasındaki nedenselliği tartışmak için, genel olarak,
[**randomize
kontrollü**](https://www.urban.org/research/data-methods/data-analysis/quantitative-data-analysis/impact-analysis/experiments)
bir deney çalıştırmanız gerekir. Aşağıdakiler, uygun bir randomize
kontrollü deneyin bazı temel bileşenleridir:

-   Deneydeki her faktörü kontrol etmelisiniz.

-   Belirli koşullar altında bir kontrol grubunuz olmalıdır.

-   Belirli koşullar altında en az bir tedavi grubunuz olmalıdır.

-   Kontrol ve tedavi grupları arasındaki fark gözlemlenebilir ve
    ölçülebilir olmalıdır.

Rastgele kontrollü bir deney kurmak oldukça zahmetli ve yoğundur. Bu
okumaya dahil edilmeyen bir dizi gereksinim ve faktör vardır, ancak
çevrimiçi ve akademik araştırmalarda kendi başınıza keşfedebileceğiniz
birçok bilgi vardır. Nedensel iddiaların temellerini anlamak, veri
analizinizin sonuçlarını sorumlu bir şekilde raporlamanıza olanak tanır.

### Korelasyon ilginç içgörülere yol açar

Bir veri uzmanı olarak çalışırken, verilerin nasıl toplandığını
genellikle tam olarak kontrol edemezsiniz. Siz veya ekibiniz rastgele
kontrollü bir deney yürütemeyebilirsiniz. Ancak, nedensel iddialarda
bulunamasanız bile, korelasyonel araştırma yine de anlamlı ticari
etkileri olan ilginç sonuçlar verebilir.

#### **Senaryo 1: Atletik performansı optimize etme**

Bir koşucunun bir yarış için antrenman yaptığını varsayalım. Yerleşik
uygulamalardan ücretli uygulamalara kadar sağlık verilerini izlemenin
birçok yolu vardır. Ancak koşucunun performansına katkıda bulunabilecek
pek çok faktör de vardır - ne kadar su içtikleri, belirli bir günde
kaslarının ne kadar ağrıyor, hava durumu, ne kadar uyudukları, yarış
gününde hangi ekipmanı kullandıkları ve giydikleri kıyafetler. Herhangi
bir faktörün yarış zamanlarını bozacağını veya yarış süresini bozacağını
iddia etmek çok zor. Ancak zamanla, uyku, ağrı, su, giysi ve diğer
faktörlerin performansla nasıl ilişkili olma eğiliminde olduğuna dair
kalıplar gözlemlenebilir. Bu nedenle sporcular ekipman markaları,
diyetleri ve yarış öncesi gün rutinleri konusunda çok dikkatli
olabilirler.

#### **Yapabileceğiniz iddialar (korelasyon)**

-   Koşucu bir yarıştan önceki gün daha fazla su içtiğinde, daha fazla
    dayanıklılığa sahip olma eğilimindedir.

-   Koşucu bir yarıştan önceki hafta uzun mesafeler koşmadığında, yarış
    gününde daha iyi hissetme eğilimindedir.

#### **Yapamayacağınız iddialar (nedensellik)**

-   Bir yarıştan önceki gün daha fazla su içmek koşucunun daha hızlı
    koşmasına neden olur.

-   Bir yarıştan önceki hafta uzun mesafeler koşmamak koşucunun daha
    hızlı koşmasına neden olur.

#### **Senaryo 2: Gıda kalitesinin iyileştirilmesi**

Belki bir restoranda yeni bir şefsiniz veya kendiniz veya aileniz için
yemek pişiriyorsunuz. Her yemek yaptığınızda birçok değişken vardır:
hangi tava kullanıldı, malzemeler ne zaman satın alındı, malzemelerin
mevsiminde olup olmadığı ve herkesin ne kadar aç olduğu. Bu faktörlerden
herhangi biri yemeğin ne kadar "iyi" olduğunu değiştirebilir. Ancak, bu
veriler nedensel iddialardan bağımsız olarak değerlidir. Zamanla, daha
iyi yemek kalitesi sağlamak için bu yemek için pişirme becerilerinizi
geliştirebilirsiniz.

Bunlar, faktörler arasındaki korelasyonu anlamak için veri toplamanın
sonuçları büyük ölçüde iyileştirebileceği sadece iki örnektir. Aynı
ilkeler, optimize etmek istediğiniz istenen sonuca bağlı olarak, büyük
veri ile ve farklı endüstrilerde daha büyük ölçekte uygulanabilir.

#### **Yapabileceğiniz iddialar (korelasyon)**

-   Daha taze malzemeler kullandığımda, son yemeğin tadı daha iyi olur.

-   Çok acıktığımda, son yemeğin tadı daha iyi olur.

#### **Yapamayacağınız iddialar (nedensellik)**

-   Daha taze malzemeler kullanmak yemeğin tadını daha iyi hale getirir.

-   Daha aç olmak yemeğin tadını daha iyi hale getirir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   Nedensellik iddiasında bulunmak, genellikle kontrolünüz içinde
    olmayan belirli durumlar gerektirir.

-   Korelasyon analizleri, veri uzmanları için inanılmaz derecede
    yararlı bir araçtır ve ilginç içgörüler ve eyleme geçirilebilir
    sonraki adımlar sağlayabilir.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Çoklu lineer regresyon senaryoları
:::

::: {.cell .markdown}
### Okumanın Hedefleri

Artık çoklu doğrusal regresyonun ne olduğunu öğrendiğinize göre, bu
okumada, çoklu regresyon modellerinin bir şirketin veya kuruluşun bir iş
problemini anlamasına yardımcı olabileceği üç senaryoyu keşfedeceksiniz.
Okumanın amacı, çoklu doğrusal regresyonun çok yönlülüğünü anlamak ve bu
güçlü ve esnek regresyon tekniğinin çeşitli uygulamaları hakkında
düşünmenizi sağlamaktır.

#### Senaryo 1: Grafik tasarım hizmetlerinin satılması

Diyelim ki grafik tasarım hizmetleri satan bir şirkette çalışan bir veri
uzmanısınız. Çalıştığınız şirket, müşteri memnuniyeti ve tutma ile
ilgili faktörleri anlamakla ilgilenebilir. Bunu ölçmenin birçok yolu
vardır ve umut verici bir çoklu doğrusal regresyon modeli geliştirmek
için aşağıdaki faktörlerden herhangi birini kullanabilirsiniz.

##### **Potansiyel bağımlı değişkenler (Y)**

-   Müşteri memnuniyeti

-   Geri dönen müşteri sayısı

-   [Net Promoter
    Puanı](https://www.qualtrics.com/experience-management/customer/net-promoter-score/)

-   Müşteri hizmetlerinden memnuniyet

##### **Potansiyel bağımsız değişkenler (X)**

-   Hizmetlerin maliyeti

-   Müşteri hizmetleri yanıt süresi

-   Yeni grafik tasarım paketleri ekleme

-   Sayfa düzenini değiştirme

#### Senaryo 2: Bir restoran işletmek

Bir restoranda çalıştığınızı ve işinizin başarısını nasıl artıracağınızı
belirlemek istediğinizi hayal edin. Diğer müşteriye dönük işletmeler
gibi, maliyetlerinizi düşük, gelirinizi yüksek ve müşterilerinizi mutlu
etmek istersiniz. Önceki örneğe benzer şekilde, restoranın başarısını
ölçmenin birçok yolu vardır. Seçilen başarı metriği ile
ilişkilendirilebilecek bir dizi değişken de vardır.

##### **Potansiyel bağımlı değişkenler (Y)**

-   Toplam gelir

-   Çevrimiçi inceleme sayısı

-   Çevrimiçi beş yıldızlı inceleme sayısı

-   Haftalık rezervasyon sayısı

##### **Potansiyel bağımsız değişkenler (X)**

-   Reklam/pazarlama harcamaları

-   Operasyonel maliyetler

-   Menü boyutu

-   Yaya trafiği

-   Rezervasyonların iptali

-   İş ortaklıkları (örn.: teslimat uygulamaları, çiftçi pazarları,
    topluluk kuruluşları)

#### Senaryo 3: Tarımsal üretim

Diyelim ki tarımsal üretimde, belki bir çiftlikte veya bir çiftlikte
çalıştığınızı varsayalım. Bu, bir restorandan veya çevrimiçi hizmetten
çok farklı bir ortam olsa da, çoklu regresyon yine de yardımcı olabilir.
Örneğin, mahsul verimini, sezon gelirini veya satılan mahsul miktarını
tahmin etmeye çalıştığınızı varsayalım. Hava koşullarından toprak
koşullarına, emek ve kaynak kullanımına, bir çiftlik veya herhangi bir
tür tarımsal üretim için iyi bir yıla veya kötü bir yıla katkıda
bulunabilecek birçok faktör vardır. Çoklu regresyon, daha kötü yıllar
için daha iyi planlamaya ve tahmin etmeye yardımcı olmak için
kullanılabilir.

##### **Potansiyel bağımlı değişkenler (Y)**

-   Mahsul verimi

-   Gelir

-   Mahsuller satıldı

##### **Potansiyel bağımsız değişkenler (X)**

-   Hava (yağış, sıcaklık)

-   Topraktaki besinler

-   Tarihi mahsul verimi

-   Gübre maliyeti

-   Ekinleri korumak için kullanılan yakıt, su veya enerji maliyeti

-   İşçilik maliyeti

-   Yerel restoranlar veya marketlerle ortaklıklar

#### Önemli Çıkarımlar {#önemli-çıkarımlar}

-   Çoklu regresyon, değişkenler arasındaki daha karmaşık ilişkileri
    anlamanın ve tanımlamanın çok yönlü ve etkili bir yoludur.

-   Çoklu regresyon, çeşitli endüstrilerde ve bağlamlarda
    kullanılabilir.

#### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

-   ["Çoklu Regresyon: Tanım, Kullanımlar ve 5 Örnek." *Indeed Editör
    Ekibi*](https://www.indeed.com/career-advice/career-development/multiple-regression).

-   ["Çok Değişkenli Regresyon Analizi \| STATA Veri Analizi
    Örnekleri."](https://stats.oarc.ucla.edu/stata/dae/multivariate-regression-analysis/)
    *UCLA: İstatistiksel Danışmanlık Grubu.*
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Çoklu doğrusal regresyon varsayımları ve çoklu doğrusallık
:::

::: {.cell .markdown}
Önceki videolarda, doğrusal regresyon varsayımları hakkında bilgi
edinmişsinizdir. Bu okumada, çoklu doğrusal regresyon varsayımları
hakkındaki anlayışınızı genişletmek için bu bilgi tabanını
oluşturacaksınız. Bu okuma, hem basit doğrusal regresyon hem de çoklu
doğrusal regresyon için geçerli olan varsayımları gözden geçirmenize
yardımcı olacak ve daha sonra çoklu doğrusallık kavramına daha fazla
odaklanacaktır.

### Çoklu doğrusal regresyon varsayımları

Basit doğrusal regresyonun, analizden türetilen sonuçlara geçerlilik
sağlayan dört ana varsayıma sahip olduğunu hatırlayın. Dört varsayımdan
oluşan bu listeye, çoklu doğrusal regresyon ile çalışırken çoklu
doğrusallık yok varsayımını ekliyoruz.

1.  **Doğrusallık: Her tahmin** değişkeni (XiXi​), sonuç değişkeni (Y)
    ile doğrusal olarak ilişkilidir.

2.  **(Çok değişkenli) normallik: Hat** alar normal olarak dağıtılır.
    \*\*\*\*\*

3.  **Bağımsız gözlemler:** Veri kümesindeki her gözlem bağımsızdır.

4.  **Homoscedastisite:** Hataların değişimi model boyunca sabit veya
    benzerdir. \*\*\*\*\*

5.  **Çoklu doğrusallık yok: Hiçbir iki bağımsız değişken
    (**XiXi​**ve**XjXj​**) birbiriyle yüksek oranda ilişkili ol** amaz.

#### \*\*\* Hatalar ve artıklar hakkında not\*\* {#-hatalar-ve-artıklar-hakkında-not}

Daha önce belirtildiği gibi, "artıklar" ve "hatalar" bazen birbirinin
yerine kullanılır, ancak bir fark vardır. Doğrusal regresyonun normallik
ve homoskedastiklik varsayımlarını kontrol ederken hataları tahmin etmek
için artıkları kullanıyoruz.

-   **Kalıntılar**, öngörülen ve gözlemlenen değerler arasındaki
    farktır. Bir regresyon modeli oluşturduktan sonra, tahmin edilen
    değerleri gözlemlenen değerlerden çıkararak artıkları
    hesaplayabilirsiniz.

-   **Hatalar**, modelde olduğu varsayılan doğal gürültüdür.

### Önceki varsayımların genişletilmesi

Basit doğrusal regresyon ile ilgili ilk dört varsayım hakkında
öğrendiklerinizin çoğu doğrudan çoklu doğrusal regresyona uygulanabilir.
Kod biraz farklı veya daha uzun olabilir, ancak mantık aynıdır.

#### **Doğrusallık** {#doğrusallık}

-   Çoklu doğrusal regresyon ile, her *x* değişkeninin *y değişkeni ile
    doğrusal bir ilişkisi olup olmadığını düşün* meniz gerekir.

-   [Seaborn\'un](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)
    [pairplot () işlevini veya scatterplot
    ()](https://seaborn.pydata.org/generated/seaborn.pairplot.html)
    işlevini birden çok kez kullanarak tek yerine birden fazla dağılım
    grafiği yapabilirsiniz. Çizim yeteneklerine sahip diğer kitaplıklar
    benzer işlevlere sahip olacaktır.

**Bağımsız gözlemler**

-   Bağımsız gözlem varsayımı hala öncelikle veri toplamaya
    odaklanmıştır.

-   Varsayımın geçerliliğini basit doğrusal regresyonla yaptığınız gibi
    kontrol edebilirsiniz.

#### **(Çok Değişkenli) Normallik**

-   Tıpkı basit doğrusal regresyonda olduğu gibi, modeli oluşturabilir
    ve ardından artıkların bir Q-Q grafiğini oluşturabilirsiniz.

-   Q-Q grafiğinde düz bir çapraz çizgi gözlemlerseniz, analizinize
    devam edebilirsiniz. Ayrıca artıkların bir histogramını çizebilir ve
    bu şekilde normal bir dağılım gözlemleyip gözlemlemediğinizi kontrol
    edebilirsiniz.

-   **Not:** Doğrusal regresyon gerçekleştirirken bağımsız ve/veya
    bağımlı değişkenlerin normal olarak dağıtılması gerektiği yaygın bir
    yanlış anlaşılmadır. Durum böyle değil. Sadece modelin artıklarının
    normal olduğu varsayılır.

**Homoscedastisite**

-   Basit doğrusal regresyonda olduğu gibi, çoklu doğrusal regresyon
    için, sadece artıkların ve uygun değerlerin bir grafiğini oluşturun.

-   Veri noktaları, artıkların 0\'a eşit olduğu çizgiye rastgele
    dağılmış gibi görünüyorsa, devam edebilirsiniz.

### Çok kollinearite yok varsayımı nasıl kontrol edilir

Çoklu doğrusallık yok varsayımı, farklı bağımsız (X) değişkenler
arasındaki potansiyel ilişkilere odaklandığı için çoklu doğrusal
regresyona özgüdür. Çok kollinearite yok varsayımını değerlendirirken,
bağımsız (X) değişkenler arasındaki doğrusal ilişkileri tanımlamakla
ilgileniyorsunuz. Doğrusal olarak ilişkili X değişkenleri, modelin
sonuçlarının yorumlanmasını karıştırabilir. Doğrusal olarak ilişkili X
değişkenleri varsa, genellikle bazı bağımsız değişkenleri modelden
kaldırmak en iyisidir.

Bununla birlikte, verileriniz hakkında çıkarımlar yapmak için regresyon
modelinizi kullanırken çoklu doğrusallık olmadığı varsayımının en önemli
olduğunu unutmayın, çünkü eşdoğrusal verilerin dahil edilmesi, modelin
beta parametre tahminlerinin standart hatalarını artırır. Ancak,
modelinizin birincil amacının tahminlerde bulunmak olduğu ve doğru
tahminlere duyulan ihtiyacın verileriniz hakkında çıkarımlar yapma
ihtiyacından daha ağır bastığı zamanlar olabilir. Bu durumda, eşdoğrusal
bağımsız değişkenleri dahil etmek haklı gösterilebilir çünkü bunların
dahil edilmesinin daha iyi tahminlerle sonuçlanması mümkündür.

Çok kollinearite yok varsayımını kontrol etmenin birkaç yolu vardır. Bu
okuma bunlardan ikisini kapsayacak. Biri tamamen görsel, diğeri ise
doğası gereği sayısal. Her ikisi de doğrusal regresyon modelini
oluşturmadan önce yapılabilir.

#### **Dağılım grafikleri veya dağılım grafiği matrisi**

Bağımsız (X) değişkenler arasındaki çoklu doğrusallığı tanımlamanın
görsel bir yolu, dağılım grafikleri veya dağılım grafiği matrisleri
kullanmaktır. Süreç, doğrusallık varsayımını kontrol ettiğinizdeki ile
aynıdır, ancak şimdi X değişkenleri ile Y değişkeni arasındaki ilişkiye
değil, sadece X değişkenlerine odaklanıyorsunuz. Seaborn kitaplığını
kullanıyorsanız, işlevi veya pairplot scatterplot işlevi birden çok kez
kullanabilirsiniz.

#### **Varyans Enflasyon Faktörleri (VIF)**

Her bağımsız (X) değişken için varyans enflasyon faktörünün veya
VIF\'nin hesaplanması, diğer X değişkenleriyle korelasyon nedeniyle her
bir değişkenin varyansının ne kadar "şişirildiğini" ölçmenin bir
yoludur. VIF\'ler hakkında daha fazla bilgiyi [Pennsylvania Eyalet
Üniversitesi\'nin Eberly Bilim
Koleji](https://online.stat.psu.edu/stat462/node/180/) web sitesinde
veya Vilnius Üniversitesi\'nin Pratik E
[*konometri*](http://web.vu.lt/mif/a.buteikis/wp-content/uploads/PE_Book/4-5-Multiple-collinearity.html)
ve Veri Bilimi e-kitabının web sitesinde okuyabilirsiniz. VIF\'yi
hesaplamanın detayları bu dersin kapsamı dışındadır, ancak bunun, tüm
öngörücü değişkenlerin korelasyonsuz olduğu bir duruma göre standart
katsayı hatasının βiβi​ arttığı miktarı VIFiVIFi​​ temsil ettiğini bilmek
faydalıdır.

Her tahmin değişkeni için VIF\'yi hesaplamak için paketteki
[variance_inflation\_](https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html)
factor () işlevini kullanabilirsiniz. statsmodels İşte öngörücü
değişkenleriniz için VIF\'leri nasıl elde edebileceğinize dair bir
örnek.

``` python
from statsmodels.stats.outliers_influence import variance_inflation_factor

X = df[['col_1', 'col_2', 'col_3']]

vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

vif = zip(X, vif)

print(list(vif))
```

Bir VIF\'nin alabileceği en küçük değer 1\'dir ve bu, söz konusu X
değişkeni ile modeldeki diğer öngörücü değişkenler arasındaki 0
korelasyonunu gösterir. [Statsmodels
belgel](https://www.statsmodels.org/dev/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html#:~:text=The%20variance%20inflation%20factor%20is,of%20the%20design%20matrix%2C%20exog.)
erine göre 5 ve üzeri gibi yüksek bir VIF, çoklu doğrusallığın varlığını
gösterebilir.

### Modelinizde çoklu doğrusallık varsa ne yapmalı

#### **Değişken Seçimi**

Çoklu doğrusallığı ele almanın en kolay yolu, modelinizde yalnızca
bağımsız değişkenlerin bir alt kümesini kullanmaktır. Örneğin, çoklu
doğrusal regresyon modeliniz şöyle bir şeyse:

y=β0+β1X1+β2X2+β3X3y=β0​+β1​X1​+β2​X2​+β3​X3​

Ancak yüksek X1X1​ or X3X3​ anda ilişkiliyse, yalnızca X1X1​ veya X3X3​ son
modelinize dahil etmeyi seçebilirsiniz, ancak her ikisini de dahil
etmeyin.

Değişkenleri stratejik olarak seçmek için kullanabileceğiniz birkaç özel
istatistiksel teknik vardır. Gelecekteki videolarda bunlar hakkında daha
fazla bilgi edineceksiniz:

-   İleri seçim

-   Geriye dönük eleme

#### **İleri Teknikler** {#i̇leri-teknikler}

Bu kursta derinlemesine ele alınacak yukarıda listelenen tekniklere ek
olarak, bir veri uzmanı olarak kariyerinizde karşılaşabileceğiniz daha
ileri teknikler vardır, örneğin:

-   Sırt regresyonu

-   Kement regresyonu

-   Ana bileşen analizi (PCA)

Bu teknikler daha doğru ve öngörücü modellerle sonuçlanabilir, ancak
regresyon sonuçlarının yorumlanmasını zorlaştırabilir.

### Önemli Çıkarımlar {#önemli-çıkarımlar}

-   Basit doğrusal regresyon varsayımlarının çoğu, çoklu doğrusal
    regresyona kolayca uzanır.

-   Bir regresyon modelinde çoklu doğrusallığı kontrol etmek için
    dağılım grafiklerini ve varyans enflasyon faktörlerini
    kullanabilirsiniz.

-   Bir modelde çoklu doğrusallığı kaldırmak için değişken seçimi için
    farklı teknikler vardır.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## OLS Modeli Oluşturma
:::

::: {.cell .markdown}
``` python
import pandas as pd
import seaborn as sns

penguins = sns.load_dataset("penguins")
penguins.dropna(inplace=True)

penguins.head()
```

`<img src="attachment:70382301-abfc-4a31-9dee-bbe2944c3c1f.png" width="400"/>`{=html}

``` python
penguins_X = penguins[["bill_length_mm", "gender", "species"]]
penguins_y = penguins[["body_mass_g"]]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(penguins_X, penguins_y,
test_size = 0.3, random_state = 42)

ols_formula = "body_mass_g ~ bill_length_mm + C(gender) + C(species)" # C for categorical columns

from statsmodels.formula.api import ols

ols_data = pd.concat([X_train, y_train], axis = 1)
OLS = ols(formula = ols_formula, data = ols_data)
model = OLS.fit()
model.summary()
```

`<img src="attachment:5f280aed-ade2-4e28-a195-f63514ec6061.png" width="700"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Yetersiz ve aşırı uyum
:::

::: {.cell .markdown}
Öğrendiğiniz gibi, modeli popülasyondan görünmeyen verilere uygulamak ve
güvenilir sonuçlar elde etmek amacıyla ilgili popülasyondan örnek
veriler kullanılarak çoklu regresyon modeli oluşturulur. **Yetersiz**
uyum ve **aşırı uyum**, uygulanabilir olabilmesi için çoklu regresyon
modelinin azaltması gereken iki engeldir. Bu okumada, yetersiz uyum
konusunda genel bir anlayış kazanacak ve aşırı uyuma daha yakından
bakacaksınız.

### Bir modelin güvenilmez olmasının iki yolu

#### Yetersiz uyum

Yetersiz uyum durumunda, çoklu regresyon modeli, sonuç değişkenindeki
temel modeli yakalayamaz. Yetersiz bir modelin R-kare değeri düşüktür.

Bir model, çeşitli nedenlerle verilere yetersiz kalabilir. Modeldeki
bağımsız değişkenlerin sonuç değişkeni ile güçlü bir ilişkisi
olmayabilir. Bu durumda, farklı veya ek tahmin edicilere ihtiyaç vardır.
Örnek veri kümesinin çok küçük olması söz konusu olabilir ve bu, modelin
öngörücüler ile sonuç arasındaki ilişkiyi öğrenmesini engeller. Modeli
oluşturmak için daha fazla örnek veri kullanmak yetersiz uyum sorununu
azaltabilir.

İkinci el bir arabanın yeniden satış fiyatını tahmin eden çoklu
regresyon modeli örneğini düşünün. Bu modelin iki öngörücüsü vardır:
arabanın rengi ve üretildiği yıl. Modelin R-kare değeri oldukça
düşüktür. Bu, modelin yetersiz olduğunu gösterir çünkü mevcut
tahmincilerin otomobilin yeniden satış fiyatı ile güçlü bir ilişkisi
yoktur. Çoklu regresyon modelinde muhtemelen eksik olan başka önemli
öngörücüler vardır, arabadaki kilometre veya arabanın markası gibi.

Çoklu regresyon modelinin verilere yetersiz kalmasının ek nedenleri
vardır ve bu engeli azaltmak için kullanılan yöntemler belirli bağlama
bağlıdır. Yetersiz bir çoklu regresyon modeli, örnek verilerdeki
tahminciler ve sonuç arasındaki ilişkiyi yakalayamadığından, bu model
popülasyondan görünmeyen veriler üzerinde kullanıldığında da güvenilir
sonuçlar üretemeyecektir.

##### Eğitim verileri ve test verileri arasındaki fark

Aşırı uyum hakkında daha fazla bilgi edinmeden önce, çoklu regresyon
modeli oluşturmadan önce veri bilimcilerinin attığı bir adımı ele almak
önemlidir. Örnek verileri **eğitim** verileri ve **test verileri adı
verilen iki kategoriye ayırırlar**. Modeli oluşturmak için eğitim
verileri kullanılır ve modelin oluşturulduktan sonra performansını
değerlendirmek için test verileri kullanılır. Örnek verilerini bu
şekilde bölmek, **bekletme örne** ği test verisi olarak da adlandırılır.
Holdout örneklemesi, veri bilimcilerinin bir modelin henüz
deneyimlemediği veriler üzerinde nasıl performans gösterdiğini
değerlendirmesine olanak tanır.

Bekleme örneği **doğrulama verileri** olarak da adlandırılabilir. Ne
olursa olsun, genel fikir aynı kalır: modeli değerlendirmek için
kullanılan verilerdir.

Veri bilimcileri, örnek veri kümesini rastgele bölerek eğitim ve test
verilerini elde eder, böylece her kayıt yalnızca iki kategoriden birine
aittir. Bu şekilde, bazı kayıtlar eğitim verisi olarak kullanılır ve
diğer kayıtlar test verileri olarak kullanılır.

#### Aşırı uyum

Yetersiz uyum, çoklu regresyon modelinin eğitim verileri üzerinde kötü
performans göstermesine neden olur, bu da test verileri üzerindeki model
performansının da standartların altında olacağını gösterir. Buna
karşılık, aşırı uyum, bir modelin eğitim verileri üzerinde iyi
performans göstermesine neden olur, ancak görünmeyen test verileri
kullanılarak değerlendirildiğinde performansı önemli ölçüde daha
kötüdür. Bu nedenle veri bilimcileri, aşırı uyumu belirlemek için eğitim
verilerindeki model performansını test verileriyle karşılaştırır.

Aşırı uyumlu bir modelin eğitim verilerindeki performansı ile test
verileri arasında neden bir tutarsızlık var?

Aşırı uyumlu bir model, gözlemlenen veya eğitim verilerine çok özel
olarak uyar ve bu da modelin genel popülasyon için uygun tahminler
oluşturamamasına neden olur. Bu çoklu regresyon modeli, **sinyali**
(yani öngörücüler ve sonuç değişkeni arasındaki ilişki) *ve* **gürü**
ltüyü (yani veri kümesindeki bu ilişkinin parçası olmayan rastgeleliği)
yakalamıştır. Popülasyon için sonuçlar çıkarmak için aşırı uyum modeli
kullanamazsınız çünkü bu model **yalnızca** onu oluşturmak için
kullanılan veriler için geçerlidir.

Aşağıdaki grafikte, kesikli siyah çizgi, verilere aşırı uymadan kırmızı
ve mavi noktaları ayırt etmede iyi performans gösteren optimal bir çoklu
regresyon modelini temsil eder. Buna karşılık, kıvrımlı sarı çizgi,
verilere aşırı uyan bir modeli temsil eder. Bu çizgi, mavi noktaları
kırmızı noktalardan ayırma konusunda biraz daha iyi bir iş çıkarsa da,
bu verilere çok özeldir ve aynı popülasyondan başka bir örnekte iyi
performans göstermeyecektir. Buna karşılık, siyah çizgi iki rengi ayırt
etmede sürekli güvenilir olacaktır.

`<img src="attachment:217fd0e1-d48f-4e98-9379-5724dd82ecfa.png" width="400"/>`{=html}

### Aşırı uyum neden daha yüksek bir R-kare değeri ile sonuçlanır?

Daha önce R-karesinin bir uygunluk ölçüsü olduğunu öğrendiniz çünkü size
çoklu regresyon modelindeki bağımsız değişkenler tarafından yakalanan
sonuç değişkenindeki varyans oranını söyler. Bununla birlikte, bir
modele daha bağımsız değişken ekledikçe, ilişkili R-kare değeri, bu
tahmin edicilerin sonuç değişkeniyle güçlü bir ilişkiye sahip olup
olmadığına bakılmaksızın artacaktır.

Araba satış fiyatını tahmin eden çoklu regresyon modeli örneğinde,
modele arabayı satan kişinin adındaki harf sayısı ve arabayı satın alan
kişinin favori yemeği gibi daha bağımsız değişkenler eklemeye devam
edebilirsiniz (tabii ki bu verilere sahipseniz). Bu tahmin edicilerin
arabanın yeniden satış fiyatı ile bir ilişkisi olması pek olası
değildir, ancak bunları çoklu regresyon modelinize eklerseniz, R-kare
değeri yine de artacaktır. Bu, daha fazla öngörücüye sahip modelin daha
iyi performans gösterdiğini düşünmenize neden olsa da, şişirilmiş R-kare
değeri yanlış bir iyileşme işaretidir.

Genel olarak, R-karesi daha fazla öngörücüyle artmaya devam edecektir
çünkü model, tahmin edicilerin sonuç değişkeniyle güçlü bir ilişkisi
olmasa bile, üzerine inşa edildiği verilere aşırı derecede spesifik hale
gelecektir. Bu nedenle, yüksek bir R-kare değeri, modelin iyi performans
göstereceğini ve bunun yerine aşırı uyum işareti olabileceğini belirtmek
için tek başına yeterli değildir.

#### Bunun yerine ayarlanmış R-karesi ne zaman kullanılır

R-kare değeriyle birlikte, bir çoklu regresyon modeli de ilişkili bir
**ayarlanmış R-** kare değerine sahiptir. Düzeltilmiş R-karesi, çoklu
regresyon modeline daha bağımsız değişkenlerin eklenmesini cezalandırır.
Ek olarak, ayarlanmış R-karesi, yalnızca sonuç değişkeni ile önemli bir
ilişki gösteren bağımsız değişkenler tarafından açıklanan varyasyon
oranını yakalar. Bu farklılıklar, ayarlanan R-kare değerinin R-kare
değeri gibi şişmesini önler.

Değişen sayıda öngörücüye sahip çoklu regresyon modelleri arasında
karşılaştırma yaparken, daha fazla öngörücüye sahip modellerin daha
yüksek bir R-kare değerine sahip olduğunu görebilirsiniz. Bu aşırı
uyumun bir sonucu olabilir. Şişirilmiş R-karesine sahip aşırı uyumlu bir
model seçmekten kaçınmak için, en uygun modeli seçmek için ayarlanmış
R-kare metriğini kullanın.

### Önyargı ve varyans

Örnek verilere uymayan bir model, yüksek **önyargıya sahip olarak
tanımlan** ırken, yeni veriler üzerinde iyi performans göstermeyen bir
model yüksek **vary** ansa sahip olarak tanımlanır. Veri biliminde,
**önyargı ve varyans değiş tokuşu olarak bilinen bir fenomen vardır.**
Bu takas, veri bilimcilerinin herhangi bir makine öğrenimi modeli
oluştururken karşılaştıkları bir ikilemdir çünkü ideal bir model düşük
önyargıya ve düşük varyansa sahip olmalıdır. Bu, ne yetersiz ne de aşırı
formda olmaması gerektiğini söylemenin başka bir yoludur. Bununla
birlikte, önyargıyı azaltmaya çalıştıkça, varyans kaçınılmaz olarak
artar ve bunun tersi de geçerlidir.

Bu nedenle yetersiz ve aşırı uyum sorunlarını asla tam olarak
çözemezsiniz. Bunun yerine, çoklu regresyon modelinizde bu sorunları
mümkün olduğunca azaltmaya odaklanın.

### Önemli çıkarımlar {#önemli-çıkarımlar}

Hem yetersiz hem de aşırı uyum, güvenilir bir çoklu regresyon modeli
oluşturmanın önündeki engellerdir. Yetersiz uyum, eğitim verilerindeki
model performansıyla tanımlanabilse de, aşırı uyumu belirlemek için hem
eğitim hem de test performansını değerlendirmelisiniz. Aşırı uyum
şişirilmiş bir R-kare değeriyle sonuçlanacağından, değişen sayıda
öngörücüye sahip çoklu regresyon modelleri arasında karşılaştırma
yaparken ayarlanmış R-kare değerini kullanın. Yanlılığa karşı varyans
değiş tokuşu nedeniyle modelden yetersiz ve aşırı uyumu tamamen ortadan
kaldıramasanız da, bu sorunları tanımlandıktan sonra önemli ölçüde
azaltabilirsiniz.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

-   [Yetersiz uyumun ayrıntılı açıklaması ve nasıl
    azaltılacağı](https://www.ibm.com/cloud/learn/underfitting)

-   [train_test_split işlevi için Scikit-learn kütüphane
    belgeleri](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)

-   [Birden çok, ayarlanmış ve tahmin edilen R-kare değerlerini tartışan
    bir
    blog](https://blog.minitab.com/en/adventures-in-statistics-2/multiple-regession-analysis-use-adjusted-r-squared-and-predicted-r-squared-to-include-the-correct-number-of-variables)
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Ki-kare testleri: Bağımsızlığa karşı uyumun iyiliği  {#ki-kare-testleri-bağımsızlığa-karşı-uyumun-iyiliği-}
:::

::: {.cell .markdown}
Önceki derste, gruplar arasındaki önemli farklılıkları görmek için
hipotez testlerinin nasıl kullanıldığını öğrendiniz. Ki-kare testleri,
gözlemlenen bir veya daha fazla kategorik değişkenin beklenen
dağılımları takip edip etmediğini belirlemek için kullanılır. Örneğin,
hafta içi filmlere kıyasla hafta sonlarında sinemaya katılanların %50
daha fazla olmasını bekleyebilirsiniz. Sinemaya müdavimlerin katılımını
bir ay boyunca gözlemledikten sonra, ilk hipotezinizin doğru olup
olmadığını görmek için bir ki-kare testi yapabilirsiniz.

Bu okuma, beklenen hipotezinizi gerçekte olanlara karşı test etmek için
kullanılabilecek iki ana ki-kare testi (uygunluk iyiliği ve bağımsızlık
testi) kapsayacaktır. Veri uzmanları, kuruluşlara karar vermeyi
yönlendiren eyleme geçirilebilir içgörüler sunmak için bu hipotez
testlerini gerçekleştirir.

### Ki-kare uyumun iyiliği testi

**Ki-kare (χ²) uyum iyiliği testi, ikiden** fazla olası seviyeye sahip
gözlemlenen bir kategorik değişkenin beklenen bir dağılımı takip edip
etmediğini belirleyen bir hipotez testidir. Testin sıfır hipotezi (H 0),
kategorik değişkenin beklenen dağılımı takip etmesidir. Alternatif
hipotez (H a), kategorik değişkenin beklenen dağılımı takip etmemesidir.
Bu okumada senaryoya dayalı sıfır ve alternatif hipotezleri
tanımlayacak, bir Uyum İyiliği testi oluşturacak, test sonuçlarını
değerlendirecek ve bir sonuç çıkaracak senaryoyu düşünün.

### Ki-kare uyumun iyiliği senaryosu

Bir çevrimiçi giyim şirketi için bir veri uzmanı olarak çalıştığınızı
hayal edin. Patronunuz, web sitesi ziyaretçilerinin sayısının haftanın
her günü için aynı olmasını beklediklerini söyler. Patronunuzun
hipotezini test etmeye ve gelecek hafta için her gün veri çekmeye karar
verirsiniz ve web sitesi ziyaretçi sayısını aşağıdaki tabloya
kaydedersiniz:

  **Haftanın Günü**   **Gözlenen Değerler**
  ------------------- -----------------------
  Pazar               650
  Pazartesi           570
  Salı                420
  Çarşamba            480
  Perşembe            510
  Cuma                380
  Cumartesi           490
  Toplam              3.500

İşte atacağınız ana adımlar:

1.  Sıfır ve Alternatif Hipotezleri Tanımlayın

2.  Ki-kare testi istatistiğini hesaplayın (2**)**

3.  P değerini hesaplayın

4.  Bir sonuca varın

#### **Adım 1: Sıfır ve alternatif hipotezleri tanımlayın**

Ki-kare uyum iyiliği testi gerçekleştirmenin ilk adımı, sıfır ve
alternatif hipotezinizi belirlemektir. Web sitesi ziyaretçi sayısının
patronunuzun beklentilerini takip edip etmediğini test ettiğinizden,
aşağıda sıfır ve alternatif hipotezleriniz verilmiştir:

H 0: Gözlemlediğiniz hafta, patronunuzun web sitesi ziyaretçi sayısının
herhangi bir günde eşit olduğuna dair beklentilerini takip eder

H a: Gözlemlediğiniz hafta patronunuzun beklentilerini takip etmiyor; bu
nedenle, web sitesi ziyaretçi sayısı haftanın günleri boyunca eşit
değildir

#### **Adım 2: Ki-kare test istatistiğini hesaplayın (\*\*2)**

Ardından, sıfır hipotezinizi reddetmeniz veya reddetmemeniz gerektiğini
belirlemek için bir test istatistiği hesaplayın. Bu test istatistiği,
ki-kare istatistiği olarak bilinir ve aşağıdaki formüle göre hesaplanır:

`<img src="attachment:0a3328e8-05fa-41a0-9825-32cc04ae03a1.png" width="300"/>`{=html}

Bu formülün arkasındaki sezgi, her kategorik seviye için gözlemlenen
frekanslar ile beklenen frekanslar arasındaki herhangi bir tutarsızlığın
kapsamını ölçmesi gerektiğidir. Bu farklılıkları kareye çıkarmak iki şey
yapar. İlk olarak, gözlemlenen ve beklenen arasındaki tüm
tutarsızlıkların ki-kare istatistiğine olumlu katkıda bulunmasını
sağlar. İkincisi, daha büyük tutarsızlıkları cezalandırır. Kareli
farklılıkların toplamını her kategori seviyesinin beklenen sıklığına
bölmek, farklılıkları standartlaştırır. Başka bir deyişle, beklenen
frekanslar küçük olduğunda daha büyük tutarsızlıkların daha önemli
olduğu ve beklenen frekanslar büyük olduğunda daha az olduğu gerçeğini
açıklar.

Örneğe dönersek, gözlemlediğiniz toplam 3.500 web sitesi ziyaretçisi
olduğundan; patronunuzun beklentisi, her gün 500 ziyaretçinin ziyaret
edeceğidir (3.500/7). Yukarıdaki formülde, 500 "beklenen" değer olarak
hizmet edecektir. Her hafta içi gün için test istatistiği hesaplamasını
içeren orijinal tablonuza bir sütun eklendi:

  **Haftanın Günü**   **Gözlenen Değerler**   **Ki-Kare Test İstatistiği**
  ------------------- ----------------------- --------------------------------------
  Pazar               650                     (650−500)2500=45500(650−500)2​=45
  Pazartesi           570                     (570−500)2500=9.8500(570−500)2​=9.8
  Salı                420                     (420−500)2500=12.8500(420−500)2​=12.8
  Çarşamba            480                     (480−500)2500=0.8500(480−500)2​=0.8
  Perşembe            510                     (510−500)2500=0.2500(510−500)2​=0.2
  Cuma                380                     (380−500)2500=28.8500(380−500)2​=28.8
  Cumartesi           490                     (490−500)2500=0.2500(490−500)2​=0.2

2 istatistiği, yukarıdaki üçüncü sütunun toplamı olacaktır:

2 = 45 + 9.8 + 12.8 + 0.8 + 0.2 + 28.8 + 0.2

2 = 97.6

Beklenen değer ler beşten az olduğunda 2 uygunluk iyiliği testinin
güvenilir sonuçlar üretmediğini unutmayın.

#### **Adım 3: p değerini bulun** {#adım-3-p-değerini-bulun}

Artık 2 istatistiğini hesapladığınıza göre, şu soruyu düşünün: Sıfır
hipotezi doğruysa, 3.500 web sitesi ziyaretini incelerken 97.6 veya daha
büyük bir 2 istatistiği elde etme olasılığı nedir? Bu, p değerinin veya
"gözlemlenen anlamlılık seviyesinin" cevaplayacağı sorudur.

Uzun zaman önce Pearson, 2 istatistikleri için p değerlerinin 2 eğrileri
olarak bilinen belirli eğrilerin altındaki alanlarla çok yakından
karşılık geldiğini fark etti. 2 eğri olasılık yoğunluğu fonksiyonlarını
temsil eder ve şekilleri deneyde kaç serbestlik derecesinin mevcut
olduğuna bağlı olarak değişir. Serbestlik dereceleri, veriler tarafından
değil model tarafından belirlenir. Bu, web sitesi trafiği örneğinde,
serbestlik derecelerinin, belirli bir ziyaretin kaç farklı gün
gerçekleşebileceğine göre belirlendiği anlamına gelir - kaç ziyaretin
örneklendiği veya örneklerin günlük sıklıklarına göre değil. Model tam
olarak belirtildiğinde (yani, olası tüm kategorik seviyeleri
biliyorsunuz), o zaman:

**serbestlik dereceleri = kategorik seviyelerin sayısı - 1**.

Bu örnekte, yedi kategorik seviye vardır (haftanın her günü için bir
tane). Bu nedenle, altı serbestlik derecesi vardır. Bunun nedeni, her
seviyenin (günün) sayısının dalgalanmasının serbest olmasıdır, ancak
altı gün boyunca sayıları öğrendikten sonra, yedinci gün değişemez.
Diğer altı gün ile toplandığında toplam 3.500 ile sonuçlanmalıdır.

Aşağıdaki şekil, üç farklı ser bestlik derecesi için 2 eğrilerini
göstermektedir: beş, 10 ve 20.

`<img src="attachment:e1e8140f-eefc-420c-b5d6-9cce65b0b59b.png" width="500"/>`{=html}

Belirli bir 2 test istatistiği için p değeri, uygun serbestlik
derecelerinin 2 eğrisinin altındaki sağındaki alan ile çok yakından
tahmin edilir. Deneyde ne kadar fazla serbestlik derecesi varsa,
herhangi bir 2 test istatistiği için eğrinin sağ kuyruğunun altındaki
alan o kadar büyük olduğuna ve bu nedenle sıfır hipotez doğruysa belirli
bir 2 test istatistiğini alma olasılığının o kadar yüksek olduğuna
dikkat edin.

Aşağıdaki şekil altı serbestlik derecesi için 2 eğrisini içerir. Örneğin
10\' luk bir 2 test istatistiği için, P\'nin değeri, x ≥ 10 olduğu
eğrinin altındaki gölgeli alan ile yaklaşık olarak hesaplanır.

`<img src="attachment:610c42b4-f003-4e75-9e95-b2fab25b325e.png" width="500"/>`{=html}

Web sitesi ziyaretleri söz konusu olduğunda, altı serbestlik derecesi
vardır, ancak 2 test istatistiği, eğrinin sağa eğri kuyruğundaki x
ekseni boyunca 97.6 uzaktadır. Bu aralığın altındaki alan çok küçüktür:
7.94e-19. Başka bir deyişle, sıfır hipotez doğruysa 3.500 web sitesi
ziyaretinden ≥ 97,6 2 test istatistiği alma şansı 7,94e -17% -pratik
olarak sıfırdır.

#### **Adım 4: Bir sonuca varın**

P değeri 0,05\'ten çok az olduğundan, ziyaretçi sayısının günde eşit
olmadığını gösteren yeterli kanıt vardır.

#### Kodlama {#kodlama}

Neyse ki, 2 test istatistiğinizi manuel olarak hesaplamanıza veya P\'yi
elle belirlemenize gerek yok. Bunu yapmak için Python\'un scipy.stats
paketindeki [chisquare ()
işlev](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html)
ini kullanabilirsiniz. Aşağıdaki kod, ki-kare test istatistiğini ve p
değerini hesaplamak için gözlemlenen ve beklenen değerlerinizi kullanır.
Serbestlik derecelerinin gözlemlenen frekansların sayısı eksi bir olarak
ayarlandığını unutmayın. Bu, parametre kullanılarak ayarlanabilir, ancak
bu ddof parametrenin, gözlemlenen frekansların sayısı olan serbest k lik
k - 1 - ddof derecelerini temsil ettiğini unutmayın. Yani, varsayılan
olarak, ddof=0 işlevi çağırdığınızda ve ayar, serbestlik derecelerinizin
iki oranında azaltıldığı ddof=1 anlamına gelir.

``` python
import scipy.stats as stats

observations = [650, 570, 420, 480, 510, 380, 490]

expectations = [500, 500, 500, 500, 500, 500, 500]

result = stats.chisquare(f_obs=observations, f_exp=expectations)

result

Power_divergenceResult(statistic=97.599999999999994, pvalue=7.9438869233438347e-19)
```

Çıktı, Adım 2\'deki ki-kare test istatistiğini hesaplamanızı onaylar ve
ayrıca size ilişkili p değerini verir. P-değeri %5\'lik anlamlılık
seviyesinden az olduğundan, sıfır hipotezini reddedebilirsiniz.

### Bağımsızlık için Ki-kare testi

**Ki-kare (χ²) Bağımsızlık Testi**, iki kategorik değişkenin birbiriyle
ilişkili olup olmadığını belirleyen bir hipotez testidir. Verileriniz
rastgele bir örnekten geldiğinde ve genel popülasyon hakkında bir
çıkarım yapmak istediğinizde geçerlidir. Testin sıfır hipotezi (H 0),
iki kategorik değişkenin bağımsız olmasıdır. Alternatif hipotez (H a),
iki kategorik değişkenin bağımsız olmadığıdır.

### Bağımsızlık senaryosu için Ki-kare testi

Şimdi, bir web sitesi kullanıcısının kullandığı cihaz ile üyelik durumu
arasındaki ilişkiye bakmak için analizinizi genişletmeniz istendiğini
varsayalım. Bunu yapmak için bağımsızlık için 2 testini kullanmalısınız.
Bu örnekte, 2 bağımsızlık testi, bir ziyaretçinin web sitesini ziyaret
etmek için kullandığı cihaz türünün (Mac veya PC) bir üyelik hesabına
sahip olup olmadığına veya misafir (üye veya misafir) olarak göz atıp
gezinmediğine bağlı olup olmadığını belirler.

#### **Adım 1: Sıfır ve alternatif hipotezleri tanımlayın**

Uyum senaryosunun iyiliği gibi, ilk adım da sıfır ve alternatif
hipotezlerinizi belirlemektir. Giyim mağazanızı (Mac veya PC) ziyaret
etmek için kullanılan cihazın ziyaretçinin üyelik durumundan (üye veya
misafir) bağımsız olup olmadığını karşılaştırıyorsunuz. Bu bilgilerden
sıfır ve alternatif hipotezlerinizin aşağıdaki gibi olduğunu
belirleyebilirsiniz:

H 0: Bir web sitesi ziyaretçisinin web sitesini ziyaret etmek için
kullandığı cihaz türü, ziyaretçinin üyelik durumundan bağımsızdır.

H a: Bir web sitesi ziyaretçisinin web sitesini ziyaret etmek için
kullandığı cihaz türü, ziyaretçinin üyelik durumundan bağımsız değildir.

#### **Adım 2: Ki-kare test istatistiğini hesaplayın (\*\*2)**

2 test istatistiğini hesaplamak için, verileri *m* x *n* değerlerini
içeren bir tablo olarak düzenleyin; burada *m* ve *n*, her bir ilgili
kategorik değişken içinde bulunan olası seviyelerin sayısıdır. Aşağıdaki
tablo, web sitesi ziyaretçilerini kullandıkları cihaza ve üyelik
durumlarına göre ayırmaktadır..

  **Gözlenen Değerler**   **Üye**   **Misafir**   **Toplam**
  ----------------------- --------- ------------- ------------
  **Mac**                 850       450           1.300
  **PC**                  1.300     900           2.200
  **Toplam**              2.150     1.350         3.500

Tablonun toplamların türetildiği 2 x 2 bilinen değerle (her kategori
için iki seviye) başladığına dikkat edin. Bu toplamlar, 2 test
istatistiğini elde etmek için gerekli olan beklenen değerleri hesaplamak
için kullanılabilir.

Beklenen değerleri hesaplamak için aşağıdaki formülü kullanın:

expected value = column total ∗ row totaloverall totalexpected value = overall totalcolumn total ∗ row total​

Örneğin, bir Mac üyesi için beklenen değer şöyle olacaktır:

expected value = 2,150 ∗ 1,3003,500 =799expected value = 3,5002,150 ∗ 1,300​ =799

Bu hesaplamanın mantığı aşağıdaki gibidir: cihaz ve üyelik durumu
gerçekten bağımsızsa, üye olan Mac kullanıcılarının oranı, misafir olan
Mac kullanıcılarının oranı ile aynı olmalıdır. *Tüm* kullanıcılar
arasında Mac kullanan kullanıcıların yüzdesi 1.300/ 3.500 = 0.371 \* 100
= 37.1\'dir. Buna göre üyelerin %37,1\'inin ve misafirlerin %37,1\'inin
Mac kullanması bekleniyor. Yani, 0.371 \* 2.150 üye ≈ 799.

Aşağıdaki tablo beklenen tüm değerleri içerir:

  **Beklenen Değerler**   **Üye**   **Misafir**
  ----------------------- --------- -------------
  **Mac**                 799       501
  **PC**                  1.351     849

#### **Adım 3: p değerini bulun** {#adım-3-p-değerini-bulun-1}

Belirli bir 2 test istatistiği ile ilişkili p değerini bulmak, uyumun
iyiliği testi için zaten ana hatlarıyla belirtilen sürece benzer. Tek
küçük fark, serbestlik derecelerinin sayısının nasıl belirleneceğidir.
*M* x *n* olası seviyeye sahip iki kategorik değişkenli bir bağımsızlık
testi için, olasılıklar üzerinde başka bir kısıtlama olmadığını
varsayarsak (*m* --- 1) (*n* --- 1) serbestlik dereceleri vardır. Yani,
çalışma örneğinde bu, (2 - 1) (2 - 1) = 1 serbestlik derecesi olduğu
anlamına gelir. Bu örnekteki p değeri 0.00022\'dir. Python kullanılarak
belirlendi.

#### **Adım 4: Bir sonuca varın**

P-değeri 0.00022 olduğundan, sıfır hipotezi alternatif lehine
reddedebilirsiniz. Bir web sitesi kullanıcısının kullandığı cihaz
türünün üyelik durumundan bağımsız olmadığı sonucuna varırsınız.
Patronunuza, ziyaretçilerin belirli bir cihazda ücretli üyeliklere neden
daha fazla kaydolmasının ardındaki nedenlere dalmasını önerebilirsiniz..
Belki de kayıt düğmesi belirli bir cihazda farklı görünür. Ya da belki
düzeltilmesi gereken cihaza özgü hatalar vardır. Bunlar, daha fazla
keşif için düşünebileceğiniz şeylerin sadece birkaç örneğidir.

#### kodlama {#kodlama-1}

Bir 2 bağımsızlık testinin 2 test istatistiğini ve p değerini elde etmek
için scipy.stats paketin [chi2_contingency ()
işlev](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html)
ini kullanabilirsiniz. Fon chi2_contingency() ksiyon sadece gözlemlenen
değerlere ihtiyaç duyar; sizin için beklenen değerleri hesaplayacaktır.
İşte Python kodu:

``` python
import numpy as np

import scipy.stats as stats

observations = np.array([[850, 450],[1300, 900]])

result = stats.contingency.chi2_contingency(observations, correction=False)

result

(13.660757846804358, 0.00021898310129108426, 1, array([[  798.57142857,   501.42857143],
       [ 1351.42857143,   848.57142857]]))
```

Yukarıdaki çıktı şu sıradadır: 2 istatistiği, p değeri, serbestlik
dereceleri ve dizi biçiminde beklenen değerler. Dikkat edilmesi gereken
bir şey, serbestlik dereceleri = 1 olduğunda (yani, 2 x 2 tablonuz
varsa), stats.chi2_contingency() fonksiyonun varsayılan davranışının
[süreklilik için Yates\'in düzeltmesini
uygulamaktır](https://en.wikipedia.org/wiki/Yates's_correction_for_continuity).
Bu, küçük tutarsızlıkların önemli 2 değerleriyle sonuçlanma olasılığını
azaltmak içindir. Tablodaki beklenen bir frekansın küçük olması mümkün
olduğunda (genellikle \< 5) kullanılmak üzere tasarlanmıştır. Verilen
örnekte, beklenen değerlerin hepsinin beşin üzerinde olduğu
bilinmektedir. Bu nedenle, correction parametre False olarak ayarlandı.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   2 uyum iyiliği testi, gözlemlenen bir kategorik değişkenin belirli
    bir beklenen dağılımı takip edip etmediğini test etmek için
    kullanılır.

-   Bağımsızlık için 2 testi, iki kategorik değişkenin birbirinden
    bağımsız olup olmadığını test etmek için kullanılır (örnekler
    rastgele çekildiğinde ve tüm popülasyon hakkında bir çıkarım yapmak
    istediğinizde).

-   Her iki 2 testi de, bu programın başka yerlerinde keşfettiğiniz
    gibi, karar vermeyi yönlendirmek için sıfır hipotezi reddedip
    reddetmemeniz gerektiğini belirlemek için aynı hipotez test
    adımlarını izler.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## ANOVA hakkında daha fazla bilgi
:::

::: {.cell .markdown}
Varyans analizinin - Anova - gruplar arasındaki ortalama farkını test
eden bir grup istatistiksel teknik olduğunu öğrendiniz. ANOVA testi,
kategorik bağımsız değişkenlere dayalı grup farklılıkları hakkında bir
hipotezi test etmek istediğinizde kullanışlıdır. Örneğin, farklı
diyetleri takip ederken insanların kilosundaki değişikliklerin
istatistiksel olarak anlamlı mı yoksa tesadüfen mi olduğunu belirlemek
istiyorsanız, sonuçları analiz etmek için ANOVA\'yı kullanabilirsiniz.
Veri uzmanları, verilerinde gruplar arasında anlamlı farklılıklar olup
olmadığını rutin olarak belirlemelidir. Bu okuma, çalışılmış bir örnek
kullanarak ANOVA\'nın arkasındaki sezgiyi daha yakından inceleyecektir.
Programın ilerleyen kısımlarında, PYTHON\'da ANOVA\'nın nasıl
uygulanacağını öğreneceksiniz.

### **ANOVA\'ya genel bakış**

ANOVA\'nın arkasındaki sezgi, farklı gruplar arasındaki değişkenliği
gruplar içindeki değişkenlikle karşılaştırmaktır.
Karşılaştırılabilirlerse, gruplar arasındaki farklılıkların örnekleme
değişkenliğinden kaynaklanması daha olasıdır. Öte yandan, gruplar
arasındaki değişkenlik, kendi gruplarındaki örneklerden beklenen
değişkenlikten çok daha büyükse, o zaman bu gruplar muhtemelen önemli
ölçüde farklı alt popülasyonlardan alınmaktadır.

Gruplar arasındaki ve gruplar içindeki varyasyon, daha sonra bir oran
olarak ifade edilen karelerin toplamları olarak hesaplanır. Bu oran
F-istatistiği olarak bilinir. Bu hesaplamaların her bir bileşeni için
formül, aşağıdaki çalışılan örnekte sunulmuştur.

Daha önce, tek yönlü ve iki yönlü ANOVA\'yı öğrendiniz. İncelemek için:

-   **Tek yönlü ANOVA:** Bir kategorik değişkenin üç veya daha fazla
    grubuna dayalı olarak bir sürekli bağımlı değişkenin ortal **am**
    alarını karşılaştırır

-   İki **yönlü ANOVA:** **İki kategorik değişkenden oluşan üç veya daha
    fazla gruba dayalı bir sürekli bağımlı değişkenin ortalam** alarını
    karşılaştırır

ANOVA\'nın arkasındaki sezgiyi anlamanıza yardımcı olmak için, bu okuma
basit bir tek yönlü ANOVA testinin çalışılmış bir örneğini
parçalayacaktır.

### **Tek yönlü ANOVA**

#### 5 adım {#5-adım}

Tek yönlü bir ANOVA testi gerçekleştirmenin beş adımı vardır:

1.  Grup ortalamalarını ve büyük (genel) ortalamayı hesaplayın

2.  Gruplar arasındaki karelerin toplamını (SSB) ve gruplar içindeki
    karelerin toplamını hesaplayın (SSW)

3.  Hem SSB hem de SSW için ortalama kareleri hesaplayın

4.  F-istatistiğini hesaplayın

5.  Sıfır hipotezini reddedip reddetmeyeceğinize karar vermek için
    kullandığınız bir p değeri elde etmek için F-dağılımını ve
    F-istatistiğini kullanın

#### Örnek {#örnek}

Sınav için okuyan öğrenciler örneğine geri dönün. Bu durumda, sınav
puanı üzerinde bir etkisi olup olmadığını belirlemek için A, B ve C
olmak üzere üç farklı çalışma programını karşılaştırmak istediğinizi
varsayalım. İşte veriler:

  **Öğrenci**   **Çalışma programı (X)**   **Sınav puanı (Y)**
  ------------- -------------------------- ---------------------
  1             BİR                        88
  2             BİR                        79
  3             BİR                        86
  4             BİR                        90
  5             B                          94
  6             B                          84
  7             B                          87
  8             B                          89
  9             C                          85
  10            C                          76
  11            C                          81
  12            C                          78

İlk olarak, hipotezlerinizi belirtin:

H 0: A = B = C

A grubunun ortalama puanı = B grubunun ortalama puanı = C grubunun
ortalama puanı.

H 1: DEĞİL (A = B = C)

Her grubun araçları eşit değildir. Unutmayın, yalnızca bir ortalama
farklı olsa bile, bu sıfır hipotezi reddetmek için yeterli kanıttır.

Ardından, sıfır hipotezini reddedeceğiniz eşik olan güven seviyenizi
belirleyin. Bu değer durumunuza bağlıdır ve genellikle biraz alan
bilgisi gerektirir. Ortak bir eşik% 95\'tir.

Şimdi, ANOVA adımlarına başlayın.

**Adım 1**

**Grup ortalamalarını ve büyük ortalamayı hesaplayın. Büyük ortalama,
tüm gruplardaki tüm örneklerin genel ortalamasıdır.**

Aşağıdaki tablo, önceki tablodaki verileri, her çalışma grubu için
puanlar kendi sütunlarında yer alacak şekilde yeniden yapılandırır. Ek
olarak, her grubun ortalama puanı hesaplanmıştır.

  -----------------------------------------------------------------------
  **Çalışma programı A    **Çalışma programı B    **Çalışma programı C
  puanları**              puanları**              puanları**
  ----------------------- ----------------------- -----------------------
  88                      94                      85

  79                      84                      76

  86                      87                      81

  90                      89                      78

  **Ortalama: 85.75**     **Ortalama: 88.5**      **Ortalama: 80**
  -----------------------------------------------------------------------

**Büyük ortalama (MG) = 84.75**

**Adım 2**

**A. Gruplar arasındaki karelerin toplamını hesaplayın (SSB).**

`<img src="attachment:5a9c8b31-4090-4f5a-b76f-95ed1899af23.png" width="300"/>`{=html}

**B. Gruplar içindeki karelerin toplamını hesaplayın (SSW).**

`<img src="attachment:66629360-551c-4a6d-ab19-1e55c7453abd.png" width="300"/>`{=html}

Çift toplama, iç içe geçmiş bir döngü gibi davranır. Dış döngü her grup
içindir ve iç döngü o gruptaki tüm örnekler içindir. Bu nedenle, grup
1\'deki her örnek için, grubun ortalamasını çıkarın ve sonucu kareye
çıkarın. Ardından, grup 2 ortalamasını kullanarak grup 2\'deki
örneklerle aynı şeyi yapın. Tüm gruplar için bu şekilde devam edin ve
tüm sonuçları toplayın.

Aşağıdaki tablo, her gözlem ile grup ortalaması arasındaki kare farkı
göstermektedir. Ayrıca, A, B ve C olmak üzere üç çalışma grubunun her
biri için bu kare farklılıkların toplamlarını içerir.

  --------------------------------------------------------------------------------------------------
  Program A   Program B   Program C   (xAi−MA)2(xAi​−MA​)2   (xBi−MB)2(xBi​−MB​)2   (xCi−MC)2(xCi​−MC​)2
  ----------- ----------- ----------- -------------------- -------------------- --------------------
  88          94          85          5.06                 30.25                25

  79          84          76          45.56                20.25                16

  86          87          81          0.06                 2.25                 1

  90          89          78          18.06                0.5                  4

  MAMA​= 85.75 MBMB​= 88.5  MCMC​= 80    **Toplam: 68.75**    **Toplam: 53**       **Toplam: 46**
  --------------------------------------------------------------------------------------------------

→ **SSW** = 68,75 + 53+46

**= 167,75**

**Adım 3**

**Gruplar arasında ve gruplar içinde ortalama kareleri hesaplayın.
Ortalama kare, sırasıyla serbestlik derecelerine bölünen karelerin
toplamıdır.**

**A. Gruplar arası ortalama kareler (MSSB):**

`<img src="attachment:ce2eb168-e148-490e-9701-46791af23606.png" width="300"/>`{=html}

**B.** **Gruplar içindeki** **ortalama kareler (MSSW**):

`<img src="attachment:1da980c2-f96e-448f-ac51-b4dfef4da772.png" width="300"/>`{=html}

**4. Adım**

**F-istatistiğini hesaplayın.**

F-istatistiği, gruplar arasındaki ortalama kareler toplamının (MSSB)
gruplar içindeki ortalama karelerin toplamına (MSSW) oranıdır:

`<img src="attachment:936a4fbb-9cfb-416e-8d9a-2e7fc874ea08.png" width="300"/>`{=html}

Daha yüksek bir F-istatistiği, gruplar içindeki değişkenliğe göre grup
ortalamaları arasında daha büyük bir değişkenlik olduğunu gösterir, bu
da en az bir grup ortalamasının diğerlerinden önemli ölçüde farklı
olduğunu düşündürür.

**Adım 5**

**Sıfır hipotezini reddedip reddetmeyeceğinize karar vermek için
kullandığınız bir p değeri elde etmek için F-dağılımını ve
F-istatistiğini kullanın.**

T-testlerine ve 2 testlerine benzer şekilde, ANOVA testi, bir p değerini
belirlemek için sıfır hipotezinin belirli bir olasılık dağılımı eğrisi
(F-dağılımı) altındaki alanı bulur. F-istatistiği ne kadar büyükse,
eğrinin altındaki alan o kadar küçük olur ve sıfır hipoteze karşı daha
fazla kanıt olur, böylece daha düşük bir p değeri ile sonuçlanır.

F-dağılım eğrisinin şekli, gruplar arasındaki ve gruplar içindeki
serbestlik dereceleri ile belirlenir. İşte her grup 50 örnek içeren üç,
beş ve 10 grup için F dağılımlarını gösteren bir grafik. "dfn" nin
paydaki (gruplar arasında) serbestlik derecelerini temsil ettiğini ve
"dfd" nin paydadaki serbestlik derecelerini temsil ettiğini unutmayın
(gruplar içinde). Serbestlik derecelerinin eğrinin şeklini nasıl
etkilediğine dikkat edin.

`<img src="attachment:09ee8ce2-4436-4159-af93-7f10cac141bd.png" width="500"/>`{=html}

2 eğrilerine benzer şekilde, F-dağılımları sıfır hipotezini yanlış bir
şekilde reddetme olasılığını belirlemeye yardımcı olur. ANOVA durumunda,
bu olasılık, x ≥ F-istatistiğinizin olduğu eğrinin altındaki F
dağılımının alanı ile temsil edilir. Örneğin, aşağıdaki grafik sınav
puanları örneği için F dağılımını göstermektedir. Sayıda iki serbestlik
derecesi ve paydada dokuz serbestlik derecesi vardır. Eğrinin altındaki
alan x ≥ 4.04 (hesaplanan F-istatistiği) gölgelenmiştir.

`<img src="attachment:4d71f83f-b92c-409c-b3c6-16f23448deb5.png" width="500"/>`{=html}

Bu alanı hesaplamak için istatistiksel yazılım kullanabilirsiniz. Bunu
daha sonraki bir etkinlikte nasıl yapacağınızı öğreneceksiniz. Bu
durumda, 4.04\'ün sağındaki F dağılımının altındaki alan 0.05604\'tür.
Bu, sıfır hipotez doğruysa 4.04\'ten büyük bir F-istatistiğini
gözlemleme olasılığıdır. Bunun sıfır hipotezi reddetmek için yeterli
olup olmadığı, hipotez testinizin başında verdiğiniz bir karardır.
Örneğin,% 95 veya daha yüksek bir güven seviyesi istediğinize karar
verdiyseniz, p değeri 0.056 olduğu için her çalışma programı için
dağılımların ortalamalarının hepsinin aynı olduğuna dair sıfır
hipotezini reddedemezsiniz.

### **ANOVA Varsayımları**

ANOVA yalnızca aşağıdaki varsayımlar doğruysa çalışır:

1.  Her grup için bağımlı değerler normal dağılımlardan gelir

    -   Bu varsayımın, *tüm* bağımlı değerlerin birlikte ele alındığında
        normal olarak dağıtılması gerektiği anlamına gelmediğini
        unutmayın. Bunun yerine, *her grup içinde* bağımlı değerlerin
        normal olarak dağıtılması gerektiği anlamına gelir.

    -   ANOVA, merkezi limit teoremi nedeniyle, özellikle örneklem
        boyutları gruplar arasında büyük veya benzer olduğunda normallik
        ihlallerine karşı genellikle dayanıklıdır. Bununla birlikte,
        önemli ihlaller yanlış sonuçlara yol açabilir.

2.  Gruplar arasındaki varyanslar eşittir

    -   ANOVA, gruplar arasındaki ortalamaları karşılaştırır ve bu
        ortalamalar etrafındaki varyansın tüm gruplar için aynı olduğunu
        varsayar. Varyanslar eşit değilse (yani heteroskedastik), yanlış
        sonuçlara yol açabilir

3.  Gözlemler birbirinden bağımsızdır

    -   ANOVA, bir gözlemin başka bir gözlemi etkilemediğini veya tahmin
        etmediğini varsayar. Gözlemler arasında otokorelasyon varsa,
        ANOVA testinin sonuçları önyargılı olabilir.

### **Önemli çıkarımlar** {#önemli-çıkarımlar}

-   ANOVA testleri, bir veya daha fazla bağımsız kategorik değişkenin
    farklı seviyelerine dayalı olarak sürekli bağımlı bir değişkenin
    ortalamalarının birbirinden önemli ölçüde farklı olup olmadığını
    inceleyen istatistiksel testlerdir.

-   Bir grubun ortalamasının sıfır hipotezini reddetmesi için
    diğerlerinden önemli ölçüde farklı olması yeterlidir; ancak, ANOVA
    testi, *hangi* grubun farklı olduğunu söylememesi bakımından
    sınırlıdır. Böyle bir belirleme yapmak için başka testler
    gereklidir.

-   ANOVA, her grup arasındaki varyansı her grup içindeki varyansla
    karşılaştırarak çalışır. Gruplar arasındaki varyansın gruplar
    içindeki varyansa oranı ne kadar büyükse, sıfır hipotezini reddetme
    olasılığı o kadar yüksek olur.

-   ANOVA belirli varsayımlara bağlıdır, bu nedenle yanlış sonuçlar
    çıkarmaktan kaçınmak için verilerinizin bunları karşılayıp
    karşılamadığını kontrol etmek önemlidir. En azından, verileriniz
    hepsini karşılamıyorsa, bu ihlalleri tanımlayın.
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Python ile tek yönlü ve iki yönlü ANOVA testlerini keşfedin
:::

::: {.cell .markdown}
``` python
import pandas as pd
import seaborn as sns

diamonds = sns.load_dataset("diamonds")
diamonds = pd.read_csv("diamonds.csv")
diamonds.head()
```

`<img src="attachment:0129a2b9-7393-4cd7-ae5f-b6f1fa921fe3.png" width="300"/>`{=html}

``` python
sns. boxplot (x = "color", у = "log_price", data = diamonds)
```

`<img src="attachment:9a55f4a0-9025-4d13-b3dd-97d56a7cab3e.png" width="500"/>`{=html}

``` python
import statsmodels.api as sm 
from statsmodels.formula.api import ols

model = ols(formula = "log_price ~ C(color)", data = diamonds).fit()

#Get summary statistics 
model.summary()
```

`<img src="attachment:04f465a7-5128-44c9-ba7d-19f9dca0ad0b.png" width="600"/>`{=html}

``` python
import statsmodels.api as sm 
from statsmodels.formula.api import ols
model = ols(formula = "log_price ~ C(color)", data = diamonds).fit()
sm.stats.anova_lm(model, typ = 2)
```

`<img src="attachment:5cbc55f3-3187-4012-82e1-0f9722d27f08.png" width="500"/>`{=html}

``` python
diamonds2.head()
```

`<img src="attachment:00715aa0-3738-4742-85ea-652b1c35d425.png" width="300"/>`{=html}

``` python
model2 = ols(formula = "log_price ~ C(color) + C(cut) + C(color):C(cut)", data=diamonds2).fit()
sm.stats.anova_lm(model2, typ = 2)
```

`<img src="attachment:ffe3464c-7b88-4b00-a865-e956284ae4d3.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Python ile ANOVA post hoc testleri
:::

::: {.cell .markdown}
``` python
import statsmodels.api as sm 
from statsmodels.formula.api import ols
diamonds = pd.read_csv("diamonds.csv")

model = ols(formula = "log_price ~ C(color)", data = diamonds). fit()
sm.stats.anova_lm(model, typ=2)
```

`<img src="attachment:a8a01d3b-69c7-4695-940c-3dbc16084af5.png" width="500"/>`{=html}

PR\>F değeri % 0,05\'ten daha küçük olduğu için sıfır hipotezini
reddedebiliriz.

``` python
from statsmodels.stats.multicomp import pairwise_tukeyhsd
tukey_oneway = pairwise_tukeyhsd(endog = diamonds ["log_price"], groups = diamonds["color"], alpha = 0.05)
tukey_oneway.summary()
```

`<img src="attachment:627cdf57-c5f1-492f-964b-0b3cacb50e3a.png" width="500"/>`{=html}

Reject kısmı True olanlar için sıfır hipotezi reddedilebilir. (Fiyatlar
farklı renkler için aynı.) False olanlar için rededilemez. (Fiyatlar
farklı renkler için aynı değil.)
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Python ile lojistik regresyon modeli oluşturun
:::

::: {.cell .markdown}
``` python
activity.describe()
```

`<img src="attachment:0496198d-9a59-4295-8cd5-33d659f6fe7a.png" width="300"/>`{=html}

``` python
activity.head()
```

`<img src="attachment:16f1a0d6-eae8-44ca-b4ce-a8971db4973e.png" width="300"/>`{=html}

``` python
# Load in sci-kit learn functions for constructing logistic regression
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LogisticRegression

# Save X and y data into variables 
X = activity[["Acc (vertical)"]]
y = activity[["LyingDown"]]

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)

clf = LogisticRegression().fit(X_train, y_train)

clf.coef_
array([[-0.1177466]])

clf.intercept_
array([6.10177895])

import seaborn as sns
sns.regplot(x="Acc (vertical)", y="LyingDown", data=activity, logistic=True)
```

`<img src="attachment:4b921b19-1f3f-4768-95e3-b22c88ca13d4.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Bir binom lojistik regresyon modelini değerlendirin
:::

::: {.cell .markdown}
``` python
# Split data into training and holdout samples 
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)
# Build regression model 
clf = LogisticRegression().fit(x_train, y_train)
# Save predictions 
y_pred = clf.predict(x_test)

clf.predict(X_test) # tahmin değeri 0,5'den küçükse 0, değilse 1.
```

`<img src="attachment:d41b0a20-86a7-416f-ba7e-2ee4cc5aafc7.png" width="500"/>`{=html}

``` python
clf.predict_proba(X_test)[::,-1] # gerçek tahmin değeri
```

`<img src="attachment:6e5b1eb0-eb27-4a7f-90c2-35d990e45e77.png" width="700"/>`{=html}

``` python
import sklearn.metrics as metrics
cm = metrics.confusion_matrix(y_test, y_pred, labels = clf.classes_) #Y tahmini ile test (gerçek) değerlerinin karşılaştırılması
disp = metrics.ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = clf.classes_)
disp.plot()
```

`<img src="attachment:9f24eeca-e13c-463c-a1bc-d67e81333678.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Lojistik regresyon sonuçlarını değerlendirmek için temel ölçümler
:::

::: {.cell .markdown}
`<img src="attachment:1abd0eb3-38d3-45c8-8b02-6e92c0a4415f.png" width="500"/>`{=html}

`<img src="attachment:48eb66c5-0950-4a14-9c61-1b0591dfea76.png" width="500"/>`{=html}

`<img src="attachment:20513275-598b-4b7a-8f09-07396745a6cf.png" width="500"/>`{=html}

`<img src="attachment:7e668389-8866-4bbb-8387-e82e3a1fcb1e.png" width="500"/>`{=html}

`<img src="attachment:78cf24a5-4223-4c49-b345-2f5798ca67ed.png" width="500"/>`{=html}

`<img src="attachment:da3a2c68-baa5-496c-9e19-c823721ecbac.png" width="500"/>`{=html}

`<img src="attachment:8b36022d-b525-40dc-b987-ccab7172edcb.png" width="500"/>`{=html}
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Python\'da yaygın lojistik regresyon metrikleri
:::

::: {.cell .markdown}
Lojistik regresyon, veri bilimindeki kategorik tahmin görevleri için
güçlü bir tekniktir. Veri uzmanları, lojistik regresyon modellerinin
performansını ölçmek için genellikle kesinlik, hatırlama ve doğruluk
gibi metriklerin yanı sıra ROC eğrileri gibi görselleştirmeleri
kullanır. Bir modelin performansını değerlendirmek önemlidir, çünkü bu,
modelin ne kadar iyi tahminlerde bulunabileceğini gösterir. Ölçümlerin
uygulanmasından elde edilen sonuçlar, bir modelin ilgili paydaşlara ne
kadar iyi performans gösterdiğini bildirmek için kullanılabilir.

Bu okumada, bir karışıklık matrisinin bölümlerini gözden geçirecek ve
Python\'da kod yoluyla lojistik regresyonu değerlendirmek için
metriklerin nasıl hesaplanacağını ve görselleştirileceğini
anlayacaksınız.

### Karışıklık matrisinin parçaları

Bir karışıklık matrisi, bir sınıflandırıcının performansını özetlemeye
yardımcı olur. Bir karışıklık matrisinin bileşenleri, lojistik regresyon
sınıflandırıcılarını değerlendirmek için metrikleri hesaplamak için
kullanılır.

`<img src="attachment:253fa77e-2b88-44b2-b509-05f0ffc2ad5c.png" width="500"/>`{=html}

İkili sınıflandırma bağlamında bir karışıklık matrisinin dört temel
kısmı şunlardır:

1.  **Gerçek negatifler:**

Bir sınıflandırıcının Yanlış olarak doğru tahmin ettiği gözlemlerin
sayısı (0)

1.  **Gerçek pozitifler:**

Bir sınıflandırıcının Doğru olarak doğru tahmin ettiği gözlemlerin
sayısı (1)

1.  **Yanlış pozitifler:**

Bir sınıflandırıcının yanlış bir şekilde Doğru olarak tahmin ettiği
gözlemlerin sayısı (1)

1.  **Yanlış negatifler:**

Bir sınıflandırıcının Yanlış olarak yanlış tahmin ettiği gözlemlerin
sayısı (0)

Bu sayımlar, lojistik regresyon sınıflandırıcılarını değerlendirmek için
hassasiyet, hatırlama, doğruluk ve ROC gibi ölçümleri hesaplamada
kullanışlıdır.

### Hassasiyet

Bir lojistik regresyon sınıflandırıcısını değerlendirmek için ana
metriklerden biri kesinliktir**.** Precision, Gerçek olarak tahmin
edilen ve gerçekte Doğru olan veri noktalarının oranını ölçer. E-posta
spam tespiti için lojistik bir regresyon sınıflandırıcısı
oluşturduğunuzu, bu sınıflandırıcıyı ilgili bir veri kümesi üzerinde
eğittiğinizi ve bu sınıflandırıcıyı bir dizi e-posta için tahminler
oluşturmak için kullandığınızı hayal edin. Tahminler Doğru ve Yanlış
değerlerden oluşur. True, spam olarak tahmin edilen bir e-postayı temsil
eder ve Yanlış, spam olmadığı tahmin edilen bir e-postayı temsil eder.
Bu sınıflandırıcının hassasiyeti, spam olarak tahmin edilen tüm
e-postaların arasından aslında spam olan e-postaların oranını
iletecektir.

Hassasiyet formülü aşağıdaki gibidir:

`<img src="attachment:c9cefa0a-fda8-424e-b768-48bc10055d24.png" width="500"/>`{=html}

Python\'da kesinliği hesaplamak için sklearn kütüphanedeki metrics
modüldeki precision_score() işlevi kullanabilirsiniz. Aşağıdaki import
ifadesi ile başlayabilirsiniz.

``` python
import sklearn.metrics as metrics
```

Fonksiyon precision_score(), gerçek değerleri ve tahmin edilen değerleri
bağımsız değişken olarak alır ve kesinlik puanını döndürür. Sırasıyla
gerçek değer y_pred leri y_test ve tahmin edilen değerleri içeren
değişkenler olduğunu varsayalım. Kesinliği hesaplamak için aşağıdaki
kodu kullanabilirsiniz.

``` python
metrics.precision_score(y_test,y_pred)
```

E-posta spam algılama bağlamında, precision_score () 0.91 değerini
döndürürse, spam olarak tahmin edilen e-postaların% 91\'inin gerçekten
spam olduğu anlamına gelir.

### Hatırlama

Lojistik regresyon sınıflandırıcısını değerlendirmek için bir diğer
önemli metrik **hatır** lamadır. Geri çağırma, gerçekte Doğru olan tüm
veri noktalarından Doğru olarak tahmin edilen veri noktalarının oranını
ölçer. Dolandırıcılık tespiti ve tahminler üretmek için lojistik bir
regresyon sınıflandırıcısı oluşturduğunuzu hayal edin. Tahminlerde,
True, hileli olarak tahmin edilen bir kredi kartı işlemini temsil eder
ve False, hileli olmadığı tahmin edilen bir kredi kartı işlemini temsil
eder. Bu sınıflandırıcının geri çağırılması, sınıflandırıcının doğru bir
şekilde tanımladığı sahte kredi kartı işlemlerinin oranını iletecektir..

Geri çağırma formülü aşağıdaki gibidir:

`<img src="attachment:7afe223e-c066-4357-ace9-7a3f8e8ec7e3.png" width="500"/>`{=html}

Python\'da geri çağırmayı hesaplamak için metrik modülündeki
recall_score() işlevi kullanabilirsiniz. İşlev, gerçek değerleri ve
tahmin edilen değerleri bağımsız değişken olarak alır ve geri çağırma
puanını döndürür. Geri çağırmayı hesaplamak için aşağıdaki kodu
kullanabilirsiniz.

``` python
metrics.recall_score(y_test,y_pred)
```

Kredi kartı işlemleri arasında dolandırıcılık tespiti bağlamında, işlev
0.87 dön recall_score() dürüyorsa, dolandırıcı kredi kartı işlemlerinin%
87\'sinin doğru bir şekilde hileli olarak tespit edildiği anlamına
gelir.

### Doğruluk

Lojistik regresyonu değerlendirmek için bir diğer önemli metrik
**doğruluktur**. Doğruluk, doğru sınıflandırılan veri noktalarının
oranını ölçer. Kredi onay tahmini için lojistik bir regresyon
sınıflandırıcısı oluşturduğunuzu hayal edin. Tahminlerde True, kredinin
onaylanacağına dair bir tahmini temsil eder ve Yanlış, kredinin
onaylanmayacağına dair bir tahmini temsil eder. Bu sınıflandırıcının
doğruluk puanı, doğru sınıflandırılmış kredilerin oranını iletecektir.

Doğruluk formülü aşağıdaki gibidir:

`<img src="attachment:f6cb0c49-6e9b-48e3-9b93-93055a57e20b.png" width="500"/>`{=html}

Python\'da doğruluğu hesaplamak için metrik modülündeki accuracy_score()
işlevi kullanabilirsiniz. İşlev, gerçek değerleri ve tahmin edilen
değerleri bağımsız değişken olarak alır ve doğruluk puanını döndürür.
Doğruluğu hesaplamak için aşağıdaki kodu kullanabilirsiniz.

``` python
metrics.accuracy_score(y_test,y_pred)
```

Kredi onay tahmini bağlamında, accuracy_score() fonksiyon 0.90
döndürüyorsa, bu, kredilerin% 90\'ının doğru tahmin edildiği ve
tahminlerin onaylanacağı veya onaylanmayacağı anlamına gelir.

### ROC eğrileri

Bir **ROC eğrisi**, bir lojistik regresyon sınıflandırıcısının
performansını görselleştirmeye yardımcı olur. ROC eğrisi alıcı çalışma
karakteristik eğrisi anlamına gelir. Bir sınıflandırıcının performansını
farklı sınıflandırma eşiklerinde görselleştirmek için bir ROC eğrisinin
grafiğini çizebilirsiniz. İkili sınıflandırma bağlamında, bir
sınıflandırma eşiği, pozitif sınıfı negatif sınıftan ayırmak için bir
sınıftır.

Bir ROC eğrisi iki temel kavramı çizer

1.  **Gerçek Pozitif Oranı: Geri** Çağırmaya eş **değerdir.** Gerçek
    Pozitif Oranın formülü aşağıdaki gibidir:

`<img src="attachment:622b7dbe-f89a-44a8-b1af-430da1ea2e21.png" width="500"/>`{=html}

1.  **Yanlış Pozitif Oranı:** Yanlış Pozitifler ile Yanlış olarak tahmin
    edilmesi gereken toplam gözlem sayısı arasındaki oran. Yanlış
    Pozitif Oranı formülü aşağıdaki gibidir:

`<img src="attachment:749c400a-f3a1-465f-9cd7-a2f326effae3.png" width="500"/>`{=html}

Eğrideki her nokta için, x ve y koordinatları, karşılık gelen eşikte
sırasıyla Yanlış Pozitif Oranı ve Gerçek Pozitif Oranını temsil eder.

`<img src="attachment:8496373d-85af-42c1-8dfc-5ef633465be9.png" width="500"/>`{=html}

An example of an ROC curve. For each point on the curve, the x and y
coordinates represent the False Positive Rate and the True Positive Rate
respectively at the corresponding threshold.

Yanlış Pozitif Oranın ve Gerçek Pozitif Oranın farklı eşikler üzerinde
birlikte nasıl değiştiğini gözlemlemek için bir ROC eğrisini
inceleyebilirsiniz. İdeal bir model için ROC eğrisinde, Gerçek Pozitif
Oranın yüksek ve Yanlış Pozitif Oranın düşük olduğu bir eşik olacaktır.
ROC eğrisi grafiğin sol üst köşesini ne kadar çok kucaklarsa, model
verileri sınıflandırmada o kadar iyi olur.

Python\'da bir ROC eğrisinin grafiğini çizmek için aşağıdaki adımları
kullanabilirsiniz.

Gerekli modülleri aşağıdaki gibi içe aktararak başlayın.

``` python
import matplotlib.pyplot as plt
from sklearn.metrics import RocCurveDisplay
```

Ardından ROC eğrisini çizmek için aşağıdaki kodu kullanın.

``` python
RocCurveDisplay.from_predictions(y_test, y_pred)
plt.show()
```

Bir ROC eğrisi oluşturmak için bu adımları kullanmak bir grafikle
sonuçlanabilir.

`<img src="attachment:4a8cd863-1554-4b2f-90cf-34d1bd1b144d.png" width="700"/>`{=html}

Bu grafikte, ROC eğrisi, karşılık gelen sınıflandırıcının iyi performans
gösterdiğini gösterir.

### AUC

**AUC**, ROC eğrisinin altındaki alan anlamına gelir. AUC, olası tüm
sınıflandırma eşiklerinde toplam bir performans ölçüsü sağlar. AUC\'nin
değeri 0.0 ile 1.0 arasında değişir. Tahminleri% 100 yanlış olan bir
modelin AUC\'si 0.0 ve tahminleri% 100 doğru olan bir modelin AUC\'si
1.0\'dır. 0.5\'ten küçük bir AUC, modelin rastgele bir sınıflandırıcıdan
daha kötü performans gösterdiğini gösterir (yani, her örneği rastgele
Doğru veya Yanlış\'a atayan bir sınıflandırıcı) ve 0.5\'ten büyük bir
AUC, modelin rastgele bir sınıflandırıcıdan daha iyi performans
gösterdiğini gösterir.

Aşağıdaki görselleştirmede AUC, gölgeli bölgenin alanıdır.

`<img src="attachment:6af931dd-50ae-4248-a0c7-5fc7e2d2dcf5.png" width="500"/>`{=html}

Python\'da AUC\'yi hesaplamak için metrik modülünden roc_auc_score ()
işlevini kullanabilirsiniz. İşlev, gerçek değerleri ve tahmin edilen
değerleri bağımsız değişken olarak alır ve doğruluk puanını döndürür.
AUC\'yi hesaplamak için aşağıdaki kodu kullanabilirsiniz.

``` python
metrics.roc_auc_score(y_test,y_pred)
```

Örneğin, e-posta spam tespiti için lojistik regresyon sınıflandırıcısı
bağlamında, roc_auc_score() işlev 0.99 döndürüyorsa, sınıflandırıcının
tahminlerinin %99\'unun tüm sınıflandırma eşiklerinde doğru olduğu
anlamına gelir.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   Hassasiyet, Geri Çağırma ve Doğruluk, lojistik regresyon
    sınıflandırıcısının performansını değerlendirmek için kullanılan
    yaygın ölçütlerdir.

-   Bu metrikleri Python\'da hesaplamak için sklearn kitaplığındaki
    metrikler modülündeki işlevleri kullanabilirsiniz.

-   Bir ROC eğrisinin grafiğini çizmek, bir sınıflandırıcının farklı
    sınıflandırma eşiklerinde nasıl performans gösterdiğini
    görselleştirmeye yardımcı olur.

-   AUC\'yi hesaplamak, bir sınıflandırıcının eşikler arasındaki
    performansını tek bir ölçümde toplamaya yardımcı olur.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

-   [precision_score:
    precision_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)
    () işlevi ile ilgili belgeler

-   [recall_score:
    recall_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html?highlight=recall_score#sklearn.metrics.recall_score)
    () işlevi ile ilgili belgeler

-   [preciacy_score:
    preciacy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy_score#sklearn.metrics.accuracy_score)
    işlevi ile ilgili belgeler

-   [RocCurveDisplay.FROM_PREDICTIONS:
    RocCurveDisplay.from_predictions](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay.from_predictions)
    işleviyle ilgili belgeler

-   [roc_auc_score:
    roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)
    işlevi ile ilgili belgeler
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Lojistik regresyon modellerini yorumlayın
:::

::: {.cell .markdown}
Lojistik regresyon modelini yorumlamak, katsayıları ve hesaplama
metriklerini incelemeyi içerir. Lojistik regresyon modelinizi eğitim
verilerine uydurduktan sonra, Python\'daki kodu kullanarak modelden
katsayı tahminlerine erişebilirsiniz. Daha sonra modelin nasıl tahmin
yaptığını anlamak için bu değerleri kullanabilirsiniz. Bu okuma size
lojistik bir regresyon modelinden katsayıların nasıl yorumlanacağına ve
model değerlendirmesi için metrikleri seçerken göz önünde bulundurulması
gereken hususlara bir örnek gösterecektir.

### Modelden katsayılar

Lojistik regresyon modelinin nasıl çalıştığını anlamak için değişkenler
arasındaki ilişkiyi tanımlayan denklemle başlamak önemlidir. Bu denklem
aynı zamanda logit fonksiyonu olarak da adlandırılır.

#### **Logit işlevi**

Logit işlevi bağımsız değişkenler cinsinden yazıldığında, aşağıdakileri
iletir: her bağımsız değişken arasında doğrusal bir ilişki vardır ve
bağımlı değişkeninXX,, 1\'e eşit olma olasılığının logiti vardırYY. Bu
olasılığın logiti, bu olasılığın olasılıklarının logaritmasıdır.

Binom lojistik regresyonda logit fonksiyonunun denklemi aşağıda
gösterilmiştir. Bu, 1\'e YY eşit olasılığı içerir, çünkü 1, olası
değerlerin 1 ve 0 olduğu ikili sınıflandırmada ilgi alanının YY tipik
sonucudur.

`<img src="attachment:6f8f4693-04ca-4e11-98c0-3b6d21ca771e.png" width="400"/>`{=html}

#### **Katsayıları yorumlayın**

E-postaları spam veya spam olmayan olarak tahmin etmek için binom
lojistik regresyon modeli oluşturduğunuzu hayal edin. Bağımlı değişken,
Y, bir e-postanın spam (1) veya spam olmayan (0) olup olmadığıdır.
Bağımsız değişken X1, mesaj uzunluğudur. Bunun eğitim clf verilerine
taktığınız sınıflandırıcı olduğunu varsayalım.

Model tarafından β1β1 tahmin edilen katsayıya erişmek için aşağıdaki
kodu kullanabilirsiniz:

`clf.coef_`

Örneğin tahmini 0.186 β1 ise, bu, mesaj uzunluğundaki bir birimlik
artışın günlük oranındaki 0.186 artışla ilişkili olduğu anlamına gelir.
p Y oranlarındaki değişikliği yüzde olarak yorumlamak için aşağıdaki
gibi β1 üstlenebilirsiniz.

`<img src="attachment:25dd4120-1353-4614-87e2-b59bbdd68f04.png" width="200"/>`{=html}

Bu nedenle, mesaj uzunluğundaki her bir birim artış için, e-postanın
spam olma ihtimalinin 1.204 veya %20.4 artmasını bekleyebilirsiniz.

### Metrik seçerken dikkat edilmesi gerekenler

Bir lojistik regresyon modelinden katsayıları inceledikten sonraki bir
sonraki önemli adım, modeli metrikler aracılığıyla değerlendirmektir. En
sık kullanılan ölçümler arasında hassasiyet, geri çağırma ve doğruluk
bulunur. Aşağıdaki bölümler, bunlar arasında seçim yaparken akılda
tutulması gereken şeyleri açıklamaktadır..

#### **Hassasiyet ne zaman kullanılır**

Kesinliği bir değerlendirme metriği olarak kullanmak, özellikle yanlış
bir pozitifin maliyetinin oldukça yüksek olduğu ve yanlış negatifin
maliyetinden çok daha yüksek olduğu bağlamlarda faydalıdır. Örneğin,
e-posta spam tespiti bağlamında, yanlış bir pozitif (spam olmayan bir
e-postayı spam olarak tahmin etmek) yanlış bir negatiften (spam
e-postayı spam olmayan olarak tahmin etmek) daha maliyetli olacaktır.
Yanlış sınıflandırılan spam olmayan bir e-posta, satıcıdan müşteriye
proje durumu güncellemeleri veya bir eğitmenden öğrenci sınıfına ödev
son tarihi duyuruları gibi önemli bilgiler içerebilir.

#### **Geri çağırma ne zaman kullanılır**

Hatırlamayı bir değerlendirme metriği olarak kullanmak, özellikle yanlış
bir negatifin maliyetinin oldukça yüksek olduğu ve yanlış pozitifin
maliyetinden çok daha yüksek olduğu bağlamlarda faydalıdır. Örneğin,
kredi kartı işlemleri arasında dolandırıcılık tespiti bağlamında, yanlış
bir negatif (sahte bir kredi kartı ücretini hileli olmayan olarak tahmin
etmek), yanlış bir pozitiften (hileli olmayan bir kredi kartı ücretinin
hileli olarak tahmin edilmesi) olduğundan daha maliyetli olacaktır.
Yanlış sınıflandırılan sahte bir kredi kartı ücreti, müşterinin tespit
edilmeden para kaybetmesine neden olabilir.

#### **Doğruluk ne zaman kullanılır**

Eldeki verilerin ne kadarının sınıflandırıcı tarafından doğru bir
şekilde kategorize edildiğini özellikle bilmek istediğinizde, doğruluğu
bir değerlendirme metriği olarak kullanmak yararlıdır. Dikkate alınması
gereken başka bir senaryo: doğruluk, veriler dengelendiğinde, başka bir
deyişle, veriler kabaca eşit sayıda olumlu örneğe ve olumsuz örneğe
sahip olduğunda kullanmak için uygun bir metriktir. Aksi takdirde,
doğruluk önyargılı olabilir. Örneğin, bir veri kümesinin %95\'inin
olumlu örnekler içerdiğini ve geri kalan% 5\'inin negatif örnekler
içerdiğini hayal edin. Daha sonra bu veriler üzerinde bir lojistik
regresyon sınıflandırıcısı eğitirsiniz ve bu veriler üzerinde bu
sınıflandırıcı tahmin kullanırsınız. %95\'lik bir doğruluk elde
ederseniz, bu mutlaka bu sınıflandırıcının etkili olduğunu göstermez.
Olumsuz örneklerden çok daha büyük bir pozitif örnek oranı olduğundan,
sınıflandırıcı çoğunluk sınıfına (pozitif) karşı önyargılı olabilir ve
bu nedenle bu bağlamdaki doğruluk metriği anlamlı olmayabilir.
Çalıştığınız veriler dengesiz olduğunda, dengelenecek şekilde
dönüştürmeyi veya doğruluk dışında farklı bir değerlendirme metriği
kullanmayı düşünün.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   Modelin bağımlı değişkeni nasıl tahmin ettiğini anlamak için bir
    modeldeki beta katsayılarını inceleyin.

-   Bir lojistik regresyon sınıflandırıcısını değerlendirmek için hangi
    metriklerin anlamlı olduğunu belirlerken, ilgili verilerin
    bağlamını, tahminlerin nasıl kullanılacağını ve bu bağlamda Yanlış
    Pozitiflere karşı Yanlış Negatiflerin ne kadar etkili olduğunu göz
    önünde bulundurun.

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

-   [LojistikRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html):
    Bir modelden kesişme ve katsayıları kullanarak sklearn ve bunlara
    erişen Lojistik Regresyon modellerinin uygulanmasına yönelik
    dokümantasyon
:::

::: {.cell .markdown jp-MarkdownHeadingCollapsed="true"}
## Farklı regresyon türleri ile tahmin
:::

::: {.cell .markdown}
Öğrendiğiniz gibi, bir veri uzmanı olarak çalışmalarınızda
karşılaşacağınız temel regresyon teknikleri arasında doğrusal regresyon,
hipotez testi ve lojistik regresyon yer alır. Amacınız verilerle
tahminler yapmak olduğunda, bu farklı yaklaşımları göz önünde
bulundurmak ve hangi yaklaşımın görevinize en iyi şekilde ulaşmanıza
yardımcı olacağını düşünmek önemlidir. Bu okumada, cevaplamak
istediğiniz soruya, sonuç değişkenine ve nasıl ölçüldüğüne bağlı olarak
bir proje için en alakalı regresyon tekniğini nasıl seçeceğiniz hakkında
daha fazla bilgi edineceksiniz.

### Regresyon tekniği nasıl seçilir

Bir regresyon tekniği seçerken, üzerinde çalıştığınız verileri ve ele
almak istediğiniz soruyu dikkate almak önemlidir.

#### **Dikkate alınması gerekenler**

1.  Cevaplamak istediğin soru nedir? Başka bir deyişle, ne tahmin etmek
    istiyorsun?

2.  Verilerinizdeki hangi değişken sonuç değişkeni olabilir?

3.  Sonuç değişkeni nasıl ölçülür? Sonuç değişkeni sürekli ise, doğrusal
    regresyon veya hipotez testinin en uygun olması daha olasıdır.
    Bununla birlikte, sonuç değişkeni ikili ise, lojistik regresyonun
    daha yararlı olduğunu göreceksiniz.

### Regresyon için örnek bağlamlar

Aşağıdaki örnekler, bir regresyon tekniği seçmek için tahmin, sonuç
değişkeni ve ölçüm hakkındaki soruların nasıl gezinilebileceğini
göstermektedir.

#### **Örnek bağlam: Kullanıcı katılımı**

Bir veri uzmanı olarak çalışmalarınızda, bir mobil uygulama için
kullanıcı katılımı hakkında tahminlerde bulunmakla ilgilendiğinizi hayal
edin.

İlk olarak, sorabilirsin, cevaplamak istediğin soru nedir?

Olası bir soru şu olabilir: "Her uygulama içi özellik kullanıcı
etkileşimini ne kadar etkiler?" Uygulama içi özellikler, müşteri
desteğiyle canlı sohbet, haftalık olarak güncellenen bir SSS bölümü ve
diğer kullanıcılarla bağlantı kurmak için bir topluluk alanı içerebilir.
Ardından, verilerinizdeki hangi değişkenin sonuç değişkeni olabileceğini
sorabilirsiniz. Kullanıcıların oturum uzunlukları hakkındaki verilere
erişiminiz varsa (başka bir deyişle, kullanıcıların uygulamayı her
açtıklarında ne kadar süre harcadıkları), sonuç değişkeni oturum
uzunluğu olabilir. Bir sonraki sorunuz şu olabilir: sonuç değişkeni
nasıl ölçülür? Oturum uzunluğu, sürekli olan dakika sayısı ile
ölçülebilir. Sonuç değişkeni sürekli olduğundan ve her özelliğin sonuç
değişkenini ne kadar etkilediğiyle ilgilendiğinizden, doğrusal
regresyona devam edebilir ve ilgili model varsayımlarını kontrol
edebilirsiniz. İlgilendiğiniz tek bir özellik varsa, basit bir doğrusal
regresyon modeli oluşturursunuz. İlgilenilen birden fazla özellik varsa,
çoklu doğrusal regresyon modeli oluşturursunuz.

Bir başka ilgi çekici soru "Dinamik bir açılış sayfası ile statik bir
açılış sayfası kullanıcı etkileşiminde bir fark yaratır mı?" olabilir.
Sonuç değişkeni, bu örnek için de dakika sayısıyla ölçülen oturum
uzunluğu olabilir. Sonuç değişkeni sürekli olduğundan ve hedef soru, bir
açılış sayfası türü diğerine göre kullanıldığında kullanıcı katılımında
bir fark olup olmadığı ile ilgili olduğundan, hipotez testine devam
edebilirsiniz. Daha sonra aşağıdaki gibi olabilecek hipotezleri
çerçeveleyebilirsiniz:

-   Sıfır hipotezi (H 0): Kullanıcılar, açılış sayfası dinamik olduğunda
    ve statik olduğunda uygulamada yaklaşık olarak aynı süreyi
    harcıyorlar.

-   Alternatif hipotez (H 1): Kullanıcılar, açılış sayfası dinamik
    olduğunda ve statik olduğunda uygulamada yaklaşık olarak aynı süreyi
    HARCAMAZ.

İlginizi çekebilecek başka bir soru da "Bir kullanıcı uygulama içi yeni
ürün serisiyle etkileşime girecek mi?" Ardından, verilerinizdeki hangi
değişkenin sonuç değişkeni olabileceğini sorabilirsiniz. Bir
kullanıcının yeni ürün serisini görüntülemek için tıklayıp tıklamadığına
ilişkin verilere erişiminiz varsa, sonuç değişkeni bu olabilir. Bir
sonraki soru şudur: sonuç değişkeni nasıl ölçülür? Bir kullanıcının bu
içeriği görüntülemek için tıklayıp tıklamadığı ikili bir değişken olarak
gösterilebilir; 1 içeriği görüntülemek için tıkladığını ve 0, içeriği
görüntülemek için tıklamadığını gösterir. Bu sonuç değişkeni ikili
olduğundan, binom lojistik regresyon ile devam edebilirsiniz.

#### **Örnek bağlam: Hasta yanıtı**

Şimdi, hastanın tıbbi tedavilere verdiği yanıtlar hakkında tahminlerde
bulunmakla görevlendirildiğinizi hayal edin.

Sorarak başlayabilirsiniz, cevaplamak istediğiniz soru nedir?

Olası bir soru şu olabilir: "Her faktör bir hastanın tıbbi tedaviye
yanıtını ne kadar etkiler?" Tedavinin amacı beyaz kan hücresi (WBC)
sayısını iyileştirmekse ve bu verilere erişiminiz varsa, WBC sayısı
sonuç değişkeni olabilir. Sonuç değişkeni sürekli bir ölçüdür ve bu
görevi ele almak için doğrusal regresyon kullanabilirsiniz.

İlgilenilen başka bir soru "Tedavi A, Tedavi B veya Tedavi C, hastanın
WBC sayısı üzerinde daha güçlü bir etkiye sahip olacak mı?" Bu durumda
sonuç değişkeni aynı zamanda sürekli olan WBC sayısı olacaktır. Hedef
soru farklı tedavileri karşılaştırmakla ilgili olduğundan, hipotez
testine devam etmek en iyisidir. Daha sonra aşağıdaki olabilecek
hipotezleri oluşturabilirsiniz.

-   Sıfır hipotezi (H 0): Hastalar her tedavide yaklaşık olarak aynı
    beyaz kan hücresi sayısına sahiptir.

-   Alternatif hipotez (H 1): Hastalar her tedavide yaklaşık olarak aynı
    beyaz kan hücresi sayısına sahip DEĞİLDİR.

İlginizi çekebilecek farklı bir soru: "Tedavi A ile hastanın WBC sayısı
ideal aralığa ulaşacak mı?" İlişkili verilere erişiminiz varsa, sonuç
değişkeni, bir hastanın WBC sayısının ideal aralığa ulaşıp ulaşmadığı
olacaktır, ki bu ikili bir değişkendir: 1, WBC sayısının ideal aralıkta
olduğunu gösterir ve 0 olmadığını gösterir. Bu senaryoda tahminlerde
bulunmak için lojistik bir regresyon modeli oluşturabilirsiniz.

### Önemli çıkarımlar {#önemli-çıkarımlar}

-   Tahminlerde bulunmak için bir regresyon tekniği seçerken cevaplamak
    istediğiniz soruyu ve erişebileceğiniz verileri göz önünde
    bulundurun.

-   İlgilendiğiniz sonuç değişkenini ve nasıl ölçüldüğünü belirlemek,
    göreviniz için hangi regresyon tekniğinin en uygun olduğuna karar
    vermenize yardımcı olacaktır.

Aşağıdaki akış şeması, bu okumada tartışıldığı gibi sonuç değişkeninden
başlayarak bir regresyon tekniği seçmek için üst düzey bir yaklaşımı
yakalar. Ayrıca hipotez testinin regresyon analizine bağlı olduğunu
unutmayın. Örneğin, doğrusal regresyonda, iki değişken arasında bir
korelasyon olup olmadığını test etme süreci (başka bir deyişle,
katsayıların doğrusal modelde istatistiksel olarak anlamlı olup
olmadığını belirleme) bir hipotez testini içerir.

`<img src="attachment:55f07cb2-29cd-4fad-a7fe-758d33f17541.png" width="1000"/>`{=html}

### Daha fazla bilgi için kaynaklar {#daha-fazla-bilgi-için-kaynaklar}

-   Farklı regresyon modelleri türleri hakkında daha fazla bilgi edinmek
    istiyorsanız, doğrusal regresyon, lojistik regresyon ve daha
    fazlasını kapsayan farklı regresyon modelleri türleri hakkında [bu
    makal](https://www.analyticsvidhya.com/blog/2022/01/different-types-of-regression-models/)
    eye göz atabilirsiniz.

-   Hipotez testi hakkında daha fazla bilgi edinmek istiyorsanız, veri
    biliminde hipotez testine yaklaşmanın temel adımlarına genel bir
    bakış sağlayan [bu
    makal](https://towardsdatascience.com/hypothesis-testing-for-data-scientists-everything-you-need-to-know-8c36ddde4cd2)
    eye göz atabilirsiniz.
:::

::: {.cell .markdown}
# 6 Makine Öğrenmesinin Somunları ve Cıvataları {#6-makine-öğrenmesinin-somunları-ve-cıvataları}
:::

::: {.cell .markdown}
``` python
```

`<img src="attachment:" width="500"/>`{=html}
:::

::: {.cell .markdown}
## 
:::

::: {.cell .markdown}
``` python
```

`<img src="attachment:" width="500"/>`{=html}
:::

::: {.cell .markdown}
##  {#section}
:::

::: {.cell .markdown}
``` python
```

`<img src="attachment:" width="500"/>`{=html}
:::

::: {.cell .markdown}
##  {#section}
:::

::: {.cell .markdown}
``` python
```

`<img src="attachment:" width="500"/>`{=html}
:::

::: {.cell .markdown}
##  {#section}
:::

::: {.cell .markdown}
``` python
```

`<img src="attachment:" width="500"/>`{=html}
:::
