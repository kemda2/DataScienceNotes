# BÃ¶lÃ¼m 1: En ÃœnlÃ¼ Tablosal YarÄ±ÅŸma â€“ Porto Seguro'nun GÃ¼venli SÃ¼rÃ¼cÃ¼ Tahmini *(Chapter 1: The Most Renowned Tabular Competition â€“ Porto Seguroâ€™s Safe Driver Prediction)*

Herhangi bir Kaggle yarÄ±ÅŸmasÄ±nda liderlik tablosunun zirvesine nasÄ±l ulaÅŸÄ±lacaÄŸÄ±nÄ± Ã¶ÄŸrenmek sabÄ±r, **azim** ve en iyi sonuÃ§larÄ± elde etmek iÃ§in rekabet etmenin en iyi yolunu Ã¶ÄŸrenmek iÃ§in **birÃ§ok deneme** gerektirir. Bu nedenle, geÃ§miÅŸteki bazÄ± Kaggle yarÄ±ÅŸmalarÄ±nÄ± deneyerek ve tartÄ±ÅŸmalarÄ± okuyarak, not defterlerini (notebooks) yeniden kullanarak, **Ã¶zellik mÃ¼hendisliÄŸi** (feature engineering) yaparak ve Ã§eÅŸitli modelleri eÄŸiterek liderlik tablosunun zirvesine nasÄ±l ulaÅŸÄ±lacaÄŸÄ±nÄ± Ã¶ÄŸrenerek bu becerileri daha hÄ±zlÄ± geliÅŸtirmenize yardÄ±mcÄ± olabilecek bir Ã§alÄ±ÅŸma kitabÄ± dÃ¼ÅŸÃ¼ndÃ¼k.

En Ã¼nlÃ¼ tablo (tabular) yarÄ±ÅŸmalarÄ±ndan biri olan **Porto Seguroâ€™s Safe Driver Prediction** ile baÅŸlÄ±yoruz. Bu yarÄ±ÅŸmada, sigortacÄ±lÄ±kta yaygÄ±n bir sorunu Ã§Ã¶zmeniz ve Ã¶nÃ¼mÃ¼zdeki yÄ±l kimin araÃ§ sigortasÄ± talebinde bulunacaÄŸÄ±nÄ± bulmanÄ±z isteniyor. BÃ¶yle bir bilgi, talepte bulunma olasÄ±lÄ±ÄŸÄ± daha yÃ¼ksek olan sÃ¼rÃ¼cÃ¼ler iÃ§in sigorta Ã¼cretini artÄ±rmak ve olasÄ±lÄ±ÄŸÄ± daha dÃ¼ÅŸÃ¼k olanlar iÃ§in dÃ¼ÅŸÃ¼rmek aÃ§Ä±sÄ±ndan faydalÄ±dÄ±r.

Bu yarÄ±ÅŸmayÄ± Ã§Ã¶zmek iÃ§in gerekli olan temel iÃ§gÃ¶rÃ¼leri ve teknik detaylarÄ± aÃ§Ä±klarken, size gerekli kodu gÃ¶sterecek ve **The Kaggle Book**â€™ta bulunan konularÄ± incelemenizi ve sorularÄ± yanÄ±tlamanÄ±zÄ± isteyeceÄŸiz. Ã–yleyse, daha fazla gecikmeden, bu yeni Ã¶ÄŸrenme yolunuza baÅŸlayalÄ±m.

Bu bÃ¶lÃ¼mde ÅŸunlarÄ± Ã¶ÄŸreneceksiniz:

  * Bir **LightGBM** modelini nasÄ±l ayarlayacaÄŸÄ±nÄ±z (tune) ve eÄŸiteceÄŸiniz
  * Bir **gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±yÄ± (denoising autoencoder)** nasÄ±l oluÅŸturacaÄŸÄ±nÄ±z ve bunu bir sinir aÄŸÄ±nÄ± beslemek iÃ§in nasÄ±l kullanacaÄŸÄ±nÄ±z
  * Birbirinden oldukÃ§a farklÄ± olan modelleri **etkili bir ÅŸekilde nasÄ±l harmanlayacaÄŸÄ±nÄ±z (blend)**

> Bu bÃ¶lÃ¼mdeki tÃ¼m kod dosyalarÄ± **[https://packt.link/kwbchp1](https://www.google.com/search?q=https://packt.link/kwbchp1)** adresinde bulunabilir.

## YarÄ±ÅŸmayÄ± ve veriyi anlama *(Understanding the competition and the data)*

Porto Seguro, Brezilya'nÄ±n (Brezilya ve Uruguay'da faaliyet gÃ¶steren) Ã¼Ã§Ã¼ncÃ¼ bÃ¼yÃ¼k sigorta ÅŸirketidir; otomobil sigortasÄ± teminatÄ±nÄ±n yanÄ± sÄ±ra pek Ã§ok baÅŸka sigorta Ã¼rÃ¼nÃ¼ de sunmaktadÄ±r ve son 20 yÄ±ldÄ±r fiyatlarÄ±nÄ± belirlemek ve otomatik sigorta teminatÄ±nÄ± daha fazla sÃ¼rÃ¼cÃ¼ iÃ§in daha eriÅŸilebilir kÄ±lmak amacÄ±yla analitik yÃ¶ntemler ve makine Ã¶ÄŸrenimi kullanmaktadÄ±r. GÃ¶revlerini baÅŸarmanÄ±n yeni yollarÄ±nÄ± keÅŸfetmek amacÄ±yla, Kaggle kullanÄ±cÄ±larÄ±nÄ±n (Kagglers) bazÄ± temel analitik problemlerine yeni ve daha iyi Ã§Ã¶zÃ¼mler bulmalarÄ±nÄ± bekleyerek bir yarÄ±ÅŸmaya ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction)) sponsor olmuÅŸlardÄ±r.

YarÄ±ÅŸma, Kaggle kullanÄ±cÄ±larÄ±nÄ±n, bir sÃ¼rÃ¼cÃ¼nÃ¼n Ã¶nÃ¼mÃ¼zdeki yÄ±l bir otomobil sigortasÄ± talebi baÅŸlatma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin eden bir model oluÅŸturmasÄ±nÄ± amaÃ§lamaktadÄ±r ki bu oldukÃ§a yaygÄ±n bir gÃ¶rev tÃ¼rÃ¼dÃ¼r (sponsor bunu "sigortacÄ±lÄ±k iÃ§in klasik bir meydan okuma" olarak bahsetmektedir). Talepte bulunma olasÄ±lÄ±ÄŸÄ± hakkÄ±ndaki bu tÃ¼r bilgiler, bir sigorta ÅŸirketi iÃ§in oldukÃ§a deÄŸerli olabilir. BÃ¶yle bir model olmadan, sigorta ÅŸirketleri mÃ¼ÅŸterilerine risklerine bakÄ±lmaksÄ±zÄ±n yalnÄ±zca sabit bir prim uygulayabilir veya kÃ¶tÃ¼ performans gÃ¶steren bir modele sahiplerse, onlara **uygunsuz bir prim** uygulayabilirler. MÃ¼ÅŸterilerin riskini profilendirmedeki yanlÄ±ÅŸlÄ±klar, iyi sÃ¼rÃ¼cÃ¼lere daha yÃ¼ksek sigorta maliyeti yÃ¼klenmesine ve kÃ¶tÃ¼ sÃ¼rÃ¼cÃ¼ler iÃ§in fiyatÄ±n dÃ¼ÅŸÃ¼rÃ¼lmesine yol aÃ§abilir. Bunun ÅŸirket Ã¼zerindeki etkisi iki yÃ¶nlÃ¼ olacaktÄ±r: iyi sÃ¼rÃ¼cÃ¼ler sigortalarÄ±nÄ± baÅŸka yerlerde arayacak ve ÅŸirketin portfÃ¶yÃ¼ kÃ¶tÃ¼ sÃ¼rÃ¼cÃ¼lerle aÅŸÄ±rÄ± yÃ¼klenecektir (teknik olarak, ÅŸirketin **kÃ¶tÃ¼ bir hasar oranÄ±** olacaktÄ±r: [https://www.investopedia.com/terms/l/loss-ratio.asp](https://www.investopedia.com/terms/l/loss-ratio.asp)). Bunun yerine, ÅŸirket talep olasÄ±lÄ±ÄŸÄ±nÄ± doÄŸru bir ÅŸekilde tahmin edebilirse, mÃ¼ÅŸterilerinden **adil bir fiyat** isteyebilir, bÃ¶ylece pazar paylarÄ±nÄ± artÄ±rabilir, daha memnun mÃ¼ÅŸterilere ve daha dengeli bir mÃ¼ÅŸteri portfÃ¶yÃ¼ne (daha iyi hasar oranÄ±) sahip olabilir ve rezervlerini (ÅŸirketin talepleri Ã¶demek iÃ§in ayÄ±rdÄ±ÄŸÄ± para) daha iyi yÃ¶netebilir.

Bunu yapmak iÃ§in, sponsor eÄŸitim ve test veri kÃ¼meleri saÄŸlamÄ±ÅŸtÄ±r ve veri kÃ¼mesi Ã§ok bÃ¼yÃ¼k olmadÄ±ÄŸÄ± ve Ã§ok iyi hazÄ±rlanmÄ±ÅŸ gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ iÃ§in yarÄ±ÅŸma herkes iÃ§in idealdi.

Verilerin sunulmasÄ±na ayrÄ±lmÄ±ÅŸ olan yarÄ±ÅŸma sayfasÄ±nda ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/data](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/data)) belirtildiÄŸi gibi:

> Benzer gruplara ait Ã¶zellikler, Ã¶zellik adlarÄ±nda bu ÅŸekilde etiketlenmiÅŸtir (Ã¶rneÄŸin, ind, reg, car, calc).
>
> Ek olarak, Ã¶zellik adlarÄ± ikili (binary) Ã¶zellikleri belirtmek iÃ§in **bin** ve kategorik Ã¶zellikleri belirtmek iÃ§in **cat** sonekini iÃ§erir. Bu tanÄ±mlamalara sahip olmayan Ã¶zellikler ya sÃ¼rekli (continuous) ya da sÄ±ralÄ±dÄ±r (ordinal). **-1** deÄŸerleri, Ã¶zelliÄŸin gÃ¶zlemde **eksik** olduÄŸunu gÃ¶sterir. **Hedef (target)** sÃ¼tunu, poliÃ§e sahibi iÃ§in bir talep aÃ§Ä±lÄ±p aÃ§Ä±lmadÄ±ÄŸÄ±nÄ± gÃ¶sterir.

YarÄ±ÅŸma iÃ§in veri hazÄ±rlÄ±ÄŸÄ±, herhangi bir bilgi sÄ±zÄ±ntÄ±sÄ±nÄ± (leak) Ã¶nlemek iÃ§in dikkatlice yapÄ±lmÄ±ÅŸtÄ±r ve Ã¶zelliklerin anlamÄ± hakkÄ±nda gizlilik korunmuÅŸ olsa da, kullanÄ±lan farklÄ± etiketlerin motorlu taÅŸÄ±t sigortasÄ± modellemesinde yaygÄ±n olarak kullanÄ±lan belirli Ã¶zellik tÃ¼rlerine atÄ±fta bulunduÄŸu oldukÃ§a aÃ§Ä±ktÄ±r:

  * **ind**: "Bireysel Ã¶zellikler" (individual characteristics)
  * **car**: "Araba Ã¶zellikleri" (car characteristics)
  * **calc**: "HesaplanmÄ±ÅŸ Ã¶zellikler" (calculated features)
  * **reg**: "BÃ¶lgesel/coÄŸrafi Ã¶zellikler" (regional/geographic features)

Bireysel Ã¶zelliklere gelince, yarÄ±ÅŸma sÄ±rasÄ±nda anlamlarÄ± hakkÄ±nda Ã§ok fazla spekÃ¼lasyon yapÄ±lmÄ±ÅŸtÄ±r. Ã–rneÄŸin ÅŸuraya bakÄ±nÄ±z:

  * [https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41489](https://www.google.com/search?q=https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41489), burada Raddar, **ps\_car\_13** Ã¶zelliÄŸinin iki yÄ±lda bir zorunlu araÃ§ muayeneleri arasÄ±nda kat edilen mesafeyi temsil edebileceÄŸini Ã¶ne sÃ¼rmektedir.
  * [https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41488](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41488), burada Raddar, **ps\_car\_12** Ã¶zelliÄŸinin bunun yerine motor silindir hacmini temsil edebileceÄŸini Ã¶ne sÃ¼rmektedir.
  * [https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41057](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41057), burada bazÄ± Ã¶zelliklerin Porto Seguro'nun Ã§evrimiÃ§i teklif formundan tÃ¼retildiÄŸi yÃ¶nÃ¼ndeki Ã¶neriyi okuyabilirsiniz.

TÃ¼m bu ve daha fazla Ã§abaya raÄŸmen, sonunda Ã¶zelliklerin Ã§oÄŸunun anlamÄ± ÅŸimdiye kadar bir **gizem olarak kalmÄ±ÅŸtÄ±r**.

Bu yarÄ±ÅŸmanÄ±n ilginÃ§ gerÃ§ekleri ÅŸunlardÄ±r:

1.  Veriler, Ã¶zellikler anonim olsa da, **gerÃ§ek dÃ¼nyadan** alÄ±nmÄ±ÅŸtÄ±r.
2.  Veriler, herhangi bir tÃ¼r sÄ±zÄ±ntÄ± olmaksÄ±zÄ±n **Ã§ok iyi hazÄ±rlanmÄ±ÅŸtÄ±r** (burada sihirli Ã¶zellikler yoktur â€“ sihirli Ã¶zellik, becerikli bir iÅŸlemle Kaggle yarÄ±ÅŸmasÄ±nda modellerinize yÃ¼ksek tahmin gÃ¼cÃ¼ saÄŸlayabilen bir Ã¶zelliktir).
3.  Test veri seti sadece eÄŸitim veri setiyle aynÄ± kategorik seviyeleri tutmakla kalmaz; aynÄ± zamanda aynÄ± daÄŸÄ±lÄ±mdan geliyormuÅŸ gibi gÃ¶rÃ¼nmektedir, ancak Yuya Yamamoto, verilerin t-SNE ile Ã¶n iÅŸlenmesinin dÃ¼ÅŸmanca doÄŸrulama (adversarial validation) testinin baÅŸarÄ±sÄ±z olmasÄ±na yol aÃ§tÄ±ÄŸÄ±nÄ± iddia etmektedir ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44784](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44784)).

> ğŸ“ AlÄ±ÅŸtÄ±rma 1
> 
> 
> 
> Ä°lk alÄ±ÅŸtÄ±rma olarak, **The Kaggle Book**'taki **dÃ¼ÅŸmanca doÄŸrulama (adversarial validation)** ile ilgili iÃ§eriklere ve koda (sayfa 179'dan baÅŸlayarak) atÄ±fta bulunarak, eÄŸitim ve test verilerinin **bÃ¼yÃ¼k olasÄ±lÄ±kla aynÄ± veri daÄŸÄ±lÄ±mÄ±ndan** kaynaklandÄ±ÄŸÄ±nÄ± kanÄ±tlayÄ±nÄ±z.
> 
> 
> 
> **AlÄ±ÅŸtÄ±rma NotlarÄ±** (Size yardÄ±mcÄ± olacak tÃ¼m notlarÄ± veya Ã§alÄ±ÅŸmalarÄ± buraya yazÄ±nÄ±z):

Tilii (Mensur Dlakic, Montana Eyalet Ãœniversitesi'nde DoÃ§ent: [https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42197](https://www.google.com/search?q=https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42197)) tarafÄ±ndan yapÄ±lan ilginÃ§ bir paylaÅŸÄ±m, t-SNE kullanarak ÅŸunu gÃ¶stermektedir: "**Sigorta parametreleri aÃ§Ä±sÄ±ndan Ã§ok benzer olan birÃ§ok insan vardÄ±r, ancak bunlardan bazÄ±larÄ± talepte bulunacak, bazÄ±larÄ± ise bulunmayacaktÄ±r**." Tilii'nin bahsettiÄŸi ÅŸey, sigortacÄ±lÄ±kta olanlara oldukÃ§a tipiktir; belirli Ã¶ncÃ¼ller (sigorta parametreleri) iÃ§in bir ÅŸeyin olma olasÄ±lÄ±ÄŸÄ± aynÄ±dÄ±r, ancak o olay, olaylar dizisini ne kadar sÃ¼re gÃ¶zlemlediÄŸimize baÄŸlÄ± olarak gerÃ§ekleÅŸir veya gerÃ§ekleÅŸmez.

Ã–rneÄŸin, sigortacÄ±lÄ±kta IoT ve telematik verilerini ele alalÄ±m. Bir sÃ¼rÃ¼cÃ¼nÃ¼n gelecekte talepte bulunup bulunmayacaÄŸÄ±nÄ± tahmin etmek iÃ§in sÃ¼rÃ¼ÅŸ davranÄ±ÅŸÄ±nÄ± analiz etmek oldukÃ§a yaygÄ±ndÄ±r. GÃ¶zlem sÃ¼reniz **Ã§ok kÄ±saysa** (Ã¶rneÄŸin, bu yarÄ±ÅŸmada olduÄŸu gibi bir yÄ±l), Ã§ok kÃ¶tÃ¼ sÃ¼rÃ¼cÃ¼lerin bile bir talepte bulunmamasÄ± sÃ¶z konusu olabilir, Ã§Ã¼nkÃ¼ kÃ¶tÃ¼ bir sÃ¼rÃ¼cÃ¼ iÃ§in bile bÃ¶yle bir olayÄ±n kÄ±sa bir zaman diliminde meydana gelme olasÄ±lÄ±ÄŸÄ± dÃ¼ÅŸÃ¼ktÃ¼r.

Benzer fikirler, Andy Harless ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42735](https://www.google.com/search?q=https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/42735)) tarafÄ±ndan tartÄ±ÅŸÄ±lmaktadÄ±r; Harless, bunun yerine yarÄ±ÅŸmanÄ±n gerÃ§ek gÃ¶revinin "kazaya daha yatkÄ±n olan sÃ¼rÃ¼cÃ¼leri belirleyen **gizli bir sÃ¼rekli deÄŸiÅŸkenin deÄŸerini tahmin etmek**" olduÄŸunu savunur, Ã§Ã¼nkÃ¼ aslÄ±nda "**talepte bulunmak bir sÃ¼rÃ¼cÃ¼nÃ¼n Ã¶zelliÄŸi deÄŸil; ÅŸansÄ±n bir sonucudur**."

## DeÄŸerlendirme metriÄŸini anlama
*(Understanding the evaluation metric)*

Elbette, metninizi TÃ¼rkÃ§eye Ã§evirdim:

-----

YarÄ±ÅŸmada kullanÄ±lan metrik, **normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±dÄ±r** (ekonomide kullanÄ±lan benzer Gini katsayÄ±sÄ±/endeksinden almÄ±ÅŸtÄ±r) ve daha Ã¶nce baÅŸka bir yarÄ±ÅŸmada, Allstate Claim Prediction Challenge'da ([https://www.kaggle.com/competitions/ClaimPredictionChallenge](https://www.google.com/search?q=https://www.kaggle.com/competitions/ClaimPredictionChallenge)) kullanÄ±lmÄ±ÅŸtÄ±r. Bu yarÄ±ÅŸmadan, metriÄŸin ne hakkÄ±nda olduÄŸuna dair Ã§ok net bir aÃ§Ä±klama alabiliriz:

> Bir giriÅŸ gÃ¶nderdiÄŸinizde, gÃ¶zlemler "en bÃ¼yÃ¼k tahminden" "en kÃ¼Ã§Ã¼k tahmine" doÄŸru sÄ±ralanÄ±r. Tahminlerinizin devreye girdiÄŸi tek adÄ±m budur, bu nedenle yalnÄ±zca tahminlerinizin belirlediÄŸi sÄ±ra Ã¶nemlidir. GÃ¶zlemleri soldan saÄŸa, en bÃ¼yÃ¼k tahminler solda olacak ÅŸekilde dÃ¼zenlenmiÅŸ olarak gÃ¶rselleÅŸtirin. ArdÄ±ndan soldan saÄŸa hareket ederek ÅŸunu sorarÄ±z: "**Verinin en soldaki %x'lik kÄ±smÄ±nda, gerÃ§ekten gÃ¶zlemlenen kaybÄ±n ne kadarÄ±nÄ± biriktirdiniz?**" Bir model olmadan, tahminlerin %10'unda kaybÄ±n %10'unu biriktirmeyi beklersiniz, bu nedenle model olmamasÄ± (veya bir "sÄ±fÄ±r" modeli) dÃ¼z bir Ã§izgiye ulaÅŸÄ±r. **Sizin eÄŸriniz ile bu dÃ¼z Ã§izgi arasÄ±ndaki alana Gini katsayÄ±sÄ± diyoruz.**
>
> "MÃ¼kemmel" bir model iÃ§in ulaÅŸÄ±labilecek maksimum bir alan vardÄ±r. Biz, modelinizin Gini katsayÄ±sÄ±nÄ± mÃ¼kemmel modelin Gini katsayÄ±sÄ±na bÃ¶lerek **normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±nÄ±** kullanacaÄŸÄ±z.

Daha iyi bir aÃ§Ä±klama da Kilian Batzner'Ä±n not defterinde (notebook) saÄŸlanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/code/batzner/gini-coefficient-an-intuitive-explanation](https://www.kaggle.com/code/batzner/gini-coefficient-an-intuitive-explanation). Kilian, net Ã§izimler ve bazÄ± basit Ã¶rnekler kullanarak, sigorta ÅŸirketlerinin aktÃ¼erya departmanlarÄ± tarafÄ±ndan rutin olarak kullanÄ±lan, ancak Ã§ok yaygÄ±n olmayan bu metriÄŸi anlamlandÄ±rmaya Ã§alÄ±ÅŸmaktadÄ±r.

Bu metrik, yaklaÅŸÄ±k olarak $2 \cdot \text{ROC-AUC} - 1$ formÃ¼lÃ¼ne karÅŸÄ±lÄ±k geldiÄŸi iÃ§in **ROC-AUC skoru** veya **Mannâ€“Whitney U non-parametrik istatistiksel testi** (U istatistiÄŸi, alÄ±cÄ± iÅŸletim karakteristiÄŸi eÄŸrisi altÄ±ndaki alana â€“ AUC'ye eÅŸdeÄŸer olduÄŸundan) ile yaklaÅŸtÄ±rÄ±labilir. DolayÄ±sÄ±yla, **ROC-AUC'yi maksimize etmek, normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±nÄ± maksimize etmekle aynÄ±dÄ±r** (bir referans iÃ§in Wikipedia giriÅŸindeki *DiÄŸer istatistiksel Ã¶lÃ§Ã¼mlerle iliÅŸki* bÃ¶lÃ¼mÃ¼ne bakÄ±nÄ±z: [https://en.wikipedia.org/wiki/Gini\_coefficient](https://en.wikipedia.org/wiki/Gini_coefficient)).

Metrik, ayrÄ±ca Ã¶lÃ§eklenmiÅŸ tahmin sÄ±rasÄ± (rank) ile Ã¶lÃ§eklenmiÅŸ hedef deÄŸerinin kovaryansÄ± olarak da yaklaÅŸÄ±k olarak ifade edilebilir, bu da daha anlaÅŸÄ±lÄ±r bir sÄ±ra iliÅŸkisi Ã¶lÃ§Ã¼tÃ¼ saÄŸlar (bkz. Dmitriy Guller: [https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/40576](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/40576)).

**AmaÃ§ fonksiyonu** (objective function) aÃ§Ä±sÄ±ndan bakÄ±ldÄ±ÄŸÄ±nda, bir sÄ±nÄ±flandÄ±rma probleminde yapacaÄŸÄ±nÄ±z gibi **ikili log-kaybÄ±** (binary log-loss) iÃ§in optimizasyon yapabilirsiniz. Ne ROC-AUC ne de normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ± tÃ¼revlenebilir deÄŸildir ve bunlar yalnÄ±zca doÄŸrulama kÃ¼mesi Ã¼zerindeki metrik deÄŸerlendirmesi iÃ§in kullanÄ±labilir (Ã¶rneÄŸin, erken durdurma veya bir sinir aÄŸÄ±nda Ã¶ÄŸrenme hÄ±zÄ±nÄ± azaltma iÃ§in). Ancak, log-kaybÄ± iÃ§in optimizasyon yapmak her zaman ROC-AUC'yi ve normalleÅŸtirilmiÅŸ Gini katsayÄ±larÄ±nÄ± iyileÅŸtirmez ve ikisi de doÄŸrudan tÃ¼revlenebilir deÄŸildir.

> AslÄ±nda tÃ¼revlenebilir bir ROC-AUC yaklaÅŸtÄ±rmasÄ± mevcuttur. Bunun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Toon Calders ve Szymon Jaroszewicz'in *Efficient AUC Optimization for Classification* adlÄ± Ã§alÄ±ÅŸmasÄ±nda okuyabilirsiniz. European Conference on Principles of Data Mining and Knowledge Discovery. Springer, Berlin, Heidelberg, 2007: [https://link.springer.com/content/pdf/10.1007/978-3-540-74976-9\_8.pdf](https://link.springer.com/content/pdf/10.1007/978-3-540-74976-9_8.pdf).

Ancak, yarÄ±ÅŸmada bir amaÃ§ fonksiyonu olarak log-kaybÄ±ndan farklÄ± bir ÅŸey kullanmaya ve deÄŸerlendirme metriÄŸi olarak ROC-AUC veya normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±ndan baÅŸka bir ÅŸey kullanmaya gerek olmadÄ±ÄŸÄ± anlaÅŸÄ±lmaktadÄ±r.

Kaggle Not Defterleri arasÄ±nda normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±nÄ± hesaplamak iÃ§in aslÄ±nda birkaÃ§ Python uygulamasÄ± bulunmaktadÄ±r. Burada, CPMP'nin ([https://www.kaggle.com/code/cpmpml/extremely-fast-gini-computation/notebook](https://www.google.com/search?q=https://www.kaggle.com/code/cpmpml/extremely-fast-gini-computation/notebook)) **Numba** kullanarak hesaplamalarÄ± hÄ±zlandÄ±ran Ã§alÄ±ÅŸmasÄ±nÄ± kullandÄ±k ve Ã¶neriyoruz: bu hem kesin hem de hÄ±zlÄ±dÄ±r.

> ğŸ“ AlÄ±ÅŸtÄ±rma 2
> 
> 
> 
> **The Kaggle Book**'un 5. bÃ¶lÃ¼mÃ¼nde (sayfa 95 ve sonrasÄ±), Ã¶zellikle yeni ve genellikle bilinmeyen yarÄ±ÅŸma metrikleriyle nasÄ±l baÅŸa Ã§Ä±kÄ±lacaÄŸÄ±nÄ± aÃ§Ä±klamÄ±ÅŸtÄ±k.
> 
> 
> 
> Bir alÄ±ÅŸtÄ±rma olarak, Kaggle'da **normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±nÄ±** bir deÄŸerlendirme metriÄŸi olarak kullanan **kaÃ§ yarÄ±ÅŸma** olduÄŸunu bulabilir misiniz?
> 
> 
> 
> **AlÄ±ÅŸtÄ±rma NotlarÄ±** (Size yardÄ±mcÄ± olacak tÃ¼m notlarÄ± veya Ã§alÄ±ÅŸmalarÄ± buraya yazÄ±nÄ±z):

## Michael Jahrer'Ä±n en iyi Ã§Ã¶zÃ¼m fikirlerini inceleme *(Examining the top solution ideas from Michael Jahrer)*

Michael Jahrer ([https://www.kaggle.com/mjahrer](https://www.kaggle.com/mjahrer), yarÄ±ÅŸma BÃ¼yÃ¼k UstasÄ± ve Netflix Ã–dÃ¼lÃ¼'nÃ¼n "BellKor's Pragmatic Chaos" ekibindeki kazananlarÄ±ndan biri), yarÄ±ÅŸma boyunca halka aÃ§Ä±k liderlik tablosunu uzun sÃ¼re ve belirgin bir farkla Ã¶nde gÃ¶tÃ¼rdÃ¼ ve Ã¶zel Ã§Ã¶zÃ¼mler nihayet aÃ§Ä±klandÄ±ÄŸÄ±nda kazanan ilan edildi.

KÄ±sa sÃ¼re sonra, tartÄ±ÅŸma forumunda, **gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±larÄ± (denoising autoencoders)** ve sinir aÄŸlarÄ±nÄ± akÄ±llÄ±ca kullanmasÄ± nedeniyle birÃ§ok Kaggler iÃ§in bir referans haline gelen Ã§Ã¶zÃ¼mÃ¼nÃ¼n kÄ±sa bir Ã¶zetini yayÄ±nladÄ± ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629)). Michael, Ã§Ã¶zÃ¼mÃ¼ne iliÅŸkin herhangi bir Python kodu eklememiÅŸ olsa da (kodlama Ã§alÄ±ÅŸmasÄ±nÄ± doÄŸrudan C++/CUDA ile Python kullanmadan yazÄ±lmÄ±ÅŸ "eski usul" ve "dÃ¼ÅŸÃ¼k seviyeli" olarak tanÄ±mlamÄ±ÅŸtÄ±r), yazÄ±larÄ± kullandÄ±ÄŸÄ± modellere, hiperparametrelerine ve mimarilerine dair referanslar aÃ§Ä±sÄ±ndan oldukÃ§a zengindir.

Ã–ncelikle Michael, Ã§Ã¶zÃ¼mÃ¼nÃ¼n altÄ± modelin bir karÄ±ÅŸÄ±mÄ±ndan (bir LightGBM modeli ve beÅŸ sinir aÄŸÄ±) oluÅŸtuÄŸunu aÃ§Ä±klamaktadÄ±r. AyrÄ±ca, muhtemelen **aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting)** nedeniyle, karÄ±ÅŸÄ±ma her bir modelin katkÄ±sÄ±nÄ± aÄŸÄ±rlÄ±klandÄ±rmanÄ±n (ayrÄ±ca doÄŸrusal ve doÄŸrusal olmayan yÄ±ÄŸÄ±nlama (stacking) yapmanÄ±n) bir avantaj saÄŸlamadÄ±ÄŸÄ± iÃ§in, yalnÄ±zca farklÄ± tohumlardan (seed) oluÅŸturulmuÅŸ, **eÅŸit aÄŸÄ±rlÄ±ÄŸa sahip** modellerin bir karÄ±ÅŸÄ±mÄ±na baÅŸvurduÄŸunu belirtmektedir.

Bu iÃ§gÃ¶rÃ¼, Michael'Ä±n yaklaÅŸÄ±mÄ±nÄ± Ã§oÄŸaltma gÃ¶revimizi Ã§ok daha kolay hale getiriyor, Ã§Ã¼nkÃ¼ kendisi ayrÄ±ca, **yalnÄ±zca LightGBM sonuÃ§larÄ±nÄ± oluÅŸturduÄŸu sinir aÄŸlarÄ±ndan biriyle karÄ±ÅŸtÄ±rmanÄ±n (blending)** bile yarÄ±ÅŸmada birinciliÄŸi garantilemek iÃ§in yeterli olacaÄŸÄ±nÄ± da belirtmiÅŸtir.

Bu iÃ§gÃ¶rÃ¼, alÄ±ÅŸtÄ±rma Ã§alÄ±ÅŸmamÄ±zÄ± bir sÃ¼rÃ¼ model yerine, iki iyi tekil modelle sÄ±nÄ±rlayacaktÄ±r. Buna ek olarak, Michael, bazÄ± sÃ¼tunlarÄ± Ã§Ä±karmak ve kategorik Ã¶zellikleri **tek-sÄ±cak kodlama (one-hot encoding)** dÄ±ÅŸÄ±nda Ã§ok az veri iÅŸleme yaptÄ±ÄŸÄ±nÄ± da belirtmiÅŸtir.

## Bir LightGBM gÃ¶nderimi oluÅŸturma *(Building a LightGBM submission)*

AlÄ±ÅŸtÄ±rmamÄ±z LightGBM tabanlÄ± bir Ã§Ã¶zÃ¼m Ã¼zerinde Ã§alÄ±ÅŸmakla baÅŸlÄ±yor. Kodu, Kaggle Notebooks'u kullanarak hemen yÃ¼rÃ¼tÃ¼lmeye hazÄ±r ÅŸekilde ÅŸu adreste bulabilirsiniz: [https://www.kaggle.com/code/lucamassaron/workbook-lgb](https://www.kaggle.com/code/lucamassaron/workbook-lgb). Kodu kolayca eriÅŸilebilir hale getirmiÅŸ olsak da, bunun yerine kodu doÄŸrudan kitaptan yazmanÄ±zÄ± veya kopyalamanÄ±zÄ± ve hÃ¼cre hÃ¼cre Ã§alÄ±ÅŸtÄ±rmanÄ±zÄ± Ã¶neriyoruz; her bir kod satÄ±rÄ±nÄ±n ne yaptÄ±ÄŸÄ±nÄ± anlamak ve Ã§Ã¶zÃ¼mÃ¼ kiÅŸiselleÅŸtirmek, performansÄ±nÄ± daha da artÄ±rabilir.

> LightGBM kullanÄ±rken, **GPU veya TPU hÄ±zlandÄ±rÄ±cÄ±larÄ±ndan hiÃ§birini aÃ§manÄ±za gerek yoktur ve aÃ§mamalÄ±sÄ±nÄ±z**. GPU hÄ±zlandÄ±rmasÄ± yalnÄ±zca LightGBM'nin GPU sÃ¼rÃ¼mÃ¼nÃ¼ yÃ¼klediyseniz yardÄ±mcÄ± olabilir. Bu tÃ¼r GPU hÄ±zlandÄ±rmalÄ± bir sÃ¼rÃ¼mÃ¼ Kaggle Notebooks'a nasÄ±l kuracaÄŸÄ±nÄ±za dair Ã§alÄ±ÅŸma ipuÃ§larÄ±nÄ± ÅŸu Ã¶rnekte bulabilirsiniz: [https://www.kaggle.com/code/lucamassaron/gpu-accelerated-lightgbm](https://www.kaggle.com/code/lucamassaron/gpu-accelerated-lightgbm).

Anahtar paketleri (hiperparametre optimizasyonu iÃ§in NumPy, pandas ve Optuna, LightGBM ve bazÄ± yardÄ±mcÄ± fonksiyonlar) iÃ§e aktararak baÅŸlÄ±yoruz. AyrÄ±ca bir konfigÃ¼rasyon sÄ±nÄ±fÄ± tanÄ±mlÄ±yor ve onu Ã¶rneklendiriyoruz. KonfigÃ¼rasyon sÄ±nÄ±fÄ±nda tanÄ±mlanan parametreleri, kodun ilerleyiÅŸi sÄ±rasÄ±nda keÅŸfederken tartÄ±ÅŸacaÄŸÄ±z. Burada Ã¶nemli olan nokta, tÃ¼m parametrelerinizi iÃ§eren bir sÄ±nÄ±f kullanarak, onlarÄ± kod boyunca tutarlÄ± bir ÅŸekilde deÄŸiÅŸtirmenizin daha kolay olacaÄŸÄ±dÄ±r. YarÄ±ÅŸmanÄ±n hararetinde, kodun birden fazla yerinde atÄ±fta bulunulan bir parametreyi gÃ¼ncellemeyi unutmak kolaydÄ±r ve parametreler hÃ¼crelere ve fonksiyonlara daÄŸÄ±lmÄ±ÅŸsa bunlarÄ± ayarlamak her zaman zordur. Bir konfigÃ¼rasyon sÄ±nÄ±fÄ±, size Ã§ok Ã§aba kazandÄ±rabilir ve yol boyunca hatalardan koruyabilir:

```python
import numpy as np
import pandas as pd
import optuna
import lightgbm as lgb
from path import Path
from sklearn.model_selection import StratifiedKFold

class Config:
    input_path = Path('../input/porto-seguro-safe-driver-prediction')
    optuna_lgb = False
    n_estimators = 1500
    early_stopping_round = 150
    cv_folds = 5
    random_state = 0
    params = {'objective': 'binary',
              'boosting_type': 'gbdt',
              'learning_rate': 0.01,
              'max_bin': 25,
              'num_leaves': 31,
              'min_child_samples': 1500,
              'colsample_bytree': 0.7,
              'subsample_freq': 1,
              'subsample': 0.7,
              'reg_alpha': 1.0,
              'reg_lambda': 1.0,
              'verbosity': 0,
              'random_state': 0}

config = Config()
```

Bir sonraki adÄ±m, eÄŸitim, test ve Ã¶rnek gÃ¶nderim veri setlerini iÃ§e aktarmayÄ± gerektirir. Bunu pandas'Ä±n `read_csv` fonksiyonunu kullanarak yapÄ±yoruz. AyrÄ±ca, yÃ¼klenen `DataFrame`'lerin indeksini her bir veri Ã¶rneÄŸinin tanÄ±mlayÄ±cÄ±sÄ±na (`id` sÃ¼tununa) ayarlÄ±yoruz.

Benzer gruplara ait Ã¶zellikler etiketlendiÄŸi (`ind`, `reg`, `car` ve `calc` etiketlerini kullanarak) ve ayrÄ±ca ikili (binary) ve kategorik Ã¶zellikler kolayca bulunabildiÄŸi (etiketlerinde sÄ±rasÄ±yla `bin` ve `cat` etiketlerini kullanÄ±rlar), bunlarÄ± numaralandÄ±rabilir ve listelere kaydedebiliriz:

```python
train = pd.read_csv(config.input_path / 'train.csv', index_col='id')
test = pd.read_csv(config.input_path / 'test.csv', index_col='id')
submission = pd.read_csv(config.input_path / 'sample_submission.csv', 
index_col='id')
calc_features = [feat for feat in train.columns if "_calc" in feat]
cat_features = [feat for feat in train.columns if "_cat" in feat]
```

Daha sonra, sadece hedefi (0'lar ve 1'lerden oluÅŸan ikili bir hedef) Ã§Ä±karÄ±r ve eÄŸitim veri setinden kaldÄ±rÄ±rÄ±z:

```python
target = train["target"]
train = train.drop("target", axis="columns")
```

Bu noktada, Michael Jahrer'in de iÅŸaret ettiÄŸi gibi, `calc` Ã¶zelliklerini silebiliriz. Bu fikir, Ã¶zellikle not defterlerinde yarÄ±ÅŸma sÄ±rasÄ±nda Ã§okÃ§a yinelenmiÅŸtir ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41970](https://www.google.com/search?q=https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/41970)), Ã§Ã¼nkÃ¼ bunlarÄ± silmenin hem yerel Ã§apraz doÄŸrulama skorunu hem de halka aÃ§Ä±k liderlik tablosu skorunu iyileÅŸtirdiÄŸi deneysel olarak doÄŸrulanabilmiÅŸtir (genel bir kural olarak, Ã¶zellik seÃ§imi sÄ±rasÄ±nda her ikisini de takip etmek Ã¶nemlidir). AyrÄ±ca, bu Ã¶zellikler gradyan artÄ±rma (gradient boosting) modellerinde de kÃ¶tÃ¼ performans gÃ¶stermiÅŸtir (Ã¶nemleri her zaman ortalamanÄ±n altÄ±ndadÄ±r).

TartÄ±ÅŸabiliriz ki, bu Ã¶zellikler mÃ¼hendislik Ã¼rÃ¼nÃ¼ Ã¶zellikler olduklarÄ± iÃ§in, orijinal Ã¶zelliklerine gÃ¶re yeni bir bilgi iÃ§ermezler, ancak onlarÄ± iÃ§eren eÄŸitilmiÅŸ herhangi bir modele sadece gÃ¼rÃ¼ltÃ¼ katarlar:

```python
train = train.drop(calc_features, axis="columns")
test = test.drop(calc_features, axis="columns")
```

> ğŸ“ AlÄ±ÅŸtÄ±rma 3
> 
> 
> 
> **The Kaggle Book**'un 220. sayfasÄ±nda (Ã‡alÄ±ÅŸmanÄ±zÄ± deÄŸerlendirmek iÃ§in Ã¶zellik Ã¶nemini kullanma baÅŸlÄ±ÄŸÄ± altÄ±nda) saÄŸlanan Ã¶nerilere dayanarak, bir alÄ±ÅŸtÄ±rma olarak:
> 
> 
> 
> 1.  Bu yarÄ±ÅŸma iÃ§in **kendi Ã¶zellik seÃ§imi** not defterinizi (notebook) kodlayÄ±n.
> 
> 2.  **Hangi Ã¶zelliklerin tutulmasÄ±** ve **hangilerinin atÄ±lmasÄ±** gerektiÄŸini kontrol edin.
> 
> 
> 
> **AlÄ±ÅŸtÄ±rma NotlarÄ±** (Size yardÄ±mcÄ± olacak tÃ¼m notlarÄ± veya Ã§alÄ±ÅŸmalarÄ± buraya yazÄ±nÄ±z):

Kategorik Ã¶zellikler bunun yerine **tek-sÄ±cak kodlama (one-hot encoded)** ile iÅŸlenir. EÄŸitim ve test veri setlerinde aynÄ± etiketler bulunduÄŸundan (Porto Seguro ekibi tarafÄ±ndan dÃ¼zenlenen dikkatli bir eÄŸitim/test ayrÄ±mÄ±nÄ±n sonucu), olaÄŸan scikit-learn `OneHotEncoder` ([https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)) yerine, pandas'Ä±n `get_dummies` fonksiyonunu ([https://pandas.pydata.org/docs/reference/api/pandas.get\_dummies.html](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)) kullanacaÄŸÄ±z. Pandas fonksiyonu, Ã¶zellikler ve seviyeleri eÄŸitim ve test setleri arasÄ±nda farklÄ±lÄ±k gÃ¶sterirse farklÄ± kodlamalar Ã¼retebileceÄŸi iÃ§in, tek-sÄ±cak kodlamanÄ±n her ikisi iÃ§in de aynÄ± olmasÄ±nÄ± saÄŸlayan bir kontrol (`assert`) ekliyoruz:

```python
train = pd.get_dummies(train, columns=cat_features)
test = pd.get_dummies(test, columns=cat_features)
assert((train.columns==test.columns).all())
```

Kategorik Ã¶zelliklerin tek-sÄ±cak kodlanmasÄ±, veri iÅŸleme aÅŸamasÄ±nÄ± tamamlar. Daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, deÄŸerlendirme metriÄŸimiz olan **normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±nÄ±** tanÄ±mlamaya geÃ§iyoruz. Daha Ã¶nce bahsedilen CPMP tarafÄ±ndan Ã¶nerilen son derece hÄ±zlÄ± Gini hesaplama kodunu kullanacaÄŸÄ±z.

Bir LightGBM modeli kullanacaÄŸÄ±mÄ±z iÃ§in, **GBM algoritmasÄ±na** eÄŸitim ve doÄŸrulama veri setlerinin deÄŸerlendirmesini onunla Ã§alÄ±ÅŸabilecek bir biÃ§imde dÃ¶ndÃ¼rmek Ã¼zere uygun bir sarmalayÄ±cÄ± (`gini_lgb`) eklememiz gerekiyor (bkz. [https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Booster.html?highlight=higher\_better\#lightgbm.Booster.eval](https://www.google.com/search?q=https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Booster.html%3Fhighlight%3Dhigher_better%23lightgbm.Booster.eval) â€“ Her deÄŸerlendirme fonksiyonu iki parametre kabul etmeli: `preds`, `eval_data` ve `(eval_name, eval_result, is_higher_better)` veya bu tÃ¼r demetlerin bir listesini dÃ¶ndÃ¼rmelidir):

```python
from numba import jit
@jit
def eval_gini(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_true = y_true[np.argsort(y_pred)]
    ntrue = 0
    gini = 0
    delta = 0
    n = len(y_true)
    for i in range(n-1, -1, -1):
        y_i = y_true[i]
        ntrue += y_i
        gini += y_i * delta
        delta += 1 - y_i
    gini = 1 - 2 * gini / (ntrue * (n - ntrue))
    return gini

def gini_lgb(y_true, y_pred):
    eval_name = 'normalized_gini_coef'
    eval_result = eval_gini(y_true, y_pred)
    is_higher_better = True
    return eval_name, eval_result, is_higher_better
```

EÄŸitim parametrelerine gelince, Michael Jahrer'in paylaÅŸÄ±mÄ±nda ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44629)) Ã¶nerdiÄŸi parametrelerin mÃ¼kemmel Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rdÃ¼k.

EÄŸer `Config` sÄ±nÄ±fÄ±ndaki `optuna_lgb` bayraÄŸÄ±nÄ± `True` olarak ayarlarsanÄ±z, Optuna ([https://optuna.org/](https://optuna.org/)) ile bir arama yaparak aynÄ± parametreleri veya benzer performans gÃ¶steren parametreleri bulmaya Ã§alÄ±ÅŸabilirsiniz. Burada optimizasyon, eÄŸitim verileri Ã¼zerinde beÅŸ katlÄ± Ã§apraz doÄŸrulama testine dayanarak Ã¶ÄŸrenme oranÄ± (learning rate) ve dÃ¼zenlileÅŸtirme (regularization) parametreleri gibi temel parametreler iÃ§in en iyi deÄŸerleri bulmaya Ã§alÄ±ÅŸÄ±r. Ä°ÅŸleri hÄ±zlandÄ±rmak iÃ§in, doÄŸrulamanÄ±n kendisinde **erken durdurma (early stopping)** dikkate alÄ±nÄ±r (ki bunun, doÄŸrulama katmanÄ±nÄ± daha iyi aÅŸÄ±rÄ± Ã¶ÄŸrenebilecek bazÄ± parametrelerin seÃ§ilmesini destekleyebileceÄŸinin farkÄ±ndayÄ±z â€“ iyi bir alternatif, erken durdurma geri Ã§aÄŸrÄ±sÄ±nÄ± kaldÄ±rmak ve eÄŸitim iÃ§in sabit bir tur sayÄ±sÄ± tutmaktÄ±r):

```python
if config.optuna_lgb:
        
    def objective(trial):
        params = {
    'learning_rate': trial.suggest_float("learning_rate", 0.01, 1.0),
    'num_leaves': trial.suggest_int("num_leaves", 3, 255),
    'min_child_samples': trial.suggest_int("min_child_samples", 
                                           3, 3000),
    'colsample_bytree': trial.suggest_float("colsample_bytree", 
                                            0.1, 1.0),
    'subsample_freq': trial.suggest_int("subsample_freq", 0, 10),
    'subsample': trial.suggest_float("subsample", 0.1, 1.0),
    'reg_alpha': trial.suggest_loguniform("reg_alpha", 1e-9, 10.0),
    'reg_lambda': trial.suggest_loguniform("reg_lambda", 1e-9, 10.0),
        }

        score = list()
        skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, 
                              random_state=config.random_state)
        
        for train_idx, valid_idx in skf.split(train, target):
            X_train = train.iloc[train_idx]
            y_train = target.iloc[train_idx]
            X_valid = train.iloc[valid_idx] 
            y_valid = target.iloc[valid_idx]
            
            model = lgb.LGBMClassifier(**params,
                                    n_estimators=1500,
                                    early_stopping_round=150,
                                    force_row_wise=True)
            callbacks=[lgb.early_stopping(stopping_rounds=150, 
                                          verbose=False)]
            
            model.fit(X_train, y_train, 
                      eval_set=[(X_valid, y_valid)],  
                      eval_metric=gini_lgb, callbacks=callbacks)
            
            score.append(
                model.best_score_['valid_0']['normalized_gini_coef'])
                
        return np.mean(score)
    
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=300)
    
    print("Best Gini Normalized Score", study.best_value)
    print("Best parameters", study.best_params)
    
    params = {'objective': 'binary',
              'boosting_type': 'gbdt',
              'verbosity': 0,
              'random_state': 0}
              
    params.update(study.best_params)
    
else:
    params = config.params
```

YarÄ±ÅŸma sÄ±rasÄ±nda Tilii, **Boruta** ([https://github.com/scikit-learn-contrib/boruta\_py](https://github.com/scikit-learn-contrib/boruta_py)) kullanarak Ã¶zellik elemesini test etti. Ã‡ekirdeÄŸini (kernel) burada bulabilirsiniz: [https://www.kaggle.com/code/tilii7/boruta-feature-elimination/notebook](https://www.google.com/search?q=https://www.kaggle.com/code/tilii7/boruta-feature-elimination/notebook). Kontrol edebileceÄŸiniz gibi, Boruta tarafÄ±ndan onaylanmÄ±ÅŸ bir Ã¶zellik olarak kabul edilen **hiÃ§bir `calc_` Ã¶zelliÄŸi yoktur**.

> ğŸ“ AlÄ±ÅŸtÄ±rma 4
> 
> 
> 
> **The Kaggle Book**'ta, **hiperparametre optimizasyonunu** (sayfa 241 ve sonrasÄ±) aÃ§Ä±klÄ±yor ve LightGBM modeli iÃ§in bazÄ± temel hiperparametreler saÄŸlÄ±yoruz.
> 
> 
> 
> Bir alÄ±ÅŸtÄ±rma olarak:
> 
> 
> 
> GerektiÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z yerlerde araÅŸtÄ±rÄ±lan parametreleri azaltarak veya artÄ±rarak **Optuna** ile hiperparametre aramasÄ±nÄ± iyileÅŸtirmeye Ã§alÄ±ÅŸÄ±n ve ayrÄ±ca scikit-learn'den **rastgele arama (random search)** veya **yarÄ±lamalÄ± arama (halving search)** gibi alternatif optimizasyon yÃ¶ntemlerini deneyin (sayfa 245â€“246).
> 
> 
> 
> **AlÄ±ÅŸtÄ±rma NotlarÄ±** (Size yardÄ±mcÄ± olacak tÃ¼m notlarÄ± veya Ã§alÄ±ÅŸmalarÄ± buraya yazÄ±nÄ±z):

En iyi parametrelerimizi elde ettiÄŸimizde (ya da sadece Jahrer'in parametrelerini denediÄŸimizde), **eÄŸitim yapmaya ve tahmin etmeye** hazÄ±rÄ±z. En iyi Ã§Ã¶zÃ¼mÃ¼n Ã¶nerdiÄŸi gibi, stratejimiz **her Ã§apraz doÄŸrulama (cross-validation) katmanÄ±nda** bir model eÄŸitmek ve bu katmanÄ±, test tahminlerinin ortalamasÄ±na katkÄ±da bulunmak iÃ§in kullanmaktÄ±r. AÅŸaÄŸÄ±daki kod parÃ§asÄ±, hem test tahminlerini hem de sonuÃ§larÄ± bir araya getirmek iÃ§in faydalÄ± olacak eÄŸitim veri setindeki **katman dÄ±ÅŸÄ± (out-of-fold)** tahminleri Ã¼retecektir:

```python
preds = np.zeros(len(test))
oof = np.zeros(len(train))
metric_evaluations = list()
skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_
                      state=config.random_state)
                      
for idx, (train_idx, valid_idx) in enumerate(skf.split(train, 
                                                       target)):
    print(f"CV fold {idx}")
    X_train, y_train = train.iloc[train_idx], target.iloc[train_idx]
    X_valid, y_valid = train.iloc[valid_idx], target.iloc[valid_idx]
    
    model = lgb.LGBMClassifier(**params,
                               n_estimators=config.n_estimators,
                    early_stopping_round=config.early_stopping_round,
                               force_row_wise=True)
    
    callbacks=[lgb.early_stopping(stopping_rounds=150), 
               lgb.log_evaluation(period=100, show_stdv=False)]
                                                                                           
    model.fit(X_train, y_train, 
              eval_set=[(X_valid, y_valid)], 
              eval_metric=gini_lgb, callbacks=callbacks)
              
    metric_evaluations.append(
                model.best_score_['valid_0']['normalized_gini_coef'])
    
    # Test tahminlerini toplama
    preds += (model.predict_proba(test,  
              num_iteration=model.best_iteration_)[:,1] 
              / skf.n_splits)
              
    # Katman dÄ±ÅŸÄ± tahminleri kaydetme
    oof[valid_idx] = model.predict_proba(X_valid, 
                    num_iteration=model.best_iteration_)[:,1]
```

Model eÄŸitimi Ã§ok uzun sÃ¼rmemelidir. Sonunda, Ã§apraz doÄŸrulama prosedÃ¼rÃ¼ sÄ±rasÄ±nda elde edilen **NormalleÅŸtirilmiÅŸ Gini KatsayÄ±sÄ±nÄ±** alabilirsiniz:

```python
print(f"LightGBM CV normalized Gini coefficient: 
{np.mean(metric_evaluations):0.3f}
        ({np.std(metric_evaluations):0.3f})")
```

SonuÃ§lar oldukÃ§a cesaret vericidir Ã§Ã¼nkÃ¼ ortalama skor **0.289**'dur ve deÄŸerlerin standart sapmasÄ± oldukÃ§a kÃ¼Ã§Ã¼ktÃ¼r:

```
LightGBM CV Gini Normalized Score: 0.289 (0.015)
```

Geriye kalan tek ÅŸey, katman dÄ±ÅŸÄ± (out-of-fold) ve test tahminlerini bir gÃ¶nderi (submission) olarak kaydetmek ve sonuÃ§larÄ± herkese aÃ§Ä±k ve Ã¶zel liderlik tablolarÄ±nda doÄŸrulamaktÄ±r:

```python
submission['target'] = preds
submission.to_csv('lgb_submission.csv')
oofs = pd.DataFrame({'id':train_index, 'target':oof})
oofs.to_csv('lgb_oof.csv', index=False)
```

Elde edilen herkese aÃ§Ä±k skor **yaklaÅŸÄ±k 0.28442** olmalÄ±dÄ±r. Ä°liÅŸkili Ã¶zel skor ise **yaklaÅŸÄ±k 0.29121** olup, sizi final liderlik tablosunda **29. sÄ±raya** yerleÅŸtirir. OldukÃ§a iyi bir sonuÃ§, ancak bunu hala farklÄ± bir modelle, yani bir **sinir aÄŸÄ±yla harmanlamamÄ±z (blend)** gerekiyor.

EÄŸitim setini **bagging** yapmak (yani, eÄŸitim verilerinin birden fazla Ã¶nyÃ¼klemesini almak ve Ã¶nyÃ¼klemelere dayalÄ± birden fazla model eÄŸitmek), Michael Jahrer'in kendi gÃ¶nderisinde belirttiÄŸi gibi, performansÄ± artÄ±rmalÄ±dÄ±r, ancak bu artÄ±ÅŸ Ã§ok fazla deÄŸildir.

## Bir gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ± (denoising autoencoder) ve bir DNN kurma *(Setting up a denoising autoencoder and a DNN)*

Bir sonraki adÄ±m, ondan Ã¶ÄŸrenip tahmin edebilecek bir **gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ± (Denoising Autoencoder - DAE)** ve bir **sinir aÄŸÄ± (Neural Network)** kurmaktÄ±r. Ã‡alÄ±ÅŸan kodu ÅŸu not defterinde bulabilirsiniz: [https://www.kaggle.com/code/lucamassaron/workbook-dae](https://www.kaggle.com/code/lucamassaron/workbook-dae). Not defteri GPU modunda Ã§alÄ±ÅŸtÄ±rÄ±labilir (Kaggle Notebook'ta hÄ±zlandÄ±rÄ±cÄ±larÄ± aÃ§arsanÄ±z daha hÄ±zlÄ± olacaktÄ±r), ancak bazÄ± kÃ¼Ã§Ã¼k deÄŸiÅŸikliklerle CPU modunda da Ã§alÄ±ÅŸabilir.

GÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±larÄ±n Kaggle yarÄ±ÅŸmalarÄ±nda kullanÄ±lmasÄ± hakkÄ±nda daha fazlasÄ±nÄ± **The Kaggle Book**'un 230. sayfasÄ±ndan itibaren okuyabilirsiniz.

Porto Seguro's Safe Driver Prediction YarÄ±ÅŸmasÄ± 18

AslÄ±nda, yarÄ±ÅŸmada Michael Jahrer'in yaklaÅŸÄ±mÄ±nÄ± DAE'ler kullanarak yeniden Ã¼reten hiÃ§bir Ã¶rnek yoktur, bu yÃ¼zden OsciiArt tarafÄ±ndan kodlanmÄ±ÅŸ ([https://www.kaggle.com/code/osciiart/denoising-autoencoder](https://www.kaggle.com/code/osciiart/denoising-autoencoder)) baÅŸka bir yarÄ±ÅŸmadaki bir TensorFlow uygulamasÄ±ndan bir Ã¶rnek aldÄ±k.

Burada, gerekli tÃ¼m paketleri, Ã¶zellikle **TensorFlow** ve **Keras'Ä±** iÃ§e aktararak baÅŸlÄ±yoruz. Birden fazla sinir aÄŸÄ± oluÅŸturacaÄŸÄ±mÄ±z iÃ§in, **deneysel `set_memory_growth`** komutunu kullanarak TensorFlow'a mevcut tÃ¼m GPU belleÄŸini kullanmamasÄ±nÄ± sÃ¶ylÃ¼yoruz. Bu, yol boyunca bellek taÅŸmasÄ± sorunlarÄ± yaÅŸamamÄ±zÄ± Ã¶nlemeye yardÄ±mcÄ± olacaktÄ±r. AyrÄ±ca **Leaky ReLU** aktivasyonunu Ã¶zel bir aktivasyon olarak kaydediyoruz, bÃ¶ylece Keras katmanlarÄ±nda bir dize ile aktivasyon olarak bahsedebiliriz:

```python
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from path import Path
import gc
import optuna
from sklearn.model_selection import StratifiedKFold
from scipy.special import erfinv
import tensorflow as tf

gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)
    
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2
from tensorflow.keras.metrics import AUC
from tensorflow.keras.utils import get_custom_objects

from tensorflow.keras.layers import Activation, LeakyReLU
get_custom_objects().update({'leaky-relu': Activation(LeakyReLU(alpha=0.2))})
```

Birden fazla sinir aÄŸÄ± oluÅŸturma ve belleÄŸimizin tÃ¼kenmemesi niyetimizle ilgili olarak, ayrÄ±ca GPU'daki belleÄŸi temizlemek ve artÄ±k ihtiyaÃ§ duyulmayan modelleri kaldÄ±rmak iÃ§in basit bir fonksiyon tanÄ±mlÄ±yoruz:

```python
def gpu_cleanup(objects):
    if objects:
        del(objects)
    K.clear_session()
    gc.collect()
```

AyrÄ±ca, gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ± ve sinir aÄŸÄ±yla ilgili birden fazla parametreyi dikkate almak iÃ§in **Config sÄ±nÄ±fÄ±nÄ± yeniden yapÄ±landÄ±rÄ±yoruz**. LightGBM hakkÄ±nda daha Ã¶nce belirtildiÄŸi gibi, tÃ¼m parametreleri tek bir yerde tutmak, bunlarÄ± tutarlÄ± bir ÅŸekilde deÄŸiÅŸtirmeniz gerektiÄŸinde sÃ¼reci basitleÅŸtirir:

```python
class Config:
    input_path = Path('../input/porto-seguro-safe-driver-prediction')
    dae_batch_size = 128
    dae_num_epoch = 50
    dae_architecture = [1500, 1500, 1500]
    reuse_autoencoder = False
    batch_size = 128
    num_epoch = 150
    units = [64, 32]
    input_dropout=0.06
    dropout=0.08
    regL2=0.09
    activation='selu'
    
    cv_folds = 5
    nas = False
    random_state = 0
    
config = Config()
```

Daha Ã¶nce gÃ¶sterildiÄŸi gibi, veri setlerini yÃ¼klÃ¼yor ve `calc` Ã¶zelliklerini kaldÄ±rarak ve kategorik olanlarÄ± tek-sÄ±cak kodlayarak Ã¶zellikleri iÅŸlemeye devam ediyoruz. Michael Jahrer'in Ã§Ã¶zÃ¼mÃ¼nde belirttiÄŸi gibi, eksik durumlarÄ± **-1** deÄŸeriyle bÄ±rakÄ±yoruz:

```python
train = pd.read_csv(config.input_path / 'train.csv', index_col='id')
test = pd.read_csv(config.input_path / 'test.csv', index_col='id')
submission = pd.read_csv(config.input_path / 'sample_submission.csv', 
index_col='id')
calc_features = [feat for feat in train.columns if "_calc" in feat]
cat_features = [feat for feat in train.columns if "_cat" in feat]
target = train["target"]
train = train.drop("target", axis="columns")
train = train.drop(calc_features, axis="columns")
test = test.drop(calc_features, axis="columns")
train = pd.get_dummies(train, columns=cat_features)
test = pd.get_dummies(test, columns=cat_features)
assert((train.columns==test.columns).all())
```

Ancak, sinir aÄŸlarÄ±yla uÄŸraÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in, ikili veya tek-sÄ±cak kodlanmÄ±ÅŸ kategorik olmayan **tÃ¼m Ã¶zellikleri normalleÅŸtirmemiz** gerekiyor. NormalleÅŸtirme, **yeniden Ã¶lÃ§eklendirme** (sÄ±nÄ±rlÄ± bir deÄŸer aralÄ±ÄŸÄ± ayarlama) ve **merkezleme** (daÄŸÄ±lÄ±mÄ±nÄ±zÄ±n belirli bir deÄŸere, genellikle sÄ±fÄ±ra, merkezlenmesi) anlamÄ±na gelir.

NormalleÅŸtirme, hem otomatik kodlayÄ±cÄ±nÄ±n hem de sinir aÄŸÄ±nÄ±n optimizasyon algoritmasÄ±nÄ±n daha hÄ±zlÄ± iyi bir Ã§Ã¶zÃ¼me yakÄ±nsamasÄ±nÄ± saÄŸlayacaktÄ±r Ã§Ã¼nkÃ¼ optimizasyon sÄ±rasÄ±nda kayÄ±p fonksiyonunun **salÄ±nÄ±m tehlikesini azaltÄ±r**. Ek olarak, normalleÅŸtirme, giriÅŸin aktivasyon fonksiyonlarÄ± aracÄ±lÄ±ÄŸÄ±yla yayÄ±lmasÄ±nÄ± kolaylaÅŸtÄ±rÄ±r.

Ä°statistiksel normalleÅŸtirme (deÄŸerlerinizin daÄŸÄ±lÄ±mÄ±nÄ± sÄ±fÄ±r ortalama ve birim standart sapmaya getirme) yerine, **GaussRank** (Gauss SÄ±ralamasÄ±), deÄŸiÅŸkenlerin daÄŸÄ±lÄ±mÄ±nÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ bir Gauss daÄŸÄ±lÄ±mÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmeye de olanak tanÄ±yan bir prosedÃ¼rdÃ¼r. *Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift* ([https://arxiv.org/pdf/1502.03167.pdf](https://arxiv.org/pdf/1502.03167.pdf)) gibi bazÄ± makalelerde de belirtildiÄŸi gibi, sinir aÄŸlarÄ± kendilerine bir Gauss giriÅŸi saÄŸlarsanÄ±z daha da iyi performans gÃ¶sterirler. Bu NVIDIA blog gÃ¶nderisine ([https://developer.nvidia.com/blog/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy/](https://developer.nvidia.com/blog/gauss-rank-transformation-is-100x-faster-with-rapids-and-cupy/)) gÃ¶re, GaussRank, Ã¶zellikler zaten normal daÄŸÄ±lmÄ±ÅŸsa veya aÅŸÄ±rÄ± asimetrikse (bu durumlarda dÃ¶nÃ¼ÅŸÃ¼mÃ¼n uygulanmasÄ± performansÄ±n kÃ¶tÃ¼leÅŸmesine neden olabilir) hariÃ§, Ã§oÄŸu zaman iÅŸe yarar:

```python
print("Applying GaussRank to columns: ", end='')
to_normalize = list()
for k, col in enumerate(train.columns):
    if '_bin' not in col and '_cat' not in col and '_missing' not in col:
        to_normalize.append(col)
print(to_normalize)

def to_gauss(x): return np.sqrt(2) * erfinv(x) 
def normalize(data, norm_cols):
    n = data.shape[0]
    for col in norm_cols:
        sorted_idx = data[col].sort_values().index.tolist()
        uniform = np.linspace(start=-0.99, stop=0.99, num=n)
        normal = to_gauss(uniform)
        normalized_col = pd.Series(index=sorted_idx, data=normal)
        data[col] = normalized_col
    return data

train = normalize(train, to_normalize)
test = normalize(test, to_normalize)
```

GaussRank dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼, veri setimizdeki tÃ¼m sayÄ±sal Ã¶zellikler Ã¼zerinde, eÄŸitim ve test Ã¶zellikleri Ã¼zerinde ayrÄ± ayrÄ± uygulayabiliriz:

```
Applying GaussRank to columns: ['ps_ind_01', 'ps_ind_03', 'ps_ind_14', 'ps_ind_15', 'ps_reg_01', 'ps_reg_02', 'ps_reg_03', 'ps_car_11', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15']
```

Ã–zellikleri normalleÅŸtirirken, verilerimizi basitÃ§e **NumPy array'ine** ve GPU iÃ§in ideal giriÅŸ olan `float32` deÄŸerlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz:

```python
features = train.columns
train_index = train.index
test_index = test.index
train = train.values.astype(np.float32)
test = test.values.astype(np.float32)
```

Daha sonra, deÄŸerlendirme fonksiyonu, normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ± (daha Ã¶nce aÃ§Ä±klanan koda dayanarak) ve bir Keras modelinin eÄŸitim ve doÄŸrulama setleri Ã¼zerindeki uygunluk geÃ§miÅŸini faydalÄ± bir ÅŸekilde temsil eden bir Ã§izim fonksiyonu gibi bazÄ± kullanÄ±ÅŸlÄ± fonksiyonlarÄ± hazÄ±rlÄ±yoruz:

```python
def plot_keras_history(history, measures):
    rows = len(measures) // 2 + len(measures) % 2
    fig, panels = plt.subplots(rows, 2, figsize=(15, 5))
    plt.subplots_adjust(top = 0.99, bottom=0.01, 
                        hspace=0.4, wspace=0.2)
    try:
        panels = [item for sublist in panels for item in sublist]
    except:
        pass
    for k, measure in enumerate(measures):
        panel = panels[k]
        panel.set_title(measure + ' history')
        panel.plot(history.epoch, history.history[measure],  
                   label="Train "+measure)
        try:
            panel.plot(history.epoch,  
                       history.history["val_"+measure], 
                       label="Validation "+measure)
        except:
            pass
        panel.set(xlabel='epochs', ylabel=measure)
        panel.legend()
    plt.show(fig)
    
from numba import jit
@jit
def eval_gini(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_true = y_true[np.argsort(y_pred)]
    ntrue = 0
    gini = 0
    delta = 0
    
    n = len(y_true)
    for i in range(n-1, -1, -1):
        y_i = y_true[i]
        ntrue += y_i
        gini += y_i * delta
        delta += 1 - y_i
    gini = 1 - 2 * gini / (ntrue * (n - ntrue))
    return gini
```

Sonraki fonksiyonlar aslÄ±nda biraz daha karmaÅŸÄ±k ve hem gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±nÄ±n hem de denetimli sinir aÄŸÄ±nÄ±n iÅŸleyiÅŸiyle daha alakalÄ±dÄ±r. `batch_generator`, veri yÄ±ÄŸÄ±nlarÄ±nÄ±n karÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ halde, yÄ±ÄŸÄ±n boyutuna (batch size) gÃ¶re saÄŸlayan bir jeneratÃ¶r oluÅŸturacak bir fonksiyondur. AslÄ±nda baÄŸÄ±msÄ±z bir jeneratÃ¶r olarak deÄŸil, yakÄ±nda aÃ§Ä±klayacaÄŸÄ±mÄ±z daha karmaÅŸÄ±k bir yÄ±ÄŸÄ±n jeneratÃ¶rÃ¼nÃ¼n, **`mixup_generator`'Ä±n**, bir parÃ§asÄ± olarak kullanÄ±lÄ±r:

```python
def batch_generator(x, batch_size, shuffle=True, random_state=None):
    batch_index = 0
    n = x.shape[0]
    while True:
        if batch_index == 0:
            index_array = np.arange(n)
            if shuffle:
                np.random.seed(seed=random_state)
                index_array = np.random.permutation(n)
        current_index = (batch_index * batch_size) % n
        if n >= current_index + batch_size:
            current_batch_size = batch_size
            batch_index += 1
        else:
            current_batch_size = n - current_index
            batch_index = 0
        batch = x[index_array[current_index: current_index + current_batch_size]]
        yield batch
```

`mixup_generator`, DAE'nin eÄŸitim veri setini **aÅŸÄ±rÄ± Ã¶ÄŸrenmesini (overfitting)** Ã¶nlemek iÃ§in **bir miktar gÃ¼rÃ¼ltÃ¼ oluÅŸturmak** ve veriyi zenginleÅŸtirmek amacÄ±yla deÄŸerlerinin kÄ±smen deÄŸiÅŸtirildiÄŸi veri yÄ±ÄŸÄ±nlarÄ±nÄ± dÃ¶ndÃ¼ren bir jeneratÃ¶rdÃ¼r. Bu jeneratÃ¶re, veri setine rastgele deÄŸerler enjekte etmenin ve eÄŸitim iÃ§in kullanÄ±lacak Ã§ok daha fazla Ã¶rnek oluÅŸturmanÄ±n bir yolu olarak bakabilirsiniz. Michael Jahrer tarafÄ±ndan Ã¶nerildiÄŸi gibi, Ã¶zelliklerin **%15'lik sabit bir takas oranÄ±na (swap rate)** gÃ¶re Ã§alÄ±ÅŸÄ±r, bu da her yÄ±ÄŸÄ±nda Ã¶rneÄŸin %15'inin rastgele deÄŸerlerden oluÅŸacaÄŸÄ± anlamÄ±na gelir. Rastgele seÃ§ilen deÄŸerlerin aynÄ± Ã¶zelliklerden rastgele olarak seÃ§ilmiÅŸ olmasÄ± da Ã¶nemlidir, Ã§Ã¼nkÃ¼ bu, yer deÄŸiÅŸtiren rastgele deÄŸerlerin tamamen rastgele olmadÄ±ÄŸÄ±, orijinal Ã¶zelliklerin daÄŸÄ±lÄ±mÄ±ndan geldiÄŸi anlamÄ±na gelir.

Fonksiyon, iki farklÄ± veri yÄ±ÄŸÄ±nÄ± Ã¼retir: biri modele verilecek ve diÄŸeri ise serbest bÄ±rakÄ±lacak yÄ±ÄŸÄ±ndaki deÄŸiÅŸtirilecek deÄŸer iÃ§in bir kaynak olarak kullanÄ±lacaktÄ±r. Temel olasÄ±lÄ±ÄŸÄ± takas oranÄ± olan rastgele bir seÃ§ime dayanarak, her yÄ±ÄŸÄ±nda belirli sayÄ±da Ã¶zellik iki yÄ±ÄŸÄ±n arasÄ±nda takas edilecektir.

Bu, DAE'nin her zaman aynÄ± Ã¶zelliklere gÃ¼venemeyeceÄŸi (Ã§Ã¼nkÃ¼ zaman zaman rastgele takas edilebilirler), bunun yerine aralarÄ±ndaki iliÅŸkileri bulmak ve sÃ¼recin sonunda veriyi doÄŸru bir ÅŸekilde yeniden yapÄ±landÄ±rmak iÃ§in **Ã¶zelliklerin tamamÄ±na odaklanmasÄ±** gerektiÄŸi anlamÄ±na gelir (bir anlamda dropout'a benzer bir ÅŸey):

```python
def mixup_generator(X, batch_size, swaprate=0.15, shuffle=True, random_state=None):
    if random_state is None:
        random_state = np.randint(0, 999)
    num_features = X.shape[1]
    num_swaps = int(num_features * swaprate)    
    generator_a = batch_generator(X, batch_size, shuffle, random_state)
    generator_b = batch_generator(X, batch_size, shuffle, random_state + 1)
    while True:
        batch = next(generator_a)
        mixed_batch = batch.copy()
        effective_batch_size = batch.shape[0]
        alternative_batch = next(generator_b)
        assert((batch != alternative_batch).any())
        for i in range(effective_batch_size):
            swap_idx = np.random.choice(num_features, num_swaps, replace=False)
            mixed_batch[i, swap_idx] = alternative_batch[i, swap_idx]
        yield (mixed_batch, batch)
```

`get_DAE`, gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±yÄ± oluÅŸturan fonksiyondur. Mimarinin tanÄ±mlanmasÄ± iÃ§in bir parametre kabul eder; bu durumda (Michael Jahrer'in Ã§Ã¶zÃ¼mÃ¼nÃ¼n Ã¶nerdiÄŸi gibi) her biri 1.500 dÃ¼ÄŸÃ¼me sahip Ã¼Ã§ katman olarak ayarlanmÄ±ÅŸtÄ±r. Ä°lk katman bir **kodlayÄ±cÄ± (encoder)**, ikincisi verideki bilgiyi ifade edebilen gizli Ã¶zellikleri ideal olarak iÃ§eren bir **darboÄŸaz katmanÄ± (bottleneck layer)** ve son katman ise baÅŸlangÄ±Ã§taki girdi verilerini yeniden yapÄ±landÄ±rabilen bir **kod Ã§Ã¶zme katmanÄ±dÄ±r (decoding layer)**. ÃœÃ§ katmanÄ±n bir `relu` aktivasyon fonksiyonu, yanlÄ±lÄ±k (bias) yok ve her biri bir **toplu normalleÅŸtirme (batch normalization)** katmanÄ± ile takip edilmektedir. Yeniden yapÄ±landÄ±rÄ±lmÄ±ÅŸ girdi verilerine sahip nihai Ã§Ä±ktÄ±, doÄŸrusal (linear) bir aktivasyona sahiptir. EÄŸitim, standart ayarlarla bir **adam iyileÅŸtirici** (optimizer) kullanÄ±larak optimize edilir (optimize edilen maliyet fonksiyonu **ortalama karesel hatadÄ±r â€“ mse**):

```python
def get_DAE(X, architecture=[1500, 1500, 1500]):
    features = X.shape[1]
    inputs = Input((features,))
    for i, nodes in enumerate(architecture):
        layer = Dense(nodes, activation='relu', 
                      use_bias=False, name=f"code_{i+1}")
        if i==0:
            x = layer(inputs)
        else:
            x = layer(x)
        x = BatchNormalization()(x)
    outputs = Dense(features, activation='linear')(x)
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam', loss='mse', 
                  metrics=['mse', 'mae'])
    return model
```

`extract_dae_features` fonksiyonu burada sadece eÄŸitim amaÃ§lÄ± rapor edilmiÅŸtir. Fonksiyon, eÄŸitilmiÅŸ gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±nÄ±n belirli katmanlarÄ±nÄ±n deÄŸerlerinin Ã§Ä±karÄ±lmasÄ±na yardÄ±mcÄ± olur. Ã‡Ä±karÄ±m, DAE giriÅŸ katmanÄ±nÄ± ve istenen Ã§Ä±kÄ±ÅŸ katmanÄ±nÄ± birleÅŸtirerek **yeni bir model oluÅŸturarak** Ã§alÄ±ÅŸÄ±r. Basit bir tahmin (`predict`) daha sonra ihtiyacÄ±mÄ±z olan deÄŸerleri Ã§Ä±karacaktÄ±r (tahmin, ayrÄ±ca herhangi bir bellek gereksinimine uyacak ÅŸekilde tercih edilen yÄ±ÄŸÄ±n boyutunu ayarlamamÄ±za da olanak tanÄ±r).

YarÄ±ÅŸma durumunda, gÃ¶zlem sayÄ±sÄ± ve otomatik kodlayÄ±cÄ±dan Ã§Ä±karÄ±lacak Ã¶zellik sayÄ±sÄ± gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, bu fonksiyonu kullanÄ±rsak, ortaya Ã§Ä±kan yoÄŸun matrisin bir Kaggle Notebook'un belleÄŸi tarafÄ±ndan iÅŸlenmesi **Ã§ok bÃ¼yÃ¼k** olacaktÄ±r. Bu nedenle, stratejimiz orijinal veriyi otomatik kodlayÄ±cÄ± dÃ¼ÄŸÃ¼m deÄŸerlerine (darboÄŸaz katmanÄ±na) dÃ¶nÃ¼ÅŸtÃ¼rmek deÄŸil, bunun yerine otomatik kodlayÄ±cÄ±yÄ±, **dondurulmuÅŸ katmanlarÄ±yla darboÄŸaz katmanÄ±na kadar denetimli sinir aÄŸÄ±yla birleÅŸtirmek** olacaktÄ±r, ki bunu yakÄ±nda tartÄ±ÅŸacaÄŸÄ±z:

```python
def extract_dae_features(autoencoder, X, layers=[3], batch_size=128):
    data = []
    for layer in layers:
        if layer==0:
            data.append(X)
        else:
            get_layer_output = Model([autoencoder.layers[0].input], 
                                  [autoencoder.layers[layer].output])
            layer_output = get_layer_output.predict(X, 
                                              batch_size= batch_size)
            data.append(layer_output)
    data = np.hstack(data)
    return data
```

DAE ile Ã§alÄ±ÅŸmayÄ± tamamlamak iÃ§in, Ã¶nceki tÃ¼m fonksiyonlarÄ± denetimsiz bir eÄŸitim prosedÃ¼rÃ¼ne (en azÄ±ndan bir doÄŸrulama setinde ayarlanmÄ±ÅŸ bir erken durdurma monitÃ¶rÃ¼ olduÄŸu iÃ§in kÄ±smen denetimsiz) saran son bir fonksiyona sahibiz. Fonksiyon, `mix-up` jeneratÃ¶rÃ¼nÃ¼ ayarlar, gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ± mimarisini oluÅŸturur ve ardÄ±ndan, aÅŸÄ±rÄ± Ã¶ÄŸrenme belirtileri varsa erken durdurma iÃ§in bir doÄŸrulama setindeki uygunluÄŸunu izleyerek onu eÄŸitir. Son olarak, eÄŸitilmiÅŸ DAE'yi dÃ¶ndÃ¼rmeden Ã¶nce, eÄŸitim ve doÄŸrulama uygunluÄŸunun bir grafiÄŸini Ã§izer ve modeli diske kaydeder.

Bu model Ã¼zerinde bir tohum (seed) belirlemeye Ã§alÄ±ÅŸsak bile, LightGBM modelinin aksine, sonuÃ§lar **aÅŸÄ±rÄ± derecede deÄŸiÅŸkendir** ve nihai birleÅŸtirme (ensemble) sonuÃ§larÄ±nÄ± etkileyebilir. SonuÃ§ yÃ¼ksek puanlÄ± olsa da, herkese aÃ§Ä±k ve Ã¶zel liderlik tablolarÄ±nda (herkese aÃ§Ä±k sonuÃ§lar Ã¶zel liderlik tablosuyla Ã§ok koreledir) daha yÃ¼ksek veya daha dÃ¼ÅŸÃ¼k sÄ±ralamaya inebilir ve herkese aÃ§Ä±k sonuÃ§larÄ±na dayanarak her zaman en iyi nihai gÃ¶nderimi seÃ§meniz kolay olacaktÄ±r:

```python
def autoencoder_fitting(X_train, X_valid, filename='dae',  
                        random_state=None, suppress_output=False):
    if suppress_output:
        verbose = 0
    else:
        verbose = 2
    print("Fitting a denoising autoencoder")
    tf.random.set_seed(seed=random_state)
    generator = mixup_generator(X_train, 
                                batch_size=config.dae_batch_size, 
                                swaprate=0.15, 
                                random_state=config.random_state)
    dae = get_DAE(X_train, architecture=config.dae_architecture)
    steps_per_epoch = np.ceil(X_train.shape[0] / 
                              config.dae_batch_size)
    early_stopping = EarlyStopping(monitor='val_mse', 
                                mode='min', 
                                patience=5, 
                                restore_best_weights=True,
                                verbose=0)
    history = dae.fit(generator,
                    steps_per_epoch=steps_per_epoch,
                    epochs=config.dae_num_epoch,
                    validation_data=(X_valid, X_valid),
                    callbacks=[early_stopping],
                    verbose=verbose)
    if not suppress_output: plot_keras_history(history, 
                                           measures=['mse', 'mae'])
    dae.save(filename)
    return dae
```

DAE ile uÄŸraÅŸtÄ±ktan sonra, talep beklentilerimizi tahmin etmesi gereken **denetimli sinir modelini** de tanÄ±mlama ÅŸansÄ±nÄ± deÄŸerlendiriyoruz. Ä°lk adÄ±m olarak, Ã§alÄ±ÅŸmanÄ±n tek bir katmanÄ±nÄ± tanÄ±mlamak iÃ§in bir fonksiyon tanÄ±mlÄ±yoruz:

  * **Rastgele normal baÅŸlatma**, Ã§Ã¼nkÃ¼ ampirik olarak bu problemde daha iyi sonuÃ§lara yakÄ±nsadÄ±ÄŸÄ± bulunmuÅŸtur.
  * L2 dÃ¼zenlileÅŸtirmesi ve Ã¶zelleÅŸtirilebilir bir aktivasyon fonksiyonu olan **yoÄŸun bir katman (dense layer)**.
  * Mimariden kolayca dahil edilebilen veya hariÃ§ tutulabilen ayarlanabilir bir **dropout katmanÄ±**.

Ä°ÅŸte yoÄŸun bloklarÄ± oluÅŸturma kodu:

```python
def dense_blocks(x, units, activation, regL2, dropout):
    kernel_initializer = keras.initializers.RandomNormal(mean=0.0, 
                                stddev=0.1, seed=config.random_state)
    for k, layer_units in enumerate(units):
        if regL2 > 0:
            x = Dense(layer_units, activation=activation, 
                      kernel_initializer=kernel_initializer, 
                      kernel_regularizer=l2(regL2))(x)
        else:
            x = Dense(layer_units, 
                      kernel_initializer=kernel_initializer, 
                      activation=activation)(x)
        if dropout > 0:
            x = Dropout(dropout)(x)
    return x
```

Daha Ã¶nce fark etmiÅŸ olabileceÄŸiniz gibi, tek bir katmanÄ± tanÄ±mlayan fonksiyon oldukÃ§a Ã¶zelleÅŸtirilebilir. AynÄ±sÄ±, iÃ§indeki katman ve birim sayÄ±sÄ±, dropout olasÄ±lÄ±klarÄ±, dÃ¼zenlileÅŸtirme ve aktivasyon tÃ¼rÃ¼ iÃ§in girdileri alan sarmalayÄ±cÄ± mimari fonksiyonu iÃ§in de geÃ§erlidir. Fikir, bir **sinir mimarisi aramasÄ± (Neural Architecture Search - NAS)** Ã§alÄ±ÅŸtÄ±rabilmek ve problemimizde hangi konfigÃ¼rasyonun daha iyi performans gÃ¶stereceÄŸini bulmaktÄ±r.

Fonksiyonla ilgili son bir not olarak, girdiler arasÄ±nda eÄŸitilmiÅŸ DAE'yi saÄŸlamak gereklidir, Ã§Ã¼nkÃ¼ giriÅŸleri sinir aÄŸÄ± model giriÅŸleri olarak kullanÄ±lÄ±rken, ilk katmanlarÄ± DAE'nin **darboÄŸaz katmanÄ±na** (DAE mimarisindeki orta katman) baÄŸlanÄ±r. Bu ÅŸekilde, iki modeli fiilen tek bir modelde birleÅŸtirmiÅŸ oluruz (ancak DAE aÄŸÄ±rlÄ±klarÄ± zaten dondurulmuÅŸtur ve eÄŸitilemez).

Bu Ã§Ã¶zÃ¼m, tÃ¼m eÄŸitim verilerinizi dÃ¶nÃ¼ÅŸtÃ¼rmek zorunda kalmamak, bunun yerine yalnÄ±zca sinir aÄŸÄ±nÄ±n iÅŸlediÄŸi tek yÄ±ÄŸÄ±nlarÄ± dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in tasarlanmÄ±ÅŸtÄ±r, bÃ¶ylece sistem belleÄŸinden tasarruf edilir:

```python
def dnn_model(dae, units=[4500, 1000, 1000], 
            input_dropout=0.1, dropout=0.5,
            regL2=0.05,
            activation='relu'):
    inputs = dae.get_layer("code_2").output
    if input_dropout > 0:
        x = Dropout(input_dropout)(inputs)
    else:
        x = tf.keras.layers.Layer()(inputs)
    x = dense_blocks(x, units, activation, regL2, dropout)
    outputs = Dense(1, activation='sigmoid')(x)
    model = Model(inputs=dae.input, outputs=outputs)
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
                loss=keras.losses.binary_crossentropy,
                metrics=[AUC(name='auc')])
    return model
```

EÄŸitim sÃ¼recine yÃ¶nelik, tÃ¼m ardÄ±ÅŸÄ±k dÃ¼zeni bir Ã§apraz doÄŸrulama katmanÄ±nda eÄŸitmek iÃ§in tÃ¼m adÄ±mlarÄ± iÃ§eren bir sarmalayÄ±cÄ± ile bitiriyoruz:

```python
def model_fitting(X_train, y_train, X_valid, y_valid, autoencoder, 
                 filename, random_state=None, suppress_output=False):
    if suppress_output:
            verbose = 0
    else:
            verbose = 2
    print("Fitting model")
    
    early_stopping = EarlyStopping(monitor='val_auc', 
                                    mode='max', 
                                    patience=10, 
                                    restore_best_weights=True,
                                    verbose=0)
    
    rlrop = ReduceLROnPlateau(monitor='val_auc', 
                                mode='max',
                                patience=2,
                                factor=0.75,
                                verbose=0)
        
    tf.random.set_seed(seed=random_state)
    model = dnn_model(autoencoder,
                    units=config.units,
                    input_dropout=config.input_dropout,
                    dropout=config.dropout,
                    regL2=config.regL2,
                    activation=config.activation)
        
    history = model.fit(X_train, y_train, 
                            epochs=config.num_epoch, 
                            batch_size=config.batch_size, 
                            validation_data=(X_valid, y_valid),
                            callbacks=[early_stopping, rlrop],
                            shuffle=True,
                            verbose=verbose)
    model.save(filename)
        
    if not suppress_output:  
        plot_keras_history(history, measures=['loss', 'auc'])
    return model, history
```

DAE uygulamamÄ±z, arkasÄ±ndaki fikir aynÄ± olmasÄ±na raÄŸmen, Jahrer'inkinden kesinlikle farklÄ± olduÄŸu iÃ§in, denetimli sinir aÄŸÄ±nÄ±n mimarisi hakkÄ±ndaki gÃ¶zlemlerine tamamen gÃ¼venemeyiz ve LightGBM modelindeki en iyi hiperparametreleri aradÄ±ÄŸÄ±mÄ±z gibi ideal gÃ¶stergeleri aramalÄ±yÄ±z. Optuna'yÄ± kullanarak ve aÄŸÄ± yapÄ±landÄ±rmak iÃ§in ayarladÄ±ÄŸÄ±mÄ±z birden fazla parametreden yararlanarak, bu kod parÃ§asÄ±nÄ± birkaÃ§ saat Ã§alÄ±ÅŸtÄ±rabilir ve neyin daha iyi Ã§alÄ±ÅŸabileceÄŸi hakkÄ±nda bir fikir edinebiliriz.

Deneylerimizde ÅŸunlarÄ± bulduk:

  * SÄ±rasÄ±yla 64 ve 32 dÃ¼ÄŸÃ¼mlÃ¼, **daha az dÃ¼ÄŸÃ¼me sahip iki katmanlÄ± bir aÄŸ** kullanmalÄ±yÄ±z.
  * **GiriÅŸ dropout'u, katmanlar arasÄ±ndaki dropout ve biraz L2 dÃ¼zenlileÅŸtirmesi** yardÄ±mcÄ± olur.
  * **SELU aktivasyon fonksiyonunu** kullanmak daha iyidir.

Ä°ÅŸte tÃ¼m optimizasyon deneylerini Ã§alÄ±ÅŸtÄ±rmak iÃ§in kod parÃ§asÄ±:

```python
if config.nas is True:
    def evaluate():
        metric_evaluations = list()
        skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, 
random_state=config.random_state)
        for k, (train_idx, valid_idx) in enumerate(skf.split(train, 
target)):
            
            X_train, y_train = train[train_idx, :], target[train_idx]
            X_valid, y_valid = train[valid_idx, :], target[valid_idx]
            if config.reuse_autoencoder:
                autoencoder = load_model(f"./dae_fold_{k}")
            else:
                autoencoder = autoencoder_fitting(X_train, X_valid,
                                                filename=f'./dae_fold_{k}', 
                                                random_state=config.random_state,
                                                suppress_output=True)
            
            model, _ = model_fitting(X_train, y_train, X_valid, y_valid,
                                        autoencoder=autoencoder,
                                        filename=f"dnn_model_fold_{k}", 
                                        random_state=config.random_state,
                                        suppress_output=True)
            
            val_preds = model.predict(X_valid, batch_size=128, verbose=0)
            best_score = eval_gini(y_true=y_valid, y_pred=np.ravel(val_preds))
            metric_evaluations.append(best_score)
            gpu_cleanup([autoencoder, model])
        return np.mean(metric_evaluations)
    
    def objective(trial):
        params = {
 'first_layer': trial.suggest_categorical("first_layer", 
[8, 16, 32, 64, 128, 256, 512]),
 'second_layer': trial.suggest_categorical("second_layer", 
[0, 8, 16, 32, 64, 128, 256]),
 'third_layer': trial.suggest_categorical("third_layer", 
[0, 8, 16, 32, 64, 128, 256]),
 'input_dropout': trial.suggest_float("input_dropout", 0.0, 
0.5),
 'dropout': trial.suggest_float("dropout", 0.0, 0.5),
 'regL2': trial.suggest_uniform("regL2", 0.0, 0.1),
 'activation': trial.suggest_categorical("activation", 
['relu', 'leaky-relu', 'selu'])
        }
        config.units = [nodes for nodes in [params['first_layer'], 
params['second_layer'], params['third_layer']] if nodes > 0]
        config.input_dropout = params['input_dropout']
        config.dropout = params['dropout']
        config.regL2 = params['regL2']
        config.activation = params['activation']
        return evaluate()
    
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=60)
    
    print("Best Gini Normalized Score", study.best_value)
    print("Best parameters", study.best_params)
    
    config.units = [nodes for nodes in [study.best_params['first_layer'], 
study.best_params['second_layer'], study.best_params['third_layer']] if 
nodes > 0]
    config.input_dropout = study.best_params['input_dropout']
    config.dropout = study.best_params['dropout']
    config.regL2 = study.best_params['regL2']
    config.activation = study.best_params['activation']
```

> ğŸ“ AlÄ±ÅŸtÄ±rma 5
> 
> 
> 
> EÄŸer **NAS (Sinir Mimarisi AramasÄ±)** hakkÄ±nda daha fazla bilgi arÄ±yorsanÄ±z, **The Kaggle Book**'un 276. sayfasÄ±ndan itibaren inceleyebilirsiniz. DAE ve denetimli sinir aÄŸÄ± sÃ¶z konusu olduÄŸunda, Michael Jahrer'in Ã§Ã¶zÃ¼mÃ¼nden kesinlikle farklÄ± bir ÅŸey uyguladÄ±ÄŸÄ±mÄ±z iÃ§in, **en iyi mimariyi aramak kritiktir**.
> 
> 
> 
> Bir alÄ±ÅŸtÄ±rma olarak, Keras'Ä±n yaratÄ±cÄ±sÄ± FranÃ§ois Chollet'in katkÄ±sÄ±nÄ± iÃ§eren, sinir aÄŸlarÄ±nÄ± optimize etmek iÃ§in hÄ±zlÄ± bir Ã§Ã¶zÃ¼m olan **KerasTuner**'Ä± (The Kaggle Book'un 285. sayfasÄ±ndan itibaren bulabilirsiniz) kullanarak hiperparametre aramasÄ±nÄ± iyileÅŸtirmeye Ã§alÄ±ÅŸÄ±n.
> 
> 
> 
> **AlÄ±ÅŸtÄ±rma NotlarÄ±** (Size yardÄ±mcÄ± olacak tÃ¼m notlarÄ± veya Ã§alÄ±ÅŸmalarÄ± buraya yazÄ±nÄ±z):

Her ÅŸeyi nihayet hazÄ±r hale getirdikten sonra, eÄŸitime baÅŸlamaya hazÄ±rÄ±z. GPU'lu bir Kaggle Notebook'ta yaklaÅŸÄ±k bir saat iÃ§inde, eksiksiz test ve katman dÄ±ÅŸÄ± (out-of-fold) tahminleri elde edebilirsiniz:

```python
preds = np.zeros(len(test))
oof = np.zeros(len(train))
metric_evaluations = list()
skf = StratifiedKFold(n_splits=config.cv_folds, shuffle=True, random_
                      state=config.random_state)
for k, (train_idx, valid_idx) in enumerate(skf.split(train, target)):
    print(f"CV fold {k}")
    X_train, y_train = train[train_idx, :], target[train_idx]
    X_valid, y_valid = train[valid_idx, :], target[valid_idx]
    
    if config.reuse_autoencoder:
        print("restoring previously trained dae")
        autoencoder = load_model(f"./dae_fold_{k}")
    else:
        autoencoder = autoencoder_fitting(X_train, X_valid,
                                        filename=f'./dae_fold_{k}', 
                                        random_state=config.random_state)
        
    model, history = model_fitting(X_train, y_train, X_valid, y_valid,
                                autoencoder=autoencoder,
                                filename=f"dnn_model_fold_{k}", 
                                random_state=config.random_state)
                                
    val_preds = model.predict(X_valid, batch_size=128)
    best_score = eval_gini(y_true=y_valid, 
                           y_pred=np.ravel(val_preds))
    best_epoch = np.argmax(history.history['val_auc']) + 1
    
    print(f"[best epoch is {best_epoch}]\tvalidation_0-gini_dnn: {best_score:0.5f}\n")
    
    metric_evaluations.append(best_score)
    
    # Test tahminlerini toplama
    preds += (model.predict(test, batch_size=128).ravel() / skf.n_splits)
    
    # Katman dÄ±ÅŸÄ± tahminleri kaydetme
    oof[valid_idx] = model.predict(X_valid, batch_size=128).ravel()
    
    # GPU belleÄŸini temizleme
    gpu_cleanup([autoencoder, model])
```

LightGBM modelinde yaptÄ±ÄŸÄ±mÄ±z gibi, ortalama katman normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ±na bakarak sonuÃ§lar hakkÄ±nda bir fikir edinebiliriz:

```python
print(f"DNN CV normalized Gini coefficient: {np.mean(metric_evaluations):0.3f} ({np.std(metric_evaluations):0.3f})")
```

SonuÃ§lar, LightGBM kullanÄ±larak daha Ã¶nce elde edilenlerle tamamen uyumlu olmayacaktÄ±r:

```
DNN CV Gini Normalized Score: 0.276 (0.015)
```

GÃ¶nderi dosyasÄ±nÄ± oluÅŸturmak ve gÃ¶ndermek, yaklaÅŸÄ±k **0.27737'lik bir herkese aÃ§Ä±k skor** ve yaklaÅŸÄ±k **0.28471'lik bir Ã¶zel skor** ile sonuÃ§lanacaktÄ±r (daha Ã¶nce bahsettiÄŸimiz gibi sonuÃ§lar bÃ¼yÃ¼k Ã¶lÃ§Ã¼de deÄŸiÅŸebilir) â€“ **Ã§ok yÃ¼ksek bir skor deÄŸil**:

```python
submission['target'] = preds
submission.to_csv('dnn_submission.csv')
oofs = pd.DataFrame({'id':train_index, 'target':oof})
oofs.to_csv('dnn_oof.csv', index=False)
```

Sinir aÄŸÄ±ndan elde edilen zayÄ±f sonuÃ§lar, sinir aÄŸlarÄ±nÄ±n tablo problemlerinde yetersiz performans gÃ¶sterdiÄŸi fikrini doÄŸrular gibi gÃ¶rÃ¼nmektedir. Ancak, bir Kaggler olarak, liderlik tablosunda baÅŸarÄ±lÄ± bir yer edinmek iÃ§in **tÃ¼m modellerin faydalÄ± olduÄŸunu** biliyoruz; sadece onlarÄ± en iyi nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± bulmamÄ±z gerekiyor. Kesinlikle, bir otomatik kodlayÄ±cÄ± ile beslenen bir sinir aÄŸÄ±, verilerdeki gÃ¼rÃ¼ltÃ¼den daha az etkilenen ve bilgiyi bir GBM'den farklÄ± bir ÅŸekilde iÅŸleyen bir Ã§Ã¶zÃ¼m Ã¼retmiÅŸtir.

## SonuÃ§larÄ± birleÅŸtirme *(Ensembling the results)*

ArtÄ±k iki modelimiz olduÄŸuna gÃ¶re, geriye kalan tek ÅŸey onlarÄ± **harmanlamak (mix)** ve sonuÃ§larÄ± iyileÅŸtirip iyileÅŸtiremeyeceÄŸimizi gÃ¶rmektir. Jahrer'in Ã¶nerdiÄŸi gibi doÄŸrudan bir **karÄ±ÅŸÄ±m (blend)** kullanÄ±yoruz, ancak kendimizi sadece ikisinin ortalamasÄ±nÄ± Ã¼retmekle sÄ±nÄ±rlandÄ±rmayacaÄŸÄ±z (Ã§Ã¼nkÃ¼ yaklaÅŸÄ±mÄ±mÄ±z sonuÃ§ta Jahrer'inkinden biraz farklÄ± oldu) ve karÄ±ÅŸÄ±m iÃ§in **en uygun aÄŸÄ±rlÄ±klarÄ±** bulmaya da Ã§alÄ±ÅŸacaÄŸÄ±z. Katman dÄ±ÅŸÄ± (out-of-fold) tahminleri iÃ§e aktararak ve deÄŸerlendirme fonksiyonumuzu hazÄ±rlayarak baÅŸlÄ±yoruz:

```python
import pandas as pd
import numpy as np

from numba import jit
@jit
def eval_gini(y_true, y_pred):
    y_true = np.asarray(y_true)
    y_true = y_true[np.argsort(y_pred)]
    ntrue = 0
    gini = 0
    delta = 0
    n = len(y_true)
    for i in range(n-1, -1, -1):
        y_i = y_true[i]
        ntrue += y_i
        gini += y_i * delta
        delta += 1 - y_i
    gini = 1 - 2 * gini / (ntrue * (n - ntrue))
    return gini

lgb_oof = pd.read_csv("../input/workbook-lgb/lgb_oof.csv")
dnn_oof = pd.read_csv("../input/workbook-dae/dnn_oof.csv")
target = pd.read_csv("../input/porto-seguro-safe-driver-prediction/train.csv", usecols=['id','target'])
```

Bu yapÄ±ldÄ±ktan sonra, LightGBM'in katman dÄ±ÅŸÄ± tahminlerini ve sinir aÄŸÄ±nÄ±n tahminlerini **sÄ±ralara (rank)** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz. Bunu yapÄ±yoruz Ã§Ã¼nkÃ¼ normalleÅŸtirilmiÅŸ Gini katsayÄ±sÄ± sÄ±ralamaya dayanÄ±r (tÄ±pkÄ± bir ROC-AUC deÄŸerlendirmesi gibi) ve dolayÄ±sÄ±yla sÄ±ralamalarÄ± harmanlamak, tahmin edilen olasÄ±lÄ±klarÄ± harmanlamaktan daha iyi Ã§alÄ±ÅŸÄ±r:

```python
lgb_oof_ranks = (lgb_oof.target.rank() / len(lgb_oof))
dnn_oof_ranks = (dnn_oof.target.rank() / len(dnn_oof))
```

Åimdi, iki modeli farklÄ± aÄŸÄ±rlÄ±klar kullanarak birleÅŸtirerek katman dÄ±ÅŸÄ± veriler iÃ§in daha iyi bir deÄŸerlendirme elde edip edemeyeceÄŸimizi test ediyoruz:

```python
baseline = eval_gini(y_true=target.target, y_pred=lgb_oof_ranks)
print(f"starting from a oof lgb baseline {baseline:0.5f}\n")
best_alpha = 1.0
for alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:
    ensemble = alpha * lgb_oof_ranks + (1.0 - alpha) * dnn_oof_ranks
    score = eval_gini(y_true=target.target, y_pred=ensemble)
    print(f"lgd={alpha:0.1f} dnn={(1.0 - alpha):0.1f} -> {score:0.5f}")
    
    if score > baseline:
        baseline = score
        best_alpha = alpha
        
print(f"\nBest alpha is {best_alpha:0.1f}")
```

HazÄ±r olduÄŸumuzda, kod parÃ§asÄ±nÄ± Ã§alÄ±ÅŸtÄ±rarak ilginÃ§ sonuÃ§lar elde edebiliriz:

```
starting from a oof lgb baseline 0.28850
lgd=0.1 dnn=0.9 -> 0.27352
lgd=0.2 dnn=0.8 -> 0.27744
lgd=0.3 dnn=0.7 -> 0.28084
lgd=0.4 dnn=0.6 -> 0.28368
lgd=0.5 dnn=0.5 -> 0.28595
lgd=0.6 dnn=0.4 -> 0.28763
lgd=0.7 dnn=0.3 -> 0.28873
lgd=0.8 dnn=0.2 -> 0.28923
lgd=0.9 dnn=0.1 -> 0.28916

Best alpha is 0.8
```

GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re, **LightGBM modeline gÃ¼Ã§lÃ¼ bir aÄŸÄ±rlÄ±k (0.8)** ve sinir aÄŸÄ±na daha zayÄ±f bir aÄŸÄ±rlÄ±k (0.2) harmanlamak, daha da iyi performans gÃ¶steren bir model ortaya Ã§Ä±karacaktÄ±r. Bu hipotezi, modeller iÃ§in aynÄ± aÄŸÄ±rlÄ±klarÄ±n bir karÄ±ÅŸÄ±mÄ±nÄ± ve bulduÄŸumuz ideal aÄŸÄ±rlÄ±klarÄ± ayarlayarak hemen deniyoruz:

```python
lgb_submission = pd.read_csv("../input/workbook-lgb/lgb_submission.csv")
dnn_submission = pd.read_csv("../input/workbook-dae/dnn_submission.csv")
submission = pd.read_csv(
 "../input/porto-seguro-safe-driver-prediction/sample_submission.csv")
```

Ã–nce, Michael Jahrer tarafÄ±ndan kullanÄ±lan strateji olan **eÅŸit aÄŸÄ±rlÄ±klÄ± Ã§Ã¶zÃ¼mÃ¼** deniyoruz:

```python
lgb_ranks = (lgb_submission.target.rank() / len(lgb_submission))
dnn_ranks = (dnn_submission.target.rank() / len(dnn_submission))
submission.target = lgb_ranks * 0.5 + dnn_ranks * 0.5
submission.to_csv("equal_blend_rank.csv", index=False)
```

Bu, nihai liderlik tablosunda 50. pozisyon civarÄ±nda olan bir **0.28393'lÃ¼k herkese aÃ§Ä±k skor** ve **0.29093'lÃ¼k Ã¶zel skor** ile sonuÃ§lanÄ±r, ki bu beklentilerimizden biraz uzaktÄ±r. Åimdi, katman dÄ±ÅŸÄ± tahminlerin bulmamÄ±za yardÄ±mcÄ± olduÄŸu aÄŸÄ±rlÄ±klarÄ± kullanmayÄ± deneyelim:

```python
lgb_ranks = (lgb_submission.target.rank() / len(lgb_submission))
dnn_ranks = (dnn_submission.target.rank() / len(dnn_submission))
submission.target = lgb_ranks * best_alpha +  dnn_ranks * (1.0 - best_alpha)
submission.to_csv("blend_rank.csv", index=False)
```

Burada sonuÃ§lar, **0.28502'lik herkese aÃ§Ä±k skor** ve **0.29192'lik Ã¶zel skor** ile sonuÃ§lanÄ±r, bu da nihai liderlik tablosunda **yedinci pozisyon** civarÄ±na denk gelir. GerÃ§ekten de Ã§ok daha iyi bir sonuÃ§tur, Ã§Ã¼nkÃ¼ LightGBM iyi bir modeldir, ancak muhtemelen verilere **gÃ¼rÃ¼ltÃ¼sÃ¼ giderilmiÅŸ veriler** Ã¼zerinde eÄŸitilmiÅŸ sinir aÄŸÄ±ndan bazÄ± bilgiler eklenerek saÄŸlanabilecek bazÄ± nÃ¼anslarÄ± kaÃ§Ä±rmaktadÄ±r.

-----

> ğŸ“ AlÄ±ÅŸtÄ±rma 6
> 
> 
> 
> CPMP'nin Ã§Ã¶zÃ¼mÃ¼nde ([https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44614](https://www.google.com/search?q=https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/discussion/44614)) iÅŸaret ettiÄŸi gibi, Ã§apraz doÄŸrulamanÄ±zÄ± nasÄ±l oluÅŸturduÄŸunuza baÄŸlÄ± olarak, **"katmanlar arasÄ±nda Gini skorlarÄ±nda bÃ¼yÃ¼k bir varyasyon"** yaÅŸayabilirsiniz. Bu nedenle, CPMP, birden fazla Ã§apraz doÄŸrulama iÃ§in **birÃ§ok farklÄ± tohum (seed)** kullanarak ve sonuÃ§larÄ± ortalayarak tahminlerin varyansÄ±nÄ± azaltmayÄ± Ã¶nermektedir.
> 
> 
> 
> Bir alÄ±ÅŸtÄ±rma olarak, Ã¶zellikle **gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±** iÃ§in daha kararlÄ± tahminler oluÅŸturmak Ã¼zere kullandÄ±ÄŸÄ±mÄ±z kodu deÄŸiÅŸtirmeye Ã§alÄ±ÅŸÄ±n.
> 
> 
> 
> **AlÄ±ÅŸtÄ±rma NotlarÄ±** (Size yardÄ±mcÄ± olacak tÃ¼m notlarÄ± veya Ã§alÄ±ÅŸmalarÄ± buraya yazÄ±nÄ±z):


## Ã–zet *(Summary)*

Bu ilk bÃ¶lÃ¼mde, klasik bir tablo (tabular) yarÄ±ÅŸmasÄ±yla ilgilendiniz. YarÄ±ÅŸmanÄ±n not defterlerini ve tartÄ±ÅŸmalarÄ±nÄ± okuyarak, kolayca harmanlanabilen sadece iki modeli iÃ§eren basit bir Ã§Ã¶zÃ¼m ortaya Ã§Ä±kardÄ±k. Ã–zellikle, tablo verileri iÃ§in sinir aÄŸlarÄ±yla Ã§alÄ±ÅŸÄ±rken Ã¶zellikle yararlÄ± olan **alternatif veri iÅŸleme** Ã¼retmek amacÄ±yla bir **gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±nÄ±n (denoising autoencoder)** nasÄ±l kullanÄ±lacaÄŸÄ±na dair bir Ã¶rnek sunduk. GeÃ§miÅŸ yarÄ±ÅŸmalardaki Ã§Ã¶zÃ¼mleri anlayÄ±p Ã§oÄŸaltarak, Kaggle yarÄ±ÅŸmalarÄ±ndaki temel yetkinliklerinizi hÄ±zla geliÅŸtirebilir ve daha yeni yarÄ±ÅŸma ve meydan okumalarda sÃ¼rekli olarak daha yÃ¼ksek performans gÃ¶sterme yeteneÄŸi kazanabilirsiniz.

Bir sonraki bÃ¶lÃ¼mde, bu kez **zaman serileriyle** ilgili karmaÅŸÄ±k bir tahmin problemine odaklanan Kaggle'dan baÅŸka bir tablo yarÄ±ÅŸmasÄ±nÄ± inceleyeceÄŸiz.

---

# BÃ¶lÃ¼m 2: Makridakis YarÄ±ÅŸmalarÄ± â€“ DoÄŸruluk ve Belirsizlik Ä°Ã§in Kaggle'daki M5 *(Chapter 2: The Makridakis Competitions â€“ M5 on Kaggle for Accuracy and Uncertainty)*

Elbette, metninizi TÃ¼rkÃ§eye Ã§evirdim:

---

## ğŸ“… M YarÄ±ÅŸmalarÄ± ve M5 Kaggle YarÄ±ÅŸmasÄ±

1982'den beri, **Spyros Makridakis** ([https://mofc.unic.ac.cy/dr-spyros-makridakis/](https://mofc.unic.ac.cy/dr-spyros-makridakis/)) mevcut ve yeni tahmin yÃ¶ntemlerinin farklÄ± tahmin problemlerine karÅŸÄ± etkinliÄŸini karÅŸÄ±laÅŸtÄ±rmak amacÄ±yla **M YarÄ±ÅŸmalarÄ±** adÄ± verilen tahmin meydan okumalarÄ±na dÃ¼nyanÄ±n her yerinden araÅŸtÄ±rmacÄ± gruplarÄ±nÄ± dahil etmiÅŸtir. Bu nedenle, M YarÄ±ÅŸmalarÄ± her zaman hem akademisyenlere hem de uygulayÄ±cÄ±lara tamamen aÃ§Ä±k olmuÅŸtur.

Bu yarÄ±ÅŸmalar muhtemelen **tahmin topluluÄŸunda en Ã§ok alÄ±ntÄ± yapÄ±lan ve atÄ±fta bulunulan** etkinliklerdir ve tahmin yÃ¶ntemlerindeki sÃ¼rekli deÄŸiÅŸen teknoloji haritasÄ±nÄ± her zaman Ã¶ne Ã§Ä±karmÄ±ÅŸlardÄ±r. Ã–nceki her M YarÄ±ÅŸmasÄ±, hem araÅŸtÄ±rmacÄ±lara hem de uygulayÄ±cÄ±lara tahmin araÃ§larÄ±nÄ± eÄŸitmek ve test etmek iÃ§in faydalÄ± veriler saÄŸlamanÄ±n yanÄ± sÄ±ra, tahmin yapÄ±lÄ±ÅŸ biÃ§iminde devrim yaratan bir dizi keÅŸif ve yaklaÅŸÄ±m sunmuÅŸtur.

En sonuncusu olan **M5 YarÄ±ÅŸmasÄ±** (bu bÃ¶lÃ¼m yazÄ±lÄ±rken M6 devam etmektedir) Kaggle'da dÃ¼zenlenmiÅŸtir ve perakende Ã¼rÃ¼nlerinin bir dizi hacim tahminini Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±rken **gradyan artÄ±rma (gradient-boosting) yÃ¶ntemlerinin kullanÄ±ÅŸlÄ±lÄ±ÄŸÄ±nÄ±** vurgulamada Ã¶zellikle Ã¶nemli olduÄŸunu kanÄ±tlamÄ±ÅŸtÄ±r. Bu bÃ¶lÃ¼mde, doÄŸruluk parkuruna (accuracy track) odaklanarak, Kaggle yarÄ±ÅŸmalarÄ±ndan bir zaman serisi problemiyle ilgileniyoruz ve en Ã¼st sÄ±ralarda yer alan, ancak en basit ve en anlaÅŸÄ±lÄ±r Ã§Ã¶zÃ¼mlerden birini Ã§oÄŸaltarak, okuyucularÄ±mÄ±za Kaggle'da ortaya Ã§Ä±kabilecek gelecekteki herhangi bir tahmin yarÄ±ÅŸmasÄ±nÄ± baÅŸarÄ±yla ele almak iÃ§in kod ve fikirler sunmayÄ± amaÃ§lÄ±yoruz.

> YarÄ±ÅŸma sayfalarÄ± dÄ±ÅŸÄ±nda, yarÄ±ÅŸma ve dinamikleri hakkÄ±nda UluslararasÄ± Tahmin Dergisi'nden aÅŸaÄŸÄ±daki makalelerde Ã§ok sayÄ±da bilgi bulduk:
>
> * Makridakis, Spyros, Evangelos Spiliotis ve Vassilios Assimakopoulos. M5 yarÄ±ÅŸmasÄ±: Arka plan, organizasyon ve uygulama. International Journal of Forecasting (2021).
> * Makridakis, Spyros, Evangelos Spiliotis ve Vassilios Assimakopoulos. M5 doÄŸruluk yarÄ±ÅŸmasÄ±: SonuÃ§lar, bulgular ve Ã§Ä±karÄ±mlar. International Journal of Forecasting (2022).
> * Makridakis, Spyros, vd. M5 Belirsizlik yarÄ±ÅŸmasÄ±: SonuÃ§lar, bulgular ve Ã§Ä±karÄ±mlar. International Journal of Forecasting (2021).

Bu bÃ¶lÃ¼mde ÅŸunlarÄ± Ã¶ÄŸreneceksiniz:

* YarÄ±ÅŸmanÄ±n zaman serisi verileri ve deÄŸerlendirme metriÄŸi
* Belirli tarihler ve zaman ufuklarÄ± (time horizons) iÃ§in tahminlerin hesaplanmasÄ±
* FarklÄ± zaman pencerelerinden gelen tahminlerin birleÅŸtirilmesi (Assembling)

> Bu bÃ¶lÃ¼mdeki tÃ¼m kod dosyalarÄ±nÄ± [https://packt.link/kwbchp2](https://packt.link/kwbchp2) adresinde bulabilirsiniz.

## YarÄ±ÅŸmayÄ± ve veriyi anlama *(Understanding the competition and the data)*

YarÄ±ÅŸma ([https://www.kaggle.com/competitions/m5-forecasting-accuracy](https://www.kaggle.com/competitions/m5-forecasting-accuracy)) Mart'tan Haziran 2020'ye kadar sÃ¼rdÃ¼ ve Kaggle'da 7.000'den fazla katÄ±lÄ±mcÄ± yer aldÄ±. OrganizatÃ¶rler, yarÄ±ÅŸmayÄ± iki ayrÄ± parkur halinde dÃ¼zenledi: biri noktasal tahmin (doÄŸruluk parkuru) ve diÄŸeri farklÄ± gÃ¼ven aralÄ±klarÄ±nda gÃ¼venilir deÄŸerleri tahmin etmek iÃ§in (belirsizlik parkuru). Bu bÃ¶lÃ¼mde odak noktamÄ±z, doÄŸruluk parkuru iÃ§in en iyi gÃ¶nderimlerden birini Ã§oÄŸaltmaya Ã§alÄ±ÅŸmak ve aynÄ± zamanda belirsizlik parkurunun da Ã¶nÃ¼nÃ¼ aÃ§mak olacak (Ã§Ã¼nkÃ¼ o da doÄŸruluk tahminlerine dayanÄ±yor).

Walmart verileri saÄŸladÄ±. Veriler, Ã¼Ã§ ABD eyaletine yayÄ±lmÄ±ÅŸ (zaman serileri birbiriyle bir miktar iliÅŸkilidir) departmanlara, kategorilere ve maÄŸazalara gÃ¶re hiyerarÅŸik olarak dÃ¼zenlenmiÅŸ 42.840 gÃ¼nlÃ¼k satÄ±ÅŸ zaman serisinden oluÅŸuyordu. SatÄ±ÅŸlarla birlikte Walmart, kalemlerin fiyatlarÄ±, bazÄ± takvim bilgileri, ilgili promosyonlar veya satÄ±ÅŸlarÄ± etkileyen diÄŸer olaylarÄ±n varlÄ±ÄŸÄ± gibi eÅŸlik eden bilgileri (tahmin problemlerinde genellikle sÄ±k saÄŸlanmayan dÄ±ÅŸsal deÄŸiÅŸkenler) de saÄŸladÄ±.

Kaggle dÄ±ÅŸÄ±nda, veriler Ã¶nceki M YarÄ±ÅŸmasÄ±ndan veri setleriyle birlikte ÅŸu adreste mevcuttur: [https://forecasters.org/resources/time-series-data/](https://forecasters.org/resources/time-series-data/).

YarÄ±ÅŸmanÄ±n ilginÃ§ bir yÃ¶nÃ¼, hem hÄ±zlÄ± hareket eden hem de yavaÅŸ hareket eden tÃ¼ketim mallarÄ± satÄ±ÅŸlarÄ±yla ilgilenmesiydi; Ã¶zellikle yavaÅŸ hareket eden mallar, aralÄ±klÄ± satÄ±ÅŸlarÄ±n (intermittent sales) birÃ§ok Ã¶rneÄŸini sunuyordu (satÄ±ÅŸlar Ã§oÄŸu zaman sÄ±fÄ±rdÄ±r, ancak nadir durumlar dÄ±ÅŸÄ±nda). AralÄ±klÄ± seriler, birÃ§ok sektÃ¶rde yaygÄ±n olmasÄ±na raÄŸmen, birÃ§ok uygulayÄ±cÄ± iÃ§in tahmin etmede hala zorlu bir durumdur.

YarÄ±ÅŸma takvimi iki bÃ¶lÃ¼m halinde dÃ¼zenlenmiÅŸtir. Ä°lk bÃ¶lÃ¼mde, Mart 2020 baÅŸÄ±ndan 1 Haziran'a kadar, yarÄ±ÅŸmacÄ±lar 1.913. gÃ¼ne kadar olan gÃ¼nler aralÄ±ÄŸÄ±nda modeller eÄŸitebilir ve herkese aÃ§Ä±k test setinde (1.914. gÃ¼nden 1.941. gÃ¼ne kadar) gÃ¶nderimlerini puanlayabilirlerdi. Bu tarihten sonra, 1 Temmuz'daki yarÄ±ÅŸmanÄ±n sonuna kadar, herkese aÃ§Ä±k test seti eÄŸitim setinin bir parÃ§asÄ± olarak kullanÄ±ma sunuldu ve katÄ±lÄ±mcÄ±larÄ±n 1.942. gÃ¼nden 1.969. gÃ¼ne kadar tahmin yapmak iÃ§in modellerini ayarlamalarÄ±na olanak saÄŸlandÄ± (28 gÃ¼nlÃ¼k, yani dÃ¶rt haftalÄ±k bir zaman penceresi). O dÃ¶nemde, gÃ¶nderimler liderlik tablosunda puanlanmadÄ±.

YarÄ±ÅŸmanÄ±n bÃ¶yle bir dÃ¼zenlemesinin ardÄ±ndaki mantÄ±k, ekiplerin baÅŸlangÄ±Ã§ta modellerini liderlik tablosunda test etmelerine ve en iyi performans gÃ¶steren yÃ¶ntemlerini not defterlerinde ve tartÄ±ÅŸmalarda paylaÅŸmalarÄ± iÃ§in zemin oluÅŸturmaktÄ±. Ä°lk aÅŸamadan sonra, organizatÃ¶rler, liderlik tablosunun aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) amaÃ§larÄ± veya modellerin hiperparametre ayarÄ± iÃ§in kullanÄ±lmasÄ±nÄ± engellemek istediler ve gerÃ§ek dÃ¼nyada olacaÄŸÄ± gibi bir tahmin durumunu taklit etmek istediler. Ek olarak, nihai olarak yalnÄ±zca tek bir gÃ¶nderimi seÃ§me gerekliliÄŸi, aynÄ± gerÃ§ekÃ§ilik ihtiyacÄ±nÄ± yansÄ±tÄ±yordu. GerÃ§ek dÃ¼nyada, bir MLOps ÅŸampiyon/meydan okuyucu stratejisi benimseseniz bile (bkz. [https://www.datarobot.com/blog/introducing-mlops-champion-challenger-models/](https://www.datarobot.com/blog/introducing-mlops-champion-challenger-models/)), belli bir noktada, kararlarÄ±nÄ±z iÃ§in hangi modele gÃ¼veneceÄŸinize karar vermeniz gerekir ve seÃ§imin sonucunu ancak ondan sonra alÄ±rsÄ±nÄ±z.

Verilere gelince, verilerin Walmart tarafÄ±ndan saÄŸlandÄ±ÄŸÄ±nÄ± ve ABD pazarÄ±nÄ± temsil ettiÄŸini belirtmiÅŸtik: Kaliforniya, Wisconsin ve Teksas'taki 10 maÄŸazadan kaynaklanmÄ±ÅŸtÄ±r. Spesifik olarak, veriler 3.049 Ã¼rÃ¼nÃ¼n satÄ±ÅŸlarÄ±ndan oluÅŸuyordu; bu Ã¼rÃ¼nler 3 kategoriye (hobiler, yiyecek ve ev eÅŸyalarÄ±) ayrÄ±lmÄ±ÅŸtÄ± ve bu kategoriler de her biri 7 departmana daha fazla bÃ¶lÃ¼nebiliyordu. BÃ¶yle bir hiyerarÅŸik yapÄ± kesinlikle bir meydan okumadÄ±r Ã§Ã¼nkÃ¼ satÄ±ÅŸ dinamiklerini ABD pazarÄ±, eyalet pazarÄ±, tek bir maÄŸaza, Ã¼rÃ¼n kategorisi, kategori departmanÄ± ve son olarak belirli bir Ã¼rÃ¼n dÃ¼zeyinde modelleyebilirsiniz. TÃ¼m bu seviyeler, ikinci parkurda, belirsizlik parkurunda tahmin edilmesi gereken farklÄ± toplamlar (aggregates) olarak da birleÅŸebilir:

| Seviye ID | Seviye AÃ§Ä±klamasÄ± | Toplama Seviyesi | Seri SayÄ±sÄ± |
| :---: | :--- | :--- | :---: |
| 1 | TÃ¼m Ã¼rÃ¼nler, tÃ¼m maÄŸazalar ve eyaletler iÃ§in toplanmÄ±ÅŸ | Toplam | 1 |
| 2 | TÃ¼m Ã¼rÃ¼nler, her eyalet iÃ§in toplanmÄ±ÅŸ | Eyalet | 3 |
| 3 | TÃ¼m Ã¼rÃ¼nler, her maÄŸaza iÃ§in toplanmÄ±ÅŸ | MaÄŸaza | 10 |
| 4 | TÃ¼m Ã¼rÃ¼nler, her kategori iÃ§in toplanmÄ±ÅŸ | Kategori | 3 |
| 5 | TÃ¼m Ã¼rÃ¼nler, her departman iÃ§in toplanmÄ±ÅŸ | Departman | 7 |
| 6 | TÃ¼m Ã¼rÃ¼nler, her eyalet ve kategori iÃ§in toplanmÄ±ÅŸ | Eyalet-Kategori | 9 |
| 7 | TÃ¼m Ã¼rÃ¼nler, her maÄŸaza ve kategori iÃ§in toplanmÄ±ÅŸ | MaÄŸaza-Kategori | 30 |
| 8 | TÃ¼m Ã¼rÃ¼nler, her eyalet ve departman iÃ§in toplanmÄ±ÅŸ | Eyalet-Departman | 21 |
| 9 | TÃ¼m Ã¼rÃ¼nler, her maÄŸaza ve departman iÃ§in toplanmÄ±ÅŸ | MaÄŸaza-Departman | 70 |
| 10 | Her Ã¼rÃ¼n, tÃ¼m maÄŸazalar/eyaletler iÃ§in toplanmÄ±ÅŸ | ÃœrÃ¼n | 3,049 |
| 11 | Her Ã¼rÃ¼n, her eyalet iÃ§in toplanmÄ±ÅŸ | ÃœrÃ¼n-Eyalet | 9,147 |
| 12 | Her Ã¼rÃ¼n, her maÄŸaza iÃ§in toplanmÄ±ÅŸ | ÃœrÃ¼n-MaÄŸaza | 30,490 |
| **Toplam** | | | **42,840** |

Zaman aÃ§Ä±sÄ±ndan bakÄ±ldÄ±ÄŸÄ±nda, ayrÄ±ntÄ± dÃ¼zeyi gÃ¼nlÃ¼k satÄ±ÅŸ kaydÄ±dÄ±r ve **29 Ocak 2011'den 19 Haziran 2016'ya kadar** olan dÃ¶nemi kapsar, bu da toplamda 1.969 gÃ¼ne eÅŸittir: 1.913 gÃ¼n eÄŸitim iÃ§in, 28 gÃ¼n doÄŸrulama iÃ§in (herkese aÃ§Ä±k liderlik tablosu) ve 28 gÃ¼n test iÃ§in (Ã¶zel liderlik tablosu). **28 gÃ¼nlÃ¼k bir tahmin ufku**, perakende sektÃ¶rÃ¼nde Ã§oÄŸu mal iÃ§in stoklarÄ± ve yeniden sipariÅŸ iÅŸlemlerini yÃ¶netmek iÃ§in uygun ufuk olarak kabul edilmektedir.

YarÄ±ÅŸma iÃ§in aldÄ±ÄŸÄ±nÄ±z farklÄ± verileri inceleyelim. `sales_train_evaluation.csv`, `sell_prices.csv` ve `calendar.csv` dosyalarÄ±nÄ± alÄ±rsÄ±nÄ±z. Zaman serilerini tutan dosya `sales_train_evaluation.csv`'dir. TanÄ±mlayÄ±cÄ± gÃ¶revi gÃ¶ren alanlardan (`item_id`, `dept_id`, `cat_id`, `store_id` ve `state_id`) ve bu gÃ¼nlerin satÄ±ÅŸlarÄ±nÄ± temsil eden `d_1`'den `d_1941`'e kadar olan sÃ¼tunlardan oluÅŸur:

![](im/1001.png)

`sell_prices.csv` dosyasÄ± ise **kalemlerin fiyatlarÄ±** hakkÄ±ndaki bilgileri iÃ§erir. Buradaki zorluk, `wm_yr_wk`'yi (haftanÄ±n kimliÄŸi) eÄŸitim verilerindeki sÃ¼tunlarla **birleÅŸtirmektir (join)**:

![](im/1002.png)


## DeÄŸerlendirme MetriÄŸini Anlama *(Understanding the Evaluation Metric)*

## Monsaraida'nÄ±n 4. sÄ±radaki Ã§Ã¶zÃ¼m fikirlerini inceleme *(Examining the 4th place solutionâ€™s ideas from Monsaraida)*

## Belirli tarihler ve zaman ufuklarÄ± (time horizons) iÃ§in tahminleri hesaplama *(Computing predictions for specific dates and time horizons)*

## Herkese aÃ§Ä±k (public) ve Ã¶zel (private) tahminleri bir araya getirme *(Assembling public and private predictions)*

## Ã–zet *(Summary)*

---

# BÃ¶lÃ¼m 3: GÃ¶rsel YarÄ±ÅŸma: Manyok YapraÄŸÄ± HastalÄ±ÄŸÄ± YarÄ±ÅŸmasÄ± *(Chapter 3: Vision Competition: Cassava Leaf Disease Competition)*

## Veriyi ve metrikleri anlama *(Understanding the data and metrics)*

## Bir temel model (baseline model) oluÅŸturma *(Building a baseline model)*

## En iyi Ã§Ã¶zÃ¼mlerden ders alma *(Learning from top solutions)*

### Ã–n eÄŸitim *(Pretraining)*

### Test zamanÄ± artÄ±rÄ±mÄ± *(Test time augmentation)*

### DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ler *(Transformers)*

### BirleÅŸtirme *(Ensembling)*

## KapsamlÄ± bir Ã§Ã¶zÃ¼m *(A complete solution)*

## Ã–zet *(Summary)*

---

# BÃ¶lÃ¼m 4: NLP YarÄ±ÅŸmasÄ± â€“ Google Quest Soru-Cevap Etiketleme *(Chapter 4: NLP Competition â€“ Google Quest Q&A Labeling)*

## Temel Ã§Ã¶zÃ¼m *(The baseline solution)*

## En iyi Ã§Ã¶zÃ¼mlerden ders alma *(Learning from top solutions)*

## Ã–zet *(Summary)*