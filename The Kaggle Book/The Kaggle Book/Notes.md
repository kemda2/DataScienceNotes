# Part I: Introduction to Competitions *(BÃ¶lÃ¼m I: YarÄ±ÅŸmalara GiriÅŸ)*

## Chapter 1: Introducing Kaggle and Other Data Science Competitions *(BÃ¶lÃ¼m 1: Kaggle ve DiÄŸer Veri Bilimi YarÄ±ÅŸmalarÄ±na GiriÅŸ)*

Veri bilimi yarÄ±ÅŸmalarÄ± uzun zamandÄ±r var ve zaman iÃ§inde giderek artan bir baÅŸarÄ± elde ettiler. Tutkulu bir yarÄ±ÅŸmacÄ± topluluÄŸundan doÄŸan bu yarÄ±ÅŸmalar, giderek daha fazla ilgi Ã§ekmeye ve milyonlarca veri bilimciden oluÅŸan Ã§ok daha geniÅŸ bir kitleye ulaÅŸmaya baÅŸladÄ±. En popÃ¼ler veri bilimi yarÄ±ÅŸma platformu olan **Kaggle**â€™da uzun yÄ±llardÄ±r yarÄ±ÅŸmacÄ± olarak yer aldÄ±ÄŸÄ±mÄ±z iÃ§in, bu deÄŸiÅŸimlerin tÃ¼mÃ¼ne yÄ±llar boyunca doÄŸrudan tanÄ±klÄ±k ettik ve bizzat deneyimledik.

BugÃ¼n, Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ± hakkÄ±nda bilgi ararsanÄ±z, Ã§ok sayÄ±da **buluÅŸma (meetup)**, **tartÄ±ÅŸma paneli**, **podcast**, **rÃ¶portaj** ve hatta bu tÃ¼r yarÄ±ÅŸmalarda nasÄ±l kazanÄ±lacaÄŸÄ±nÄ± anlatan **Ã§evrimiÃ§i kurslar** bulabilirsiniz. (Genellikle bu kurslar size azim, hesaplama kaynaklarÄ± ve harcanan zamanÄ±n doÄŸru karÄ±ÅŸÄ±mÄ±nÄ± kullanmanÄ±zÄ± tavsiye eder.) Ancak, ÅŸu anda okumakta olduÄŸunuz kitap dÄ±ÅŸÄ±nda, bu kadar Ã§ok veri bilimi yarÄ±ÅŸmasÄ±nÄ± nasÄ±l yÃ¶neteceÄŸinizi ve onlardan nasÄ±l en iyi ÅŸekilde yararlanabileceÄŸinizi â€” yalnÄ±zca puan veya sÄ±ralama aÃ§Ä±sÄ±ndan deÄŸil, **profesyonel deneyim** bakÄ±mÄ±ndan da â€” sistematik bir ÅŸekilde anlatan bir rehber bulmanÄ±z oldukÃ§a zordur.

Bu kitapta amacÄ±mÄ±z, Kaggle veya diÄŸer veri bilimi yarÄ±ÅŸmalarÄ±nda nasÄ±l yÃ¼ksek puan alacaÄŸÄ±nÄ±zÄ± anlatan birkaÃ§ ipucu vermek deÄŸil. Bunun yerine, **Kaggleâ€™da daha etkili yarÄ±ÅŸmanÄ±z** ve yarÄ±ÅŸma deneyimlerinizden â€” Ã¶zellikle de profesyonel hayatÄ±nÄ±z aÃ§Ä±sÄ±ndan â€” **en fazla faydayÄ± elde etmeniz** iÃ§in kapsamlÄ± bir rehber sunmak istiyoruz. Kitap iÃ§eriÄŸine, **Kaggle Master** ve **Grandmaster**â€™larla yapÄ±lan rÃ¶portajlar da eÅŸlik ediyor. Bu rÃ¶portajlarÄ±n size Kaggleâ€™da yarÄ±ÅŸmanÄ±n belirli yÃ¶nleri hakkÄ±nda farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve iÃ§gÃ¶rÃ¼ler sunacaÄŸÄ±nÄ± ve rekabetÃ§i veri bilimi yaparken kendinizi sÄ±nama ve Ã¶ÄŸrenme biÃ§iminize ilham vereceÄŸini umuyoruz.

Bu kitabÄ±n sonunda, **kendi deneyimlerimizden**, **yarÄ±ÅŸmalardan edindiÄŸimiz bilgilerden** ve **kaynaklardan** doÄŸrudan derlediÄŸimiz bilgileri iÃ§selleÅŸtirmiÅŸ olacaksÄ±nÄ±z. BÃ¶ylece yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã¶ÄŸrenmenizi ve geliÅŸmenizi saÄŸlayacak bir yol haritasÄ±na sahip olacaksÄ±nÄ±z.

BaÅŸlangÄ±Ã§ noktasÄ± olarak, bu bÃ¶lÃ¼mde ÅŸunlarÄ± inceleyeceÄŸiz:

* RekabetÃ§i programlamanÄ±n nasÄ±l veri bilimi yarÄ±ÅŸmalarÄ±na evrildiÄŸini,
* Neden Kaggle platformunun bu tÃ¼r yarÄ±ÅŸmalar iÃ§in en popÃ¼ler site olduÄŸunu,
* Ve bu platformun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±.

Bu bÃ¶lÃ¼mde aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

* Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi
* **Common Task Framework** (Ortak GÃ¶rev Ã‡erÃ§evesi) paradigmasÄ±
* Kaggle platformu ve bazÄ± alternatifleri
* Bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸi: aÅŸamalarÄ±, yarÄ±ÅŸma tÃ¼rleri, gÃ¶nderim ve liderlik tablosu dinamikleri, hesaplama kaynaklarÄ±, aÄŸ oluÅŸturma ve daha fazlasÄ±

### The rise of data science competition platforms *(Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi)*

RekabetÃ§i programlamanÄ±n kÃ¶klÃ¼ bir geÃ§miÅŸi vardÄ±r; 1970â€™lerde dÃ¼zenlenen ilk **ICPC (International Collegiate Programming Contest â€“ UluslararasÄ± ÃœniversitelerarasÄ± Programlama YarÄ±ÅŸmasÄ±)** ile baÅŸlamÄ±ÅŸtÄ±r. Ä°lk ICPCâ€™de, Ã¼niversitelerden ve ÅŸirketlerden gelen kÃ¼Ã§Ã¼k takÄ±mlar, bir dizi problemi bilgisayar programÄ± kullanarak Ã§Ã¶zmeleri gereken bir yarÄ±ÅŸmaya katÄ±lÄ±yordu (baÅŸlangÄ±Ã§ta katÄ±lÄ±mcÄ±lar **FORTRAN** dilinde kodlama yapÄ±yordu). Ä°yi bir final sÄ±ralamasÄ± elde etmek iÃ§in takÄ±mlarÄ±n gÃ¼Ã§lÃ¼ **takÄ±m Ã§alÄ±ÅŸmasÄ±**, **problem Ã§Ã¶zme** ve **programlama** becerileri sergilemeleri gerekiyordu.

Bu tÃ¼r bir yarÄ±ÅŸmanÄ±n yoÄŸun atmosferinde yer almak ve iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§ekme fÄ±rsatÄ±, Ã¶ÄŸrencilere bÃ¼yÃ¼k bir motivasyon saÄŸladÄ± ve yarÄ±ÅŸmanÄ±n yÄ±llar boyunca popÃ¼ler kalmasÄ±na neden oldu. ICPC finalistleri arasÄ±nda, gÃ¼nÃ¼mÃ¼zde oldukÃ§a tanÄ±nmÄ±ÅŸ isimler vardÄ±r: **Adam Dâ€™Angelo** (Facebookâ€™un eski CTOâ€™su ve Quoraâ€™nÄ±n kurucusu), **Nikolai Durov** (Telegram Messengerâ€™Ä±n kurucu ortaÄŸÄ±) ve **Matei Zaharia** (Apache Sparkâ€™Ä±n yaratÄ±cÄ±sÄ±). Bu isimlerin yanÄ± sÄ±ra birÃ§ok profesyonel aynÄ± ortak deneyimi paylaÅŸÄ±r: bir ICPC yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸlardÄ±r.

ICPCâ€™nin ardÄ±ndan, Ã¶zellikle 2000 yÄ±lÄ±ndan sonra uzaktan katÄ±lÄ±mÄ±n kolaylaÅŸmasÄ±yla programlama yarÄ±ÅŸmalarÄ± bÃ¼yÃ¼k bir geliÅŸme gÃ¶sterdi. Bu sayede uluslararasÄ± yarÄ±ÅŸmalarÄ±n dÃ¼zenlenmesi hem daha kolay hem de daha dÃ¼ÅŸÃ¼k maliyetli hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸunun formatÄ± benzerdir: bir dizi problem verilir ve katÄ±lÄ±mcÄ±larÄ±n bunlarÄ± Ã§Ã¶zmek iÃ§in kod yazmasÄ± gerekir. Kazananlar sadece Ã¶dÃ¼l kazanmakla kalmaz, aynÄ± zamanda iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§eker veya kendi alanlarÄ±nda tanÄ±nÄ±r hale gelirler.

RekabetÃ§i programlamadaki problemler genellikle **kombinatorik**, **sayÄ± teorisi**, **graf teorisi**, **algoritmik oyun teorisi**, **hesaplamalÄ± geometri**, **dizgi analizi** ve **veri yapÄ±larÄ±** gibi konulardan oluÅŸur. Son yÄ±llarda ise **yapay zekÃ¢** ile ilgili problemler de bu yarÄ±ÅŸmalarda yer almaya baÅŸlamÄ±ÅŸtÄ±r. Ã–zellikle **KDD Cup**â€™Ä±n (Knowledge Discovery and Data Mining Cup â€“ Bilgi KeÅŸfi ve Veri MadenciliÄŸi YarÄ±ÅŸmasÄ±) baÅŸlatÄ±lmasÄ±ndan sonra bu tÃ¼r problemler oldukÃ§a popÃ¼ler hale gelmiÅŸtir. Bu yarÄ±ÅŸma, her yÄ±l **Association for Computing Machinery (ACM)** tarafÄ±ndan dÃ¼zenlenen konferans kapsamÄ±nda **Ã–zel Ä°lgi Grubu (SIG)** tarafÄ±ndan yÃ¼rÃ¼tÃ¼lmektedir. (Kaynak: [https://kdd.org/conferences](https://kdd.org/conferences))

Ä°lk **KDD Cup**, 1997 yÄ±lÄ±nda dÃ¼zenlenmiÅŸ ve **doÄŸrudan pazarlamada lift eÄŸrisi optimizasyonu** konusundaki bir problemi iÃ§ermiÅŸtir. Bu yarÄ±ÅŸma, gÃ¼nÃ¼mÃ¼zde hÃ¢lÃ¢ devam eden uzun bir yarÄ±ÅŸma serisinin baÅŸlangÄ±cÄ±nÄ± oluÅŸturmuÅŸtur. Veri kÃ¼meleri, yÃ¶nergeler ve kazananlar dÃ¢hil olmak Ã¼zere tÃ¼m arÅŸivlere ÅŸu adresten ulaÅŸabilirsiniz: [https://www.kdd.org/kdd-cup](https://www.kdd.org/kdd-cup). YazÄ±m sÄ±rasÄ±nda en son mevcut olan yarÄ±ÅŸma ise [https://ogb.stanford.edu/kddcup2021/](https://ogb.stanford.edu/kddcup2021/).
KDD Cup yarÄ±ÅŸmalarÄ±, en iyi uygulamalarÄ± belirlemede oldukÃ§a etkili olmuÅŸtur. BirÃ§ok makalede yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri, teknikler ve veri kÃ¼meleri paylaÅŸÄ±lmÄ±ÅŸ, bu da araÅŸtÄ±rmacÄ±lar ve uygulayÄ±cÄ±lar iÃ§in **deney**, **eÄŸitim** ve **karÅŸÄ±laÅŸtÄ±rma (benchmarking)** aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k fayda saÄŸlamÄ±ÅŸtÄ±r.

Hem rekabetÃ§i programlama etkinliklerinin hem de KDD Cupâ€™Ä±n baÅŸarÄ±sÄ±, ÅŸirketleri (Ã¶rneÄŸin **Netflix**) ve giriÅŸimcileri (Ã¶rneÄŸin Kaggleâ€™Ä±n kurucusu **Anthony Goldbloom**) **veri bilimi yarÄ±ÅŸma platformlarÄ±** kurmaya teÅŸvik etti. Bu platformlar, ÅŸirketlerin Ã§Ã¶zÃ¼lmesi zor veri bilimi problemlerini kitle kaynaklÄ± Ã§Ã¶zÃ¼mlerle Ã§Ã¶zebilmesine olanak tanÄ±dÄ±. GerÃ§ekten de veri bilimi alanÄ±nda her problem iÃ§in iÅŸe yarayan tek bir â€œaltÄ±nâ€ yÃ¶ntem yoktur; Ã§oÄŸu zaman, **â€œdeneyebileceÄŸin her ÅŸeyi deneâ€** yaklaÅŸÄ±mÄ± gerekir.

AslÄ±nda, uzun vadede hiÃ§bir algoritma tÃ¼m problemler iÃ§in diÄŸerlerini alt edemez. Bu durum, **David Wolpert** ve **William Macready** tarafÄ±ndan ortaya konan **No Free Lunch Teoremi (Bedava Ã–ÄŸle YemeÄŸi Yok Teoremi)** ile aÃ§Ä±klanÄ±r. Bu teoreme gÃ¶re, her makine Ã¶ÄŸrenimi algoritmasÄ± yalnÄ±zca Ã§Ã¶zÃ¼mÃ¼ iÃ§eren bir hipotez uzayÄ±na sahipse baÅŸarÄ±lÄ± olur. DolayÄ±sÄ±yla, bir algoritmanÄ±n belirli bir problemi en iyi ÅŸekilde Ã§Ã¶zebileceÄŸini Ã¶nceden bilemezsiniz; bunu Ã¶ÄŸrenmenin tek yolu, algoritmayÄ± doÄŸrudan o problem Ã¼zerinde test etmektir.
Makine Ã¶ÄŸreniminde herhangi bir â€œkutsal kÃ¢seâ€ veya teorik kestirme yoktur â€” yalnÄ±zca **ampirik deneyler** size neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶sterebilir.

Bu konuda daha fazla bilgi edinmek iÃ§in **No Free Lunch Teoremi** Ã¼zerine kuramsal aÃ§Ä±klamalarÄ± inceleyebilirsiniz. AÅŸaÄŸÄ±da bu konuyu detaylÄ± anlatan bir makaleye baÄŸlantÄ± verilmiÅŸtir:
ğŸ‘‰ [Analytics India Magazine â€“ What are the No Free Lunch Theorems in Data Science?](https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/)

Bu tÃ¼r durumlarda **crowdsourcing (kitle kaynak kullanÄ±mÄ±)** mÃ¼kemmel bir yÃ¶ntemdir; Ã§Ã¼nkÃ¼ algoritmalarÄ± ve veri dÃ¶nÃ¼ÅŸÃ¼mlerini kapsamlÄ± bir ÅŸekilde test etmeniz gerekir, ancak bunu yapacak insan gÃ¼cÃ¼ ve iÅŸlem gÃ¼cÃ¼nÃ¼z yoktur. Bu nedenle, hÃ¼kÃ¼metler ve ÅŸirketler belirli alanlarda ilerleme kaydetmek iÃ§in yarÄ±ÅŸmalara baÅŸvurur:

* **Kamu tarafÄ±nda:** ABDâ€™nin **DARPA** kuruluÅŸu tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalarda; **otonom araÃ§lar**, **robotik operasyonlar**, **makine Ã§evirisi**, **konuÅŸmacÄ± tanÄ±ma**, **parmak izi tanÄ±ma**, **bilgi eriÅŸimi**, **OCR (Optik Karakter TanÄ±ma)**, **otomatik hedef tanÄ±ma** gibi birÃ§ok alanda yarÄ±ÅŸmalar dÃ¼zenlenmiÅŸtir.
* **Åirket tarafÄ±nda:** Ã–rneÄŸin **Netflix**, kullanÄ±cÄ±larÄ±n film tercihlerinin tahmin edilmesini iyileÅŸtirmek amacÄ±yla dÃ¼zenlenen bir yarÄ±ÅŸmanÄ±n sonucuna gÃ¶re algoritmasÄ±nÄ± geliÅŸtirmiÅŸtir.

**Netflix YarÄ±ÅŸmasÄ± (Netflix Prize)**, mevcut **Ã¶neri sistemini** (collaborative filtering) geliÅŸtirmeyi amaÃ§lÄ±yordu. YarÄ±ÅŸmanÄ±n hedefi, bir kullanÄ±cÄ±nÄ±n bir filme vereceÄŸi puanÄ±, yalnÄ±zca daha Ã¶nce puanladÄ±ÄŸÄ± filmlerden yola Ã§Ä±karak tahmin etmekti â€” yani kullanÄ±cÄ± kimliÄŸi veya film aÃ§Ä±klamalarÄ± hakkÄ±nda hiÃ§bir bilgi yoktu (bunlarÄ±n tÃ¼mÃ¼ kimlik kodlarÄ±yla deÄŸiÅŸtirilmiÅŸti). KatÄ±lÄ±mcÄ±lardan, mevcut puan geÃ§miÅŸini akÄ±llÄ±ca kullanarak tahmin yapan modeller geliÅŸtirmeleri istendi.
**1.000.000 ABD DolarÄ±** tutarÄ±ndaki bÃ¼yÃ¼k Ã¶dÃ¼l, yalnÄ±zca geliÅŸtirilen modelin Netflixâ€™in mevcut algoritmasÄ± **Cinematch**â€™i belirli bir eÅŸiÄŸin Ã¼zerinde iyileÅŸtirmesi durumunda verilecekti.

YarÄ±ÅŸma 2006â€™dan 2009â€™a kadar sÃ¼rdÃ¼ ve kazanan takÄ±m, Ã¶nceki yarÄ±ÅŸmalardan birÃ§ok takÄ±mÄ±n birleÅŸmesiyle oluÅŸtu: **Commendo Research & Consulting GmbH**â€™den **Andreas TÃ¶scher** ve **Michael Jahrer** (aynÄ± zamanda Kaggleâ€™da da tanÄ±nan yarÄ±ÅŸmacÄ±lar), **AT&T Labs**â€™tan iki araÅŸtÄ±rmacÄ± ve **Yahoo!**â€™dan iki araÅŸtÄ±rmacÄ±.
YarÄ±ÅŸmayÄ± kazanmak, o kadar bÃ¼yÃ¼k bir hesaplama gÃ¼cÃ¼ ve farklÄ± Ã§Ã¶zÃ¼mlerin birleÅŸtirilmesini (ensemble) gerektirdi ki, takÄ±mlar rekabeti sÃ¼rdÃ¼rebilmek iÃ§in birleÅŸmek zorunda kaldÄ±lar. SonuÃ§ta, **Netflix** bu Ã§Ã¶zÃ¼mÃ¼ doÄŸrudan uygulamak yerine, yarÄ±ÅŸmadan elde edilen en deÄŸerli iÃ§gÃ¶rÃ¼leri alÄ±p mevcut **Cinematch algoritmasÄ±nÄ±** geliÅŸtirmede kullandÄ±.
Bu konuda daha fazla bilgi iÃ§in ÅŸu **Wired** makalesini okuyabilirsiniz:
ğŸ‘‰ [https://www.wired.com/2012/04/netflix-prize-costs/](https://www.wired.com/2012/04/netflix-prize-costs/)

Netflix yarÄ±ÅŸmasÄ±nÄ±n sonunda Ã¶nemli olan ÅŸey, Ã§Ã¶zÃ¼mÃ¼n kendisi deÄŸil, **Netflixâ€™in iÅŸ modelinin DVD kiralamadan Ã§evrimiÃ§i yayÄ±n platformuna geÃ§mesiyle** birlikte elde edilen **bilgi ve deneyimdi**. YarÄ±ÅŸmadan hem katÄ±lÄ±mcÄ±lar (Ã¶neri sistemleri alanÄ±nda bÃ¼yÃ¼k bir Ã¼n kazandÄ±lar) hem de Netflix (geliÅŸtirilmiÅŸ Ã¶neri sistemi bilgisini yeni iÅŸ modeline aktardÄ±) bÃ¼yÃ¼k fayda saÄŸladÄ±.

#### The Kaggle competition platform *(Kaggle yarÄ±ÅŸma platformu)*

**Netflix dÄ±ÅŸÄ±ndaki birÃ§ok ÅŸirket de veri bilimi yarÄ±ÅŸmalarÄ±ndan fayda saÄŸlamÄ±ÅŸtÄ±r.** Liste oldukÃ§a uzundur, ancak yarÄ±ÅŸmayÄ± dÃ¼zenleyen ÅŸirketlerin aÃ§Ä±k bir ÅŸekilde fayda elde ettiÄŸini bildirdiÄŸi birkaÃ§ Ã¶rneÄŸi verebiliriz. Ã–rneÄŸin:

* **Allstate** adlÄ± sigorta ÅŸirketi, yÃ¼zlerce veri bilimcinin katÄ±ldÄ±ÄŸÄ± bir yarÄ±ÅŸma sayesinde ([https://www.kaggle.com/c/ClaimPredictionChallenge](https://www.kaggle.com/c/ClaimPredictionChallenge)), kendi uzmanlarÄ± tarafÄ±ndan geliÅŸtirilen aktÃ¼eryal modellerini Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirebilmiÅŸtir.
* BaÅŸka iyi belgelenmiÅŸ bir Ã¶rnek olarak, **General Electric**, havayolu uÃ§uÅŸlarÄ±nÄ±n varÄ±ÅŸ zamanlarÄ±nÄ± tahmin etmede kullanÄ±lan sektÃ¶r standardÄ± performans Ã¶lÃ§Ã¼tÃ¼ne gÃ¶re (kÃ¶k ortalama kare hatasÄ± â€“ *root mean squared error* metriÄŸiyle Ã¶lÃ§Ã¼lÃ¼r) %40â€™lÄ±k bir geliÅŸme saÄŸlamÄ±ÅŸtÄ±r. Bu baÅŸarÄ±, benzer bir yarÄ±ÅŸma sayesinde elde edilmiÅŸtir ([https://www.kaggle.com/c/flight](https://www.kaggle.com/c/flight)).

**Kaggle yarÄ±ÅŸma platformu** bugÃ¼ne kadar yÃ¼zlerce yarÄ±ÅŸma dÃ¼zenlemiÅŸtir ve bu iki Ã¶rnek, platformu baÅŸarÄ±yla kullanan ÅŸirketlerden yalnÄ±zca birkaÃ§Ä±dÄ±r.
Åimdi, belirli yarÄ±ÅŸmalarÄ±n Ã¶tesine geÃ§ip bu kitabÄ±n da merkezinde yer alan **Kaggle ÅŸirketi** hakkÄ±nda konuÅŸalÄ±m.

##### A history of Kaggle *(Kaggleâ€™Ä±n tarihÃ§esi)*

**Kaggle**, ilk adÄ±mlarÄ±nÄ± **Åubat 2010â€™da**, ekonomist ve ekonometrikÃ§i olarak eÄŸitim almÄ±ÅŸ AvustralyalÄ± **Anthony Goldbloom** sayesinde attÄ±. Goldbloom, Avustralya Hazine BakanlÄ±ÄŸÄ±â€™nda (*Department of the Treasury*) ve Avustralya Merkez BankasÄ±â€™nÄ±n (*Reserve Bank of Australia*) AraÅŸtÄ±rma DepartmanÄ±â€™nda Ã§alÄ±ÅŸtÄ±ktan sonra, Londraâ€™da haftalÄ±k uluslararasÄ± dergi **The Economist**â€™te staj yaptÄ±.

The Economistâ€™te Ã§alÄ±ÅŸtÄ±ÄŸÄ± dÃ¶nemde â€œ**bÃ¼yÃ¼k veri (big data)**â€ Ã¼zerine bir makale yazma fÄ±rsatÄ± buldu. Bu makale, onun aklÄ±na **ilginÃ§ makine Ã¶ÄŸrenimi problemlerini Ã§Ã¶zmek iÃ§in en iyi analitik uzmanlarÄ± kitlesel katÄ±lÄ±mla (crowdsourcing) bir araya getirecek bir yarÄ±ÅŸma platformu kurma fikrini** getirdi ([kaynak](https://www.smh.com.au/technology/from-bondi-to-the-big-bucks-the-28yearold-whos-making-datascience-a-sport-20111104-1myq1.html)).

Bu platformun iÅŸ fikrinde â€œcrowdsourcingâ€ dinamiklerinin Ã¶nemli bir rol oynamasÄ±ndan dolayÄ±, Goldbloom platformun adÄ±nÄ± **Kaggle** koydu. Bu isim, Ä°ngilizce â€œ**gaggle**â€ (kaz sÃ¼rÃ¼sÃ¼) kelimesine bir gÃ¶nderme yapÄ±yor; kaz figÃ¼rÃ¼ de zaten Kaggle platformunun sembolÃ¼dÃ¼r.

Goldbloom, daha sonra **ABDâ€™nin Silikon Vadisiâ€™ne taÅŸÄ±ndÄ±** ve Kaggle giriÅŸimi, iki tanÄ±nmÄ±ÅŸ risk sermayesi ÅŸirketi olan **Khosla Ventures** ve **Index Ventures** tarafÄ±ndan yÃ¶netilen bir yatÄ±rÄ±m turunda **11,25 milyon dolar** tutarÄ±nda **A Serisi yatÄ±rÄ±m** aldÄ±. Ä°lk yarÄ±ÅŸmalar baÅŸlatÄ±ldÄ±, topluluk hÄ±zla bÃ¼yÃ¼dÃ¼ ve bazÄ± erken dÃ¶nem yarÄ±ÅŸmacÄ±lar dikkat Ã§ekici baÅŸarÄ±lara ulaÅŸtÄ±. Bunlardan biri olan **Jeremy Howard**, AvustralyalÄ± bir veri bilimci ve giriÅŸimciydi. Kaggleâ€™da birkaÃ§ yarÄ±ÅŸma kazandÄ±ktan sonra ÅŸirketin **BaÅŸkanÄ± (President)** ve **BaÅŸ Bilimcisi (Chief Scientist)** oldu.

Jeremy Howard, **AralÄ±k 2013â€™te** gÃ¶revinden ayrÄ±ldÄ± ve daha sonra **fast.ai** ([www.fast.ai](http://www.fast.ai)) adlÄ± yeni bir giriÅŸim kurdu. Bu giriÅŸim, **makine Ã¶ÄŸrenimi kurslarÄ±** ve **geliÅŸtiriciler iÃ§in derin Ã¶ÄŸrenme (deep learning) kÃ¼tÃ¼phanesi** sunmaktadÄ±r.

O dÃ¶nemde Ã¶ne Ã§Ä±kan diÄŸer bazÄ± **Kaggle yarÄ±ÅŸmacÄ±larÄ± (Kagglers)** arasÄ±nda **Jeremy Achin** ve **Thomas de Godoy** da bulunuyordu. Platformda **ilk 20 kÃ¼resel sÄ±ralama** arasÄ±na girdikten sonra emekli olmaya karar verdiler ve **DataRobot** adlÄ± kendi ÅŸirketlerini kurdular. KÄ±sa sÃ¼re sonra, geliÅŸtirdikleri yazÄ±lÄ±ma en iyi makine Ã¶ÄŸrenimi bilgilerini ve uygulamalarÄ±nÄ± kazandÄ±rmak amacÄ±yla **Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmuÅŸ katÄ±lÄ±mcÄ±larÄ± iÅŸe almaya** baÅŸladÄ±lar. BugÃ¼n **DataRobot**, **AutoML (otomatik makine Ã¶ÄŸrenimi)** Ã§Ã¶zÃ¼mleri geliÅŸtiren Ã¶nde gelen ÅŸirketlerden biridir.

Kaggle yarÄ±ÅŸmalarÄ±, giderek artan bir ilgiyle bÃ¼yÃ¼meye devam etti. **Derin Ã¶ÄŸrenmenin â€œbabasÄ±â€ Geoffrey Hinton**, 2012â€™de **Merck** tarafÄ±ndan dÃ¼zenlenen bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ± ve kazandÄ± ([kaynak](https://www.kaggle.com/c/MerckActivity/overview/winners)).

AyrÄ±ca Kaggle, **FranÃ§ois Chollet**â€™nin derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi **Keras**â€™Ä± tanÄ±ttÄ±ÄŸÄ± **Otto Group Product Classification Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13632)) yarÄ±ÅŸmasÄ±nÄ±n ve **Tianqi Chen**â€™in **XGBoost** adlÄ± daha hÄ±zlÄ± ve daha doÄŸru bir **gradient boosting** algoritmasÄ±nÄ± tanÄ±ttÄ±ÄŸÄ± **Higgs Boson Machine Learning Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/higgs-boson/discussion/10335)) yarÄ±ÅŸmasÄ±nÄ±n da dÃ¼zenlendiÄŸi platformdur.

FranÃ§ois Chollet ayrÄ±ca **Quora** sitesinde â€œKaggle yarÄ±ÅŸmalarÄ±nda neden Keras bu kadar baÅŸarÄ±lÄ± oldu?â€ sorusuna verdiÄŸi cevapta, Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmanÄ±n Ã¶zÃ¼nÃ¼ mÃ¼kemmel bir ÅŸekilde aÃ§Ä±klamÄ±ÅŸtÄ±r ([kaynak](https://www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions)).
Ona gÃ¶re, **Ã§ok sayÄ±da denemeyi hÄ±zlÄ± ÅŸekilde yapmak ve teoriden ziyade ampirik kanÄ±tlarla yÃ¶nlenmek**, Kaggleâ€™da baÅŸarÄ±lÄ± olmanÄ±n temelidir. Biz de onun belirttiÄŸi noktalarÄ±n dÄ±ÅŸÄ±nda baÅŸka bir â€œgizli sÄ±râ€ olduÄŸuna inanmÄ±yoruz.

FranÃ§ois Chollet ayrÄ±ca Kaggleâ€™da kendi yarÄ±ÅŸmasÄ±nÄ± da dÃ¼zenlemiÅŸtir ([Abstraction and Reasoning Challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge/)) â€” bu yarÄ±ÅŸma, **dÃ¼nyanÄ±n ilk genel yapay zekÃ¢ (general AI) yarÄ±ÅŸmasÄ±** olarak kabul edilir.

YarÄ±ÅŸma Ã¼stÃ¼ne yarÄ±ÅŸma geldikÃ§e, Kaggle etrafÄ±ndaki topluluk bÃ¼yÃ¼meye devam etti ve **2017 yÄ±lÄ±nda 1 milyon kullanÄ±cÄ±ya** ulaÅŸtÄ±. AynÄ± yÄ±l, **Google BaÅŸ Bilimcisi Fei-Fei Li**, **Google Next** etkinliÄŸinde yaptÄ±ÄŸÄ± aÃ§Ä±lÄ±ÅŸ konuÅŸmasÄ±nda **Googleâ€™Ä±n Kaggleâ€™Ä± satÄ±n alacaÄŸÄ±nÄ±** duyurdu.
O tarihten bu yana **Kaggle, Google Ã§atÄ±sÄ± altÄ±nda** faaliyet gÃ¶stermektedir.

BugÃ¼n, **Kaggle topluluÄŸu hÃ¢lÃ¢ aktif ve bÃ¼yÃ¼meye devam ediyor.**
Anthony Goldbloomâ€™un bir tweetâ€™inde ([kaynak](https://twitter.com/antgoldbloom/status/1400119591246852096)) belirttiÄŸi Ã¼zere, kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k bir kÄ±smÄ± sadece yarÄ±ÅŸmalara katÄ±lmakla kalmÄ±yor; aynÄ± zamanda **Kaggleâ€™Ä±n herkese aÃ§Ä±k veri setlerini indiriyor** (Kaggle artÄ±k Ã¶nemli bir **veri merkezi** haline gelmiÅŸtir), **Python veya R ile herkese aÃ§Ä±k Notebooks oluÅŸturuyor** ya da **platformun sunduÄŸu kurslardan yeni bir ÅŸeyler Ã¶ÄŸreniyor.**

![](im/1001.png)

YÄ±llar boyunca Kaggle, katÄ±lÄ±mcÄ±larÄ±na aÅŸaÄŸÄ±daki gibi **daha pek Ã§ok fÄ±rsat** sunmuÅŸtur:

* **Kendi ÅŸirketlerini kurmak**
* **Makine Ã¶ÄŸrenimi yazÄ±lÄ±mlarÄ± ve paketleri baÅŸlatmak**
* **Dergilerde rÃ¶portajlar yapmak** ([kaynak](https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/))
* **Makine Ã¶ÄŸrenimi kitaplarÄ± yazmak** ([kaynak](https://twitter.com/antgoldbloom/status/745662719588589568))
* **Hayallerindeki iÅŸi bulmak**

Ve en Ã¶nemlisi, **veri bilimi ile ilgili beceriler ve teknik detaylar hakkÄ±nda daha fazla bilgi edinmek**.

#### Other competition platforms *(DiÄŸer yarÄ±ÅŸma platformlarÄ±)*

Bu kitap Kaggleâ€™daki yarÄ±ÅŸmalara odaklansa da, birÃ§ok veri yarÄ±ÅŸmasÄ±nÄ±n Ã¶zel platformlarda veya diÄŸer yarÄ±ÅŸma platformlarÄ±nda dÃ¼zenlendiÄŸini unutmamak gerekir. AslÄ±nda, bu kitapta bulacaÄŸÄ±nÄ±z bilgilerin Ã§oÄŸu diÄŸer yarÄ±ÅŸmalar iÃ§in de geÃ§erlidir; Ã§Ã¼nkÃ¼ temelde hepsi benzer prensiplerle Ã§alÄ±ÅŸÄ±r ve katÄ±lÄ±mcÄ±lara saÄŸladÄ±klarÄ± faydalar da aÅŸaÄŸÄ± yukarÄ± aynÄ±dÄ±r.

BirÃ§ok diÄŸer platform belirli Ã¼lkelere odaklanmÄ±ÅŸ ya da yalnÄ±zca belirli tÃ¼rde yarÄ±ÅŸmalarda uzmanlaÅŸmÄ±ÅŸtÄ±r. Yine de, tamlÄ±k aÃ§Ä±sÄ±ndan, en azÄ±ndan deneyim ve bilgimizin bulunduÄŸu bazÄ±larÄ±nÄ± kÄ±saca tanÄ±tmakta fayda var:

â€¢ **DrivenData** ([https://www.drivendata.org/competitions/](https://www.drivendata.org/competitions/)) sosyal problemlere yÃ¶nelik yarÄ±ÅŸmalar dÃ¼zenleyen bir kitle kaynaklÄ± (crowdsourcing) yarÄ±ÅŸma platformudur (bkz. [https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/](https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/)). Åirketin kendisi, dÃ¼nyanÄ±n en bÃ¼yÃ¼k sorunlarÄ±yla mÃ¼cadele eden kuruluÅŸlara veri bilimi Ã§Ã¶zÃ¼mleri sunmayÄ± amaÃ§layan bir sosyal giriÅŸimdir. Veri bilimciler, sosyal fayda iÃ§in algoritmalar geliÅŸtirir. Ã–rneÄŸin, [https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html](https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html) adresindeki makalede okuyabileceÄŸiniz gibi, Facebook nefret sÃ¶ylemi ve yanlÄ±ÅŸ bilgiyle mÃ¼cadele iÃ§in dÃ¼zenlediÄŸi yarÄ±ÅŸmada DrivenDataâ€™yÄ± seÃ§miÅŸtir.

â€¢ **Numerai** ([https://numer.ai/](https://numer.ai/)) San Francisco merkezli, yapay zekÃ¢ destekli bir kitle kaynaklÄ± hedge fonudur. KatÄ±lÄ±mcÄ±lar her hafta fonun anonimleÅŸtirilmiÅŸ verileri Ã¼zerinde tahmin modelleri gÃ¶nderir ve ÅŸirketin kendi kripto para birimi olan *Numeraire* ile Ã¶dÃ¼ller kazanÄ±rlar.

â€¢ **CrowdANALYTIX** ([https://www.crowdanalytix.com/community](https://www.crowdanalytix.com/community)) artÄ±k eskisi kadar aktif olmasa da, bir sÃ¼re Ã¶nce birÃ§ok zorlu yarÄ±ÅŸmaya ev sahipliÄŸi yapmÄ±ÅŸtÄ±r (bkz. [https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1](https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1)). AyrÄ±ca topluluk blogu, bu platformda ne tÃ¼r zorluklarla karÅŸÄ±laÅŸabileceÄŸinize dair fikir edinmek iÃ§in oldukÃ§a ilginÃ§tir: [https://www.crowdanalytix.com/jq/communityBlog/listBlog.html](https://www.crowdanalytix.com/jq/communityBlog/listBlog.html).

â€¢ **Signate** ([https://signate.jp/competitions](https://signate.jp/competitions)) Japonya merkezli bir veri bilimi yarÄ±ÅŸma platformudur. BirÃ§ok yarÄ±ÅŸmaya ev sahipliÄŸi yapar ve Kaggleâ€™a benzer bir sÄ±ralama sistemi sunar ([https://signate.jp/users/rankings](https://signate.jp/users/rankings)).

â€¢ **Zindi** ([https://zindi.africa/competitions](https://zindi.africa/competitions)) Afrika merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Afrikaâ€™nÄ±n en acil sosyal, ekonomik ve Ã§evresel sorunlarÄ±nÄ± Ã§Ã¶zmeye odaklÄ± yarÄ±ÅŸmalar dÃ¼zenler.

â€¢ **Alibaba Cloud** ([https://www.alibabacloud.com/campaign/tianchi-competitions](https://www.alibabacloud.com/campaign/tianchi-competitions)) Ã‡in merkezli bir bulut biliÅŸim ve yapay zekÃ¢ saÄŸlayÄ±cÄ±sÄ±dÄ±r. SIGKDD, IJCAI-PRICAI ve CVPR gibi akademik konferanslarla ortaklaÅŸa dÃ¼zenlenen *Tianchi Academic* yarÄ±ÅŸmalarÄ±nÄ± baÅŸlatmÄ±ÅŸtÄ±r. GÃ¶rsel tabanlÄ± 3D ÅŸekil tanÄ±ma, 3D nesne yeniden oluÅŸturma ve Ã¶rnek segmentasyonu gibi zorluklar iÃ§eren yarÄ±ÅŸmalar dÃ¼zenler.

â€¢ **Analytics Vidhya** ([https://datahack.analyticsvidhya.com/](https://datahack.analyticsvidhya.com/)) Hindistanâ€™Ä±n en bÃ¼yÃ¼k veri bilimi topluluÄŸudur ve veri bilimi hackathonâ€™larÄ± iÃ§in bir platform sunar.

â€¢ **CodaLab** ([https://codalab.lri.fr/](https://codalab.lri.fr/)) 2013 yÄ±lÄ±nda Microsoft ve Stanford Ãœniversitesiâ€™nin ortak giriÅŸimiyle kurulmuÅŸ, Fransa merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Bilgi paylaÅŸÄ±mÄ± ve yeniden Ã¼retilebilir modelleme iÃ§in **Worksheets** ([https://worksheets.codalab.org/](https://worksheets.codalab.org/)) adlÄ± Ã¼cretsiz bulut tabanlÄ± bir defter sunar.

DiÄŸer daha kÃ¼Ã§Ã¼k platformlar arasÄ±nda Ä°sviÃ§reâ€™deki Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne tarafÄ±ndan geliÅŸtirilen **CrowdAI** ([https://www.crowdai.org/](https://www.crowdai.org/)), **InnoCentive** ([https://www.innocentive.com/](https://www.innocentive.com/)), biyomedikal gÃ¶rÃ¼ntÃ¼leme iÃ§in **Grand-Challenge** ([https://grand-challenge.org/](https://grand-challenge.org/)), **DataFountain** ([https://www.datafountain.cn/business?lang=en-US](https://www.datafountain.cn/business?lang=en-US)), **OpenML** ([https://www.openml.org/](https://www.openml.org/)) gibi platformlar yer alÄ±r. AyrÄ±ca, Rus topluluÄŸu **Open Data Science** ([https://ods.ai/competitions](https://ods.ai/competitions)) sitesinde devam eden bÃ¼yÃ¼k yarÄ±ÅŸmalarÄ±n kapsamlÄ± bir listesini bulabilir ve zaman zaman yeni yarÄ±ÅŸma platformlarÄ±nÄ± keÅŸfedebilirsiniz.

Kaggle, hÃ¢lÃ¢ en ilginÃ§ yarÄ±ÅŸmalarÄ± bulabileceÄŸiniz ve yarÄ±ÅŸma Ã§abalarÄ±nÄ±zla en geniÅŸ tanÄ±nÄ±rlÄ±ÄŸÄ± elde edebileceÄŸiniz en iyi platformdur. Ancak, Kaggle dÄ±ÅŸÄ±ndaki bir yarÄ±ÅŸmayÄ± seÃ§mek de anlamlÄ± olabilir; Ã¶zellikle kiÅŸisel veya profesyonel ilgi alanlarÄ±nÄ±za uyan bir yarÄ±ÅŸma bulduÄŸunuzda. GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, Kaggle dÄ±ÅŸÄ±nda da oldukÃ§a fazla alternatif ve fÄ±rsat mevcut. Bu da, Kaggle ile birlikte diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± da dikkate alarak, ilginizi Ã§ekebilecek Ã¶zel veri veya temalÄ± bir yarÄ±ÅŸma bulma olasÄ±lÄ±ÄŸÄ±nÄ±zÄ± artÄ±rÄ±r.

AyrÄ±ca, bu tÃ¼r platformlarda rekabetin genellikle daha az olduÄŸunu (dolayÄ±sÄ±yla daha iyi bir sÄ±ralama veya Ã¶dÃ¼l kazanma ÅŸansÄ±nÄ±zÄ±n daha yÃ¼ksek olabileceÄŸini) bekleyebilirsiniz; ancak katÄ±lÄ±mcÄ±lar arasÄ±nda bilgi paylaÅŸÄ±mÄ±nÄ±n Kaggleâ€™daki kadar zengin olmadÄ±ÄŸÄ±nÄ± da unutmamalÄ±sÄ±nÄ±z.

### Introducing Kaggle *(Kaggleâ€™a giriÅŸ)*

Bu noktada, Ã¶zellikle **Kaggle**â€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha derinlemesine incelememiz gerekiyor.
AÅŸaÄŸÄ±daki paragraflarda, Kaggle platformunun ve yarÄ±ÅŸmalarÄ±nÄ±n Ã§eÅŸitli yÃ¶nlerini ele alacaÄŸÄ±z ve Kaggleâ€™daki bir yarÄ±ÅŸmada yer almanÄ±n ne anlama geldiÄŸine dair bir fikir edineceksiniz.
Daha sonra, kitabÄ±n geri kalan bÃ¶lÃ¼mlerinde bu konularÄ±n Ã§oÄŸuna Ã§ok daha ayrÄ±ntÄ±lÄ± biÃ§imde geri dÃ¶nerek, ek Ã¶neriler ve stratejilerle birlikte tartÄ±ÅŸacaÄŸÄ±z.

#### Stages of a competition *(Bir yarÄ±ÅŸmanÄ±n aÅŸamalarÄ±)*

Kaggleâ€™daki bir yarÄ±ÅŸma, farklÄ± adÄ±mlardan oluÅŸacak ÅŸekilde dÃ¼zenlenir.
Bu adÄ±mlarÄ±n her birine gÃ¶z atarak, bir veri bilimi yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸini ve sizden neler beklenebileceÄŸini daha iyi anlayabilirsiniz.

Bir yarÄ±ÅŸma baÅŸlatÄ±ldÄ±ÄŸÄ±nda, genellikle sosyal medyada â€” Ã¶rneÄŸin Kaggleâ€™Ä±n Twitter hesabÄ±nda ([https://twitter.com/kaggle](https://twitter.com/kaggle)) â€” yarÄ±ÅŸmayÄ± duyuran paylaÅŸÄ±mlar yapÄ±lÄ±r. AyrÄ±ca, **Competitions** sayfasÄ±nda ([https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)) **Active Competitions** (aktif yarÄ±ÅŸmalar) bÃ¶lÃ¼mÃ¼nde yeni bir sekme gÃ¶rÃ¼nÃ¼r.

Belirli bir yarÄ±ÅŸmanÄ±n sekmesine tÄ±kladÄ±ÄŸÄ±nÄ±zda, o yarÄ±ÅŸmanÄ±n sayfasÄ±na yÃ¶nlendirilirsiniz. Ä°lk bakÄ±ÅŸta, yarÄ±ÅŸmanÄ±n Ã¶dÃ¼l verip vermediÄŸini (ve yarÄ±ÅŸmaya katÄ±lmanÄ±n bir sonucu olarak puan ve madalya kazandÄ±rÄ±p kazandÄ±rmadÄ±ÄŸÄ±nÄ±), ÅŸu anda kaÃ§ takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ±nÄ± ve Ã§Ã¶zÃ¼mÃ¼nÃ¼z Ã¼zerinde Ã§alÄ±ÅŸmak iÃ§in ne kadar sÃ¼reniz kaldÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz.

![](im/1002.png)

Orada, Ã¶ncelikle **Overview (Genel BakÄ±ÅŸ)** menÃ¼sÃ¼nÃ¼ inceleyebilirsiniz. Bu menÃ¼ size ÅŸu konularda bilgi verir:

* YarÄ±ÅŸmanÄ±n konusu
* DeÄŸerlendirme metriÄŸi (modellerinizin deÄŸerlendirileceÄŸi Ã¶lÃ§Ã¼t)
* YarÄ±ÅŸmanÄ±n zaman Ã§izelgesi
* Ã–dÃ¼ller
* Yasal veya yarÄ±ÅŸma gereklilikleri

Genellikle zaman Ã§izelgesi Ã§ok dikkat edilmeyen bir kÄ±sÄ±mdÄ±r, ancak kontrol etmeniz gereken ilk ÅŸeylerden biri olmalÄ±dÄ±r; Ã§Ã¼nkÃ¼ yalnÄ±zca yarÄ±ÅŸmanÄ±n ne zaman baÅŸlayÄ±p biteceÄŸini deÄŸil, aynÄ± zamanda **kural kabul etme son tarihini** de gÃ¶sterir. Bu tarih genellikle yarÄ±ÅŸma kapanmadan **7 ila 14 gÃ¼n Ã¶nce** olur ve yarÄ±ÅŸmaya katÄ±labileceÄŸiniz (kurallarÄ± kabul edebileceÄŸiniz) son gÃ¼nÃ¼ belirtir.

AyrÄ±ca bir **takÄ±m birleÅŸtirme son tarihi (team merger deadline)** de bulunur: Bu tarihten Ã¶nce istediÄŸiniz herhangi bir zamanda ekibinizi baÅŸka bir yarÄ±ÅŸmacÄ±nÄ±n ekibiyle birleÅŸtirebilirsiniz; ancak bu tarihten sonra artÄ±k mÃ¼mkÃ¼n deÄŸildir.

**Rules (Kurallar)** menÃ¼sÃ¼ de sÄ±klÄ±kla gÃ¶z ardÄ± edilir (Ã§oÄŸu kiÅŸi doÄŸrudan **Data** kÄ±smÄ±na geÃ§er), ancak kontrol edilmesi Ã¶nemlidir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n gereklilikleri hakkÄ±nda bilgi verir. Kurallar kÄ±smÄ±ndan edinebileceÄŸiniz Ã¶nemli bilgiler arasÄ±nda ÅŸunlar yer alÄ±r:

* Ã–dÃ¼l almaya uygun olup olmadÄ±ÄŸÄ±nÄ±z
* PuanÄ±nÄ±zÄ± artÄ±rmak iÃ§in harici veri kullanÄ±p kullanamayacaÄŸÄ±nÄ±z
* GÃ¼nde kaÃ§ tane gÃ¶nderim (Ã§Ã¶zÃ¼m testi) yapabileceÄŸiniz
* KaÃ§ tane nihai Ã§Ã¶zÃ¼m seÃ§ebileceÄŸiniz

KurallarÄ± kabul ettikten sonra, **Data** menÃ¼sÃ¼nden verileri indirebilir veya doÄŸrudan **Code** menÃ¼sÃ¼nden Kaggle Notebooks (Ã§evrimiÃ§i, bulut tabanlÄ± defterler) Ã¼zerinde Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz. Burada diÄŸerlerinin paylaÅŸtÄ±ÄŸÄ± kodlarÄ± yeniden kullanabilir veya sÄ±fÄ±rdan kendi kodunuzu oluÅŸturabilirsiniz.

EÄŸer verileri indirmeye karar verirseniz, **Kaggle API**â€™sini de kullanabileceÄŸinizi unutmayÄ±n. Bu API, indirme ve gÃ¶nderim iÅŸlemlerini neredeyse otomatik hale getirmenize yardÄ±mcÄ± olur. Yerel bilgisayarÄ±nÄ±zda veya bulut sunucunuzda modellerinizi Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z, bu araÃ§ oldukÃ§a faydalÄ±dÄ±r. API hakkÄ±nda daha fazla bilgiyi ÅŸu adreste bulabilirsiniz:
ğŸ‘‰ [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)
Kaynak koduna ise GitHub Ã¼zerinden ulaÅŸabilirsiniz:
ğŸ‘‰ [https://github.com/Kaggle/kaggle-api](https://github.com/Kaggle/kaggle-api)

Kaggleâ€™Ä±n GitHub deposunu daha yakÄ±ndan incelerseniz, **Kaggle Notebooks** (Ã§evrimiÃ§i defterler) iÃ§in kullanÄ±lan tÃ¼m **Docker imajlarÄ±nÄ±** da bulabilirsiniz.

![](im/1003.png)

Bu noktada, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirirken **tek baÅŸÄ±nÄ±za devam etmemenizi**, diÄŸer yarÄ±ÅŸmacÄ±larla **Discussion (TartÄ±ÅŸma)** forumu Ã¼zerinden iletiÅŸime geÃ§menizi iÃ§tenlikle tavsiye ederiz. Bu forumda yarÄ±ÅŸmaya Ã¶zgÃ¼ sorular sorabilir ve diÄŸer katÄ±lÄ±mcÄ±larÄ±n sorularÄ±nÄ± yanÄ±tlayabilirsiniz.
Ã‡oÄŸu zaman burada, veriyle ilgili belirli problemlere dair faydalÄ± ipuÃ§larÄ± veya kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirmeye yardÄ±mcÄ± olabilecek fikirler bulabilirsiniz.
BirÃ§ok baÅŸarÄ±lÄ± Kaggle kullanÄ±cÄ±sÄ± (*Kaggler*), forumlarda edindikleri fikirlerin kendilerine daha iyi performans saÄŸladÄ±ÄŸÄ±nÄ± ve daha da Ã¶nemlisi, veri bilimi modelleme konusunda Ã§ok ÅŸey Ã¶ÄŸrenmelerine yardÄ±mcÄ± olduÄŸunu belirtmiÅŸtir.

Ã‡Ã¶zÃ¼mÃ¼nÃ¼z hazÄ±r olduÄŸunda, yarÄ±ÅŸmanÄ±n yÃ¶nergelerine uygun ÅŸekilde **Kaggle deÄŸerlendirme sistemine** gÃ¶nderebilirsiniz.
BazÄ± yarÄ±ÅŸmalar Ã§Ã¶zÃ¼mleri **CSV dosyasÄ±** olarak kabul ederken, bazÄ±larÄ± **Kaggle Notebook** Ã¼zerinde kod yazmanÄ±zÄ± ve sonuÃ§larÄ± orada Ã¼retmenizi ister.
YarÄ±ÅŸma sÃ¼resince Ã§Ã¶zÃ¼m gÃ¶ndermeye devam edebilirsiniz.

Her gÃ¶nderim yaptÄ±ÄŸÄ±nÄ±zda, kÄ±sa bir sÃ¼re sonra **liderlik tablosu (leaderboard)** size bir puan ve yarÄ±ÅŸmacÄ±lar arasÄ±ndaki konumunuzu gÃ¶sterecektir (bekleme sÃ¼resi, puan hesaplamasÄ± iÃ§in gereken iÅŸlem sÃ¼resine baÄŸlÄ± olarak deÄŸiÅŸir).
Ancak bu sÄ±ralama yalnÄ±zca yaklaÅŸÄ±k bir gÃ¶stergedir; Ã§Ã¼nkÃ¼ modelinizin performansÄ±nÄ±, test verisinin yalnÄ±zca bir kÄ±smÄ± olan **public test set (genel test kÃ¼mesi)** Ã¼zerinde yansÄ±tÄ±r. Bu kÃ¼medeki sonuÃ§lar yarÄ±ÅŸma boyunca herkesin gÃ¶rebileceÄŸi ÅŸekilde paylaÅŸÄ±lÄ±r.

YarÄ±ÅŸma kapanmadan Ã¶nce, her yarÄ±ÅŸmacÄ± **nihai deÄŸerlendirme** iÃ§in kendi Ã§Ã¶zÃ¼mleri arasÄ±ndan belirli bir sayÄ±da (genellikle iki) Ã§Ã¶zÃ¼m seÃ§ebilir.

![](im/1004.png)

YarÄ±ÅŸma ancak kapandÄ±ktan sonra, yarÄ±ÅŸmacÄ±larÄ±n deÄŸerlendirilmesini istedikleri modeller temel alÄ±narak, **test veri setinin baÅŸka bir kÄ±smÄ±** olan **private test set (Ã¶zel test kÃ¼mesi)** Ã¼zerindeki puanlarÄ± aÃ§Ä±klanÄ±r.
Bu yeni sÄ±ralama tablosu **private leaderboard (Ã¶zel liderlik tablosu)** olarak adlandÄ±rÄ±lÄ±r ve yarÄ±ÅŸmanÄ±n **nihai, gerÃ§ek puanlarÄ±nÄ±** gÃ¶sterir; ancak bu sÄ±ralama henÃ¼z **resmÃ® ve kesin** deÄŸildir.

GerÃ§ekte, Kaggle ekibi her ÅŸeyin doÄŸru olduÄŸunu ve tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n yarÄ±ÅŸma kurallarÄ±na uyduÄŸunu kontrol etmek iÃ§in bir sÃ¼re ayÄ±rÄ±r.
Bir sÃ¼re sonra (ve bazen bazÄ± yarÄ±ÅŸmacÄ±larÄ±n diskalifiye edilmesine baÄŸlÄ± olarak sÄ±ralamalarda deÄŸiÅŸiklikler olduktan sonra), **private leaderboard** resmÃ® ve kesin hale gelir.
Kazananlar aÃ§Ä±klanÄ±r ve birÃ§ok katÄ±lÄ±mcÄ±, yarÄ±ÅŸma tartÄ±ÅŸma forumunda kendi stratejilerini, Ã§Ã¶zÃ¼mlerini ve kodlarÄ±nÄ± paylaÅŸÄ±r.

Bu noktada, diÄŸer katÄ±lÄ±mcÄ±larÄ±n Ã§Ã¶zÃ¼mlerini incelemek ve kendi yaklaÅŸÄ±mÄ±nÄ±zÄ± geliÅŸtirmeye Ã§alÄ±ÅŸmak tamamen size kalmÄ±ÅŸtÄ±r.
Bunu yapmanÄ±zÄ± **ÅŸiddetle tavsiye ederiz**, Ã§Ã¼nkÃ¼ bu sÃ¼reÃ§ Kaggleâ€™daki en Ã¶nemli Ã¶ÄŸrenme kaynaklarÄ±ndan bir diÄŸeridir.

#### Types of competitions and examples *(YarÄ±ÅŸma tÃ¼rleri ve Ã¶rnekleri)*

Kaggle yarÄ±ÅŸmalarÄ±, **yarÄ±ÅŸma kategorilerine** gÃ¶re sÄ±nÄ±flandÄ±rÄ±lÄ±r ve her kategori, yarÄ±ÅŸma biÃ§imi ve beklentiler aÃ§Ä±sÄ±ndan farklÄ±lÄ±k gÃ¶sterir.
Veri tÃ¼rÃ¼, problem zorluÄŸu, verilen Ã¶dÃ¼ller ve yarÄ±ÅŸma dinamikleri bu kategoriler iÃ§inde oldukÃ§a Ã§eÅŸitlidir; bu nedenle her kategorinin ne anlama geldiÄŸini Ã¶nceden anlamak Ã¶nemlidir.

Kaggleâ€™daki yarÄ±ÅŸmalarÄ± filtrelemek iÃ§in kullanabileceÄŸiniz **resmÃ® kategoriler** ÅŸunlardÄ±r:

* **Featured**
* **Masters**
* **Annuals**
* **Research**
* **Recruitment**
* **Getting Started**
* **Playground**
* **Analytics**
* **Community**

---

> ğŸ† Featured (Ã–ne Ã‡Ä±kan) YarÄ±ÅŸmalar

Bunlar en yaygÄ±n yarÄ±ÅŸma tÃ¼rÃ¼dÃ¼r. Genellikle sponsor bir ÅŸirketin iÅŸ ile ilgili bir problemini iÃ§erir ve en iyi performans gÃ¶sterenlere Ã¶dÃ¼l verilir.
Kazananlar, Ã§Ã¶zÃ¼mlerinin **lisanssÄ±z (non-exclusive)** kullanÄ±m hakkÄ±nÄ± sponsor ÅŸirkete verirler; ayrÄ±ca ayrÄ±ntÄ±lÄ± bir rapor hazÄ±rlamalarÄ± ve bazen sponsor ÅŸirketle toplantÄ±lara katÄ±lmalarÄ± gerekebilir.

Kaggleâ€™da neredeyse her zaman Featured yarÄ±ÅŸmalara rastlayabilirsiniz. GÃ¼nÃ¼mÃ¼zde Ã§oÄŸu, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veriler** (metin, gÃ¶rÃ¼ntÃ¼, video, ses gibi) Ã¼zerinde derin Ã¶ÄŸrenme yÃ¶ntemlerinin uygulanmasÄ±na yÃ¶neliktir.
GeÃ§miÅŸte ise daha Ã§ok **tablo biÃ§iminde veriler (tabular data)** Ã¼zerine kurulu yarÄ±ÅŸmalar yapÄ±lÄ±rdÄ± â€” yani veritabanlarÄ±nda bulunan yapÄ±landÄ±rÄ±lmÄ±ÅŸ veriler Ã¼zerinde Ã§alÄ±ÅŸan problemlerdi.
Ä°lk zamanlarda rastgele ormanlar (random forests), daha sonra ise akÄ±llÄ± Ã¶zellik mÃ¼hendisliÄŸiyle birlikte **gradient boosting** yÃ¶ntemleri Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar vermiÅŸtir.
Ancak gÃ¼nÃ¼mÃ¼zde, geliÅŸmiÅŸ yazÄ±lÄ±mlar ve **AutoML** araÃ§larÄ± sayesinde bu tÃ¼r problemlerde yarÄ±ÅŸmalardan elde edilen geliÅŸmeler genellikle marjinaldir.
Buna karÅŸÄ±lÄ±k, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veri** dÃ¼nyasÄ±nda iyi bir derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mÃ¼ hÃ¢lÃ¢ bÃ¼yÃ¼k fark yaratabilir.
Ã–rneÄŸin, **BERT** gibi Ã¶nceden eÄŸitilmiÅŸ aÄŸlar, birÃ§ok NLP gÃ¶revinde Ã¶nceki standartlara gÃ¶re Ã§ift haneli performans artÄ±ÅŸlarÄ± saÄŸlamÄ±ÅŸtÄ±r.

---

> ğŸ§  Masters (Ustalar) YarÄ±ÅŸmalarÄ±

ArtÄ±k daha az dÃ¼zenlenmektedir, ancak bunlar **Ã¶zel (invite-only)** yarÄ±ÅŸmalardÄ±r.
AmaÃ§, yalnÄ±zca uzmanlar (genellikle Kaggle sÄ±ralamasÄ±nda **Master** veya **Grandmaster** unvanÄ±na sahip yarÄ±ÅŸmacÄ±lar) iÃ§in yarÄ±ÅŸmalar dÃ¼zenlemektir.

---

> ğŸ“… Annuals (YÄ±llÄ±k) YarÄ±ÅŸmalar

Her yÄ±l belirli dÃ¶nemlerde dÃ¼zenlenen yarÄ±ÅŸmalardÄ±r.
Bunlar arasÄ±nda:

* **Santa Claus Competitions** (genellikle algoritmik optimizasyon problemleri Ã¼zerine),
* **March Machine Learning Mania** (2014â€™ten beri her yÄ±l ABD Kolej Basketbol TurnuvalarÄ± sÄ±rasÄ±nda dÃ¼zenlenir) bulunur.

---

> ğŸ”¬ Research (AraÅŸtÄ±rma) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarÄ±n amacÄ± ticari deÄŸil, **bilimsel veya araÅŸtÄ±rma odaklÄ±dÄ±r**, bazen de kamu yararÄ±na hizmet eder.
Bu nedenle genellikle para Ã¶dÃ¼lÃ¼ sunmazlar.
AyrÄ±ca kazananlardan Ã§Ã¶zÃ¼mlerini **aÃ§Ä±k kaynak (open-source)** olarak paylaÅŸmalarÄ± istenebilir.

Ã–rneÄŸin, **Google Landmark Recognition 2020** ([https://www.kaggle.com/c/landmark-recognition-2020](https://www.kaggle.com/c/landmark-recognition-2020)) yarÄ±ÅŸmasÄ±nda, Ã¼nlÃ¼ (veya pek tanÄ±nmamÄ±ÅŸ) yapÄ±tlarÄ±n fotoÄŸraflarÄ±nÄ± tanÄ±mlamak hedeflenmiÅŸtir.

---

> ğŸ’¼ Recruitment (Ä°ÅŸe AlÄ±m) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar, sponsor ÅŸirketlerin **potansiyel iÅŸ adaylarÄ±nÄ±n yeteneklerini test etmek** iÃ§in dÃ¼zenlenir.
Genellikle tek kiÅŸilik takÄ±mlarla sÄ±nÄ±rlÄ±dÄ±r ve en iyi performans gÃ¶steren yarÄ±ÅŸmacÄ±lara **iÅŸ gÃ¶rÃ¼ÅŸmesi** Ã¶dÃ¼lÃ¼ sunulur.
YarÄ±ÅŸma sonunda, deÄŸerlendirilmek isteyen yarÄ±ÅŸmacÄ±larÄ±n **Ã¶zgeÃ§miÅŸlerini (CV)** yÃ¼klemeleri gerekir.

Ã–rnekler:

* **Facebook Recruiting Competition** ([https://www.kaggle.com/c/FacebookRecruiting](https://www.kaggle.com/c/FacebookRecruiting))
* **Yelp Recruiting Competition** ([https://www.kaggle.com/c/yelp-recruiting](https://www.kaggle.com/c/yelp-recruiting))

---

> ğŸš€ Getting Started (BaÅŸlangÄ±Ã§) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar Ã¶dÃ¼l sunmaz, ancak **yeni baÅŸlayanlarÄ±n** Kaggle prensiplerine ve dinamiklerine alÄ±ÅŸmalarÄ± iÃ§in **kolay ve Ã¶ÄŸretici problemler** iÃ§erir.
Genellikle **yarÄ± kalÄ±cÄ±dÄ±rlar** ve liderlik tablolarÄ± zaman zaman yenilenir.
Makine Ã¶ÄŸrenmesine giriÅŸ yapmak istiyorsanÄ±z, bu yarÄ±ÅŸmalar mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r; Ã§Ã¼nkÃ¼ oldukÃ§a **iÅŸbirlikÃ§i bir ortam** sunarlar ve veri iÅŸleme ile model oluÅŸturma adÄ±mlarÄ±nÄ± gÃ¶steren birÃ§ok **Kaggle Notebook** mevcuttur.

BazÄ± Ã¼nlÃ¼ Getting Started yarÄ±ÅŸmalarÄ±:

* [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer)
* [Titanic â€” Machine Learning from Disaster](https://www.kaggle.com/c/titanic)
* [House Prices â€” Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

---

> ğŸ® Playground (Oyun AlanÄ±) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar **Getting Started** yarÄ±ÅŸmalarÄ±ndan biraz daha zordur, ancak hÃ¢lÃ¢ Ã¶ÄŸrenme ve pratik yapma odaklÄ±dÄ±r.
Tam Ã¶lÃ§ekli Featured yarÄ±ÅŸmalar kadar baskÄ± oluÅŸturmazlar, fakat bazen rekabet oldukÃ§a kÄ±zÄ±ÅŸabilir.
Ã–dÃ¼ller genellikle **Kaggle logolu hediyelikler (swag: kupa, tiÅŸÃ¶rt, Ã§orap vb.)** veya kÃ¼Ã§Ã¼k miktarlarda paradÄ±r.

ÃœnlÃ¼ bir Playground yarÄ±ÅŸmasÄ± Ã¶rneÄŸi:

* [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats) â€” kÃ¶pekleri ve kedileri ayÄ±rt eden bir algoritma geliÅŸtirme gÃ¶revi.

---

> ğŸ“Š Analytics (Analiz) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarda deÄŸerlendirme **niteliksel (qualitative)** olup, katÄ±lÄ±mcÄ±lardan fikirler, Ã§Ã¶zÃ¼m taslaklarÄ±, PowerPoint sunumlarÄ±, grafikler vb. hazÄ±rlamalarÄ± beklenir.

---

> ğŸ‘¥ Community (Topluluk) YarÄ±ÅŸmalarÄ±

Eskiden **InClass** olarak bilinen bu yarÄ±ÅŸmalar, **akademik kurumlar** veya bireysel **Kagglerâ€™lar** tarafÄ±ndan dÃ¼zenlenir.
Topluluk yarÄ±ÅŸmalarÄ±nÄ±n duyurusu iÃ§in:
ğŸ”— [https://www.kaggle.com/product-feedback/294337](https://www.kaggle.com/product-feedback/294337)
Kendi yarÄ±ÅŸmanÄ±zÄ± dÃ¼zenleme rehberleri iÃ§in:
ğŸ”— [https://www.kaggle.com/c/about/host](https://www.kaggle.com/c/about/host)
ğŸ”— [https://www.kaggle.com/community-competitions-setup-guide](https://www.kaggle.com/community-competitions-setup-guide)


> **Parul Pandey**
> 
> [https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey)
> 
> 
> 
> Kaggle Notebooks Grandmasterâ€™Ä±, Datasets Masterâ€™Ä± ve H2O.aiâ€™de veri bilimci olan **Parul Pandey** ile analitik yarÄ±ÅŸmalar ve deneyimleri hakkÄ±nda konuÅŸtuk.
> 
> ---
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±n nedir?**
> 
> Veri analizi yapmanÄ±zÄ± ve sonunda kapsamlÄ± bir analiz raporu sunmanÄ±zÄ± gerektiren **Veri AnalitiÄŸi yarÄ±ÅŸmalarÄ±nÄ±** gerÃ§ekten Ã§ok seviyorum. Bunlara *Data Science for Good* (DS4G) yarÄ±ÅŸmalarÄ±, spor analitiÄŸi yarÄ±ÅŸmalarÄ± (Ã¶rneÄŸin NFL) ve genel anket temelli yarÄ±ÅŸmalar dÃ¢hildir. Geleneksel yarÄ±ÅŸmalardan farklÄ± olarak, bu tÃ¼r yarÄ±ÅŸmalarda performansÄ±nÄ±zÄ± baÅŸkalarÄ±yla kÄ±yaslayabileceÄŸiniz bir **liderlik tablosu (leaderboard)** bulunmaz; ayrÄ±ca madalya veya puan da kazanmazsÄ±nÄ±z.
> 
> Ã–te yandan bu yarÄ±ÅŸmalar, veri biliminin Ã§ok yÃ¶nlÃ¼ alanlarÄ±na â€“ veri temizleme, veri madenciliÄŸi, gÃ¶rselleÅŸtirme ve iÃ§gÃ¶rÃ¼ iletimi gibi â€“ dokunan uÃ§tan uca Ã§Ã¶zÃ¼mler gerektirir. Bu tÃ¼r problemler, gerÃ§ek hayattaki senaryolarÄ± taklit etmenizi ve kendi iÃ§gÃ¶rÃ¼nÃ¼zÃ¼, bakÄ±ÅŸ aÃ§Ä±nÄ±zÄ± sunmanÄ±zÄ± saÄŸlar. Tek bir â€œen iyiâ€ Ã§Ã¶zÃ¼m olmayabilir, ancak bu size Ã§eÅŸitli yaklaÅŸÄ±mlarÄ± tartÄ±p deÄŸerlendirerek kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼ze entegre etme fÄ±rsatÄ± verir.
> 
> ---
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinden ne kadar farklÄ±?**
> 
> Ä°lk adÄ±mÄ±m her zaman **EDA (keÅŸifsel veri analizi)** yapmaktÄ±r. Bu, iÅŸ rutinimin de bir parÃ§asÄ±dÄ±r. Genellikle verideki tutarsÄ±zlÄ±klarÄ±, eksik deÄŸerleri, aykÄ±rÄ± noktalarÄ± vb. belirlemek iÃ§in veriyi incelerim; Ã§Ã¼nkÃ¼ bunlar ileride sorun yaratabilir. Sonra **iyi ve gÃ¼venilir bir Ã§apraz doÄŸrulama stratejisi** oluÅŸtururum. ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±nÄ± okur ve diÄŸer kullanÄ±cÄ±larÄ±n paylaÅŸtÄ±ÄŸÄ± Notebookâ€™lara gÃ¶z atarÄ±m. Bu genelde iyi bir baÅŸlangÄ±Ã§ noktasÄ± olur; sonra Ã¶nceki deneyimlerimden edindiÄŸim ÅŸeyleri bu sÃ¼rece eklerim. AyrÄ±ca **model performansÄ±nÄ± izlemek** de Ã§ok Ã¶nemlidir.
> 
> Analitik yarÄ±ÅŸmalar sÃ¶z konusu olduÄŸunda ise problemi genellikle birkaÃ§ adÄ±ma ayÄ±rmayÄ± severim. Ã–rneÄŸin, ilk kÄ±sÄ±m problemi anlamakla ilgilidir ve bu birkaÃ§ gÃ¼n sÃ¼rebilir. SonrasÄ±nda veriyi keÅŸfederim, ardÄ±ndan temel bir baÅŸlangÄ±Ã§ Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururum. Daha sonra bu Ã§Ã¶zÃ¼mÃ¼, her seferinde bir parÃ§a ekleyerek geliÅŸtiririm. Bu, Lego parÃ§alarÄ±nÄ± tek tek ekleyerek son eseri oluÅŸturmak gibidir.
> 
> ---
> 
> **KatÄ±ldÄ±ÄŸÄ±n zorlu bir yarÄ±ÅŸmadan ve bu gÃ¶revi nasÄ±l ele aldÄ±ÄŸÄ±ndan bahseder misin?**
> 
> Daha Ã¶nce de belirttiÄŸim gibi genellikle Analitik yarÄ±ÅŸmalara katÄ±lmayÄ± tercih ediyorum, ama bazen klasik yarÄ±ÅŸmalarda da ÅŸansÄ±mÄ± deniyorum. Ã–zellikle **Environmental Insights Explorer** adlÄ± *Data Science for Good* yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/ds4g-environmental-insightsexplorer](https://www.kaggle.com/c/ds4g-environmental-insightsexplorer)) Ã§ok ilgimi Ã§ekmiÅŸti. GÃ¶rev, mevcut metodolojilerdeki emisyon katsayÄ±larÄ±nÄ± hesaplamak yerine, **uzaktan algÄ±lama (remote sensing)** tekniklerini kullanarak Ã§evresel emisyonlarÄ± anlamaktÄ±.
> 
> Beni en Ã§ok etkileyen ÅŸey, bu yarÄ±ÅŸmanÄ±n ele aldÄ±ÄŸÄ± konuydu. Gezegenimiz iklim deÄŸiÅŸikliÄŸiyle mÃ¼cadele ediyor ve bu yarÄ±ÅŸma tam da bu konuya odaklanmÄ±ÅŸtÄ±. YarÄ±ÅŸma iÃ§in araÅŸtÄ±rma yaparken, **uydu gÃ¶rÃ¼ntÃ¼leme teknolojilerindeki ilerlemeyi** gÃ¶rÃ¼nce hayran kaldÄ±m. Bu sayede bu konuyu daha derinlemesine anlama fÄ±rsatÄ± buldum. Landsat, Modis ve Sentinel gibi uydularÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve bu verilerin nasÄ±l eriÅŸilebilir hale getirildiÄŸini Ã¶ÄŸrendim. Bu yarÄ±ÅŸma, Ã¶nceden Ã§ok az bilgim olan bir alan hakkÄ±nda bilgi edinmemi saÄŸlayan harika bir deneyimdi.
> 
> ---
> 
> **YarÄ±ÅŸma biÃ§imleri Ã¼zerine**
> 
> Kaggle yarÄ±ÅŸmalarÄ±nÄ±n kendi iÃ§inde farklÄ± biÃ§imleri de vardÄ±r. En yaygÄ±n olanÄ±, katÄ±lÄ±mcÄ±nÄ±n Ã§Ã¶zÃ¼mÃ¼nÃ¼ sunup deÄŸerlendirildiÄŸi **â€œbasit formatâ€tÄ±r.** Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸmalarda**, yarÄ±ÅŸma ikiye ayrÄ±lÄ±r: Ä°lk kÄ±sÄ±m tamamlandÄ±ktan sonra ikinci kÄ±sma Ã¶zel bir veri seti yalnÄ±zca ilk kÄ±sÄ±m katÄ±lÄ±mcÄ±larÄ±na verilir. Bu format, yarÄ±ÅŸmacÄ±larÄ±n hile yapma ihtimalini azaltmak iÃ§in tasarlanmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼reliÄŸine eriÅŸilebilen, daha Ã¶nce hiÃ§ gÃ¶rÃ¼lmemiÅŸ bir test setinde yapÄ±lÄ±r. Bu nedenle katÄ±lÄ±mcÄ±larÄ±n deneme sayÄ±sÄ± ve zamanÄ± daha sÄ±nÄ±rlÄ±dÄ±r.
> 
> ---
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nda bilmek isteyeceÄŸin ÅŸey ne olurdu?**
> 
> Kaggleâ€™daki ilk yÄ±llarÄ±mda yaptÄ±ÄŸÄ±m bazÄ± hatalardan bahsedebilirim.
> 
> Ã–ncelikle, Ã§oÄŸu yeni baÅŸlayan **Kaggleâ€™Ä± sadece yarÄ±ÅŸma platformu** olarak gÃ¶rÃ¼r. EÄŸer yarÄ±ÅŸmalarÄ± seviyorsanÄ±z, burada fazlasÄ±yla var; ama Kaggle aynÄ± zamanda baÅŸka alanlarda da katkÄ± yapabileceÄŸiniz bir platformdur. Kod yazabilir, baÅŸkalarÄ±yla paylaÅŸabilir, saÄŸlÄ±klÄ± tartÄ±ÅŸmalara katÄ±labilir ve aÄŸÄ±nÄ±zÄ± geniÅŸletebilirsiniz. Toplulukla kaliteli veri setleri oluÅŸturup paylaÅŸabilirsiniz. BaÅŸlangÄ±Ã§ta Kaggleâ€™Ä± yalnÄ±zca veri seti indirmek iÃ§in kullanÄ±yordum; ancak birkaÃ§ yÄ±l Ã¶nce aktif oldum. Geriye dÃ¶nÃ¼p baktÄ±ÄŸÄ±mda, daha Ã¶nce ne kadar yanÄ±ldÄ±ÄŸÄ±mÄ± gÃ¶rÃ¼yorum.
> 
> BirÃ§ok kiÅŸi yarÄ±ÅŸmalardan Ã§ekiniyor. Ã–nce platforma alÄ±ÅŸÄ±p, sonra yavaÅŸ yavaÅŸ yarÄ±ÅŸmalara katÄ±labilirsiniz.
> 
> AyrÄ±ca birÃ§ok kiÅŸi **tek baÅŸÄ±na Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in motivasyonunu kaybedip bÄ±rakÄ±yor.** Kaggleâ€™da takÄ±m kurmanÄ±n birÃ§ok gÃ¶rÃ¼nmeyen avantajÄ± var. TakÄ±m Ã§alÄ±ÅŸmasÄ± Ã¶ÄŸrenmenizi, deneyim paylaÅŸmanÄ±zÄ± ve sÄ±nÄ±rlÄ± bir zaman diliminde ortak bir hedefe ulaÅŸmayÄ± Ã¶ÄŸretir.
> 
> ---
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± da kullanÄ±yor musun? Bunlar Kaggle ile nasÄ±l kÄ±yaslanÄ±r?**
> 
> Åu anda zamanÄ±mÄ±n Ã§oÄŸunu Kaggleâ€™a ayÄ±rÄ±yorum, ancak geÃ§miÅŸte **Zindi** adlÄ± platformu da kullandÄ±m. Zindi, Afrika odaklÄ± veri bilimi yarÄ±ÅŸmalarÄ±na yoÄŸunlaÅŸan bir platform. Afrikaâ€™ya Ã¶zel veri setlerine eriÅŸmek iÃ§in harika bir yer.
> 
> Kaggle Ã§ok yÃ¶nlÃ¼ bir platform olsa da, dÃ¼nyanÄ±n farklÄ± bÃ¶lgelerinden gelen problem ifadeleri konusunda eksiklikler var. Son zamanlarda bu Ã§eÅŸitlilik artmaya baÅŸladÄ±; Ã¶rneÄŸin **chaii yarÄ±ÅŸmasÄ±** â€“ Hint dillerine odaklanan bir NLP yarÄ±ÅŸmasÄ± â€“ buna iyi bir Ã¶rnektir. Benzer ÅŸekilde, farklÄ± Ã¼lkelere odaklanan yarÄ±ÅŸmalarÄ±n da hem araÅŸtÄ±rma hem de genel veri bilimi topluluÄŸu iÃ§in faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.

Kaggle yarÄ±ÅŸmalarÄ±nÄ±n bu sÄ±nÄ±flandÄ±rmasÄ±nÄ±n Ã¶tesinde, yarÄ±ÅŸmalarÄ±n farklÄ± **formatlarda** dÃ¼zenlenebileceÄŸini de dikkate almak gerekir.
En yaygÄ±n format, daha Ã¶nce aÃ§Ä±klandÄ±ÄŸÄ± gibi, bir Ã§Ã¶zÃ¼m sunduÄŸunuz ve bu Ã§Ã¶zÃ¼mÃ¼n deÄŸerlendirildiÄŸi **â€œbasit (simple)â€ formattÄ±r.**
Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸma (two-stage competition)** formatÄ±nda ise yarÄ±ÅŸma iki bÃ¶lÃ¼me ayrÄ±lÄ±r. Son veri seti yalnÄ±zca ilk bÃ¶lÃ¼m tamamlandÄ±ktan sonra ve sadece bu ilk bÃ¶lÃ¼me katÄ±lan yarÄ±ÅŸmacÄ±lara sunulur.
Bu iki aÅŸamalÄ± yarÄ±ÅŸma formatÄ±, bazÄ± yarÄ±ÅŸmacÄ±larÄ±n **hile yapma veya kurallarÄ± ihlal etme olasÄ±lÄ±ÄŸÄ±nÄ± azaltmak** amacÄ±yla ortaya Ã§Ä±kmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼re iÃ§in eriÅŸilebilen ve daha Ã¶nce hiÃ§ test edilmemiÅŸ bir test seti Ã¼zerinde yapÄ±lÄ±r.
Orijinal Kaggle yarÄ±ÅŸma formatÄ±nÄ±n aksine, bu durumda yarÄ±ÅŸmacÄ±larÄ±n **Ã§ok daha az zamanÄ±** ve test setindeki Ã¶rÃ¼ntÃ¼leri (pattern) keÅŸfetmek iÃ§in **Ã§ok daha az sayÄ±da gÃ¶nderim hakkÄ±** vardÄ±r.

AynÄ± nedenle, son zamanlarda **Code yarÄ±ÅŸmalarÄ±** da ortaya Ã§Ä±kmÄ±ÅŸtÄ±r.
Bu yarÄ±ÅŸmalarda tÃ¼m gÃ¶nderimler doÄŸrudan bir **Kaggle Notebook** Ã¼zerinden yapÄ±lÄ±r ve herhangi bir dÄ±ÅŸ dosya yÃ¼kleme seÃ§eneÄŸi devre dÄ±ÅŸÄ± bÄ±rakÄ±lmÄ±ÅŸtÄ±r.

Kaggle yarÄ±ÅŸma kariyerlerinin farklÄ± aÅŸamalarÄ±nda olan kullanÄ±cÄ±larÄ±n her tÃ¼r yarÄ±ÅŸmaya katÄ±lmasÄ±nda hiÃ§bir kÄ±sÄ±tlama yoktur.
Ancak, **veri bilimi konusundaki deneyim dÃ¼zeyinize** ve **hesaplama kaynaklarÄ±nÄ±za** baÄŸlÄ± olarak, belirli yarÄ±ÅŸma tÃ¼rleri veya formatlarÄ± lehine veya aleyhine bazÄ± Ã¶nerilerimiz vardÄ±r:

* **Tamamen yeni baÅŸlayanlar** iÃ§in, *Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± iyi bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r.
  Bu yarÄ±ÅŸmalar, yÃ¼ksek rekabet baskÄ±sÄ± olmadan Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmenizi saÄŸlar.
  Bununla birlikte, birÃ§ok yeni baÅŸlayan da *Featured* veya *Research* yarÄ±ÅŸmalarÄ±ndan baÅŸlamÄ±ÅŸ ve rekabet baskÄ±sÄ±nÄ±n altÄ±nda daha hÄ±zlÄ± Ã¶ÄŸrendiklerini fark etmiÅŸtir.
  Bu nedenle Ã¶nerimiz, **Ã¶ÄŸrenme tarzÄ±nÄ±za gÃ¶re karar vermenizdir:**

  * BazÄ± Kaggle kullanÄ±cÄ±larÄ± keÅŸfederek ve iÅŸ birliÄŸi yaparak Ã¶ÄŸrenir (*Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± bu kiÅŸiler iÃ§in idealdir).
  * DiÄŸerleri ise hÄ±zlÄ± tempolu bir yarÄ±ÅŸmanÄ±n rekabet ortamÄ±nda motive olur.

* *Featured* ve *Research* yarÄ±ÅŸmalarÄ±nda ise ÅŸunu da gÃ¶z Ã¶nÃ¼nde bulundurmak gerekir:
  Bu yarÄ±ÅŸmalar genellikle yapay zekÃ¢ ve makine Ã¶ÄŸrenmesinin **uÃ§ (deneysel) uygulamalarÄ±yla** ilgilidir.
  DolayÄ±sÄ±yla bu yarÄ±ÅŸmalarda baÅŸarÄ±lÄ± olabilmek iÃ§in ya bu alanda **saÄŸlam bir altyapÄ±ya sahip olmanÄ±z** ya da yarÄ±ÅŸmanÄ±n uygulama alanÄ±yla ilgili araÅŸtÄ±rmalarÄ± Ã¶ÄŸrenmeye istekli olmanÄ±z gerekir.

Son olarak, Ã§oÄŸu yarÄ±ÅŸmanÄ±n, birÃ§ok veri bilimcisinin iÅŸ yerinde eriÅŸemediÄŸi **hesaplama kaynaklarÄ±na** ihtiyaÃ§ duyduÄŸunu unutmayÄ±n.
Kaggle dÄ±ÅŸÄ±ndaki bulut platformlarÄ±nÄ± kullanÄ±rsanÄ±z bu, **artan maliyetlere** yol aÃ§abilir.
Bu nedenle, **Code yarÄ±ÅŸmalarÄ±** veya **zaman ve kaynak sÄ±nÄ±rlamalarÄ± olan yarÄ±ÅŸmalar**, tÃ¼m katÄ±lÄ±mcÄ±larÄ± aynÄ± kaynak dÃ¼zeyine getirmeyi amaÃ§ladÄ±klarÄ± iÃ§in Ã§abalarÄ±nÄ±zÄ± yoÄŸunlaÅŸtÄ±rmak aÃ§Ä±sÄ±ndan ideal bir seÃ§enek olabilir.

#### Submission and leaderboard dynamics *(GÃ¶nderim ve liderlik tablosu dinamikleri)*

Kaggleâ€™Ä±n Ã§alÄ±ÅŸma biÃ§imi basit gÃ¶rÃ¼nebilir: Test seti katÄ±lÄ±mcÄ±lardan gizlenir; modelinizi eÄŸitirsiniz; eÄŸer modeliniz test setindeki sonuÃ§larÄ± en iyi ÅŸekilde tahmin ederse yÃ¼ksek puan alÄ±r ve muhtemelen kazanÄ±rsÄ±nÄ±z.
Ne yazÄ±k ki, bu tanÄ±m Kaggle yarÄ±ÅŸmalarÄ±nÄ±n iÃ§ iÅŸleyiÅŸini **fazla basitleÅŸtirilmiÅŸ** bir ÅŸekilde aÃ§Ä±klar.
Bu aÃ§Ä±klama, yarÄ±ÅŸmacÄ±larÄ±n doÄŸrudan ve dolaylÄ± etkileÅŸimleriyle ilgili dinamikleri ya da karÅŸÄ± karÅŸÄ±ya olduÄŸunuz problemin, eÄŸitim ve test setinin **ince ayrÄ±ntÄ±larÄ±nÄ± (nÃ¼anslarÄ±nÄ±)** dikkate almaz.

##### Explaining the Common Task Framework paradigm *(Ortak GÃ¶rev Ã‡erÃ§evesi paradigmasÄ±nÄ±n aÃ§Ä±klanmasÄ±)*

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair daha kapsamlÄ± bir aÃ§Ä±klama, **Stanford Ãœniversitesi Ä°statistik ProfesÃ¶rÃ¼ David Donoho** tarafÄ±ndan *50 Years of Data Science* (Veri Biliminin 50 YÄ±lÄ±) adlÄ± makalesinde verilmiÅŸtir.
Bu makale ilk olarak *Journal of Computational and Graphical Statistics* dergisinde yayÄ±mlanmÄ±ÅŸ, ardÄ±ndan MIT Bilgisayar Bilimi ve Yapay ZekÃ¢ LaboratuvarÄ± sitesinde paylaÅŸÄ±lmÄ±ÅŸtÄ±r (bkz. [http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)).

ProfesÃ¶r Donoho doÄŸrudan Kaggleâ€™dan deÄŸil, genel olarak **veri bilimi yarÄ±ÅŸma platformlarÄ±ndan** bahseder.
BilgisayarlÄ± dilbilimci **Mark Liberman**â€™dan alÄ±ntÄ± yaparak, veri bilimi yarÄ±ÅŸmalarÄ±nÄ± ve platformlarÄ±nÄ± **â€œCommon Task Framework (CTF)â€ â€” Ortak GÃ¶rev Ã‡erÃ§evesi** paradigmasÄ±nÄ±n bir parÃ§asÄ± olarak tanÄ±mlar.
Bu paradigma, son on yÄ±llarda birÃ§ok alanda veri biliminin sessiz ama istikrarlÄ± bir ÅŸekilde ilerlemesini saÄŸlamÄ±ÅŸtÄ±r.

Donoho, CTFâ€™nin veri bilimi problemlerine **ampirik (deneysel)** aÃ§Ä±dan Ã§Ã¶zÃ¼m getirmede son derece etkili olduÄŸunu sÃ¶yler ve bunu desteklemek iÃ§in **Netflix yarÄ±ÅŸmasÄ±** ile Ã§eÅŸitli **DARPA yarÄ±ÅŸmalarÄ±nÄ±** baÅŸarÄ±lÄ± Ã¶rnekler olarak gÃ¶sterir.
CTF paradigmasÄ±, birÃ§ok alanda en iyi Ã§Ã¶zÃ¼mleri yeniden ÅŸekillendirmeye katkÄ±da bulunmuÅŸtur.

---

**CTFâ€™nin bileÅŸenleri ve â€œgizli sosuâ€**

Bir CTF, bazÄ± bileÅŸenlerden ve â€œgizli bir sostanâ€ oluÅŸur.
BileÅŸenler ÅŸunlardÄ±r:

1. Herkese aÃ§Ä±k bir veri seti ve bununla iliÅŸkili bir tahmin gÃ¶revi,
2. Bu gÃ¶reve en iyi tahmini Ã¼retmek iÃ§in ortak bir amaÃ§la Ã§alÄ±ÅŸan yarÄ±ÅŸmacÄ±lar,
3. KatÄ±lÄ±mcÄ±larÄ±n tahminlerini adil ve objektif biÃ§imde puanlayan, ancak Ã§Ã¶zÃ¼me dair fazla ipucu vermeyen (ya da en azÄ±ndan bunu sÄ±nÄ±rlayan) bir deÄŸerlendirme sistemi.

Bu sistem, gÃ¶rev aÃ§Ä±k ÅŸekilde tanÄ±mlandÄ±ÄŸÄ±nda ve veri kaliteli olduÄŸunda en iyi ÅŸekilde Ã§alÄ±ÅŸÄ±r.
Zaman iÃ§inde Ã§Ã¶zÃ¼mlerin performansÄ± kÃ¼Ã§Ã¼k artÄ±ÅŸlarla geliÅŸir ve sonunda bir **asimptota (doyum noktasÄ±na)** ulaÅŸÄ±r.
Bu sÃ¼reÃ§, katÄ±lÄ±mcÄ±lar arasÄ±nda belli bir dÃ¼zeyde paylaÅŸÄ±mÄ±n teÅŸvik edilmesiyle hÄ±zlanabilir.
Kaggleâ€™da bu paylaÅŸÄ±m; **tartÄ±ÅŸmalar, paylaÅŸÄ±lan Kaggle Notebookâ€™larÄ±** ve **Datasets** bÃ¶lÃ¼mÃ¼ndeki ek veriler aracÄ±lÄ±ÄŸÄ±yla gerÃ§ekleÅŸir.

CTF paradigmasÄ±na gÃ¶re, bir yarÄ±ÅŸmadaki **rekabet baskÄ±sÄ±**, Ã§Ã¶zÃ¼mlerin sÃ¼rekli olarak geliÅŸmesi iÃ§in tek baÅŸÄ±na yeterlidir.
Bu rekabet baskÄ±sÄ±, katÄ±lÄ±mcÄ±lar arasÄ±nda belli Ã¶lÃ§Ã¼de **bilgi paylaÅŸÄ±mÄ±yla** birleÅŸtiÄŸinde, geliÅŸme Ã§ok daha hÄ±zlÄ± gerÃ§ekleÅŸir.
Ä°ÅŸte bu nedenle Kaggle, paylaÅŸÄ±mÄ± teÅŸvik eden birÃ§ok Ã¶dÃ¼l ve mekanizma getirmiÅŸtir.

---

**CTFâ€™nin gizli sosu: rekabetin kendisi**

CTF paradigmasÄ±ndaki â€œgizli sosâ€, **bizzat yarÄ±ÅŸmanÄ±n kendisidir**.
Bu yapÄ±, ampirik performansÄ±n artÄ±rÄ±lmasÄ±nÄ±n hedeflendiÄŸi pratik bir problem Ã§erÃ§evesinde, her zaman yeni **Ã¶lÃ§Ã¼tlerin (benchmark)**, **veri ve modelleme Ã§Ã¶zÃ¼mlerinin**, ve genel anlamda **makine Ã¶ÄŸrenmesinin daha iyi uygulanma biÃ§imlerinin** ortaya Ã§Ä±kmasÄ±nÄ± saÄŸlar.

Bir yarÄ±ÅŸma, dolayÄ±sÄ±yla bir tahmin problemini Ã§Ã¶zmenin yeni yollarÄ±nÄ±, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** iÃ§in yeni yÃ¶ntemleri ve yeni **algoritmik veya modelleme Ã§Ã¶zÃ¼mlerini** sunabilir.
Ã–rneÄŸin, **derin Ã¶ÄŸrenme (deep learning)** yalnÄ±zca akademik araÅŸtÄ±rmalardan doÄŸmamÄ±ÅŸtÄ±r; tersine, etkinliÄŸini kanÄ±tlayan baÅŸarÄ±lÄ± yarÄ±ÅŸmalar sayesinde bÃ¼yÃ¼k bir ivme kazanmÄ±ÅŸtÄ±r.
(Ã–rneÄŸin, Geoffrey Hinton ekibinin kazandÄ±ÄŸÄ± **Merck yarÄ±ÅŸmasÄ±nÄ±** hatÄ±rlayalÄ±m: [https://www.kaggle.com/c/MerckActivity/overview/winners](https://www.kaggle.com/c/MerckActivity/overview/winners)).

---

**CTF ve aÃ§Ä±k yazÄ±lÄ±m hareketi**

**AÃ§Ä±k kaynak yazÄ±lÄ±m hareketi** ile birleÅŸtiÄŸinde (Ã¶rneÄŸin Scikit-learn, TensorFlow veya PyTorch gibi gÃ¼Ã§lÃ¼ analitik araÃ§lara herkesin eriÅŸebilmesi), CTF paradigmasÄ± Ã§ok daha iyi sonuÃ§lar Ã¼retir.
Bunun nedeni, tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n baÅŸlangÄ±Ã§ta **aynÄ± dÃ¼zeyde olanaklara sahip** olmasÄ±dÄ±r.

Ancak, bir yarÄ±ÅŸmadaki Ã§Ã¶zÃ¼mÃ¼n **Ã¶zel donanÄ±m veya yÃ¼ksek iÅŸlem gÃ¼cÃ¼ne** dayanmasÄ±, elde edilebilecek sonuÃ§larÄ± sÄ±nÄ±rlayabilir.
Ã‡Ã¼nkÃ¼ bu durum, bu tÃ¼r kaynaklara eriÅŸimi olmayan yarÄ±ÅŸmacÄ±larÄ±n doÄŸru ÅŸekilde katÄ±lÄ±m gÃ¶stermesini ya da diÄŸer katÄ±lÄ±mcÄ±lar Ã¼zerinde **rekabet baskÄ±sÄ±** oluÅŸturarak dolaylÄ± katkÄ± saÄŸlamasÄ±nÄ± engelleyebilir.

Ä°ÅŸte bu nedenle Kaggle, yarÄ±ÅŸmalara katÄ±lanlar iÃ§in **Ã¼cretsiz bulut hizmetleri** (Ã¶rneÄŸin **Kaggle Notebooks**) sunmaya baÅŸlamÄ±ÅŸtÄ±r.
Bu uygulama, Ã¶zellikle donanÄ±m yoÄŸun yarÄ±ÅŸmalarda (Ã¶rneÄŸin derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ± gibi) bazÄ± farklarÄ± azaltabilir ve genel anlamda rekabeti artÄ±rabilir.

##### Understanding what can go wrong in a competition *(Bir yarÄ±ÅŸmada nelerin ters gidebileceÄŸini anlamak)*

**CTF ParadigmasÄ± ve YarÄ±ÅŸma BaÅŸarÄ±sÄ±zlÄ±klarÄ±nÄ±n Nedenleri**

CTF paradigmasÄ±na dair Ã¶nceki aÃ§Ä±klamamÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurursak, bir yarÄ±ÅŸmanÄ±n tek ihtiyacÄ± uygun bir platformda dÃ¼zenlenmekmiÅŸ gibi gÃ¶rÃ¼nebilir. BÃ¶yle olursa, katÄ±lÄ±mcÄ±lar iÃ§in olumlu bir katÄ±lÄ±m ve sponsor ÅŸirket iÃ§in olaÄŸanÃ¼stÃ¼ modeller gibi iyi sonuÃ§larÄ±n kendiliÄŸinden ortaya Ã§Ä±kacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

Ancak, hem katÄ±lÄ±mcÄ±lar hem de yarÄ±ÅŸmayÄ± dÃ¼zenleyen kurum aÃ§Ä±sÄ±ndan **hayal kÄ±rÄ±klÄ±ÄŸÄ±na yol aÃ§abilecek** bazÄ± durumlar da meydana gelebilir:

* Veri sÄ±zÄ±ntÄ±sÄ± (data leakage)
* Liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼m denemesi (probing)
* AÅŸÄ±rÄ± uyum (overfitting) ve buna baÄŸlÄ± liderlik tablosu deÄŸiÅŸimleri
* Ã–zel paylaÅŸÄ±m (private sharing)

---

**Veri SÄ±zÄ±ntÄ±sÄ± (Data Leakage)**

**Veri sÄ±zÄ±ntÄ±sÄ±**, Ã§Ã¶zÃ¼mÃ¼n bir kÄ±smÄ±nÄ±n bizzat verinin kendisinden geri izlenebilmesi durumudur.
Ã–rneÄŸin, bazÄ± deÄŸiÅŸkenler hedef deÄŸiÅŸkenden (target variable) sonra oluÅŸmuÅŸ olabilir ve bu da hedef hakkÄ±nda bilgi sÄ±zdÄ±rÄ±r.

Bu durum, Ã¶rneÄŸin dolandÄ±rÄ±cÄ±lÄ±k tespitinde, dolandÄ±rÄ±cÄ±lÄ±k gerÃ§ekleÅŸtikten sonra gÃ¼ncellenen deÄŸiÅŸkenleri kullandÄ±ÄŸÄ±nÄ±zda; veya satÄ±ÅŸ tahmini yaparken, bir Ã¼rÃ¼nÃ¼n **gerÃ§ek daÄŸÄ±tÄ±m bilgilerini** iÅŸlediÄŸinizde (daha fazla daÄŸÄ±tÄ±m â†’ daha fazla talep â†’ daha fazla satÄ±ÅŸ) ortaya Ã§Ä±kar.

BaÅŸka bir Ã¶rnek de, **eÄŸitim ve test Ã¶rneklerinin tahmin edilebilir bir sÄ±rada dÃ¼zenlenmiÅŸ olmasÄ±** ya da Ã¶rnek kimliklerinin (identifier) deÄŸerlerinin Ã§Ã¶zÃ¼me dair ipuÃ§larÄ± iÃ§ermesidir.
Ã–rneÄŸin, kimlik numarasÄ± hedef deÄŸiÅŸkenin sÄ±rasÄ±na gÃ¶re belirlenmiÅŸse ya da kimlik deÄŸeri zamanla iliÅŸkiliyse ve zaman hedef deÄŸiÅŸkenin olasÄ±lÄ±ÄŸÄ±nÄ± etkiliyorsa bu da bir sÄ±zÄ±ntÄ±dÄ±r.

Bu tÃ¼r veri sÄ±zÄ±ntÄ±larÄ±na, bazÄ± yarÄ±ÅŸmacÄ±lar tarafÄ±ndan **â€œaltÄ±n Ã¶zellikler (golden features)â€** adÄ± verilir â€” Ã§Ã¼nkÃ¼ verideki bu tÃ¼r kÃ¼Ã§Ã¼k ipuÃ§larÄ±nÄ± fark etmek, katÄ±lÄ±mcÄ±lar iÃ§in adeta altÄ±n deÄŸerinde Ã¶dÃ¼ller kazandÄ±rabilir.
Ancak bu durum genellikle **yeniden kullanÄ±labilir olmayan Ã§Ã¶zÃ¼mler** Ã¼retir.
Bu da sponsor iÃ§in **optimal olmayan sonuÃ§lar** anlamÄ±na gelir, ancak en azÄ±ndan sponsor hangi deÄŸiÅŸkenlerin sÄ±zÄ±ntÄ±ya yol aÃ§abileceÄŸini Ã¶ÄŸrenmiÅŸ olur.

---

**Liderlik Tablosu Ãœzerinden Ã‡Ã¶zÃ¼m Denemesi (Leaderboard Probing)**

Bir diÄŸer problem, **liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼mÃ¼ test etmek veya â€œdeÅŸifre etmekâ€** olasÄ±lÄ±ÄŸÄ±dÄ±r.
Bu durumda, yarÄ±ÅŸmacÄ±lar deÄŸerlendirme metriklerinden yararlanarak sÃ¼rekli denemeler yapabilir ve bu yolla Ã§Ã¶zÃ¼m hakkÄ±nda bilgi elde edebilir.
Yine bu tÃ¼r Ã§Ã¶zÃ¼mler, farklÄ± koÅŸullarda tamamen **kullanÄ±lamaz** hale gelir.

Bunun aÃ§Ä±k bir Ã¶rneÄŸi **â€œDonâ€™t Overfit IIâ€** yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r.
Kazanan katÄ±lÄ±mcÄ± **Zachary Mayers**, her bir deÄŸiÅŸkeni tek tek gÃ¶ndererek her birinin model Ã¼zerindeki etkisini analiz etmiÅŸ ve bu yolla modelinin katsayÄ±larÄ±nÄ± doÄŸru tahmin edebilmiÅŸtir.
(Zachâ€™Ä±n detaylÄ± Ã§Ã¶zÃ¼mÃ¼nÃ¼ burada okuyabilirsiniz: [https://www.kaggle.com/c/dont-overfit-ii/discussion/91766](https://www.kaggle.com/c/dont-overfit-ii/discussion/91766))

Genellikle **zaman serisi problemleri** veya test verisinde sistematik deÄŸiÅŸimler olan diÄŸer problemler, bu tÃ¼r probingâ€™den ciddi ÅŸekilde etkilenebilir.
Ã‡Ã¼nkÃ¼ bu durum, yarÄ±ÅŸmacÄ±larÄ±n tahminlerini Ã¶rneÄŸin sabit bir sayÄ± ile Ã§arpmak gibi bir **son iÅŸleme (post-processing)** adÄ±mÄ±yla puanlarÄ±nÄ± artÄ±rmalarÄ±na olanak tanÄ±yabilir.

---

**Liderlik Tablosuna AÅŸÄ±rÄ± GÃ¼venme ve AÅŸÄ±rÄ± Uyum (Overfitting)**

Liderlik tablosuna aÅŸÄ±rÄ± gÃ¼venmek, bir baÅŸka tÃ¼r **aÅŸÄ±rÄ± uyum (overfitting)** Ã¶rneÄŸidir.
KatÄ±lÄ±mcÄ±lar kendi doÄŸrulama testlerinden Ã§ok liderlik tablosundaki geri bildirimlere gÃ¶re hareket ettiklerinde bu durum ortaya Ã§Ä±kar.

Bazen bu durum yarÄ±ÅŸmanÄ±n **tamamen baÅŸarÄ±sÄ±z olmasÄ±na**, yani nihai liderlik tablosunda **beklenmedik ve rastlantÄ±sal sÄ±ralama deÄŸiÅŸikliklerine (shake-up)** yol aÃ§abilir.
BÃ¶yle bir durumda kazanan Ã§Ã¶zÃ¼mler, aslÄ±nda probleme uygun olmayan veya tamamen tesadÃ¼fi Ã§Ã¶zÃ¼mler olabilir.

Bu tÃ¼r olaylar, **eÄŸitim seti ile test seti arasÄ±ndaki farklarÄ± analiz eden** bazÄ± tekniklerin geliÅŸtirilmesine yol aÃ§mÄ±ÅŸtÄ±r.
Bu tÃ¼r analizlere **adversarial testing** denir ve liderlik tablosuna ne kadar gÃ¼venileceÄŸi veya eÄŸitim ve test setleri arasÄ±nda tamamen kaÃ§Ä±nÄ±lmasÄ± gereken Ã¶zellikler olup olmadÄ±ÄŸÄ± konusunda fikir verir.
Ã–rnek olarak, **Bojan Tunguz**â€™un ÅŸu Notebookâ€™una gÃ¶z atabilirsiniz:
[https://www.kaggle.com/tunguz/adversarial-ieee](https://www.kaggle.com/tunguz/adversarial-ieee).

---

**Overfittingâ€™e KarÅŸÄ± Savunma Stratejileri**

Liderlik tablosuna aÅŸÄ±rÄ± uyumu Ã¶nlemenin bir baÅŸka yolu, **gÃ¼venli stratejiler** kullanmaktÄ±r.
Ã–rneÄŸin, genellikle her katÄ±lÄ±mcÄ±nÄ±n **final deÄŸerlendirmesi iÃ§in iki Ã§Ã¶zÃ¼m** gÃ¶ndermesine izin verilir.
Bu durumda iyi bir strateji, birini liderlik tablosuna gÃ¶re en baÅŸarÄ±lÄ± olan Ã§Ã¶zÃ¼m olarak, diÄŸerini ise **kendi Ã§apraz doÄŸrulama testlerinde** en iyi performans gÃ¶steren Ã§Ã¶zÃ¼m olarak gÃ¶ndermektir.

Liderlik tablosu probingâ€™i ve overfittingâ€™i Ã¶nlemek iÃ§in Kaggle, daha Ã¶nce de bahsettiÄŸimiz gibi, **iki aÅŸamalÄ± deÄŸerlendirme sistemi** iÃ§eren **Code yarÄ±ÅŸmalarÄ±na** yÃ¶nelik Ã§eÅŸitli yenilikler getirmiÅŸtir.
Bu yarÄ±ÅŸmalarda katÄ±lÄ±mcÄ±lar test verisini hiÃ§ gÃ¶rmedikleri iÃ§in, kendi **yerel doÄŸrulama testlerine** daha fazla Ã¶nem vermek zorunda kalÄ±rlar.

---

**Ã–zel PaylaÅŸÄ±m (Private Sharing) ve Etik DÄ±ÅŸÄ± DavranÄ±ÅŸlar**

Bir yarÄ±ÅŸmayÄ± bozabilecek bir diÄŸer unsur, **Ã¶zel paylaÅŸÄ±m (private sharing)** yani fikir ve Ã§Ã¶zÃ¼mlerin yalnÄ±zca kapalÄ± bir grup arasÄ±nda paylaÅŸÄ±lmasÄ±dÄ±r.
Buna ek olarak, **birden fazla hesapla yarÄ±ÅŸmak**, **birden fazla takÄ±ma katÄ±lÄ±p fikir Ã§almak** gibi etik dÄ±ÅŸÄ± davranÄ±ÅŸlar da olabilir.

Bu tÃ¼r durumlar, bazÄ± katÄ±lÄ±mcÄ±lar iÃ§in avantaj yaratÄ±rken Ã§oÄŸunluk iÃ§in dezavantaj doÄŸurur â€” yani **bilgi asimetrisi** oluÅŸur.
BÃ¶ylece, yarÄ±ÅŸma boyunca paylaÅŸÄ±m eksik kalÄ±r ve az sayÄ±da takÄ±m tam rekabet baskÄ±sÄ± yaratabilir.

AyrÄ±ca, bu tÃ¼r durumlar katÄ±lÄ±mcÄ±larÄ±n farkÄ±na vardÄ±ÄŸÄ±nda (Ã¶rneÄŸin ÅŸu tartÄ±ÅŸmaya bakÄ±labilir: [https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503](https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503)), yarÄ±ÅŸmaya ve sonraki yarÄ±ÅŸmalara olan gÃ¼ven ve katÄ±lÄ±m da azalabilir.

#### Computational resources *(Hesaplama kaynaklarÄ±)*

BazÄ± yarÄ±ÅŸmalar, **Ã¼retim ortamÄ±nda uygulanabilir Ã§Ã¶zÃ¼mler** elde edebilmek iÃ§in belirli sÄ±nÄ±rlamalar getirir.
Ã–rneÄŸin, **Bosch Production Line Performance** yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/bosch-production-line-performance](https://www.kaggle.com/c/bosch-production-line-performance)) Ã§Ã¶zÃ¼m modelleri iÃ§in **Ã§alÄ±ÅŸma sÃ¼resi**, **Ã§Ä±ktÄ± dosyasÄ± boyutu** ve **bellek kullanÄ±mÄ±** aÃ§Ä±sÄ±ndan katÄ± sÄ±nÄ±rlamalara sahipti.

**Notebook tabanlÄ± yarÄ±ÅŸmalar** (Ã¶nceden *Kernel-Only* yarÄ±ÅŸmalarÄ± olarak biliniyordu), hem eÄŸitimin hem de Ã§Ä±karÄ±mÄ±n (inference) **Kaggle Notebooks** Ã¼zerinde gerÃ§ekleÅŸtirilmesini zorunlu kÄ±lar.
Bu durumda, kullanmanÄ±z gereken kaynaklarla ilgili bir sorun oluÅŸmaz; Ã§Ã¼nkÃ¼ **Kaggle size tÃ¼m gerekli donanÄ±m kaynaklarÄ±nÄ± saÄŸlar**.
Bu yaklaÅŸÄ±m aynÄ± zamanda, **tÃ¼m katÄ±lÄ±mcÄ±larÄ±n aynÄ± baÅŸlangÄ±Ã§ noktasÄ±nda yarÄ±ÅŸmasÄ±nÄ±** saÄŸlamak amacÄ±yla da tasarlanmÄ±ÅŸtÄ±r.

Sorunlar, yalnÄ±zca **Ã§Ä±karÄ±m (inference)** aÅŸamasÄ±nda Notebook kullanÄ±mÄ±nÄ± zorunlu kÄ±lan yarÄ±ÅŸmalarda ortaya Ã§Ä±kar.
Bu tÃ¼r yarÄ±ÅŸmalarda modellerinizi kendi bilgisayarÄ±nÄ±zda eÄŸitebilir, ancak **test aÅŸamasÄ±nda** model sayÄ±sÄ± ve karmaÅŸÄ±klÄ±ÄŸÄ± aÃ§Ä±sÄ±ndan sÄ±nÄ±rlamalara tabi olursunuz.

GÃ¼nÃ¼mÃ¼zde yarÄ±ÅŸmalarÄ±n Ã§oÄŸu **derin Ã¶ÄŸrenme (deep learning)** Ã§Ã¶zÃ¼mleri gerektirdiÄŸinden, **rekabetÃ§i sonuÃ§lar elde edebilmek iÃ§in GPU gibi Ã¶zel donanÄ±mlara** ihtiyaÃ§ duyacaÄŸÄ±nÄ±zÄ± bilmelisiniz.

GÃ¼nÃ¼mÃ¼zde nadirleÅŸmiÅŸ olsa da, bazÄ± **tabular veri yarÄ±ÅŸmalarÄ±nda** bile, **Ã§ok Ã§ekirdekli iÅŸlemcilere** ve **yÃ¼ksek belleÄŸe** sahip gÃ¼Ã§lÃ¼ bir makineye ihtiyacÄ±nÄ±z olduÄŸunu fark edeceksiniz.
Bu kaynaklar, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** uygulamak, **deneyler yÃ¼rÃ¼tmek** ve **modelleri hÄ±zlÄ± bir ÅŸekilde inÅŸa etmek** iÃ§in gereklidir.

Standartlar hÄ±zla deÄŸiÅŸtiÄŸi iÃ§in, tÃ¼m katÄ±lÄ±mcÄ±larla aynÄ± seviyede rekabet edebilmek adÄ±na **net bir donanÄ±m standardÄ± tanÄ±mlamak zordur**.
Ancak, diÄŸer yarÄ±ÅŸmacÄ±larÄ±n hangi makineleri kullandÄ±ÄŸÄ±na bakarak gÃ¼ncel standartlar hakkÄ±nda fikir edinebilirsiniz â€” ister kendi bilgisayarlarÄ± olsun, ister bulut tabanlÄ± makineler.

Ã–rneÄŸin, **HP**, marka gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼ karÅŸÄ±lÄ±ÄŸÄ±nda bazÄ± seÃ§ilmiÅŸ Kaggle yarÄ±ÅŸmacÄ±larÄ±na **HP Z4 veya Z8** makineleri hediye ettiÄŸi bir program baÅŸlatmÄ±ÅŸtÄ±r.
Bir **Z8 makinesi**,

* 72 Ã§ekirdeÄŸe kadar CPU,
* 3 TB bellek,
* 48 TB depolama (Ã§oÄŸunluÄŸu SSD),
* ve genellikle **Ã§ift NVIDIA RTX GPU** barÄ±ndÄ±rÄ±r.

Bu dÃ¼zeyde bir sistemin birÃ§ok kiÅŸi iÃ§in eriÅŸilemez olduÄŸunu anlamak zor deÄŸildir.
Benzer Ã¶zelliklerde bir makineyi kÄ±sa sÃ¼reliÄŸine bile **Google Cloud (GCP)** veya **Amazon AWS** gibi platformlarda kiralamak bile **yÃ¼ksek maliyetler** doÄŸurabilir.

Bu nedenle, **Kaggleâ€™da Ã¼st sÄ±ralara tÄ±rmanma yolculuÄŸunuza baÅŸlarken**, en iyi yaklaÅŸÄ±m **Kaggleâ€™Ä±n Ã¼cretsiz sunduÄŸu altyapÄ±yÄ±**, yani **Kaggle Notebooksâ€™u (Ã¶nceki adÄ±yla Kaggle Kernels)** kullanmaktÄ±r.

##### Kaggle Notebooks *(Kaggle Defterleri)*

**Kaggle Notebooks**, bulut makinelerinde Ã§alÄ±ÅŸan **Docker konteynerleri** tabanlÄ±, sÃ¼rÃ¼mlenebilir (versioned) hesaplama ortamlarÄ±dÄ±r.
Bu ortamlar, **R** ve **Python** dillerinde hem **script** hem de **notebook** yazÄ±p Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r.

Kaggle Notebooks:

* **Kaggle ortamÄ±na entegredir:** Bu sayede doÄŸrudan notebookâ€™tan yarÄ±ÅŸmaya gÃ¶nderim (submission) yapabilir ve hangi gÃ¶nderimin hangi notebookâ€™tan geldiÄŸini takip edebilirsiniz.
* **Ã‡oÄŸu veri bilimi paketini Ã¶nceden yÃ¼klÃ¼ olarak iÃ§erir.**
* **KÄ±sÄ±tlÄ± Ã¶zelleÅŸtirme olanaÄŸÄ± sunar:** Dosya indirebilir ve ek Python/R paketleri yÃ¼kleyebilirsiniz.

Temel **Kaggle Notebook**, yalnÄ±zca CPU tabanlÄ±dÄ±r. Ancak, isterseniz:

* **NVIDIA Tesla P100 GPU**,
* veya **TPU v3-8** (Ã¶zellikle derin Ã¶ÄŸrenme gÃ¶revleri iÃ§in optimize edilmiÅŸ donanÄ±m hÄ±zlandÄ±rÄ±cÄ±sÄ±)
  desteÄŸiyle gÃ¼Ã§lendirilmiÅŸ sÃ¼rÃ¼mleri de kullanabilirsiniz.

Her yarÄ±ÅŸmanÄ±n bulut maliyeti, **iÅŸlenecek veri miktarÄ±na**, **kurduÄŸunuz model sayÄ±sÄ±na ve tÃ¼rÃ¼ne** baÄŸlÄ±dÄ±r.
Kaggle yarÄ±ÅŸmalarÄ±nda, **GCP (Google Cloud Platform)** veya **AWS** Ã¼zerinde kullanÄ±lmak Ã¼zere genellikle **200 â€“ 500 ABD DolarÄ±** aralÄ±ÄŸÄ±nda **Ã¼cretsiz bulut kredisi** daÄŸÄ±tÄ±lÄ±r.

Kaggle Notebooks, belirli **kullanÄ±m ve sÃ¼re sÄ±nÄ±rlamalarÄ±** altÄ±nda Ã§alÄ±ÅŸÄ±r; ancak bu sÄ±nÄ±rlar dahilinde yarÄ±ÅŸmalarda **temel modellerinizi geliÅŸtirmek iÃ§in yeterli hesaplama gÃ¼cÃ¼nÃ¼** saÄŸlar.

| Notebook tÃ¼rÃ¼ | CPU Ã§ekirdeÄŸi | Bellek | AynÄ± anda Ã§alÄ±ÅŸtÄ±rÄ±labilen notebook sayÄ±sÄ± | HaftalÄ±k kota |
| ------------- | ------------- | ------ | ------------------------------------------ | ------------- |
| **CPU**       | 4             | 16 GB  | 10                                         | SÄ±nÄ±rsÄ±z      |
| **GPU**       | 2             | 13 GB  | 2                                          | 30 saat       |
| **TPU**       | 4             | 16 GB  | 2                                          | 30 saat       |

* **CPU ve GPU notebookâ€™larÄ±**, **maksimum 12 saat** boyunca kesintisiz Ã§alÄ±ÅŸabilir.
* **TPU notebookâ€™larÄ±** ise **en fazla 9 saat** boyunca Ã§alÄ±ÅŸtÄ±rÄ±labilir.
  Bu sÃ¼reler dolduÄŸunda, diske kaydedilmemiÅŸ hiÃ§bir Ã§Ä±ktÄ± alÄ±namaz.

KullanÄ±cÄ±larÄ±n **20 GB kalÄ±cÄ± disk alanÄ±** bulunur (model ve sonuÃ§larÄ± saklamak iÃ§in).
Buna ek olarak, geÃ§ici dosyalar iÃ§in **20 GBâ€™tan fazla geÃ§ici (scratchpad) alan** kullanÄ±labilir.

BazÄ± durumlarda, Kaggleâ€™Ä±n sunduÄŸu **GPU destekli makineler** yeterli olmayabilir.
Ã–rneÄŸin, **Deepfake Detection Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/deepfake-detection-challenge](https://www.kaggle.com/c/deepfake-detection-challenge)) yaklaÅŸÄ±k **500 GB video verisi** iÅŸlenmesi gerekiyordu.

Bu, iki aÃ§Ä±dan zorluk yaratÄ±yordu:

1. HaftalÄ±k **30 saatlik kullanÄ±m sÃ¼resi** sÄ±nÄ±rlamasÄ±,
2. AynÄ± anda **en fazla iki GPU destekli makine** Ã§alÄ±ÅŸtÄ±rÄ±labilmesi.

Kodunuzu **GPU yerine TPU kullanacak ÅŸekilde optimize ederek** (bunun iÃ§in rehber: [https://www.kaggle.com/docs/tpu](https://www.kaggle.com/docs/tpu)) sÃ¼reyi iki katÄ±na Ã§Ä±karabilirsiniz.
Ancak bu bile, **bÃ¼yÃ¼k veri setlerine sahip yarÄ±ÅŸmalarda** (Ã¶rneÄŸin Deepfake Detection Challenge gibi) **hÄ±zlÄ± denemeler** yapmak iÃ§in yeterli olmayabilir.

Bu nedenle, **BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek** kÄ±smÄ±nda, bu tÃ¼r sÄ±nÄ±rlamalarla nasÄ±l baÅŸa Ã§Ä±kabileceÄŸinize dair **ipuÃ§larÄ±** vereceÄŸiz.
AmaÃ§, **yÃ¼ksek performanslÄ± donanÄ±m satÄ±n almadan** tatmin edici sonuÃ§lar elde etmenize yardÄ±mcÄ± olmaktÄ±r.

AyrÄ±ca, **Kaggle Notebooksâ€™u GCP ile entegre etme** yÃ¶ntemlerini gÃ¶stereceÄŸiz.
Alternatif olarak, **BÃ¶lÃ¼m 2: Datasets ile Verileri Organize Etmek** kÄ±smÄ±nda, tÃ¼m Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± **Google Colab** gibi baÅŸka bir bulut tabanlÄ± ortama nasÄ±l taÅŸÄ±yabileceÄŸinizi anlatacaÄŸÄ±z.

#### Teaming and networking *(TakÄ±m kurma ve aÄŸ oluÅŸturma)*

Hesaplama gÃ¼cÃ¼ (computational power) Ã¶nemli bir rol oynasa da, bir Kaggle yarÄ±ÅŸmasÄ±nda **gerÃ§ek farkÄ± yaratan unsur, insan uzmanlÄ±ÄŸÄ± ve yeteneÄŸidir.**
Bir yarÄ±ÅŸmanÄ±n baÅŸarÄ±lÄ± bir ÅŸekilde yÃ¼rÃ¼tÃ¼lebilmesi bazen bir **takÄ±mÄ±n ortak Ã§alÄ±ÅŸmasÄ±nÄ±** gerektirir.

**Recruitment (Ä°ÅŸe AlÄ±m)** yarÄ±ÅŸmalarÄ± hariÃ§ â€” ki bu yarÄ±ÅŸmalarda sponsor ÅŸirket, katÄ±lÄ±mcÄ±larÄ±n bireysel yeteneklerini daha iyi deÄŸerlendirebilmek iÃ§in yalnÄ±z katÄ±lÄ±m talep edebilir â€” Kaggleâ€™da genellikle **takÄ±m kurmaya dair herhangi bir kÄ±sÄ±tlama yoktur.**
Bir takÄ±m genellikle **en fazla beÅŸ kiÅŸiden** oluÅŸabilir.

TakÄ±m kurmanÄ±n birÃ§ok avantajÄ± vardÄ±r; Ã§Ã¼nkÃ¼ **farklÄ± becerilerin birleÅŸmesi**, daha iyi Ã§Ã¶zÃ¼mler Ã¼retilmesini saÄŸlar.
Bir ekip, **probleme daha fazla zaman ayÄ±rabilir** ve her Ã¼yenin sahip olduÄŸu farklÄ± uzmanlÄ±k alanlarÄ± (Ã¶rneÄŸin modelleme, veri Ã¶n iÅŸleme, gÃ¶rselleÅŸtirme) ortak hedefe katkÄ± saÄŸlar.
Her veri bilimcisi aynÄ± becerilere veya aynÄ± seviyede uzmanlÄ±ÄŸa sahip deÄŸildir; dolayÄ±sÄ±yla ekip iÃ§indeki **beceri Ã§eÅŸitliliÄŸi**, yarÄ±ÅŸma performansÄ±nÄ± artÄ±rÄ±r.

Yine de, takÄ±m Ã§alÄ±ÅŸmasÄ±nÄ±n dezavantajlarÄ± da vardÄ±r.
**FarklÄ± bireyleri ortak bir hedef doÄŸrultusunda koordine etmek her zaman kolay deÄŸildir** ve bazen verimsiz durumlar yaÅŸanabilir.

YaygÄ±n sorunlardan biri, bazÄ± ekip Ã¼yelerinin **aktif katÄ±lÄ±m gÃ¶stermemesi** veya **tamamen pasif kalmasÄ±dÄ±r.**
Ancak en kÃ¶tÃ¼ senaryo, ekip Ã¼yelerinden birinin yarÄ±ÅŸma kurallarÄ±nÄ± ihlal etmesidir; bu durumda **tÃ¼m ekip diskalifiye edilebilir.**
Daha da kÃ¶tÃ¼sÃ¼, bazen bir ekip Ã¼yesi **diÄŸer bir takÄ±ma avantaj saÄŸlamak iÃ§in casusluk** bile yapabilir â€” ki bu durum geÃ§miÅŸte yaÅŸanmÄ±ÅŸtÄ±r.

Olumsuzluklara raÄŸmen, Kaggleâ€™da takÄ±m olmak harika bir fÄ±rsattÄ±r.
DiÄŸer veri bilimcileriyle tanÄ±ÅŸmak, **ortak bir amaÃ§ iÃ§in iÅŸ birliÄŸi yapmak** ve **bireysel olarak elde edilemeyecek sonuÃ§lara ulaÅŸmak** iÃ§in Ã¶nemli bir deneyimdir.

AyrÄ±ca Kaggle, **takÄ±m katÄ±lÄ±mcÄ±larÄ±nÄ± bireysel katÄ±lÄ±mcÄ±lara gÃ¶re Ã¶dÃ¼llendirme aÃ§Ä±sÄ±ndan avantajlÄ±** kÄ±lar.
KÃ¼Ã§Ã¼k takÄ±mlar, Ã¶dÃ¼l havuzundan **eÅŸit paydan daha yÃ¼ksek bir yÃ¼zde** alabilir.

TakÄ±m kurmak, Kaggleâ€™da **aÄŸ kurmanÄ±n (networking)** tek yolu deÄŸildir, ancak katÄ±lÄ±mcÄ±lar iÃ§in kesinlikle **daha faydalÄ± ve etkileÅŸimli** bir yoldur.
Bunun dÄ±ÅŸÄ±nda, **forum tartÄ±ÅŸmalarÄ±**, **dataset paylaÅŸÄ±mÄ±** ve **notebook paylaÅŸÄ±mÄ±** aracÄ±lÄ±ÄŸÄ±yla da diÄŸer katÄ±lÄ±mcÄ±larla baÄŸlantÄ± kurabilirsiniz.
Bu olanaklar, **diÄŸer veri bilimcileriyle tanÄ±ÅŸmanÄ±za** ve **toplulukta tanÄ±nmanÄ±za** yardÄ±mcÄ± olur.

Kaggle platformunun dÄ±ÅŸÄ±nda da Kaggle topluluÄŸuyla iletiÅŸim kurabileceÄŸiniz birÃ§ok ortam bulunmaktadÄ±r.
Ã–ncelikle, **Slack kanallarÄ±** oldukÃ§a faydalÄ±dÄ±r.

Ã–rneÄŸin, **KaggleNoobs** ([https://www.kaggle.com/getting-started/20577](https://www.kaggle.com/getting-started/20577)) adlÄ± kanal 2016 yÄ±lÄ±nda aÃ§Ä±lmÄ±ÅŸtÄ±r ve Kaggle yarÄ±ÅŸmalarÄ± Ã¼zerine birÃ§ok tartÄ±ÅŸmayÄ± barÄ±ndÄ±rÄ±r.
Burada, **kod veya model ile ilgili Ã¶zel bir probleminiz varsa**, size yardÄ±mcÄ± olabilecek destekleyici bir topluluk vardÄ±r.

Bunun dÄ±ÅŸÄ±nda da birÃ§ok Slack kanalÄ±, **Kaggle yarÄ±ÅŸmalarÄ±** ve **veri bilimi konularÄ±nda gÃ¶rÃ¼ÅŸ alÄ±ÅŸveriÅŸi** yapmak iÃ§in kurulmuÅŸtur.
BazÄ±larÄ± **bÃ¶lgesel veya ulusal dÃ¼zeyde** organize edilmiÅŸtir; Ã¶rneÄŸin:

* **Japon topluluÄŸu:** [Kaggler-ja](http://kaggler-ja-wiki.herokuapp.com/)
* **Rus topluluÄŸu:** [Open Data Science Network (ODS)](https://ods.ai/) â€” 2015 yÄ±lÄ±nda kurulmuÅŸ, daha sonra **RusÃ§a bilmeyen katÄ±lÄ±mcÄ±lara da aÃ§Ä±lmÄ±ÅŸtÄ±r.**

**ODS Network**, yalnÄ±zca bir Slack kanalÄ± deÄŸildir; aynÄ± zamanda:

* **YarÄ±ÅŸma kazanma stratejileri Ã¼zerine kurslar**,
* **Etkinlikler**,
* **TÃ¼m veri bilimi platformlarÄ±nda aktif yarÄ±ÅŸmalar hakkÄ±nda raporlar**
  da sunar.
  (Bkz. [https://ods.ai/competitions](https://ods.ai/competitions))

Slack dÄ±ÅŸÄ±nda, **Kaggle temalÄ± yerel buluÅŸmalar (meetup)** da giderek yaygÄ±nlaÅŸmaktadÄ±r.
BazÄ±larÄ± belirli yarÄ±ÅŸmalar etrafÄ±nda, bazÄ±larÄ± ise genel Kaggle topluluÄŸu odaÄŸÄ±nda dÃ¼zenlenir.
BazÄ±larÄ± **geÃ§ici**, bazÄ±larÄ± ise **dÃ¼zenli ve kalÄ±cÄ± etkinlikler** haline gelmiÅŸtir.

Bu buluÅŸmalar genellikle, **deneyimlerini paylaÅŸmak isteyen yarÄ±ÅŸmacÄ±larÄ±n sunumlarÄ±** etrafÄ±nda ÅŸekillenir.
KatÄ±lÄ±mcÄ±lar, bu tÃ¼r etkinliklerde **diÄŸer Kaggle kullanÄ±cÄ±larÄ±yla yÃ¼z yÃ¼ze tanÄ±ÅŸabilir**, **fikir alÄ±ÅŸveriÅŸinde bulunabilir** ve **ortak yarÄ±ÅŸma ekipleri kurabilir.**

Bu alanda Ã¶zellikle **Kaggle Days** ([https://kaggledays.com/](https://kaggledays.com/)) etkinliklerinden bahsetmek gerekir.
Bu etkinlikler, **Maria Parysz** ve **PaweÅ‚ Jankiewicz** tarafÄ±ndan organize edilmiÅŸtir.

**Kaggle Days**, dÃ¼nyanÄ±n dÃ¶rt bir yanÄ±nda dÃ¼zenlenen (bkz. [https://kaggledays.com/about-us/](https://kaggledays.com/about-us/)) konferanslar aracÄ±lÄ±ÄŸÄ±yla **Kaggle uzmanlarÄ±nÄ± bir araya getirmeyi** amaÃ§lar.
AyrÄ±ca, farklÄ± Ã¼lkelerde hÃ¢lÃ¢ aktif olan **yerel Kaggle meetup aÄŸlarÄ±** da oluÅŸturmuÅŸtur (bkz. [https://kaggledays.com/meetups/](https://kaggledays.com/meetups/)).

> PaweÅ‚ Jankiewicz ile RÃ¶portaj
> 
> 
> 
> **Profil:** [PaweÅ‚ Jankiewicz](https://www.kaggle.com/paweljankiewicz)
> 
> PaweÅ‚, **Kaggle Competitions Grandmaster** ve **LogicAIâ€™nin kurucu ortaklarÄ±ndan** biridir. Kaggle deneyimleri hakkÄ±nda kendisiyle konuÅŸma fÄ±rsatÄ± bulduk.
> 
> 
> 
> **Soru:** En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?
> 
> 
> 
> En sevdiÄŸim yarÄ±ÅŸma tÃ¼rÃ¼ **kod yarÄ±ÅŸmalarÄ±dÄ±r**. Ã‡Ã¼nkÃ¼ sÄ±nÄ±rlÄ± bir ortamda Ã§alÄ±ÅŸmak, farklÄ± tÃ¼rde bÃ¼tÃ§eleri dÃ¼ÅŸÃ¼nmeye zorlar: zaman, CPU, bellek. Ã–nceki yarÄ±ÅŸmalarda Ã§oÄŸu zaman **3-4 gÃ¼Ã§lÃ¼ sanal makine** kullanmam gerekiyordu. Bunu sevmiyordum; Ã§Ã¼nkÃ¼ kazanÃ§ iÃ§in bu kadar kaynak kullanmak, yarÄ±ÅŸmayÄ± adaletsiz hale getiriyor.
> 
> 
> 
> **Soru:** Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±?
> 
> 
> 
> Her yarÄ±ÅŸmaya biraz farklÄ± yaklaÅŸÄ±rÄ±m. Her yarÄ±ÅŸma iÃ§in **mÃ¼mkÃ¼n olduÄŸunca Ã§ok deney oluÅŸturmayÄ± saÄŸlayan bir Ã§erÃ§eve (framework) kurarÄ±m.**
> 
> 
> 
> Ã–rneÄŸin, bir yarÄ±ÅŸmada **derin Ã¶ÄŸrenme konvolÃ¼syonel sinir aÄŸÄ± (CNN)** kurmamÄ±z gerekiyordu. Ben, aÄŸlarÄ± **C4-MP4-C3-MP3** formatÄ±nda yapÄ±landÄ±rmayÄ± saÄŸlayan bir yÃ¶ntem geliÅŸtirdim (her harf farklÄ± bir katmanÄ± temsil ediyordu).
> 
> Bu olay yÄ±llar Ã¶nce oldu; artÄ±k muhtemelen sinir aÄŸlarÄ± yapÄ±landÄ±rmasÄ±, **backbone model seÃ§imiyle** yapÄ±lÄ±yor. Ama kural hÃ¢lÃ¢ geÃ§erli: **Pipelineâ€™daki en hassas bÃ¶lÃ¼mleri hÄ±zlÄ±ca deÄŸiÅŸtirebileceÄŸiniz bir Ã§erÃ§eve oluÅŸturmalÄ±sÄ±nÄ±z.**
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ, modelleme yaklaÅŸÄ±mÄ± ve doÄŸru validasyon aÃ§Ä±sÄ±ndan Kaggle yarÄ±ÅŸmalarÄ±yla benzerlik gÃ¶sterir.
> 
> Kaggle yarÄ±ÅŸmalarÄ±ndan Ã¶ÄŸrendiÄŸim en Ã¶nemli ÅŸey: **validasyonun Ã¶nemi ve veri sÄ±zÄ±ntÄ±sÄ±nÄ± (data leakage) Ã¶nlemenin gerekliliÄŸi.**
> 
> Ã–rneÄŸin, veri sÄ±zÄ±ntÄ±larÄ± Ã§ok sayÄ±da yarÄ±ÅŸmada gÃ¶rÃ¼lÃ¼yor; ve bunlarÄ± hazÄ±rlayan kiÅŸiler alanÄ±n en iyileri. Bu durum, Ã¼retimde kullanÄ±lan modellerin **%80â€™den fazlasÄ±nÄ±n doÄŸru ÅŸekilde validasyon edilmediÄŸini** dÃ¼ÅŸÃ¼ndÃ¼rÃ¼yor (kiÅŸisel gÃ¶rÃ¼ÅŸ).
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ ile farklÄ±lÄ±k: kimse size **modelleme problemini nasÄ±l tanÄ±mlayacaÄŸÄ±nÄ±zÄ±** sÃ¶ylemez.
> 
> Ã–rneÄŸin:
> 
> 
> 
> 1. RaporlayacaÄŸÄ±nÄ±z veya optimize edeceÄŸiniz metrik **RMSE, RMSLE, SMAPE, MAPE** hangisi olmalÄ±?
> 
> 2. Problem zaman bazlÄ±ysa, modeli en gerÃ§ekÃ§i ÅŸekilde deÄŸerlendirmek iÃ§in veriyi nasÄ±l bÃ¶lmelisiniz?
> 
> 
> 
> Bunlar sadece iÅŸ aÃ§Ä±sÄ±ndan Ã¶nemli olan noktalar deÄŸil; ayrÄ±ca **seÃ§imlerinizi aÃ§Ä±klayabilme ve neden yaptÄ±ÄŸÄ±nÄ±zÄ± anlatabilme** becerisine de sahip olmalÄ±sÄ±nÄ±z.
> 
> 
> 
> **Soru:** KatÄ±ldÄ±ÄŸÄ±nÄ±z en zorlu yarÄ±ÅŸma hangisiydi ve problemi Ã§Ã¶zmek iÃ§in hangi yaklaÅŸÄ±mlarÄ± kullandÄ±nÄ±z?
> 
> 
> 
> **PaweÅ‚â€™Ä±n CevabÄ±:**
> 
> En zorlu ve ilginÃ§ yarÄ±ÅŸma, **Mercari Price Prediction Code** yarÄ±ÅŸmasÄ±ydÄ±.
> 
> DiÄŸer yarÄ±ÅŸmalardan farklÄ±ydÄ± Ã§Ã¼nkÃ¼ **sadece 1 saat hesaplama sÃ¼resi ve 4 Ã§ekirdek ile 16 GB bellek** ile sÄ±nÄ±rlÄ±ydÄ±. Bu kÄ±sÄ±tlarÄ± aÅŸmak, yarÄ±ÅŸmanÄ±n en heyecan verici kÄ±smÄ±ydÄ±.
> 
> 
> 
> Bu yarÄ±ÅŸmadan Ã¶ÄŸrendiÄŸim: **tabular veri iÃ§in aÄŸlara daha fazla gÃ¼venmek** gerekir.
> 
> TakÄ±m arkadaÅŸÄ±m **Konstantin Lopukhin** ile birleÅŸmeden Ã¶nce, karmaÅŸÄ±k modellerim vardÄ± (neural networkâ€™ler ve bazÄ± boosting algoritmalarÄ±).
> 
> BirleÅŸtiÄŸimizde, Konstantin sadece **Ã§ok optimize edilmiÅŸ tek bir mimari** kullanÄ±yordu (epoch sayÄ±sÄ±, Ã¶ÄŸrenme hÄ±zÄ± vb.).
> 
> 
> 
> Bu yarÄ±ÅŸmada ayrÄ±ca, **sadece Ã§Ã¶zÃ¼mleri ortalamak yeterli deÄŸildi.**
> 
> Workflowâ€™u yeniden organize edip, **tek bir uyumlu Ã§Ã¶zÃ¼m** Ã¼retmemiz gerekiyordu. Ã‡Ã¶zÃ¼mlerimizi birleÅŸtirmemiz **3 hafta** sÃ¼rdÃ¼.
> 
> 
> 
> **Soru:** TecrÃ¼besiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r?
> 
> 
> 
> **YazÄ±lÄ±m mÃ¼hendisliÄŸi becerileri (software engineering skills)** genellikle fazla Ã¶nemsenmez.
> 
> Her yarÄ±ÅŸma ve problem biraz farklÄ±dÄ±r ve Ã§Ã¶zÃ¼mÃ¼ **dÃ¼zene sokacak bir framework** gerektirir.
> 
> Ã–rnek: [https://github.com/bestfitting/instance_level_recognition](https://github.com/bestfitting/instance_level_recognition)
> 
> Ä°yi kod organizasyonu, **daha hÄ±zlÄ± iterasyon ve daha fazla deneme** yapmanÄ±za olanak saÄŸlar.
> 
> 
> 
> **PaweÅ‚â€™Ä±n Tavsiyesi:**
> 
> En Ã¶nemli ÅŸey **yarÄ±ÅŸmadan keyif almak.**

#### Performance tiers and rankings *(Performans seviyeleri ve sÄ±ralamalar)*

Parasal Ã¶dÃ¼ller ve kupa, tiÅŸÃ¶rt, hoodie veya sticker gibi maddi Ã¶dÃ¼llerin yanÄ± sÄ±ra, Kaggle birÃ§ok **maddi olmayan Ã¶dÃ¼l** de sunar.

Kagglers yarÄ±ÅŸmalar sÄ±rasÄ±nda Ã§ok **zaman ve Ã§aba harcar** (yarÄ±ÅŸmada kullandÄ±klarÄ± beceriler, genel nÃ¼fus arasÄ±nda oldukÃ§a nadirdir). Parasal Ã¶dÃ¼ller genellikle sadece en iyi birkaÃ§ Kaggle katÄ±lÄ±mcÄ±sÄ±nÄ±n Ã§abasÄ±nÄ± karÅŸÄ±lar, Ã§oÄŸu zaman sadece **birinciyi**. DiÄŸer katÄ±lÄ±mcÄ±lar ise saatlerce gÃ¶nÃ¼llÃ¼ Ã§alÄ±ÅŸÄ±r ama karÅŸÄ±lÄ±ÄŸÄ±nda Ã§ok az ÅŸey alÄ±r. Uzun vadede, somut bir Ã¶dÃ¼l olmadan yarÄ±ÅŸmalara katÄ±lmak, **ilgi kaybÄ±na ve motivasyon dÃ¼ÅŸÃ¼ÅŸÃ¼ne** yol aÃ§abilir.

Bu nedenle Kaggle, yarÄ±ÅŸmacÄ±larÄ± **madalya ve puan temelli bir onur sistemiyle** Ã¶dÃ¼llendirmeyi bulmuÅŸtur. AmaÃ§: ne kadar Ã§ok madalya ve puan kazanÄ±rsanÄ±z, becerileriniz o kadar tanÄ±nÄ±r ve iÅŸ arayÄ±ÅŸÄ± veya diÄŸer ilgili aktivitelerde fÄ±rsatlar elde edebilirsiniz.

Kaggleâ€™de bir **genel lider tablosu** vardÄ±r. Bu tablo, tÃ¼m bireysel yarÄ±ÅŸmalarÄ±n lider tablolarÄ±nÄ± birleÅŸtirir: [https://www.kaggle.com/rankings](https://www.kaggle.com/rankings).

* Her yarÄ±ÅŸmadaki pozisyonunuza gÃ¶re puan kazanÄ±rsÄ±nÄ±z.
* Bu puanlar toplandÄ±ÄŸÄ±nda genel lider tablosundaki sÄ±ralamanÄ±zÄ± belirler.

Ä°lk bakÄ±ÅŸta puan hesaplama formÃ¼lÃ¼ karmaÅŸÄ±k gÃ¶rÃ¼nebilir:

[
\left[ \frac{100000}{\sqrt{N_{\text{total}}}} \right] * [RRR - 0.75] * [\log_{10}(1 + \log_{10}(N_{\text{total}}))] * [e^{-t/500}]
]

Ama aslÄ±nda puanlar **temel birkaÃ§ unsur** Ã¼zerine kuruludur:

* YarÄ±ÅŸmadaki sÄ±ralamanÄ±z
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼z
* YarÄ±ÅŸmanÄ±n popÃ¼lerliÄŸi
* YarÄ±ÅŸmanÄ±n yaÅŸÄ±

**Ä°puÃ§larÄ±:**

* PopÃ¼ler yarÄ±ÅŸmalarda yÃ¼ksek sÄ±ralama, daha Ã§ok puan kazandÄ±rÄ±r.
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ **doÄŸrusal olmayan bir ÅŸekilde** puanlarÄ± etkiler. FormÃ¼ldeki **ters kare kÃ¶k** nedeniyle, takÄ±m bÃ¼yÃ¼dÃ¼kÃ§e kaybedilen puan oranÄ± artar.
* TakÄ±mÄ±nÄ±z **kÃ¼Ã§Ã¼k (2-3 kiÅŸi)** ise iÅŸbirliÄŸi ve hesaplama avantajÄ± aÃ§Ä±sÄ±ndan daha iyidir.
* Puanlar **zamanla azalÄ±r**; lineer olmasa da, bir yÄ±l sonra kazandÄ±ÄŸÄ±nÄ±z puanlarÄ±n Ã§oÄŸu kaybolur.

Yine de, profilinizde **ulaÅŸtÄ±ÄŸÄ±nÄ±z en yÃ¼ksek sÄ±ralamayÄ±** her zaman saklarsÄ±nÄ±z.

Daha kalÄ±cÄ± olan, Kaggleâ€™daki dÃ¶rt alanÄ± kapsayan **madalya sistemidir**:

* **Competitions (YarÄ±ÅŸmalar)**
* **Notebooks (Not Defterleri)**
* **Discussion (Forum KatkÄ±larÄ±)**
* **Datasets (Veri Setleri)**

**Competitions:** Madalyalar, lider tablodaki sÄ±ralamanÄ±za gÃ¶re verilir.
**DiÄŸer Ã¼Ã§ alan:** Madalyalar, diÄŸer katÄ±lÄ±mcÄ±larÄ±n **upvoteâ€™larÄ±** ile verilir. (Upvoteâ€™lar popÃ¼lerliÄŸe baÄŸlÄ± ve daha az objektif olabilir.)

Daha fazla madalya kazandÄ±kÃ§a **Kaggle uzmanlÄ±k sÄ±ralamalarÄ±** yÃ¼kselir:

* **Novice (Acemi)**
* **Contributor (KatÄ±lÄ±mcÄ±)**
* **Expert (Uzman)**
* **Master (Usta)**
* **Grandmaster (BÃ¼yÃ¼k Usta)**

DetaylÄ± bilgi ve gerekli madalya sayÄ±larÄ± iÃ§in: [https://www.kaggle.com/progression](https://www.kaggle.com/progression)

> Not: Bu sÄ±ralamalar **her zaman gÃ¶recelidir** ve zamanla deÄŸiÅŸebilir. BirkaÃ§ yÄ±l Ã¶nce puanlama sistemi ve sÄ±ralamalar oldukÃ§a farklÄ±ydÄ±. Muhtemelen gelecekte de, Ã¼st sÄ±ralar **daha nadir ve deÄŸerli** olacak ÅŸekilde deÄŸiÅŸtirilecektir.

#### Criticism and opportunities *(EleÅŸtiriler ve fÄ±rsatlar)*

Kaggle, baÅŸladÄ±ÄŸÄ± gÃ¼nden bu yana pek Ã§ok eleÅŸtiri aldÄ±. Veri bilimi yarÄ±ÅŸmalarÄ±na katÄ±lmak hÃ¢lÃ¢ tartÄ±ÅŸmalÄ± bir konu olup, bu konuda hem olumlu hem de olumsuz pek Ã§ok farklÄ± gÃ¶rÃ¼ÅŸ bulunmaktadÄ±r.

**Olumsuz eleÅŸtiriler aÃ§Ä±sÄ±ndan:**

* Kaggle, makine Ã¶ÄŸreniminin gerÃ§ekte ne olduÄŸuna dair yanlÄ±ÅŸ bir algÄ± yaratÄ±yor Ã§Ã¼nkÃ¼ sadece liderlik tablosu dinamiklerine odaklanÄ±yor.
* Kaggle, aslÄ±nda sadece biraz daha yÃ¼ksek doÄŸruluk elde etmek iÃ§in birÃ§ok modeli bir araya getirip hiperparametre optimizasyonu yapmak Ã¼zerine kurulu bir oyun gibi (gerÃ§ekte test setine fazla uyum saÄŸlama/overfitting yapÄ±yor).
* Kaggle, puan ve dikkat Ã§ekme umuduyla her ÅŸeyi denemeye hazÄ±r deneyimsiz meraklÄ±larla dolu.
* SonuÃ§ olarak, yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri Ã§ok karmaÅŸÄ±k ve genellikle yalnÄ±zca test setine Ã¶zgÃ¼ olup uygulanmasÄ± zor.

BirÃ§ok kiÅŸi Kaggle ve diÄŸer veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ± gerÃ§ek veri bilimine oldukÃ§a uzak olarak gÃ¶rÃ¼yor. EleÅŸtirmenlerin vurguladÄ±ÄŸÄ± nokta ÅŸudur: Ä°ÅŸ problemleri boÅŸluktan ortaya Ã§Ä±kmaz ve nadiren Ã¶nceden iyi hazÄ±rlanmÄ±ÅŸ bir veri setine sahip olursunuz; Ã§Ã¼nkÃ¼ genellikle bunu, iÅŸ gereksinimlerini ve problem anlayÄ±ÅŸÄ±nÄ± geliÅŸtirerek oluÅŸturursunuz. AyrÄ±ca, birÃ§ok eleÅŸtirmen, kazanan Ã§Ã¶zÃ¼mlerin kaynak sÄ±nÄ±rlamalarÄ± veya teknik borÃ§ gibi kÄ±sÄ±tlamalarla sÄ±nÄ±rlandÄ±rÄ±lamayacaÄŸÄ± iÃ§in Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n Ã¼retim odaklÄ± modeller yaratmada yeterince Ã¶ÄŸrenmediÄŸini vurguluyor (her yarÄ±ÅŸma iÃ§in bu doÄŸru olmasa da).

TÃ¼m bu eleÅŸtiriler, nihayetinde Kaggle sÄ±ralamalarÄ±nÄ±n iÅŸveren gÃ¶zÃ¼nde diÄŸer deneyim tÃ¼rleriyle karÅŸÄ±laÅŸtÄ±rÄ±labilirliÄŸi ile ilgilidir; Ã¶zellikle veri bilimi eÄŸitimi ve iÅŸ deneyimi ile kÄ±yaslandÄ±ÄŸÄ±nda. SÃ¼regelen bir mit, Kaggle yarÄ±ÅŸmalarÄ±nÄ±n size iÅŸ bulmada veya daha iyi bir iÅŸ elde etmede yardÄ±mcÄ± olmayacaÄŸÄ± ve Kaggleâ€™a katÄ±lmayan veri bilimcilerden sizi farklÄ± bir seviyeye taÅŸÄ±yamayacaÄŸÄ±dÄ±r.

Bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼z, Kaggle sÄ±ralamalarÄ±nÄ±n Kaggle topluluÄŸunun Ã¶tesinde otomatik bir deÄŸeri olmadÄ±ÄŸÄ±na dair bu inanÄ±ÅŸÄ±n yanÄ±ltÄ±cÄ± olduÄŸudur. Ã–rneÄŸin, iÅŸ ararken Kaggle size veri ve problem modelleme ile etkili model test etme konusunda Ã§ok faydalÄ± beceriler kazandÄ±rabilir. AyrÄ±ca, sizi mevcut deneyim ve konfor alanÄ±nÄ±zÄ±n Ã¶tesinde birÃ§ok teknik ve farklÄ± veri/iÅŸ problemleriyle tanÄ±ÅŸtÄ±rabilir; ancak bir ÅŸirkette veri bilimci olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken her ÅŸeyi tek baÅŸÄ±na saÄŸlayamaz.

Kaggleâ€™Ä± Ã¶ÄŸrenmek iÃ§in (web sitesinde yalnÄ±zca Ã¶ÄŸrenmeye ayrÄ±lmÄ±ÅŸ â€œCoursesâ€ bÃ¶lÃ¼mÃ¼ de vardÄ±r) ve iÅŸ arayÄ±ÅŸÄ±nda kendinizi diÄŸer adaylardan farklÄ± kÄ±lmak iÃ§in kullanabilirsiniz; fakat bunun nasÄ±l deÄŸerlendirileceÄŸi ÅŸirketten ÅŸirkete oldukÃ§a deÄŸiÅŸir. Yine de, Kaggleâ€™da Ã¶ÄŸrendikleriniz kariyeriniz boyunca kesinlikle faydalÄ± olacaktÄ±r ve veri modelleme ile karmaÅŸÄ±k ve alÄ±ÅŸÄ±lmadÄ±k problemleri Ã§Ã¶zmeniz gerektiÄŸinde size bir avantaj saÄŸlayacaktÄ±r. Kaggle yarÄ±ÅŸmalarÄ±na katÄ±larak modelleme ve doÄŸrulama konusunda gÃ¼Ã§lÃ¼ yetkinlikler kazanÄ±rsÄ±nÄ±z. AyrÄ±ca, diÄŸer veri bilimcilerle aÄŸ kurabilir, bu sayede bir iÅŸ referansÄ± elde etmeniz kolaylaÅŸÄ±r ve kendi becerilerinizin Ã¶tesinde zor problemleri Ã§Ã¶zmek iÃ§in baÅŸkalarÄ±nÄ±n yetkinliklerinden ve gÃ¶rÃ¼ÅŸlerinden faydalanabilirsiniz.

Bu nedenle, bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼ze gÃ¶re Kaggle, veri bilimci olarak kariyerinize dolaylÄ± yollardan pek Ã§ok ÅŸekilde katkÄ± saÄŸlar. Elbette, bazen Kaggle, baÅŸarÄ±larÄ±nÄ±z Ã¼zerinden doÄŸrudan bir iÅŸ teklifi almanÄ±za yardÄ±mcÄ± olabilir; fakat Ã§oÄŸu zaman Kaggle, Ã¶nce bir aday olarak, sonra bir uygulayÄ±cÄ± olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken entelektÃ¼el beceri ve deneyimi saÄŸlar.

AslÄ±nda, Kaggleâ€™da bir sÃ¼re veri ve modellerle uÄŸraÅŸtÄ±ktan sonra, farklÄ± veri setleri, problemler ve bunlarla baÅŸa Ã§Ä±kma yÃ¶ntemlerini zaman baskÄ±sÄ± altÄ±nda gÃ¶rmÃ¼ÅŸ olursunuz; bu da benzer problemlerle gerÃ§ek ortamda karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda hÄ±zlÄ± ve etkili Ã§Ã¶zÃ¼mler bulma konusunda sizi yetkin kÄ±lar.

Ä°ÅŸte bu beceri geliÅŸimi fÄ±rsatÄ±, bizi bu kitabÄ± yazmaya motive eden ve kitabÄ±n temel amacÄ±nÄ± oluÅŸturan ÅŸeydir. Burada yalnÄ±zca Kaggle yarÄ±ÅŸmalarÄ±nÄ± kazanma veya yÃ¼ksek puan alma rehberi bulamayacaksÄ±nÄ±z; fakat yarÄ±ÅŸmalarda daha iyi nasÄ±l rekabet edeceÄŸinizi ve yarÄ±ÅŸma deneyimlerinden en iyi ÅŸekilde nasÄ±l faydalanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz.

Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± akÄ±llÄ±ca kullanÄ±n. Kaggle bir sihirli anahtar deÄŸildir â€“ bir yarÄ±ÅŸmada birinci olmak, yÃ¼ksek maaÅŸ veya Kaggle topluluÄŸu dÄ±ÅŸÄ±nda ÅŸan getirmez. Ancak, yarÄ±ÅŸmalara dÃ¼zenli olarak katÄ±lmak, veri bilimi iÅŸ arayÄ±ÅŸÄ±nÄ±zda ilgi ve tutkuyu gÃ¶stermek ve bazÄ± Ã¶zel becerileri geliÅŸtirerek sizi diÄŸer veri bilimcilerden farklÄ± kÄ±lmak iÃ§in stratejik bir karttÄ±r; ayrÄ±ca sizi AutoML Ã§Ã¶zÃ¼mlerine karÅŸÄ± modasÄ± geÃ§miÅŸ hÃ¢le getirmez.

EÄŸer kitabÄ±n ilerleyen bÃ¶lÃ¼mlerini takip ederseniz, bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± gÃ¶stereceÄŸiz.

### Summary *(Ã–zet)*

Bu baÅŸlangÄ±Ã§ bÃ¶lÃ¼mÃ¼nde, Ã¶ncelikle veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n nasÄ±l ortaya Ã§Ä±ktÄ±ÄŸÄ±nÄ± ve hem yarÄ±ÅŸmacÄ±lar hem de bu platformlarÄ± iÅŸleten kurumlar aÃ§Ä±sÄ±ndan nasÄ±l iÅŸlediÄŸini tartÄ±ÅŸtÄ±k; Ã¶zellikle ProfesÃ¶r David Donoho tarafÄ±ndan ele alÄ±nan ikna edici CTF (Capture The Flag) paradigmasÄ±na atÄ±fta bulunduk.

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶rneklerle gÃ¶sterdik, aynÄ± zamanda diÄŸer kayda deÄŸer yarÄ±ÅŸma platformlarÄ±ndan da bahsederek, Kaggle dÄ±ÅŸÄ±ndaki meydan okumalarÄ± da denemenin size nasÄ±l fayda saÄŸlayabileceÄŸini anlattÄ±k. Kaggle ile ilgili olarak, bir yarÄ±ÅŸmanÄ±n farklÄ± aÅŸamalarÄ±nÄ±n nasÄ±l iÅŸlediÄŸini, yarÄ±ÅŸmalarÄ±n birbirinden nasÄ±l farklÄ±laÅŸtÄ±ÄŸÄ±nÄ± ve Kaggle platformunun size sunabileceÄŸi kaynaklarÄ± detaylÄ± ÅŸekilde ele aldÄ±k.

Bir sonraki birkaÃ§ bÃ¶lÃ¼mde, Kaggleâ€™Ä± daha ayrÄ±ntÄ±lÄ± olarak incelemeye baÅŸlayacaÄŸÄ±z; bunun ilk adÄ±mÄ± olarak veri setleri (Datasets) ile nasÄ±l Ã§alÄ±ÅŸÄ±lacaÄŸÄ±nÄ± ele alacaÄŸÄ±z.

---

## Chapter 2: Organizing Data with Datasets *(BÃ¶lÃ¼m 2: Veri Setleriyle Veriyi DÃ¼zenleme)*

Arthur Conan Doyleâ€™un *The Adventure of the Copper Beeches* (BakÄ±r KayÄ±n AÄŸaÃ§larÄ±nÄ±n MacerasÄ±) adlÄ± hikÃ¢yesinde Sherlock Holmes, â€œVeri! Veri! Veri! Kil olmadan tuÄŸla yapamam.â€ diye baÄŸÄ±rÄ±r. EdebiyatÄ±n en Ã¼nlÃ¼ dedektifine bu kadar iyi hizmet eden bu bakÄ±ÅŸ aÃ§Ä±sÄ±, her veri bilimcinin benimsemesi gereken bir yaklaÅŸÄ±m olmalÄ±dÄ±r. Bu nedenle, kitabÄ±n daha teknik bÃ¶lÃ¼mÃ¼ne veri odaklÄ± bir bÃ¶lÃ¼mle baÅŸlÄ±yoruz: Ã¶zellikle Kaggle baÄŸlamÄ±nda, amaÃ§larÄ±mÄ±z doÄŸrultusunda Kaggle Datasets (Veri Setleri) fonksiyonunun gÃ¼cÃ¼nden yararlanmayÄ± ele alacaÄŸÄ±z.

Bu bÃ¶lÃ¼mde ÅŸu konularÄ± ele alacaÄŸÄ±z:

* Bir veri seti oluÅŸturma
* Veriyi toplama
* Veri setleriyle Ã§alÄ±ÅŸma
* Kaggle Datasetsâ€™i Google Colabâ€™de kullanma
* Hukuki uyarÄ±lar

### Setting up a dataset *(Bir veri seti oluÅŸturma)*

Ä°lke olarak, kullanabileceÄŸiniz herhangi bir veriyi Kaggleâ€™a yÃ¼kleyebilirsiniz (sÄ±nÄ±rlamalara tabi; daha sonra â€œHukuki UyarÄ±larâ€ bÃ¶lÃ¼mÃ¼ne bakÄ±nÄ±z). YazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihteki Ã¶zel sÄ±nÄ±rlamalar, her Ã¶zel veri seti iÃ§in 100 GB ve toplam kota olarak 100 GBâ€™dÄ±r. Tek bir veri seti iÃ§in boyut sÄ±nÄ±rÄ±nÄ±n sÄ±kÄ±ÅŸtÄ±rÄ±lmamÄ±ÅŸ hÃ¢liyle hesaplandÄ±ÄŸÄ±nÄ± unutmayÄ±n; sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ versiyonlarÄ± yÃ¼klemek aktarÄ±mÄ± hÄ±zlandÄ±rÄ±r ancak sÄ±nÄ±rlamalara karÅŸÄ± bir avantaj saÄŸlamaz. Veri setleri ile ilgili en gÃ¼ncel dokÃ¼mantasyonu bu baÄŸlantÄ±dan kontrol edebilirsiniz: [Kaggle Datasets Documentation](https://www.kaggle.com/docs/datasets).

Kaggle kendini â€œveri biliminin eviâ€ olarak tanÄ±tÄ±r ve sitede bulunan etkileyici veri seti koleksiyonu bu iddiaya bÃ¼yÃ¼k Ã¶lÃ§Ã¼de gÃ¼venilirlik kazandÄ±rÄ±r. Sadece petrol fiyatlarÄ±ndan anime Ã¶nerilerine kadar Ã§eÅŸitli konularda veri bulmakla kalmazsÄ±nÄ±z; verilerin ne kadar hÄ±zlÄ± bir ÅŸekilde siteye ulaÅŸtÄ±ÄŸÄ± da etkileyicidir. Ã–rneÄŸin, Anthony Fauciâ€™nin e-postalarÄ± 2021 MayÄ±s ayÄ±nda Bilgi Edinme HakkÄ± YasasÄ± kapsamÄ±nda yayÄ±mlandÄ±ÄŸÄ±nda ([link](https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/)), yalnÄ±zca 48 saat iÃ§inde bir Kaggle veri seti olarak yÃ¼klenmiÅŸti.

![](im/1005.png)

Projeniz iÃ§in verileri bir veri setine yÃ¼klemeden Ã¶nce, mevcut iÃ§erikleri kontrol ettiÄŸinizden emin olun.
BazÄ± popÃ¼ler uygulamalar iÃ§in (gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, NLP, finansal zaman serileri) verilerin zaten orada depolanmÄ±ÅŸ olma ihtimali vardÄ±r.

Bu giriÅŸ iÃ§in, projenizde kullanacaÄŸÄ±nÄ±z veri tÃ¼rÃ¼nÃ¼n henÃ¼z orada bulunmadÄ±ÄŸÄ±nÄ± varsayalÄ±m; bu durumda yeni bir veri seti oluÅŸturmanÄ±z gerekir. Sol taraftaki Ã¼Ã§ Ã§izgili menÃ¼ye gidip â€œDataâ€ (Veri) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, Datasets (Veri Setleri) sayfasÄ±na yÃ¶nlendirileceksiniz:

![](im/1006.png)

â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, sizden temel bilgileri girmeniz istenecektir: veriyi yÃ¼klemek ve bir baÅŸlÄ±k vermek.

![](im/1007.png)

Sol taraftaki simgeler, veri setiniz iÃ§in kullanabileceÄŸiniz farklÄ± kaynaklara karÅŸÄ±lÄ±k gelir. BunlarÄ± sayfada gÃ¶sterildikleri sÄ±rayla aÃ§Ä±klÄ±yoruz:

* Yerel bir sÃ¼rÃ¼cÃ¼den dosya yÃ¼kleme (ÅŸekilde gÃ¶sterilmiÅŸtir)
* Uzak bir URLâ€™den oluÅŸturma
* Bir GitHub deposunu iÃ§e aktarma
* Mevcut bir Notebookâ€™tan Ã§Ä±ktÄ± dosyalarÄ±nÄ± kullanma
* Google Cloud Storage dosyasÄ±nÄ± iÃ§e aktarma

GitHub seÃ§eneÄŸi ile ilgili Ã¶nemli bir nokta: Bu Ã¶zellik, Ã¶zellikle deneysel kÃ¼tÃ¼phaneler sÃ¶z konusu olduÄŸunda oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r. HenÃ¼z mevcut olmayan iÅŸlevsellikler sunmalarÄ±na sÄ±kÃ§a raÄŸmen, bu kÃ¼tÃ¼phaneler genellikle Kaggle ortamÄ±na dahil edilmez; bu nedenle, kodunuzda bÃ¶yle bir kÃ¼tÃ¼phaneyi kullanmak istiyorsanÄ±z, aÅŸaÄŸÄ±da gÃ¶sterildiÄŸi gibi veri seti olarak iÃ§e aktarabilirsiniz:

1. Datasets (Veri Setleri) sayfasÄ±na gidin ve â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±klayÄ±n.
2. GitHub simgesini seÃ§in.
3. Depo baÄŸlantÄ±sÄ±nÄ± ve veri seti iÃ§in baÅŸlÄ±ÄŸÄ± girin.
4. SaÄŸ alt kÃ¶ÅŸedeki â€œCreateâ€ (OluÅŸtur) butonuna tÄ±klayÄ±n.

![](im/1008.png)

â€œCreateâ€ (OluÅŸtur) butonunun yanÄ±nda bir de â€œPrivateâ€ (Ã–zel) olarak iÅŸaretlenmiÅŸ baÅŸka bir buton vardÄ±r. VarsayÄ±lan olarak oluÅŸturduÄŸunuz herhangi bir veri seti Ã¶zeldir: yalnÄ±zca siz, yani veri setinin yaratÄ±cÄ±sÄ±, onu gÃ¶rÃ¼ntÃ¼leyip dÃ¼zenleyebilirsiniz. Veri seti oluÅŸturma aÅŸamasÄ±nda bu ayarÄ± varsayÄ±lan hÃ¢lde bÄ±rakmak ve yalnÄ±zca daha sonraki bir aÅŸamada veri setini halka aÃ§mak (ya belirli bir katkÄ±da bulunanlar listesi iÃ§in ya da herkes iÃ§in) muhtemelen iyi bir fikirdir.

Kaggleâ€™Ä±n popÃ¼ler bir platform olduÄŸunu ve birÃ§ok kiÅŸinin veri setlerini â€“ Ã¶zel olanlar da dahil â€“ yÃ¼klediÄŸini unutmayÄ±n; bu nedenle, veri setiniz iÃ§in genel olmayan bir baÅŸlÄ±k dÃ¼ÅŸÃ¼nmeye Ã§alÄ±ÅŸÄ±n. Bu, veri setinizin gerÃ§ekten fark edilme ÅŸansÄ±nÄ± artÄ±racaktÄ±r.

TÃ¼m adÄ±mlarÄ± tamamlayÄ±p â€œCreateâ€ (OluÅŸtur) butonuna tÄ±kladÄ±ÄŸÄ±nÄ±zda, voilÃ ! Ä°lk veri setiniz hazÄ±r. ArdÄ±ndan â€œDataâ€ sekmesine gidebilirsiniz:

![](im/1009.png)

YukarÄ±daki ekran gÃ¶rÃ¼ntÃ¼sÃ¼, veri setinizle ilgili saÄŸlayabileceÄŸiniz farklÄ± bilgileri gÃ¶stermektedir; saÄŸladÄ±ÄŸÄ±nÄ±z bilgi ne kadar Ã§ok olursa, kullanÄ±labilirlik indeksi o kadar yÃ¼ksek olur. Bu indeks, veri setinizin ne kadar iyi tanÄ±mlandÄ±ÄŸÄ±nÄ± Ã¶zetleyen sentetik bir Ã¶lÃ§Ã¼dÃ¼r. YÃ¼ksek kullanÄ±labilirlik indeksine sahip veri setleri, arama sonuÃ§larÄ±nda daha Ã¼st sÄ±ralarda gÃ¶rÃ¼nÃ¼r. Her veri seti iÃ§in kullanÄ±labilirlik indeksi, dokÃ¼mantasyon seviyesi, Notebooks gibi ilgili kamuya aÃ§Ä±k iÃ§eriklerin referans olarak bulunabilirliÄŸi, dosya tÃ¼rleri ve temel meta verilerin kapsanmasÄ± gibi Ã§eÅŸitli faktÃ¶rlere dayanÄ±r.

Ä°lke olarak, yukarÄ±daki gÃ¶rselde gÃ¶sterilen tÃ¼m alanlarÄ± doldurmak zorunda deÄŸilsiniz; yeni oluÅŸturduÄŸunuz veri seti bunlar olmadan da tamamen kullanÄ±labilir (ve eÄŸer Ã¶zel bir veri seti ise, muhtemelen Ã¶nemsemezsiniz; sonuÃ§ta iÃ§eriÄŸini siz biliyorsunuz). Ancak, topluluk gÃ¶rgÃ¼ kurallarÄ±, veri setlerinizi halka aÃ§tÄ±ÄŸÄ±nÄ±zda bilgileri doldurmanÄ±zÄ± Ã¶nerir: ne kadar Ã§ok bilgi belirtirseniz, veri baÅŸkalarÄ± iÃ§in o kadar kullanÄ±ÅŸlÄ± olur.

### Gathering the data *(Veri toplama)*

Hukuki boyutlar dÄ±ÅŸÄ±nda, veri setlerinde saklayabileceÄŸiniz iÃ§erik tÃ¼rÃ¼ konusunda gerÃ§ek bir sÄ±nÄ±r yoktur: tablo verileri, gÃ¶rseller, metin; eÄŸer boyut gereksinimlerine uyuyorsa, bunlarÄ± saklayabilirsiniz. Bu, diÄŸer kaynaklardan elde edilen verileri de kapsar; yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihte popÃ¼ler veri setleri arasÄ±nda hashtag veya konuya gÃ¶re toplanmÄ±ÅŸ tweetler yer almaktadÄ±r:

![](im/1010.png)

Sosyal medyadan (Twitter, Reddit ve benzeri) veri toplamak iÃ§in kullanÄ±lan farklÄ± Ã§erÃ§evelerin tartÄ±ÅŸÄ±lmasÄ±, bu kitabÄ±n kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r.

> **Andrew MaranhÃ£o**
> 
> [https://www.kaggle.com/andrewmvd](https://www.kaggle.com/andrewmvd)
> 
> 
> 
> Andrew MaranhÃ£o (diÄŸer adÄ±yla Larxel), Datasets Grandmaster (yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± sÄ±rada Datasetsâ€™te bir numara) ve SÃ£o Pauloâ€™daki Hospital Albert Einsteinâ€™da KÄ±demli Veri Bilimci, bize Datasets baÅŸarÄ±sÄ±na nasÄ±l ulaÅŸtÄ±ÄŸÄ±nÄ±, veri seti oluÅŸturma ipuÃ§larÄ±nÄ± ve Kaggleâ€™daki genel deneyimlerini anlattÄ±.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Genellikle en sevdiÄŸim alan tÄ±bbi gÃ¶rÃ¼ntÃ¼lemedir. Hem iÅŸimle hem de amacÄ±mla Ã¶rtÃ¼ÅŸÃ¼yor. TÄ±bbi yarÄ±ÅŸmalarda NLP dil ile sÄ±nÄ±rlÄ±dÄ±r, tablo verileri hastaneler arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±k gÃ¶sterir, fakat gÃ¶rÃ¼ntÃ¼leme Ã§oÄŸunlukla aynÄ±dÄ±r; bu nedenle bu baÄŸlamda yapÄ±lan herhangi bir geliÅŸme, dÃ¼nya genelinde birÃ§ok Ã¼lke iÃ§in fayda saÄŸlayabilir ve bu etki potansiyelini seviyorum. AyrÄ±ca NLP ve tablo verilerini de severim, ama sanÄ±rÄ±m bu oldukÃ§a standart bir tercih.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸmayÄ± ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemleri anlatÄ±r mÄ±sÄ±nÄ±z?**
> 
> Bir tÃ¼berkÃ¼loz tespit yarÄ±ÅŸmasÄ±nda, yaklaÅŸÄ±k 1.000 rÃ¶ntgen gÃ¶rÃ¼ntÃ¼sÃ¼ vardÄ±; bu sayÄ±, hastalÄ±ÄŸÄ±n tÃ¼m belirtilerini yakalamak iÃ§in oldukÃ§a kÃ¼Ã§Ã¼ktÃ¼. Bunu telafi etmek iÃ§in iki fikir geliÅŸtirdim:
> 
> 
> 
> 1. DÄ±ÅŸ veri ile pnÃ¶moni tespiti iÃ§in Ã¶n eÄŸitim (~20k gÃ¶rÃ¼ntÃ¼), Ã§Ã¼nkÃ¼ pnÃ¶moni tÃ¼berkÃ¼loz ile karÄ±ÅŸtÄ±rÄ±labilir.
> 
> 2. AkciÄŸer anomalilerinin Ã§ok etiketli sÄ±nÄ±flandÄ±rmasÄ± (~600k gÃ¶rÃ¼ntÃ¼) Ã¼zerinde Ã¶n eÄŸitim ve basit bir SSD ile sÄ±nÄ±flandÄ±rma etiketlerinin bounding box anotasyonlarÄ±nÄ± oluÅŸturmak iÃ§in grad-CAM kullanÄ±mÄ±.
> 
> 
> 
> SonuÃ§ta, bu iki yaklaÅŸÄ±mÄ±n basit bir karÄ±ÅŸÄ±mÄ±, ikinci sÄ±radaki takÄ±mÄ±n sonucuna gÃ¶re %22 daha iyi bir performans saÄŸladÄ±. Bu yarÄ±ÅŸma, yaklaÅŸÄ±k 100 takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ± bir tÄ±bbi kongrede gerÃ§ekleÅŸti.
> 
> 
> 
> **Dataset Grandmaster oldunuz ve Datasetsâ€™te 1 numara oldunuz. Veri setleri iÃ§in konu seÃ§imi, veri bulma, toplama ve yayÄ±mlama sÃ¼reciniz nasÄ±l iÅŸliyor?**
> 
> Bu bÃ¼yÃ¼k bir soru; parÃ§alar hÃ¢linde aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m:
> 
> 
> 
> 1. **Kendinize bir amaÃ§ belirleyin**
> 
>    Konu seÃ§erken aklÄ±mda tuttuÄŸum ilk ÅŸey, bunu yapmamÄ±n temel nedenidir. Derin bir amaÃ§ olduÄŸunda, mÃ¼kemmel veri setleri bir sonuÃ§ olarak ortaya Ã§Ä±kar, hedef olarak deÄŸil.
> 
> 
> 
> 2. **Harika bir veri seti, harika bir sorunun vÃ¼cut bulmuÅŸ hÃ¢lidir**
> 
>    En iyi veri setlerinde ortak temalar:
> 
> 
> 
> * Cesur ve ilgili bir soru, bÃ¼yÃ¼k potansiyele sahip
> 
> * Veriler iyi toplanmÄ±ÅŸ, kalite kontrolÃ¼ yapÄ±lmÄ±ÅŸ ve iyi belgelenmiÅŸ
> 
> * Mevcut donanÄ±m iÃ§in yeterli veri ve Ã§eÅŸitlilik
> 
> * Veriye sÃ¼rekli katkÄ±da bulunan aktif bir topluluk
> 
> 
> 
> 3. **Sadece baÅŸarÄ±ya odaklanmayÄ±n; baÅŸarÄ± iÃ§in sÃ¼reci oluÅŸturun**
> 
>    Kalite, nicelikten Ã§ok daha Ã¶nemlidir. Grandmaster olmak iÃ§in sadece 15 veri setine ihtiyacÄ±nÄ±z vardÄ±r ve Ã¶ne Ã§Ä±kan veri setleri az ve iyi hazÄ±rlanmÄ±ÅŸ olmalÄ±dÄ±r. AyrÄ±ca veri setlerinin bakÄ±m ve sÃ¼rekli geliÅŸtirme gerektirdiÄŸini unutmayÄ±n. Topluluk desteÄŸi de Ã§ok Ã¶nemlidir; veri setinizi analiz edenlerin ihtiyaÃ§larÄ±nÄ± ve seÃ§imlerini anlamak, Ã¶n iÅŸleme adÄ±mlarÄ±nÄ±zÄ± ve belgelerinizi geliÅŸtirebilir.
> 
> 
> 
> **Ã–rnek sÃ¼reÃ§:**
> 
> Sosyal refahÄ± artÄ±rmak istiyorsunuz â†’ hedef: Ä±rksal eÅŸitlik â†’ konular: Black Lives Matter hareketi â†’ soru: Milyonlarca sesin ne dediÄŸini nasÄ±l anlayabilirim? â†’ veri tÃ¼rÃ¼: NLP â†’ veri toplama: haber makaleleri, YouTube yorumlarÄ±, tweetler â†’ Ã¶n iÅŸleme ve anonimleÅŸtirme â†’ yayÄ±nlama â†’ topluluk desteÄŸi ve geliÅŸtirme.
> 
> 
> 
> 4. **Ä°yi iÅŸ yapmak, kontrolÃ¼nÃ¼zde olan tek ÅŸeydir**
> 
>    Grandmaster olmanÄ±zÄ± baÅŸkalarÄ± saÄŸlar; oylar her zaman Ã§abaya veya etkiye dÃ¶nÃ¼ÅŸmez. Ã–nemli olan sizin Ã§abanÄ±z, Ã¶ÄŸrenmeniz ve denemenizdir.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz araÃ§lar/lisanslar nelerdir?**
> 
> LightGBM, CatBoost, Optuna, Streamlit, Gradio, FastAPI, Plotly, PyTorch gibi kÃ¼tÃ¼phaneleri Ã¶neriyor. AyrÄ±ca, kendi Ã§Ã¶zÃ¼mlerinizi uygulamak, derinlemesine bilgi edinmek aÃ§Ä±sÄ±ndan Ã§ok deÄŸerli.
> 
> 
> 
> **Deneyimsiz Kagglers neyi sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rÄ±r?**
> 
> 
> 
> * YarÄ±ÅŸmanÄ±n sonunda bilgiyi tam olarak absorbe etmek
> 
> * BitmiÅŸ yarÄ±ÅŸmalarda kazanan Ã§Ã¶zÃ¼mleri tekrar etmek
> 
> 
> 
> **Kaggle kariyerinize nasÄ±l katkÄ± saÄŸladÄ±?**
> 
> Kaggle bilgi, deneyim ve portfÃ¶y kazandÄ±rdÄ±. Ä°lk veri bilimi iÅŸim bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Kaggle ve DrivenData yarÄ±ÅŸmalarÄ± sayesinde oldu.
> 
> 
> 
> **PortfÃ¶yÃ¼nÃ¼zÃ¼ potansiyel iÅŸverenlere gÃ¶stermek iÃ§in Kaggle deneyimlerinizi kullandÄ±nÄ±z mÄ±?**
> 
> Kesinlikle. Ä°lk iÅŸimi Kaggle portfÃ¶yÃ¼ sayesinde aldÄ±m. PortfÃ¶y, eÄŸitim geÃ§miÅŸinden daha iyi veri bilimi bilgisi ve deneyimi temsil eder.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musunuz? Kaggle ile karÅŸÄ±laÅŸtÄ±rmasÄ± nasÄ±l?**
> 
> DrivenData ve AICrowdâ€™u da kullanÄ±yorum. Kaggle daha bÃ¼yÃ¼k ve aktif bir topluluk sunuyor, donanÄ±m ve veri/Notebook Ã¶zellikleri ile en iyi seÃ§enek. Ancak diÄŸer platformlar da ilginÃ§ ve Ã§eÅŸitli zorluklar sunuyor.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya girerken en Ã¶nemli ÅŸey nedir?**
> 
> GeliÅŸim odaklÄ±ysanÄ±z, ilginizi Ã§eken ve daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z bir konuyu seÃ§in. Derinlik ve Ã§eÅŸitlilik kritik; derinlik, odaklanarak ve en iyinizi vererek; Ã§eÅŸitlilik ise daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z veya farklÄ± yaptÄ±ÄŸÄ±nÄ±z ÅŸeyleri deneyerek elde edilir.

### Working with datasets *(Veri setleriyle Ã§alÄ±ÅŸma)*

Bir veri seti oluÅŸturduktan sonra, muhtemelen onu analizlerinizde kullanmak isteyeceksiniz. Bu bÃ¶lÃ¼mde, bunu yapmanÄ±n farklÄ± yÃ¶ntemlerini ele alÄ±yoruz.

Muhtemelen en Ã¶nemli yÃ¶ntem, veri setinizi birincil kaynak olarak kullanacaÄŸÄ±nÄ±z bir Notebook baÅŸlatmaktÄ±r. Bunu yapmak iÃ§in veri seti sayfasÄ±na gidip ardÄ±ndan **New Notebook** Ã¼zerine tÄ±klayabilirsiniz.

![](im/1011.png)

Bunu yaptÄ±ktan sonra, Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![](im/1012.png)

Ä°ÅŸte bununla ilgili birkaÃ§ ipucu:

* AlfasayÄ±sal baÅŸlÄ±k otomatik olarak oluÅŸturulur; Ã¼zerine tÄ±klayarak dÃ¼zenleyebilirsiniz.
* SaÄŸ tarafta, **Data** altÄ±nda Notebookâ€™unuza baÄŸlÄ± veri kaynaklarÄ±nÄ±n listesini gÃ¶rÃ¼rsÃ¼nÃ¼z; seÃ§tiÄŸim veri setine **../input/** veya **/kaggle/input/** Ã¼zerinden eriÅŸilebilir.
* AÃ§Ä±lÄ±ÅŸ bloÄŸu (iÃ§e aktarÄ±lan paketler, aÃ§Ä±klayÄ±cÄ± yorumlar ve mevcut dosyalarÄ±n listesi) yeni bir Python Notebookâ€™a otomatik olarak eklenir.

Bu temel kurulumla, analiziniz iÃ§in bir Notebook yazmaya baÅŸlayabilir ve veri setinizi veri kaynaÄŸÄ± olarak kullanabilirsiniz. Notebookâ€™larÄ± daha ayrÄ±ntÄ±lÄ± olarak **BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±ndan Yararlanmak** kÄ±smÄ±nda ele alacaÄŸÄ±z.

### Using Kaggle Datasets in Google Colab *(Google Colabâ€™da Kaggle veri setlerini kullanma)*

Kaggle Notebookâ€™larÄ± Ã¼cretsizdir, ancak sÄ±nÄ±rsÄ±z deÄŸildir (buna BÃ¶lÃ¼m 4â€™te daha ayrÄ±ntÄ±lÄ± deÄŸineceÄŸiz) ve karÅŸÄ±laÅŸabileceÄŸiniz ilk sÄ±nÄ±rlama muhtemelen **zaman limitidir**. PopÃ¼ler bir alternatif, tamamen bulutta Ã§alÄ±ÅŸan Ã¼cretsiz bir Jupyter Notebook ortamÄ± olan **Google Colab**â€™a geÃ§mektir: [https://colab.research.google.com](https://colab.research.google.com).

HesaplamalarÄ± Colabâ€™a taÅŸÄ±dÄ±ktan sonra bile Kaggle veri setlerine eriÅŸmek isteyebiliriz; bu yÃ¼zden onlarÄ± Colabâ€™a aktarmak oldukÃ§a kullanÄ±ÅŸlÄ± bir Ã¶zelliktir. Bu bÃ¶lÃ¼mÃ¼n geri kalanÄ±nda, Kaggle Datasetsâ€™i Colab Ã¼zerinden kullanmak iÃ§in gerekli adÄ±mlarÄ± ele alacaÄŸÄ±z.

Ä°lk olarak, Kaggleâ€™a zaten kayÄ±tlÄ± olduÄŸumuzu varsayarak, **API token** (giriÅŸ oturumu, kullanÄ±cÄ± kimliÄŸi, yetkiler vb. iÃ§in gÃ¼venlik bilgilerini iÃ§eren eriÅŸim belirteci) oluÅŸturmak iÃ§in hesap sayfasÄ±na gideriz:

1. HesabÄ±nÄ±za gidin: [https://www.kaggle.com/USERNAME/account](https://www.kaggle.com/USERNAME/account)

**Create New API Token** butonuna tÄ±klayÄ±n.

![](im/1013.png)

Bir **kaggle.json** dosyasÄ± oluÅŸturulacak; bu dosya kullanÄ±cÄ± adÄ±nÄ±zÄ± ve API tokenâ€™Ä±nÄ±zÄ± iÃ§erir.

2. Google Driveâ€™Ä±nÄ±zda **Kaggle** adÄ±nda bir klasÃ¶r oluÅŸturun ve **.json** dosyasÄ±nÄ± bu klasÃ¶re yÃ¼kleyin.

![](im/1014.png)

3. Ä°ÅŸlem tamamlandÄ±ktan sonra, yeni bir Colab defteri oluÅŸturmanÄ±z ve Google Driveâ€™Ä±nÄ±zÄ± baÄŸlamanÄ±z gerekir. Bunu yapmak iÃ§in defterde aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rÄ±n:

```python
from google.colab import drive
drive.mount('/content/gdrive')
```

4. URL isteminden yetkilendirme kodunu alÄ±n ve aÃ§Ä±lan boÅŸ kutuya girin, ardÄ±ndan aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rarak `.json` yapÄ±landÄ±rma dosyasÄ±nÄ±n yolunu belirtin:

```python
import os
# content/gdrive/My Drive/Kaggle is the path where kaggle.json is
# present in the Google Drive
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
# change the working directory
%cd /content/gdrive/My Drive/Kaggle
# check the present working directory using the pwd command
```

5. ArtÄ±k veri setini indirebiliriz. Bunun iÃ§in Kaggleâ€™daki veri seti sayfasÄ±na gidin, **New Notebook** yanÄ±ndaki Ã¼Ã§ noktaya tÄ±klayÄ±n ve **Copy API command** seÃ§eneÄŸini seÃ§in:

![alt text](im/1015.png)

6. Veri setini indirmek iÃ§in API komutunu Ã§alÄ±ÅŸtÄ±rÄ±n (komutlarÄ±n detaylarÄ±yla ilgilenenler resmi dokÃ¼mantasyona bakabilir: [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)):

```python
!kaggle datasets download -d ajaypalsinghlo/world-happinessreport-2021
```
7. Veri seti, Kaggle klasÃ¶rÃ¼ne bir .zip arÅŸivi olarak indirilecektir â€“ arÅŸivi aÃ§Ä±n ve kullanÄ±ma hazÄ±r hale gelmiÅŸ olacaktÄ±r.

YukarÄ±daki listeden de gÃ¶rebileceÄŸiniz gibi, bir Kaggle veri setini Colabâ€™da kullanmak oldukÃ§a basit bir sÃ¼reÃ§tir â€“ tek ihtiyacÄ±nÄ±z olan bir API tokenâ€™Ä±dÄ±r ve bu geÃ§iÅŸ size Kaggleâ€™Ä±n saÄŸladÄ±ÄŸÄ±ndan daha fazla GPU saatini kullanma imkÃ¢nÄ± verir.

### Legal caveats *(Yasal uyarÄ±lar)*

Sadece bazÄ± verileri Kaggleâ€™a yÃ¼kleyebilmeniz, bunu yapmanÄ±z gerektiÄŸi anlamÄ±na gelmez. MÃ¼kemmel bir Ã¶rnek, **People of Tinder** veri setidir. 2017â€™de bir geliÅŸtirici, Tinder APIâ€™sini kullanarak web sitesinden yarÄ±-Ã¶zel profilleri Ã§ekmiÅŸ ve veriyi Kaggleâ€™a yÃ¼klemiÅŸti. Bu durum ortaya Ã§Ä±ktÄ±ktan sonra, Kaggle veri setini kaldÄ±rdÄ±. Tam hikÃ¢yeyi ÅŸuradan okuyabilirsiniz: [Forbes makalesi](https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454).

Genel olarak, Kaggleâ€™a herhangi bir ÅŸey yÃ¼klemeden Ã¶nce kendinize ÅŸu iki soruyu sorun:

1. **Telif hakkÄ± aÃ§Ä±sÄ±ndan izinli mi?** LisanslarÄ± her zaman kontrol edin. ÅÃ¼phe durumunda [Open Definition Guide](https://opendefinition.org/guide/data/) veya Kaggle ile iletiÅŸime geÃ§ebilirsiniz.
2. **Bu veri setiyle ilgili gizlilik riskleri var mÄ±?** Belirli bilgileri paylaÅŸmak, teknik olarak yasadÄ±ÅŸÄ± olmasa da, baÅŸka bir kiÅŸinin gizliliÄŸine zarar verebilir.

Bu sÄ±nÄ±rlamalar aslÄ±nda saÄŸduyuya dayanmaktadÄ±r, bu yÃ¼zden Kaggleâ€™daki Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± engellemesi pek olasÄ± deÄŸildir.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle platformunda verileri depolamanÄ±n ve kullanmanÄ±n standart yolu olan **Kaggle Datasets**â€™i tanÄ±ttÄ±k. Veri seti oluÅŸturmayÄ±, Kaggle dÄ±ÅŸÄ±ndaki ortamlarda Ã§alÄ±ÅŸma yÃ¶ntemlerini ve en Ã¶nemli iÅŸlevi olan **veri setini Notebookâ€™ta kullanmayÄ±** ele aldÄ±k. Bu, bir sonraki bÃ¶lÃ¼mde odaklanacaÄŸÄ±mÄ±z **Kaggle Notebooks** konusuna geÃ§iÅŸ iÃ§in gÃ¼zel bir kÃ¶prÃ¼ oluÅŸturuyor.

---

## Chapter 3: Working and Learning with Kaggle Notebooks *(BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek)*

Kaggle Notebooks â€” yakÄ±n zamana kadar **Kernels** olarak adlandÄ±rÄ±lÄ±yordu â€” tarayÄ±cÄ± Ã¼zerinden Ã§alÄ±ÅŸan ve Ã¼cretsiz olan **Jupyter Notebook**â€™lardÄ±r. Bu, internet baÄŸlantÄ±sÄ± olan herhangi bir cihazdan deneylerinizi Ã§alÄ±ÅŸtÄ±rabileceÄŸiniz anlamÄ±na gelir; ancak mobil telefondan daha bÃ¼yÃ¼k bir cihaz kullanmak muhtemelen daha iyi olacaktÄ±r. OrtamÄ±n teknik Ã¶zellikleri (yazÄ±m tarihi itibarÄ±yla) Kaggle web sitesinden alÄ±nmÄ±ÅŸtÄ±r; en gÃ¼ncel sÃ¼rÃ¼mÃ¼ **[https://www.kaggle.com/docs/notebooks](https://www.kaggle.com/docs/notebooks)** adresinden doÄŸrulanabilir:

* CPU/GPU iÃ§in 12 saat Ã§alÄ±ÅŸma sÃ¼resi, TPU iÃ§in 9 saat
* 20 GB otomatik kaydedilen disk alanÄ± (/kaggle/working)
* Ek geÃ§ici disk alanÄ± ( /kaggle/working dÄ±ÅŸÄ±nda) â€” bu alan mevcut oturum dÄ±ÅŸÄ±nda kaydedilmez

**CPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

**GPU Ã¶zellikleri:**

* 2 CPU Ã§ekirdeÄŸi
* 13 GB RAM

**TPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

Bu bÃ¶lÃ¼mde ele alacaÄŸÄ±mÄ±z konular:

* Notebook kurulumunu yapmak
* Notebookâ€™unuzu Ã§alÄ±ÅŸtÄ±rmak
* Notebookâ€™larÄ± GitHubâ€™a kaydetmek
* Notebookâ€™lardan en iyi ÅŸekilde faydalanmak
* Kaggle Learn kurslarÄ±

Hadi baÅŸlayalÄ±m. Ä°lk yapmamÄ±z gereken, bir Notebookâ€™un nasÄ±l kurulacaÄŸÄ±nÄ± Ã¶ÄŸrenmek.

### Setting up a Notebook *(Bir defter oluÅŸturma)*

Bir Notebook oluÅŸturmanÄ±n iki temel yÃ¶ntemi vardÄ±r: **ana sayfadan** veya **bir Dataset Ã¼zerinden**.

Ä°lk yÃ¶ntemi kullanmak iÃ§in:

1. [https://www.kaggle.com/](https://www.kaggle.com/) adresindeki ana sayfada, sol menÃ¼deki **Code** bÃ¶lÃ¼mÃ¼ne gidin.
2. ArdÄ±ndan **+ New Notebook** butonuna tÄ±klayÄ±n.

Bu yÃ¶ntem, kendi veri setinizi yÃ¼klemeyi iÃ§eren bir deneme planlÄ±yorsanÄ±z tercih edilen yÃ¶ntemdir.

![alt text](im/1016.png)

Alternatif olarak, ilgilendiÄŸiniz Datasetâ€™in sayfasÄ±na gidip oradaki **New Notebook** butonuna tÄ±klayabilirsiniz; bu yÃ¶ntemi bir Ã¶nceki bÃ¶lÃ¼mde gÃ¶rmÃ¼ÅŸtÃ¼k.

![alt text](im/1017.png)

Hangi yÃ¶ntemi seÃ§erseniz seÃ§in, **New Notebook** butonuna tÄ±kladÄ±ktan sonra Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![alt text](im/1018.png)

YukarÄ±da gÃ¶sterilen yeni Notebook sayfasÄ±nÄ±n saÄŸ tarafÄ±nda, ayarlanabilecek birkaÃ§ farklÄ± ayar bulunmaktadÄ±r:

![alt text](im/1019.png)

AyarlarÄ± kÄ±saca ele alalÄ±m:

1. **Kodlama Dili (Language)**:
   Kaggle ortamÄ±, yazÄ±ldÄ±ÄŸÄ± tarihte yalnÄ±zca Python ve R dillerini destekliyor. Yeni bir Notebook varsayÄ±lan olarak Python ile aÃ§Ä±lÄ±r. R kullanmak isterseniz aÃ§Ä±lÄ±r menÃ¼den Râ€™yi seÃ§ebilirsiniz.

2. **Ortam (Environment)**:
   Bu seÃ§enek, Notebookâ€™un hangi Docker ortamÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirler.

   * **Latest Docker**: En gÃ¼ncel ortamÄ± kullanÄ±r; hÄ±zlÄ± gÃ¼ncellemeler alÄ±rsÄ±nÄ±z ama baÄŸÄ±mlÄ±lÄ±klar bozulabilir (riskli).
   * **Original Kaggle environment**: Kaggle tarafÄ±ndan saÄŸlanan orijinal ortamÄ± kullanÄ±r (gÃ¼venli ve varsayÄ±lan).

3. **HÄ±zlandÄ±rÄ±cÄ± (Accelerator)**:
   Kodun hangi donanÄ±mda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± seÃ§menizi saÄŸlar:

   * **CPU**: HÄ±zlandÄ±rmasÄ±z
   * **GPU**: Derin Ã¶ÄŸrenme uygulamalarÄ± iÃ§in gereklidir
   * **TPU**: TPUâ€™ya taÅŸÄ±mak iÃ§in veri iÅŸleme ve kodda daha kapsamlÄ± deÄŸiÅŸiklik gerekir

   CPU, GPU veya TPU arasÄ±nda geÃ§iÅŸ yapabilirsiniz; fakat geÃ§iÅŸ yaptÄ±ÄŸÄ±nÄ±zda ortam yeniden baÅŸlatÄ±lÄ±r ve tÃ¼m kodu baÅŸtan Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekir.

4. **Ä°nternet (Internet) AÃ§ma/Kapama**:
   Ä°nternete eriÅŸimi aÃ§Ä±p kapatmanÄ±zÄ± saÄŸlar. Ã–rneÄŸin, ek paket yÃ¼klemek gerektiÄŸinde internet aÃ§Ä±k olmalÄ±dÄ±r. BazÄ± yarÄ±ÅŸmalarda, teslim sÄ±rasÄ±nda internetin kapalÄ± olmasÄ± zorunludur.

AyrÄ±ca, mevcut bir Notebookâ€™u (kendinizin veya baÅŸkasÄ±nÄ±n oluÅŸturduÄŸu) **kopyalayÄ±p dÃ¼zenleyebilirsiniz**. Bunun iÃ§in Notebook sayfasÄ±nÄ±n saÄŸ Ã¼stÃ¼ndeki **Copy and Edit** butonuna tÄ±klamanÄ±z yeterlidir. Kaggleâ€™da bu iÅŸlem **forking** olarak adlandÄ±rÄ±lÄ±r.

![alt text](im/1020.png)

> Bir gÃ¶rgÃ¼ notu: EÄŸer daha Ã¶nce bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ±ysanÄ±z, sÄ±ralama tablosunun (leaderboard) iyi puan alan Notebookâ€™larÄ±n kopyalarÄ±yla (forks of forks) dolu olduÄŸunu fark etmiÅŸsinizdir. BaÅŸkasÄ±nÄ±n Ã§alÄ±ÅŸmasÄ± Ã¼zerine inÅŸa etmek yanlÄ±ÅŸ deÄŸildir; ancak bunu yaparken **orijinal yazara oy vermeyi (upvote) ve referans alÄ±nan Ã§alÄ±ÅŸmanÄ±n sahibine aÃ§Ä±kÃ§a kredi vermeyi** unutmayÄ±n.

OluÅŸturduÄŸunuz bir Notebook varsayÄ±lan olarak **Ã¶zel**dir (sadece siz gÃ¶rebilirsiniz). EÄŸer baÅŸkalarÄ±nÄ±n eriÅŸmesini istiyorsanÄ±z iki seÃ§enek vardÄ±r:

1. **Ä°ÅŸbirlikÃ§ileri eklemek (adding collaborators):** Sadece aÃ§Ä±kÃ§a eklenen kullanÄ±cÄ±lar Notebookâ€™u gÃ¶rebilir veya dÃ¼zenleyebilir.
2. **Notebookâ€™u herkese aÃ§Ä±k yapmak (making public):** Bu durumda herkes Notebookâ€™u gÃ¶rebilir.

### Running your Notebook *(Defterinizi Ã§alÄ±ÅŸtÄ±rma)*

TÃ¼m kodlamalar tamamlandÄ±, Notebook sorunsuz Ã§alÄ±ÅŸÄ±yor gibi gÃ¶rÃ¼nÃ¼yor ve Ã§alÄ±ÅŸtÄ±rmaya hazÄ±rsÄ±nÄ±z. Bunu yapmak iÃ§in, Notebook sayfanÄ±zÄ±n **saÄŸ Ã¼st kÃ¶ÅŸesine** gidin ve **Save Version** (SÃ¼rÃ¼mÃ¼ Kaydet) dÃ¼ÄŸmesine tÄ±klayÄ±n.

![](im/1021.png)

**Save & Run All** genellikle tÃ¼m scripti Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r, ancak **Quick Save** seÃ§eneÄŸi de vardÄ±r; bu, script henÃ¼z gÃ¶nderime hazÄ±r olmadan Ã¶nce ara bir sÃ¼rÃ¼mÃ¼ kaydetmek iÃ§in kullanÄ±labilir.

![](im/1022.png)

Scriptinizi baÅŸlattÄ±ktan sonra, sol alt kÃ¶ÅŸeye gidip **Active Events** (Aktif Etkinlikler) butonuna tÄ±klayabilirsiniz. Bu bÃ¶lÃ¼m, Ã§alÄ±ÅŸmakta olan Notebook sÃ¼rÃ¼mlerinizin durumunu ve ilerlemesini izlemenizi saÄŸlar.

![](im/1023.png)

Bu ÅŸekilde, Notebookâ€™larÄ±nÄ±zÄ±n Ã§alÄ±ÅŸma durumunu takip edebilirsiniz. Normal bir yÃ¼rÃ¼tme sÄ±rasÄ±nda **Running** mesajÄ± gÃ¶rÃ¼nÃ¼r; aksi durumda **Failed** olarak gÃ¶rÃ¼ntÃ¼lenir.

EÄŸer herhangi bir nedenle (Ã¶rneÄŸin en gÃ¼ncel veriyi kullanmayÄ± unuttuÄŸunuzu fark ederseniz) Ã§alÄ±ÅŸan bir oturumu sonlandÄ±rmak isterseniz, **Active Events** altÄ±nda script giriÅŸinizin saÄŸ tarafÄ±ndaki Ã¼Ã§ noktaya tÄ±klayabilirsiniz. Bu iÅŸlem size aÅŸaÄŸÄ±daki ÅŸekilde bir aÃ§Ä±lÄ±r pencere (pop-up) gÃ¶sterecektir ve oturumu durdurmanÄ±za olanak tanÄ±r.

![](im/1024.png)

### Saving Notebooks to GitHub *(Defterleri GitHubâ€™a kaydetme)*

YakÄ±n zamanda eklenen bir Ã¶zellik (bkz. [https://www.kaggle.com/product-feedback/295170](https://www.kaggle.com/product-feedback/295170)), kodunuzu veya Notebookâ€™unuzu GitHub sÃ¼rÃ¼m kontrol deposuna ([https://github.com/](https://github.com/)) kaydetmenize olanak tanÄ±r. Ã‡alÄ±ÅŸmanÄ±zÄ± hem **public** hem de **private** depolara kaydedebilirsiniz ve bu iÅŸlem, kodunuzun bir versiyonunu kaydettiÄŸinizde otomatik olarak gerÃ§ekleÅŸir.

Bu Ã¶zellik, hem Kaggle takÄ±m arkadaÅŸlarÄ±nÄ±zla Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± paylaÅŸmak hem de Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± daha geniÅŸ bir kitleye sergilemek iÃ§in oldukÃ§a faydalÄ± olabilir.

Bu Ã¶zelliÄŸi etkinleÅŸtirmek iÃ§in:

1. Notebookâ€™unuzu aÃ§Ä±n.
2. Ãœst menÃ¼den **File** menÃ¼sÃ¼ne gidin.
3. **Link to GitHub** seÃ§eneÄŸini tÄ±klayÄ±n.

![](im/1025.png)

Bu seÃ§eneÄŸi seÃ§tikten sonra, GitHub hesabÄ±nÄ±zÄ± Notebook ile baÄŸlamanÄ±z gerekecek. Ä°lk kez baÄŸlama iÅŸlemi yaptÄ±ÄŸÄ±nÄ±zda, aÃ§Ä±kÃ§a **baÄŸlantÄ± izinleri** sorulacaktÄ±r. Sonraki yeni Notebookâ€™larda ise bu iÅŸlem otomatik olarak gerÃ§ekleÅŸtirilecektir.

![](im/1026.png)

Notebookâ€™unuzu ancak baÄŸladÄ±ktan sonra, kaydettiÄŸinizde Ã§alÄ±ÅŸmanÄ±zÄ± seÃ§tiÄŸiniz bir GitHub deposuyla senkronize etme izniniz olur.

![](im/1027.png)

Bir depo ve dal (branch) seÃ§tikten sonra, Ã§alÄ±ÅŸmanÄ±zÄ±n farklÄ± geliÅŸtirme aÅŸamalarÄ±nÄ± saklamanÄ±za olanak tanÄ±r ve depoya gÃ¶ndereceÄŸiniz dosyanÄ±n adÄ±nÄ± deÄŸiÅŸtirebilir ve commit mesajÄ±nÄ± dÃ¼zenleyebilirsiniz.

ArtÄ±k belirli bir Notebookâ€™u GitHub ile senkronize etmek istemiyorsanÄ±z, tek yapmanÄ±z gereken Dosya menÃ¼sÃ¼nden **Unlink from GitHub** seÃ§eneÄŸini tÄ±klamaktÄ±r.

Son olarak, Kaggleâ€™Ä±n GitHub hesabÄ±nÄ±za baÄŸlanmasÄ±nÄ± tamamen durdurmak isterseniz, hesaplarÄ±nÄ±zÄ± ya Kaggleâ€™daki **My linked accounts** sayfasÄ±ndan ya da GitHubâ€™daki [ayarlar](https://github.com/settings/applications) sayfasÄ±ndan ayÄ±rabilirsiniz.

### Getting the most out of Notebooks *(Defterlerden en iyi ÅŸekilde yararlanma)*

Kaggle, belirli miktarda kaynaklarÄ± Ã¼cretsiz olarak saÄŸlar ve bu kotlar haftalÄ±k olarak sÄ±fÄ±rlanÄ±r. GPU ve TPU kullanÄ±mÄ± iÃ§in belli bir saat hakkÄ±nÄ±z vardÄ±r; TPU iÃ§in bu sÃ¼re 30 saattir, GPU iÃ§in ise haftadan haftaya deÄŸiÅŸen bir kota uygulanÄ±r (resmÃ® aÃ§Ä±klamayÄ± ve â€œfloatingâ€ kotalar politikasÄ±nÄ± [buradan](https://www.kaggle.com/product-feedback/173129) inceleyebilirsiniz).

Kendi kullanÄ±mÄ±nÄ±zÄ± her zaman profilinizden takip edebilirsiniz.

![](im/1028.png)

Ä°lk bakÄ±ÅŸta kaynak miktarlarÄ± bÃ¼yÃ¼k gÃ¶rÃ¼nebilir, ancak bu izlenim yanÄ±ltÄ±cÄ± olabilir; kotanÄ±zÄ± oldukÃ§a hÄ±zlÄ± bir ÅŸekilde tÃ¼ketmek kolaydÄ±r. Kaynak kullanÄ±mÄ±nÄ± kontrol etmenize yardÄ±mcÄ± olacak bazÄ± pratik Ã¶neriler:

* Kota sayacÄ± (GPU veya TPU gibi seÃ§tiÄŸiniz hÄ±zlandÄ±rÄ±cÄ±yÄ± ne kadar sÃ¼re kullandÄ±ÄŸÄ±nÄ±zÄ± Ã¶lÃ§en sayaÃ§) Notebookâ€™u baÅŸlattÄ±ÄŸÄ±nÄ±z anda Ã§alÄ±ÅŸmaya baÅŸlar.
* Bu nedenle, Ã¶ncelikle ayarlardan GPUâ€™nun devre dÄ±ÅŸÄ± olduÄŸundan emin olun (bkz. Åekil 3.6). Ã–nce temel kodu yazÄ±n, sÃ¶zdizimini kontrol edin ve yalnÄ±zca GPU gerektiren kod parÃ§alarÄ±nÄ± eklediÄŸinizde GPUâ€™yu etkinleÅŸtirin. HatÄ±rlatma: HÄ±zlandÄ±rÄ±cÄ±yÄ± deÄŸiÅŸtirdiÄŸinizde Notebook yeniden baÅŸlatÄ±lÄ±r.
* Kodun tamamÄ±nÄ± kÃ¼Ã§Ã¼k bir veri alt kÃ¼mesi Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmak genellikle iyi bir fikirdir; bÃ¶ylece Ã§alÄ±ÅŸtÄ±rma sÃ¼resini tahmin edebilir ve kotayÄ± aÅŸarak kodun Ã§Ã¶kmesi riskini en aza indirirsiniz.

Bazen Kaggleâ€™Ä±n Ã¼cretsiz olarak saÄŸladÄ±ÄŸÄ± kaynaklar, yapÄ±lacak iÅŸ iÃ§in yeterli olmayabilir ve daha gÃ¼Ã§lÃ¼ bir makineye geÃ§meniz gerekir. Ã–rneÄŸin, yakÄ±n zamanda yapÄ±lan bir tÃ¼mÃ¶r sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmasÄ±: [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data).

EÄŸer ham veriniz 100GBâ€™dan bÃ¼yÃ¼kse, ya gÃ¶rÃ¼ntÃ¼leri yeniden boyutlandÄ±rmalÄ±/aÅŸaÄŸÄ± Ã¶rneklemeli (bu model performansÄ±nÄ± olumsuz etkileyebilir) ya da yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼leri iÅŸleyebilecek bir ortamda model eÄŸitmelisiniz. BÃ¼tÃ¼n ortamÄ± kendiniz kurabilirsiniz (Ã¶rnek olarak, BÃ¶lÃ¼m 2â€™deki â€œGoogle Colabâ€™da Kaggle Datasets KullanÄ±mÄ±â€ kÄ±smÄ±na bakabilirsiniz) veya Notebooks Ã§erÃ§evesinde kalÄ±p, altyapÄ± makinesini deÄŸiÅŸtirebilirsiniz. Ä°ÅŸte burada Google Cloud AI Notebooks devreye girer.

### Upgrading to Google Cloud Platform (GCP) *(Google Cloud Platformâ€™a (GCP) yÃ¼kseltme)*

GCPâ€™ye (Google Cloud Platform) geÃ§menin bariz avantajÄ±, daha gÃ¼Ã§lÃ¼ donanÄ±ma eriÅŸim saÄŸlamaktÄ±r: Kaggle tarafÄ±ndan saÄŸlanan Tesla P100 GPU birÃ§ok uygulama iÃ§in yeterli olsa da performans aÃ§Ä±sÄ±ndan en Ã¼st seviye deÄŸildir ve 16 GB RAM de Ã¶zellikle bÃ¼yÃ¼k NLP modelleri veya yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼ iÅŸleme gibi kaynak yoÄŸun uygulamalarda sÄ±nÄ±rlayÄ±cÄ± olabilir. Ã‡alÄ±ÅŸtÄ±rma sÃ¼resindeki iyileÅŸme, geliÅŸtirme dÃ¶ngÃ¼sÃ¼nde daha hÄ±zlÄ± iterasyon imkÃ¢nÄ± saÄŸlarken, bunun bir maliyeti vardÄ±r: Ne kadar harcamaya hazÄ±r olduÄŸunuzu belirlemeniz gerekir. GÃ¼Ã§lÃ¼ bir makine ile veri iÅŸlemek sÃ¶z konusu olduÄŸunda zaman, kelimenin tam anlamÄ±yla paradÄ±r.

Notebookâ€™unuzu GCP ortamÄ±na taÅŸÄ±mak iÃ§in, saÄŸ taraftaki yan menÃ¼den **Upgrade to Google Cloud AI Notebooks** seÃ§eneÄŸine tÄ±klayÄ±n.

![](im/1029.png)

Åu ifadeyle karÅŸÄ±lanacaksÄ±nÄ±z:

![](im/1030.png)

â€œDevam Etâ€e tÄ±kladÄ±ÄŸÄ±nÄ±zda, faturalandÄ±rma seÃ§eneklerinizi yapÄ±landÄ±rmanÄ±z gereken Google Cloud Platform konsoluna yÃ¶nlendirileceksiniz. HatÄ±rlatma: GCP Ã¼cretsiz deÄŸildir. Ä°lk kez kullanÄ±yorsanÄ±z, gerekli adÄ±mlar boyunca size rehberlik edecek bir Ã¶ÄŸreticiyi (tutorial) tamamlamanÄ±z gerekecektir.

### One step beyond *(Bir adÄ±m Ã¶teye geÃ§mek)*

### Kaggle Learn courses *(Kaggle Learn kurslarÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 4: Leveraging Discussion Forums *(BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±nÄ± Etkin Kullanma)*

### How forums work *(Forumlar nasÄ±l Ã§alÄ±ÅŸÄ±r)*

### Example discussion approaches *(TartÄ±ÅŸma Ã¶rnekleri ve yaklaÅŸÄ±mlar)*

### Netiquette *(Ä°nternet gÃ¶rgÃ¼ kurallarÄ±)*

### Summary *(Ã–zet)*

---

# Part II: Sharpening Your Skills for Competitions *(BÃ¶lÃ¼m II: YarÄ±ÅŸmalar Ä°Ã§in Becerilerini GeliÅŸtirme)*

## Chapter 5: Competition Tasks and Metrics *(BÃ¶lÃ¼m 5: YarÄ±ÅŸma GÃ¶revleri ve Ã–lÃ§Ã¼tleri)*

### Evaluation metrics and objective functions *(DeÄŸerlendirme metrikleri ve hedef fonksiyonlar)*

### Basic types of tasks *(Temel gÃ¶rev tÃ¼rleri)*

#### Regression *(Regresyon)*

#### Classification *(SÄ±nÄ±flandÄ±rma)*

#### Ordinal *(SÄ±ralÄ± veriler)*

### The Meta Kaggle dataset *(Meta Kaggle veri seti)*

### Handling never-before-seen metrics *(Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerle baÅŸa Ã§Ä±kma)*

### Metrics for regression (standard and ordinal) *(Regresyon iÃ§in metrikler - standart ve sÄ±ralÄ±)*

#### Mean squared error (MSE) and RÂ² *(Ortalama kare hata (MSE) ve RÂ²)*

#### Root mean squared error (RMSE) *(KÃ¶k ortalama kare hata (RMSE))*

#### Root mean squared log error (RMSLE) *(KÃ¶k ortalama log kare hata (RMSLE))*

#### Mean absolute error (MAE) *(Ortalama mutlak hata (MAE))*

### Metrics for classification (label prediction and probability) *(SÄ±nÄ±flandÄ±rma metrikleri - etiket tahmini ve olasÄ±lÄ±k)*

#### Accuracy *(DoÄŸruluk)*

#### Precision and recall *(Kesinlik ve duyarlÄ±lÄ±k)*

#### The F1 score *(F1 skoru)*

#### Log loss and ROC-AUC *(Log kaybÄ± ve ROC-AUC)*

#### Matthews correlation coefficient (MCC) *(Matthews korelasyon katsayÄ±sÄ±)*

### Metrics for multi-class classification *(Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri)*

### Metrics for object detection problems *(Nesne tespiti problemleri iÃ§in metrikler)*

#### Intersection over union (IoU) *(KesiÅŸim/BirleÅŸim oranÄ±)*

#### Dice *(Dice katsayÄ±sÄ±)*

### Metrics for multi-label classification and recommendation problems *(Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri problemleri iÃ§in metrikler)*

#### MAP@K *(MAP@K metriÄŸi)*

### Optimizing evaluation metrics *(DeÄŸerlendirme metriklerini optimize etme)*

### Custom metrics and custom objective functions *(Ã–zel metrikler ve Ã¶zel hedef fonksiyonlarÄ±)*

### Post-processing your predictions *(Tahminleri sonradan iÅŸleme)*

### Predicted probability and its adjustment *(Tahmin edilen olasÄ±lÄ±ÄŸÄ±n ayarlanmasÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 6: Designing Good Validation *(BÃ¶lÃ¼m 6: Ä°yi Bir DoÄŸrulama Sistemi Tasarlama)*

### Snooping on the leaderboard *(Liderlik tablosunu gÃ¶zetlemek)*

### The importance of validation in competitions *(YarÄ±ÅŸmalarda doÄŸrulamanÄ±n Ã¶nemi)*

### Bias and variance *(Ã–nyargÄ± ve varyans)*

### Trying different splitting strategies *(FarklÄ± veri bÃ¶lme stratejilerini denemek)*

#### The basic train-test split *(Temel eÄŸitim-test bÃ¶lÃ¼nmesi)*

#### Probabilistic evaluation methods *(OlasÄ±lÄ±ksal deÄŸerlendirme yÃ¶ntemleri)*

#### k-fold cross-validation *(k-katlÄ± Ã§apraz doÄŸrulama)*

#### Subsampling *(Alt Ã¶rnekleme)*

#### The bootstrap *(Bootstrap yÃ¶ntemi)*

### Tuning your model validation system *(Model doÄŸrulama sistemini ayarlamak)*

### Using adversarial validation *(ZÄ±t doÄŸrulama yÃ¶ntemini kullanmak)*

#### Example implementation *(Uygulama Ã¶rneÄŸi)*

### Handling different distributions of training and test data *(EÄŸitim ve test verilerindeki farklÄ± daÄŸÄ±lÄ±mlarla baÅŸa Ã§Ä±kma)*

### Handling leakage *(Veri sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nleme)*

### Summary *(Ã–zet)*

---

## Chapter 7: Modeling for Tabular Competitions *(BÃ¶lÃ¼m 7: Tablo Verisi YarÄ±ÅŸmalarÄ± Ä°Ã§in Modellemede YaklaÅŸÄ±mlar)*

### The Tabular Playground Series *(Tabular Playground Serisi)*

### Setting a random state for reproducibility *(Tekrarlanabilirlik iÃ§in rastgele durum belirleme)*

### The importance of EDA *(KeÅŸifsel veri analizinin Ã¶nemi)*

### Dimensionality reduction with t-SNE and UMAP *(t-SNE ve UMAP ile boyut indirgeme)*

### Reducing the size of your data *(Veri boyutunu kÃ¼Ã§Ã¼ltme)*

### Applying feature engineering *(Ã–zellik mÃ¼hendisliÄŸi uygulama)*

#### Easily derived features *(Kolay tÃ¼retilen Ã¶zellikler)*

#### Meta-features based on rows and columns *(SatÄ±r ve sÃ¼tunlara dayalÄ± meta-Ã¶zellikler)*

#### Target encoding *(Hedef kodlama)*

### Using feature importance to evaluate your work *(Ã–zellik Ã¶nemini kullanarak Ã§alÄ±ÅŸmanÄ± deÄŸerlendirme)*

### Pseudo-labeling *(Sahte etiketleme)*

### Denoising with autoencoders *(Otoenkoderlerle gÃ¼rÃ¼ltÃ¼ giderme)*

### Neural networks for tabular competitions *(Tablo verisi yarÄ±ÅŸmalarÄ± iÃ§in sinir aÄŸlarÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 8: Hyperparameter Optimization *(BÃ¶lÃ¼m 8: Hiperparametre Optimizasyonu)*

### Basic optimization techniques *(Temel optimizasyon teknikleri)*

#### Grid search *(Izgara aramasÄ±)*

#### Random search *(Rastgele arama)*

#### Halving search *(YarÄ±ya indirme aramasÄ±)*

### Key parameters and how to use them *(Temel parametreler ve nasÄ±l kullanÄ±lacaklarÄ±)*

#### Linear models *(DoÄŸrusal modeller)*

#### Support-vector machines *(Destek vektÃ¶r makineleri)*

#### Random forests and extremely randomized trees *(Rastgele ormanlar ve aÅŸÄ±rÄ± rastgele aÄŸaÃ§lar)*

#### Gradient tree boosting *(Gradyan aÄŸaÃ§ gÃ¼Ã§lendirmesi)*

#### LightGBM *(LightGBM algoritmasÄ±)*

#### XGBoost *(XGBoost algoritmasÄ±)*

#### CatBoost *(CatBoost algoritmasÄ±)*

#### HistGradientBoosting *(Histogram tabanlÄ± gradyan gÃ¼Ã§lendirme)*

### Bayesian optimization *(Bayesyen optimizasyon)*

#### Using Scikit-optimize *(Scikit-optimize kullanÄ±mÄ±)*

#### Customizing a Bayesian optimization search *(Bayesyen aramayÄ± Ã¶zelleÅŸtirme)*

#### Extending Bayesian optimization to neural architecture search *(Bayesyen optimizasyonu sinir aÄŸÄ± mimarisi aramasÄ±na geniÅŸletme)*

#### Creating lighter and faster models with KerasTuner *(KerasTuner ile daha hafif ve hÄ±zlÄ± modeller oluÅŸturma)*

#### The TPE approach in Optuna *(Optunaâ€™daki TPE yaklaÅŸÄ±mÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 9: Ensembling with Blending and Stacking Solutions *(BÃ¶lÃ¼m 9: KarÄ±ÅŸtÄ±rma ve YÄ±ÄŸÄ±nlama (Ensemble) Ã‡Ã¶zÃ¼mleri)*

### A brief introduction to ensemble algorithms *(Topluluk (ensemble) algoritmalarÄ±na kÄ±sa bir giriÅŸ)*

### Averaging models into an ensemble *(Modelleri ortalama alarak birleÅŸtirme)*

#### Majority voting *(Ã‡oÄŸunluk oylamasÄ±)*

#### Averaging of model predictions *(Model tahminlerinin ortalamasÄ±)*

#### Weighted averages *(AÄŸÄ±rlÄ±klÄ± ortalamalar)*

#### Averaging in your cross-validation strategy *(Ã‡apraz doÄŸrulama stratejinde ortalama alma)*

#### Correcting averaging for ROC-AUC evaluations *(ROC-AUC deÄŸerlendirmeleri iÃ§in ortalamayÄ± dÃ¼zeltme)*

### Blending models using a meta-model *(Meta-model kullanarak modelleri karÄ±ÅŸtÄ±rma)*

#### Best practices for blending *(KarÄ±ÅŸtÄ±rma iÃ§in en iyi uygulamalar)*

### Stacking models together *(Modelleri yÄ±ÄŸÄ±nlama)*

#### Stacking variations *(YÄ±ÄŸÄ±nlama varyasyonlarÄ±)*

### Creating complex stacking and blending solutions *(KarmaÅŸÄ±k karÄ±ÅŸtÄ±rma ve yÄ±ÄŸÄ±nlama Ã§Ã¶zÃ¼mleri oluÅŸturma)*

### Summary *(Ã–zet)*

---

## Chapter 10: Modeling for Computer Vision *(BÃ¶lÃ¼m 10: BilgisayarlÄ± GÃ¶rÃ¼ (Computer Vision) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Augmentation strategies *(Veri artÄ±rma stratejileri)*

#### Keras built-in augmentations *(Kerasâ€™Ä±n yerleÅŸik artÄ±rmalarÄ±)*

#### ImageDataGenerator approach *(ImageDataGenerator yaklaÅŸÄ±mÄ±)*

#### Preprocessing layers *(Ã–n iÅŸleme katmanlarÄ±)*

#### albumentations *(Albumentations kÃ¼tÃ¼phanesi)*

### Classification *(SÄ±nÄ±flandÄ±rma)*

### Object detection *(Nesne tespiti)*

### Semantic segmentation *(Anlamsal segmentasyon)*

### Summary *(Ã–zet)*

---

## Chapter 11: Modeling for NLP *(BÃ¶lÃ¼m 11: DoÄŸal Dil Ä°ÅŸleme (NLP) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Sentiment analysis *(Duygu analizi)*

### Open domain Q&A *(AÃ§Ä±k alan soru-cevap)*

### Text augmentation strategies *(Metin artÄ±rma stratejileri)*

#### Basic techniques *(Temel teknikler)*

#### nlpaug *(nlpaug kÃ¼tÃ¼phanesi)*

### Summary *(Ã–zet)*

---

## Chapter 12: Simulation and Optimization Competitions *(BÃ¶lÃ¼m 12: SimÃ¼lasyon ve Optimizasyon YarÄ±ÅŸmalarÄ±)*

### Connect X *(Connect X oyunu)*

### Rock-paper-scissors *(TaÅŸ-kaÄŸÄ±t-makas)*

### Santa competition 2020 *(Santa yarÄ±ÅŸmasÄ± 2020)*

### The name of the game *(Oyunun Ã¶zÃ¼)*

### Summary *(Ã–zet)*

---

# Part III: Leveraging Competitions for Your Career *(BÃ¶lÃ¼m III: YarÄ±ÅŸmalarÄ± Kariyerinde Avantaja DÃ¶nÃ¼ÅŸtÃ¼rme)*

## Chapter 13: Creating Your Portfolio of Projects and Ideas *(BÃ¶lÃ¼m 13: Proje ve Fikir PortfÃ¶yÃ¼ OluÅŸturma)*

### Building your portfolio with Kaggle *(Kaggle ile portfÃ¶y oluÅŸturma)*

### Leveraging Notebooks and discussions *(Defterler ve tartÄ±ÅŸmalardan yararlanma)*

### Leveraging Datasets *(Veri setlerinden yararlanma)*

### Arranging your online presence beyond Kaggle *(Kaggle dÄ±ÅŸÄ±nda Ã§evrimiÃ§i varlÄ±ÄŸÄ±nÄ± dÃ¼zenleme)*

#### Blogs and publications *(Bloglar ve yayÄ±nlar)*

#### GitHub *(GitHub)*

### Monitoring competition updates and newsletters *(YarÄ±ÅŸma gÃ¼ncellemelerini ve bÃ¼ltenleri takip etme)*

### Summary *(Ã–zet)*

---

## Chapter 14: Finding New Professional Opportunities *(BÃ¶lÃ¼m 14: Yeni Profesyonel FÄ±rsatlar Bulmak)*

### Building connections with other competition data scientists *(DiÄŸer yarÄ±ÅŸmacÄ± veri bilimcilerle baÄŸlantÄ± kurma)*

### Participating in Kaggle Days and other Kaggle meetups *(Kaggle Days ve diÄŸer Kaggle buluÅŸmalarÄ±na katÄ±lma)*

### Getting spotted and other job opportunities *(Fark edilmek ve diÄŸer iÅŸ fÄ±rsatlarÄ±)*

#### The STAR approach *(STAR yaklaÅŸÄ±mÄ±)*

### Summary (and some parting words) *(Ã–zet ve kapanÄ±ÅŸ notlarÄ±)*

---

## Other Books You May Enjoy *(HoÅŸunuza Gidebilecek DiÄŸer Kitaplar)*

## Index *(Dizin)*
