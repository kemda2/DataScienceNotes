# Part I: Introduction to Competitions *(BÃ¶lÃ¼m I: YarÄ±ÅŸmalara GiriÅŸ)*

## Chapter 1: Introducing Kaggle and Other Data Science Competitions *(BÃ¶lÃ¼m 1: Kaggle ve DiÄŸer Veri Bilimi YarÄ±ÅŸmalarÄ±na GiriÅŸ)*

Veri bilimi yarÄ±ÅŸmalarÄ± uzun zamandÄ±r var ve zaman iÃ§inde giderek artan bir baÅŸarÄ± elde ettiler. Tutkulu bir yarÄ±ÅŸmacÄ± topluluÄŸundan doÄŸan bu yarÄ±ÅŸmalar, giderek daha fazla ilgi Ã§ekmeye ve milyonlarca veri bilimciden oluÅŸan Ã§ok daha geniÅŸ bir kitleye ulaÅŸmaya baÅŸladÄ±. En popÃ¼ler veri bilimi yarÄ±ÅŸma platformu olan **Kaggle**â€™da uzun yÄ±llardÄ±r yarÄ±ÅŸmacÄ± olarak yer aldÄ±ÄŸÄ±mÄ±z iÃ§in, bu deÄŸiÅŸimlerin tÃ¼mÃ¼ne yÄ±llar boyunca doÄŸrudan tanÄ±klÄ±k ettik ve bizzat deneyimledik.

BugÃ¼n, Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ± hakkÄ±nda bilgi ararsanÄ±z, Ã§ok sayÄ±da **buluÅŸma (meetup)**, **tartÄ±ÅŸma paneli**, **podcast**, **rÃ¶portaj** ve hatta bu tÃ¼r yarÄ±ÅŸmalarda nasÄ±l kazanÄ±lacaÄŸÄ±nÄ± anlatan **Ã§evrimiÃ§i kurslar** bulabilirsiniz. (Genellikle bu kurslar size azim, hesaplama kaynaklarÄ± ve harcanan zamanÄ±n doÄŸru karÄ±ÅŸÄ±mÄ±nÄ± kullanmanÄ±zÄ± tavsiye eder.) Ancak, ÅŸu anda okumakta olduÄŸunuz kitap dÄ±ÅŸÄ±nda, bu kadar Ã§ok veri bilimi yarÄ±ÅŸmasÄ±nÄ± nasÄ±l yÃ¶neteceÄŸinizi ve onlardan nasÄ±l en iyi ÅŸekilde yararlanabileceÄŸinizi â€” yalnÄ±zca puan veya sÄ±ralama aÃ§Ä±sÄ±ndan deÄŸil, **profesyonel deneyim** bakÄ±mÄ±ndan da â€” sistematik bir ÅŸekilde anlatan bir rehber bulmanÄ±z oldukÃ§a zordur.

Bu kitapta amacÄ±mÄ±z, Kaggle veya diÄŸer veri bilimi yarÄ±ÅŸmalarÄ±nda nasÄ±l yÃ¼ksek puan alacaÄŸÄ±nÄ±zÄ± anlatan birkaÃ§ ipucu vermek deÄŸil. Bunun yerine, **Kaggleâ€™da daha etkili yarÄ±ÅŸmanÄ±z** ve yarÄ±ÅŸma deneyimlerinizden â€” Ã¶zellikle de profesyonel hayatÄ±nÄ±z aÃ§Ä±sÄ±ndan â€” **en fazla faydayÄ± elde etmeniz** iÃ§in kapsamlÄ± bir rehber sunmak istiyoruz. Kitap iÃ§eriÄŸine, **Kaggle Master** ve **Grandmaster**â€™larla yapÄ±lan rÃ¶portajlar da eÅŸlik ediyor. Bu rÃ¶portajlarÄ±n size Kaggleâ€™da yarÄ±ÅŸmanÄ±n belirli yÃ¶nleri hakkÄ±nda farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve iÃ§gÃ¶rÃ¼ler sunacaÄŸÄ±nÄ± ve rekabetÃ§i veri bilimi yaparken kendinizi sÄ±nama ve Ã¶ÄŸrenme biÃ§iminize ilham vereceÄŸini umuyoruz.

Bu kitabÄ±n sonunda, **kendi deneyimlerimizden**, **yarÄ±ÅŸmalardan edindiÄŸimiz bilgilerden** ve **kaynaklardan** doÄŸrudan derlediÄŸimiz bilgileri iÃ§selleÅŸtirmiÅŸ olacaksÄ±nÄ±z. BÃ¶ylece yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã¶ÄŸrenmenizi ve geliÅŸmenizi saÄŸlayacak bir yol haritasÄ±na sahip olacaksÄ±nÄ±z.

BaÅŸlangÄ±Ã§ noktasÄ± olarak, bu bÃ¶lÃ¼mde ÅŸunlarÄ± inceleyeceÄŸiz:

* RekabetÃ§i programlamanÄ±n nasÄ±l veri bilimi yarÄ±ÅŸmalarÄ±na evrildiÄŸini,
* Neden Kaggle platformunun bu tÃ¼r yarÄ±ÅŸmalar iÃ§in en popÃ¼ler site olduÄŸunu,
* Ve bu platformun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±.

Bu bÃ¶lÃ¼mde aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

* Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi
* **Common Task Framework** (Ortak GÃ¶rev Ã‡erÃ§evesi) paradigmasÄ±
* Kaggle platformu ve bazÄ± alternatifleri
* Bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸi: aÅŸamalarÄ±, yarÄ±ÅŸma tÃ¼rleri, gÃ¶nderim ve liderlik tablosu dinamikleri, hesaplama kaynaklarÄ±, aÄŸ oluÅŸturma ve daha fazlasÄ±

### The rise of data science competition platforms *(Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi)*

RekabetÃ§i programlamanÄ±n kÃ¶klÃ¼ bir geÃ§miÅŸi vardÄ±r; 1970â€™lerde dÃ¼zenlenen ilk **ICPC (International Collegiate Programming Contest â€“ UluslararasÄ± ÃœniversitelerarasÄ± Programlama YarÄ±ÅŸmasÄ±)** ile baÅŸlamÄ±ÅŸtÄ±r. Ä°lk ICPCâ€™de, Ã¼niversitelerden ve ÅŸirketlerden gelen kÃ¼Ã§Ã¼k takÄ±mlar, bir dizi problemi bilgisayar programÄ± kullanarak Ã§Ã¶zmeleri gereken bir yarÄ±ÅŸmaya katÄ±lÄ±yordu (baÅŸlangÄ±Ã§ta katÄ±lÄ±mcÄ±lar **FORTRAN** dilinde kodlama yapÄ±yordu). Ä°yi bir final sÄ±ralamasÄ± elde etmek iÃ§in takÄ±mlarÄ±n gÃ¼Ã§lÃ¼ **takÄ±m Ã§alÄ±ÅŸmasÄ±**, **problem Ã§Ã¶zme** ve **programlama** becerileri sergilemeleri gerekiyordu.

Bu tÃ¼r bir yarÄ±ÅŸmanÄ±n yoÄŸun atmosferinde yer almak ve iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§ekme fÄ±rsatÄ±, Ã¶ÄŸrencilere bÃ¼yÃ¼k bir motivasyon saÄŸladÄ± ve yarÄ±ÅŸmanÄ±n yÄ±llar boyunca popÃ¼ler kalmasÄ±na neden oldu. ICPC finalistleri arasÄ±nda, gÃ¼nÃ¼mÃ¼zde oldukÃ§a tanÄ±nmÄ±ÅŸ isimler vardÄ±r: **Adam Dâ€™Angelo** (Facebookâ€™un eski CTOâ€™su ve Quoraâ€™nÄ±n kurucusu), **Nikolai Durov** (Telegram Messengerâ€™Ä±n kurucu ortaÄŸÄ±) ve **Matei Zaharia** (Apache Sparkâ€™Ä±n yaratÄ±cÄ±sÄ±). Bu isimlerin yanÄ± sÄ±ra birÃ§ok profesyonel aynÄ± ortak deneyimi paylaÅŸÄ±r: bir ICPC yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸlardÄ±r.

ICPCâ€™nin ardÄ±ndan, Ã¶zellikle 2000 yÄ±lÄ±ndan sonra uzaktan katÄ±lÄ±mÄ±n kolaylaÅŸmasÄ±yla programlama yarÄ±ÅŸmalarÄ± bÃ¼yÃ¼k bir geliÅŸme gÃ¶sterdi. Bu sayede uluslararasÄ± yarÄ±ÅŸmalarÄ±n dÃ¼zenlenmesi hem daha kolay hem de daha dÃ¼ÅŸÃ¼k maliyetli hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸunun formatÄ± benzerdir: bir dizi problem verilir ve katÄ±lÄ±mcÄ±larÄ±n bunlarÄ± Ã§Ã¶zmek iÃ§in kod yazmasÄ± gerekir. Kazananlar sadece Ã¶dÃ¼l kazanmakla kalmaz, aynÄ± zamanda iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§eker veya kendi alanlarÄ±nda tanÄ±nÄ±r hale gelirler.

RekabetÃ§i programlamadaki problemler genellikle **kombinatorik**, **sayÄ± teorisi**, **graf teorisi**, **algoritmik oyun teorisi**, **hesaplamalÄ± geometri**, **dizgi analizi** ve **veri yapÄ±larÄ±** gibi konulardan oluÅŸur. Son yÄ±llarda ise **yapay zekÃ¢** ile ilgili problemler de bu yarÄ±ÅŸmalarda yer almaya baÅŸlamÄ±ÅŸtÄ±r. Ã–zellikle **KDD Cup**â€™Ä±n (Knowledge Discovery and Data Mining Cup â€“ Bilgi KeÅŸfi ve Veri MadenciliÄŸi YarÄ±ÅŸmasÄ±) baÅŸlatÄ±lmasÄ±ndan sonra bu tÃ¼r problemler oldukÃ§a popÃ¼ler hale gelmiÅŸtir. Bu yarÄ±ÅŸma, her yÄ±l **Association for Computing Machinery (ACM)** tarafÄ±ndan dÃ¼zenlenen konferans kapsamÄ±nda **Ã–zel Ä°lgi Grubu (SIG)** tarafÄ±ndan yÃ¼rÃ¼tÃ¼lmektedir. (Kaynak: [https://kdd.org/conferences](https://kdd.org/conferences))

Ä°lk **KDD Cup**, 1997 yÄ±lÄ±nda dÃ¼zenlenmiÅŸ ve **doÄŸrudan pazarlamada lift eÄŸrisi optimizasyonu** konusundaki bir problemi iÃ§ermiÅŸtir. Bu yarÄ±ÅŸma, gÃ¼nÃ¼mÃ¼zde hÃ¢lÃ¢ devam eden uzun bir yarÄ±ÅŸma serisinin baÅŸlangÄ±cÄ±nÄ± oluÅŸturmuÅŸtur. Veri kÃ¼meleri, yÃ¶nergeler ve kazananlar dÃ¢hil olmak Ã¼zere tÃ¼m arÅŸivlere ÅŸu adresten ulaÅŸabilirsiniz: [https://www.kdd.org/kdd-cup](https://www.kdd.org/kdd-cup). YazÄ±m sÄ±rasÄ±nda en son mevcut olan yarÄ±ÅŸma ise [https://ogb.stanford.edu/kddcup2021/](https://ogb.stanford.edu/kddcup2021/).
KDD Cup yarÄ±ÅŸmalarÄ±, en iyi uygulamalarÄ± belirlemede oldukÃ§a etkili olmuÅŸtur. BirÃ§ok makalede yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri, teknikler ve veri kÃ¼meleri paylaÅŸÄ±lmÄ±ÅŸ, bu da araÅŸtÄ±rmacÄ±lar ve uygulayÄ±cÄ±lar iÃ§in **deney**, **eÄŸitim** ve **karÅŸÄ±laÅŸtÄ±rma (benchmarking)** aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k fayda saÄŸlamÄ±ÅŸtÄ±r.

Hem rekabetÃ§i programlama etkinliklerinin hem de KDD Cupâ€™Ä±n baÅŸarÄ±sÄ±, ÅŸirketleri (Ã¶rneÄŸin **Netflix**) ve giriÅŸimcileri (Ã¶rneÄŸin Kaggleâ€™Ä±n kurucusu **Anthony Goldbloom**) **veri bilimi yarÄ±ÅŸma platformlarÄ±** kurmaya teÅŸvik etti. Bu platformlar, ÅŸirketlerin Ã§Ã¶zÃ¼lmesi zor veri bilimi problemlerini kitle kaynaklÄ± Ã§Ã¶zÃ¼mlerle Ã§Ã¶zebilmesine olanak tanÄ±dÄ±. GerÃ§ekten de veri bilimi alanÄ±nda her problem iÃ§in iÅŸe yarayan tek bir â€œaltÄ±nâ€ yÃ¶ntem yoktur; Ã§oÄŸu zaman, **â€œdeneyebileceÄŸin her ÅŸeyi deneâ€** yaklaÅŸÄ±mÄ± gerekir.

AslÄ±nda, uzun vadede hiÃ§bir algoritma tÃ¼m problemler iÃ§in diÄŸerlerini alt edemez. Bu durum, **David Wolpert** ve **William Macready** tarafÄ±ndan ortaya konan **No Free Lunch Teoremi (Bedava Ã–ÄŸle YemeÄŸi Yok Teoremi)** ile aÃ§Ä±klanÄ±r. Bu teoreme gÃ¶re, her makine Ã¶ÄŸrenimi algoritmasÄ± yalnÄ±zca Ã§Ã¶zÃ¼mÃ¼ iÃ§eren bir hipotez uzayÄ±na sahipse baÅŸarÄ±lÄ± olur. DolayÄ±sÄ±yla, bir algoritmanÄ±n belirli bir problemi en iyi ÅŸekilde Ã§Ã¶zebileceÄŸini Ã¶nceden bilemezsiniz; bunu Ã¶ÄŸrenmenin tek yolu, algoritmayÄ± doÄŸrudan o problem Ã¼zerinde test etmektir.
Makine Ã¶ÄŸreniminde herhangi bir â€œkutsal kÃ¢seâ€ veya teorik kestirme yoktur â€” yalnÄ±zca **ampirik deneyler** size neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶sterebilir.

Bu konuda daha fazla bilgi edinmek iÃ§in **No Free Lunch Teoremi** Ã¼zerine kuramsal aÃ§Ä±klamalarÄ± inceleyebilirsiniz. AÅŸaÄŸÄ±da bu konuyu detaylÄ± anlatan bir makaleye baÄŸlantÄ± verilmiÅŸtir:
ğŸ‘‰ [Analytics India Magazine â€“ What are the No Free Lunch Theorems in Data Science?](https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/)

Bu tÃ¼r durumlarda **crowdsourcing (kitle kaynak kullanÄ±mÄ±)** mÃ¼kemmel bir yÃ¶ntemdir; Ã§Ã¼nkÃ¼ algoritmalarÄ± ve veri dÃ¶nÃ¼ÅŸÃ¼mlerini kapsamlÄ± bir ÅŸekilde test etmeniz gerekir, ancak bunu yapacak insan gÃ¼cÃ¼ ve iÅŸlem gÃ¼cÃ¼nÃ¼z yoktur. Bu nedenle, hÃ¼kÃ¼metler ve ÅŸirketler belirli alanlarda ilerleme kaydetmek iÃ§in yarÄ±ÅŸmalara baÅŸvurur:

* **Kamu tarafÄ±nda:** ABDâ€™nin **DARPA** kuruluÅŸu tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalarda; **otonom araÃ§lar**, **robotik operasyonlar**, **makine Ã§evirisi**, **konuÅŸmacÄ± tanÄ±ma**, **parmak izi tanÄ±ma**, **bilgi eriÅŸimi**, **OCR (Optik Karakter TanÄ±ma)**, **otomatik hedef tanÄ±ma** gibi birÃ§ok alanda yarÄ±ÅŸmalar dÃ¼zenlenmiÅŸtir.
* **Åirket tarafÄ±nda:** Ã–rneÄŸin **Netflix**, kullanÄ±cÄ±larÄ±n film tercihlerinin tahmin edilmesini iyileÅŸtirmek amacÄ±yla dÃ¼zenlenen bir yarÄ±ÅŸmanÄ±n sonucuna gÃ¶re algoritmasÄ±nÄ± geliÅŸtirmiÅŸtir.

**Netflix YarÄ±ÅŸmasÄ± (Netflix Prize)**, mevcut **Ã¶neri sistemini** (collaborative filtering) geliÅŸtirmeyi amaÃ§lÄ±yordu. YarÄ±ÅŸmanÄ±n hedefi, bir kullanÄ±cÄ±nÄ±n bir filme vereceÄŸi puanÄ±, yalnÄ±zca daha Ã¶nce puanladÄ±ÄŸÄ± filmlerden yola Ã§Ä±karak tahmin etmekti â€” yani kullanÄ±cÄ± kimliÄŸi veya film aÃ§Ä±klamalarÄ± hakkÄ±nda hiÃ§bir bilgi yoktu (bunlarÄ±n tÃ¼mÃ¼ kimlik kodlarÄ±yla deÄŸiÅŸtirilmiÅŸti). KatÄ±lÄ±mcÄ±lardan, mevcut puan geÃ§miÅŸini akÄ±llÄ±ca kullanarak tahmin yapan modeller geliÅŸtirmeleri istendi.
**1.000.000 ABD DolarÄ±** tutarÄ±ndaki bÃ¼yÃ¼k Ã¶dÃ¼l, yalnÄ±zca geliÅŸtirilen modelin Netflixâ€™in mevcut algoritmasÄ± **Cinematch**â€™i belirli bir eÅŸiÄŸin Ã¼zerinde iyileÅŸtirmesi durumunda verilecekti.

YarÄ±ÅŸma 2006â€™dan 2009â€™a kadar sÃ¼rdÃ¼ ve kazanan takÄ±m, Ã¶nceki yarÄ±ÅŸmalardan birÃ§ok takÄ±mÄ±n birleÅŸmesiyle oluÅŸtu: **Commendo Research & Consulting GmbH**â€™den **Andreas TÃ¶scher** ve **Michael Jahrer** (aynÄ± zamanda Kaggleâ€™da da tanÄ±nan yarÄ±ÅŸmacÄ±lar), **AT&T Labs**â€™tan iki araÅŸtÄ±rmacÄ± ve **Yahoo!**â€™dan iki araÅŸtÄ±rmacÄ±.
YarÄ±ÅŸmayÄ± kazanmak, o kadar bÃ¼yÃ¼k bir hesaplama gÃ¼cÃ¼ ve farklÄ± Ã§Ã¶zÃ¼mlerin birleÅŸtirilmesini (ensemble) gerektirdi ki, takÄ±mlar rekabeti sÃ¼rdÃ¼rebilmek iÃ§in birleÅŸmek zorunda kaldÄ±lar. SonuÃ§ta, **Netflix** bu Ã§Ã¶zÃ¼mÃ¼ doÄŸrudan uygulamak yerine, yarÄ±ÅŸmadan elde edilen en deÄŸerli iÃ§gÃ¶rÃ¼leri alÄ±p mevcut **Cinematch algoritmasÄ±nÄ±** geliÅŸtirmede kullandÄ±.
Bu konuda daha fazla bilgi iÃ§in ÅŸu **Wired** makalesini okuyabilirsiniz:
ğŸ‘‰ [https://www.wired.com/2012/04/netflix-prize-costs/](https://www.wired.com/2012/04/netflix-prize-costs/)

Netflix yarÄ±ÅŸmasÄ±nÄ±n sonunda Ã¶nemli olan ÅŸey, Ã§Ã¶zÃ¼mÃ¼n kendisi deÄŸil, **Netflixâ€™in iÅŸ modelinin DVD kiralamadan Ã§evrimiÃ§i yayÄ±n platformuna geÃ§mesiyle** birlikte elde edilen **bilgi ve deneyimdi**. YarÄ±ÅŸmadan hem katÄ±lÄ±mcÄ±lar (Ã¶neri sistemleri alanÄ±nda bÃ¼yÃ¼k bir Ã¼n kazandÄ±lar) hem de Netflix (geliÅŸtirilmiÅŸ Ã¶neri sistemi bilgisini yeni iÅŸ modeline aktardÄ±) bÃ¼yÃ¼k fayda saÄŸladÄ±.

#### The Kaggle competition platform *(Kaggle yarÄ±ÅŸma platformu)*

**Netflix dÄ±ÅŸÄ±ndaki birÃ§ok ÅŸirket de veri bilimi yarÄ±ÅŸmalarÄ±ndan fayda saÄŸlamÄ±ÅŸtÄ±r.** Liste oldukÃ§a uzundur, ancak yarÄ±ÅŸmayÄ± dÃ¼zenleyen ÅŸirketlerin aÃ§Ä±k bir ÅŸekilde fayda elde ettiÄŸini bildirdiÄŸi birkaÃ§ Ã¶rneÄŸi verebiliriz. Ã–rneÄŸin:

* **Allstate** adlÄ± sigorta ÅŸirketi, yÃ¼zlerce veri bilimcinin katÄ±ldÄ±ÄŸÄ± bir yarÄ±ÅŸma sayesinde ([https://www.kaggle.com/c/ClaimPredictionChallenge](https://www.kaggle.com/c/ClaimPredictionChallenge)), kendi uzmanlarÄ± tarafÄ±ndan geliÅŸtirilen aktÃ¼eryal modellerini Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirebilmiÅŸtir.
* BaÅŸka iyi belgelenmiÅŸ bir Ã¶rnek olarak, **General Electric**, havayolu uÃ§uÅŸlarÄ±nÄ±n varÄ±ÅŸ zamanlarÄ±nÄ± tahmin etmede kullanÄ±lan sektÃ¶r standardÄ± performans Ã¶lÃ§Ã¼tÃ¼ne gÃ¶re (kÃ¶k ortalama kare hatasÄ± â€“ *root mean squared error* metriÄŸiyle Ã¶lÃ§Ã¼lÃ¼r) %40â€™lÄ±k bir geliÅŸme saÄŸlamÄ±ÅŸtÄ±r. Bu baÅŸarÄ±, benzer bir yarÄ±ÅŸma sayesinde elde edilmiÅŸtir ([https://www.kaggle.com/c/flight](https://www.kaggle.com/c/flight)).

**Kaggle yarÄ±ÅŸma platformu** bugÃ¼ne kadar yÃ¼zlerce yarÄ±ÅŸma dÃ¼zenlemiÅŸtir ve bu iki Ã¶rnek, platformu baÅŸarÄ±yla kullanan ÅŸirketlerden yalnÄ±zca birkaÃ§Ä±dÄ±r.
Åimdi, belirli yarÄ±ÅŸmalarÄ±n Ã¶tesine geÃ§ip bu kitabÄ±n da merkezinde yer alan **Kaggle ÅŸirketi** hakkÄ±nda konuÅŸalÄ±m.

##### A history of Kaggle *(Kaggleâ€™Ä±n tarihÃ§esi)*

**Kaggle**, ilk adÄ±mlarÄ±nÄ± **Åubat 2010â€™da**, ekonomist ve ekonometrikÃ§i olarak eÄŸitim almÄ±ÅŸ AvustralyalÄ± **Anthony Goldbloom** sayesinde attÄ±. Goldbloom, Avustralya Hazine BakanlÄ±ÄŸÄ±â€™nda (*Department of the Treasury*) ve Avustralya Merkez BankasÄ±â€™nÄ±n (*Reserve Bank of Australia*) AraÅŸtÄ±rma DepartmanÄ±â€™nda Ã§alÄ±ÅŸtÄ±ktan sonra, Londraâ€™da haftalÄ±k uluslararasÄ± dergi **The Economist**â€™te staj yaptÄ±.

The Economistâ€™te Ã§alÄ±ÅŸtÄ±ÄŸÄ± dÃ¶nemde â€œ**bÃ¼yÃ¼k veri (big data)**â€ Ã¼zerine bir makale yazma fÄ±rsatÄ± buldu. Bu makale, onun aklÄ±na **ilginÃ§ makine Ã¶ÄŸrenimi problemlerini Ã§Ã¶zmek iÃ§in en iyi analitik uzmanlarÄ± kitlesel katÄ±lÄ±mla (crowdsourcing) bir araya getirecek bir yarÄ±ÅŸma platformu kurma fikrini** getirdi ([kaynak](https://www.smh.com.au/technology/from-bondi-to-the-big-bucks-the-28yearold-whos-making-datascience-a-sport-20111104-1myq1.html)).

Bu platformun iÅŸ fikrinde â€œcrowdsourcingâ€ dinamiklerinin Ã¶nemli bir rol oynamasÄ±ndan dolayÄ±, Goldbloom platformun adÄ±nÄ± **Kaggle** koydu. Bu isim, Ä°ngilizce â€œ**gaggle**â€ (kaz sÃ¼rÃ¼sÃ¼) kelimesine bir gÃ¶nderme yapÄ±yor; kaz figÃ¼rÃ¼ de zaten Kaggle platformunun sembolÃ¼dÃ¼r.

Goldbloom, daha sonra **ABDâ€™nin Silikon Vadisiâ€™ne taÅŸÄ±ndÄ±** ve Kaggle giriÅŸimi, iki tanÄ±nmÄ±ÅŸ risk sermayesi ÅŸirketi olan **Khosla Ventures** ve **Index Ventures** tarafÄ±ndan yÃ¶netilen bir yatÄ±rÄ±m turunda **11,25 milyon dolar** tutarÄ±nda **A Serisi yatÄ±rÄ±m** aldÄ±. Ä°lk yarÄ±ÅŸmalar baÅŸlatÄ±ldÄ±, topluluk hÄ±zla bÃ¼yÃ¼dÃ¼ ve bazÄ± erken dÃ¶nem yarÄ±ÅŸmacÄ±lar dikkat Ã§ekici baÅŸarÄ±lara ulaÅŸtÄ±. Bunlardan biri olan **Jeremy Howard**, AvustralyalÄ± bir veri bilimci ve giriÅŸimciydi. Kaggleâ€™da birkaÃ§ yarÄ±ÅŸma kazandÄ±ktan sonra ÅŸirketin **BaÅŸkanÄ± (President)** ve **BaÅŸ Bilimcisi (Chief Scientist)** oldu.

Jeremy Howard, **AralÄ±k 2013â€™te** gÃ¶revinden ayrÄ±ldÄ± ve daha sonra **fast.ai** ([www.fast.ai](http://www.fast.ai)) adlÄ± yeni bir giriÅŸim kurdu. Bu giriÅŸim, **makine Ã¶ÄŸrenimi kurslarÄ±** ve **geliÅŸtiriciler iÃ§in derin Ã¶ÄŸrenme (deep learning) kÃ¼tÃ¼phanesi** sunmaktadÄ±r.

O dÃ¶nemde Ã¶ne Ã§Ä±kan diÄŸer bazÄ± **Kaggle yarÄ±ÅŸmacÄ±larÄ± (Kagglers)** arasÄ±nda **Jeremy Achin** ve **Thomas de Godoy** da bulunuyordu. Platformda **ilk 20 kÃ¼resel sÄ±ralama** arasÄ±na girdikten sonra emekli olmaya karar verdiler ve **DataRobot** adlÄ± kendi ÅŸirketlerini kurdular. KÄ±sa sÃ¼re sonra, geliÅŸtirdikleri yazÄ±lÄ±ma en iyi makine Ã¶ÄŸrenimi bilgilerini ve uygulamalarÄ±nÄ± kazandÄ±rmak amacÄ±yla **Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmuÅŸ katÄ±lÄ±mcÄ±larÄ± iÅŸe almaya** baÅŸladÄ±lar. BugÃ¼n **DataRobot**, **AutoML (otomatik makine Ã¶ÄŸrenimi)** Ã§Ã¶zÃ¼mleri geliÅŸtiren Ã¶nde gelen ÅŸirketlerden biridir.

Kaggle yarÄ±ÅŸmalarÄ±, giderek artan bir ilgiyle bÃ¼yÃ¼meye devam etti. **Derin Ã¶ÄŸrenmenin â€œbabasÄ±â€ Geoffrey Hinton**, 2012â€™de **Merck** tarafÄ±ndan dÃ¼zenlenen bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ± ve kazandÄ± ([kaynak](https://www.kaggle.com/c/MerckActivity/overview/winners)).

AyrÄ±ca Kaggle, **FranÃ§ois Chollet**â€™nin derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi **Keras**â€™Ä± tanÄ±ttÄ±ÄŸÄ± **Otto Group Product Classification Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13632)) yarÄ±ÅŸmasÄ±nÄ±n ve **Tianqi Chen**â€™in **XGBoost** adlÄ± daha hÄ±zlÄ± ve daha doÄŸru bir **gradient boosting** algoritmasÄ±nÄ± tanÄ±ttÄ±ÄŸÄ± **Higgs Boson Machine Learning Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/higgs-boson/discussion/10335)) yarÄ±ÅŸmasÄ±nÄ±n da dÃ¼zenlendiÄŸi platformdur.

FranÃ§ois Chollet ayrÄ±ca **Quora** sitesinde â€œKaggle yarÄ±ÅŸmalarÄ±nda neden Keras bu kadar baÅŸarÄ±lÄ± oldu?â€ sorusuna verdiÄŸi cevapta, Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmanÄ±n Ã¶zÃ¼nÃ¼ mÃ¼kemmel bir ÅŸekilde aÃ§Ä±klamÄ±ÅŸtÄ±r ([kaynak](https://www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions)).
Ona gÃ¶re, **Ã§ok sayÄ±da denemeyi hÄ±zlÄ± ÅŸekilde yapmak ve teoriden ziyade ampirik kanÄ±tlarla yÃ¶nlenmek**, Kaggleâ€™da baÅŸarÄ±lÄ± olmanÄ±n temelidir. Biz de onun belirttiÄŸi noktalarÄ±n dÄ±ÅŸÄ±nda baÅŸka bir â€œgizli sÄ±râ€ olduÄŸuna inanmÄ±yoruz.

FranÃ§ois Chollet ayrÄ±ca Kaggleâ€™da kendi yarÄ±ÅŸmasÄ±nÄ± da dÃ¼zenlemiÅŸtir ([Abstraction and Reasoning Challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge/)) â€” bu yarÄ±ÅŸma, **dÃ¼nyanÄ±n ilk genel yapay zekÃ¢ (general AI) yarÄ±ÅŸmasÄ±** olarak kabul edilir.

YarÄ±ÅŸma Ã¼stÃ¼ne yarÄ±ÅŸma geldikÃ§e, Kaggle etrafÄ±ndaki topluluk bÃ¼yÃ¼meye devam etti ve **2017 yÄ±lÄ±nda 1 milyon kullanÄ±cÄ±ya** ulaÅŸtÄ±. AynÄ± yÄ±l, **Google BaÅŸ Bilimcisi Fei-Fei Li**, **Google Next** etkinliÄŸinde yaptÄ±ÄŸÄ± aÃ§Ä±lÄ±ÅŸ konuÅŸmasÄ±nda **Googleâ€™Ä±n Kaggleâ€™Ä± satÄ±n alacaÄŸÄ±nÄ±** duyurdu.
O tarihten bu yana **Kaggle, Google Ã§atÄ±sÄ± altÄ±nda** faaliyet gÃ¶stermektedir.

BugÃ¼n, **Kaggle topluluÄŸu hÃ¢lÃ¢ aktif ve bÃ¼yÃ¼meye devam ediyor.**
Anthony Goldbloomâ€™un bir tweetâ€™inde ([kaynak](https://twitter.com/antgoldbloom/status/1400119591246852096)) belirttiÄŸi Ã¼zere, kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k bir kÄ±smÄ± sadece yarÄ±ÅŸmalara katÄ±lmakla kalmÄ±yor; aynÄ± zamanda **Kaggleâ€™Ä±n herkese aÃ§Ä±k veri setlerini indiriyor** (Kaggle artÄ±k Ã¶nemli bir **veri merkezi** haline gelmiÅŸtir), **Python veya R ile herkese aÃ§Ä±k Notebooks oluÅŸturuyor** ya da **platformun sunduÄŸu kurslardan yeni bir ÅŸeyler Ã¶ÄŸreniyor.**

![](im/1001.png)

YÄ±llar boyunca Kaggle, katÄ±lÄ±mcÄ±larÄ±na aÅŸaÄŸÄ±daki gibi **daha pek Ã§ok fÄ±rsat** sunmuÅŸtur:

* **Kendi ÅŸirketlerini kurmak**
* **Makine Ã¶ÄŸrenimi yazÄ±lÄ±mlarÄ± ve paketleri baÅŸlatmak**
* **Dergilerde rÃ¶portajlar yapmak** ([kaynak](https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/))
* **Makine Ã¶ÄŸrenimi kitaplarÄ± yazmak** ([kaynak](https://twitter.com/antgoldbloom/status/745662719588589568))
* **Hayallerindeki iÅŸi bulmak**

Ve en Ã¶nemlisi, **veri bilimi ile ilgili beceriler ve teknik detaylar hakkÄ±nda daha fazla bilgi edinmek**.

#### Other competition platforms *(DiÄŸer yarÄ±ÅŸma platformlarÄ±)*

Bu kitap Kaggleâ€™daki yarÄ±ÅŸmalara odaklansa da, birÃ§ok veri yarÄ±ÅŸmasÄ±nÄ±n Ã¶zel platformlarda veya diÄŸer yarÄ±ÅŸma platformlarÄ±nda dÃ¼zenlendiÄŸini unutmamak gerekir. AslÄ±nda, bu kitapta bulacaÄŸÄ±nÄ±z bilgilerin Ã§oÄŸu diÄŸer yarÄ±ÅŸmalar iÃ§in de geÃ§erlidir; Ã§Ã¼nkÃ¼ temelde hepsi benzer prensiplerle Ã§alÄ±ÅŸÄ±r ve katÄ±lÄ±mcÄ±lara saÄŸladÄ±klarÄ± faydalar da aÅŸaÄŸÄ± yukarÄ± aynÄ±dÄ±r.

BirÃ§ok diÄŸer platform belirli Ã¼lkelere odaklanmÄ±ÅŸ ya da yalnÄ±zca belirli tÃ¼rde yarÄ±ÅŸmalarda uzmanlaÅŸmÄ±ÅŸtÄ±r. Yine de, tamlÄ±k aÃ§Ä±sÄ±ndan, en azÄ±ndan deneyim ve bilgimizin bulunduÄŸu bazÄ±larÄ±nÄ± kÄ±saca tanÄ±tmakta fayda var:

â€¢ **DrivenData** ([https://www.drivendata.org/competitions/](https://www.drivendata.org/competitions/)) sosyal problemlere yÃ¶nelik yarÄ±ÅŸmalar dÃ¼zenleyen bir kitle kaynaklÄ± (crowdsourcing) yarÄ±ÅŸma platformudur (bkz. [https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/](https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/)). Åirketin kendisi, dÃ¼nyanÄ±n en bÃ¼yÃ¼k sorunlarÄ±yla mÃ¼cadele eden kuruluÅŸlara veri bilimi Ã§Ã¶zÃ¼mleri sunmayÄ± amaÃ§layan bir sosyal giriÅŸimdir. Veri bilimciler, sosyal fayda iÃ§in algoritmalar geliÅŸtirir. Ã–rneÄŸin, [https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html](https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html) adresindeki makalede okuyabileceÄŸiniz gibi, Facebook nefret sÃ¶ylemi ve yanlÄ±ÅŸ bilgiyle mÃ¼cadele iÃ§in dÃ¼zenlediÄŸi yarÄ±ÅŸmada DrivenDataâ€™yÄ± seÃ§miÅŸtir.

â€¢ **Numerai** ([https://numer.ai/](https://numer.ai/)) San Francisco merkezli, yapay zekÃ¢ destekli bir kitle kaynaklÄ± hedge fonudur. KatÄ±lÄ±mcÄ±lar her hafta fonun anonimleÅŸtirilmiÅŸ verileri Ã¼zerinde tahmin modelleri gÃ¶nderir ve ÅŸirketin kendi kripto para birimi olan *Numeraire* ile Ã¶dÃ¼ller kazanÄ±rlar.

â€¢ **CrowdANALYTIX** ([https://www.crowdanalytix.com/community](https://www.crowdanalytix.com/community)) artÄ±k eskisi kadar aktif olmasa da, bir sÃ¼re Ã¶nce birÃ§ok zorlu yarÄ±ÅŸmaya ev sahipliÄŸi yapmÄ±ÅŸtÄ±r (bkz. [https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1](https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1)). AyrÄ±ca topluluk blogu, bu platformda ne tÃ¼r zorluklarla karÅŸÄ±laÅŸabileceÄŸinize dair fikir edinmek iÃ§in oldukÃ§a ilginÃ§tir: [https://www.crowdanalytix.com/jq/communityBlog/listBlog.html](https://www.crowdanalytix.com/jq/communityBlog/listBlog.html).

â€¢ **Signate** ([https://signate.jp/competitions](https://signate.jp/competitions)) Japonya merkezli bir veri bilimi yarÄ±ÅŸma platformudur. BirÃ§ok yarÄ±ÅŸmaya ev sahipliÄŸi yapar ve Kaggleâ€™a benzer bir sÄ±ralama sistemi sunar ([https://signate.jp/users/rankings](https://signate.jp/users/rankings)).

â€¢ **Zindi** ([https://zindi.africa/competitions](https://zindi.africa/competitions)) Afrika merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Afrikaâ€™nÄ±n en acil sosyal, ekonomik ve Ã§evresel sorunlarÄ±nÄ± Ã§Ã¶zmeye odaklÄ± yarÄ±ÅŸmalar dÃ¼zenler.

â€¢ **Alibaba Cloud** ([https://www.alibabacloud.com/campaign/tianchi-competitions](https://www.alibabacloud.com/campaign/tianchi-competitions)) Ã‡in merkezli bir bulut biliÅŸim ve yapay zekÃ¢ saÄŸlayÄ±cÄ±sÄ±dÄ±r. SIGKDD, IJCAI-PRICAI ve CVPR gibi akademik konferanslarla ortaklaÅŸa dÃ¼zenlenen *Tianchi Academic* yarÄ±ÅŸmalarÄ±nÄ± baÅŸlatmÄ±ÅŸtÄ±r. GÃ¶rsel tabanlÄ± 3D ÅŸekil tanÄ±ma, 3D nesne yeniden oluÅŸturma ve Ã¶rnek segmentasyonu gibi zorluklar iÃ§eren yarÄ±ÅŸmalar dÃ¼zenler.

â€¢ **Analytics Vidhya** ([https://datahack.analyticsvidhya.com/](https://datahack.analyticsvidhya.com/)) Hindistanâ€™Ä±n en bÃ¼yÃ¼k veri bilimi topluluÄŸudur ve veri bilimi hackathonâ€™larÄ± iÃ§in bir platform sunar.

â€¢ **CodaLab** ([https://codalab.lri.fr/](https://codalab.lri.fr/)) 2013 yÄ±lÄ±nda Microsoft ve Stanford Ãœniversitesiâ€™nin ortak giriÅŸimiyle kurulmuÅŸ, Fransa merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Bilgi paylaÅŸÄ±mÄ± ve yeniden Ã¼retilebilir modelleme iÃ§in **Worksheets** ([https://worksheets.codalab.org/](https://worksheets.codalab.org/)) adlÄ± Ã¼cretsiz bulut tabanlÄ± bir defter sunar.

DiÄŸer daha kÃ¼Ã§Ã¼k platformlar arasÄ±nda Ä°sviÃ§reâ€™deki Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne tarafÄ±ndan geliÅŸtirilen **CrowdAI** ([https://www.crowdai.org/](https://www.crowdai.org/)), **InnoCentive** ([https://www.innocentive.com/](https://www.innocentive.com/)), biyomedikal gÃ¶rÃ¼ntÃ¼leme iÃ§in **Grand-Challenge** ([https://grand-challenge.org/](https://grand-challenge.org/)), **DataFountain** ([https://www.datafountain.cn/business?lang=en-US](https://www.datafountain.cn/business?lang=en-US)), **OpenML** ([https://www.openml.org/](https://www.openml.org/)) gibi platformlar yer alÄ±r. AyrÄ±ca, Rus topluluÄŸu **Open Data Science** ([https://ods.ai/competitions](https://ods.ai/competitions)) sitesinde devam eden bÃ¼yÃ¼k yarÄ±ÅŸmalarÄ±n kapsamlÄ± bir listesini bulabilir ve zaman zaman yeni yarÄ±ÅŸma platformlarÄ±nÄ± keÅŸfedebilirsiniz.

Kaggle, hÃ¢lÃ¢ en ilginÃ§ yarÄ±ÅŸmalarÄ± bulabileceÄŸiniz ve yarÄ±ÅŸma Ã§abalarÄ±nÄ±zla en geniÅŸ tanÄ±nÄ±rlÄ±ÄŸÄ± elde edebileceÄŸiniz en iyi platformdur. Ancak, Kaggle dÄ±ÅŸÄ±ndaki bir yarÄ±ÅŸmayÄ± seÃ§mek de anlamlÄ± olabilir; Ã¶zellikle kiÅŸisel veya profesyonel ilgi alanlarÄ±nÄ±za uyan bir yarÄ±ÅŸma bulduÄŸunuzda. GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, Kaggle dÄ±ÅŸÄ±nda da oldukÃ§a fazla alternatif ve fÄ±rsat mevcut. Bu da, Kaggle ile birlikte diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± da dikkate alarak, ilginizi Ã§ekebilecek Ã¶zel veri veya temalÄ± bir yarÄ±ÅŸma bulma olasÄ±lÄ±ÄŸÄ±nÄ±zÄ± artÄ±rÄ±r.

AyrÄ±ca, bu tÃ¼r platformlarda rekabetin genellikle daha az olduÄŸunu (dolayÄ±sÄ±yla daha iyi bir sÄ±ralama veya Ã¶dÃ¼l kazanma ÅŸansÄ±nÄ±zÄ±n daha yÃ¼ksek olabileceÄŸini) bekleyebilirsiniz; ancak katÄ±lÄ±mcÄ±lar arasÄ±nda bilgi paylaÅŸÄ±mÄ±nÄ±n Kaggleâ€™daki kadar zengin olmadÄ±ÄŸÄ±nÄ± da unutmamalÄ±sÄ±nÄ±z.

### Introducing Kaggle *(Kaggleâ€™a giriÅŸ)*

Bu noktada, Ã¶zellikle **Kaggle**â€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha derinlemesine incelememiz gerekiyor.
AÅŸaÄŸÄ±daki paragraflarda, Kaggle platformunun ve yarÄ±ÅŸmalarÄ±nÄ±n Ã§eÅŸitli yÃ¶nlerini ele alacaÄŸÄ±z ve Kaggleâ€™daki bir yarÄ±ÅŸmada yer almanÄ±n ne anlama geldiÄŸine dair bir fikir edineceksiniz.
Daha sonra, kitabÄ±n geri kalan bÃ¶lÃ¼mlerinde bu konularÄ±n Ã§oÄŸuna Ã§ok daha ayrÄ±ntÄ±lÄ± biÃ§imde geri dÃ¶nerek, ek Ã¶neriler ve stratejilerle birlikte tartÄ±ÅŸacaÄŸÄ±z.

#### Stages of a competition *(Bir yarÄ±ÅŸmanÄ±n aÅŸamalarÄ±)*

Kaggleâ€™daki bir yarÄ±ÅŸma, farklÄ± adÄ±mlardan oluÅŸacak ÅŸekilde dÃ¼zenlenir.
Bu adÄ±mlarÄ±n her birine gÃ¶z atarak, bir veri bilimi yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸini ve sizden neler beklenebileceÄŸini daha iyi anlayabilirsiniz.

Bir yarÄ±ÅŸma baÅŸlatÄ±ldÄ±ÄŸÄ±nda, genellikle sosyal medyada â€” Ã¶rneÄŸin Kaggleâ€™Ä±n Twitter hesabÄ±nda ([https://twitter.com/kaggle](https://twitter.com/kaggle)) â€” yarÄ±ÅŸmayÄ± duyuran paylaÅŸÄ±mlar yapÄ±lÄ±r. AyrÄ±ca, **Competitions** sayfasÄ±nda ([https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)) **Active Competitions** (aktif yarÄ±ÅŸmalar) bÃ¶lÃ¼mÃ¼nde yeni bir sekme gÃ¶rÃ¼nÃ¼r.

Belirli bir yarÄ±ÅŸmanÄ±n sekmesine tÄ±kladÄ±ÄŸÄ±nÄ±zda, o yarÄ±ÅŸmanÄ±n sayfasÄ±na yÃ¶nlendirilirsiniz. Ä°lk bakÄ±ÅŸta, yarÄ±ÅŸmanÄ±n Ã¶dÃ¼l verip vermediÄŸini (ve yarÄ±ÅŸmaya katÄ±lmanÄ±n bir sonucu olarak puan ve madalya kazandÄ±rÄ±p kazandÄ±rmadÄ±ÄŸÄ±nÄ±), ÅŸu anda kaÃ§ takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ±nÄ± ve Ã§Ã¶zÃ¼mÃ¼nÃ¼z Ã¼zerinde Ã§alÄ±ÅŸmak iÃ§in ne kadar sÃ¼reniz kaldÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz.

![](im/1002.png)

Orada, Ã¶ncelikle **Overview (Genel BakÄ±ÅŸ)** menÃ¼sÃ¼nÃ¼ inceleyebilirsiniz. Bu menÃ¼ size ÅŸu konularda bilgi verir:

* YarÄ±ÅŸmanÄ±n konusu
* DeÄŸerlendirme metriÄŸi (modellerinizin deÄŸerlendirileceÄŸi Ã¶lÃ§Ã¼t)
* YarÄ±ÅŸmanÄ±n zaman Ã§izelgesi
* Ã–dÃ¼ller
* Yasal veya yarÄ±ÅŸma gereklilikleri

Genellikle zaman Ã§izelgesi Ã§ok dikkat edilmeyen bir kÄ±sÄ±mdÄ±r, ancak kontrol etmeniz gereken ilk ÅŸeylerden biri olmalÄ±dÄ±r; Ã§Ã¼nkÃ¼ yalnÄ±zca yarÄ±ÅŸmanÄ±n ne zaman baÅŸlayÄ±p biteceÄŸini deÄŸil, aynÄ± zamanda **kural kabul etme son tarihini** de gÃ¶sterir. Bu tarih genellikle yarÄ±ÅŸma kapanmadan **7 ila 14 gÃ¼n Ã¶nce** olur ve yarÄ±ÅŸmaya katÄ±labileceÄŸiniz (kurallarÄ± kabul edebileceÄŸiniz) son gÃ¼nÃ¼ belirtir.

AyrÄ±ca bir **takÄ±m birleÅŸtirme son tarihi (team merger deadline)** de bulunur: Bu tarihten Ã¶nce istediÄŸiniz herhangi bir zamanda ekibinizi baÅŸka bir yarÄ±ÅŸmacÄ±nÄ±n ekibiyle birleÅŸtirebilirsiniz; ancak bu tarihten sonra artÄ±k mÃ¼mkÃ¼n deÄŸildir.

**Rules (Kurallar)** menÃ¼sÃ¼ de sÄ±klÄ±kla gÃ¶z ardÄ± edilir (Ã§oÄŸu kiÅŸi doÄŸrudan **Data** kÄ±smÄ±na geÃ§er), ancak kontrol edilmesi Ã¶nemlidir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n gereklilikleri hakkÄ±nda bilgi verir. Kurallar kÄ±smÄ±ndan edinebileceÄŸiniz Ã¶nemli bilgiler arasÄ±nda ÅŸunlar yer alÄ±r:

* Ã–dÃ¼l almaya uygun olup olmadÄ±ÄŸÄ±nÄ±z
* PuanÄ±nÄ±zÄ± artÄ±rmak iÃ§in harici veri kullanÄ±p kullanamayacaÄŸÄ±nÄ±z
* GÃ¼nde kaÃ§ tane gÃ¶nderim (Ã§Ã¶zÃ¼m testi) yapabileceÄŸiniz
* KaÃ§ tane nihai Ã§Ã¶zÃ¼m seÃ§ebileceÄŸiniz

KurallarÄ± kabul ettikten sonra, **Data** menÃ¼sÃ¼nden verileri indirebilir veya doÄŸrudan **Code** menÃ¼sÃ¼nden Kaggle Notebooks (Ã§evrimiÃ§i, bulut tabanlÄ± defterler) Ã¼zerinde Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz. Burada diÄŸerlerinin paylaÅŸtÄ±ÄŸÄ± kodlarÄ± yeniden kullanabilir veya sÄ±fÄ±rdan kendi kodunuzu oluÅŸturabilirsiniz.

EÄŸer verileri indirmeye karar verirseniz, **Kaggle API**â€™sini de kullanabileceÄŸinizi unutmayÄ±n. Bu API, indirme ve gÃ¶nderim iÅŸlemlerini neredeyse otomatik hale getirmenize yardÄ±mcÄ± olur. Yerel bilgisayarÄ±nÄ±zda veya bulut sunucunuzda modellerinizi Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z, bu araÃ§ oldukÃ§a faydalÄ±dÄ±r. API hakkÄ±nda daha fazla bilgiyi ÅŸu adreste bulabilirsiniz:
ğŸ‘‰ [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)
Kaynak koduna ise GitHub Ã¼zerinden ulaÅŸabilirsiniz:
ğŸ‘‰ [https://github.com/Kaggle/kaggle-api](https://github.com/Kaggle/kaggle-api)

Kaggleâ€™Ä±n GitHub deposunu daha yakÄ±ndan incelerseniz, **Kaggle Notebooks** (Ã§evrimiÃ§i defterler) iÃ§in kullanÄ±lan tÃ¼m **Docker imajlarÄ±nÄ±** da bulabilirsiniz.

![](im/1003.png)

Bu noktada, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirirken **tek baÅŸÄ±nÄ±za devam etmemenizi**, diÄŸer yarÄ±ÅŸmacÄ±larla **Discussion (TartÄ±ÅŸma)** forumu Ã¼zerinden iletiÅŸime geÃ§menizi iÃ§tenlikle tavsiye ederiz. Bu forumda yarÄ±ÅŸmaya Ã¶zgÃ¼ sorular sorabilir ve diÄŸer katÄ±lÄ±mcÄ±larÄ±n sorularÄ±nÄ± yanÄ±tlayabilirsiniz.
Ã‡oÄŸu zaman burada, veriyle ilgili belirli problemlere dair faydalÄ± ipuÃ§larÄ± veya kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirmeye yardÄ±mcÄ± olabilecek fikirler bulabilirsiniz.
BirÃ§ok baÅŸarÄ±lÄ± Kaggle kullanÄ±cÄ±sÄ± (*Kaggler*), forumlarda edindikleri fikirlerin kendilerine daha iyi performans saÄŸladÄ±ÄŸÄ±nÄ± ve daha da Ã¶nemlisi, veri bilimi modelleme konusunda Ã§ok ÅŸey Ã¶ÄŸrenmelerine yardÄ±mcÄ± olduÄŸunu belirtmiÅŸtir.

Ã‡Ã¶zÃ¼mÃ¼nÃ¼z hazÄ±r olduÄŸunda, yarÄ±ÅŸmanÄ±n yÃ¶nergelerine uygun ÅŸekilde **Kaggle deÄŸerlendirme sistemine** gÃ¶nderebilirsiniz.
BazÄ± yarÄ±ÅŸmalar Ã§Ã¶zÃ¼mleri **CSV dosyasÄ±** olarak kabul ederken, bazÄ±larÄ± **Kaggle Notebook** Ã¼zerinde kod yazmanÄ±zÄ± ve sonuÃ§larÄ± orada Ã¼retmenizi ister.
YarÄ±ÅŸma sÃ¼resince Ã§Ã¶zÃ¼m gÃ¶ndermeye devam edebilirsiniz.

Her gÃ¶nderim yaptÄ±ÄŸÄ±nÄ±zda, kÄ±sa bir sÃ¼re sonra **liderlik tablosu (leaderboard)** size bir puan ve yarÄ±ÅŸmacÄ±lar arasÄ±ndaki konumunuzu gÃ¶sterecektir (bekleme sÃ¼resi, puan hesaplamasÄ± iÃ§in gereken iÅŸlem sÃ¼resine baÄŸlÄ± olarak deÄŸiÅŸir).
Ancak bu sÄ±ralama yalnÄ±zca yaklaÅŸÄ±k bir gÃ¶stergedir; Ã§Ã¼nkÃ¼ modelinizin performansÄ±nÄ±, test verisinin yalnÄ±zca bir kÄ±smÄ± olan **public test set (genel test kÃ¼mesi)** Ã¼zerinde yansÄ±tÄ±r. Bu kÃ¼medeki sonuÃ§lar yarÄ±ÅŸma boyunca herkesin gÃ¶rebileceÄŸi ÅŸekilde paylaÅŸÄ±lÄ±r.

YarÄ±ÅŸma kapanmadan Ã¶nce, her yarÄ±ÅŸmacÄ± **nihai deÄŸerlendirme** iÃ§in kendi Ã§Ã¶zÃ¼mleri arasÄ±ndan belirli bir sayÄ±da (genellikle iki) Ã§Ã¶zÃ¼m seÃ§ebilir.

![](im/1004.png)

YarÄ±ÅŸma ancak kapandÄ±ktan sonra, yarÄ±ÅŸmacÄ±larÄ±n deÄŸerlendirilmesini istedikleri modeller temel alÄ±narak, **test veri setinin baÅŸka bir kÄ±smÄ±** olan **private test set (Ã¶zel test kÃ¼mesi)** Ã¼zerindeki puanlarÄ± aÃ§Ä±klanÄ±r.
Bu yeni sÄ±ralama tablosu **private leaderboard (Ã¶zel liderlik tablosu)** olarak adlandÄ±rÄ±lÄ±r ve yarÄ±ÅŸmanÄ±n **nihai, gerÃ§ek puanlarÄ±nÄ±** gÃ¶sterir; ancak bu sÄ±ralama henÃ¼z **resmÃ® ve kesin** deÄŸildir.

GerÃ§ekte, Kaggle ekibi her ÅŸeyin doÄŸru olduÄŸunu ve tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n yarÄ±ÅŸma kurallarÄ±na uyduÄŸunu kontrol etmek iÃ§in bir sÃ¼re ayÄ±rÄ±r.
Bir sÃ¼re sonra (ve bazen bazÄ± yarÄ±ÅŸmacÄ±larÄ±n diskalifiye edilmesine baÄŸlÄ± olarak sÄ±ralamalarda deÄŸiÅŸiklikler olduktan sonra), **private leaderboard** resmÃ® ve kesin hale gelir.
Kazananlar aÃ§Ä±klanÄ±r ve birÃ§ok katÄ±lÄ±mcÄ±, yarÄ±ÅŸma tartÄ±ÅŸma forumunda kendi stratejilerini, Ã§Ã¶zÃ¼mlerini ve kodlarÄ±nÄ± paylaÅŸÄ±r.

Bu noktada, diÄŸer katÄ±lÄ±mcÄ±larÄ±n Ã§Ã¶zÃ¼mlerini incelemek ve kendi yaklaÅŸÄ±mÄ±nÄ±zÄ± geliÅŸtirmeye Ã§alÄ±ÅŸmak tamamen size kalmÄ±ÅŸtÄ±r.
Bunu yapmanÄ±zÄ± **ÅŸiddetle tavsiye ederiz**, Ã§Ã¼nkÃ¼ bu sÃ¼reÃ§ Kaggleâ€™daki en Ã¶nemli Ã¶ÄŸrenme kaynaklarÄ±ndan bir diÄŸeridir.

#### Types of competitions and examples *(YarÄ±ÅŸma tÃ¼rleri ve Ã¶rnekleri)*

Kaggle yarÄ±ÅŸmalarÄ±, **yarÄ±ÅŸma kategorilerine** gÃ¶re sÄ±nÄ±flandÄ±rÄ±lÄ±r ve her kategori, yarÄ±ÅŸma biÃ§imi ve beklentiler aÃ§Ä±sÄ±ndan farklÄ±lÄ±k gÃ¶sterir.
Veri tÃ¼rÃ¼, problem zorluÄŸu, verilen Ã¶dÃ¼ller ve yarÄ±ÅŸma dinamikleri bu kategoriler iÃ§inde oldukÃ§a Ã§eÅŸitlidir; bu nedenle her kategorinin ne anlama geldiÄŸini Ã¶nceden anlamak Ã¶nemlidir.

Kaggleâ€™daki yarÄ±ÅŸmalarÄ± filtrelemek iÃ§in kullanabileceÄŸiniz **resmÃ® kategoriler** ÅŸunlardÄ±r:

* **Featured**
* **Masters**
* **Annuals**
* **Research**
* **Recruitment**
* **Getting Started**
* **Playground**
* **Analytics**
* **Community**

---

> ğŸ† Featured (Ã–ne Ã‡Ä±kan) YarÄ±ÅŸmalar

Bunlar en yaygÄ±n yarÄ±ÅŸma tÃ¼rÃ¼dÃ¼r. Genellikle sponsor bir ÅŸirketin iÅŸ ile ilgili bir problemini iÃ§erir ve en iyi performans gÃ¶sterenlere Ã¶dÃ¼l verilir.
Kazananlar, Ã§Ã¶zÃ¼mlerinin **lisanssÄ±z (non-exclusive)** kullanÄ±m hakkÄ±nÄ± sponsor ÅŸirkete verirler; ayrÄ±ca ayrÄ±ntÄ±lÄ± bir rapor hazÄ±rlamalarÄ± ve bazen sponsor ÅŸirketle toplantÄ±lara katÄ±lmalarÄ± gerekebilir.

Kaggleâ€™da neredeyse her zaman Featured yarÄ±ÅŸmalara rastlayabilirsiniz. GÃ¼nÃ¼mÃ¼zde Ã§oÄŸu, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veriler** (metin, gÃ¶rÃ¼ntÃ¼, video, ses gibi) Ã¼zerinde derin Ã¶ÄŸrenme yÃ¶ntemlerinin uygulanmasÄ±na yÃ¶neliktir.
GeÃ§miÅŸte ise daha Ã§ok **tablo biÃ§iminde veriler (tabular data)** Ã¼zerine kurulu yarÄ±ÅŸmalar yapÄ±lÄ±rdÄ± â€” yani veritabanlarÄ±nda bulunan yapÄ±landÄ±rÄ±lmÄ±ÅŸ veriler Ã¼zerinde Ã§alÄ±ÅŸan problemlerdi.
Ä°lk zamanlarda rastgele ormanlar (random forests), daha sonra ise akÄ±llÄ± Ã¶zellik mÃ¼hendisliÄŸiyle birlikte **gradient boosting** yÃ¶ntemleri Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar vermiÅŸtir.
Ancak gÃ¼nÃ¼mÃ¼zde, geliÅŸmiÅŸ yazÄ±lÄ±mlar ve **AutoML** araÃ§larÄ± sayesinde bu tÃ¼r problemlerde yarÄ±ÅŸmalardan elde edilen geliÅŸmeler genellikle marjinaldir.
Buna karÅŸÄ±lÄ±k, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veri** dÃ¼nyasÄ±nda iyi bir derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mÃ¼ hÃ¢lÃ¢ bÃ¼yÃ¼k fark yaratabilir.
Ã–rneÄŸin, **BERT** gibi Ã¶nceden eÄŸitilmiÅŸ aÄŸlar, birÃ§ok NLP gÃ¶revinde Ã¶nceki standartlara gÃ¶re Ã§ift haneli performans artÄ±ÅŸlarÄ± saÄŸlamÄ±ÅŸtÄ±r.

---

> ğŸ§  Masters (Ustalar) YarÄ±ÅŸmalarÄ±

ArtÄ±k daha az dÃ¼zenlenmektedir, ancak bunlar **Ã¶zel (invite-only)** yarÄ±ÅŸmalardÄ±r.
AmaÃ§, yalnÄ±zca uzmanlar (genellikle Kaggle sÄ±ralamasÄ±nda **Master** veya **Grandmaster** unvanÄ±na sahip yarÄ±ÅŸmacÄ±lar) iÃ§in yarÄ±ÅŸmalar dÃ¼zenlemektir.

---

> ğŸ“… Annuals (YÄ±llÄ±k) YarÄ±ÅŸmalar

Her yÄ±l belirli dÃ¶nemlerde dÃ¼zenlenen yarÄ±ÅŸmalardÄ±r.
Bunlar arasÄ±nda:

* **Santa Claus Competitions** (genellikle algoritmik optimizasyon problemleri Ã¼zerine),
* **March Machine Learning Mania** (2014â€™ten beri her yÄ±l ABD Kolej Basketbol TurnuvalarÄ± sÄ±rasÄ±nda dÃ¼zenlenir) bulunur.

---

> ğŸ”¬ Research (AraÅŸtÄ±rma) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarÄ±n amacÄ± ticari deÄŸil, **bilimsel veya araÅŸtÄ±rma odaklÄ±dÄ±r**, bazen de kamu yararÄ±na hizmet eder.
Bu nedenle genellikle para Ã¶dÃ¼lÃ¼ sunmazlar.
AyrÄ±ca kazananlardan Ã§Ã¶zÃ¼mlerini **aÃ§Ä±k kaynak (open-source)** olarak paylaÅŸmalarÄ± istenebilir.

Ã–rneÄŸin, **Google Landmark Recognition 2020** ([https://www.kaggle.com/c/landmark-recognition-2020](https://www.kaggle.com/c/landmark-recognition-2020)) yarÄ±ÅŸmasÄ±nda, Ã¼nlÃ¼ (veya pek tanÄ±nmamÄ±ÅŸ) yapÄ±tlarÄ±n fotoÄŸraflarÄ±nÄ± tanÄ±mlamak hedeflenmiÅŸtir.

---

> ğŸ’¼ Recruitment (Ä°ÅŸe AlÄ±m) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar, sponsor ÅŸirketlerin **potansiyel iÅŸ adaylarÄ±nÄ±n yeteneklerini test etmek** iÃ§in dÃ¼zenlenir.
Genellikle tek kiÅŸilik takÄ±mlarla sÄ±nÄ±rlÄ±dÄ±r ve en iyi performans gÃ¶steren yarÄ±ÅŸmacÄ±lara **iÅŸ gÃ¶rÃ¼ÅŸmesi** Ã¶dÃ¼lÃ¼ sunulur.
YarÄ±ÅŸma sonunda, deÄŸerlendirilmek isteyen yarÄ±ÅŸmacÄ±larÄ±n **Ã¶zgeÃ§miÅŸlerini (CV)** yÃ¼klemeleri gerekir.

Ã–rnekler:

* **Facebook Recruiting Competition** ([https://www.kaggle.com/c/FacebookRecruiting](https://www.kaggle.com/c/FacebookRecruiting))
* **Yelp Recruiting Competition** ([https://www.kaggle.com/c/yelp-recruiting](https://www.kaggle.com/c/yelp-recruiting))

---

> ğŸš€ Getting Started (BaÅŸlangÄ±Ã§) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar Ã¶dÃ¼l sunmaz, ancak **yeni baÅŸlayanlarÄ±n** Kaggle prensiplerine ve dinamiklerine alÄ±ÅŸmalarÄ± iÃ§in **kolay ve Ã¶ÄŸretici problemler** iÃ§erir.
Genellikle **yarÄ± kalÄ±cÄ±dÄ±rlar** ve liderlik tablolarÄ± zaman zaman yenilenir.
Makine Ã¶ÄŸrenmesine giriÅŸ yapmak istiyorsanÄ±z, bu yarÄ±ÅŸmalar mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r; Ã§Ã¼nkÃ¼ oldukÃ§a **iÅŸbirlikÃ§i bir ortam** sunarlar ve veri iÅŸleme ile model oluÅŸturma adÄ±mlarÄ±nÄ± gÃ¶steren birÃ§ok **Kaggle Notebook** mevcuttur.

BazÄ± Ã¼nlÃ¼ Getting Started yarÄ±ÅŸmalarÄ±:

* [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer)
* [Titanic â€” Machine Learning from Disaster](https://www.kaggle.com/c/titanic)
* [House Prices â€” Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

---

> ğŸ® Playground (Oyun AlanÄ±) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar **Getting Started** yarÄ±ÅŸmalarÄ±ndan biraz daha zordur, ancak hÃ¢lÃ¢ Ã¶ÄŸrenme ve pratik yapma odaklÄ±dÄ±r.
Tam Ã¶lÃ§ekli Featured yarÄ±ÅŸmalar kadar baskÄ± oluÅŸturmazlar, fakat bazen rekabet oldukÃ§a kÄ±zÄ±ÅŸabilir.
Ã–dÃ¼ller genellikle **Kaggle logolu hediyelikler (swag: kupa, tiÅŸÃ¶rt, Ã§orap vb.)** veya kÃ¼Ã§Ã¼k miktarlarda paradÄ±r.

ÃœnlÃ¼ bir Playground yarÄ±ÅŸmasÄ± Ã¶rneÄŸi:

* [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats) â€” kÃ¶pekleri ve kedileri ayÄ±rt eden bir algoritma geliÅŸtirme gÃ¶revi.

---

> ğŸ“Š Analytics (Analiz) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarda deÄŸerlendirme **niteliksel (qualitative)** olup, katÄ±lÄ±mcÄ±lardan fikirler, Ã§Ã¶zÃ¼m taslaklarÄ±, PowerPoint sunumlarÄ±, grafikler vb. hazÄ±rlamalarÄ± beklenir.

---

> ğŸ‘¥ Community (Topluluk) YarÄ±ÅŸmalarÄ±

Eskiden **InClass** olarak bilinen bu yarÄ±ÅŸmalar, **akademik kurumlar** veya bireysel **Kagglerâ€™lar** tarafÄ±ndan dÃ¼zenlenir.
Topluluk yarÄ±ÅŸmalarÄ±nÄ±n duyurusu iÃ§in:
ğŸ”— [https://www.kaggle.com/product-feedback/294337](https://www.kaggle.com/product-feedback/294337)
Kendi yarÄ±ÅŸmanÄ±zÄ± dÃ¼zenleme rehberleri iÃ§in:
ğŸ”— [https://www.kaggle.com/c/about/host](https://www.kaggle.com/c/about/host)
ğŸ”— [https://www.kaggle.com/community-competitions-setup-guide](https://www.kaggle.com/community-competitions-setup-guide)


> **Parul Pandey**
> 
> [https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey)
> 
> 
> 
> Kaggle Notebooks Grandmasterâ€™Ä±, Datasets Masterâ€™Ä± ve H2O.aiâ€™de veri bilimci olan **Parul Pandey** ile analitik yarÄ±ÅŸmalar ve deneyimleri hakkÄ±nda konuÅŸtuk.
> 
> ---
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±n nedir?**
> 
> Veri analizi yapmanÄ±zÄ± ve sonunda kapsamlÄ± bir analiz raporu sunmanÄ±zÄ± gerektiren **Veri AnalitiÄŸi yarÄ±ÅŸmalarÄ±nÄ±** gerÃ§ekten Ã§ok seviyorum. Bunlara *Data Science for Good* (DS4G) yarÄ±ÅŸmalarÄ±, spor analitiÄŸi yarÄ±ÅŸmalarÄ± (Ã¶rneÄŸin NFL) ve genel anket temelli yarÄ±ÅŸmalar dÃ¢hildir. Geleneksel yarÄ±ÅŸmalardan farklÄ± olarak, bu tÃ¼r yarÄ±ÅŸmalarda performansÄ±nÄ±zÄ± baÅŸkalarÄ±yla kÄ±yaslayabileceÄŸiniz bir **liderlik tablosu (leaderboard)** bulunmaz; ayrÄ±ca madalya veya puan da kazanmazsÄ±nÄ±z.
> 
> Ã–te yandan bu yarÄ±ÅŸmalar, veri biliminin Ã§ok yÃ¶nlÃ¼ alanlarÄ±na â€“ veri temizleme, veri madenciliÄŸi, gÃ¶rselleÅŸtirme ve iÃ§gÃ¶rÃ¼ iletimi gibi â€“ dokunan uÃ§tan uca Ã§Ã¶zÃ¼mler gerektirir. Bu tÃ¼r problemler, gerÃ§ek hayattaki senaryolarÄ± taklit etmenizi ve kendi iÃ§gÃ¶rÃ¼nÃ¼zÃ¼, bakÄ±ÅŸ aÃ§Ä±nÄ±zÄ± sunmanÄ±zÄ± saÄŸlar. Tek bir â€œen iyiâ€ Ã§Ã¶zÃ¼m olmayabilir, ancak bu size Ã§eÅŸitli yaklaÅŸÄ±mlarÄ± tartÄ±p deÄŸerlendirerek kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼ze entegre etme fÄ±rsatÄ± verir.
> 
> ---
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinden ne kadar farklÄ±?**
> 
> Ä°lk adÄ±mÄ±m her zaman **EDA (keÅŸifsel veri analizi)** yapmaktÄ±r. Bu, iÅŸ rutinimin de bir parÃ§asÄ±dÄ±r. Genellikle verideki tutarsÄ±zlÄ±klarÄ±, eksik deÄŸerleri, aykÄ±rÄ± noktalarÄ± vb. belirlemek iÃ§in veriyi incelerim; Ã§Ã¼nkÃ¼ bunlar ileride sorun yaratabilir. Sonra **iyi ve gÃ¼venilir bir Ã§apraz doÄŸrulama stratejisi** oluÅŸtururum. ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±nÄ± okur ve diÄŸer kullanÄ±cÄ±larÄ±n paylaÅŸtÄ±ÄŸÄ± Notebookâ€™lara gÃ¶z atarÄ±m. Bu genelde iyi bir baÅŸlangÄ±Ã§ noktasÄ± olur; sonra Ã¶nceki deneyimlerimden edindiÄŸim ÅŸeyleri bu sÃ¼rece eklerim. AyrÄ±ca **model performansÄ±nÄ± izlemek** de Ã§ok Ã¶nemlidir.
> 
> Analitik yarÄ±ÅŸmalar sÃ¶z konusu olduÄŸunda ise problemi genellikle birkaÃ§ adÄ±ma ayÄ±rmayÄ± severim. Ã–rneÄŸin, ilk kÄ±sÄ±m problemi anlamakla ilgilidir ve bu birkaÃ§ gÃ¼n sÃ¼rebilir. SonrasÄ±nda veriyi keÅŸfederim, ardÄ±ndan temel bir baÅŸlangÄ±Ã§ Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururum. Daha sonra bu Ã§Ã¶zÃ¼mÃ¼, her seferinde bir parÃ§a ekleyerek geliÅŸtiririm. Bu, Lego parÃ§alarÄ±nÄ± tek tek ekleyerek son eseri oluÅŸturmak gibidir.
> 
> ---
> 
> **KatÄ±ldÄ±ÄŸÄ±n zorlu bir yarÄ±ÅŸmadan ve bu gÃ¶revi nasÄ±l ele aldÄ±ÄŸÄ±ndan bahseder misin?**
> 
> Daha Ã¶nce de belirttiÄŸim gibi genellikle Analitik yarÄ±ÅŸmalara katÄ±lmayÄ± tercih ediyorum, ama bazen klasik yarÄ±ÅŸmalarda da ÅŸansÄ±mÄ± deniyorum. Ã–zellikle **Environmental Insights Explorer** adlÄ± *Data Science for Good* yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/ds4g-environmental-insightsexplorer](https://www.kaggle.com/c/ds4g-environmental-insightsexplorer)) Ã§ok ilgimi Ã§ekmiÅŸti. GÃ¶rev, mevcut metodolojilerdeki emisyon katsayÄ±larÄ±nÄ± hesaplamak yerine, **uzaktan algÄ±lama (remote sensing)** tekniklerini kullanarak Ã§evresel emisyonlarÄ± anlamaktÄ±.
> 
> Beni en Ã§ok etkileyen ÅŸey, bu yarÄ±ÅŸmanÄ±n ele aldÄ±ÄŸÄ± konuydu. Gezegenimiz iklim deÄŸiÅŸikliÄŸiyle mÃ¼cadele ediyor ve bu yarÄ±ÅŸma tam da bu konuya odaklanmÄ±ÅŸtÄ±. YarÄ±ÅŸma iÃ§in araÅŸtÄ±rma yaparken, **uydu gÃ¶rÃ¼ntÃ¼leme teknolojilerindeki ilerlemeyi** gÃ¶rÃ¼nce hayran kaldÄ±m. Bu sayede bu konuyu daha derinlemesine anlama fÄ±rsatÄ± buldum. Landsat, Modis ve Sentinel gibi uydularÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve bu verilerin nasÄ±l eriÅŸilebilir hale getirildiÄŸini Ã¶ÄŸrendim. Bu yarÄ±ÅŸma, Ã¶nceden Ã§ok az bilgim olan bir alan hakkÄ±nda bilgi edinmemi saÄŸlayan harika bir deneyimdi.
> 
> ---
> 
> **YarÄ±ÅŸma biÃ§imleri Ã¼zerine**
> 
> Kaggle yarÄ±ÅŸmalarÄ±nÄ±n kendi iÃ§inde farklÄ± biÃ§imleri de vardÄ±r. En yaygÄ±n olanÄ±, katÄ±lÄ±mcÄ±nÄ±n Ã§Ã¶zÃ¼mÃ¼nÃ¼ sunup deÄŸerlendirildiÄŸi **â€œbasit formatâ€tÄ±r.** Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸmalarda**, yarÄ±ÅŸma ikiye ayrÄ±lÄ±r: Ä°lk kÄ±sÄ±m tamamlandÄ±ktan sonra ikinci kÄ±sma Ã¶zel bir veri seti yalnÄ±zca ilk kÄ±sÄ±m katÄ±lÄ±mcÄ±larÄ±na verilir. Bu format, yarÄ±ÅŸmacÄ±larÄ±n hile yapma ihtimalini azaltmak iÃ§in tasarlanmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼reliÄŸine eriÅŸilebilen, daha Ã¶nce hiÃ§ gÃ¶rÃ¼lmemiÅŸ bir test setinde yapÄ±lÄ±r. Bu nedenle katÄ±lÄ±mcÄ±larÄ±n deneme sayÄ±sÄ± ve zamanÄ± daha sÄ±nÄ±rlÄ±dÄ±r.
> 
> ---
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nda bilmek isteyeceÄŸin ÅŸey ne olurdu?**
> 
> Kaggleâ€™daki ilk yÄ±llarÄ±mda yaptÄ±ÄŸÄ±m bazÄ± hatalardan bahsedebilirim.
> 
> Ã–ncelikle, Ã§oÄŸu yeni baÅŸlayan **Kaggleâ€™Ä± sadece yarÄ±ÅŸma platformu** olarak gÃ¶rÃ¼r. EÄŸer yarÄ±ÅŸmalarÄ± seviyorsanÄ±z, burada fazlasÄ±yla var; ama Kaggle aynÄ± zamanda baÅŸka alanlarda da katkÄ± yapabileceÄŸiniz bir platformdur. Kod yazabilir, baÅŸkalarÄ±yla paylaÅŸabilir, saÄŸlÄ±klÄ± tartÄ±ÅŸmalara katÄ±labilir ve aÄŸÄ±nÄ±zÄ± geniÅŸletebilirsiniz. Toplulukla kaliteli veri setleri oluÅŸturup paylaÅŸabilirsiniz. BaÅŸlangÄ±Ã§ta Kaggleâ€™Ä± yalnÄ±zca veri seti indirmek iÃ§in kullanÄ±yordum; ancak birkaÃ§ yÄ±l Ã¶nce aktif oldum. Geriye dÃ¶nÃ¼p baktÄ±ÄŸÄ±mda, daha Ã¶nce ne kadar yanÄ±ldÄ±ÄŸÄ±mÄ± gÃ¶rÃ¼yorum.
> 
> BirÃ§ok kiÅŸi yarÄ±ÅŸmalardan Ã§ekiniyor. Ã–nce platforma alÄ±ÅŸÄ±p, sonra yavaÅŸ yavaÅŸ yarÄ±ÅŸmalara katÄ±labilirsiniz.
> 
> AyrÄ±ca birÃ§ok kiÅŸi **tek baÅŸÄ±na Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in motivasyonunu kaybedip bÄ±rakÄ±yor.** Kaggleâ€™da takÄ±m kurmanÄ±n birÃ§ok gÃ¶rÃ¼nmeyen avantajÄ± var. TakÄ±m Ã§alÄ±ÅŸmasÄ± Ã¶ÄŸrenmenizi, deneyim paylaÅŸmanÄ±zÄ± ve sÄ±nÄ±rlÄ± bir zaman diliminde ortak bir hedefe ulaÅŸmayÄ± Ã¶ÄŸretir.
> 
> ---
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± da kullanÄ±yor musun? Bunlar Kaggle ile nasÄ±l kÄ±yaslanÄ±r?**
> 
> Åu anda zamanÄ±mÄ±n Ã§oÄŸunu Kaggleâ€™a ayÄ±rÄ±yorum, ancak geÃ§miÅŸte **Zindi** adlÄ± platformu da kullandÄ±m. Zindi, Afrika odaklÄ± veri bilimi yarÄ±ÅŸmalarÄ±na yoÄŸunlaÅŸan bir platform. Afrikaâ€™ya Ã¶zel veri setlerine eriÅŸmek iÃ§in harika bir yer.
> 
> Kaggle Ã§ok yÃ¶nlÃ¼ bir platform olsa da, dÃ¼nyanÄ±n farklÄ± bÃ¶lgelerinden gelen problem ifadeleri konusunda eksiklikler var. Son zamanlarda bu Ã§eÅŸitlilik artmaya baÅŸladÄ±; Ã¶rneÄŸin **chaii yarÄ±ÅŸmasÄ±** â€“ Hint dillerine odaklanan bir NLP yarÄ±ÅŸmasÄ± â€“ buna iyi bir Ã¶rnektir. Benzer ÅŸekilde, farklÄ± Ã¼lkelere odaklanan yarÄ±ÅŸmalarÄ±n da hem araÅŸtÄ±rma hem de genel veri bilimi topluluÄŸu iÃ§in faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.

Kaggle yarÄ±ÅŸmalarÄ±nÄ±n bu sÄ±nÄ±flandÄ±rmasÄ±nÄ±n Ã¶tesinde, yarÄ±ÅŸmalarÄ±n farklÄ± **formatlarda** dÃ¼zenlenebileceÄŸini de dikkate almak gerekir.
En yaygÄ±n format, daha Ã¶nce aÃ§Ä±klandÄ±ÄŸÄ± gibi, bir Ã§Ã¶zÃ¼m sunduÄŸunuz ve bu Ã§Ã¶zÃ¼mÃ¼n deÄŸerlendirildiÄŸi **â€œbasit (simple)â€ formattÄ±r.**
Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸma (two-stage competition)** formatÄ±nda ise yarÄ±ÅŸma iki bÃ¶lÃ¼me ayrÄ±lÄ±r. Son veri seti yalnÄ±zca ilk bÃ¶lÃ¼m tamamlandÄ±ktan sonra ve sadece bu ilk bÃ¶lÃ¼me katÄ±lan yarÄ±ÅŸmacÄ±lara sunulur.
Bu iki aÅŸamalÄ± yarÄ±ÅŸma formatÄ±, bazÄ± yarÄ±ÅŸmacÄ±larÄ±n **hile yapma veya kurallarÄ± ihlal etme olasÄ±lÄ±ÄŸÄ±nÄ± azaltmak** amacÄ±yla ortaya Ã§Ä±kmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼re iÃ§in eriÅŸilebilen ve daha Ã¶nce hiÃ§ test edilmemiÅŸ bir test seti Ã¼zerinde yapÄ±lÄ±r.
Orijinal Kaggle yarÄ±ÅŸma formatÄ±nÄ±n aksine, bu durumda yarÄ±ÅŸmacÄ±larÄ±n **Ã§ok daha az zamanÄ±** ve test setindeki Ã¶rÃ¼ntÃ¼leri (pattern) keÅŸfetmek iÃ§in **Ã§ok daha az sayÄ±da gÃ¶nderim hakkÄ±** vardÄ±r.

AynÄ± nedenle, son zamanlarda **Code yarÄ±ÅŸmalarÄ±** da ortaya Ã§Ä±kmÄ±ÅŸtÄ±r.
Bu yarÄ±ÅŸmalarda tÃ¼m gÃ¶nderimler doÄŸrudan bir **Kaggle Notebook** Ã¼zerinden yapÄ±lÄ±r ve herhangi bir dÄ±ÅŸ dosya yÃ¼kleme seÃ§eneÄŸi devre dÄ±ÅŸÄ± bÄ±rakÄ±lmÄ±ÅŸtÄ±r.

Kaggle yarÄ±ÅŸma kariyerlerinin farklÄ± aÅŸamalarÄ±nda olan kullanÄ±cÄ±larÄ±n her tÃ¼r yarÄ±ÅŸmaya katÄ±lmasÄ±nda hiÃ§bir kÄ±sÄ±tlama yoktur.
Ancak, **veri bilimi konusundaki deneyim dÃ¼zeyinize** ve **hesaplama kaynaklarÄ±nÄ±za** baÄŸlÄ± olarak, belirli yarÄ±ÅŸma tÃ¼rleri veya formatlarÄ± lehine veya aleyhine bazÄ± Ã¶nerilerimiz vardÄ±r:

* **Tamamen yeni baÅŸlayanlar** iÃ§in, *Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± iyi bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r.
  Bu yarÄ±ÅŸmalar, yÃ¼ksek rekabet baskÄ±sÄ± olmadan Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmenizi saÄŸlar.
  Bununla birlikte, birÃ§ok yeni baÅŸlayan da *Featured* veya *Research* yarÄ±ÅŸmalarÄ±ndan baÅŸlamÄ±ÅŸ ve rekabet baskÄ±sÄ±nÄ±n altÄ±nda daha hÄ±zlÄ± Ã¶ÄŸrendiklerini fark etmiÅŸtir.
  Bu nedenle Ã¶nerimiz, **Ã¶ÄŸrenme tarzÄ±nÄ±za gÃ¶re karar vermenizdir:**

  * BazÄ± Kaggle kullanÄ±cÄ±larÄ± keÅŸfederek ve iÅŸ birliÄŸi yaparak Ã¶ÄŸrenir (*Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± bu kiÅŸiler iÃ§in idealdir).
  * DiÄŸerleri ise hÄ±zlÄ± tempolu bir yarÄ±ÅŸmanÄ±n rekabet ortamÄ±nda motive olur.

* *Featured* ve *Research* yarÄ±ÅŸmalarÄ±nda ise ÅŸunu da gÃ¶z Ã¶nÃ¼nde bulundurmak gerekir:
  Bu yarÄ±ÅŸmalar genellikle yapay zekÃ¢ ve makine Ã¶ÄŸrenmesinin **uÃ§ (deneysel) uygulamalarÄ±yla** ilgilidir.
  DolayÄ±sÄ±yla bu yarÄ±ÅŸmalarda baÅŸarÄ±lÄ± olabilmek iÃ§in ya bu alanda **saÄŸlam bir altyapÄ±ya sahip olmanÄ±z** ya da yarÄ±ÅŸmanÄ±n uygulama alanÄ±yla ilgili araÅŸtÄ±rmalarÄ± Ã¶ÄŸrenmeye istekli olmanÄ±z gerekir.

Son olarak, Ã§oÄŸu yarÄ±ÅŸmanÄ±n, birÃ§ok veri bilimcisinin iÅŸ yerinde eriÅŸemediÄŸi **hesaplama kaynaklarÄ±na** ihtiyaÃ§ duyduÄŸunu unutmayÄ±n.
Kaggle dÄ±ÅŸÄ±ndaki bulut platformlarÄ±nÄ± kullanÄ±rsanÄ±z bu, **artan maliyetlere** yol aÃ§abilir.
Bu nedenle, **Code yarÄ±ÅŸmalarÄ±** veya **zaman ve kaynak sÄ±nÄ±rlamalarÄ± olan yarÄ±ÅŸmalar**, tÃ¼m katÄ±lÄ±mcÄ±larÄ± aynÄ± kaynak dÃ¼zeyine getirmeyi amaÃ§ladÄ±klarÄ± iÃ§in Ã§abalarÄ±nÄ±zÄ± yoÄŸunlaÅŸtÄ±rmak aÃ§Ä±sÄ±ndan ideal bir seÃ§enek olabilir.

#### Submission and leaderboard dynamics *(GÃ¶nderim ve liderlik tablosu dinamikleri)*

Kaggleâ€™Ä±n Ã§alÄ±ÅŸma biÃ§imi basit gÃ¶rÃ¼nebilir: Test seti katÄ±lÄ±mcÄ±lardan gizlenir; modelinizi eÄŸitirsiniz; eÄŸer modeliniz test setindeki sonuÃ§larÄ± en iyi ÅŸekilde tahmin ederse yÃ¼ksek puan alÄ±r ve muhtemelen kazanÄ±rsÄ±nÄ±z.
Ne yazÄ±k ki, bu tanÄ±m Kaggle yarÄ±ÅŸmalarÄ±nÄ±n iÃ§ iÅŸleyiÅŸini **fazla basitleÅŸtirilmiÅŸ** bir ÅŸekilde aÃ§Ä±klar.
Bu aÃ§Ä±klama, yarÄ±ÅŸmacÄ±larÄ±n doÄŸrudan ve dolaylÄ± etkileÅŸimleriyle ilgili dinamikleri ya da karÅŸÄ± karÅŸÄ±ya olduÄŸunuz problemin, eÄŸitim ve test setinin **ince ayrÄ±ntÄ±larÄ±nÄ± (nÃ¼anslarÄ±nÄ±)** dikkate almaz.

##### Explaining the Common Task Framework paradigm *(Ortak GÃ¶rev Ã‡erÃ§evesi paradigmasÄ±nÄ±n aÃ§Ä±klanmasÄ±)*

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair daha kapsamlÄ± bir aÃ§Ä±klama, **Stanford Ãœniversitesi Ä°statistik ProfesÃ¶rÃ¼ David Donoho** tarafÄ±ndan *50 Years of Data Science* (Veri Biliminin 50 YÄ±lÄ±) adlÄ± makalesinde verilmiÅŸtir.
Bu makale ilk olarak *Journal of Computational and Graphical Statistics* dergisinde yayÄ±mlanmÄ±ÅŸ, ardÄ±ndan MIT Bilgisayar Bilimi ve Yapay ZekÃ¢ LaboratuvarÄ± sitesinde paylaÅŸÄ±lmÄ±ÅŸtÄ±r (bkz. [http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)).

ProfesÃ¶r Donoho doÄŸrudan Kaggleâ€™dan deÄŸil, genel olarak **veri bilimi yarÄ±ÅŸma platformlarÄ±ndan** bahseder.
BilgisayarlÄ± dilbilimci **Mark Liberman**â€™dan alÄ±ntÄ± yaparak, veri bilimi yarÄ±ÅŸmalarÄ±nÄ± ve platformlarÄ±nÄ± **â€œCommon Task Framework (CTF)â€ â€” Ortak GÃ¶rev Ã‡erÃ§evesi** paradigmasÄ±nÄ±n bir parÃ§asÄ± olarak tanÄ±mlar.
Bu paradigma, son on yÄ±llarda birÃ§ok alanda veri biliminin sessiz ama istikrarlÄ± bir ÅŸekilde ilerlemesini saÄŸlamÄ±ÅŸtÄ±r.

Donoho, CTFâ€™nin veri bilimi problemlerine **ampirik (deneysel)** aÃ§Ä±dan Ã§Ã¶zÃ¼m getirmede son derece etkili olduÄŸunu sÃ¶yler ve bunu desteklemek iÃ§in **Netflix yarÄ±ÅŸmasÄ±** ile Ã§eÅŸitli **DARPA yarÄ±ÅŸmalarÄ±nÄ±** baÅŸarÄ±lÄ± Ã¶rnekler olarak gÃ¶sterir.
CTF paradigmasÄ±, birÃ§ok alanda en iyi Ã§Ã¶zÃ¼mleri yeniden ÅŸekillendirmeye katkÄ±da bulunmuÅŸtur.

---

**CTFâ€™nin bileÅŸenleri ve â€œgizli sosuâ€**

Bir CTF, bazÄ± bileÅŸenlerden ve â€œgizli bir sostanâ€ oluÅŸur.
BileÅŸenler ÅŸunlardÄ±r:

1. Herkese aÃ§Ä±k bir veri seti ve bununla iliÅŸkili bir tahmin gÃ¶revi,
2. Bu gÃ¶reve en iyi tahmini Ã¼retmek iÃ§in ortak bir amaÃ§la Ã§alÄ±ÅŸan yarÄ±ÅŸmacÄ±lar,
3. KatÄ±lÄ±mcÄ±larÄ±n tahminlerini adil ve objektif biÃ§imde puanlayan, ancak Ã§Ã¶zÃ¼me dair fazla ipucu vermeyen (ya da en azÄ±ndan bunu sÄ±nÄ±rlayan) bir deÄŸerlendirme sistemi.

Bu sistem, gÃ¶rev aÃ§Ä±k ÅŸekilde tanÄ±mlandÄ±ÄŸÄ±nda ve veri kaliteli olduÄŸunda en iyi ÅŸekilde Ã§alÄ±ÅŸÄ±r.
Zaman iÃ§inde Ã§Ã¶zÃ¼mlerin performansÄ± kÃ¼Ã§Ã¼k artÄ±ÅŸlarla geliÅŸir ve sonunda bir **asimptota (doyum noktasÄ±na)** ulaÅŸÄ±r.
Bu sÃ¼reÃ§, katÄ±lÄ±mcÄ±lar arasÄ±nda belli bir dÃ¼zeyde paylaÅŸÄ±mÄ±n teÅŸvik edilmesiyle hÄ±zlanabilir.
Kaggleâ€™da bu paylaÅŸÄ±m; **tartÄ±ÅŸmalar, paylaÅŸÄ±lan Kaggle Notebookâ€™larÄ±** ve **Datasets** bÃ¶lÃ¼mÃ¼ndeki ek veriler aracÄ±lÄ±ÄŸÄ±yla gerÃ§ekleÅŸir.

CTF paradigmasÄ±na gÃ¶re, bir yarÄ±ÅŸmadaki **rekabet baskÄ±sÄ±**, Ã§Ã¶zÃ¼mlerin sÃ¼rekli olarak geliÅŸmesi iÃ§in tek baÅŸÄ±na yeterlidir.
Bu rekabet baskÄ±sÄ±, katÄ±lÄ±mcÄ±lar arasÄ±nda belli Ã¶lÃ§Ã¼de **bilgi paylaÅŸÄ±mÄ±yla** birleÅŸtiÄŸinde, geliÅŸme Ã§ok daha hÄ±zlÄ± gerÃ§ekleÅŸir.
Ä°ÅŸte bu nedenle Kaggle, paylaÅŸÄ±mÄ± teÅŸvik eden birÃ§ok Ã¶dÃ¼l ve mekanizma getirmiÅŸtir.

---

**CTFâ€™nin gizli sosu: rekabetin kendisi**

CTF paradigmasÄ±ndaki â€œgizli sosâ€, **bizzat yarÄ±ÅŸmanÄ±n kendisidir**.
Bu yapÄ±, ampirik performansÄ±n artÄ±rÄ±lmasÄ±nÄ±n hedeflendiÄŸi pratik bir problem Ã§erÃ§evesinde, her zaman yeni **Ã¶lÃ§Ã¼tlerin (benchmark)**, **veri ve modelleme Ã§Ã¶zÃ¼mlerinin**, ve genel anlamda **makine Ã¶ÄŸrenmesinin daha iyi uygulanma biÃ§imlerinin** ortaya Ã§Ä±kmasÄ±nÄ± saÄŸlar.

Bir yarÄ±ÅŸma, dolayÄ±sÄ±yla bir tahmin problemini Ã§Ã¶zmenin yeni yollarÄ±nÄ±, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** iÃ§in yeni yÃ¶ntemleri ve yeni **algoritmik veya modelleme Ã§Ã¶zÃ¼mlerini** sunabilir.
Ã–rneÄŸin, **derin Ã¶ÄŸrenme (deep learning)** yalnÄ±zca akademik araÅŸtÄ±rmalardan doÄŸmamÄ±ÅŸtÄ±r; tersine, etkinliÄŸini kanÄ±tlayan baÅŸarÄ±lÄ± yarÄ±ÅŸmalar sayesinde bÃ¼yÃ¼k bir ivme kazanmÄ±ÅŸtÄ±r.
(Ã–rneÄŸin, Geoffrey Hinton ekibinin kazandÄ±ÄŸÄ± **Merck yarÄ±ÅŸmasÄ±nÄ±** hatÄ±rlayalÄ±m: [https://www.kaggle.com/c/MerckActivity/overview/winners](https://www.kaggle.com/c/MerckActivity/overview/winners)).

---

**CTF ve aÃ§Ä±k yazÄ±lÄ±m hareketi**

**AÃ§Ä±k kaynak yazÄ±lÄ±m hareketi** ile birleÅŸtiÄŸinde (Ã¶rneÄŸin Scikit-learn, TensorFlow veya PyTorch gibi gÃ¼Ã§lÃ¼ analitik araÃ§lara herkesin eriÅŸebilmesi), CTF paradigmasÄ± Ã§ok daha iyi sonuÃ§lar Ã¼retir.
Bunun nedeni, tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n baÅŸlangÄ±Ã§ta **aynÄ± dÃ¼zeyde olanaklara sahip** olmasÄ±dÄ±r.

Ancak, bir yarÄ±ÅŸmadaki Ã§Ã¶zÃ¼mÃ¼n **Ã¶zel donanÄ±m veya yÃ¼ksek iÅŸlem gÃ¼cÃ¼ne** dayanmasÄ±, elde edilebilecek sonuÃ§larÄ± sÄ±nÄ±rlayabilir.
Ã‡Ã¼nkÃ¼ bu durum, bu tÃ¼r kaynaklara eriÅŸimi olmayan yarÄ±ÅŸmacÄ±larÄ±n doÄŸru ÅŸekilde katÄ±lÄ±m gÃ¶stermesini ya da diÄŸer katÄ±lÄ±mcÄ±lar Ã¼zerinde **rekabet baskÄ±sÄ±** oluÅŸturarak dolaylÄ± katkÄ± saÄŸlamasÄ±nÄ± engelleyebilir.

Ä°ÅŸte bu nedenle Kaggle, yarÄ±ÅŸmalara katÄ±lanlar iÃ§in **Ã¼cretsiz bulut hizmetleri** (Ã¶rneÄŸin **Kaggle Notebooks**) sunmaya baÅŸlamÄ±ÅŸtÄ±r.
Bu uygulama, Ã¶zellikle donanÄ±m yoÄŸun yarÄ±ÅŸmalarda (Ã¶rneÄŸin derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ± gibi) bazÄ± farklarÄ± azaltabilir ve genel anlamda rekabeti artÄ±rabilir.

##### Understanding what can go wrong in a competition *(Bir yarÄ±ÅŸmada nelerin ters gidebileceÄŸini anlamak)*

**CTF ParadigmasÄ± ve YarÄ±ÅŸma BaÅŸarÄ±sÄ±zlÄ±klarÄ±nÄ±n Nedenleri**

CTF paradigmasÄ±na dair Ã¶nceki aÃ§Ä±klamamÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurursak, bir yarÄ±ÅŸmanÄ±n tek ihtiyacÄ± uygun bir platformda dÃ¼zenlenmekmiÅŸ gibi gÃ¶rÃ¼nebilir. BÃ¶yle olursa, katÄ±lÄ±mcÄ±lar iÃ§in olumlu bir katÄ±lÄ±m ve sponsor ÅŸirket iÃ§in olaÄŸanÃ¼stÃ¼ modeller gibi iyi sonuÃ§larÄ±n kendiliÄŸinden ortaya Ã§Ä±kacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

Ancak, hem katÄ±lÄ±mcÄ±lar hem de yarÄ±ÅŸmayÄ± dÃ¼zenleyen kurum aÃ§Ä±sÄ±ndan **hayal kÄ±rÄ±klÄ±ÄŸÄ±na yol aÃ§abilecek** bazÄ± durumlar da meydana gelebilir:

* Veri sÄ±zÄ±ntÄ±sÄ± (data leakage)
* Liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼m denemesi (probing)
* AÅŸÄ±rÄ± uyum (overfitting) ve buna baÄŸlÄ± liderlik tablosu deÄŸiÅŸimleri
* Ã–zel paylaÅŸÄ±m (private sharing)

---

**Veri SÄ±zÄ±ntÄ±sÄ± (Data Leakage)**

**Veri sÄ±zÄ±ntÄ±sÄ±**, Ã§Ã¶zÃ¼mÃ¼n bir kÄ±smÄ±nÄ±n bizzat verinin kendisinden geri izlenebilmesi durumudur.
Ã–rneÄŸin, bazÄ± deÄŸiÅŸkenler hedef deÄŸiÅŸkenden (target variable) sonra oluÅŸmuÅŸ olabilir ve bu da hedef hakkÄ±nda bilgi sÄ±zdÄ±rÄ±r.

Bu durum, Ã¶rneÄŸin dolandÄ±rÄ±cÄ±lÄ±k tespitinde, dolandÄ±rÄ±cÄ±lÄ±k gerÃ§ekleÅŸtikten sonra gÃ¼ncellenen deÄŸiÅŸkenleri kullandÄ±ÄŸÄ±nÄ±zda; veya satÄ±ÅŸ tahmini yaparken, bir Ã¼rÃ¼nÃ¼n **gerÃ§ek daÄŸÄ±tÄ±m bilgilerini** iÅŸlediÄŸinizde (daha fazla daÄŸÄ±tÄ±m â†’ daha fazla talep â†’ daha fazla satÄ±ÅŸ) ortaya Ã§Ä±kar.

BaÅŸka bir Ã¶rnek de, **eÄŸitim ve test Ã¶rneklerinin tahmin edilebilir bir sÄ±rada dÃ¼zenlenmiÅŸ olmasÄ±** ya da Ã¶rnek kimliklerinin (identifier) deÄŸerlerinin Ã§Ã¶zÃ¼me dair ipuÃ§larÄ± iÃ§ermesidir.
Ã–rneÄŸin, kimlik numarasÄ± hedef deÄŸiÅŸkenin sÄ±rasÄ±na gÃ¶re belirlenmiÅŸse ya da kimlik deÄŸeri zamanla iliÅŸkiliyse ve zaman hedef deÄŸiÅŸkenin olasÄ±lÄ±ÄŸÄ±nÄ± etkiliyorsa bu da bir sÄ±zÄ±ntÄ±dÄ±r.

Bu tÃ¼r veri sÄ±zÄ±ntÄ±larÄ±na, bazÄ± yarÄ±ÅŸmacÄ±lar tarafÄ±ndan **â€œaltÄ±n Ã¶zellikler (golden features)â€** adÄ± verilir â€” Ã§Ã¼nkÃ¼ verideki bu tÃ¼r kÃ¼Ã§Ã¼k ipuÃ§larÄ±nÄ± fark etmek, katÄ±lÄ±mcÄ±lar iÃ§in adeta altÄ±n deÄŸerinde Ã¶dÃ¼ller kazandÄ±rabilir.
Ancak bu durum genellikle **yeniden kullanÄ±labilir olmayan Ã§Ã¶zÃ¼mler** Ã¼retir.
Bu da sponsor iÃ§in **optimal olmayan sonuÃ§lar** anlamÄ±na gelir, ancak en azÄ±ndan sponsor hangi deÄŸiÅŸkenlerin sÄ±zÄ±ntÄ±ya yol aÃ§abileceÄŸini Ã¶ÄŸrenmiÅŸ olur.

---

**Liderlik Tablosu Ãœzerinden Ã‡Ã¶zÃ¼m Denemesi (Leaderboard Probing)**

Bir diÄŸer problem, **liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼mÃ¼ test etmek veya â€œdeÅŸifre etmekâ€** olasÄ±lÄ±ÄŸÄ±dÄ±r.
Bu durumda, yarÄ±ÅŸmacÄ±lar deÄŸerlendirme metriklerinden yararlanarak sÃ¼rekli denemeler yapabilir ve bu yolla Ã§Ã¶zÃ¼m hakkÄ±nda bilgi elde edebilir.
Yine bu tÃ¼r Ã§Ã¶zÃ¼mler, farklÄ± koÅŸullarda tamamen **kullanÄ±lamaz** hale gelir.

Bunun aÃ§Ä±k bir Ã¶rneÄŸi **â€œDonâ€™t Overfit IIâ€** yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r.
Kazanan katÄ±lÄ±mcÄ± **Zachary Mayers**, her bir deÄŸiÅŸkeni tek tek gÃ¶ndererek her birinin model Ã¼zerindeki etkisini analiz etmiÅŸ ve bu yolla modelinin katsayÄ±larÄ±nÄ± doÄŸru tahmin edebilmiÅŸtir.
(Zachâ€™Ä±n detaylÄ± Ã§Ã¶zÃ¼mÃ¼nÃ¼ burada okuyabilirsiniz: [https://www.kaggle.com/c/dont-overfit-ii/discussion/91766](https://www.kaggle.com/c/dont-overfit-ii/discussion/91766))

Genellikle **zaman serisi problemleri** veya test verisinde sistematik deÄŸiÅŸimler olan diÄŸer problemler, bu tÃ¼r probingâ€™den ciddi ÅŸekilde etkilenebilir.
Ã‡Ã¼nkÃ¼ bu durum, yarÄ±ÅŸmacÄ±larÄ±n tahminlerini Ã¶rneÄŸin sabit bir sayÄ± ile Ã§arpmak gibi bir **son iÅŸleme (post-processing)** adÄ±mÄ±yla puanlarÄ±nÄ± artÄ±rmalarÄ±na olanak tanÄ±yabilir.

---

**Liderlik Tablosuna AÅŸÄ±rÄ± GÃ¼venme ve AÅŸÄ±rÄ± Uyum (Overfitting)**

Liderlik tablosuna aÅŸÄ±rÄ± gÃ¼venmek, bir baÅŸka tÃ¼r **aÅŸÄ±rÄ± uyum (overfitting)** Ã¶rneÄŸidir.
KatÄ±lÄ±mcÄ±lar kendi doÄŸrulama testlerinden Ã§ok liderlik tablosundaki geri bildirimlere gÃ¶re hareket ettiklerinde bu durum ortaya Ã§Ä±kar.

Bazen bu durum yarÄ±ÅŸmanÄ±n **tamamen baÅŸarÄ±sÄ±z olmasÄ±na**, yani nihai liderlik tablosunda **beklenmedik ve rastlantÄ±sal sÄ±ralama deÄŸiÅŸikliklerine (shake-up)** yol aÃ§abilir.
BÃ¶yle bir durumda kazanan Ã§Ã¶zÃ¼mler, aslÄ±nda probleme uygun olmayan veya tamamen tesadÃ¼fi Ã§Ã¶zÃ¼mler olabilir.

Bu tÃ¼r olaylar, **eÄŸitim seti ile test seti arasÄ±ndaki farklarÄ± analiz eden** bazÄ± tekniklerin geliÅŸtirilmesine yol aÃ§mÄ±ÅŸtÄ±r.
Bu tÃ¼r analizlere **adversarial testing** denir ve liderlik tablosuna ne kadar gÃ¼venileceÄŸi veya eÄŸitim ve test setleri arasÄ±nda tamamen kaÃ§Ä±nÄ±lmasÄ± gereken Ã¶zellikler olup olmadÄ±ÄŸÄ± konusunda fikir verir.
Ã–rnek olarak, **Bojan Tunguz**â€™un ÅŸu Notebookâ€™una gÃ¶z atabilirsiniz:
[https://www.kaggle.com/tunguz/adversarial-ieee](https://www.kaggle.com/tunguz/adversarial-ieee).

---

**Overfittingâ€™e KarÅŸÄ± Savunma Stratejileri**

Liderlik tablosuna aÅŸÄ±rÄ± uyumu Ã¶nlemenin bir baÅŸka yolu, **gÃ¼venli stratejiler** kullanmaktÄ±r.
Ã–rneÄŸin, genellikle her katÄ±lÄ±mcÄ±nÄ±n **final deÄŸerlendirmesi iÃ§in iki Ã§Ã¶zÃ¼m** gÃ¶ndermesine izin verilir.
Bu durumda iyi bir strateji, birini liderlik tablosuna gÃ¶re en baÅŸarÄ±lÄ± olan Ã§Ã¶zÃ¼m olarak, diÄŸerini ise **kendi Ã§apraz doÄŸrulama testlerinde** en iyi performans gÃ¶steren Ã§Ã¶zÃ¼m olarak gÃ¶ndermektir.

Liderlik tablosu probingâ€™i ve overfittingâ€™i Ã¶nlemek iÃ§in Kaggle, daha Ã¶nce de bahsettiÄŸimiz gibi, **iki aÅŸamalÄ± deÄŸerlendirme sistemi** iÃ§eren **Code yarÄ±ÅŸmalarÄ±na** yÃ¶nelik Ã§eÅŸitli yenilikler getirmiÅŸtir.
Bu yarÄ±ÅŸmalarda katÄ±lÄ±mcÄ±lar test verisini hiÃ§ gÃ¶rmedikleri iÃ§in, kendi **yerel doÄŸrulama testlerine** daha fazla Ã¶nem vermek zorunda kalÄ±rlar.

---

**Ã–zel PaylaÅŸÄ±m (Private Sharing) ve Etik DÄ±ÅŸÄ± DavranÄ±ÅŸlar**

Bir yarÄ±ÅŸmayÄ± bozabilecek bir diÄŸer unsur, **Ã¶zel paylaÅŸÄ±m (private sharing)** yani fikir ve Ã§Ã¶zÃ¼mlerin yalnÄ±zca kapalÄ± bir grup arasÄ±nda paylaÅŸÄ±lmasÄ±dÄ±r.
Buna ek olarak, **birden fazla hesapla yarÄ±ÅŸmak**, **birden fazla takÄ±ma katÄ±lÄ±p fikir Ã§almak** gibi etik dÄ±ÅŸÄ± davranÄ±ÅŸlar da olabilir.

Bu tÃ¼r durumlar, bazÄ± katÄ±lÄ±mcÄ±lar iÃ§in avantaj yaratÄ±rken Ã§oÄŸunluk iÃ§in dezavantaj doÄŸurur â€” yani **bilgi asimetrisi** oluÅŸur.
BÃ¶ylece, yarÄ±ÅŸma boyunca paylaÅŸÄ±m eksik kalÄ±r ve az sayÄ±da takÄ±m tam rekabet baskÄ±sÄ± yaratabilir.

AyrÄ±ca, bu tÃ¼r durumlar katÄ±lÄ±mcÄ±larÄ±n farkÄ±na vardÄ±ÄŸÄ±nda (Ã¶rneÄŸin ÅŸu tartÄ±ÅŸmaya bakÄ±labilir: [https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503](https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503)), yarÄ±ÅŸmaya ve sonraki yarÄ±ÅŸmalara olan gÃ¼ven ve katÄ±lÄ±m da azalabilir.

#### Computational resources *(Hesaplama kaynaklarÄ±)*

BazÄ± yarÄ±ÅŸmalar, **Ã¼retim ortamÄ±nda uygulanabilir Ã§Ã¶zÃ¼mler** elde edebilmek iÃ§in belirli sÄ±nÄ±rlamalar getirir.
Ã–rneÄŸin, **Bosch Production Line Performance** yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/bosch-production-line-performance](https://www.kaggle.com/c/bosch-production-line-performance)) Ã§Ã¶zÃ¼m modelleri iÃ§in **Ã§alÄ±ÅŸma sÃ¼resi**, **Ã§Ä±ktÄ± dosyasÄ± boyutu** ve **bellek kullanÄ±mÄ±** aÃ§Ä±sÄ±ndan katÄ± sÄ±nÄ±rlamalara sahipti.

**Notebook tabanlÄ± yarÄ±ÅŸmalar** (Ã¶nceden *Kernel-Only* yarÄ±ÅŸmalarÄ± olarak biliniyordu), hem eÄŸitimin hem de Ã§Ä±karÄ±mÄ±n (inference) **Kaggle Notebooks** Ã¼zerinde gerÃ§ekleÅŸtirilmesini zorunlu kÄ±lar.
Bu durumda, kullanmanÄ±z gereken kaynaklarla ilgili bir sorun oluÅŸmaz; Ã§Ã¼nkÃ¼ **Kaggle size tÃ¼m gerekli donanÄ±m kaynaklarÄ±nÄ± saÄŸlar**.
Bu yaklaÅŸÄ±m aynÄ± zamanda, **tÃ¼m katÄ±lÄ±mcÄ±larÄ±n aynÄ± baÅŸlangÄ±Ã§ noktasÄ±nda yarÄ±ÅŸmasÄ±nÄ±** saÄŸlamak amacÄ±yla da tasarlanmÄ±ÅŸtÄ±r.

Sorunlar, yalnÄ±zca **Ã§Ä±karÄ±m (inference)** aÅŸamasÄ±nda Notebook kullanÄ±mÄ±nÄ± zorunlu kÄ±lan yarÄ±ÅŸmalarda ortaya Ã§Ä±kar.
Bu tÃ¼r yarÄ±ÅŸmalarda modellerinizi kendi bilgisayarÄ±nÄ±zda eÄŸitebilir, ancak **test aÅŸamasÄ±nda** model sayÄ±sÄ± ve karmaÅŸÄ±klÄ±ÄŸÄ± aÃ§Ä±sÄ±ndan sÄ±nÄ±rlamalara tabi olursunuz.

GÃ¼nÃ¼mÃ¼zde yarÄ±ÅŸmalarÄ±n Ã§oÄŸu **derin Ã¶ÄŸrenme (deep learning)** Ã§Ã¶zÃ¼mleri gerektirdiÄŸinden, **rekabetÃ§i sonuÃ§lar elde edebilmek iÃ§in GPU gibi Ã¶zel donanÄ±mlara** ihtiyaÃ§ duyacaÄŸÄ±nÄ±zÄ± bilmelisiniz.

GÃ¼nÃ¼mÃ¼zde nadirleÅŸmiÅŸ olsa da, bazÄ± **tabular veri yarÄ±ÅŸmalarÄ±nda** bile, **Ã§ok Ã§ekirdekli iÅŸlemcilere** ve **yÃ¼ksek belleÄŸe** sahip gÃ¼Ã§lÃ¼ bir makineye ihtiyacÄ±nÄ±z olduÄŸunu fark edeceksiniz.
Bu kaynaklar, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** uygulamak, **deneyler yÃ¼rÃ¼tmek** ve **modelleri hÄ±zlÄ± bir ÅŸekilde inÅŸa etmek** iÃ§in gereklidir.

Standartlar hÄ±zla deÄŸiÅŸtiÄŸi iÃ§in, tÃ¼m katÄ±lÄ±mcÄ±larla aynÄ± seviyede rekabet edebilmek adÄ±na **net bir donanÄ±m standardÄ± tanÄ±mlamak zordur**.
Ancak, diÄŸer yarÄ±ÅŸmacÄ±larÄ±n hangi makineleri kullandÄ±ÄŸÄ±na bakarak gÃ¼ncel standartlar hakkÄ±nda fikir edinebilirsiniz â€” ister kendi bilgisayarlarÄ± olsun, ister bulut tabanlÄ± makineler.

Ã–rneÄŸin, **HP**, marka gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼ karÅŸÄ±lÄ±ÄŸÄ±nda bazÄ± seÃ§ilmiÅŸ Kaggle yarÄ±ÅŸmacÄ±larÄ±na **HP Z4 veya Z8** makineleri hediye ettiÄŸi bir program baÅŸlatmÄ±ÅŸtÄ±r.
Bir **Z8 makinesi**,

* 72 Ã§ekirdeÄŸe kadar CPU,
* 3 TB bellek,
* 48 TB depolama (Ã§oÄŸunluÄŸu SSD),
* ve genellikle **Ã§ift NVIDIA RTX GPU** barÄ±ndÄ±rÄ±r.

Bu dÃ¼zeyde bir sistemin birÃ§ok kiÅŸi iÃ§in eriÅŸilemez olduÄŸunu anlamak zor deÄŸildir.
Benzer Ã¶zelliklerde bir makineyi kÄ±sa sÃ¼reliÄŸine bile **Google Cloud (GCP)** veya **Amazon AWS** gibi platformlarda kiralamak bile **yÃ¼ksek maliyetler** doÄŸurabilir.

Bu nedenle, **Kaggleâ€™da Ã¼st sÄ±ralara tÄ±rmanma yolculuÄŸunuza baÅŸlarken**, en iyi yaklaÅŸÄ±m **Kaggleâ€™Ä±n Ã¼cretsiz sunduÄŸu altyapÄ±yÄ±**, yani **Kaggle Notebooksâ€™u (Ã¶nceki adÄ±yla Kaggle Kernels)** kullanmaktÄ±r.

##### Kaggle Notebooks *(Kaggle Defterleri)*

**Kaggle Notebooks**, bulut makinelerinde Ã§alÄ±ÅŸan **Docker konteynerleri** tabanlÄ±, sÃ¼rÃ¼mlenebilir (versioned) hesaplama ortamlarÄ±dÄ±r.
Bu ortamlar, **R** ve **Python** dillerinde hem **script** hem de **notebook** yazÄ±p Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r.

Kaggle Notebooks:

* **Kaggle ortamÄ±na entegredir:** Bu sayede doÄŸrudan notebookâ€™tan yarÄ±ÅŸmaya gÃ¶nderim (submission) yapabilir ve hangi gÃ¶nderimin hangi notebookâ€™tan geldiÄŸini takip edebilirsiniz.
* **Ã‡oÄŸu veri bilimi paketini Ã¶nceden yÃ¼klÃ¼ olarak iÃ§erir.**
* **KÄ±sÄ±tlÄ± Ã¶zelleÅŸtirme olanaÄŸÄ± sunar:** Dosya indirebilir ve ek Python/R paketleri yÃ¼kleyebilirsiniz.

Temel **Kaggle Notebook**, yalnÄ±zca CPU tabanlÄ±dÄ±r. Ancak, isterseniz:

* **NVIDIA Tesla P100 GPU**,
* veya **TPU v3-8** (Ã¶zellikle derin Ã¶ÄŸrenme gÃ¶revleri iÃ§in optimize edilmiÅŸ donanÄ±m hÄ±zlandÄ±rÄ±cÄ±sÄ±)
  desteÄŸiyle gÃ¼Ã§lendirilmiÅŸ sÃ¼rÃ¼mleri de kullanabilirsiniz.

Her yarÄ±ÅŸmanÄ±n bulut maliyeti, **iÅŸlenecek veri miktarÄ±na**, **kurduÄŸunuz model sayÄ±sÄ±na ve tÃ¼rÃ¼ne** baÄŸlÄ±dÄ±r.
Kaggle yarÄ±ÅŸmalarÄ±nda, **GCP (Google Cloud Platform)** veya **AWS** Ã¼zerinde kullanÄ±lmak Ã¼zere genellikle **200 â€“ 500 ABD DolarÄ±** aralÄ±ÄŸÄ±nda **Ã¼cretsiz bulut kredisi** daÄŸÄ±tÄ±lÄ±r.

Kaggle Notebooks, belirli **kullanÄ±m ve sÃ¼re sÄ±nÄ±rlamalarÄ±** altÄ±nda Ã§alÄ±ÅŸÄ±r; ancak bu sÄ±nÄ±rlar dahilinde yarÄ±ÅŸmalarda **temel modellerinizi geliÅŸtirmek iÃ§in yeterli hesaplama gÃ¼cÃ¼nÃ¼** saÄŸlar.

| Notebook tÃ¼rÃ¼ | CPU Ã§ekirdeÄŸi | Bellek | AynÄ± anda Ã§alÄ±ÅŸtÄ±rÄ±labilen notebook sayÄ±sÄ± | HaftalÄ±k kota |
| ------------- | ------------- | ------ | ------------------------------------------ | ------------- |
| **CPU**       | 4             | 16 GB  | 10                                         | SÄ±nÄ±rsÄ±z      |
| **GPU**       | 2             | 13 GB  | 2                                          | 30 saat       |
| **TPU**       | 4             | 16 GB  | 2                                          | 30 saat       |

* **CPU ve GPU notebookâ€™larÄ±**, **maksimum 12 saat** boyunca kesintisiz Ã§alÄ±ÅŸabilir.
* **TPU notebookâ€™larÄ±** ise **en fazla 9 saat** boyunca Ã§alÄ±ÅŸtÄ±rÄ±labilir.
  Bu sÃ¼reler dolduÄŸunda, diske kaydedilmemiÅŸ hiÃ§bir Ã§Ä±ktÄ± alÄ±namaz.

KullanÄ±cÄ±larÄ±n **20 GB kalÄ±cÄ± disk alanÄ±** bulunur (model ve sonuÃ§larÄ± saklamak iÃ§in).
Buna ek olarak, geÃ§ici dosyalar iÃ§in **20 GBâ€™tan fazla geÃ§ici (scratchpad) alan** kullanÄ±labilir.

BazÄ± durumlarda, Kaggleâ€™Ä±n sunduÄŸu **GPU destekli makineler** yeterli olmayabilir.
Ã–rneÄŸin, **Deepfake Detection Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/deepfake-detection-challenge](https://www.kaggle.com/c/deepfake-detection-challenge)) yaklaÅŸÄ±k **500 GB video verisi** iÅŸlenmesi gerekiyordu.

Bu, iki aÃ§Ä±dan zorluk yaratÄ±yordu:

1. HaftalÄ±k **30 saatlik kullanÄ±m sÃ¼resi** sÄ±nÄ±rlamasÄ±,
2. AynÄ± anda **en fazla iki GPU destekli makine** Ã§alÄ±ÅŸtÄ±rÄ±labilmesi.

Kodunuzu **GPU yerine TPU kullanacak ÅŸekilde optimize ederek** (bunun iÃ§in rehber: [https://www.kaggle.com/docs/tpu](https://www.kaggle.com/docs/tpu)) sÃ¼reyi iki katÄ±na Ã§Ä±karabilirsiniz.
Ancak bu bile, **bÃ¼yÃ¼k veri setlerine sahip yarÄ±ÅŸmalarda** (Ã¶rneÄŸin Deepfake Detection Challenge gibi) **hÄ±zlÄ± denemeler** yapmak iÃ§in yeterli olmayabilir.

Bu nedenle, **BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek** kÄ±smÄ±nda, bu tÃ¼r sÄ±nÄ±rlamalarla nasÄ±l baÅŸa Ã§Ä±kabileceÄŸinize dair **ipuÃ§larÄ±** vereceÄŸiz.
AmaÃ§, **yÃ¼ksek performanslÄ± donanÄ±m satÄ±n almadan** tatmin edici sonuÃ§lar elde etmenize yardÄ±mcÄ± olmaktÄ±r.

AyrÄ±ca, **Kaggle Notebooksâ€™u GCP ile entegre etme** yÃ¶ntemlerini gÃ¶stereceÄŸiz.
Alternatif olarak, **BÃ¶lÃ¼m 2: Datasets ile Verileri Organize Etmek** kÄ±smÄ±nda, tÃ¼m Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± **Google Colab** gibi baÅŸka bir bulut tabanlÄ± ortama nasÄ±l taÅŸÄ±yabileceÄŸinizi anlatacaÄŸÄ±z.

#### Teaming and networking *(TakÄ±m kurma ve aÄŸ oluÅŸturma)*

Hesaplama gÃ¼cÃ¼ (computational power) Ã¶nemli bir rol oynasa da, bir Kaggle yarÄ±ÅŸmasÄ±nda **gerÃ§ek farkÄ± yaratan unsur, insan uzmanlÄ±ÄŸÄ± ve yeteneÄŸidir.**
Bir yarÄ±ÅŸmanÄ±n baÅŸarÄ±lÄ± bir ÅŸekilde yÃ¼rÃ¼tÃ¼lebilmesi bazen bir **takÄ±mÄ±n ortak Ã§alÄ±ÅŸmasÄ±nÄ±** gerektirir.

**Recruitment (Ä°ÅŸe AlÄ±m)** yarÄ±ÅŸmalarÄ± hariÃ§ â€” ki bu yarÄ±ÅŸmalarda sponsor ÅŸirket, katÄ±lÄ±mcÄ±larÄ±n bireysel yeteneklerini daha iyi deÄŸerlendirebilmek iÃ§in yalnÄ±z katÄ±lÄ±m talep edebilir â€” Kaggleâ€™da genellikle **takÄ±m kurmaya dair herhangi bir kÄ±sÄ±tlama yoktur.**
Bir takÄ±m genellikle **en fazla beÅŸ kiÅŸiden** oluÅŸabilir.

TakÄ±m kurmanÄ±n birÃ§ok avantajÄ± vardÄ±r; Ã§Ã¼nkÃ¼ **farklÄ± becerilerin birleÅŸmesi**, daha iyi Ã§Ã¶zÃ¼mler Ã¼retilmesini saÄŸlar.
Bir ekip, **probleme daha fazla zaman ayÄ±rabilir** ve her Ã¼yenin sahip olduÄŸu farklÄ± uzmanlÄ±k alanlarÄ± (Ã¶rneÄŸin modelleme, veri Ã¶n iÅŸleme, gÃ¶rselleÅŸtirme) ortak hedefe katkÄ± saÄŸlar.
Her veri bilimcisi aynÄ± becerilere veya aynÄ± seviyede uzmanlÄ±ÄŸa sahip deÄŸildir; dolayÄ±sÄ±yla ekip iÃ§indeki **beceri Ã§eÅŸitliliÄŸi**, yarÄ±ÅŸma performansÄ±nÄ± artÄ±rÄ±r.

Yine de, takÄ±m Ã§alÄ±ÅŸmasÄ±nÄ±n dezavantajlarÄ± da vardÄ±r.
**FarklÄ± bireyleri ortak bir hedef doÄŸrultusunda koordine etmek her zaman kolay deÄŸildir** ve bazen verimsiz durumlar yaÅŸanabilir.

YaygÄ±n sorunlardan biri, bazÄ± ekip Ã¼yelerinin **aktif katÄ±lÄ±m gÃ¶stermemesi** veya **tamamen pasif kalmasÄ±dÄ±r.**
Ancak en kÃ¶tÃ¼ senaryo, ekip Ã¼yelerinden birinin yarÄ±ÅŸma kurallarÄ±nÄ± ihlal etmesidir; bu durumda **tÃ¼m ekip diskalifiye edilebilir.**
Daha da kÃ¶tÃ¼sÃ¼, bazen bir ekip Ã¼yesi **diÄŸer bir takÄ±ma avantaj saÄŸlamak iÃ§in casusluk** bile yapabilir â€” ki bu durum geÃ§miÅŸte yaÅŸanmÄ±ÅŸtÄ±r.

Olumsuzluklara raÄŸmen, Kaggleâ€™da takÄ±m olmak harika bir fÄ±rsattÄ±r.
DiÄŸer veri bilimcileriyle tanÄ±ÅŸmak, **ortak bir amaÃ§ iÃ§in iÅŸ birliÄŸi yapmak** ve **bireysel olarak elde edilemeyecek sonuÃ§lara ulaÅŸmak** iÃ§in Ã¶nemli bir deneyimdir.

AyrÄ±ca Kaggle, **takÄ±m katÄ±lÄ±mcÄ±larÄ±nÄ± bireysel katÄ±lÄ±mcÄ±lara gÃ¶re Ã¶dÃ¼llendirme aÃ§Ä±sÄ±ndan avantajlÄ±** kÄ±lar.
KÃ¼Ã§Ã¼k takÄ±mlar, Ã¶dÃ¼l havuzundan **eÅŸit paydan daha yÃ¼ksek bir yÃ¼zde** alabilir.

TakÄ±m kurmak, Kaggleâ€™da **aÄŸ kurmanÄ±n (networking)** tek yolu deÄŸildir, ancak katÄ±lÄ±mcÄ±lar iÃ§in kesinlikle **daha faydalÄ± ve etkileÅŸimli** bir yoldur.
Bunun dÄ±ÅŸÄ±nda, **forum tartÄ±ÅŸmalarÄ±**, **dataset paylaÅŸÄ±mÄ±** ve **notebook paylaÅŸÄ±mÄ±** aracÄ±lÄ±ÄŸÄ±yla da diÄŸer katÄ±lÄ±mcÄ±larla baÄŸlantÄ± kurabilirsiniz.
Bu olanaklar, **diÄŸer veri bilimcileriyle tanÄ±ÅŸmanÄ±za** ve **toplulukta tanÄ±nmanÄ±za** yardÄ±mcÄ± olur.

Kaggle platformunun dÄ±ÅŸÄ±nda da Kaggle topluluÄŸuyla iletiÅŸim kurabileceÄŸiniz birÃ§ok ortam bulunmaktadÄ±r.
Ã–ncelikle, **Slack kanallarÄ±** oldukÃ§a faydalÄ±dÄ±r.

Ã–rneÄŸin, **KaggleNoobs** ([https://www.kaggle.com/getting-started/20577](https://www.kaggle.com/getting-started/20577)) adlÄ± kanal 2016 yÄ±lÄ±nda aÃ§Ä±lmÄ±ÅŸtÄ±r ve Kaggle yarÄ±ÅŸmalarÄ± Ã¼zerine birÃ§ok tartÄ±ÅŸmayÄ± barÄ±ndÄ±rÄ±r.
Burada, **kod veya model ile ilgili Ã¶zel bir probleminiz varsa**, size yardÄ±mcÄ± olabilecek destekleyici bir topluluk vardÄ±r.

Bunun dÄ±ÅŸÄ±nda da birÃ§ok Slack kanalÄ±, **Kaggle yarÄ±ÅŸmalarÄ±** ve **veri bilimi konularÄ±nda gÃ¶rÃ¼ÅŸ alÄ±ÅŸveriÅŸi** yapmak iÃ§in kurulmuÅŸtur.
BazÄ±larÄ± **bÃ¶lgesel veya ulusal dÃ¼zeyde** organize edilmiÅŸtir; Ã¶rneÄŸin:

* **Japon topluluÄŸu:** [Kaggler-ja](http://kaggler-ja-wiki.herokuapp.com/)
* **Rus topluluÄŸu:** [Open Data Science Network (ODS)](https://ods.ai/) â€” 2015 yÄ±lÄ±nda kurulmuÅŸ, daha sonra **RusÃ§a bilmeyen katÄ±lÄ±mcÄ±lara da aÃ§Ä±lmÄ±ÅŸtÄ±r.**

**ODS Network**, yalnÄ±zca bir Slack kanalÄ± deÄŸildir; aynÄ± zamanda:

* **YarÄ±ÅŸma kazanma stratejileri Ã¼zerine kurslar**,
* **Etkinlikler**,
* **TÃ¼m veri bilimi platformlarÄ±nda aktif yarÄ±ÅŸmalar hakkÄ±nda raporlar**
  da sunar.
  (Bkz. [https://ods.ai/competitions](https://ods.ai/competitions))

Slack dÄ±ÅŸÄ±nda, **Kaggle temalÄ± yerel buluÅŸmalar (meetup)** da giderek yaygÄ±nlaÅŸmaktadÄ±r.
BazÄ±larÄ± belirli yarÄ±ÅŸmalar etrafÄ±nda, bazÄ±larÄ± ise genel Kaggle topluluÄŸu odaÄŸÄ±nda dÃ¼zenlenir.
BazÄ±larÄ± **geÃ§ici**, bazÄ±larÄ± ise **dÃ¼zenli ve kalÄ±cÄ± etkinlikler** haline gelmiÅŸtir.

Bu buluÅŸmalar genellikle, **deneyimlerini paylaÅŸmak isteyen yarÄ±ÅŸmacÄ±larÄ±n sunumlarÄ±** etrafÄ±nda ÅŸekillenir.
KatÄ±lÄ±mcÄ±lar, bu tÃ¼r etkinliklerde **diÄŸer Kaggle kullanÄ±cÄ±larÄ±yla yÃ¼z yÃ¼ze tanÄ±ÅŸabilir**, **fikir alÄ±ÅŸveriÅŸinde bulunabilir** ve **ortak yarÄ±ÅŸma ekipleri kurabilir.**

Bu alanda Ã¶zellikle **Kaggle Days** ([https://kaggledays.com/](https://kaggledays.com/)) etkinliklerinden bahsetmek gerekir.
Bu etkinlikler, **Maria Parysz** ve **PaweÅ‚ Jankiewicz** tarafÄ±ndan organize edilmiÅŸtir.

**Kaggle Days**, dÃ¼nyanÄ±n dÃ¶rt bir yanÄ±nda dÃ¼zenlenen (bkz. [https://kaggledays.com/about-us/](https://kaggledays.com/about-us/)) konferanslar aracÄ±lÄ±ÄŸÄ±yla **Kaggle uzmanlarÄ±nÄ± bir araya getirmeyi** amaÃ§lar.
AyrÄ±ca, farklÄ± Ã¼lkelerde hÃ¢lÃ¢ aktif olan **yerel Kaggle meetup aÄŸlarÄ±** da oluÅŸturmuÅŸtur (bkz. [https://kaggledays.com/meetups/](https://kaggledays.com/meetups/)).

> PaweÅ‚ Jankiewicz ile RÃ¶portaj
> 
> 
> 
> **Profil:** [PaweÅ‚ Jankiewicz](https://www.kaggle.com/paweljankiewicz)
> 
> PaweÅ‚, **Kaggle Competitions Grandmaster** ve **LogicAIâ€™nin kurucu ortaklarÄ±ndan** biridir. Kaggle deneyimleri hakkÄ±nda kendisiyle konuÅŸma fÄ±rsatÄ± bulduk.
> 
> 
> 
> **Soru:** En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?
> 
> 
> 
> En sevdiÄŸim yarÄ±ÅŸma tÃ¼rÃ¼ **kod yarÄ±ÅŸmalarÄ±dÄ±r**. Ã‡Ã¼nkÃ¼ sÄ±nÄ±rlÄ± bir ortamda Ã§alÄ±ÅŸmak, farklÄ± tÃ¼rde bÃ¼tÃ§eleri dÃ¼ÅŸÃ¼nmeye zorlar: zaman, CPU, bellek. Ã–nceki yarÄ±ÅŸmalarda Ã§oÄŸu zaman **3-4 gÃ¼Ã§lÃ¼ sanal makine** kullanmam gerekiyordu. Bunu sevmiyordum; Ã§Ã¼nkÃ¼ kazanÃ§ iÃ§in bu kadar kaynak kullanmak, yarÄ±ÅŸmayÄ± adaletsiz hale getiriyor.
> 
> 
> 
> **Soru:** Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±?
> 
> 
> 
> Her yarÄ±ÅŸmaya biraz farklÄ± yaklaÅŸÄ±rÄ±m. Her yarÄ±ÅŸma iÃ§in **mÃ¼mkÃ¼n olduÄŸunca Ã§ok deney oluÅŸturmayÄ± saÄŸlayan bir Ã§erÃ§eve (framework) kurarÄ±m.**
> 
> 
> 
> Ã–rneÄŸin, bir yarÄ±ÅŸmada **derin Ã¶ÄŸrenme konvolÃ¼syonel sinir aÄŸÄ± (CNN)** kurmamÄ±z gerekiyordu. Ben, aÄŸlarÄ± **C4-MP4-C3-MP3** formatÄ±nda yapÄ±landÄ±rmayÄ± saÄŸlayan bir yÃ¶ntem geliÅŸtirdim (her harf farklÄ± bir katmanÄ± temsil ediyordu).
> 
> Bu olay yÄ±llar Ã¶nce oldu; artÄ±k muhtemelen sinir aÄŸlarÄ± yapÄ±landÄ±rmasÄ±, **backbone model seÃ§imiyle** yapÄ±lÄ±yor. Ama kural hÃ¢lÃ¢ geÃ§erli: **Pipelineâ€™daki en hassas bÃ¶lÃ¼mleri hÄ±zlÄ±ca deÄŸiÅŸtirebileceÄŸiniz bir Ã§erÃ§eve oluÅŸturmalÄ±sÄ±nÄ±z.**
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ, modelleme yaklaÅŸÄ±mÄ± ve doÄŸru validasyon aÃ§Ä±sÄ±ndan Kaggle yarÄ±ÅŸmalarÄ±yla benzerlik gÃ¶sterir.
> 
> Kaggle yarÄ±ÅŸmalarÄ±ndan Ã¶ÄŸrendiÄŸim en Ã¶nemli ÅŸey: **validasyonun Ã¶nemi ve veri sÄ±zÄ±ntÄ±sÄ±nÄ± (data leakage) Ã¶nlemenin gerekliliÄŸi.**
> 
> Ã–rneÄŸin, veri sÄ±zÄ±ntÄ±larÄ± Ã§ok sayÄ±da yarÄ±ÅŸmada gÃ¶rÃ¼lÃ¼yor; ve bunlarÄ± hazÄ±rlayan kiÅŸiler alanÄ±n en iyileri. Bu durum, Ã¼retimde kullanÄ±lan modellerin **%80â€™den fazlasÄ±nÄ±n doÄŸru ÅŸekilde validasyon edilmediÄŸini** dÃ¼ÅŸÃ¼ndÃ¼rÃ¼yor (kiÅŸisel gÃ¶rÃ¼ÅŸ).
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ ile farklÄ±lÄ±k: kimse size **modelleme problemini nasÄ±l tanÄ±mlayacaÄŸÄ±nÄ±zÄ±** sÃ¶ylemez.
> 
> Ã–rneÄŸin:
> 
> 
> 
> 1. RaporlayacaÄŸÄ±nÄ±z veya optimize edeceÄŸiniz metrik **RMSE, RMSLE, SMAPE, MAPE** hangisi olmalÄ±?
> 
> 2. Problem zaman bazlÄ±ysa, modeli en gerÃ§ekÃ§i ÅŸekilde deÄŸerlendirmek iÃ§in veriyi nasÄ±l bÃ¶lmelisiniz?
> 
> 
> 
> Bunlar sadece iÅŸ aÃ§Ä±sÄ±ndan Ã¶nemli olan noktalar deÄŸil; ayrÄ±ca **seÃ§imlerinizi aÃ§Ä±klayabilme ve neden yaptÄ±ÄŸÄ±nÄ±zÄ± anlatabilme** becerisine de sahip olmalÄ±sÄ±nÄ±z.
> 
> 
> 
> **Soru:** KatÄ±ldÄ±ÄŸÄ±nÄ±z en zorlu yarÄ±ÅŸma hangisiydi ve problemi Ã§Ã¶zmek iÃ§in hangi yaklaÅŸÄ±mlarÄ± kullandÄ±nÄ±z?
> 
> 
> 
> **PaweÅ‚â€™Ä±n CevabÄ±:**
> 
> En zorlu ve ilginÃ§ yarÄ±ÅŸma, **Mercari Price Prediction Code** yarÄ±ÅŸmasÄ±ydÄ±.
> 
> DiÄŸer yarÄ±ÅŸmalardan farklÄ±ydÄ± Ã§Ã¼nkÃ¼ **sadece 1 saat hesaplama sÃ¼resi ve 4 Ã§ekirdek ile 16 GB bellek** ile sÄ±nÄ±rlÄ±ydÄ±. Bu kÄ±sÄ±tlarÄ± aÅŸmak, yarÄ±ÅŸmanÄ±n en heyecan verici kÄ±smÄ±ydÄ±.
> 
> 
> 
> Bu yarÄ±ÅŸmadan Ã¶ÄŸrendiÄŸim: **tabular veri iÃ§in aÄŸlara daha fazla gÃ¼venmek** gerekir.
> 
> TakÄ±m arkadaÅŸÄ±m **Konstantin Lopukhin** ile birleÅŸmeden Ã¶nce, karmaÅŸÄ±k modellerim vardÄ± (neural networkâ€™ler ve bazÄ± boosting algoritmalarÄ±).
> 
> BirleÅŸtiÄŸimizde, Konstantin sadece **Ã§ok optimize edilmiÅŸ tek bir mimari** kullanÄ±yordu (epoch sayÄ±sÄ±, Ã¶ÄŸrenme hÄ±zÄ± vb.).
> 
> 
> 
> Bu yarÄ±ÅŸmada ayrÄ±ca, **sadece Ã§Ã¶zÃ¼mleri ortalamak yeterli deÄŸildi.**
> 
> Workflowâ€™u yeniden organize edip, **tek bir uyumlu Ã§Ã¶zÃ¼m** Ã¼retmemiz gerekiyordu. Ã‡Ã¶zÃ¼mlerimizi birleÅŸtirmemiz **3 hafta** sÃ¼rdÃ¼.
> 
> 
> 
> **Soru:** TecrÃ¼besiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r?
> 
> 
> 
> **YazÄ±lÄ±m mÃ¼hendisliÄŸi becerileri (software engineering skills)** genellikle fazla Ã¶nemsenmez.
> 
> Her yarÄ±ÅŸma ve problem biraz farklÄ±dÄ±r ve Ã§Ã¶zÃ¼mÃ¼ **dÃ¼zene sokacak bir framework** gerektirir.
> 
> Ã–rnek: [https://github.com/bestfitting/instance_level_recognition](https://github.com/bestfitting/instance_level_recognition)
> 
> Ä°yi kod organizasyonu, **daha hÄ±zlÄ± iterasyon ve daha fazla deneme** yapmanÄ±za olanak saÄŸlar.
> 
> 
> 
> **PaweÅ‚â€™Ä±n Tavsiyesi:**
> 
> En Ã¶nemli ÅŸey **yarÄ±ÅŸmadan keyif almak.**

#### Performance tiers and rankings *(Performans seviyeleri ve sÄ±ralamalar)*

Parasal Ã¶dÃ¼ller ve kupa, tiÅŸÃ¶rt, hoodie veya sticker gibi maddi Ã¶dÃ¼llerin yanÄ± sÄ±ra, Kaggle birÃ§ok **maddi olmayan Ã¶dÃ¼l** de sunar.

Kagglers yarÄ±ÅŸmalar sÄ±rasÄ±nda Ã§ok **zaman ve Ã§aba harcar** (yarÄ±ÅŸmada kullandÄ±klarÄ± beceriler, genel nÃ¼fus arasÄ±nda oldukÃ§a nadirdir). Parasal Ã¶dÃ¼ller genellikle sadece en iyi birkaÃ§ Kaggle katÄ±lÄ±mcÄ±sÄ±nÄ±n Ã§abasÄ±nÄ± karÅŸÄ±lar, Ã§oÄŸu zaman sadece **birinciyi**. DiÄŸer katÄ±lÄ±mcÄ±lar ise saatlerce gÃ¶nÃ¼llÃ¼ Ã§alÄ±ÅŸÄ±r ama karÅŸÄ±lÄ±ÄŸÄ±nda Ã§ok az ÅŸey alÄ±r. Uzun vadede, somut bir Ã¶dÃ¼l olmadan yarÄ±ÅŸmalara katÄ±lmak, **ilgi kaybÄ±na ve motivasyon dÃ¼ÅŸÃ¼ÅŸÃ¼ne** yol aÃ§abilir.

Bu nedenle Kaggle, yarÄ±ÅŸmacÄ±larÄ± **madalya ve puan temelli bir onur sistemiyle** Ã¶dÃ¼llendirmeyi bulmuÅŸtur. AmaÃ§: ne kadar Ã§ok madalya ve puan kazanÄ±rsanÄ±z, becerileriniz o kadar tanÄ±nÄ±r ve iÅŸ arayÄ±ÅŸÄ± veya diÄŸer ilgili aktivitelerde fÄ±rsatlar elde edebilirsiniz.

Kaggleâ€™de bir **genel lider tablosu** vardÄ±r. Bu tablo, tÃ¼m bireysel yarÄ±ÅŸmalarÄ±n lider tablolarÄ±nÄ± birleÅŸtirir: [https://www.kaggle.com/rankings](https://www.kaggle.com/rankings).

* Her yarÄ±ÅŸmadaki pozisyonunuza gÃ¶re puan kazanÄ±rsÄ±nÄ±z.
* Bu puanlar toplandÄ±ÄŸÄ±nda genel lider tablosundaki sÄ±ralamanÄ±zÄ± belirler.

Ä°lk bakÄ±ÅŸta puan hesaplama formÃ¼lÃ¼ karmaÅŸÄ±k gÃ¶rÃ¼nebilir:

[
\left[ \frac{100000}{\sqrt{N_{\text{total}}}} \right] * [RRR - 0.75] * [\log_{10}(1 + \log_{10}(N_{\text{total}}))] * [e^{-t/500}]
]

Ama aslÄ±nda puanlar **temel birkaÃ§ unsur** Ã¼zerine kuruludur:

* YarÄ±ÅŸmadaki sÄ±ralamanÄ±z
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼z
* YarÄ±ÅŸmanÄ±n popÃ¼lerliÄŸi
* YarÄ±ÅŸmanÄ±n yaÅŸÄ±

**Ä°puÃ§larÄ±:**

* PopÃ¼ler yarÄ±ÅŸmalarda yÃ¼ksek sÄ±ralama, daha Ã§ok puan kazandÄ±rÄ±r.
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ **doÄŸrusal olmayan bir ÅŸekilde** puanlarÄ± etkiler. FormÃ¼ldeki **ters kare kÃ¶k** nedeniyle, takÄ±m bÃ¼yÃ¼dÃ¼kÃ§e kaybedilen puan oranÄ± artar.
* TakÄ±mÄ±nÄ±z **kÃ¼Ã§Ã¼k (2-3 kiÅŸi)** ise iÅŸbirliÄŸi ve hesaplama avantajÄ± aÃ§Ä±sÄ±ndan daha iyidir.
* Puanlar **zamanla azalÄ±r**; lineer olmasa da, bir yÄ±l sonra kazandÄ±ÄŸÄ±nÄ±z puanlarÄ±n Ã§oÄŸu kaybolur.

Yine de, profilinizde **ulaÅŸtÄ±ÄŸÄ±nÄ±z en yÃ¼ksek sÄ±ralamayÄ±** her zaman saklarsÄ±nÄ±z.

Daha kalÄ±cÄ± olan, Kaggleâ€™daki dÃ¶rt alanÄ± kapsayan **madalya sistemidir**:

* **Competitions (YarÄ±ÅŸmalar)**
* **Notebooks (Not Defterleri)**
* **Discussion (Forum KatkÄ±larÄ±)**
* **Datasets (Veri Setleri)**

**Competitions:** Madalyalar, lider tablodaki sÄ±ralamanÄ±za gÃ¶re verilir.
**DiÄŸer Ã¼Ã§ alan:** Madalyalar, diÄŸer katÄ±lÄ±mcÄ±larÄ±n **upvoteâ€™larÄ±** ile verilir. (Upvoteâ€™lar popÃ¼lerliÄŸe baÄŸlÄ± ve daha az objektif olabilir.)

Daha fazla madalya kazandÄ±kÃ§a **Kaggle uzmanlÄ±k sÄ±ralamalarÄ±** yÃ¼kselir:

* **Novice (Acemi)**
* **Contributor (KatÄ±lÄ±mcÄ±)**
* **Expert (Uzman)**
* **Master (Usta)**
* **Grandmaster (BÃ¼yÃ¼k Usta)**

DetaylÄ± bilgi ve gerekli madalya sayÄ±larÄ± iÃ§in: [https://www.kaggle.com/progression](https://www.kaggle.com/progression)

> Not: Bu sÄ±ralamalar **her zaman gÃ¶recelidir** ve zamanla deÄŸiÅŸebilir. BirkaÃ§ yÄ±l Ã¶nce puanlama sistemi ve sÄ±ralamalar oldukÃ§a farklÄ±ydÄ±. Muhtemelen gelecekte de, Ã¼st sÄ±ralar **daha nadir ve deÄŸerli** olacak ÅŸekilde deÄŸiÅŸtirilecektir.

#### Criticism and opportunities *(EleÅŸtiriler ve fÄ±rsatlar)*

Kaggle, baÅŸladÄ±ÄŸÄ± gÃ¼nden bu yana pek Ã§ok eleÅŸtiri aldÄ±. Veri bilimi yarÄ±ÅŸmalarÄ±na katÄ±lmak hÃ¢lÃ¢ tartÄ±ÅŸmalÄ± bir konu olup, bu konuda hem olumlu hem de olumsuz pek Ã§ok farklÄ± gÃ¶rÃ¼ÅŸ bulunmaktadÄ±r.

**Olumsuz eleÅŸtiriler aÃ§Ä±sÄ±ndan:**

* Kaggle, makine Ã¶ÄŸreniminin gerÃ§ekte ne olduÄŸuna dair yanlÄ±ÅŸ bir algÄ± yaratÄ±yor Ã§Ã¼nkÃ¼ sadece liderlik tablosu dinamiklerine odaklanÄ±yor.
* Kaggle, aslÄ±nda sadece biraz daha yÃ¼ksek doÄŸruluk elde etmek iÃ§in birÃ§ok modeli bir araya getirip hiperparametre optimizasyonu yapmak Ã¼zerine kurulu bir oyun gibi (gerÃ§ekte test setine fazla uyum saÄŸlama/overfitting yapÄ±yor).
* Kaggle, puan ve dikkat Ã§ekme umuduyla her ÅŸeyi denemeye hazÄ±r deneyimsiz meraklÄ±larla dolu.
* SonuÃ§ olarak, yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri Ã§ok karmaÅŸÄ±k ve genellikle yalnÄ±zca test setine Ã¶zgÃ¼ olup uygulanmasÄ± zor.

BirÃ§ok kiÅŸi Kaggle ve diÄŸer veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ± gerÃ§ek veri bilimine oldukÃ§a uzak olarak gÃ¶rÃ¼yor. EleÅŸtirmenlerin vurguladÄ±ÄŸÄ± nokta ÅŸudur: Ä°ÅŸ problemleri boÅŸluktan ortaya Ã§Ä±kmaz ve nadiren Ã¶nceden iyi hazÄ±rlanmÄ±ÅŸ bir veri setine sahip olursunuz; Ã§Ã¼nkÃ¼ genellikle bunu, iÅŸ gereksinimlerini ve problem anlayÄ±ÅŸÄ±nÄ± geliÅŸtirerek oluÅŸturursunuz. AyrÄ±ca, birÃ§ok eleÅŸtirmen, kazanan Ã§Ã¶zÃ¼mlerin kaynak sÄ±nÄ±rlamalarÄ± veya teknik borÃ§ gibi kÄ±sÄ±tlamalarla sÄ±nÄ±rlandÄ±rÄ±lamayacaÄŸÄ± iÃ§in Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n Ã¼retim odaklÄ± modeller yaratmada yeterince Ã¶ÄŸrenmediÄŸini vurguluyor (her yarÄ±ÅŸma iÃ§in bu doÄŸru olmasa da).

TÃ¼m bu eleÅŸtiriler, nihayetinde Kaggle sÄ±ralamalarÄ±nÄ±n iÅŸveren gÃ¶zÃ¼nde diÄŸer deneyim tÃ¼rleriyle karÅŸÄ±laÅŸtÄ±rÄ±labilirliÄŸi ile ilgilidir; Ã¶zellikle veri bilimi eÄŸitimi ve iÅŸ deneyimi ile kÄ±yaslandÄ±ÄŸÄ±nda. SÃ¼regelen bir mit, Kaggle yarÄ±ÅŸmalarÄ±nÄ±n size iÅŸ bulmada veya daha iyi bir iÅŸ elde etmede yardÄ±mcÄ± olmayacaÄŸÄ± ve Kaggleâ€™a katÄ±lmayan veri bilimcilerden sizi farklÄ± bir seviyeye taÅŸÄ±yamayacaÄŸÄ±dÄ±r.

Bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼z, Kaggle sÄ±ralamalarÄ±nÄ±n Kaggle topluluÄŸunun Ã¶tesinde otomatik bir deÄŸeri olmadÄ±ÄŸÄ±na dair bu inanÄ±ÅŸÄ±n yanÄ±ltÄ±cÄ± olduÄŸudur. Ã–rneÄŸin, iÅŸ ararken Kaggle size veri ve problem modelleme ile etkili model test etme konusunda Ã§ok faydalÄ± beceriler kazandÄ±rabilir. AyrÄ±ca, sizi mevcut deneyim ve konfor alanÄ±nÄ±zÄ±n Ã¶tesinde birÃ§ok teknik ve farklÄ± veri/iÅŸ problemleriyle tanÄ±ÅŸtÄ±rabilir; ancak bir ÅŸirkette veri bilimci olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken her ÅŸeyi tek baÅŸÄ±na saÄŸlayamaz.

Kaggleâ€™Ä± Ã¶ÄŸrenmek iÃ§in (web sitesinde yalnÄ±zca Ã¶ÄŸrenmeye ayrÄ±lmÄ±ÅŸ â€œCoursesâ€ bÃ¶lÃ¼mÃ¼ de vardÄ±r) ve iÅŸ arayÄ±ÅŸÄ±nda kendinizi diÄŸer adaylardan farklÄ± kÄ±lmak iÃ§in kullanabilirsiniz; fakat bunun nasÄ±l deÄŸerlendirileceÄŸi ÅŸirketten ÅŸirkete oldukÃ§a deÄŸiÅŸir. Yine de, Kaggleâ€™da Ã¶ÄŸrendikleriniz kariyeriniz boyunca kesinlikle faydalÄ± olacaktÄ±r ve veri modelleme ile karmaÅŸÄ±k ve alÄ±ÅŸÄ±lmadÄ±k problemleri Ã§Ã¶zmeniz gerektiÄŸinde size bir avantaj saÄŸlayacaktÄ±r. Kaggle yarÄ±ÅŸmalarÄ±na katÄ±larak modelleme ve doÄŸrulama konusunda gÃ¼Ã§lÃ¼ yetkinlikler kazanÄ±rsÄ±nÄ±z. AyrÄ±ca, diÄŸer veri bilimcilerle aÄŸ kurabilir, bu sayede bir iÅŸ referansÄ± elde etmeniz kolaylaÅŸÄ±r ve kendi becerilerinizin Ã¶tesinde zor problemleri Ã§Ã¶zmek iÃ§in baÅŸkalarÄ±nÄ±n yetkinliklerinden ve gÃ¶rÃ¼ÅŸlerinden faydalanabilirsiniz.

Bu nedenle, bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼ze gÃ¶re Kaggle, veri bilimci olarak kariyerinize dolaylÄ± yollardan pek Ã§ok ÅŸekilde katkÄ± saÄŸlar. Elbette, bazen Kaggle, baÅŸarÄ±larÄ±nÄ±z Ã¼zerinden doÄŸrudan bir iÅŸ teklifi almanÄ±za yardÄ±mcÄ± olabilir; fakat Ã§oÄŸu zaman Kaggle, Ã¶nce bir aday olarak, sonra bir uygulayÄ±cÄ± olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken entelektÃ¼el beceri ve deneyimi saÄŸlar.

AslÄ±nda, Kaggleâ€™da bir sÃ¼re veri ve modellerle uÄŸraÅŸtÄ±ktan sonra, farklÄ± veri setleri, problemler ve bunlarla baÅŸa Ã§Ä±kma yÃ¶ntemlerini zaman baskÄ±sÄ± altÄ±nda gÃ¶rmÃ¼ÅŸ olursunuz; bu da benzer problemlerle gerÃ§ek ortamda karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda hÄ±zlÄ± ve etkili Ã§Ã¶zÃ¼mler bulma konusunda sizi yetkin kÄ±lar.

Ä°ÅŸte bu beceri geliÅŸimi fÄ±rsatÄ±, bizi bu kitabÄ± yazmaya motive eden ve kitabÄ±n temel amacÄ±nÄ± oluÅŸturan ÅŸeydir. Burada yalnÄ±zca Kaggle yarÄ±ÅŸmalarÄ±nÄ± kazanma veya yÃ¼ksek puan alma rehberi bulamayacaksÄ±nÄ±z; fakat yarÄ±ÅŸmalarda daha iyi nasÄ±l rekabet edeceÄŸinizi ve yarÄ±ÅŸma deneyimlerinden en iyi ÅŸekilde nasÄ±l faydalanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz.

Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± akÄ±llÄ±ca kullanÄ±n. Kaggle bir sihirli anahtar deÄŸildir â€“ bir yarÄ±ÅŸmada birinci olmak, yÃ¼ksek maaÅŸ veya Kaggle topluluÄŸu dÄ±ÅŸÄ±nda ÅŸan getirmez. Ancak, yarÄ±ÅŸmalara dÃ¼zenli olarak katÄ±lmak, veri bilimi iÅŸ arayÄ±ÅŸÄ±nÄ±zda ilgi ve tutkuyu gÃ¶stermek ve bazÄ± Ã¶zel becerileri geliÅŸtirerek sizi diÄŸer veri bilimcilerden farklÄ± kÄ±lmak iÃ§in stratejik bir karttÄ±r; ayrÄ±ca sizi AutoML Ã§Ã¶zÃ¼mlerine karÅŸÄ± modasÄ± geÃ§miÅŸ hÃ¢le getirmez.

EÄŸer kitabÄ±n ilerleyen bÃ¶lÃ¼mlerini takip ederseniz, bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± gÃ¶stereceÄŸiz.

### Summary *(Ã–zet)*

Bu baÅŸlangÄ±Ã§ bÃ¶lÃ¼mÃ¼nde, Ã¶ncelikle veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n nasÄ±l ortaya Ã§Ä±ktÄ±ÄŸÄ±nÄ± ve hem yarÄ±ÅŸmacÄ±lar hem de bu platformlarÄ± iÅŸleten kurumlar aÃ§Ä±sÄ±ndan nasÄ±l iÅŸlediÄŸini tartÄ±ÅŸtÄ±k; Ã¶zellikle ProfesÃ¶r David Donoho tarafÄ±ndan ele alÄ±nan ikna edici CTF (Capture The Flag) paradigmasÄ±na atÄ±fta bulunduk.

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶rneklerle gÃ¶sterdik, aynÄ± zamanda diÄŸer kayda deÄŸer yarÄ±ÅŸma platformlarÄ±ndan da bahsederek, Kaggle dÄ±ÅŸÄ±ndaki meydan okumalarÄ± da denemenin size nasÄ±l fayda saÄŸlayabileceÄŸini anlattÄ±k. Kaggle ile ilgili olarak, bir yarÄ±ÅŸmanÄ±n farklÄ± aÅŸamalarÄ±nÄ±n nasÄ±l iÅŸlediÄŸini, yarÄ±ÅŸmalarÄ±n birbirinden nasÄ±l farklÄ±laÅŸtÄ±ÄŸÄ±nÄ± ve Kaggle platformunun size sunabileceÄŸi kaynaklarÄ± detaylÄ± ÅŸekilde ele aldÄ±k.

Bir sonraki birkaÃ§ bÃ¶lÃ¼mde, Kaggleâ€™Ä± daha ayrÄ±ntÄ±lÄ± olarak incelemeye baÅŸlayacaÄŸÄ±z; bunun ilk adÄ±mÄ± olarak veri setleri (Datasets) ile nasÄ±l Ã§alÄ±ÅŸÄ±lacaÄŸÄ±nÄ± ele alacaÄŸÄ±z.

---

## Chapter 2: Organizing Data with Datasets *(BÃ¶lÃ¼m 2: Veri Setleriyle Veriyi DÃ¼zenleme)*

Arthur Conan Doyleâ€™un *The Adventure of the Copper Beeches* (BakÄ±r KayÄ±n AÄŸaÃ§larÄ±nÄ±n MacerasÄ±) adlÄ± hikÃ¢yesinde Sherlock Holmes, â€œVeri! Veri! Veri! Kil olmadan tuÄŸla yapamam.â€ diye baÄŸÄ±rÄ±r. EdebiyatÄ±n en Ã¼nlÃ¼ dedektifine bu kadar iyi hizmet eden bu bakÄ±ÅŸ aÃ§Ä±sÄ±, her veri bilimcinin benimsemesi gereken bir yaklaÅŸÄ±m olmalÄ±dÄ±r. Bu nedenle, kitabÄ±n daha teknik bÃ¶lÃ¼mÃ¼ne veri odaklÄ± bir bÃ¶lÃ¼mle baÅŸlÄ±yoruz: Ã¶zellikle Kaggle baÄŸlamÄ±nda, amaÃ§larÄ±mÄ±z doÄŸrultusunda Kaggle Datasets (Veri Setleri) fonksiyonunun gÃ¼cÃ¼nden yararlanmayÄ± ele alacaÄŸÄ±z.

Bu bÃ¶lÃ¼mde ÅŸu konularÄ± ele alacaÄŸÄ±z:

* Bir veri seti oluÅŸturma
* Veriyi toplama
* Veri setleriyle Ã§alÄ±ÅŸma
* Kaggle Datasetsâ€™i Google Colabâ€™de kullanma
* Hukuki uyarÄ±lar

### Setting up a dataset *(Bir veri seti oluÅŸturma)*

Ä°lke olarak, kullanabileceÄŸiniz herhangi bir veriyi Kaggleâ€™a yÃ¼kleyebilirsiniz (sÄ±nÄ±rlamalara tabi; daha sonra â€œHukuki UyarÄ±larâ€ bÃ¶lÃ¼mÃ¼ne bakÄ±nÄ±z). YazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihteki Ã¶zel sÄ±nÄ±rlamalar, her Ã¶zel veri seti iÃ§in 100 GB ve toplam kota olarak 100 GBâ€™dÄ±r. Tek bir veri seti iÃ§in boyut sÄ±nÄ±rÄ±nÄ±n sÄ±kÄ±ÅŸtÄ±rÄ±lmamÄ±ÅŸ hÃ¢liyle hesaplandÄ±ÄŸÄ±nÄ± unutmayÄ±n; sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ versiyonlarÄ± yÃ¼klemek aktarÄ±mÄ± hÄ±zlandÄ±rÄ±r ancak sÄ±nÄ±rlamalara karÅŸÄ± bir avantaj saÄŸlamaz. Veri setleri ile ilgili en gÃ¼ncel dokÃ¼mantasyonu bu baÄŸlantÄ±dan kontrol edebilirsiniz: [Kaggle Datasets Documentation](https://www.kaggle.com/docs/datasets).

Kaggle kendini â€œveri biliminin eviâ€ olarak tanÄ±tÄ±r ve sitede bulunan etkileyici veri seti koleksiyonu bu iddiaya bÃ¼yÃ¼k Ã¶lÃ§Ã¼de gÃ¼venilirlik kazandÄ±rÄ±r. Sadece petrol fiyatlarÄ±ndan anime Ã¶nerilerine kadar Ã§eÅŸitli konularda veri bulmakla kalmazsÄ±nÄ±z; verilerin ne kadar hÄ±zlÄ± bir ÅŸekilde siteye ulaÅŸtÄ±ÄŸÄ± da etkileyicidir. Ã–rneÄŸin, Anthony Fauciâ€™nin e-postalarÄ± 2021 MayÄ±s ayÄ±nda Bilgi Edinme HakkÄ± YasasÄ± kapsamÄ±nda yayÄ±mlandÄ±ÄŸÄ±nda ([link](https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/)), yalnÄ±zca 48 saat iÃ§inde bir Kaggle veri seti olarak yÃ¼klenmiÅŸti.

![](im/1005.png)

Projeniz iÃ§in verileri bir veri setine yÃ¼klemeden Ã¶nce, mevcut iÃ§erikleri kontrol ettiÄŸinizden emin olun.
BazÄ± popÃ¼ler uygulamalar iÃ§in (gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, NLP, finansal zaman serileri) verilerin zaten orada depolanmÄ±ÅŸ olma ihtimali vardÄ±r.

Bu giriÅŸ iÃ§in, projenizde kullanacaÄŸÄ±nÄ±z veri tÃ¼rÃ¼nÃ¼n henÃ¼z orada bulunmadÄ±ÄŸÄ±nÄ± varsayalÄ±m; bu durumda yeni bir veri seti oluÅŸturmanÄ±z gerekir. Sol taraftaki Ã¼Ã§ Ã§izgili menÃ¼ye gidip â€œDataâ€ (Veri) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, Datasets (Veri Setleri) sayfasÄ±na yÃ¶nlendirileceksiniz:

![](im/1006.png)

â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, sizden temel bilgileri girmeniz istenecektir: veriyi yÃ¼klemek ve bir baÅŸlÄ±k vermek.

![](im/1007.png)

Sol taraftaki simgeler, veri setiniz iÃ§in kullanabileceÄŸiniz farklÄ± kaynaklara karÅŸÄ±lÄ±k gelir. BunlarÄ± sayfada gÃ¶sterildikleri sÄ±rayla aÃ§Ä±klÄ±yoruz:

* Yerel bir sÃ¼rÃ¼cÃ¼den dosya yÃ¼kleme (ÅŸekilde gÃ¶sterilmiÅŸtir)
* Uzak bir URLâ€™den oluÅŸturma
* Bir GitHub deposunu iÃ§e aktarma
* Mevcut bir Notebookâ€™tan Ã§Ä±ktÄ± dosyalarÄ±nÄ± kullanma
* Google Cloud Storage dosyasÄ±nÄ± iÃ§e aktarma

GitHub seÃ§eneÄŸi ile ilgili Ã¶nemli bir nokta: Bu Ã¶zellik, Ã¶zellikle deneysel kÃ¼tÃ¼phaneler sÃ¶z konusu olduÄŸunda oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r. HenÃ¼z mevcut olmayan iÅŸlevsellikler sunmalarÄ±na sÄ±kÃ§a raÄŸmen, bu kÃ¼tÃ¼phaneler genellikle Kaggle ortamÄ±na dahil edilmez; bu nedenle, kodunuzda bÃ¶yle bir kÃ¼tÃ¼phaneyi kullanmak istiyorsanÄ±z, aÅŸaÄŸÄ±da gÃ¶sterildiÄŸi gibi veri seti olarak iÃ§e aktarabilirsiniz:

1. Datasets (Veri Setleri) sayfasÄ±na gidin ve â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±klayÄ±n.
2. GitHub simgesini seÃ§in.
3. Depo baÄŸlantÄ±sÄ±nÄ± ve veri seti iÃ§in baÅŸlÄ±ÄŸÄ± girin.
4. SaÄŸ alt kÃ¶ÅŸedeki â€œCreateâ€ (OluÅŸtur) butonuna tÄ±klayÄ±n.

![](im/1008.png)

â€œCreateâ€ (OluÅŸtur) butonunun yanÄ±nda bir de â€œPrivateâ€ (Ã–zel) olarak iÅŸaretlenmiÅŸ baÅŸka bir buton vardÄ±r. VarsayÄ±lan olarak oluÅŸturduÄŸunuz herhangi bir veri seti Ã¶zeldir: yalnÄ±zca siz, yani veri setinin yaratÄ±cÄ±sÄ±, onu gÃ¶rÃ¼ntÃ¼leyip dÃ¼zenleyebilirsiniz. Veri seti oluÅŸturma aÅŸamasÄ±nda bu ayarÄ± varsayÄ±lan hÃ¢lde bÄ±rakmak ve yalnÄ±zca daha sonraki bir aÅŸamada veri setini halka aÃ§mak (ya belirli bir katkÄ±da bulunanlar listesi iÃ§in ya da herkes iÃ§in) muhtemelen iyi bir fikirdir.

Kaggleâ€™Ä±n popÃ¼ler bir platform olduÄŸunu ve birÃ§ok kiÅŸinin veri setlerini â€“ Ã¶zel olanlar da dahil â€“ yÃ¼klediÄŸini unutmayÄ±n; bu nedenle, veri setiniz iÃ§in genel olmayan bir baÅŸlÄ±k dÃ¼ÅŸÃ¼nmeye Ã§alÄ±ÅŸÄ±n. Bu, veri setinizin gerÃ§ekten fark edilme ÅŸansÄ±nÄ± artÄ±racaktÄ±r.

TÃ¼m adÄ±mlarÄ± tamamlayÄ±p â€œCreateâ€ (OluÅŸtur) butonuna tÄ±kladÄ±ÄŸÄ±nÄ±zda, voilÃ ! Ä°lk veri setiniz hazÄ±r. ArdÄ±ndan â€œDataâ€ sekmesine gidebilirsiniz:

![](im/1009.png)

YukarÄ±daki ekran gÃ¶rÃ¼ntÃ¼sÃ¼, veri setinizle ilgili saÄŸlayabileceÄŸiniz farklÄ± bilgileri gÃ¶stermektedir; saÄŸladÄ±ÄŸÄ±nÄ±z bilgi ne kadar Ã§ok olursa, kullanÄ±labilirlik indeksi o kadar yÃ¼ksek olur. Bu indeks, veri setinizin ne kadar iyi tanÄ±mlandÄ±ÄŸÄ±nÄ± Ã¶zetleyen sentetik bir Ã¶lÃ§Ã¼dÃ¼r. YÃ¼ksek kullanÄ±labilirlik indeksine sahip veri setleri, arama sonuÃ§larÄ±nda daha Ã¼st sÄ±ralarda gÃ¶rÃ¼nÃ¼r. Her veri seti iÃ§in kullanÄ±labilirlik indeksi, dokÃ¼mantasyon seviyesi, Notebooks gibi ilgili kamuya aÃ§Ä±k iÃ§eriklerin referans olarak bulunabilirliÄŸi, dosya tÃ¼rleri ve temel meta verilerin kapsanmasÄ± gibi Ã§eÅŸitli faktÃ¶rlere dayanÄ±r.

Ä°lke olarak, yukarÄ±daki gÃ¶rselde gÃ¶sterilen tÃ¼m alanlarÄ± doldurmak zorunda deÄŸilsiniz; yeni oluÅŸturduÄŸunuz veri seti bunlar olmadan da tamamen kullanÄ±labilir (ve eÄŸer Ã¶zel bir veri seti ise, muhtemelen Ã¶nemsemezsiniz; sonuÃ§ta iÃ§eriÄŸini siz biliyorsunuz). Ancak, topluluk gÃ¶rgÃ¼ kurallarÄ±, veri setlerinizi halka aÃ§tÄ±ÄŸÄ±nÄ±zda bilgileri doldurmanÄ±zÄ± Ã¶nerir: ne kadar Ã§ok bilgi belirtirseniz, veri baÅŸkalarÄ± iÃ§in o kadar kullanÄ±ÅŸlÄ± olur.

### Gathering the data *(Veri toplama)*

Hukuki boyutlar dÄ±ÅŸÄ±nda, veri setlerinde saklayabileceÄŸiniz iÃ§erik tÃ¼rÃ¼ konusunda gerÃ§ek bir sÄ±nÄ±r yoktur: tablo verileri, gÃ¶rseller, metin; eÄŸer boyut gereksinimlerine uyuyorsa, bunlarÄ± saklayabilirsiniz. Bu, diÄŸer kaynaklardan elde edilen verileri de kapsar; yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihte popÃ¼ler veri setleri arasÄ±nda hashtag veya konuya gÃ¶re toplanmÄ±ÅŸ tweetler yer almaktadÄ±r:

![](im/1010.png)

Sosyal medyadan (Twitter, Reddit ve benzeri) veri toplamak iÃ§in kullanÄ±lan farklÄ± Ã§erÃ§evelerin tartÄ±ÅŸÄ±lmasÄ±, bu kitabÄ±n kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r.

> **Andrew MaranhÃ£o**
> 
> [https://www.kaggle.com/andrewmvd](https://www.kaggle.com/andrewmvd)
> 
> 
> 
> Andrew MaranhÃ£o (diÄŸer adÄ±yla Larxel), Datasets Grandmaster (yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± sÄ±rada Datasetsâ€™te bir numara) ve SÃ£o Pauloâ€™daki Hospital Albert Einsteinâ€™da KÄ±demli Veri Bilimci, bize Datasets baÅŸarÄ±sÄ±na nasÄ±l ulaÅŸtÄ±ÄŸÄ±nÄ±, veri seti oluÅŸturma ipuÃ§larÄ±nÄ± ve Kaggleâ€™daki genel deneyimlerini anlattÄ±.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Genellikle en sevdiÄŸim alan tÄ±bbi gÃ¶rÃ¼ntÃ¼lemedir. Hem iÅŸimle hem de amacÄ±mla Ã¶rtÃ¼ÅŸÃ¼yor. TÄ±bbi yarÄ±ÅŸmalarda NLP dil ile sÄ±nÄ±rlÄ±dÄ±r, tablo verileri hastaneler arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±k gÃ¶sterir, fakat gÃ¶rÃ¼ntÃ¼leme Ã§oÄŸunlukla aynÄ±dÄ±r; bu nedenle bu baÄŸlamda yapÄ±lan herhangi bir geliÅŸme, dÃ¼nya genelinde birÃ§ok Ã¼lke iÃ§in fayda saÄŸlayabilir ve bu etki potansiyelini seviyorum. AyrÄ±ca NLP ve tablo verilerini de severim, ama sanÄ±rÄ±m bu oldukÃ§a standart bir tercih.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸmayÄ± ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemleri anlatÄ±r mÄ±sÄ±nÄ±z?**
> 
> Bir tÃ¼berkÃ¼loz tespit yarÄ±ÅŸmasÄ±nda, yaklaÅŸÄ±k 1.000 rÃ¶ntgen gÃ¶rÃ¼ntÃ¼sÃ¼ vardÄ±; bu sayÄ±, hastalÄ±ÄŸÄ±n tÃ¼m belirtilerini yakalamak iÃ§in oldukÃ§a kÃ¼Ã§Ã¼ktÃ¼. Bunu telafi etmek iÃ§in iki fikir geliÅŸtirdim:
> 
> 
> 
> 1. DÄ±ÅŸ veri ile pnÃ¶moni tespiti iÃ§in Ã¶n eÄŸitim (~20k gÃ¶rÃ¼ntÃ¼), Ã§Ã¼nkÃ¼ pnÃ¶moni tÃ¼berkÃ¼loz ile karÄ±ÅŸtÄ±rÄ±labilir.
> 
> 2. AkciÄŸer anomalilerinin Ã§ok etiketli sÄ±nÄ±flandÄ±rmasÄ± (~600k gÃ¶rÃ¼ntÃ¼) Ã¼zerinde Ã¶n eÄŸitim ve basit bir SSD ile sÄ±nÄ±flandÄ±rma etiketlerinin bounding box anotasyonlarÄ±nÄ± oluÅŸturmak iÃ§in grad-CAM kullanÄ±mÄ±.
> 
> 
> 
> SonuÃ§ta, bu iki yaklaÅŸÄ±mÄ±n basit bir karÄ±ÅŸÄ±mÄ±, ikinci sÄ±radaki takÄ±mÄ±n sonucuna gÃ¶re %22 daha iyi bir performans saÄŸladÄ±. Bu yarÄ±ÅŸma, yaklaÅŸÄ±k 100 takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ± bir tÄ±bbi kongrede gerÃ§ekleÅŸti.
> 
> 
> 
> **Dataset Grandmaster oldunuz ve Datasetsâ€™te 1 numara oldunuz. Veri setleri iÃ§in konu seÃ§imi, veri bulma, toplama ve yayÄ±mlama sÃ¼reciniz nasÄ±l iÅŸliyor?**
> 
> Bu bÃ¼yÃ¼k bir soru; parÃ§alar hÃ¢linde aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m:
> 
> 
> 
> 1. **Kendinize bir amaÃ§ belirleyin**
> 
>    Konu seÃ§erken aklÄ±mda tuttuÄŸum ilk ÅŸey, bunu yapmamÄ±n temel nedenidir. Derin bir amaÃ§ olduÄŸunda, mÃ¼kemmel veri setleri bir sonuÃ§ olarak ortaya Ã§Ä±kar, hedef olarak deÄŸil.
> 
> 
> 
> 2. **Harika bir veri seti, harika bir sorunun vÃ¼cut bulmuÅŸ hÃ¢lidir**
> 
>    En iyi veri setlerinde ortak temalar:
> 
> 
> 
> * Cesur ve ilgili bir soru, bÃ¼yÃ¼k potansiyele sahip
> 
> * Veriler iyi toplanmÄ±ÅŸ, kalite kontrolÃ¼ yapÄ±lmÄ±ÅŸ ve iyi belgelenmiÅŸ
> 
> * Mevcut donanÄ±m iÃ§in yeterli veri ve Ã§eÅŸitlilik
> 
> * Veriye sÃ¼rekli katkÄ±da bulunan aktif bir topluluk
> 
> 
> 
> 3. **Sadece baÅŸarÄ±ya odaklanmayÄ±n; baÅŸarÄ± iÃ§in sÃ¼reci oluÅŸturun**
> 
>    Kalite, nicelikten Ã§ok daha Ã¶nemlidir. Grandmaster olmak iÃ§in sadece 15 veri setine ihtiyacÄ±nÄ±z vardÄ±r ve Ã¶ne Ã§Ä±kan veri setleri az ve iyi hazÄ±rlanmÄ±ÅŸ olmalÄ±dÄ±r. AyrÄ±ca veri setlerinin bakÄ±m ve sÃ¼rekli geliÅŸtirme gerektirdiÄŸini unutmayÄ±n. Topluluk desteÄŸi de Ã§ok Ã¶nemlidir; veri setinizi analiz edenlerin ihtiyaÃ§larÄ±nÄ± ve seÃ§imlerini anlamak, Ã¶n iÅŸleme adÄ±mlarÄ±nÄ±zÄ± ve belgelerinizi geliÅŸtirebilir.
> 
> 
> 
> **Ã–rnek sÃ¼reÃ§:**
> 
> Sosyal refahÄ± artÄ±rmak istiyorsunuz â†’ hedef: Ä±rksal eÅŸitlik â†’ konular: Black Lives Matter hareketi â†’ soru: Milyonlarca sesin ne dediÄŸini nasÄ±l anlayabilirim? â†’ veri tÃ¼rÃ¼: NLP â†’ veri toplama: haber makaleleri, YouTube yorumlarÄ±, tweetler â†’ Ã¶n iÅŸleme ve anonimleÅŸtirme â†’ yayÄ±nlama â†’ topluluk desteÄŸi ve geliÅŸtirme.
> 
> 
> 
> 4. **Ä°yi iÅŸ yapmak, kontrolÃ¼nÃ¼zde olan tek ÅŸeydir**
> 
>    Grandmaster olmanÄ±zÄ± baÅŸkalarÄ± saÄŸlar; oylar her zaman Ã§abaya veya etkiye dÃ¶nÃ¼ÅŸmez. Ã–nemli olan sizin Ã§abanÄ±z, Ã¶ÄŸrenmeniz ve denemenizdir.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz araÃ§lar/lisanslar nelerdir?**
> 
> LightGBM, CatBoost, Optuna, Streamlit, Gradio, FastAPI, Plotly, PyTorch gibi kÃ¼tÃ¼phaneleri Ã¶neriyor. AyrÄ±ca, kendi Ã§Ã¶zÃ¼mlerinizi uygulamak, derinlemesine bilgi edinmek aÃ§Ä±sÄ±ndan Ã§ok deÄŸerli.
> 
> 
> 
> **Deneyimsiz Kagglers neyi sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rÄ±r?**
> 
> 
> 
> * YarÄ±ÅŸmanÄ±n sonunda bilgiyi tam olarak absorbe etmek
> 
> * BitmiÅŸ yarÄ±ÅŸmalarda kazanan Ã§Ã¶zÃ¼mleri tekrar etmek
> 
> 
> 
> **Kaggle kariyerinize nasÄ±l katkÄ± saÄŸladÄ±?**
> 
> Kaggle bilgi, deneyim ve portfÃ¶y kazandÄ±rdÄ±. Ä°lk veri bilimi iÅŸim bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Kaggle ve DrivenData yarÄ±ÅŸmalarÄ± sayesinde oldu.
> 
> 
> 
> **PortfÃ¶yÃ¼nÃ¼zÃ¼ potansiyel iÅŸverenlere gÃ¶stermek iÃ§in Kaggle deneyimlerinizi kullandÄ±nÄ±z mÄ±?**
> 
> Kesinlikle. Ä°lk iÅŸimi Kaggle portfÃ¶yÃ¼ sayesinde aldÄ±m. PortfÃ¶y, eÄŸitim geÃ§miÅŸinden daha iyi veri bilimi bilgisi ve deneyimi temsil eder.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musunuz? Kaggle ile karÅŸÄ±laÅŸtÄ±rmasÄ± nasÄ±l?**
> 
> DrivenData ve AICrowdâ€™u da kullanÄ±yorum. Kaggle daha bÃ¼yÃ¼k ve aktif bir topluluk sunuyor, donanÄ±m ve veri/Notebook Ã¶zellikleri ile en iyi seÃ§enek. Ancak diÄŸer platformlar da ilginÃ§ ve Ã§eÅŸitli zorluklar sunuyor.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya girerken en Ã¶nemli ÅŸey nedir?**
> 
> GeliÅŸim odaklÄ±ysanÄ±z, ilginizi Ã§eken ve daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z bir konuyu seÃ§in. Derinlik ve Ã§eÅŸitlilik kritik; derinlik, odaklanarak ve en iyinizi vererek; Ã§eÅŸitlilik ise daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z veya farklÄ± yaptÄ±ÄŸÄ±nÄ±z ÅŸeyleri deneyerek elde edilir.

### Working with datasets *(Veri setleriyle Ã§alÄ±ÅŸma)*

Bir veri seti oluÅŸturduktan sonra, muhtemelen onu analizlerinizde kullanmak isteyeceksiniz. Bu bÃ¶lÃ¼mde, bunu yapmanÄ±n farklÄ± yÃ¶ntemlerini ele alÄ±yoruz.

Muhtemelen en Ã¶nemli yÃ¶ntem, veri setinizi birincil kaynak olarak kullanacaÄŸÄ±nÄ±z bir Notebook baÅŸlatmaktÄ±r. Bunu yapmak iÃ§in veri seti sayfasÄ±na gidip ardÄ±ndan **New Notebook** Ã¼zerine tÄ±klayabilirsiniz.

![](im/1011.png)

Bunu yaptÄ±ktan sonra, Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![](im/1012.png)

Ä°ÅŸte bununla ilgili birkaÃ§ ipucu:

* AlfasayÄ±sal baÅŸlÄ±k otomatik olarak oluÅŸturulur; Ã¼zerine tÄ±klayarak dÃ¼zenleyebilirsiniz.
* SaÄŸ tarafta, **Data** altÄ±nda Notebookâ€™unuza baÄŸlÄ± veri kaynaklarÄ±nÄ±n listesini gÃ¶rÃ¼rsÃ¼nÃ¼z; seÃ§tiÄŸim veri setine **../input/** veya **/kaggle/input/** Ã¼zerinden eriÅŸilebilir.
* AÃ§Ä±lÄ±ÅŸ bloÄŸu (iÃ§e aktarÄ±lan paketler, aÃ§Ä±klayÄ±cÄ± yorumlar ve mevcut dosyalarÄ±n listesi) yeni bir Python Notebookâ€™a otomatik olarak eklenir.

Bu temel kurulumla, analiziniz iÃ§in bir Notebook yazmaya baÅŸlayabilir ve veri setinizi veri kaynaÄŸÄ± olarak kullanabilirsiniz. Notebookâ€™larÄ± daha ayrÄ±ntÄ±lÄ± olarak **BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±ndan Yararlanmak** kÄ±smÄ±nda ele alacaÄŸÄ±z.

### Using Kaggle Datasets in Google Colab *(Google Colabâ€™da Kaggle veri setlerini kullanma)*

Kaggle Notebookâ€™larÄ± Ã¼cretsizdir, ancak sÄ±nÄ±rsÄ±z deÄŸildir (buna BÃ¶lÃ¼m 4â€™te daha ayrÄ±ntÄ±lÄ± deÄŸineceÄŸiz) ve karÅŸÄ±laÅŸabileceÄŸiniz ilk sÄ±nÄ±rlama muhtemelen **zaman limitidir**. PopÃ¼ler bir alternatif, tamamen bulutta Ã§alÄ±ÅŸan Ã¼cretsiz bir Jupyter Notebook ortamÄ± olan **Google Colab**â€™a geÃ§mektir: [https://colab.research.google.com](https://colab.research.google.com).

HesaplamalarÄ± Colabâ€™a taÅŸÄ±dÄ±ktan sonra bile Kaggle veri setlerine eriÅŸmek isteyebiliriz; bu yÃ¼zden onlarÄ± Colabâ€™a aktarmak oldukÃ§a kullanÄ±ÅŸlÄ± bir Ã¶zelliktir. Bu bÃ¶lÃ¼mÃ¼n geri kalanÄ±nda, Kaggle Datasetsâ€™i Colab Ã¼zerinden kullanmak iÃ§in gerekli adÄ±mlarÄ± ele alacaÄŸÄ±z.

Ä°lk olarak, Kaggleâ€™a zaten kayÄ±tlÄ± olduÄŸumuzu varsayarak, **API token** (giriÅŸ oturumu, kullanÄ±cÄ± kimliÄŸi, yetkiler vb. iÃ§in gÃ¼venlik bilgilerini iÃ§eren eriÅŸim belirteci) oluÅŸturmak iÃ§in hesap sayfasÄ±na gideriz:

1. HesabÄ±nÄ±za gidin: [https://www.kaggle.com/USERNAME/account](https://www.kaggle.com/USERNAME/account)

**Create New API Token** butonuna tÄ±klayÄ±n.

![](im/1013.png)

Bir **kaggle.json** dosyasÄ± oluÅŸturulacak; bu dosya kullanÄ±cÄ± adÄ±nÄ±zÄ± ve API tokenâ€™Ä±nÄ±zÄ± iÃ§erir.

2. Google Driveâ€™Ä±nÄ±zda **Kaggle** adÄ±nda bir klasÃ¶r oluÅŸturun ve **.json** dosyasÄ±nÄ± bu klasÃ¶re yÃ¼kleyin.

![](im/1014.png)

3. Ä°ÅŸlem tamamlandÄ±ktan sonra, yeni bir Colab defteri oluÅŸturmanÄ±z ve Google Driveâ€™Ä±nÄ±zÄ± baÄŸlamanÄ±z gerekir. Bunu yapmak iÃ§in defterde aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rÄ±n:

```python
from google.colab import drive
drive.mount('/content/gdrive')
```

4. URL isteminden yetkilendirme kodunu alÄ±n ve aÃ§Ä±lan boÅŸ kutuya girin, ardÄ±ndan aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rarak `.json` yapÄ±landÄ±rma dosyasÄ±nÄ±n yolunu belirtin:

```python
import os
# content/gdrive/My Drive/Kaggle is the path where kaggle.json is
# present in the Google Drive
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
# change the working directory
%cd /content/gdrive/My Drive/Kaggle
# check the present working directory using the pwd command
```

5. ArtÄ±k veri setini indirebiliriz. Bunun iÃ§in Kaggleâ€™daki veri seti sayfasÄ±na gidin, **New Notebook** yanÄ±ndaki Ã¼Ã§ noktaya tÄ±klayÄ±n ve **Copy API command** seÃ§eneÄŸini seÃ§in:

![alt text](im/1015.png)

6. Veri setini indirmek iÃ§in API komutunu Ã§alÄ±ÅŸtÄ±rÄ±n (komutlarÄ±n detaylarÄ±yla ilgilenenler resmi dokÃ¼mantasyona bakabilir: [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)):

```python
!kaggle datasets download -d ajaypalsinghlo/world-happinessreport-2021
```
7. Veri seti, Kaggle klasÃ¶rÃ¼ne bir .zip arÅŸivi olarak indirilecektir â€“ arÅŸivi aÃ§Ä±n ve kullanÄ±ma hazÄ±r hale gelmiÅŸ olacaktÄ±r.

YukarÄ±daki listeden de gÃ¶rebileceÄŸiniz gibi, bir Kaggle veri setini Colabâ€™da kullanmak oldukÃ§a basit bir sÃ¼reÃ§tir â€“ tek ihtiyacÄ±nÄ±z olan bir API tokenâ€™Ä±dÄ±r ve bu geÃ§iÅŸ size Kaggleâ€™Ä±n saÄŸladÄ±ÄŸÄ±ndan daha fazla GPU saatini kullanma imkÃ¢nÄ± verir.

### Legal caveats *(Yasal uyarÄ±lar)*

Sadece bazÄ± verileri Kaggleâ€™a yÃ¼kleyebilmeniz, bunu yapmanÄ±z gerektiÄŸi anlamÄ±na gelmez. MÃ¼kemmel bir Ã¶rnek, **People of Tinder** veri setidir. 2017â€™de bir geliÅŸtirici, Tinder APIâ€™sini kullanarak web sitesinden yarÄ±-Ã¶zel profilleri Ã§ekmiÅŸ ve veriyi Kaggleâ€™a yÃ¼klemiÅŸti. Bu durum ortaya Ã§Ä±ktÄ±ktan sonra, Kaggle veri setini kaldÄ±rdÄ±. Tam hikÃ¢yeyi ÅŸuradan okuyabilirsiniz: [Forbes makalesi](https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454).

Genel olarak, Kaggleâ€™a herhangi bir ÅŸey yÃ¼klemeden Ã¶nce kendinize ÅŸu iki soruyu sorun:

1. **Telif hakkÄ± aÃ§Ä±sÄ±ndan izinli mi?** LisanslarÄ± her zaman kontrol edin. ÅÃ¼phe durumunda [Open Definition Guide](https://opendefinition.org/guide/data/) veya Kaggle ile iletiÅŸime geÃ§ebilirsiniz.
2. **Bu veri setiyle ilgili gizlilik riskleri var mÄ±?** Belirli bilgileri paylaÅŸmak, teknik olarak yasadÄ±ÅŸÄ± olmasa da, baÅŸka bir kiÅŸinin gizliliÄŸine zarar verebilir.

Bu sÄ±nÄ±rlamalar aslÄ±nda saÄŸduyuya dayanmaktadÄ±r, bu yÃ¼zden Kaggleâ€™daki Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± engellemesi pek olasÄ± deÄŸildir.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle platformunda verileri depolamanÄ±n ve kullanmanÄ±n standart yolu olan **Kaggle Datasets**â€™i tanÄ±ttÄ±k. Veri seti oluÅŸturmayÄ±, Kaggle dÄ±ÅŸÄ±ndaki ortamlarda Ã§alÄ±ÅŸma yÃ¶ntemlerini ve en Ã¶nemli iÅŸlevi olan **veri setini Notebookâ€™ta kullanmayÄ±** ele aldÄ±k. Bu, bir sonraki bÃ¶lÃ¼mde odaklanacaÄŸÄ±mÄ±z **Kaggle Notebooks** konusuna geÃ§iÅŸ iÃ§in gÃ¼zel bir kÃ¶prÃ¼ oluÅŸturuyor.

---

## Chapter 3: Working and Learning with Kaggle Notebooks *(BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek)*

Kaggle Notebooks â€” yakÄ±n zamana kadar **Kernels** olarak adlandÄ±rÄ±lÄ±yordu â€” tarayÄ±cÄ± Ã¼zerinden Ã§alÄ±ÅŸan ve Ã¼cretsiz olan **Jupyter Notebook**â€™lardÄ±r. Bu, internet baÄŸlantÄ±sÄ± olan herhangi bir cihazdan deneylerinizi Ã§alÄ±ÅŸtÄ±rabileceÄŸiniz anlamÄ±na gelir; ancak mobil telefondan daha bÃ¼yÃ¼k bir cihaz kullanmak muhtemelen daha iyi olacaktÄ±r. OrtamÄ±n teknik Ã¶zellikleri (yazÄ±m tarihi itibarÄ±yla) Kaggle web sitesinden alÄ±nmÄ±ÅŸtÄ±r; en gÃ¼ncel sÃ¼rÃ¼mÃ¼ **[https://www.kaggle.com/docs/notebooks](https://www.kaggle.com/docs/notebooks)** adresinden doÄŸrulanabilir:

* CPU/GPU iÃ§in 12 saat Ã§alÄ±ÅŸma sÃ¼resi, TPU iÃ§in 9 saat
* 20 GB otomatik kaydedilen disk alanÄ± (/kaggle/working)
* Ek geÃ§ici disk alanÄ± ( /kaggle/working dÄ±ÅŸÄ±nda) â€” bu alan mevcut oturum dÄ±ÅŸÄ±nda kaydedilmez

**CPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

**GPU Ã¶zellikleri:**

* 2 CPU Ã§ekirdeÄŸi
* 13 GB RAM

**TPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

Bu bÃ¶lÃ¼mde ele alacaÄŸÄ±mÄ±z konular:

* Notebook kurulumunu yapmak
* Notebookâ€™unuzu Ã§alÄ±ÅŸtÄ±rmak
* Notebookâ€™larÄ± GitHubâ€™a kaydetmek
* Notebookâ€™lardan en iyi ÅŸekilde faydalanmak
* Kaggle Learn kurslarÄ±

Hadi baÅŸlayalÄ±m. Ä°lk yapmamÄ±z gereken, bir Notebookâ€™un nasÄ±l kurulacaÄŸÄ±nÄ± Ã¶ÄŸrenmek.

### Setting up a Notebook *(Bir defter oluÅŸturma)*

Bir Notebook oluÅŸturmanÄ±n iki temel yÃ¶ntemi vardÄ±r: **ana sayfadan** veya **bir Dataset Ã¼zerinden**.

Ä°lk yÃ¶ntemi kullanmak iÃ§in:

1. [https://www.kaggle.com/](https://www.kaggle.com/) adresindeki ana sayfada, sol menÃ¼deki **Code** bÃ¶lÃ¼mÃ¼ne gidin.
2. ArdÄ±ndan **+ New Notebook** butonuna tÄ±klayÄ±n.

Bu yÃ¶ntem, kendi veri setinizi yÃ¼klemeyi iÃ§eren bir deneme planlÄ±yorsanÄ±z tercih edilen yÃ¶ntemdir.

![alt text](im/1016.png)

Alternatif olarak, ilgilendiÄŸiniz Datasetâ€™in sayfasÄ±na gidip oradaki **New Notebook** butonuna tÄ±klayabilirsiniz; bu yÃ¶ntemi bir Ã¶nceki bÃ¶lÃ¼mde gÃ¶rmÃ¼ÅŸtÃ¼k.

![alt text](im/1017.png)

Hangi yÃ¶ntemi seÃ§erseniz seÃ§in, **New Notebook** butonuna tÄ±kladÄ±ktan sonra Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![alt text](im/1018.png)

YukarÄ±da gÃ¶sterilen yeni Notebook sayfasÄ±nÄ±n saÄŸ tarafÄ±nda, ayarlanabilecek birkaÃ§ farklÄ± ayar bulunmaktadÄ±r:

![alt text](im/1019.png)

AyarlarÄ± kÄ±saca ele alalÄ±m:

1. **Kodlama Dili (Language)**:
   Kaggle ortamÄ±, yazÄ±ldÄ±ÄŸÄ± tarihte yalnÄ±zca Python ve R dillerini destekliyor. Yeni bir Notebook varsayÄ±lan olarak Python ile aÃ§Ä±lÄ±r. R kullanmak isterseniz aÃ§Ä±lÄ±r menÃ¼den Râ€™yi seÃ§ebilirsiniz.

2. **Ortam (Environment)**:
   Bu seÃ§enek, Notebookâ€™un hangi Docker ortamÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirler.

   * **Latest Docker**: En gÃ¼ncel ortamÄ± kullanÄ±r; hÄ±zlÄ± gÃ¼ncellemeler alÄ±rsÄ±nÄ±z ama baÄŸÄ±mlÄ±lÄ±klar bozulabilir (riskli).
   * **Original Kaggle environment**: Kaggle tarafÄ±ndan saÄŸlanan orijinal ortamÄ± kullanÄ±r (gÃ¼venli ve varsayÄ±lan).

3. **HÄ±zlandÄ±rÄ±cÄ± (Accelerator)**:
   Kodun hangi donanÄ±mda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± seÃ§menizi saÄŸlar:

   * **CPU**: HÄ±zlandÄ±rmasÄ±z
   * **GPU**: Derin Ã¶ÄŸrenme uygulamalarÄ± iÃ§in gereklidir
   * **TPU**: TPUâ€™ya taÅŸÄ±mak iÃ§in veri iÅŸleme ve kodda daha kapsamlÄ± deÄŸiÅŸiklik gerekir

   CPU, GPU veya TPU arasÄ±nda geÃ§iÅŸ yapabilirsiniz; fakat geÃ§iÅŸ yaptÄ±ÄŸÄ±nÄ±zda ortam yeniden baÅŸlatÄ±lÄ±r ve tÃ¼m kodu baÅŸtan Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekir.

4. **Ä°nternet (Internet) AÃ§ma/Kapama**:
   Ä°nternete eriÅŸimi aÃ§Ä±p kapatmanÄ±zÄ± saÄŸlar. Ã–rneÄŸin, ek paket yÃ¼klemek gerektiÄŸinde internet aÃ§Ä±k olmalÄ±dÄ±r. BazÄ± yarÄ±ÅŸmalarda, teslim sÄ±rasÄ±nda internetin kapalÄ± olmasÄ± zorunludur.

AyrÄ±ca, mevcut bir Notebookâ€™u (kendinizin veya baÅŸkasÄ±nÄ±n oluÅŸturduÄŸu) **kopyalayÄ±p dÃ¼zenleyebilirsiniz**. Bunun iÃ§in Notebook sayfasÄ±nÄ±n saÄŸ Ã¼stÃ¼ndeki **Copy and Edit** butonuna tÄ±klamanÄ±z yeterlidir. Kaggleâ€™da bu iÅŸlem **forking** olarak adlandÄ±rÄ±lÄ±r.

![alt text](im/1020.png)

> Bir gÃ¶rgÃ¼ notu: EÄŸer daha Ã¶nce bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ±ysanÄ±z, sÄ±ralama tablosunun (leaderboard) iyi puan alan Notebookâ€™larÄ±n kopyalarÄ±yla (forks of forks) dolu olduÄŸunu fark etmiÅŸsinizdir. BaÅŸkasÄ±nÄ±n Ã§alÄ±ÅŸmasÄ± Ã¼zerine inÅŸa etmek yanlÄ±ÅŸ deÄŸildir; ancak bunu yaparken **orijinal yazara oy vermeyi (upvote) ve referans alÄ±nan Ã§alÄ±ÅŸmanÄ±n sahibine aÃ§Ä±kÃ§a kredi vermeyi** unutmayÄ±n.

OluÅŸturduÄŸunuz bir Notebook varsayÄ±lan olarak **Ã¶zel**dir (sadece siz gÃ¶rebilirsiniz). EÄŸer baÅŸkalarÄ±nÄ±n eriÅŸmesini istiyorsanÄ±z iki seÃ§enek vardÄ±r:

1. **Ä°ÅŸbirlikÃ§ileri eklemek (adding collaborators):** Sadece aÃ§Ä±kÃ§a eklenen kullanÄ±cÄ±lar Notebookâ€™u gÃ¶rebilir veya dÃ¼zenleyebilir.
2. **Notebookâ€™u herkese aÃ§Ä±k yapmak (making public):** Bu durumda herkes Notebookâ€™u gÃ¶rebilir.

### Running your Notebook *(Defterinizi Ã§alÄ±ÅŸtÄ±rma)*

TÃ¼m kodlamalar tamamlandÄ±, Notebook sorunsuz Ã§alÄ±ÅŸÄ±yor gibi gÃ¶rÃ¼nÃ¼yor ve Ã§alÄ±ÅŸtÄ±rmaya hazÄ±rsÄ±nÄ±z. Bunu yapmak iÃ§in, Notebook sayfanÄ±zÄ±n **saÄŸ Ã¼st kÃ¶ÅŸesine** gidin ve **Save Version** (SÃ¼rÃ¼mÃ¼ Kaydet) dÃ¼ÄŸmesine tÄ±klayÄ±n.

![](im/1021.png)

**Save & Run All** genellikle tÃ¼m scripti Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r, ancak **Quick Save** seÃ§eneÄŸi de vardÄ±r; bu, script henÃ¼z gÃ¶nderime hazÄ±r olmadan Ã¶nce ara bir sÃ¼rÃ¼mÃ¼ kaydetmek iÃ§in kullanÄ±labilir.

![](im/1022.png)

Scriptinizi baÅŸlattÄ±ktan sonra, sol alt kÃ¶ÅŸeye gidip **Active Events** (Aktif Etkinlikler) butonuna tÄ±klayabilirsiniz. Bu bÃ¶lÃ¼m, Ã§alÄ±ÅŸmakta olan Notebook sÃ¼rÃ¼mlerinizin durumunu ve ilerlemesini izlemenizi saÄŸlar.

![](im/1023.png)

Bu ÅŸekilde, Notebookâ€™larÄ±nÄ±zÄ±n Ã§alÄ±ÅŸma durumunu takip edebilirsiniz. Normal bir yÃ¼rÃ¼tme sÄ±rasÄ±nda **Running** mesajÄ± gÃ¶rÃ¼nÃ¼r; aksi durumda **Failed** olarak gÃ¶rÃ¼ntÃ¼lenir.

EÄŸer herhangi bir nedenle (Ã¶rneÄŸin en gÃ¼ncel veriyi kullanmayÄ± unuttuÄŸunuzu fark ederseniz) Ã§alÄ±ÅŸan bir oturumu sonlandÄ±rmak isterseniz, **Active Events** altÄ±nda script giriÅŸinizin saÄŸ tarafÄ±ndaki Ã¼Ã§ noktaya tÄ±klayabilirsiniz. Bu iÅŸlem size aÅŸaÄŸÄ±daki ÅŸekilde bir aÃ§Ä±lÄ±r pencere (pop-up) gÃ¶sterecektir ve oturumu durdurmanÄ±za olanak tanÄ±r.

![](im/1024.png)

### Saving Notebooks to GitHub *(Defterleri GitHubâ€™a kaydetme)*

YakÄ±n zamanda eklenen bir Ã¶zellik (bkz. [https://www.kaggle.com/product-feedback/295170](https://www.kaggle.com/product-feedback/295170)), kodunuzu veya Notebookâ€™unuzu GitHub sÃ¼rÃ¼m kontrol deposuna ([https://github.com/](https://github.com/)) kaydetmenize olanak tanÄ±r. Ã‡alÄ±ÅŸmanÄ±zÄ± hem **public** hem de **private** depolara kaydedebilirsiniz ve bu iÅŸlem, kodunuzun bir versiyonunu kaydettiÄŸinizde otomatik olarak gerÃ§ekleÅŸir.

Bu Ã¶zellik, hem Kaggle takÄ±m arkadaÅŸlarÄ±nÄ±zla Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± paylaÅŸmak hem de Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± daha geniÅŸ bir kitleye sergilemek iÃ§in oldukÃ§a faydalÄ± olabilir.

Bu Ã¶zelliÄŸi etkinleÅŸtirmek iÃ§in:

1. Notebookâ€™unuzu aÃ§Ä±n.
2. Ãœst menÃ¼den **File** menÃ¼sÃ¼ne gidin.
3. **Link to GitHub** seÃ§eneÄŸini tÄ±klayÄ±n.

![](im/1025.png)

Bu seÃ§eneÄŸi seÃ§tikten sonra, GitHub hesabÄ±nÄ±zÄ± Notebook ile baÄŸlamanÄ±z gerekecek. Ä°lk kez baÄŸlama iÅŸlemi yaptÄ±ÄŸÄ±nÄ±zda, aÃ§Ä±kÃ§a **baÄŸlantÄ± izinleri** sorulacaktÄ±r. Sonraki yeni Notebookâ€™larda ise bu iÅŸlem otomatik olarak gerÃ§ekleÅŸtirilecektir.

![](im/1026.png)

Notebookâ€™unuzu ancak baÄŸladÄ±ktan sonra, kaydettiÄŸinizde Ã§alÄ±ÅŸmanÄ±zÄ± seÃ§tiÄŸiniz bir GitHub deposuyla senkronize etme izniniz olur.

![](im/1027.png)

Bir depo ve dal (branch) seÃ§tikten sonra, Ã§alÄ±ÅŸmanÄ±zÄ±n farklÄ± geliÅŸtirme aÅŸamalarÄ±nÄ± saklamanÄ±za olanak tanÄ±r ve depoya gÃ¶ndereceÄŸiniz dosyanÄ±n adÄ±nÄ± deÄŸiÅŸtirebilir ve commit mesajÄ±nÄ± dÃ¼zenleyebilirsiniz.

ArtÄ±k belirli bir Notebookâ€™u GitHub ile senkronize etmek istemiyorsanÄ±z, tek yapmanÄ±z gereken Dosya menÃ¼sÃ¼nden **Unlink from GitHub** seÃ§eneÄŸini tÄ±klamaktÄ±r.

Son olarak, Kaggleâ€™Ä±n GitHub hesabÄ±nÄ±za baÄŸlanmasÄ±nÄ± tamamen durdurmak isterseniz, hesaplarÄ±nÄ±zÄ± ya Kaggleâ€™daki **My linked accounts** sayfasÄ±ndan ya da GitHubâ€™daki [ayarlar](https://github.com/settings/applications) sayfasÄ±ndan ayÄ±rabilirsiniz.

### Getting the most out of Notebooks *(Defterlerden en iyi ÅŸekilde yararlanma)*

Kaggle, belirli miktarda kaynaklarÄ± Ã¼cretsiz olarak saÄŸlar ve bu kotlar haftalÄ±k olarak sÄ±fÄ±rlanÄ±r. GPU ve TPU kullanÄ±mÄ± iÃ§in belli bir saat hakkÄ±nÄ±z vardÄ±r; TPU iÃ§in bu sÃ¼re 30 saattir, GPU iÃ§in ise haftadan haftaya deÄŸiÅŸen bir kota uygulanÄ±r (resmÃ® aÃ§Ä±klamayÄ± ve â€œfloatingâ€ kotalar politikasÄ±nÄ± [buradan](https://www.kaggle.com/product-feedback/173129) inceleyebilirsiniz).

Kendi kullanÄ±mÄ±nÄ±zÄ± her zaman profilinizden takip edebilirsiniz.

![](im/1028.png)

Ä°lk bakÄ±ÅŸta kaynak miktarlarÄ± bÃ¼yÃ¼k gÃ¶rÃ¼nebilir, ancak bu izlenim yanÄ±ltÄ±cÄ± olabilir; kotanÄ±zÄ± oldukÃ§a hÄ±zlÄ± bir ÅŸekilde tÃ¼ketmek kolaydÄ±r. Kaynak kullanÄ±mÄ±nÄ± kontrol etmenize yardÄ±mcÄ± olacak bazÄ± pratik Ã¶neriler:

* Kota sayacÄ± (GPU veya TPU gibi seÃ§tiÄŸiniz hÄ±zlandÄ±rÄ±cÄ±yÄ± ne kadar sÃ¼re kullandÄ±ÄŸÄ±nÄ±zÄ± Ã¶lÃ§en sayaÃ§) Notebookâ€™u baÅŸlattÄ±ÄŸÄ±nÄ±z anda Ã§alÄ±ÅŸmaya baÅŸlar.
* Bu nedenle, Ã¶ncelikle ayarlardan GPUâ€™nun devre dÄ±ÅŸÄ± olduÄŸundan emin olun (bkz. Åekil 3.6). Ã–nce temel kodu yazÄ±n, sÃ¶zdizimini kontrol edin ve yalnÄ±zca GPU gerektiren kod parÃ§alarÄ±nÄ± eklediÄŸinizde GPUâ€™yu etkinleÅŸtirin. HatÄ±rlatma: HÄ±zlandÄ±rÄ±cÄ±yÄ± deÄŸiÅŸtirdiÄŸinizde Notebook yeniden baÅŸlatÄ±lÄ±r.
* Kodun tamamÄ±nÄ± kÃ¼Ã§Ã¼k bir veri alt kÃ¼mesi Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmak genellikle iyi bir fikirdir; bÃ¶ylece Ã§alÄ±ÅŸtÄ±rma sÃ¼resini tahmin edebilir ve kotayÄ± aÅŸarak kodun Ã§Ã¶kmesi riskini en aza indirirsiniz.

Bazen Kaggleâ€™Ä±n Ã¼cretsiz olarak saÄŸladÄ±ÄŸÄ± kaynaklar, yapÄ±lacak iÅŸ iÃ§in yeterli olmayabilir ve daha gÃ¼Ã§lÃ¼ bir makineye geÃ§meniz gerekir. Ã–rneÄŸin, yakÄ±n zamanda yapÄ±lan bir tÃ¼mÃ¶r sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmasÄ±: [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data).

EÄŸer ham veriniz 100GBâ€™dan bÃ¼yÃ¼kse, ya gÃ¶rÃ¼ntÃ¼leri yeniden boyutlandÄ±rmalÄ±/aÅŸaÄŸÄ± Ã¶rneklemeli (bu model performansÄ±nÄ± olumsuz etkileyebilir) ya da yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼leri iÅŸleyebilecek bir ortamda model eÄŸitmelisiniz. BÃ¼tÃ¼n ortamÄ± kendiniz kurabilirsiniz (Ã¶rnek olarak, BÃ¶lÃ¼m 2â€™deki â€œGoogle Colabâ€™da Kaggle Datasets KullanÄ±mÄ±â€ kÄ±smÄ±na bakabilirsiniz) veya Notebooks Ã§erÃ§evesinde kalÄ±p, altyapÄ± makinesini deÄŸiÅŸtirebilirsiniz. Ä°ÅŸte burada Google Cloud AI Notebooks devreye girer.

### Upgrading to Google Cloud Platform (GCP) *(Google Cloud Platformâ€™a (GCP) yÃ¼kseltme)*

GCPâ€™ye (Google Cloud Platform) geÃ§menin bariz avantajÄ±, daha gÃ¼Ã§lÃ¼ donanÄ±ma eriÅŸim saÄŸlamaktÄ±r: Kaggle tarafÄ±ndan saÄŸlanan Tesla P100 GPU birÃ§ok uygulama iÃ§in yeterli olsa da performans aÃ§Ä±sÄ±ndan en Ã¼st seviye deÄŸildir ve 16 GB RAM de Ã¶zellikle bÃ¼yÃ¼k NLP modelleri veya yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼ iÅŸleme gibi kaynak yoÄŸun uygulamalarda sÄ±nÄ±rlayÄ±cÄ± olabilir. Ã‡alÄ±ÅŸtÄ±rma sÃ¼resindeki iyileÅŸme, geliÅŸtirme dÃ¶ngÃ¼sÃ¼nde daha hÄ±zlÄ± iterasyon imkÃ¢nÄ± saÄŸlarken, bunun bir maliyeti vardÄ±r: Ne kadar harcamaya hazÄ±r olduÄŸunuzu belirlemeniz gerekir. GÃ¼Ã§lÃ¼ bir makine ile veri iÅŸlemek sÃ¶z konusu olduÄŸunda zaman, kelimenin tam anlamÄ±yla paradÄ±r.

Notebookâ€™unuzu GCP ortamÄ±na taÅŸÄ±mak iÃ§in, saÄŸ taraftaki yan menÃ¼den **Upgrade to Google Cloud AI Notebooks** seÃ§eneÄŸine tÄ±klayÄ±n.

![](im/1029.png)

Åu ifadeyle karÅŸÄ±lanacaksÄ±nÄ±z:

![](im/1030.png)

â€œDevam Etâ€e tÄ±kladÄ±ÄŸÄ±nÄ±zda, faturalandÄ±rma seÃ§eneklerinizi yapÄ±landÄ±rmanÄ±z gereken Google Cloud Platform konsoluna yÃ¶nlendirileceksiniz. HatÄ±rlatma: GCP Ã¼cretsiz deÄŸildir. Ä°lk kez kullanÄ±yorsanÄ±z, gerekli adÄ±mlar boyunca size rehberlik edecek bir Ã¶ÄŸreticiyi (tutorial) tamamlamanÄ±z gerekecektir.

### One step beyond *(Bir adÄ±m Ã¶teye geÃ§mek)*

Bu bÃ¶lÃ¼mÃ¼n Ã¶nceki kÄ±sÄ±mlarÄ±nda da belirtildiÄŸi gibi, **Kaggle Notebooks** (Kaggle Defterleri) eÄŸitim ve yarÄ±ÅŸmalara katÄ±lÄ±m iÃ§in harika bir araÃ§tÄ±r; ancak aynÄ± zamanda bir baÅŸka son derece faydalÄ± amaca da hizmet eder: **veri bilimi becerilerinizi sergileyebileceÄŸiniz bir portfÃ¶yÃ¼n parÃ§asÄ±** olarak kullanÄ±labilirler.

Bir veri bilimi portfÃ¶yÃ¼ oluÅŸtururken dikkate alÄ±nabilecek birÃ§ok potansiyel kriter vardÄ±r (markalaÅŸma, hedef kitleye ulaÅŸma, potansiyel iÅŸvereninize kendinizi tanÄ±tma vb.); ancak kimse portfÃ¶yÃ¼nÃ¼zÃ¼ bulamazsa, bunlarÄ±n hiÃ§birinin Ã¶nemi kalmaz. Kaggle, Googleâ€™Ä±n bir parÃ§asÄ± olduÄŸu iÃ§in Notebooks (defterler), dÃ¼nyanÄ±n en popÃ¼ler arama motoru tarafÄ±ndan dizine eklenir; dolayÄ±sÄ±yla biri kodunuzla ilgili bir konuyu aradÄ±ÄŸÄ±nda, Ã§alÄ±ÅŸmanÄ±z arama sonuÃ§larÄ±nda gÃ¶rÃ¼nebilir.

AÅŸaÄŸÄ±da kiÅŸisel bir Ã¶rnek gÃ¶steriyorum: birkaÃ§ yÄ±l Ã¶nce bir yarÄ±ÅŸma iÃ§in bir Notebook yazmÄ±ÅŸtÄ±m. Ãœzerinde Ã§alÄ±ÅŸmak istediÄŸim problem, **adversarial validation** (karÅŸÄ±t doÄŸrulama) idi. (Bu konuya aÅŸina olmayanlar iÃ§in kÄ±sa bir aÃ§Ä±klama: eÄŸitim ve test veri kÃ¼melerinizin benzer bir daÄŸÄ±lÄ±ma sahip olup olmadÄ±ÄŸÄ±nÄ± anlamanÄ±n oldukÃ§a kolay bir yolu, onlarÄ± ayÄ±rt etmeyi Ã¶ÄŸrenen ikili bir sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturmaktÄ±r; bu kavram 6. BÃ¶lÃ¼mâ€™de, *Ä°yi Bir DoÄŸrulama Tasarlama* kÄ±smÄ±nda daha ayrÄ±ntÄ±lÄ± olarak ele alÄ±nmÄ±ÅŸtÄ±r.)

Bu bÃ¶lÃ¼mÃ¼ yazarken, o defteri aramayÄ± denedim ve tahmin edin ne oldu â€” arama sonuÃ§larÄ±nda oldukÃ§a Ã¼st sÄ±ralarda gÃ¶rÃ¼ndÃ¼. (Dikkat ederseniz, arama sorguma â€œKaggleâ€ veya adÄ±m gibi kiÅŸisel bilgiler eklemedim.)

![](im/1031.png)

Notebooks kullanarak becerilerinizi sergilemenin diÄŸer avantajlarÄ±na geÃ§elim: **Competitions (YarÄ±ÅŸmalar)**, **Datasets (Veri KÃ¼meleri)** ve **Discussions (TartÄ±ÅŸmalar)** bÃ¶lÃ¼mlerinde olduÄŸu gibi, **Notebooks** da oy (vote) ve madalya (medal) alabilir. Bu sayede Kaggleâ€™daki ilerleme sisteminde ve sÄ±ralamalarda yerinizi alabilirsiniz.

YarÄ±ÅŸmalara hiÃ§ katÄ±lmadan da, yalnÄ±zca topluluk tarafÄ±ndan beÄŸenilen yÃ¼ksek kaliteli kodlara odaklanarak **Expert (Uzman)**, **Master (Usta)** veya **Grandmaster (BÃ¼yÃ¼k Usta)** unvanlarÄ±na ulaÅŸabilirsiniz.

Ä°lerleme gereksinimlerinin en gÃ¼ncel hÃ¢lini [https://www.kaggle.com/progression](https://www.kaggle.com/progression) adresinde bulabilirsiniz; aÅŸaÄŸÄ±da ise **Expert** ve **Master** seviyeleriyle ilgili bir Ã¶zet yer almaktadÄ±r:

![](im/1032.png)

**Notebooks** kategorisinde ilerlemek zorlu bir deneyim olabilir; **Competitions (YarÄ±ÅŸmalar)** bÃ¶lÃ¼mÃ¼ne gÃ¶re biraz daha kolay olsa da, **Discussions (TartÄ±ÅŸmalar)** bÃ¶lÃ¼mÃ¼nden kesinlikle daha zordur. En popÃ¼ler Notebooks genellikle belirli bir yarÄ±ÅŸmayla baÄŸlantÄ±lÄ± olanlardÄ±r: **keÅŸifsel veri analizi (exploratory data analysis)**, **uÃ§tan uca kavramsal kanÄ±t Ã§Ã¶zÃ¼mleri (end-to-end proof of concept)** ve **liderlik tablosu kovalamaca (leaderboard chasing)** gibi konulara odaklanÄ±rlar.

Ne yazÄ±k ki, sÄ±kÃ§a rastlanan bir uygulama da ÅŸudur: bazÄ± kiÅŸiler en yÃ¼ksek puanÄ± alan herkese aÃ§Ä±k bir Notebookâ€™u kopyalar (clone eder), birkaÃ§ parametreyi deÄŸiÅŸtirerek skoru biraz artÄ±rÄ±r ve ardÄ±ndan bunu bÃ¼yÃ¼k beÄŸeniyle (upvoteâ€™lar bir beÄŸeni Ã¶lÃ§Ã¼sÃ¼ olarak kabul edilirse) yayÄ±mlar. Bu durum, okuyucunun Kaggleâ€™da kaliteli Ã§alÄ±ÅŸmalar yayÄ±mlama isteÄŸini kÄ±rmak iÃ§in sÃ¶ylenmemektedir â€” Ã§Ã¼nkÃ¼ Kaggle topluluÄŸunun bÃ¼yÃ¼k bir kÄ±smÄ± yenilikÃ§i Ã§alÄ±ÅŸmalarÄ± gerÃ§ekten takdir eder ve uzun vadede kalite her zaman Ã¶ne Ã§Ä±kar â€” ancak **beklentilerin gerÃ§ekÃ§i bir ÅŸekilde ayarlanmasÄ±** gerekir.

Kaggle profilinizin takipÃ§ileri (followers) olur ve **LinkedIn** veya **GitHub** gibi diÄŸer profesyonel aÄŸlarla baÄŸlantÄ± kurma olanaÄŸÄ± sunar; bÃ¶ylece topluluk iÃ§inde kazandÄ±ÄŸÄ±nÄ±z baÄŸlantÄ±larÄ± **fÄ±rsata dÃ¶nÃ¼ÅŸtÃ¼rebilirsiniz**.

![](im/1033.png)

GÃ¼nÃ¼mÃ¼zde â€œtopluluk oluÅŸturmaâ€ iddialarÄ±na karÅŸÄ± kuÅŸkucu olmak oldukÃ§a kolaydÄ±r, ancak **Kaggle** sÃ¶z konusu olduÄŸunda bu durum gerÃ§ekten doÄŸrudur. Kaggleâ€™Ä±n veri bilimi dÃ¼nyasÄ±ndaki marka bilinirliÄŸi, hem uygulayÄ±cÄ±lar (practitioners) hem de iÅŸini gerÃ§ekten iyi yapan iÅŸe alÄ±m uzmanlarÄ± (recruiters) arasÄ±nda rakipsizdir.

Pratikte bu ÅŸu anlama gelir: **yeterince iyi bir Kaggle profili**, sizi zaten â€œkapÄ±dan iÃ§eri sokabilirâ€ â€” ki hepimizin bildiÄŸi gibi, bu genellikle en zor adÄ±mdÄ±r.

> **Martin Henze**
> 
> [https://www.kaggle.com/headsortails](https://www.kaggle.com/headsortails)
> 
> 
> 
> Martin Henze, yani â€œHeads or Tailsâ€ ile konuÅŸma fÄ±rsatÄ±nÄ± bulduk. Kendisi Notebooks ve Discussion alanlarÄ±nda bir **Kaggle Grandmaster** (bÃ¼yÃ¼k usta) ve **Edison Software**â€™da bir veri bilimci. Martin aynÄ± zamanda, her hafta gÃ¶zden kaÃ§mÄ±ÅŸ en iyi Notebooksâ€™larÄ± bir araya getirdiÄŸi **â€œNotebooks of the Week: Hidden Gemsâ€** adlÄ± koleksiyonun yazarÄ±. Yeni â€œHidden Gemsâ€ paylaÅŸÄ±mlarÄ±ndan haberdar olmak iÃ§in Kaggle profilini veya Twitter ve LinkedIn hesaplarÄ±nÄ± takip edebilirsiniz.
> 
> 
> 
> ---
> 
> 
> 
> En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ hangisi ve neden? Teknik aÃ§Ä±dan ya da Ã§Ã¶zÃ¼m yaklaÅŸÄ±mÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™daki uzmanlÄ±k alanÄ±n nedir?
> 
> 
> 
> Uzun bir sÃ¼re boyunca odak noktam, sÄ±ralama tablolarÄ±ndaki tahminlerden ziyade **EDA (exploratory data analysis â€“ keÅŸifsel veri analizi)** not defterleri oldu. Kaggleâ€™dan Ã¶nceki deneyimlerimin Ã§oÄŸu tablo (tabular) verilerleydi ve EDA not defterlerimin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu da yeni baÅŸlayan tablo tabanlÄ± yarÄ±ÅŸmalardan karmaÅŸÄ±k iÃ§gÃ¶rÃ¼ler Ã§Ä±karmak Ã¼zerineydi. Bunu hÃ¢lÃ¢ Kaggleâ€™daki uzmanlÄ±k alanÄ±m olarak gÃ¶rÃ¼yorum ve not defterlerimin yapÄ±sÄ±nÄ±, veri gÃ¶rselleÅŸtirmelerini ve anlatÄ±m biÃ§imini tasarlamaya Ã§ok zaman harcadÄ±m.
> 
> 
> 
> ---
> 
> 
> 
> Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m gÃ¼nlÃ¼k iÅŸinde yaptÄ±klarÄ±ndan ne kadar farklÄ±?
> 
> 
> 
> Kaggle her ne kadar tablo tabanlÄ± yarÄ±ÅŸmalardan uzaklaÅŸmÄ±ÅŸ olsa da, ben hÃ¢lÃ¢ bir yarÄ±ÅŸmadaki en Ã¶nemli unsurun **verinin kendisi** olduÄŸuna inanÄ±yorum. Model mimarilerine ve hiperparametre ayarlamalarÄ±na fazla erken odaklanmak kolaydÄ±r. Ancak birÃ§ok yarÄ±ÅŸmada baÅŸarÄ±ya ulaÅŸmanÄ±n anahtarÄ±, verisetinin ayrÄ±ntÄ±lÄ± ÅŸekilde anlaÅŸÄ±lmasÄ±na dayanan veri merkezli bir yaklaÅŸÄ±mdÄ±r. Bu; gÃ¶rÃ¼ntÃ¼ verisi, NLP, zaman serisi ya da baÅŸka veri tÃ¼rleri iÃ§in de geÃ§erlidir.
> 
> Bu yÃ¼zden, her zaman kapsamlÄ± bir **EDA** ile baÅŸlarÄ±m; ardÄ±ndan basit bir temel model, bir Ã§apraz doÄŸrulama (CV) Ã§erÃ§evesi kurar ve bu yapÄ±nÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yavaÅŸ yavaÅŸ artÄ±rÄ±rÄ±m.
> 
> 
> 
> GÃ¼nlÃ¼k veri bilimi iÅŸimle en bÃ¼yÃ¼k fark muhtemelen ÅŸu: Deneyimli Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n, yeni bir yarÄ±ÅŸmanÄ±n ilk haftasÄ±nda kurduÄŸu temel modeller, endÃ¼stride Ã¼retime alÄ±nacak dÃ¼zeyde kabul edilir. Ã‡oÄŸu durumda, o ilk birkaÃ§ gÃ¼nÃ¼n sonunda nihai kazananÄ±n puanÄ±na %80 oranÄ±nda yaklaÅŸmÄ±ÅŸ oluruz.
> 
> Elbette Kaggleâ€™daki eÄŸlence ve zorluk, o son birkaÃ§ yÃ¼zde puanlÄ±k farkÄ± yaratacak yaratÄ±cÄ± yollar bulmaktÄ±r. Ancak bir ÅŸirkette, o zamanÄ± genellikle yeni bir projeye baÅŸlamak iÃ§in harcamak daha verimlidir.
> 
> 
> 
> ---
> 
> 
> 
> Kaggle kariyerine yardÄ±mcÄ± oldu mu? Olduysa nasÄ±l?
> 
> 
> 
> Kaggle kariyerimi olaÄŸanÃ¼stÃ¼ derecede ÅŸekillendirdi ve destekledi. Kaggle topluluÄŸundaki harika deneyimim beni akademiden endÃ¼striye geÃ§meye motive etti. Åu anda bir teknoloji giriÅŸiminde veri bilimci olarak Ã§alÄ±ÅŸÄ±yorum ve Kaggle yarÄ±ÅŸmalarÄ± aracÄ±lÄ±ÄŸÄ±yla becerilerimi sÃ¼rekli geliÅŸtiriyorum.
> 
> 
> 
> Benim durumumda, kapsamlÄ± Kaggle Notebooksâ€™larÄ± oluÅŸturma odaÄŸÄ±m Ã§ok faydalÄ± oldu; Ã§Ã¼nkÃ¼ bunlarÄ± kolayca **portfÃ¶yÃ¼m** olarak kullanabildim.
> 
> Bir iÅŸe alÄ±m yÃ¶neticisinin gerÃ§ekten bu kaynaklara ne kadar baktÄ±ÄŸÄ±nÄ± bilmiyorum ama sÄ±klÄ±kla â€œGrandmasterâ€ unvanÄ±mÄ±n, doktora (PhD) derecemden daha fazla kapÄ± aÃ§tÄ±ÄŸÄ± izlenimini edindim. Ya da belki ikisinin birleÅŸimi iÅŸe yaradÄ±.
> 
> Her durumda, herkese kamuya aÃ§Ä±k bir Notebooks portfÃ¶yÃ¼ne sahip olmayÄ± tavsiye ederim. AyrÄ±ca iÅŸ arayÄ±ÅŸÄ±m sÄ±rasÄ±nda, Kaggleâ€™da Ã¶ÄŸrendiÄŸim stratejileri ev Ã¶devi tarzÄ± deÄŸerlendirmelerde uyguladÄ±m ve bunlar bana Ã§ok yardÄ±mcÄ± oldu.
> 
> 
> 
> ---
> 
> 
> 
> Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ± ÅŸey nedir? BaÅŸlarken bilmediÄŸin ama ÅŸimdi bildiÄŸin bir ÅŸey var mÄ±?
> 
> 
> 
> Hepimiz sÃ¼rekli deneyim kazanÄ±yoruz. On yÄ±l, beÅŸ yÄ±l ya da bir yÄ±l Ã¶ncesine gÃ¶re hepimiz daha bilgeyiz.
> 
> Bunu bir kenara koyarsak, sÄ±klÄ±kla gÃ¶zden kaÃ§an en Ã¶nemli ÅŸeylerden biri, **ne yaptÄ±ÄŸÄ±nÄ±za dair bir planÄ±nÄ±zÄ±n olmasÄ±** ve bu planÄ± **uygulayÄ±p belgelemeniz** gerektiÄŸidir.
> 
> Yeni baÅŸlayan Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n bunu atlamasÄ± anlaÅŸÄ±lÄ±r bir durum, Ã§Ã¼nkÃ¼ her ÅŸey yeni, karmaÅŸÄ±k ve kafa karÄ±ÅŸtÄ±rÄ±cÄ±dÄ±r. Kaggleâ€™a ilk katÄ±ldÄ±ÄŸÄ±mda benim iÃ§in de Ã¶yleydi: forumlar, veri setleri, yarÄ±ÅŸmalar, kurslarâ€¦ Hepsi birbirine karÄ±ÅŸÄ±yordu.
> 
> Ve yarÄ±ÅŸmalar bazen gerÃ§ekten gÃ¶z korkutucu: *NÃ¶ronal HÃ¼cre Segmentasyonu*, *Borsa OynaklÄ±ÄŸÄ± Tahmini*â€¦ Bunlar ne ki?
> 
> Ama yarÄ±ÅŸmalar aynÄ± zamanda baÅŸlamanÄ±n da en iyi yoludur.
> 
> 
> 
> Bir yarÄ±ÅŸma baÅŸladÄ±ÄŸÄ±nda aslÄ±nda kimsenin tam bir fikri yoktur. Belki konuyla neredeyse aynÄ± konuda doktora yapmÄ±ÅŸ biri vardÄ±r ama bu nadirdir. Geri kalan herkes sÄ±fÄ±rdan baÅŸlar.
> 
> Veriyi inceleyerek, kayÄ±p fonksiyonlarÄ±yla oynayarak, basit baÅŸlangÄ±Ã§ modelleri Ã§alÄ±ÅŸtÄ±rarak Ã¶ÄŸrenirsiniz.
> 
> Bir yarÄ±ÅŸmaya en baÅŸÄ±nda katÄ±ldÄ±ÄŸÄ±nÄ±zda, bu Ã¶ÄŸrenme sÃ¼recini hÄ±zlandÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde, topluluÄŸun bir parÃ§asÄ± olarak yaÅŸarsÄ±nÄ±z. Topluluktaki diÄŸerleri size tonlarca fikir saÄŸlar. Ama yine de bir **planÄ±nÄ±zÄ±n** olmasÄ± gerekir.
> 
> 
> 
> Plan Ã¶nemlidir; Ã§Ã¼nkÃ¼ bazen sadece rastgele deneyler Ã§alÄ±ÅŸtÄ±rÄ±r, GPU belleÄŸinin dolduÄŸunu gÃ¶rÃ¼p mutlu olursunuz ama sonra en iyi modeli hangisiydi unutur, yerel doÄŸrulama ile lider tablosu arasÄ±nda korelasyon var mÄ±ydÄ± hatÄ±rlamazsÄ±nÄ±z.
> 
> Bu yÃ¼zden ne yapacaÄŸÄ±nÄ±zÄ± yazÄ±n ve sonuÃ§larÄ± kaydedin.
> 
> Bunun iÃ§in otomatik loglama araÃ§larÄ± giderek artÄ±yor ama basit bir Ã¶zel betik (script) ile de yapÄ±labilir.
> 
> 
> 
> Makine Ã¶ÄŸrenimi hÃ¢lÃ¢ bÃ¼yÃ¼k Ã¶lÃ§Ã¼de **deneysel bir bilimdir**, ve verimli deneylerin anahtarÄ± onlarÄ± iyi planlamak ve sonuÃ§larÄ± yazarak karÅŸÄ±laÅŸtÄ±rabilmektir.
> 
> 
> 
> ---
> 
> 
> 
> GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±n hatalar nelerdi?
> 
> 
> 
> BirÃ§ok hata yaptÄ±m ve onlardan ders Ã§Ä±karmayÄ± baÅŸardÄ±ÄŸÄ±mÄ± umuyorum.
> 
> SaÄŸlam bir **Ã§apraz doÄŸrulama (CV) Ã§erÃ§evesi** kurmamak bunlardan biriydi.
> 
> EÄŸitim ve test setleri arasÄ±ndaki farklarÄ± hesaba katmamak, Ã§ok fazla EDA yapÄ±p model kurulumunu ihmal etmek â€” bu ilk birkaÃ§ yarÄ±ÅŸmadaki â€œimza hatamâ€ olabilir.
> 
> Yeterince EDA yapmayÄ±p Ã¶nemli bir ÅŸeyi kaÃ§Ä±rmak â€” evet, onu da yaptÄ±m.
> 
> Finalde gÃ¶ndereceÄŸim iki modeli seÃ§meyi unutmak â€” Ã§ok fark yaratmadÄ± ama bir daha asla unutmam.
> 
> 
> 
> Ama hatalarla ilgili Ã¶nemli nokta ÅŸu: Deney ve plan konusundaki Ã¶nceki dÃ¼ÅŸÃ¼ncemle aynÄ±.
> 
> Hatalar **Ã¶ÄŸreniyorsanÄ±z** ve sizi geliÅŸtirmeye yardÄ±mcÄ± oluyorsa sorun deÄŸildir.
> 
> Tabii ki Ã¶ngÃ¶rÃ¼yle Ã¶nlenebilecek basit hatalardan kaÃ§Ä±nmak istersiniz.
> 
> Ama makine Ã¶ÄŸreniminde (ve bilimde!) baÅŸarÄ±sÄ±zlÄ±k sÃ¼recin bir parÃ§asÄ±dÄ±r.
> 
> Her ÅŸey her zaman iÅŸe yaramayacaktÄ±r â€” ve bu normaldir.
> 
> Ancak aynÄ± hatalarÄ± tekrar tekrar yapmak istemezsiniz.
> 
> DolayÄ±sÄ±yla gerÃ§ek hata, hatalarÄ±nÄ±zdan **ders almamaktÄ±r**.
> 
> Bu hem Kaggle yarÄ±ÅŸmalarÄ± hem de hayat iÃ§in geÃ§erlidir.
> 
> 
> 
> ---
> 
> 
> 
> Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸin araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?
> 
> 
> 
> Evet, gÃ¼nÃ¼mÃ¼zde giderek daha fazla **Python** kullanÄ±yoruz; ancak tablo verileriyle Ã§alÄ±ÅŸmak ve veri gÃ¶rselleÅŸtirmek sÃ¶z konusu olduÄŸunda hÃ¢lÃ¢ **R** ve **tidyverse** (Ã¶r. `dplyr`, `ggplot2`, `lubridate`) tercih ediyorum.
> 
> Yeni **tidymodels** Ã§erÃ§evesi de `sklearn`â€™e ciddi bir rakip.
> 
> SÄ±kÄ± bir Python hayranÄ± olsanÄ±z bile, zaman zaman `pandas` ve benzeri araÃ§larÄ±n Ã¶tesine bakmak faydalÄ±dÄ±r.
> 
> FarklÄ± araÃ§lar farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve daha fazla yaratÄ±cÄ±lÄ±k getirir.
> 
> 
> 
> Derin Ã¶ÄŸrenim aÃ§Ä±sÄ±ndan **PyTorch**â€™u en sezgisel buluyorum, Ã¶zellikle de **FastAI** arayÃ¼zÃ¼yle birlikte.
> 
> Ve tabii ki gÃ¼nÃ¼mÃ¼zde herkesin sevdiÄŸi **Hugging Face** â€” hem de Ã§ok haklÄ± sebeplerle.
> 
> 
> 
> ---
> 
> 
> 
> Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± veya yapÄ±lmasÄ± gereken en Ã¶nemli ÅŸey nedir?
> 
> 
> 
> En Ã¶nemlisi **eÄŸlenmek** ve **bir ÅŸeyler Ã¶ÄŸrenmek**.
> 
> Bir yarÄ±ÅŸma sÄ±rasÄ±nda ve sonrasÄ±nda paylaÅŸÄ±lan o kadar Ã§ok deÄŸerli bilgi ve deneyim var ki, bunlardan yararlanmamak bÃ¼yÃ¼k bir kayÄ±p olur.
> 
> Sadece kazanmak isteseniz bile, bunu ancak Ã¶ÄŸrenerek, deneyerek ve topluluÄŸun desteÄŸinden faydalanarak baÅŸarabilirsiniz.
> 
> Ama Kaggle, lider tablolarÄ±ndan Ã§ok daha fazlasÄ±dÄ±r; topluluÄŸa katkÄ± yapmaya baÅŸladÄ±ÄŸÄ±nÄ±zda, Ã§ok daha bÃ¼tÃ¼nsel bir ÅŸekilde geliÅŸirsiniz.
> 
> Buna garanti verebilirim.
> 
> 

### Kaggle Learn courses *(Kaggle Learn kurslarÄ±)*

Kaggle hakkÄ±nda pek Ã§ok ÅŸey bilgi edinme ile ilgilidir. Ä°ster bir yarÄ±ÅŸmada Ã¶ÄŸrendikleriniz, ister hÄ±zla bÃ¼yÃ¼yen veri seti deposunda bulduÄŸunuz veriler, isterse de henÃ¼z keÅŸfedilmemiÅŸ bir model sÄ±nÄ±fÄ±nÄ± gÃ¶steren bir ÅŸey olsun, her zaman Ã¶ÄŸrenilecek yeni bir ÅŸey vardÄ±r. Bu koleksiyona en yeni eklenen ÅŸey, Kaggle Learn etiketinde toplanan kurslardÄ±r: [https://www.kaggle.com/learn](https://www.kaggle.com/learn). Bu kurslar, Kaggle tarafÄ±ndan "baÄŸÄ±msÄ±z veri bilimi projeleri yapmanÄ±z iÃ§in gerekli becerileri kazanmanÄ±n en hÄ±zlÄ± yolu" olarak tanÄ±tÄ±lmaktadÄ±r; ana tema, Ã§eÅŸitli konularda hÄ±zlÄ± bir giriÅŸ kursu sunmaktÄ±r. Her kurs, kÃ¼Ã§Ã¼k bÃ¶lÃ¼mlere ayrÄ±lmÄ±ÅŸtÄ±r ve ardÄ±ndan kodlama uygulama sorularÄ± gelir. Kurslar, gerekli teori ve aÃ§Ä±klamalarÄ±n, kod yazÄ±p uygulamanÄ±z gereken kÄ±sÄ±mlarla iÃ§ iÃ§e geÃ§tiÄŸi Notebooks kullanÄ±larak sunulmaktadÄ±r.

AÅŸaÄŸÄ±da, en kullanÄ±ÅŸlÄ± olanlarÄ±nÄ±n kÄ±sa bir Ã¶zeti yer almaktadÄ±r:

â€¢ **Intro to ML / Intermediate ML**: [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning) ve [https://www.kaggle.com/learn/intermediate-machine-learning](https://www.kaggle.com/learn/intermediate-machine-learning)
Bu iki kurs, birbirini tamamlayan birer parÃ§a olarak gÃ¶rÃ¼lebilir: ilki, makine Ã¶ÄŸrenmesinde kullanÄ±lan farklÄ± model sÄ±nÄ±flarÄ±nÄ± tanÄ±tarak baÅŸlar ve ardÄ±ndan farklÄ± modeller iÃ§in ortak olan konularÄ± (aÅŸÄ±rÄ±/eksik Ã¶ÄŸrenme veya model doÄŸrulama gibi) tartÄ±ÅŸÄ±r. Ä°kincisi, Ã¶zellik mÃ¼hendisliÄŸine daha derinlemesine bir bakÄ±ÅŸ sunar, eksik deÄŸerlerle baÅŸa Ã§Ä±kma ve kategorik deÄŸiÅŸkenleri ele alma gibi konularÄ± iÅŸler. Makine Ã¶ÄŸrenmesine yeni baÅŸlayanlar iÃ§in faydalÄ±dÄ±r.

â€¢ **pandas**: [https://www.kaggle.com/learn/pandas](https://www.kaggle.com/learn/pandas)
Bu kurs, modern veri biliminin en temel araÃ§larÄ±ndan birine hÄ±zlÄ± bir giriÅŸ saÄŸlar. Ä°lk olarak veri oluÅŸturma, okuma ve yazma konularÄ±nÄ± Ã¶ÄŸrenirsiniz, ardÄ±ndan veri temizleme (indeksleme, seÃ§me, birleÅŸtirme, gruplama vb.) Ã¼zerine Ã§alÄ±ÅŸÄ±rsÄ±nÄ±z. Hem yeni baÅŸlayanlar (pandas'Ä±n fonksiyonelliÄŸi zaman zaman bunaltÄ±cÄ± olabilir) hem de uygulayÄ±cÄ±lar (yeniden gÃ¶zden geÃ§irme/referans olarak) iÃ§in faydalÄ±dÄ±r.

â€¢ **Game AI**: [https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning)
Bu kurs, Kaggleâ€™Ä±n Ã¶ÄŸrenme modÃ¼llerinde sunulan teknoloji odaklÄ± kÄ±smÄ±n gÃ¼zel bir tamamlayÄ±cÄ±sÄ±dÄ±r. Bir oyun oynama ajanÄ± yazacak, performansÄ±nÄ± inceleyecek ve minimax algoritmasÄ±nÄ± kullanacaksÄ±nÄ±z. Bu kurs, muhtemelen pekiÅŸtirmeli Ã¶ÄŸrenmeye yÃ¶nelik bir uygulamalÄ± tanÄ±tÄ±m olarak gÃ¶rÃ¼lmelidir.

â€¢ **Machine Learning Explainability**: [https://www.kaggle.com/learn/machine-learning-explainability](https://www.kaggle.com/learn/machine-learning-explainability)
Modeller oluÅŸturmak eÄŸlenceli olabilir, ancak gerÃ§ek dÃ¼nyada herkes veri bilimcisi deÄŸildir, bu yÃ¼zden yaptÄ±klarÄ±nÄ±zÄ± baÅŸkalarÄ±na aÃ§Ä±klamanÄ±z gereken bir durumda olabilirsiniz. Ä°ÅŸte bu noktada model aÃ§Ä±klanabilirliÄŸi Ã¼zerine olan bu mini kurs devreye giriyor: Ã¼Ã§ farklÄ± yÃ¶ntemle (permutasyon Ã¶nemi, SHAP ve kÄ±smi baÄŸÄ±mlÄ±lÄ±k grafikleri) Ã¶zelliklerinizi nasÄ±l deÄŸerlendireceÄŸinizi Ã¶ÄŸrenirsiniz. Ã–zellikle ticari bir ortamda ML ile Ã§alÄ±ÅŸan herkes iÃ§in son derece faydalÄ±dÄ±r; burada projeler, mesajÄ±n ne kadar iyi iletildiÄŸine baÄŸlÄ± olarak varlÄ±klarÄ±nÄ± sÃ¼rdÃ¼rebilir.

â€¢ **AI Ethics**: [https://www.kaggle.com/learn/intro-to-ai-ethics](https://www.kaggle.com/learn/intro-to-ai-ethics)
Bu son kurs, sunumun oldukÃ§a ilginÃ§ bir eklemesi olarak karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor: AI sistemlerinin ahlaki tasarÄ±mÄ±na rehberlik edecek pratik araÃ§larÄ± tartÄ±ÅŸmaktadÄ±r. AI modellerindeki Ã¶nyargÄ±yÄ± nasÄ±l tanÄ±yacaÄŸÄ±nÄ±zÄ±, AI adaleti kavramÄ±nÄ± incelemenizi ve ML model bilgilerini nasÄ±l ileterek ÅŸeffaflÄ±ÄŸÄ± artÄ±racaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenirsiniz. UygulayÄ±cÄ±lar iÃ§in Ã§ok faydalÄ±dÄ±r, Ã§Ã¼nkÃ¼ "sorumlu yapay zeka" artÄ±k daha sÄ±k duyacaÄŸÄ±mÄ±z bir kavram olacaktÄ±r.

Kaggle tarafÄ±ndan oluÅŸturulan orijinal iÃ§eriÄŸin dÄ±ÅŸÄ±nda, platformda kullanÄ±cÄ±lar tarafÄ±ndan oluÅŸturulmuÅŸ Notebooks aracÄ±lÄ±ÄŸÄ±yla baÅŸka Ã¶ÄŸrenme fÄ±rsatlarÄ± da bulunmaktadÄ±r; okuyucularÄ±n bunlarÄ± kendi baÅŸlarÄ±na keÅŸfetmeleri teÅŸvik edilir.

> **Andrada Olteanu**
> 
> [https://www.kaggle.com/andradaolteanu](https://www.kaggle.com/andradaolteanu)
> 
> Andrada Olteanu, Kaggle Notebooks Grandmaster'larÄ±ndan biridir ve Notebooks'tan Ã¶ÄŸrenmeyi Ã§ok teÅŸvik etmektedir. Andrada, Z by HP Global Data Science Ambassador, Endava'da Veri Bilimci ve Weights & Biases'ta Dev Expert olarak gÃ¶rev yapmaktadÄ±r. Andrada ile Notebook yarÄ±ÅŸmalarÄ±, kariyeri ve daha fazlasÄ± hakkÄ±nda sohbet ettik.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Kaggle'da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Kaggle'daki uzmanlÄ±ÄŸÄ±m, verileri gÃ¶rselleÅŸtirme konusunda yoÄŸunlaÅŸÄ±yor, Ã§Ã¼nkÃ¼ bu alan bana sanatÄ± ve yaratÄ±cÄ±lÄ±ÄŸÄ± verilerle birleÅŸtirme imkanÄ± veriyor.
> 
> Kesinlikle favori bir yarÄ±ÅŸma tÃ¼rÃ¼m yok, ama daha Ã§ok zaman zaman deÄŸiÅŸim yapmak ve ilginÃ§ bulduÄŸum yarÄ±ÅŸmalarÄ± seÃ§mek hoÅŸuma gidiyor.
> 
> Kaggleâ€™Ä±n gÃ¼zelliÄŸi, bir kiÅŸinin Veri Biliminin birÃ§ok alanÄ±nÄ± (bilgisayarla gÃ¶rme, NLP, keÅŸifsel veri analizi ve istatistik, zaman serileri vb.) Ã¶ÄŸrenebilmesinin yanÄ± sÄ±ra birÃ§ok konuya (spor, tÄ±p, finans ve kripto paralar, dÃ¼nya Ã§apÄ±ndaki olaylar vb.) da aÅŸina olma fÄ±rsatÄ± sunmasÄ±dÄ±r.
> 
> AyrÄ±ca, Ã¶rneÄŸin metin verileriyle daha fazla deneyim kazanmak isteyen biri iÃ§in, neredeyse her zaman bir Kaggle YarÄ±ÅŸmasÄ±'nda NLP gereksinimi vardÄ±r. Ya da ses dosyalarÄ±yla nasÄ±l Ã¶n iÅŸleme yapÄ±lacaÄŸÄ± ve modellerin nasÄ±l kurulacaÄŸÄ± Ã¶ÄŸrenmek isteyen biri iÃ§in de bu beceriyi geliÅŸtirecek yarÄ±ÅŸmalar bulunabilir.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlu bir yarÄ±ÅŸmadan ve gÃ¶revi ele almak iÃ§in kullandÄ±ÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼lerden bahseder misiniz?**
> 
> KatÄ±ldÄ±ÄŸÄ±m en zorlu â€œyarÄ±ÅŸmaâ€ Kaggleâ€™Ä±n â€œVeri Bilimi ve Makine Ã–ÄŸrenimi YÄ±llÄ±k Anketiâ€ydi. Bu bir â€œgerÃ§ekâ€ yarÄ±ÅŸma deÄŸil â€“ yani bir liderlik tablosu ve aÄŸÄ±r makine Ã¶ÄŸrenimi gerekmiyor â€“ ancak benim iÃ§in katÄ±ldÄ±ÄŸÄ±m ve en Ã§ok ÅŸey Ã¶ÄŸrendiÄŸim yarÄ±ÅŸmalardan biriydi.
> 
> Bu bir Notebook yarÄ±ÅŸmasÄ±dÄ±r ve katÄ±lÄ±mcÄ±larÄ±n kazanmak iÃ§in yaratÄ±cÄ± olmalarÄ± gerekmektedir. Bu yarÄ±ÅŸmaya 2 yÄ±l Ã¼st Ã¼ste katÄ±ldÄ±m. Ä°lk yÄ±l (2020), daha â€œtemelâ€ gÃ¶rselleÅŸtirme becerilerimi test etti ve bana kutunun dÄ±ÅŸÄ±na Ã§Ä±kmamÄ± saÄŸladÄ± (3. oldum); ikinci yÄ±l (2021), 4 ay boyunca D3 Ã¶ÄŸrenerek bu alandaki gÃ¶rselleÅŸtirme becerilerimi bir Ã¼st seviyeye Ã§Ä±karmayÄ± hedefledim (hala incelemede; ÅŸu ana kadar â€œErken Notebook Ã–dÃ¼lÃ¼â€nÃ¼ kazandÄ±m). Burada verebileceÄŸim en iyi iÃ§gÃ¶rÃ¼ler ÅŸunlar:
> 
> â€¢ Ã–ncelikle veriye kaybolmayÄ±n ve olabildiÄŸince doÄŸru grafikler oluÅŸturmaya Ã§alÄ±ÅŸÄ±n; gerekirse, neyi temsil ettiÄŸinizin net ve Ã¶z olduÄŸundan emin olmak iÃ§in Ã§ift doÄŸrulama yÃ¶ntemleri oluÅŸturun. GÃ¼zel bir grafiÄŸin yanÄ±ltÄ±cÄ± iÃ§gÃ¶rÃ¼ler sunduÄŸu bir ÅŸeyden daha kÃ¶tÃ¼ bir ÅŸey yoktur.
> 
> â€¢ Ã‡evrenizde ilham kaynaÄŸÄ± arayÄ±n: doÄŸadan, filmlerden, iÅŸinizden. GÃ¶rselleÅŸtirmelerinizi canlandÄ±rmak iÃ§in harika temalar ve ilginÃ§ yollar bulabilirsiniz.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? YardÄ±mcÄ± olduysa nasÄ±l?**
> 
> Evet. MÃ¼him Ã¶lÃ§Ã¼de. Åu anda bulunduÄŸum noktada Kaggle'a bÃ¼yÃ¼k bir borcum olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum ve bunun iÃ§in sonsuza dek minnettarÄ±m. Kaggle sayesinde Z by HP Ambassador'Ä± oldum; ayrÄ±ca harika bir makine Ã¶ÄŸrenimi deney platformu olan Weights & Biases'Ä± keÅŸfettim ve ÅŸu anda onlarÄ±n gururlu bir Dev Expert'Ä±yÄ±m. Son olarak, bu platform sayesinde ÅŸu anda Endava'da Lead Data Scientist olarak gÃ¶rev yapan kiÅŸiyle tanÄ±ÅŸtÄ±m, o beni iÅŸe aldÄ± ve o zamandan beri onunla Ã§alÄ±ÅŸÄ±yorum. KÄ±sacasÄ±, Endava'daki pozisyonum ve HP ile Weights & Biases gibi 2 bÃ¼yÃ¼k ÅŸirketle olan baÄŸlantÄ±larÄ±m, Kaggle platformundaki faaliyetlerimin doÄŸrudan bir sonucu.
> 
> Bence Kaggle'Ä±n en gÃ¶zden kaÃ§an yÃ¶nÃ¼, topluluktur. Kaggle, birbirleriyle baÄŸlantÄ± kurup etkileÅŸimde bulunabilecek ve birbirlerinden Ã¶ÄŸrenebilecek dev bir insan havuzuna sahiptir.
> 
> Bunun en iyi ÅŸekilde nasÄ±l deÄŸerlendirileceÄŸiyle ilgili bir Ã¶rnek: Kaggleâ€™daki her bÃ¶lÃ¼mden (YarÄ±ÅŸmalar, Veri Setleri, Notebooks â€“ ve eÄŸer isterseniz, TartÄ±ÅŸmalar) ilk 100 kiÅŸiyi alÄ±n ve profilinde bu bilgiyi paylaÅŸan herkesin Twitter/LinkedIn hesaplarÄ±nÄ± takip edin. Bu ÅŸekilde, bu harika insanlarla dÃ¼zenli olarak etkileÅŸimde bulunabilir, iÃ§gÃ¶rÃ¼ ve bilgilerinden faydalanabilirsiniz.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±m en bÃ¼yÃ¼k hata, onlara katÄ±lmamaktÄ±. Bence bu, baÅŸlangÄ±Ã§ seviyesindeki kullanÄ±cÄ±larÄ±n platforma girdiÄŸinde yaptÄ±klarÄ± en bÃ¼yÃ¼k ve en temel hatadÄ±r.
> 
> Korku nedeniyle (ve burada kiÅŸisel deneyimimden konuÅŸuyorum), hazÄ±r olmadÄ±klarÄ±nÄ± veya nasÄ±l baÅŸlayacaklarÄ±nÄ± bilmediklerini dÃ¼ÅŸÃ¼nÃ¼yorlar. Neyse ki, basit bir sistem takip ederseniz, herhangi bir yarÄ±ÅŸmaya katÄ±lmak oldukÃ§a kolay hale gelir:
> 
> â€¢ Ä°lginizi Ã§eken herhangi bir yarÄ±ÅŸmaya katÄ±lÄ±n.
> 
> â€¢ TanÄ±tÄ±m sayfasÄ±nÄ± ve verileri keÅŸfedin.
> 
> â€¢ BaÅŸlamak iÃ§in fikriniz yoksa, endiÅŸelenmeyin! â€œKodâ€ kÄ±smÄ±na girin ve Ã§ok fazla oy almÄ±ÅŸ, ya da deneyimli kiÅŸiler tarafÄ±ndan yapÄ±lmÄ±ÅŸ Notebooks'larÄ± inceleyin, Ã¶rneÄŸin Grandmasters.
> 
> Bir â€œkodla birlikte Ã§alÄ±ÅŸâ€ Notebookâ€™u yapmaya baÅŸlayÄ±n, burada baÅŸkalarÄ±nÄ±n ne yaptÄ±ÄŸÄ±nÄ± inceleyin ve â€œkopyalayÄ±n,â€ araÅŸtÄ±rÄ±n ve kendiniz geliÅŸtirmeye Ã§alÄ±ÅŸÄ±n. Bence bu, Ã¶ÄŸrenmenin en iyi yoludur â€“ hiÃ§ takÄ±lmazsÄ±nÄ±z ve belirli bir projede yaparak Ã¶ÄŸrenirsiniz.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> UnutulmamasÄ± gereken en Ã¶nemli ÅŸey, baÅŸarÄ±sÄ±z olmanÄ±n tamamen normal olduÄŸudur, Ã§Ã¼nkÃ¼ genellikle en iyi Ã¶ÄŸrenme yolu budur.
> 
> AyrÄ±ca her zaman YarÄ±ÅŸma Grandmastersâ€™larÄ±ndan Ã¶ÄŸrenmeyi unutmamalÄ±dÄ±rlar, Ã§Ã¼nkÃ¼ genellikle, bir kiÅŸinin aklÄ±na gelmeyecek makine Ã¶ÄŸrenimi tekniklerini paylaÅŸan ve aÃ§Ä±klayan kiÅŸilerdir. Bir ÅŸeyi Ã¶ÄŸrenmenin en iyi yolu, zaten â€œbaÅŸarÄ±sÄ±nÄ±â€ kanÄ±tlamÄ±ÅŸ olanlarÄ± incelemektir, bÃ¶ylece baÅŸarÄ± yolunuz daha az engebeli, daha rahat, pÃ¼rÃ¼zsÃ¼z ve hÄ±zlÄ± olur. GerÃ§ekten hayran olduÄŸunuz 2-3 Grandmasterâ€™Ä± seÃ§in ve onlarÄ± Ã¶ÄŸretmenleriniz yapÄ±n; onlarÄ±n Notebooksâ€™larÄ±nÄ± inceleyin, birlikte kod yazÄ±n ve olabildiÄŸince Ã§ok ÅŸey Ã¶ÄŸrenin.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musunuz? Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±rsÄ±nÄ±z?**
> 
> HiÃ§ baÅŸka bir yarÄ±ÅŸma platformu kullanmadÄ±m â€“ Ã§Ã¼nkÃ¼ bence Kaggle her ÅŸeyi sunuyor.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, eÄŸitim ve deney yapma amacÄ±yla kullanÄ±labilen, ayrÄ±ca veri bilimi proje portfÃ¶yÃ¼nÃ¼zÃ¼ tanÄ±tmak iÃ§in de kullanÄ±labilen Ã§ok amaÃ§lÄ±, aÃ§Ä±k kodlama ortamlarÄ± olan Kaggle Notebooks'tan bahsettik. ArtÄ±k kendi Notebook'unuzu oluÅŸturma, mevcut kaynaklarÄ± verimli bir ÅŸekilde kullanma ve sonuÃ§larÄ± yarÄ±ÅŸmalar veya bireysel projeleriniz iÃ§in kullanma aÅŸamasÄ±na geldiniz.

Bir sonraki bÃ¶lÃ¼mde, Kaggle'da fikir ve gÃ¶rÃ¼ÅŸlerinizi paylaÅŸmanÄ±n birincil yolu olan tartÄ±ÅŸma forumlarÄ±nÄ± tanÄ±tacaÄŸÄ±z.

---

## Chapter 4: Leveraging Discussion Forums *(BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±nÄ± Etkin Kullanma)*

TartÄ±ÅŸma forumlarÄ±, Kaggle'daki bilgi alÄ±ÅŸveriÅŸinin birincil aracÄ±dÄ±r. Ä°ster devam eden bir yarÄ±ÅŸmayÄ± tartÄ±ÅŸmak, ister bir Veri Seti hakkÄ±nda konuÅŸmak, isterse yeni bir yaklaÅŸÄ±m sunan bir Notebook'u ele almak olsun, Kaggle kullanÄ±cÄ±larÄ± her zaman bir ÅŸeyler hakkÄ±nda konuÅŸurlar.

Bu bÃ¶lÃ¼mde, tartÄ±ÅŸma forumlarÄ±nÄ± tanÄ±tÄ±yoruz: nasÄ±l organize olduklarÄ±nÄ± ve iÃ§indeki bilgilerin nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± dÃ¼zenleyen davranÄ±ÅŸ kurallarÄ±nÄ±. AÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:
â€¢ ForumlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±
â€¢ Ã–rnek yarÄ±ÅŸmalar iÃ§in tartÄ±ÅŸma yaklaÅŸÄ±mlarÄ±
â€¢ Ä°nternette uygun davranÄ±ÅŸ (Netik)

### How forums work *(Forumlar nasÄ±l Ã§alÄ±ÅŸÄ±r)*

TartÄ±ÅŸma forumuna birkaÃ§ farklÄ± ÅŸekilde girebilirsiniz. En doÄŸrudan yol, sol paneldeki **TartÄ±ÅŸmalar** sekmesine tÄ±klamaktÄ±r:

![](im/1034.png)

Ãœst kÄ±sÄ±mda, genel konularÄ±n bir araya getirildiÄŸi **Forumlar** bulunur. Bunlara gÃ¶z atmak, ister ilk yarÄ±ÅŸmanÄ±za katÄ±lÄ±yor olun, ister bir Ã¶neriniz olsun, ister sadece kafanÄ±z karÄ±ÅŸtÄ±ÄŸÄ± iÃ§in genel bir soru sormak isteyin, oldukÃ§a faydalÄ±dÄ±r.

ForumlarÄ±n altÄ±nda, **Kaggle genelinde yapÄ±lan tartÄ±ÅŸmalarÄ±n birleÅŸik gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼** bulabilirsiniz. Bunlar Ã§oÄŸunlukla yarÄ±ÅŸmalarla ilgili sohbetlerdir (Ã§Ã¼nkÃ¼ Kaggleâ€™daki etkinliÄŸin bÃ¼yÃ¼k kÄ±smÄ±nÄ± yarÄ±ÅŸmalar oluÅŸturur), ancak bazen Notebooks (defterler) veya dikkat Ã§ekici veri kÃ¼meleriyle ilgili konuÅŸmalar da yer alÄ±r. VarsayÄ±lan olarak bu tartÄ±ÅŸmalar **"Hotness" (PopÃ¼lerlik)** sÄ±rasÄ±na gÃ¶re listelenir; yani katÄ±lÄ±mÄ± en yÃ¼ksek ve en aktif olanlar Ã¼st sÄ±ralarda gÃ¶rÃ¼nÃ¼r.

Bu bÃ¶lÃ¼m, alanÄ±n dinamik doÄŸasÄ±na daha uygun iÃ§erikleri bulabileceÄŸiniz yerdir: Kaggleâ€™Ä±n farklÄ± alt bÃ¶lÃ¼mlerinden gelen tartÄ±ÅŸmalarÄ±n bir koleksiyonu olup, belirli Ã¶lÃ§Ã¼tlere gÃ¶re **filtreleme yapma** olanaÄŸÄ± da sunar.

![](im/1035.png)

Ä°lgi alanlarÄ±nÄ±za baÄŸlÄ± olarak, iÃ§erikleri **filtreleri kullanarak kiÅŸiselleÅŸtirmeye** baÅŸlayabilirsiniz. Tercihlerinize gÃ¶re ÅŸu Ã¶lÃ§Ã¼tlere gÃ¶re filtreleme yapabilirsiniz:

â€¢ **RECENCY (GÃ¼ncellik):** Takip ettiÄŸiniz bilgilerin zaman aralÄ±ÄŸÄ±nÄ± kontrol etmenizi saÄŸlar.
â€¢ **MY ACTIVITY (Benim EtkinliÄŸim):** TÃ¼m forumlardaki yorumlarÄ±nÄ±zÄ±n, paylaÅŸÄ±mlarÄ±nÄ±zÄ±n ve gÃ¶rÃ¼ntÃ¼lemelerinizin genel bir Ã¶zetini verir; birden fazla tartÄ±ÅŸmaya aynÄ± anda katÄ±lÄ±yorsanÄ±z oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r.
â€¢ **ADMIN (YÃ¶netici):** Kaggle yÃ¶neticilerinin duyurularÄ±na hÄ±zlÄ± bir genel bakÄ±ÅŸ saÄŸlar.
â€¢ **TYPES (TÃ¼rler):** TartÄ±ÅŸmalar genel forumlarda, belirli yarÄ±ÅŸmalarda veya veri kÃ¼meleri etrafÄ±nda gerÃ§ekleÅŸebilir.
â€¢ **TAGS (Etiketler):** Her yerde bulunmasa da birÃ§ok tartÄ±ÅŸma etiketlenmiÅŸtir; bu iÅŸlev, kullanÄ±cÄ±larÄ±n bu Ã¶zelliÄŸi kullanarak belirli konulara gÃ¶re filtreleme yapmasÄ±na olanak tanÄ±r.

![](im/1036.png)

AÅŸaÄŸÄ±daki ÅŸekil, **Beginner (Yeni BaÅŸlayan)** etiketiyle filtrelenmiÅŸ tartÄ±ÅŸmalarÄ±n Ã¶rnek bir Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶stermektedir.

![](im/1037.png)

Alternatif olarak, belirli bir konuya da odaklanabilirsiniz; Ã¶rneÄŸin **bilgisayarla gÃ¶rme (computer vision)** gibi konular bÃ¼yÃ¼k ilgi Ã§ektiÄŸinden, konularÄ± **sÄ±ralamak** faydalÄ± olabilir. KonularÄ± ÅŸu Ã¶lÃ§Ã¼tlere gÃ¶re sÄ±ralayabilirsiniz:

* **Hotness (PopÃ¼lerlik):** En fazla ilgi ve katÄ±lÄ±m gÃ¶ren konular Ã¼stte gÃ¶sterilir.
* **Recent Comments (Son Yorumlar):** En son yorum yapÄ±lan konulara gÃ¶re sÄ±ralar.
* **Recently Posted (Yeni PaylaÅŸÄ±lanlar):** YakÄ±n zamanda oluÅŸturulan konulara Ã¶ncelik verir.
* **Most Votes (En Ã‡ok Oy Alanlar):** En fazla oyu almÄ±ÅŸ konularÄ± Ã¼stte gÃ¶sterir.
* **Most Comments (En Ã‡ok Yorum Alanlar):** En fazla yorum yapÄ±lan konularÄ± sÄ±ralar.

![](im/1038.png)

Ä°nsanlar **Kaggleâ€™a** farklÄ± nedenlerle gelirler; ancak **Notebooks**â€™larÄ±n popÃ¼laritesinin artmasÄ±na raÄŸmen, **yarÄ±ÅŸmalar** hÃ¢lÃ¢ temel Ã§ekim noktasÄ± olmaya devam etmektedir. Her Kaggle yarÄ±ÅŸmasÄ±nÄ±n kendine ait Ã¶zel bir **tartÄ±ÅŸma forumu** vardÄ±r. Bu foruma, yarÄ±ÅŸmanÄ±n sayfasÄ±na gidip **Discussion (TartÄ±ÅŸma)** sekmesini seÃ§erek eriÅŸebilirsiniz.

![](im/1039.png)

Eskiden bu her zaman bÃ¶yle deÄŸildi, ancak gÃ¼nÃ¼mÃ¼zde neredeyse tÃ¼m yarÄ±ÅŸmalarÄ±n, kendilerine ait tartÄ±ÅŸma forumlarÄ±nÄ±n en Ã¼st kÄ±smÄ±na sabitlenmiÅŸ bir **SSS (SÄ±kÃ§a Sorulan Sorular)** konusu bulunmaktadÄ±r. Bu bÃ¶lÃ¼mden baÅŸlamak iki temel nedenle iyi bir fikirdir:

â€¢ **Zamandan tasarruf edersiniz;** en popÃ¼ler sorularÄ±n yanÄ±tlarÄ± bÃ¼yÃ¼k olasÄ±lÄ±kla burada yer alÄ±r.
â€¢ **Gereksiz veya yinelenen sorular sormaktan kaÃ§Ä±nÄ±rsÄ±nÄ±z,** bÃ¶ylece forumdaki herkes iÃ§in daha iyi bir deneyim saÄŸlanmÄ±ÅŸ olur.

**Notebooks**â€™larda olduÄŸu gibi, tartÄ±ÅŸma forumlarÄ±nda da daha sonra tekrar bakmak Ã¼zere **Ã¶zellikle Ã¶nemli konularÄ± yer imlerine ekleme (bookmark)** seÃ§eneÄŸi bulunur.

![](im/1040.png)

Yer iÅŸareti eklediÄŸiniz (bookmarkladÄ±ÄŸÄ±nÄ±z) tÃ¼m konularÄ±n genel bir Ã¶zetini, **profil sayfanÄ±zda** bulabilirsiniz.

![](im/1041.png)

### Example discussion approaches *(TartÄ±ÅŸma Ã¶rnekleri ve yaklaÅŸÄ±mlar)*

Bir yarÄ±ÅŸmada kendinizi bir noktada kaybolmuÅŸ hissetmeniz tamamen normaldir: Geldiniz, birkaÃ§ fikir denediniz, sÄ±ralamada bir ilerleme kaydettiniz ve sonra Kaggle versiyonu ile koÅŸucularÄ±n duvarÄ±na Ã§arptÄ±nÄ±z. Ä°ÅŸte bu noktada tartÄ±ÅŸma forumlarÄ± baÅŸvurulacak yerdir.

Ã–rnek olarak, Optiver Realized Volatility Prediction yarÄ±ÅŸmasÄ±na bakalÄ±m ([https://www.kaggle.com/c/optiver-realized-volatility-prediction](https://www.kaggle.com/c/optiver-realized-volatility-prediction)). Organizasyon tarafÄ±ndan ÅŸÃ¶yle tanÄ±mlanmÄ±ÅŸ:

> Ä°lk Ã¼Ã§ ay boyunca, farklÄ± sektÃ¶rlerde yÃ¼zlerce hisse senedi iÃ§in kÄ±sa vadeli volatiliteyi tahmin eden modeller geliÅŸtireceksiniz. Elinizde yÃ¼z milyonlarca detaylÄ± finansal veri olacak ve bu verilerle 10 dakikalÄ±k periyotlar iÃ§in volatiliteyi tahmin eden bir model tasarlayacaksÄ±nÄ±z. Modelleriniz, eÄŸitim sonrasÄ± Ã¼Ã§ aylÄ±k deÄŸerlendirme dÃ¶neminde gerÃ§ek piyasa verileriyle karÅŸÄ±laÅŸtÄ±rÄ±larak deÄŸerlendirilecektir.

Burada ele alÄ±nacak Ã§ok ÅŸey var; bu yÃ¼zden bu zorluÄŸun ana bileÅŸenlerini inceleyip, tartÄ±ÅŸma forumlarÄ± aracÄ±lÄ±ÄŸÄ±yla nasÄ±l yaklaÅŸÄ±labileceÄŸini gÃ¶stereceÄŸiz. Ã–ncelikle, bu yarÄ±ÅŸmaya katÄ±lÄ±m belirli bir finansal bilgi gerektiriyor; belki deneyimli bir trader seviyesinde olmanÄ±z gerekmiyor, ama volatilitenin farklÄ± hesaplama yÃ¶ntemlerini anlamak, Ã§oÄŸu Kaggle katÄ±lÄ±mcÄ±sÄ± iÃ§in oldukÃ§a karmaÅŸÄ±ktÄ±r. Neyse ki organizatÃ¶rler yarÄ±ÅŸma boyunca oldukÃ§a aktifti ve yeni baÅŸlayanlar iÃ§in kaynaklar sundular: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273923](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273923)

EÄŸer baÅŸlangÄ±Ã§ bilgisi yeterli deÄŸilse, kamuya aÃ§Ä±k ÅŸekilde sorularÄ±nÄ±zÄ± sormaktan Ã§ekinmeyin, Ã¶rneÄŸin:
[https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/263039](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/263039)
veya
[https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250612](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250612)

YarÄ±ÅŸma ilerledikÃ§e, katÄ±lÄ±mcÄ±lar problemi Ã§Ã¶zmek iÃ§in giderek daha sofistike modeller geliÅŸtirmeye baÅŸladÄ±lar. Burada bir denge kurmak gerekiyor: bir yandan, veteriner katÄ±lÄ±mcÄ±lardan Ã¶ÄŸrendiklerinizi paylaÅŸarak geri vermek isteyebilirsiniz; diÄŸer yandan, tÃ¼m harika kodlarÄ±nÄ±zÄ± Notebook olarak paylaÅŸarak potansiyel avantajÄ±nÄ±zÄ± kaybetmek istemezsiniz. Makul bir orta yol, Ã¶rneÄŸin forumda Ã¶zellik fikirlerinizi paylaÅŸmak olabilir: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273915](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273915)

Son yÄ±llarda, daha fazla yarÄ±ÅŸma sabit test veri seti formatÄ±ndan uzaklaÅŸÄ±p farklÄ± yaklaÅŸÄ±mlar getirdi: bazÄ±larÄ± Kaggle API kullanÄ±mÄ±nÄ± zorunlu kÄ±lÄ±yor (Notebook Ã¼zerinden gÃ¶nderim yapmanÄ±z gerekiyor), bazÄ±larÄ± ise eÄŸitim ve canlÄ± veri deÄŸerlendirmesi olarak Ã¶zel bir zaman Ã§izelgesi sunuyor. Optiver yarÄ±ÅŸmasÄ± da bÃ¶yleydi:

> Final gÃ¶nderim tarihinden sonra, seÃ§ilen notebookâ€™lar Ã¼zerinde piyasa verisi gÃ¼ncellemelerine baÄŸlÄ± olarak sÄ±ralama tablosu periyodik olarak gÃ¼ncellenecektir. GÃ¼ncellemeler yaklaÅŸÄ±k iki haftada bir yapÄ±lacak ve tatil dÃ¶nemlerinden kaÃ§Ä±nmak iÃ§in ayarlamalar yapÄ±lacaktÄ±r.

Bu kurulum, modellerin yeniden eÄŸitilmesi ve gÃ¼ncellenmesi konusunda bazÄ± zorluklar yarattÄ±. Bu tÃ¼r bir durumla karÅŸÄ±laÅŸÄ±rsanÄ±z, katÄ±lÄ±mcÄ±larÄ±n yaptÄ±ÄŸÄ± gibi sorular sormaktan Ã§ekinmeyin: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/249752](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/249752)

EÄŸitilen modeliniz iÃ§in bir doÄŸrulama ÅŸemasÄ± her zaman Ã¶nemli bir konudur ve genellikle â€œCV vs LBâ€ (Ã§apraz doÄŸrulama vs sÄ±ralama tablosu) tartÄ±ÅŸmasÄ± ile baÄŸlantÄ±lÄ±dÄ±r. Optiver yarÄ±ÅŸmasÄ± da bu kuralÄ±n istisnasÄ± deÄŸildi: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250650](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250650)

EÄŸer ilgili baÅŸlÄ±k zaten yoksa â€“ ve bunu kontrol etmek her zaman iyi bir fikirdir â€“ tek model performansÄ±yla ilgili bir baÅŸlÄ±ÄŸÄ± dÃ¼ÅŸÃ¼nmek isteyebilirsiniz. Er ya da geÃ§ herkes model ansambllarÄ±nÄ± kullanmaya baÅŸlar, ancak iyi tek model bileÅŸenleri olmadan bunlar Ã§ok verimli deÄŸildir.

EÄŸer problemi Ã§Ã¶zmenin daha iyi bir yolunu bulduysanÄ±z, paylaÅŸmak genellikle iyi bir fikirdir. Ya baÅŸkalarÄ± iÃ§in faydalÄ± bir ÅŸey yapmÄ±ÅŸ olursunuz, ya da neden yanlÄ±ÅŸ olduÄŸunuzu Ã¶ÄŸrenirsiniz (zaman ve Ã§aba tasarrufu saÄŸlar); her iki durumda da kazanÃ§lÄ± Ã§Ä±karsÄ±nÄ±z: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/260694](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/260694)

Bunun dÄ±ÅŸÄ±nda, diÄŸer katÄ±lÄ±mcÄ±larÄ±n ne yaptÄ±ÄŸÄ±na gÃ¶z atmak ve topluluk iÃ§inde bilgi paylaÅŸÄ±mÄ±na katkÄ±da bulunmak kiÅŸisel fayda saÄŸlar ve Ã¶zellikle yeni baÅŸlayanlar iÃ§in yararlÄ±dÄ±r: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250695](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250695)

TÃ¼m bu konulara gÃ¶z attÄ±ysanÄ±z, hÃ¢lÃ¢ â€œÃ–nemli bir ÅŸeyi mi kaÃ§Ä±rÄ±yorum?â€ diye dÃ¼ÅŸÃ¼nebilirsiniz. Kaggle, bu tÃ¼r sorularÄ± sormanÄ±n tamamen kabul edildiÄŸi bir platformdur: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/262203](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/262203)

DiÄŸer yarÄ±ÅŸmalara gÃ¶z atalÄ±m. Daha Ã¶nce doÄŸrulama konusundan bahsettik; bu genellikle bilgi sÄ±zÄ±ntÄ±sÄ± ve aÅŸÄ±rÄ± uyum (overfitting) ile baÄŸlantÄ±lÄ±dÄ±r. SÄ±zÄ±ntÄ±lar, doÄŸrulama ÅŸemalarÄ±nÄ±n tasarlanmasÄ±na ayrÄ±lmÄ±ÅŸ olan 6. bÃ¶lÃ¼mde ayrÄ±ntÄ±lÄ± olarak ele alÄ±nmÄ±ÅŸtÄ±r. Burada, forumlar aracÄ±lÄ±ÄŸÄ±yla nasÄ±l ele alÄ±ndÄ±ÄŸÄ±nÄ± kÄ±saca inceleyeceÄŸiz. Kaggle, meraklÄ± katÄ±lÄ±mcÄ±lardan oluÅŸan bir topluluk olduÄŸundan, sÄ±zÄ±ntÄ± ÅŸÃ¼phesi varsa, biri konuyu muhtemelen gÃ¼ndeme getirir.

Ã–rneÄŸin, dosya adlarÄ± veya kayÄ±t IDâ€™leri zaman damgalarÄ± iÃ§erebilir, bu da geleceÄŸe bakmak ve hatalÄ± ÅŸekilde dÃ¼ÅŸÃ¼k hata metriÄŸi elde etmek iÃ§in tersine mÃ¼hendislik yapÄ±labileceÄŸi anlamÄ±na gelir. Bu durum, Two Sigma Connect yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870#176513](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870#176513)

BaÅŸka bir Ã¶rnek, Airbus Ship Detection Challengeâ€™dÄ±r, katÄ±lÄ±mcÄ±larÄ±n uydu gÃ¶rÃ¼ntÃ¼lerinde gemileri bulmasÄ± gerekiyordu. Test gÃ¶rÃ¼ntÃ¼lerinin Ã¶nemli bir kÄ±smÄ±, eÄŸitim gÃ¶rÃ¼ntÃ¼lerinden rastgele kÄ±rpÄ±lmÄ±ÅŸtÄ± ve eÅŸleÅŸtirmek oldukÃ§a kolaydÄ±: [https://www.kaggle.com/c/airbus-ship-detection/discussion/64355#377037](https://www.kaggle.com/c/airbus-ship-detection/discussion/64355#377037)

Santander tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalar da oldukÃ§a Ã¼nlÃ¼dÃ¼r. Åirketin dÃ¼zenlediÄŸi Ã¼Ã§ yarÄ±ÅŸmadan ikisinde veri sÄ±zÄ±ntÄ±sÄ± yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61172](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61172)

Sonraki adÄ±mlar yarÄ±ÅŸmadan yarÄ±ÅŸmaya deÄŸiÅŸir: BazÄ± durumlarda Kaggle, yarÄ±ÅŸmayÄ± yeni veya temizlenmiÅŸ verilerle yeniden baÅŸlatmÄ±ÅŸtÄ±r; bazen ise minimal etki algÄ±ladÄ±klarÄ± iÃ§in devam ettirmiÅŸtir. Ã–rneÄŸin, Predicting Red Hat Business Value yarÄ±ÅŸmasÄ±nda bÃ¶yle bir durum yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/23788](https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/23788)

Veri sÄ±zÄ±ntÄ±larÄ± yarÄ±ÅŸmayÄ± ciddi ÅŸekilde bozabilir, ancak iyi haber ÅŸu ki, son 2-3 yÄ±lda Kaggleâ€™da sÄ±zÄ±ntÄ±lar neredeyse tamamen ortadan kalkmÄ±ÅŸtÄ±r â€“ dolayÄ±sÄ±yla bu bÃ¶lÃ¼m, bir kez okunacak ama platformdaki deneyiminizin sÃ¼rekli bir parÃ§asÄ± olmayacaktÄ±r.

Platformdaki deneyim konusuna gelince, bu Grandmaster rÃ¶portajÄ±na mÃ¼kemmel bir geÃ§iÅŸtir.

> **Yifan Xie**
> 
> [https://www.kaggle.com/yifanxie](https://www.kaggle.com/yifanxie)
> 
> 
> 
> Yifan Xie, **Discussions ve Competitions Master** unvanÄ±na sahip ve aynÄ± zamanda **Arion.ai**â€™nin kurucu ortaÄŸÄ±dÄ±r. Ä°ÅŸte yarÄ±ÅŸmalara katÄ±lma ve diÄŸer Kaggle kullanÄ±cÄ±larÄ±yla Ã§alÄ±ÅŸma konusundaki gÃ¶rÃ¼ÅŸleri:
> 
> 
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™da uzmanlÄ±ÄŸÄ±n nedir?**
> 
> AslÄ±nda Ã¶zel bir favorim yok; her tÃ¼r problemi Ã§Ã¶zmeyi seviyorum. Teknik aÃ§Ä±dan, Ã§oÄŸu veri problemi Ã¼zerinde hÄ±zlÄ±ca uygulanabilecek tipik teknikleri ve algoritmalarÄ± kapsayan saÄŸlam bir **makine Ã¶ÄŸrenimi pipelineâ€™Ä±** geliÅŸtirdim. Bunu, iÅŸ rutinleri ve teknik araÃ§lar aÃ§Ä±sÄ±ndan standartlaÅŸtÄ±rmaya odaklanmÄ±ÅŸ bir **rekabet avantajÄ±** olarak gÃ¶rÃ¼yorum. Bu sayede daha hÄ±zlÄ± iterasyonlar yapabiliyor ve veri deneyleri sÄ±rasÄ±nda verimliliÄŸi artÄ±rabiliyorum; bu da Kaggle iÃ§in temel bir bileÅŸendir.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±n? Bu yaklaÅŸÄ±m gÃ¼nlÃ¼k iÅŸlerinden ne kadar farklÄ±?**
> 
> Zamanla, bÃ¼yÃ¼k veri projelerimin Ã§oÄŸu iÃ§in **bilgi yÃ¶netimi ve toplama** konusunda Ã¶zel bir yÃ¶ntem geliÅŸtirdim. Bu yaklaÅŸÄ±m, iÅŸ projeleri, Kaggle yarÄ±ÅŸmalarÄ± ve diÄŸer yan projeler iÃ§in uygulanabilir. Genellikle yararlÄ± bilgileri (bookmarkâ€™lar, veri sÃ¶zlÃ¼kleri, yapÄ±lacaklar listesi, komutlar, deney sonuÃ§larÄ±) her yarÄ±ÅŸma iÃ§in standart bir formatta toplarÄ±m ve bir takÄ±mda yarÄ±ÅŸÄ±yorsam bu bilgileri takÄ±m arkadaÅŸlarÄ±mla paylaÅŸÄ±rÄ±m.
> 
> 
> 
> **GirdiÄŸin Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±n iÃ§gÃ¶rÃ¼lerden bahseder misin?**
> 
> Benim iÃ§in yarÄ±ÅŸmanÄ±n **genel baÄŸlamÄ±nÄ± anlamak** her zaman faydalÄ± olmuÅŸtur; Ã¶rneÄŸin, verinin ortaya Ã§Ä±kmasÄ±na neden olan sosyal/mÃ¼hendislik/finans sÃ¼reÃ§leri nedir? Deepfake Detection Challenge gibi bireysel veri noktalarÄ±nÄ±n anlamlÄ± ÅŸekilde gÃ¶zlemlenebildiÄŸi yarÄ±ÅŸmalarda, genellikle **Streamlit** kullanarak Ã¶zel bir dashboard hazÄ±rlardÄ±m. Bu dashboard ile bireysel veri noktalarÄ±nÄ± (Ã¶rneÄŸin gerÃ§ek ve sahte video Ã§iftleri) kontrol edebilir ve basit istatistik toplama ile veriyi daha iyi anlayabilirdim.
> 
> 
> 
> **Kaggle kariyerine yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?**
> 
> Kaggle, ÅŸu anki kariyerimde, veri bilimi danÄ±ÅŸmanlÄ±k firmasÄ±nda eÅŸ sahip olarak yer almamda en bÃ¼yÃ¼k katkÄ±yÄ± saÄŸlayan platform oldu diyebilirim. YÄ±llar iÃ§inde farklÄ± alanlardaki veri problemlerini Ã§Ã¶zmek iÃ§in gerekli **beceri ve metodolojiyi** kazanmamÄ± saÄŸladÄ±. Hem mÃ¼ÅŸterilerim hem de ekip arkadaÅŸlarÄ±m, Kaggle yarÄ±ÅŸmalarÄ±nda kurduÄŸum takÄ±mlardan tanÄ±ÅŸtÄ±ÄŸÄ±m kiÅŸiler. Bu platform, bilgi kaynaÄŸÄ± olarak her zaman Ã§ok faydalÄ± oldu; gÃ¼nÃ¼mÃ¼zde daha az aktif olsam da.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r? BaÅŸladÄ±ÄŸÄ±nda bilmek istediÄŸin ÅŸey neydi?**
> 
> Yeni baÅŸlayanlarÄ±n sÄ±k yaptÄ±ÄŸÄ± hata, **kritik teknik olmayan konularÄ±** gÃ¶z ardÄ± etmeleridir: takÄ±m kurallarÄ±, veri kullanÄ±mÄ±, Ã¶zel bilgilerin paylaÅŸÄ±mÄ±, masum sebeplerle birden fazla hesap kullanÄ±mÄ± vb. Bu tÃ¼r hatalar, Ã§oÄŸu zaman aylardÄ±r sÃ¼ren yarÄ±ÅŸma Ã§alÄ±ÅŸmalarÄ±nÄ± tamamen geÃ§ersiz kÄ±labilir.
> 
> 
> 
> BaÅŸladÄ±ÄŸÄ±mda bilmek istediÄŸim bir diÄŸer ÅŸey ise, **gÃ¼nlÃ¼k public leaderboard pozisyonuna takÄ±lmamak** olurdu. Bu gereksiz baskÄ± yaratÄ±r ve overfittingâ€™e yol aÃ§ar.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nereceÄŸin araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Standart araÃ§lar: **Scikit-learn, XGB/LGB, PyTorch** vb.
> 
> Ancak temel kullanÄ±mÄ±n Ã¶tesinde herkesin **NumPyâ€™yi** iyi Ã¶ÄŸrenmesini Ã¶neririm; Ã¶zellikle verileri daha geliÅŸmiÅŸ ÅŸekilde sÄ±ralamak ve alt kÃ¼melere ayÄ±rmak iÃ§in. Pandas kolaylaÅŸtÄ±rÄ±r, ama NumPy ile daha verimli yÃ¶ntemler uygulanabilir.
> 
> 
> 
> **YarÄ±ÅŸmaya girerken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Bana gÃ¶re veri bilimi ile ilgili iÅŸleri yapmanÄ±n dÃ¶rt nedeni vardÄ±r: **kar, bilgi, eÄŸlence ve iyilik**. Kaggle benim iÃ§in her zaman **bÃ¼yÃ¼k bir bilgi kaynaÄŸÄ±** ve hatÄ±rlanacak bir hafÄ±za deposu olmuÅŸtur. Bu yÃ¼zden Ã¶nerim: **SÄ±ralamanÄ±n geÃ§ici, bilginin ve hafÄ±zanÄ±n kalÄ±cÄ± olduÄŸunu hatÄ±rlayÄ±n.**
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musun? Kaggle ile karÅŸÄ±laÅŸtÄ±rÄ±nca?**
> 
> Numeraiâ€™da oldukÃ§a aktifim. DÃ¶rt nedenim aÃ§Ä±sÄ±ndan, Numerai daha Ã§ok **kar amacÄ±yla** oluyor Ã§Ã¼nkÃ¼ Ã¶demeyi kripto para ile yapÄ±yorlar. Daha Ã§ok **bireysel Ã§aba** gerektiriyor; takÄ±m kurmak Ã§ok avantaj saÄŸlamÄ±yor.
> 
> 
> 
> Numerai, yoÄŸun iÅŸ takvimimde **Kaggleâ€™dan daha sÃ¼rdÃ¼rÃ¼lebilir** bir etkinlik Ã§Ã¼nkÃ¼ her turda eÄŸitim verisi genellikle deÄŸiÅŸmiyor. Ä°lk modeller kurulduktan sonra tahmin ve gÃ¶nderim sÃ¼reÃ§lerini **yÃ¼ksek derecede otomatikleÅŸtirebilirim**. AyrÄ±ca Numerai, tabular veri setleri iÃ§in Ã¶zel makine Ã¶ÄŸrenimi pipelineâ€™larÄ± geliÅŸtirmek isteyenler iÃ§in daha uygun bir platform.

### Netiquette *(Ä°nternet gÃ¶rgÃ¼ kurallarÄ±)*

Ä°nternette 15 dakikadan uzun sÃ¼re vakit geÃ§iren herkes bunu bilir: Bir tartÄ±ÅŸma sÄ±rasÄ±nda, konunun ne kadar masum olursa olsun, insanlarÄ±n duygusal tepkiler vermesi ve sohbetin medeni sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±na taÅŸmasÄ± her zaman mÃ¼mkÃ¼ndÃ¼r. Kaggle da bu kuralÄ±n istisnasÄ± deÄŸildir; bu yÃ¼zden topluluÄŸun **uygun davranÄ±ÅŸ kurallarÄ±** vardÄ±r: [https://www.kaggle.com/community-guidelines](https://www.kaggle.com/community-guidelines).

Bu kurallar yalnÄ±zca tartÄ±ÅŸmalara deÄŸil, **Notebooks** ve diÄŸer iletiÅŸim biÃ§imlerine de uygulanÄ±r. Kaggleâ€™da etkileÅŸimde bulunurken akÄ±lda tutulmasÄ± gereken baÅŸlÄ±ca noktalar ÅŸunlardÄ±r:

* **Zihinsel okuma yanÄ±lgÄ±sÄ±na dÃ¼ÅŸmeyin:** Scott Adamsâ€™Ä±n adlandÄ±rdÄ±ÄŸÄ± bu yanÄ±lgÄ±, insanlarÄ±n ne dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼ varsayma eÄŸilimidir. Kaggle, dÃ¼nyanÄ±n dÃ¶rt bir yanÄ±ndan gelen Ã§ok Ã§eÅŸitli bir topluluktur (Ã§oÄŸu iÃ§in Ä°ngilizce ikinci dil), bu nedenle nÃ¼ansÄ± korumak bÃ¼yÃ¼k bir zorluktur. VarsayÄ±mlarda bulunmayÄ±n ve mÃ¼mkÃ¼n olduÄŸunca netleÅŸtirmeye Ã§alÄ±ÅŸÄ±n.
* **Åahsi saldÄ±rÄ±lardan kaÃ§Ä±nÄ±n:** Godwinâ€™in yasasÄ± boÅŸuna yoktur. Ã–zellikle korunan ve deÄŸiÅŸtirilemez Ã¶zelliklere yÃ¶nelik referanslar kesinlikle yasaktÄ±r.
* **AÅŸaÄŸÄ±lamalardan kaÃ§Ä±nÄ±n:** Deneyimleriniz farklÄ± olabilir, ancak internetin 1990â€™larda â€œRTFMâ€ demenin normal olduÄŸu vahÅŸi batÄ± ortamÄ± artÄ±k yok. AÅŸaÄŸÄ±lamalar insanlarÄ± uzaklaÅŸtÄ±rÄ±r.
* **Ä°lerleme sistemini manipÃ¼le etmeye Ã§alÄ±ÅŸmayÄ±n:** Kaggle madalyalarÄ±nÄ±n verildiÄŸi bu sistemin manipÃ¼lasyonu, aÃ§Ä±kÃ§a oy istemekten, gizli anlaÅŸmalara, hatta doÄŸrudan hileye kadar platform kÃ¶tÃ¼ye kullanÄ±mÄ±nÄ±n tÃ¼m yelpazesini kapsar.

KÄ±saca, baÅŸkalarÄ±na kendinize davranÄ±lmasÄ±nÄ± istediÄŸiniz ÅŸekilde davranÄ±n, her ÅŸey yolunda gider.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle platformunda iletiÅŸimin birincil yolu olan **tartÄ±ÅŸma forumlarÄ±nÄ±** ele aldÄ±k. Forum mekaniklerini gÃ¶sterdik, tartÄ±ÅŸmalarÄ±n daha geliÅŸmiÅŸ yarÄ±ÅŸmalarda nasÄ±l kullanÄ±labileceÄŸine dair Ã¶rnekler sunduk ve tartÄ±ÅŸma **netiketi**ni kÄ±saca Ã¶zetledik.

Bu, kitabÄ±n ilk ve giriÅŸ niteliÄŸindeki bÃ¶lÃ¼mÃ¼nÃ¼n sonunu iÅŸaret ediyor. Bir sonraki bÃ¶lÃ¼m, Kaggleâ€™dan elde edeceÄŸiniz verimi **maksimize etme** konusunda daha derin bir incelemenin baÅŸlangÄ±cÄ±nÄ± oluÅŸturuyor ve yarÄ±ÅŸmalarda karÅŸÄ±laÅŸmanÄ±z gereken Ã§ok Ã§eÅŸitli gÃ¶revler ve metriklerle baÅŸa Ã§Ä±kmayÄ± ele alÄ±yor.

---

# Part II: Sharpening Your Skills for Competitions *(BÃ¶lÃ¼m II: YarÄ±ÅŸmalar Ä°Ã§in Becerilerini GeliÅŸtirme)*

## Chapter 5: Competition Tasks and Metrics *(BÃ¶lÃ¼m 5: YarÄ±ÅŸma GÃ¶revleri ve Ã–lÃ§Ã¼tleri)*

Bir yarÄ±ÅŸmada, iÅŸe hedef metriÄŸi inceleyerek baÅŸlarsÄ±nÄ±z. Modelinizin hatalarÄ±nÄ±n nasÄ±l deÄŸerlendirildiÄŸini anlamak, her yarÄ±ÅŸmada yÃ¼ksek puan alabilmek iÃ§in kritik Ã¶neme sahiptir. Tahminleriniz Kaggle platformuna gÃ¶nderildiÄŸinde, hedef metrik temel alÄ±narak gerÃ§ek deÄŸerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

Ã–rneÄŸin, Titanic yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/titanic/](https://www.kaggle.com/c/titanic/)) tÃ¼m gÃ¶nderimleriniz doÄŸruluk (accuracy) temelinde deÄŸerlendirilir; yani, hayatta kalan yolcularÄ± doÄŸru tahmin etme yÃ¼zdesi. Organizasyon bu metriÄŸi seÃ§miÅŸtir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n amacÄ±, benzer koÅŸullar altÄ±nda bir yolcunun hayatta kalma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin edebilen bir model bulmaktÄ±r.

BaÅŸka bir bilgi yarÄ±ÅŸmasÄ±nda, House Prices - Advanced Regression Techniques ([https://www.kaggle.com/c/house-prices-advanced-regression-techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)), Ã§alÄ±ÅŸmalarÄ±nÄ±z tahmininiz ile gerÃ§ek deÄŸer arasÄ±ndaki ortalama fark temelinde deÄŸerlendirilir. Bu, logaritmayÄ± almayÄ±, karesini almayÄ± ve karekÃ¶kÃ¼nÃ¼ hesaplamayÄ± iÃ§erir; Ã§Ã¼nkÃ¼ modelden, satÄ±ÅŸta olan bir evin fiyat sÄ±rasÄ±nÄ± olabildiÄŸince doÄŸru bir ÅŸekilde tahmin etmesi beklenir.

GerÃ§ek dÃ¼nyadaki veri bilimi projelerinde de hedef metrikler, projenin baÅŸarÄ±sÄ± iÃ§in kritiktir; ancak gerÃ§ek dÃ¼nya ile Kaggle yarÄ±ÅŸmalarÄ± arasÄ±nda bazÄ± farklÄ±lÄ±klar vardÄ±r. Ã–zetle, gerÃ§ek dÃ¼nyada iÅŸler daha karmaÅŸÄ±ktÄ±r. GerÃ§ek dÃ¼nya projelerinde modeliniz genellikle yalnÄ±zca bir deÄŸil, birden fazla metrikle deÄŸerlendirilecektir. SÄ±klÄ±kla bazÄ± deÄŸerlendirme metrikleri, test iÃ§in kullandÄ±ÄŸÄ±nÄ±z gerÃ§ek deÄŸerlerle tahminlerinizin performansÄ± ile doÄŸrudan iliÅŸkili olmayabilir.

Ã–rneÄŸin, Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z bilgi alanÄ±, projenin kapsamÄ±, modelinizin dikkate aldÄ±ÄŸÄ± Ã¶zellik sayÄ±sÄ±, genel bellek kullanÄ±mÄ±, Ã¶zel donanÄ±m gereksinimleri (Ã¶r. GPU), tahmin sÃ¼recinin gecikmesi, modelin karmaÅŸÄ±klÄ±ÄŸÄ± ve diÄŸer birÃ§ok faktÃ¶r, yalnÄ±zca tahmin performansÄ±ndan daha fazla Ã¶nem taÅŸÄ±yabilir.

GerÃ§ek dÃ¼nyadaki problemler, dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼zden Ã§ok daha fazla iÅŸ ve teknik altyapÄ± kaygÄ±larÄ± tarafÄ±ndan ÅŸekillendirilir.

Yine de, hem gerÃ§ek dÃ¼nya projelerinde hem de Kaggle yarÄ±ÅŸmalarÄ±nda temel prensip aynÄ±dÄ±r: Ã‡alÄ±ÅŸmanÄ±z belirli kriterlere gÃ¶re deÄŸerlendirilecektir. Bu kriterlerin detaylarÄ±nÄ± anlamak, modelinizi akÄ±llÄ±ca optimize etmek veya parametrelerini bu kriterlere gÃ¶re seÃ§mek baÅŸarÄ± getirir. Kaggleâ€™da model deÄŸerlendirmesinin nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenebilirseniz, gerÃ§ek dÃ¼nyadaki veri bilimi iÅŸiniz de bundan fayda saÄŸlar.

Bu bÃ¶lÃ¼mde, belirli problem tÃ¼rleri iÃ§in deÄŸerlendirme metriklerinin, veri bilimi yarÄ±ÅŸmalarÄ±nda model Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururken nasÄ±l hareket edebileceÄŸinizi gÃ¼Ã§lÃ¼ bir ÅŸekilde etkilediÄŸini detaylÄ± olarak inceleyeceÄŸiz. AyrÄ±ca, Kaggle yarÄ±ÅŸmalarÄ±nda bulunan Ã§eÅŸitli metrikleri ele alarak, hangi metriklerin daha Ã¶nemli olduÄŸunu anlamanÄ±zÄ± saÄŸlayacaÄŸÄ±z ve yan not olarak metriklerin tahmin performansÄ± Ã¼zerindeki farklÄ± etkilerini ve bunlarÄ± projelerinize nasÄ±l doÄŸru ÅŸekilde aktarabileceÄŸinizi tartÄ±ÅŸacaÄŸÄ±z.

Bu bÃ¶lÃ¼mde ele alÄ±nacak konular:

* DeÄŸerlendirme metrikleri ve amaÃ§ fonksiyonlarÄ±
* Temel gÃ¶rev tÃ¼rleri: regresyon, sÄ±nÄ±flandÄ±rma ve sÄ±ralÄ± (ordinal)
* Meta Kaggle veri seti
* Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerin ele alÄ±nmasÄ±
* Regresyon metrikleri (standart ve ordinal)
* Ä°kili sÄ±nÄ±flandÄ±rma metrikleri (etiket tahmini ve olasÄ±lÄ±k)
* Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri
* Nesne tespit problemleri iÃ§in metrikler
* Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri sistemleri metrikleri
* DeÄŸerlendirme metriklerini optimize etme

### Evaluation metrics and objective functions *(DeÄŸerlendirme metrikleri ve hedef fonksiyonlar)*

Bir Kaggle yarÄ±ÅŸmasÄ±nda, deÄŸerlendirme metriÄŸini yarÄ±ÅŸmanÄ±n **Overview (Genel BakÄ±ÅŸ)** sayfasÄ±nÄ±n sol menÃ¼sÃ¼nden bulabilirsiniz. **Evaluation (DeÄŸerlendirme)** sekmesini seÃ§tiÄŸinizde, metriÄŸe iliÅŸkin detaylarÄ± gÃ¶rebilirsiniz. Bazen burada metrik formÃ¼lÃ¼, metrikle ilgili yeniden Ã¼retim kodu ve metrik hakkÄ±nda bazÄ± tartÄ±ÅŸmalar da bulunur. AynÄ± sayfada, ayrÄ±ca gÃ¶nderim dosyasÄ± formatÄ± hakkÄ±nda aÃ§Ä±klamalar yer alÄ±r; dosyanÄ±n baÅŸlÄ±k satÄ±rÄ± ve birkaÃ§ Ã¶rnek satÄ±r gÃ¶sterilir.

DeÄŸerlendirme metriÄŸi ile gÃ¶nderim dosyasÄ± arasÄ±ndaki iliÅŸki Ã¶nemlidir, Ã§Ã¼nkÃ¼ metrik esasen modelinizi eÄŸitip tahminleri Ã¼rettikten sonra iÅŸler. DolayÄ±sÄ±yla ilk adÄ±m olarak, **deÄŸerlendirme metriÄŸi ile amaÃ§ fonksiyonu arasÄ±ndaki farkÄ±** anlamalÄ±sÄ±nÄ±z.

Temel olarak Ã¶zetlersek:

* **AmaÃ§ fonksiyonu (objective function)**, modelinizi eÄŸitirken kullanÄ±lÄ±r; hata minimizasyonu veya skor maksimizasyonu sÃ¼recinde yer alÄ±r.
* **DeÄŸerlendirme metriÄŸi (evaluation metric)** ise model eÄŸitildikten sonra bir skor saÄŸlar. Bu nedenle doÄŸrudan modelin veriyle uyumunu etkilemez, ancak dolaylÄ± olarak etkiler: en iyi hiperparametre ayarlarÄ±nÄ± seÃ§menize ve rekabet eden modeller arasÄ±nda en iyi modelleri belirlemenize yardÄ±mcÄ± olur.

BÃ¶lÃ¼mÃ¼n geri kalanÄ±nda, bunun bir Kaggle yarÄ±ÅŸmasÄ±nÄ± nasÄ±l etkileyebileceÄŸini ve neden yarÄ±ÅŸmadaki deÄŸerlendirme metriÄŸinin analizinin ilk adÄ±mÄ±nÄ±z olmasÄ± gerektiÄŸini gÃ¶stereceÄŸiz. Ã–nce, tartÄ±ÅŸma forumlarÄ±nda sÄ±kÃ§a karÅŸÄ±laÅŸabileceÄŸiniz bazÄ± terimleri ele alalÄ±m.

Genellikle **objective function, cost function ve loss function** terimlerini birbirinin yerine duyarÄ±z, ama hepsi tam olarak aynÄ± ÅŸey deÄŸildir:

* **Loss function (KayÄ±p fonksiyonu):** Tek bir veri noktasÄ± Ã¼zerine tanÄ±mlanÄ±r ve modelin tahmini ile gerÃ§ek deÄŸer arasÄ±ndaki ceza miktarÄ±nÄ± hesaplar.
* **Cost function (Maliyet fonksiyonu):** EÄŸitim iÃ§in kullanÄ±lan tÃ¼m veri setini (veya bir batchâ€™ini) dikkate alÄ±r ve veri noktalarÄ±nÄ±n kayÄ±p fonksiyonlarÄ± Ã¼zerinden toplam veya ortalama hesaplar. L1 veya L2 ceza terimleri gibi ek kÄ±sÄ±tlamalarÄ± iÃ§erebilir. Maliyet fonksiyonu doÄŸrudan eÄŸitim sÃ¼recini etkiler.
* **Objective function (AmaÃ§ fonksiyonu):** Makine Ã¶ÄŸrenimi eÄŸitiminde optimizasyon kapsamÄ±yla ilgili en genel terimdir; maliyet fonksiyonlarÄ±nÄ± iÃ§erir ama onlarla sÄ±nÄ±rlÄ± deÄŸildir. Ã–rneÄŸin, tahmin edilen modelin katsayÄ±larÄ±nÄ±n seyrek olmasÄ±nÄ± veya katsayÄ± deÄŸerlerinin minimize edilmesini gerektiren L1/L2 regularizasyonlarÄ± gibi hedefleri de iÃ§erebilir. Loss ve cost fonksiyonlarÄ± genellikle minimizasyona dayalÄ± iken, amaÃ§ fonksiyonu nÃ¶trdÃ¼r ve hem maximizasyon hem minimizasyon amaÃ§lÄ± optimizasyonu kapsayabilir.

Benzer ÅŸekilde, deÄŸerlendirme metriklerinde de **scoring function (skor fonksiyonu)** ve **error function (hata fonksiyonu)** terimlerini duyabilirsiniz:

* **Scoring function:** Fonksiyonun skoru yÃ¼ksek olduÄŸunda tahminler daha iyi kabul edilir; bu bir **maksimizasyon** sÃ¼recini ifade eder.
* **Error function:** Fonksiyonun hata deÄŸeri daha kÃ¼Ã§Ã¼k olduÄŸunda tahminler daha iyi kabul edilir; bu bir **minimizasyon** sÃ¼recini ifade eder.

### Basic types of tasks *(Temel gÃ¶rev tÃ¼rleri)*

TÃ¼m amaÃ§ fonksiyonlarÄ± her problem iÃ§in uygun deÄŸildir. Genel bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla, Kaggle yarÄ±ÅŸmalarÄ±nda iki tÃ¼r problem bulursunuz: **regresyon gÃ¶revleri** ve **sÄ±nÄ±flandÄ±rma gÃ¶revleri**.

Son zamanlarda, bazÄ± yarÄ±ÅŸmalarda **reinforcement learning (RL â€“ pekiÅŸtirmeli Ã¶ÄŸrenme)** gÃ¶revleri de gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Ancak RL, deÄŸerlendirme iÃ§in metrik kullanmaz; bunun yerine, Ã§Ã¶zÃ¼mleri sizin Ã§Ã¶zÃ¼mÃ¼nÃ¼z kadar iyi olduÄŸu varsayÄ±lan diÄŸer katÄ±lÄ±mcÄ±larla doÄŸrudan karÅŸÄ±laÅŸtÄ±rmalardan tÃ¼retilen bir sÄ±ralamaya dayanÄ±r. Bu karÅŸÄ±laÅŸtÄ±rmada diÄŸer katÄ±lÄ±mcÄ±lardan daha iyi performans gÃ¶sterirseniz sÄ±ralamanÄ±z yÃ¼kselir, daha kÃ¶tÃ¼ performans gÃ¶sterirseniz dÃ¼ÅŸer.

RL metrik kullanmadÄ±ÄŸÄ± iÃ§in, biz hÃ¢lÃ¢ **regresyon-sÄ±nÄ±flandÄ±rma ikiliÄŸini** temel alacaÄŸÄ±z. Ancak **ordinal gÃ¶revler** (sÄ±ralÄ± etiketleri, genellikle tamsayÄ±larla temsil edilen, tahmin ettiÄŸiniz gÃ¶revler) bu kategorilere tam olarak uymayabilir. Ordinal gÃ¶revler, regresyon veya sÄ±nÄ±flandÄ±rma yaklaÅŸÄ±mlarÄ±ndan biriyle baÅŸarÄ±yla ele alÄ±nabilir.

#### Regression *(Regresyon)*

**Regresyon**, gerÃ§ek bir sayÄ± tahmin edebilen bir model kurmanÄ±zÄ± gerektirir; Ã§oÄŸunlukla pozitif bir sayÄ± tahmin edilir, ancak negatif sayÄ± tahmini yapÄ±lan Ã¶rnekler de olmuÅŸtur.

Regresyon problemlerine klasik bir Ã¶rnek, **House Prices - Advanced Regression Techniques** yarÄ±ÅŸmasÄ±dÄ±r; Ã§Ã¼nkÃ¼ burada bir evin deÄŸerini tahmin etmeniz gerekir.

Bir regresyon gÃ¶revinde deÄŸerlendirme, tahminleriniz ile gerÃ§ek deÄŸerler arasÄ±ndaki **farkÄ±n Ã¶lÃ§Ã¼lmesi** ile yapÄ±lÄ±r. Bu fark farklÄ± yollarla deÄŸerlendirilebilir:

* **Karesini almak**, yani hatalarÄ± daha bÃ¼yÃ¼k olan tahminleri daha fazla cezalandÄ±rmak,
* **Logaritma uygulamak**, yani yanlÄ±ÅŸ Ã¶lÃ§eklerdeki tahminleri cezalandÄ±rmak iÃ§in.

#### Classification *(SÄ±nÄ±flandÄ±rma)*

Kaggleâ€™da bir **sÄ±nÄ±flandÄ±rma (classification)** gÃ¶revi ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda dikkate alÄ±nmasÄ± gereken daha fazla nÃ¼ans vardÄ±r. SÄ±nÄ±flandÄ±rma, aslÄ±nda **ikili (binary), Ã§ok sÄ±nÄ±flÄ± (multi-class) veya Ã§ok etiketli (multi-label)** olabilir.

* **Ä°kili sÄ±nÄ±flandÄ±rma (binary problems):**
  Bir Ã¶rneÄŸin belirli bir sÄ±nÄ±fa ait olup olmadÄ±ÄŸÄ±nÄ± tahmin etmeniz gerekir (genellikle â€œpozitif sÄ±nÄ±fâ€ olarak adlandÄ±rÄ±lÄ±r ve â€œnegatif sÄ±nÄ±fâ€ ile karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r).
  Burada deÄŸerlendirme, doÄŸrudan sÄ±nÄ±f tahminine dayanabilir veya sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ±nÄ±n tahmin edilmesini gerektirebilir.
  Ã–rnek: **Titanic** yarÄ±ÅŸmasÄ±; burada ikili bir sonuÃ§ tahmin edersiniz: hayatta kalma veya kalmama. YarÄ±ÅŸma Ã§oÄŸu zaman sadece tahmini ister, ancak bazÄ± alanlardaâ€”Ã¶zellikle tÄ±p uygulamalarÄ±ndaâ€”pozitif tahminleri farklÄ± seÃ§enekler ve durumlar arasÄ±nda sÄ±ralamak gerekebilir, bu yÃ¼zden olasÄ±lÄ±k tahmini gerekir.

* **Dengesiz sÄ±nÄ±flar (imbalanced classes):**
  Ä°kili sÄ±nÄ±flandÄ±rmada doÄŸru eÅŸleÅŸmelerin sayÄ±sÄ±nÄ± doÄŸrudan saymak mantÄ±klÄ± gÃ¶rÃ¼nse de, pozitif ve negatif sÄ±nÄ±flar arasÄ±nda Ã¶rnek sayÄ±sÄ± farklÄ± olduÄŸunda bu yÃ¶ntem iyi Ã§alÄ±ÅŸmaz.
  Dengesiz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±, model geliÅŸtirmelerini doÄŸru ÅŸekilde takip edebilmek iÃ§in **dengeyi dikkate alan deÄŸerlendirme metrikleri** gerektirir.

* **Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma (multi-class):**
  Ä°ki sÄ±nÄ±ftan fazlasÄ± varsa, bu bir **Ã§ok sÄ±nÄ±flÄ± tahmin problemi**dir. Bu durumda, modelin genel performansÄ±nÄ± izlemek ve sÄ±nÄ±flar arasÄ±ndaki performansÄ±n karÅŸÄ±laÅŸtÄ±rÄ±labilir olmasÄ±nÄ± saÄŸlamak iÃ§in uygun metrikler kullanmak gerekir.
  Ã–rnek: **Leaf Classification** yarÄ±ÅŸmasÄ±; burada her yaprak Ã¶rneÄŸinin doÄŸru bitki tÃ¼rÃ¼ ile eÅŸleÅŸtirilmesi gerekir.

* **Ã‡ok etiketli sÄ±nÄ±flandÄ±rma (multi-label):**
  EÄŸer her Ã¶rnek iÃ§in birden fazla sÄ±nÄ±f tahmin edilebiliyorsa, bu bir **Ã§ok etiketli problem**dir. Bu durumda, modelin doÄŸru sÄ±nÄ±flarÄ±, doÄŸru sayÄ± ve karÄ±ÅŸÄ±mÄ± tahmin edip etmediÄŸini kontrol etmek iÃ§in ek deÄŸerlendirmeler gerekir.
  Ã–rnek: **Greek Media Monitoring Multilabel Classification (WISE 2014)**; burada her makale, iÅŸlediÄŸi tÃ¼m konularla iliÅŸkilendirilmeliydi.

#### Ordinal *(SÄ±ralÄ± veriler)*

Bir **ordinal Ã¶lÃ§ekli tahmin probleminde**, tam sayÄ± ÅŸeklinde etiketleri tahmin etmeniz gerekir; bu etiketler doÄŸal olarak sÄ±ralÄ±dÄ±r.
Ã–rnek: Bir depremin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ordinal bir Ã¶lÃ§ektedir.
AyrÄ±ca, pazarlama araÅŸtÄ±rmalarÄ± anketlerinden elde edilen veriler de sÄ±klÄ±kla ordinal Ã¶lÃ§ekle kaydedilir (Ã¶rneÄŸin, tÃ¼ketici tercihleri veya fikir uyumu).

Ordinal Ã¶lÃ§ek **sÄ±ralÄ± deÄŸerlerden** oluÅŸtuÄŸu iÃ§in, ordinal gÃ¶revler hem regresyon hem de sÄ±nÄ±flandÄ±rma yÃ¶ntemleriyle Ã§Ã¶zÃ¼lebilir; yani adeta bu iki yÃ¶ntem arasÄ±nda bir geÃ§iÅŸ niteliÄŸindedir.

* **Ã‡ok sÄ±nÄ±flÄ± problem olarak yaklaÅŸmak:**
  Ordinal gÃ¶revi Ã§ok sÄ±nÄ±flÄ± bir problem gibi ele almak en yaygÄ±n yaklaÅŸÄ±mdÄ±r. Bu durumda, bir tam sayÄ± deÄŸeri (sÄ±nÄ±f etiketi) tahmin edersiniz, ancak tahmin **sÄ±nÄ±flarÄ±n sÄ±ralÄ± olduÄŸunu dikkate almaz**.
  EÄŸer sÄ±nÄ±flar iÃ§in tahmin olasÄ±lÄ±klarÄ±nÄ± incelerseniz, problem Ã¼zerinde Ã§ok sÄ±nÄ±flÄ± bir yaklaÅŸÄ±mÄ±n eksiklerini fark edebilirsiniz. OlasÄ±lÄ±klar genellikle tÃ¼m olasÄ± deÄŸerler boyunca daÄŸÄ±lÄ±r; bu, **Ã§ok modlu ve genellikle simetrik olmayan bir daÄŸÄ±lÄ±m** oluÅŸturur. Halbuki doÄŸru yaklaÅŸÄ±mda, maksimum olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±f etrafÄ±nda **Gaussian benzeri bir daÄŸÄ±lÄ±m** beklenir.

* **Regresyon problemine dÃ¶nÃ¼ÅŸtÃ¼rmek:**
  Ordinal tahmin problemini regresyon olarak ele alÄ±p ardÄ±ndan post-processing yapmak baÅŸka bir yaklaÅŸÄ±mdÄ±r. Bu yÃ¶ntemle, sÄ±nÄ±flar arasÄ±ndaki sÄ±ralama dikkate alÄ±nÄ±r, ancak tahmin Ã§Ä±ktÄ±sÄ± hemen deÄŸerlendirme metriÄŸinde kullanÄ±labilir deÄŸildir.
  Regresyonda Ã§Ä±ktÄ± bir tam sayÄ± deÄŸil, **float bir sayÄ±**dÄ±r ve bu sayÄ± ordinal daÄŸÄ±lÄ±mÄ±nÄ±zdaki tam sayÄ±lar arasÄ±ndaki tÃ¼m deÄŸerleri (ve hatta bazen sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±ndaki deÄŸerleri) iÃ§erebilir. Ã‡Ä±ktÄ± deÄŸerlerini kÄ±rpÄ±p birim yuvarlamasÄ±yla tam sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rmek iÅŸe yarayabilir, ancak bu yÃ¶ntem bazÄ± hatalara yol aÃ§abilir ve daha sofistike bir post-processing gerekebilir (bunun detaylarÄ± ilerleyen bÃ¶lÃ¼mlerde ele alÄ±nacaktÄ±r).

Åimdi muhtemelen merak ediyorsunuz: **Kaggleâ€™da baÅŸarÄ±lÄ± olmak iÃ§in hangi deÄŸerlendirme metriklerini bilmemiz gerekir?**
AÃ§Ä±kÃ§a, her zaman katÄ±ldÄ±ÄŸÄ±nÄ±z yarÄ±ÅŸmanÄ±n **deÄŸerlendirme metriÄŸini** iyi bilmelisiniz. Ancak bazÄ± metrikler diÄŸerlerinden daha yaygÄ±ndÄ±r; bu bilgiyi kendi avantajÄ±nÄ±za kullanabilirsiniz.

* **SÄ±k kullanÄ±lan metrikler nelerdir?**
* **Benzer deÄŸerlendirme metrikleri kullanan yarÄ±ÅŸmalardan ipuÃ§larÄ±nÄ± nasÄ±l bulabilirsiniz?**

Bunun cevabÄ±: **Meta Kaggle veri setini** incelemektir.

### The Meta Kaggle dataset *(Meta Kaggle veri seti)*

**Meta Kaggle veri seti** ([https://www.kaggle.com/kaggle/meta-kaggle](https://www.kaggle.com/kaggle/meta-kaggle)), Kaggle topluluÄŸu ve aktiviteleri hakkÄ±nda zengin veri iÃ§eren, Kaggle tarafÄ±ndan yayÄ±mlanmÄ±ÅŸ bir halka aÃ§Ä±k veri setidir.
Veri seti, **Competitions, Datasets, Notebooks ve Discussions** gibi Kaggleâ€™daki kamuya aÃ§Ä±k aktiviteleri iÃ§eren CSV tablolarÄ±ndan oluÅŸur.

KullanÄ±mÄ± oldukÃ§a basittir:

1. Bir **Kaggle Notebook** baÅŸlatÄ±n (BÃ¶lÃ¼m 2 ve 3â€™te gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi).
2. Notebookâ€™a **Meta Kaggle veri setini** ekleyin.
3. Verileri analiz etmeye baÅŸlayÄ±n.

CSV tablolarÄ± gÃ¼nlÃ¼k olarak gÃ¼ncellenir, bu yÃ¼zden analizlerinizi sÄ±k sÄ±k yenilemeniz gerekir, ama Ã§Ä±karacaÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼ler buna deÄŸecektir.

Bu kitapta, Meta Kaggle veri setine hem **yarÄ±ÅŸmalardaki dinamikler iÃ§in ilginÃ§ Ã¶rnekler bulmak** hem de **Ã¶ÄŸrenme ve yarÄ±ÅŸma stratejileriniz iÃ§in faydalÄ± Ã¶rnekler Ã§Ä±karmak** iÃ§in atÄ±fta bulunacaÄŸÄ±z.

Burada veri setini, **son yedi yÄ±lda hangi deÄŸerlendirme metriklerinin en sÄ±k kullanÄ±ldÄ±ÄŸÄ±nÄ±** anlamak iÃ§in kullanacaÄŸÄ±z. Bu metrikleri gÃ¶rerek:

* Herhangi bir yarÄ±ÅŸmaya saÄŸlam bir temel ile baÅŸlayabilir,
* ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±ndan elde ettiÄŸiniz bilgilerle metrik hakkÄ±nda yarÄ±ÅŸmaya Ã¶zgÃ¼ ince ayrÄ±ntÄ±larÄ± Ã¶ÄŸrenebilirsiniz.

---

AÅŸaÄŸÄ±daki kod, **yÄ±llara gÃ¶re kullanÄ±lan metriklerin ve sayÄ±larÄ±nÄ± tablo hÃ¢line getirmek** iÃ§in gerekli Ã¶rnek kodu gÃ¶stermektedir. Kod, doÄŸrudan Kaggle platformunda Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r:

```python
import numpy as np
import pandas as pd

# Competitions CSV tablosunu oku
comps = pd.read_csv("/kaggle/input/meta-kaggle/Competitions.csv")

# Ä°lgilenilen sÃ¼tunlar
evaluation = ['EvaluationAlgorithmAbbreviation',
              'EvaluationAlgorithmName',
              'EvaluationAlgorithmDescription',]

compt = ['Title', 'EnabledDate', 'HostSegmentTitle']

# Analiz iÃ§in kopya DataFrame oluÅŸtur
df = comps[compt + evaluation].copy()
df['year'] = pd.to_datetime(df.EnabledDate).dt.year.values
df['comps'] = 1

# 2015 ve sonrasÄ± yarÄ±ÅŸmalarÄ± seÃ§
time_select = df.year >= 2015

# Featured ve Research tÃ¼rÃ¼ndeki yarÄ±ÅŸmalar
competition_type_select = df.HostSegmentTitle.isin(['Featured', 'Research'])

# Pivot tablo oluÅŸtur ve yÄ±llara gÃ¶re metrik sayÄ±sÄ±nÄ± hesapla
pd.pivot_table(df[time_select & competition_type_select],
               values='comps',
               index=['EvaluationAlgorithmAbbreviation'],
               columns=['year'],
               fill_value=0.0,
               aggfunc=np.sum,
               margins=True
              ).sort_values(by=('All'), ascending=False).iloc[1:, :].head(20)
```

Kodun iÅŸleyiÅŸi:

1. Competitions CSVâ€™si okunur.
2. Sadece analiz iÃ§in gerekli sÃ¼tunlar seÃ§ilir: **deÄŸerlendirme algoritmasÄ±, yarÄ±ÅŸma adÄ±, baÅŸlama tarihi ve yarÄ±ÅŸma tÃ¼rÃ¼**.
3. SatÄ±rlar, 2015 sonrasÄ± ve **Featured veya Research tÃ¼rÃ¼ndeki yarÄ±ÅŸmalar** ile sÄ±nÄ±rlanÄ±r (en yaygÄ±n olanlar).
4. **Pivot tablo** ile deÄŸerlendirme algoritmalarÄ± yÄ±llara gÃ¶re gruplanÄ±r ve her birinin kaÃ§ yarÄ±ÅŸmada kullanÄ±ldÄ±ÄŸÄ± sayÄ±lÄ±r.
5. Son olarak **en Ã§ok kullanÄ±lan 20 algoritma** gÃ¶rÃ¼ntÃ¼lenir.

![](im/1042.png)

AynÄ± tablolarÄ± oluÅŸturmak iÃ§in az Ã¶nce baÅŸlattÄ±ÄŸÄ±mÄ±z deÄŸiÅŸkenleri kullanarak, ayrÄ±ca veriyi kontrol edip seÃ§tiÄŸiniz metriÄŸin kullanÄ±ldÄ±ÄŸÄ± yarÄ±ÅŸmalarÄ± da bulabilirsiniz:

```python
metric = 'AUC'
metric_select = df['EvaluationAlgorithmAbbreviation'] == metric
print(df[time_select & competition_type_select & metric_select][['Title', 'year']])
```

YukarÄ±daki Ã¶rnekte, AUC metriÄŸini kullanan yarÄ±ÅŸmalarÄ± temsil etmeye karar verdik. Sadece seÃ§tiÄŸiniz metriÄŸi temsil eden stringâ€™i deÄŸiÅŸtirmeniz yeterlidir; bÃ¶ylece ortaya Ã§Ä±kan liste buna gÃ¶re gÃ¼ncellenecektir.

Tabloya geri dÃ¶nersek, Kaggleâ€™da dÃ¼zenlenen yarÄ±ÅŸmalarda en popÃ¼ler deÄŸerlendirme metriklerini inceleyebiliriz:

* Ä°lk iki metrik birbirine ve ikili olasÄ±lÄ±k sÄ±nÄ±flandÄ±rma problemlerine yakÄ±ndan iliÅŸkilidir. AUC metriÄŸi, modelinizin tahmin ettiÄŸi olasÄ±lÄ±klarÄ±n pozitif Ã¶rnekleri yÃ¼ksek olasÄ±lÄ±kla tahmin etme eÄŸilimini Ã¶lÃ§meye yardÄ±mcÄ± olur. Log Loss ise tahmin edilen olasÄ±lÄ±klarÄ±n gerÃ§ek deÄŸerlerden ne kadar uzak olduÄŸunu Ã¶lÃ§er (ve Log Lossâ€™u optimize ettikÃ§e AUC metriÄŸini de optimize etmiÅŸ olursunuz).
* 3\. sÄ±rada MAP@{K} bulunur; bu metrik Ã¶neri sistemleri ve arama motorlarÄ±nda yaygÄ±n olarak kullanÄ±lÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda bu metrik, Ã§oÄŸunlukla bilgi getirme (information retrieval) deÄŸerlendirmeleri iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Ã–rneÄŸin, **Humpback Whale Identification** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/humpback-whale-identification](https://www.kaggle.com/c/humpback-whale-identification)) bir balinayÄ± tam olarak tanÄ±mlamanÄ±z gerekir ve beÅŸ tahmin hakkÄ±nÄ±z vardÄ±r. BaÅŸka bir Ã¶rnek, **Quick, Draw! Doodle Recognition Challenge** yarÄ±ÅŸmasÄ±dÄ±r ([https://www.kaggle.com/c/quickdraw-doodle-recognition/](https://www.kaggle.com/c/quickdraw-doodle-recognition/)), burada Ã§izilen bir karenin iÃ§eriÄŸini tahmin etmeniz gerekir ve Ã¼Ã§ deneme hakkÄ±nÄ±z vardÄ±r. Temelde, MAP@{K} metriÄŸi kullanÄ±ldÄ±ÄŸÄ±nda, sadece doÄŸru tahmin yapÄ±p yapmadÄ±ÄŸÄ±nÄ±z deÄŸil, aynÄ± zamanda doÄŸru tahmininizin belirli bir sayÄ±da (â€œKâ€ adÄ±yla belirtilen) yanlÄ±ÅŸ tahmin arasÄ±nda olup olmadÄ±ÄŸÄ± da deÄŸerlendirilir.
* 6\. sÄ±rada bir regresyon metriÄŸi olan RMSLE (Root Mean Squared Logarithmic Error) yer alÄ±r ve 7. sÄ±rada Quadratic Weighted Kappa bulunur; bu metrik, ardÄ±ÅŸÄ±k tamsayÄ± tahminleri gerektiren problemler (ordinal Ã¶lÃ§ek problemleri) iÃ§in Ã¶zellikle faydalÄ±dÄ±r.

Listeye gÃ¶z attÄ±ÄŸÄ±nÄ±zda, karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z metriklerin Ã§oÄŸunun makine Ã¶ÄŸrenmesi ders kitaplarÄ±nda sÄ±kÃ§a tartÄ±ÅŸÄ±lan metrikler olduÄŸunu gÃ¶receksiniz. Ã–nÃ¼mÃ¼zdeki birkaÃ§ bÃ¶lÃ¼mde, daha Ã¶nce hiÃ§ karÅŸÄ±laÅŸmadÄ±ÄŸÄ±nÄ±z bir metriÄŸi gÃ¶rdÃ¼ÄŸÃ¼nÃ¼zde ne yapmanÄ±z gerektiÄŸini tartÄ±ÅŸtÄ±ktan sonra, regresyon ve sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmalarÄ±nda en yaygÄ±n olarak kullanÄ±lan metrikleri gÃ¶zden geÃ§ireceÄŸiz.

### Handling never-before-seen metrics *(Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerle baÅŸa Ã§Ä±kma)*

Ä°lerlemeye baÅŸlamadan Ã¶nce, en popÃ¼ler 20 metriÄŸi gÃ¶steren tablonun yarÄ±ÅŸmalarda kullanÄ±lan tÃ¼m metrikleri kapsamadÄ±ÄŸÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±yÄ±z. Son yÄ±llarda yalnÄ±zca bir kez kullanÄ±lmÄ±ÅŸ metrikler de vardÄ±r.

**YarÄ±ÅŸma GÃ¶revleri ve Metrikler**

Ã–nceki kod sonuÃ§larÄ±nÄ± kullanarak, bu nadir kullanÄ±lan metriklerin neler olduÄŸunu bulmaya devam edelim:

```python
counts = (df[time_select & competition_type_select]
          .groupby('EvaluationAlgorithmAbbreviation'))
total_comps_per_year = (df[time_select & competition_type_select]
                        .groupby('year').sum())
single_metrics_per_year = (counts.sum()[counts.sum().comps == 1]
                           .groupby('year').sum())
single_metrics_per_year
table = (total_comps_per_year.rename(columns={'comps': 'n_comps'})
         .join(single_metrics_per_year / total_comps_per_year)
         .rename(columns={'comps': 'pct_comps'}))
print(table)
```

SonuÃ§ olarak, her yÄ±l iÃ§in aÅŸaÄŸÄ±daki tabloyu elde ederiz. Bu tabloda, her yÄ±l kaÃ§ yarÄ±ÅŸmanÄ±n daha sonra bir daha kullanÄ±lmamÄ±ÅŸ bir metrik kullandÄ±ÄŸÄ±nÄ± (`n_comps`) ve bu yarÄ±ÅŸmalarÄ±n toplam yarÄ±ÅŸmalara oranÄ±nÄ± (`pct_comps`) gÃ¶rebiliriz:

| year | n_comps | pct_comps |
| ---- | ------- | --------- |
| 2015 | 28      | 0.179     |
| 2016 | 19      | 0.158     |
| 2017 | 34      | 0.177     |
| 2018 | 35      | 0.229     |
| 2019 | 36      | 0.278     |
| 2020 | 43      | 0.302     |
| 2021 | 8       | 0.250     |

Daha sonra bir daha kullanÄ±lmamÄ±ÅŸ metriklerin payÄ±na baktÄ±ÄŸÄ±mÄ±zda, bu oranÄ±n yÄ±l geÃ§tikÃ§e arttÄ±ÄŸÄ±nÄ± ve son yÄ±llarda %25â€“%30 seviyelerine ulaÅŸtÄ±ÄŸÄ±nÄ± hemen fark ederiz. Bu, genellikle her Ã¼Ã§ veya dÃ¶rt yarÄ±ÅŸmadan birinin size metrikleri baÅŸtan Ã¶ÄŸrenip anlamayÄ± gerektirdiÄŸini gÃ¶sterir.

GeÃ§miÅŸte kullanÄ±lmÄ±ÅŸ ve bir daha tekrar edilmeyen metriklerin listesini ÅŸu kÄ±sa kodla alabilirsiniz:

```python
print(counts.sum()[counts.sum().comps == 1].index.values)
```

Bu kodu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, benzer bir liste elde edersiniz:

```
['AHD@{Type}', 'CVPRAutoDrivingAveragePrecision', 'CernWeightedAuc',
 'FScore_1', 'GroupMeanLogMAE', 'ImageNetObjectLocalization',
 'IndoorLocalization', 'IntersectionOverUnionObjectSegmentationBeta',
 'IntersectionOverUnionObjectSegmentationWithClassification',
 'IntersectionOverUnionObjectSegmentationWithF1', 'Jaccard',
 'JaccardDSTLParallel', 'JigsawBiasAUC', 'LaplaceLogLikelihood',
 'LevenshteinMean', 'Lyft3DObjectDetectionAP', 'M5_WRMSSE', 'MASpearmanR',
 'MCRMSE', 'MCSpearmanR', 'MWCRMSE', 'MeanColumnwiseLogLoss',
 'MulticlassLossOld', 'NDCG@{K}', 'NQMicroF1', 'NWRMSLE', 'PKUAutoDrivingAP',
 'R2Score', 'RValue', 'RootMeanSquarePercentageError', 'SIIMDice', 'SMAPE',
 'SantaResident', 'SantaRideShare', 'SantaWorkshopSchedule2019', 'TrackML',
 'TravelingSanta2', 'TwoSigmaNews', 'WeightedAUC', 'WeightedMulticlassLoss',
 'WeightedPinballLoss', 'WeightedRowwisePinballLoss', 'YT8M_MeanAveragePrecisionAtK',
 'ZillowMAE', 'football', 'halite', 'mab']
```

YakÄ±ndan incelendiÄŸinde, listede derin Ã¶ÄŸrenme ve pekiÅŸtirmeli Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ±na iliÅŸkin birÃ§ok metrik bulabilirsiniz.

Peki, daha Ã¶nce hiÃ§ karÅŸÄ±laÅŸmadÄ±ÄŸÄ±nÄ±z bir metrikle karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda ne yapmalÄ±sÄ±nÄ±z?

* Tabii ki, Kaggle tartÄ±ÅŸma forumlarÄ±ndaki paylaÅŸÄ±mlara gÃ¼venebilirsiniz; burada her zaman iyi fikirler ve size yardÄ±mcÄ± olacak birÃ§ok Kaggle katÄ±lÄ±mcÄ±sÄ± bulabilirsiniz.
* Ancak metriÄŸi kendi baÅŸÄ±nÄ±za anlamak istiyorsanÄ±z, Googleâ€™da arama yapmanÄ±n yanÄ± sÄ±ra, deÄŸerlendirme fonksiyonunu kendi kodunuzla denemeyi tavsiye ederiz. Bunu mÃ¼kemmel olmasa bile yapabilir, modelin farklÄ± hata tÃ¼rlerine karÅŸÄ± metrik nasÄ±l tepki veriyor simÃ¼le edebilirsiniz. AyrÄ±ca metrik fonksiyonunu yarÄ±ÅŸma eÄŸitim verisi Ã¶rnekleri Ã¼zerinde veya sizin hazÄ±rladÄ±ÄŸÄ±nÄ±z sentetik veri Ã¼zerinde test edebilirsiniz.

BazÄ± Kaggle kullanÄ±cÄ±larÄ±nÄ±n bu yaklaÅŸÄ±mÄ± nasÄ±l kullandÄ±ÄŸÄ±na Ã¶rnekler:

* **Carlo Lepelaars** ile Spearmanâ€™s Rho: [Link](https://www.kaggle.com/carlolepelaars/understanding-the-metric-spearman-s-rho)
* **Carlo Lepelaars** ile Quadratic Weighted Kappa: [Link](https://www.kaggle.com/carlolepelaars/understanding-the-metric-quadratic-weighted-kappa)
* **Rohan Rao** ile Laplace Log Likelihood: [Link](https://www.kaggle.com/rohanrao/osic-understanding-laplace-log-likelihood)

Bu yaklaÅŸÄ±m, deÄŸerlendirme sÃ¼reci hakkÄ±nda daha derin bir anlayÄ±ÅŸ kazandÄ±rÄ±r ve sadece Google ve forumlardan gelen cevaplara gÃ¼venen rakiplere karÅŸÄ± size avantaj saÄŸlar.

> **Rohan Rao**
> 
> [Kaggle Profili](https://www.kaggle.com/rohanrao)
> 
> 
> 
> FarklÄ± metrikleri keÅŸfetmeye baÅŸlamadan Ã¶nce, Quadruple Grandmaster ve H2O.aiâ€™de KÄ±demli Veri Bilimcisi olan Rohan Rao (namÄ± diÄŸer Vopani) ile Kaggleâ€™daki baÅŸarÄ±larÄ±nÄ± ve bizlerle paylaÅŸmak istediÄŸi bilgeliÄŸi konuÅŸalÄ±m.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±ÄŸÄ±nÄ±z nedir?**
> 
> FarklÄ± yarÄ±ÅŸma tÃ¼rleriyle ilgilenmeyi seviyorum, ama en favorim kesinlikle zaman serisi yarÄ±ÅŸmalarÄ±. EndÃ¼strideki tipik zaman serisi yaklaÅŸÄ±mlarÄ±nÄ± ve kavramlarÄ±nÄ± pek sevmiyorum, bu yÃ¼zden Ã§Ã¶zÃ¼mleri alÄ±ÅŸÄ±lmÄ±ÅŸÄ±n dÄ±ÅŸÄ±nda, yenilikÃ§i bir ÅŸekilde kurmayÄ± tercih ediyorum ve bu bana Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar getirdi.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±?**
> 
> Her Kaggle yarÄ±ÅŸmasÄ± iÃ§in tipik iÅŸ akÄ±ÅŸÄ±m ÅŸÃ¶yle:
> 
> 
> 
> * Problem tanÄ±mÄ±nÄ± anlamak ve kurallar, format, zaman Ã§izelgesi, veri setleri, metrikler ve teslimatlar ile ilgili tÃ¼m bilgileri okumak.
> 
> * Veriye derinlemesine dalmak. Veriyi her aÃ§Ä±dan inceleyip dilimleyip gÃ¶rselleÅŸtirerek her tÃ¼rlÃ¼ soruya cevap verebilecek hÃ¢le gelmek.
> 
> * Basit bir pipeline ve temel bir model kurup, sÃ¼recin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrulamak iÃ§in bir gÃ¶nderim yapmak.
> 
> * Ã–zellik mÃ¼hendisliÄŸi yapmak, hiperparametreleri ayarlamak ve hangi modellerin genellikle iÅŸe yaradÄ±ÄŸÄ±nÄ± anlamak iÃ§in Ã§eÅŸitli modellerle denemeler yapmak.
> 
> * Veriyi analiz etmeye, forum tartÄ±ÅŸmalarÄ±nÄ± okumaya ve Ã¶zellikleri ile modelleri sÃ¼rekli olarak geliÅŸtirmeye devam etmek. Belki bir noktada ekip kurmak.
> 
> * Birden fazla modeli ensemble yapmak ve hangi gÃ¶nderimleri final olarak kullanacaÄŸÄ±nÄ±za karar vermek.
> 
> 
> 
> GÃ¼nlÃ¼k veri bilimi Ã§alÄ±ÅŸmalarÄ±mda bunlarÄ±n Ã§oÄŸu da gerÃ§ekleÅŸiyor. Ama ek olarak iki kritik unsur var:
> 
> 
> 
> * Problem tanÄ±mÄ± iÃ§in veri setlerini hazÄ±rlamak ve dÃ¼zenlemek.
> 
> * Nihai model veya Ã§Ã¶zÃ¼mÃ¼ Ã¼retime almak.
> 
> 
> 
> GeÃ§miÅŸte Ã§alÄ±ÅŸtÄ±ÄŸÄ±m projelerin Ã§oÄŸunda zamanÄ±mÄ±n bÃ¼yÃ¼k kÄ±smÄ± bu iki aktiviteye harcandÄ±.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? Olduysa nasÄ±l?**
> 
> Makine Ã¶ÄŸrenmesinde Ã¶ÄŸrendiÄŸim ÅŸeylerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu Kaggleâ€™dan geldi. Topluluk, platform ve iÃ§erik gerÃ§ekten paha biÃ§ilemez; Ã¶ÄŸrenilecek inanÄ±lmaz miktarda bilgi var.
> 
> Kaggle yarÄ±ÅŸmalarÄ±na katÄ±lmak, sorunlarÄ± anlamak, yapÄ±landÄ±rmak ve Ã§Ã¶zmek konusunda bana bÃ¼yÃ¼k gÃ¼ven kazandÄ±rdÄ±. Bu deneyimi, Kaggle dÄ±ÅŸÄ±nda Ã§alÄ±ÅŸtÄ±ÄŸÄ±m ÅŸirketler ve projelerde baÅŸarÄ±yla uygulayabildim.
> 
> BirÃ§ok iÅŸe alÄ±m gÃ¶revlisi, Kaggleâ€™daki baÅŸarÄ±larÄ±mÄ± (Ã¶zellikle yarÄ±ÅŸmalarda) gÃ¶rerek benimle iletiÅŸime geÃ§ti. Bu, adayÄ±n veri bilimi problemlerini Ã§Ã¶zme yeteneÄŸini gÃ¶steren iyi bir gÃ¶stergedir ve yeteneklerinizi sergilemek ve portfÃ¶y oluÅŸturmak iÃ§in harika bir platformdur.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar oldu mu?**
> 
> Her yarÄ±ÅŸmada bazÄ± hatalar yaptÄ±m! BÃ¶ylece Ã¶ÄŸrenip geliÅŸiyorsunuz. Bazen bir kod hatasÄ±, bazen yanlÄ±ÅŸ bir doÄŸrulama kurulumu, bazen de yanlÄ±ÅŸ bir gÃ¶nderim seÃ§imi olabiliyor.
> 
> Ã–nemli olan bu hatalardan ders almak ve tekrar etmemeyi saÄŸlamaktÄ±r. Bu sÃ¼reci tekrar etmek, Kaggleâ€™daki genel performansÄ±nÄ±zÄ± otomatik olarak artÄ±rÄ±r.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> HiÃ§bir teknolojiye â€œbaÄŸlanmamakâ€ gerektiÄŸine inanÄ±yorum. En iyi Ã§alÄ±ÅŸan, en rahat ve en etkili olanÄ± kullanÄ±n, ama sÃ¼rekli olarak yeni araÃ§lar ve kÃ¼tÃ¼phaneler Ã¶ÄŸrenmeye aÃ§Ä±k olun.

### Metrics for regression (standard and ordinal) *(Regresyon iÃ§in metrikler - standart ve sÄ±ralÄ±)*

Regresyon problemleriyle Ã§alÄ±ÅŸÄ±rken, yani sÃ¼rekli bir deÄŸeri tahmin etmeyi gerektiren (eksi sonsuzdan artÄ± sonsuza kadar deÄŸiÅŸebilen) problemlerle uÄŸraÅŸÄ±rken, en yaygÄ±n kullanÄ±lan hata Ã¶lÃ§Ã¼leri RMSE (karekÃ¶k ortalama kare hata) ve MAE (ortalama mutlak hata) yÃ¶ntemleridir. Ancak, RMSLE veya MCRMSLE gibi biraz farklÄ± hata Ã¶lÃ§Ã¼leri de faydalÄ± olabilir.

#### Mean squared error (MSE) and RÂ² *(Ortalama kare hata (MSE) ve RÂ²)*

KarekÃ¶k ortalama kare hata (RMSE), ortalama kare hatanÄ±n (MSE) karekÃ¶kÃ¼dÃ¼r. MSE, aslÄ±nda regresyon Ã§alÄ±ÅŸmasÄ±nÄ± Ã¶ÄŸrenirken tanÄ±ÅŸtÄ±ÄŸÄ±nÄ±z eski iyi hata kareleri toplamÄ±nÄ±n (SSE) ortalamasÄ±ndan baÅŸka bir ÅŸey deÄŸildir.

**MSE formÃ¼lÃ¼ ÅŸu ÅŸekildedir:**

$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (\hat{y_i} - y_i)^2
$$

FormÃ¼lÃ¼n iÅŸleyiÅŸini aÃ§Ä±klayalÄ±m:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.
* Ã–nce tahminler ile gerÃ§ek deÄŸerler arasÄ±ndaki farkÄ± alÄ±rsÄ±nÄ±z.
* FarklarÄ± kareye alÄ±rsÄ±nÄ±z (pozitif ya da sÄ±fÄ±r olur).
* TÃ¼m kareleri toplarsÄ±nÄ±z; iÅŸte bu sizin SSEâ€™nizdir.
* Son olarak, SSEâ€™yi tahmin sayÄ±sÄ±na bÃ¶lerek ortalama deÄŸeri (MSE) elde edersiniz.

Genellikle tÃ¼m regresyon modelleri SSEâ€™yi minimize eder, bu yÃ¼zden MSEâ€™yi veya MSEâ€™den tÃ¼retilmiÅŸ RÂ² (determinasyon katsayÄ±sÄ±) gibi metrikleri minimize etmekte bÃ¼yÃ¼k sorun yaÅŸamazsÄ±nÄ±z. RÂ² ÅŸÃ¶yle hesaplanÄ±r:

$$
R^2 = 1 - \frac{\sum_{i=1}^{n} (\hat{y_i} - y_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

Burada SSE (hata kareleri toplamÄ±), toplam kareler toplamÄ±na (SST) karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r. SST, aslÄ±nda hedef deÄŸiÅŸkenin varyansÄ±dÄ±r ve ÅŸu ÅŸekilde tanÄ±mlanÄ±r:

$$
SST = \sum_{i=1}^{n} (y_i - \bar{y})^2
$$

BaÅŸka bir deyiÅŸle, RÂ² modelin hata karelerini, en basit model olan hedefin ortalamasÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±r. SSE ve SST aynÄ± Ã¶lÃ§eÄŸe sahip olduÄŸu iÃ§in RÂ², hedef deÄŸiÅŸkeni dÃ¶nÃ¼ÅŸtÃ¼rmenin tahminleri iyileÅŸtirip iyileÅŸtirmediÄŸini anlamanÄ±za yardÄ±mcÄ± olabilir.

> UnutmayÄ±n: min-max Ã¶lÃ§ekleme veya standardizasyon gibi lineer dÃ¶nÃ¼ÅŸÃ¼mler, herhangi bir regresyon modelinin performansÄ±nÄ± deÄŸiÅŸtirmez; Ã§Ã¼nkÃ¼ bunlar hedefin lineer dÃ¶nÃ¼ÅŸÃ¼mÃ¼dÃ¼r. Ancak karekÃ¶k, kÃ¼p kÃ¶k, logaritma, Ã¼s alma gibi **lineer olmayan dÃ¶nÃ¼ÅŸÃ¼mler** ve bunlarÄ±n kombinasyonlarÄ±, regresyon modelinizin deÄŸerlendirme metriÄŸi Ã¼zerindeki performansÄ±nÄ± kesinlikle deÄŸiÅŸtirebilir (doÄŸru dÃ¶nÃ¼ÅŸÃ¼mÃ¼ seÃ§erseniz genellikle daha iyi olur).

MSE, aynÄ± probleme uygulanan regresyon modellerini karÅŸÄ±laÅŸtÄ±rmak iÃ§in mÃ¼kemmel bir araÃ§tÄ±r. Ancak kÃ¶tÃ¼ haber ÅŸu ki, Kaggle yarÄ±ÅŸmalarÄ±nda genellikle MSE kullanÄ±lmaz; RMSE tercih edilir. Ã‡Ã¼nkÃ¼ MSEâ€™nin karekÃ¶kÃ¼nÃ¼ almak, deÄŸerleri hedefin orijinal Ã¶lÃ§eÄŸine yaklaÅŸtÄ±rÄ±r ve modelinizin performansÄ±nÄ± gÃ¶zle kontrol etmek kolaylaÅŸÄ±r. AyrÄ±ca, farklÄ± veri problemleri veya yarÄ±ÅŸmalar arasÄ±nda aynÄ± regresyon modelini deÄŸerlendiriyorsanÄ±z, RÂ² daha kullanÄ±ÅŸlÄ±dÄ±r; Ã§Ã¼nkÃ¼ MSE ile tamamen iliÅŸkili olup 0 ile 1 arasÄ±nda deÄŸer alÄ±r ve tÃ¼m karÅŸÄ±laÅŸtÄ±rmalarÄ± kolaylaÅŸtÄ±rÄ±r.

#### Root mean squared error (RMSE) *(KÃ¶k ortalama kare hata (RMSE))*

RMSE (KarekÃ¶k Ortalama Kare Hata), MSEâ€™nin karekÃ¶kÃ¼ olmakla birlikte bazÄ± ince farklÄ±lÄ±klar ortaya Ã§Ä±kar. FormÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{y_i} - y_i)^2}
$$

Bu formÃ¼lde:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.

MSEâ€™de, bÃ¼yÃ¼k tahmin hatalarÄ± kare alma iÅŸlemi nedeniyle Ã§ok fazla cezalandÄ±rÄ±lÄ±r. RMSEâ€™de ise bu etki karekÃ¶k sayesinde biraz azaltÄ±lÄ±r. Ancak yine de uÃ§ deÄŸerler (outlier) performansÄ± ciddi ÅŸekilde etkileyebilir; MSE veya RMSE ile deÄŸerlendiriyor olmanÄ±z fark etmez.

SonuÃ§ olarak, probleme baÄŸlÄ± olarak, MSEâ€™yi hedef fonksiyonu olarak kullanan bir algoritmayla daha iyi bir uyum elde edebilirsiniz. Bunun iÃ§in Ã¶nce hedef deÄŸiÅŸkenin karekÃ¶kÃ¼nÃ¼ almak (pozitif deÄŸerler gerektirir), ardÄ±ndan sonuÃ§larÄ± kareye almak iÅŸe yarayabilir. Scikit-learnâ€™daki **TransformedTargetRegressor** gibi fonksiyonlar, regresyon hedefinizi uygun ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rmenize yardÄ±mcÄ± olarak deÄŸerlendirme metriÄŸinize gÃ¶re daha iyi uyumlu sonuÃ§lar almanÄ±zÄ± saÄŸlar.

> Son zamanlarda RMSEâ€™nin kullanÄ±ldÄ±ÄŸÄ± bazÄ± yarÄ±ÅŸmalar ÅŸunlardÄ±r:
> 
> 
> 
> * **Avito Demand Prediction Challenge**: [Kaggle linki](https://www.kaggle.com/c/avitodemand-prediction)
> 
> * **Google Analytics Customer Revenue Prediction**: [Kaggle linki](https://www.kaggle.com/c/ga-customer-revenue-prediction)
> 
> * **Elo Merchant Category Recommendation**: [Kaggle linki](https://www.kaggle.com/c/elo-merchant-category-recommendation)

#### Root mean squared log error (RMSLE) *(KÃ¶k ortalama log kare hata (RMSLE))*

MSEâ€™nin bir diÄŸer yaygÄ±n dÃ¶nÃ¼ÅŸÃ¼mÃ¼, **karekÃ¶k ortalama log hatasÄ± (RMSLE)**â€™dir. **MCRMSLE**, COVID-19 tahmin yarÄ±ÅŸmalarÄ±nda popÃ¼ler olan bir varyanttÄ±r ve birden fazla hedef deÄŸiÅŸken olduÄŸunda her bir hedefin RMSLE deÄŸerlerinin sÃ¼tun bazÄ±nda ortalamasÄ±nÄ± alÄ±r.

RMSLE formÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
RMSLE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\log(\hat{y_i}+1) - \log(y_i+1))^2}
$$

FormÃ¼lde:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.

Logaritmik dÃ¶nÃ¼ÅŸÃ¼m, tahminlerinize ve gerÃ§ek deÄŸerlere uygulanÄ±r; ardÄ±ndan kare alma, ortalama alma ve karekÃ¶k iÅŸlemleri yapÄ±lÄ±r. Bu sayede, Ã¶zellikle bÃ¼yÃ¼k deÄŸerler iÃ§in tahmin edilen ve gerÃ§ek deÄŸerler arasÄ±ndaki bÃ¼yÃ¼k farklar Ã§ok fazla cezalandÄ±rÄ±lmaz. Yani RMSLE kullanÄ±rken en Ã§ok Ã¶nem verdiÄŸiniz ÅŸey, tahminlerinizin Ã¶lÃ§eÄŸinin gerÃ§ek deÄŸerlerin Ã¶lÃ§eÄŸiyle ne kadar uyumlu olduÄŸudur.

RMSEâ€™de olduÄŸu gibi, regresyon algoritmalarÄ± RMSLEâ€™yi daha iyi optimize edebilir. Bunun iÃ§in hedef deÄŸiÅŸkene logaritmik dÃ¶nÃ¼ÅŸÃ¼m uygulayÄ±p modeli eÄŸitmek ve ardÄ±ndan ters dÃ¶nÃ¼ÅŸÃ¼m olarak Ã¼stel fonksiyonu kullanmak gerekir.

> Son dÃ¶nemde RMSLE kullanÄ±lan bazÄ± Kaggle yarÄ±ÅŸmalarÄ±:
> 
> 
> 
> * **ASHRAE - Great Energy Predictor III**: [Kaggle linki](https://www.kaggle.com/c/ashrae-energy-prediction)
> 
> * **Santander Value Prediction Challenge**: [Kaggle linki](https://www.kaggle.com/c/santander-value-prediction-challenge)
> 
> * **Mercari Price Suggestion Challenge**: [Kaggle linki](https://www.kaggle.com/c/mercari-price-suggestion-challenge)
> 
> * **Sberbank Russian Housing Market**: [Kaggle linki](https://www.kaggle.com/olgabelitskaya/sberbank-russian-housing-market)
> 
> * **Recruit Restaurant Visitor Forecasting**: [Kaggle linki](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting)

Åu anda, Kaggle yarÄ±ÅŸmalarÄ±nda regresyon iÃ§in en yaygÄ±n kullanÄ±lan deÄŸerlendirme metriÄŸi **RMSLE**â€™dir.

#### Mean absolute error (MAE) *(Ortalama mutlak hata (MAE))*

**MAE (Mean Absolute Error â€“ Ortalama Mutlak Hata)**, tahminler ile gerÃ§ek deÄŸerler arasÄ±ndaki farkÄ±n **mutlak deÄŸerini** alÄ±r. FormÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |\hat{y_i} - y_i|
$$

FormÃ¼lde:

* ($n$) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir,
* ($y_i$) gerÃ§ek deÄŸer (ground truth),
* ($\hat{y_i}$) modelin tahminidir.

**Ã–zellikleri ve avantajlarÄ±:**

* MAE, **outlierâ€™lara (aykÄ±rÄ± deÄŸerlere) karÅŸÄ± duyarlÄ± deÄŸildir**, Ã§Ã¼nkÃ¼ hatalar karelenmez. Bu nedenle outlier iÃ§eren veri setlerinde MAE sÄ±klÄ±kla tercih edilen bir deÄŸerlendirme metriÄŸidir.
* BirÃ§ok algoritma, MAEâ€™yi doÄŸrudan **objective function** olarak kullanabilir. EÄŸer algoritma bunu doÄŸrudan desteklemiyorsa, hedef deÄŸiÅŸkene karekÃ¶k uygulayÄ±p ardÄ±ndan tahminleri karesini alarak dolaylÄ± optimizasyon yapÄ±labilir.

**DezavantajlarÄ±:**

* MAE ile optimize etmek, daha yavaÅŸ **convergence** (yakÄ±nsama) saÄŸlar. Bunun nedeni, MAE ile aslÄ±nda hedefin ortalamasÄ± yerine **medyanÄ±nÄ±** tahmin etmeye Ã§alÄ±ÅŸmanÄ±zdÄ±r (L1 normu). Oysa MSE ile optimize edildiÄŸinde hedefin ortalamasÄ± (L2 normu) minimize edilir.
* Bu durum optimizasyon sÃ¼recini daha karmaÅŸÄ±k hale getirir ve eÄŸitim sÃ¼resi, gÃ¶zlem sayÄ±sÄ±na baÄŸlÄ± olarak Ã¼stel biÃ§imde artabilir. Ã–rneÄŸin, MAE kriteri ile bir Random Forest regressor eÄŸitmek, MSE kriterine gÃ¶re Ã§ok daha yavaÅŸ olabilir ([Stack Overflow Ã¶rneÄŸi](https://stackoverflow.com/questions/57243267/why-is-training-a-random-forest-regressor-with-mae-criterion-so-slow-compared-to)).

> **MAE kullanÄ±lan Ã¶nemli yarÄ±ÅŸmalar:**
> 
> 
> 
> * **LANL Earthquake Prediction**: [Kaggle linki](https://www.kaggle.com/c/LANL-Earthquake-Prediction)
> 
> * **How Much Did It Rain? II**: [Kaggle linki](https://www.kaggle.com/c/how-much-did-it-rain-ii)

Tahmin yarÄ±ÅŸmalarÄ±nda (forecasting competitions), kullanÄ±lan regresyon Ã¶lÃ§Ã¼tleri bÃ¼yÃ¼k Ã¶lÃ§Ã¼de benzerdir. Ã–rneÄŸin:

* **M5 Forecasting Competition**: [Link](https://mofc.unic.ac.cy/m5-competition/)
* DiÄŸer M serisi yarÄ±ÅŸmalar: [Hyndsight Ã¶zetleri](https://robjhyndman.com/hyndsight/forecasting-competitions/)

Forecasting yarÄ±ÅŸmalarÄ±nda bazen daha Ã¶zel Ã¶lÃ§Ã¼tler de kullanÄ±lÄ±r, Ã¶rneÄŸin:

* **Weighted Root Mean Squared Scaled Error (WRMSSE)**: [Kaggle linki](https://www.kaggle.com/c/m5-forecasting-accuracy/overview/evaluation)
* **Symmetric Mean Absolute Percentage Error (sMAPE)**: [Kaggle linki](https://www.kaggle.com/c/demand-forecasting-kernels-only/overview/evaluation)

Ancak, temel olarak bunlar RMSE veya MAEâ€™nin varyasyonlarÄ±dÄ±r ve doÄŸru hedef dÃ¶nÃ¼ÅŸÃ¼mleri ile yÃ¶netilebilirler.

### Metrics for classification (label prediction and probability) *(SÄ±nÄ±flandÄ±rma metrikleri - etiket tahmini ve olasÄ±lÄ±k)*

Regresyon problemleri iÃ§in metrikleri tartÄ±ÅŸtÄ±ktan sonra, ÅŸimdi sÄ±nÄ±flandÄ±rma problemleri iÃ§in metrikleri aÃ§Ä±klamaya geÃ§iyoruz; Ã¶nce ikili sÄ±nÄ±flandÄ±rma problemlerinden baÅŸlÄ±yoruz (iki sÄ±nÄ±ftan birini tahmin etmeniz gerektiÄŸinde), sonra Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmaya (iki sÄ±nÄ±ftan fazla olduÄŸunda) ve en sonunda Ã§ok etiketli sÄ±nÄ±flandÄ±rmaya (sÄ±nÄ±flarÄ±n birbirinin Ã¼zerine bindiÄŸi durumlarda).

#### Accuracy *(DoÄŸruluk)*

Ä°kili bir sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n performansÄ±nÄ± analiz ederken, en yaygÄ±n ve eriÅŸilebilir metrik **doÄŸruluk (accuracy)** olarak kullanÄ±lÄ±r. **YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma hatasÄ±**, modelinizin bir Ã¶rnek iÃ§in yanlÄ±ÅŸ sÄ±nÄ±fÄ± tahmin etmesi durumudur. DoÄŸruluk ise yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma hatasÄ±nÄ±n tamamlayÄ±cÄ±sÄ±dÄ±r ve doÄŸru tahmin edilen Ã¶rneklerin sayÄ±sÄ±nÄ±n toplam tahmin sayÄ±sÄ±na bÃ¶lÃ¼nmesiyle hesaplanabilir:

$$
\text{Accuracy} = \frac{\text{Correct Answers}}{\text{Total Answers}}
$$

> Bu metrik, Ã¶rneÄŸin **Cassava Leaf Disease Classification** ([https://www.kaggle.com/c/cassava-leaf-disease-classification](https://www.kaggle.com/c/cassava-leaf-disease-classification)) ve **Text Normalization Challenge - English Language** ([https://www.kaggle.com/c/text-normalization-challenge-english-language](https://www.kaggle.com/c/text-normalization-challenge-english-language)) gibi yarÄ±ÅŸmalarda kullanÄ±lmÄ±ÅŸtÄ±r. Bu yarÄ±ÅŸmalarda doÄŸru bir tahmin, yalnÄ±zca tahmin edilen metin gerÃ§ek metinle tamamen eÅŸleÅŸtiÄŸinde sayÄ±lmÄ±ÅŸtÄ±r.

Bir metrik olarak doÄŸruluk, modelin gerÃ§ek dÃ¼nyadaki etkili performansÄ±na gÃ¼Ã§lÃ¼ bir ÅŸekilde odaklanÄ±r; modelin beklendiÄŸi gibi Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± gÃ¶sterir. Ancak, eÄŸer amacÄ±nÄ±z modeli deÄŸerlendirmek, karÅŸÄ±laÅŸtÄ±rmak ve yaklaÅŸÄ±mÄ±nÄ±zÄ±n gerÃ§ekten ne kadar etkili olduÄŸunu net bir ÅŸekilde gÃ¶rmekse, doÄŸruluÄŸu kullanÄ±rken dikkatli olmanÄ±z gerekir. Ã‡Ã¼nkÃ¼ sÄ±nÄ±flar **dengesiz** olduÄŸunda (farklÄ± frekanslara sahip olduÄŸunda) yanlÄ±ÅŸ sonuÃ§lara yol aÃ§abilir. Ã–rneÄŸin, bir sÄ±nÄ±f verinin yalnÄ±zca %10â€™unu oluÅŸturuyorsa, yalnÄ±zca Ã§oÄŸunluk sÄ±nÄ±fÄ±nÄ± tahmin eden bir model %90 doÄŸruluk gÃ¶sterebilir; yÃ¼ksek doÄŸruluk gÃ¶rÃ¼nmesine raÄŸmen oldukÃ§a iÅŸe yaramaz olur.

BÃ¶yle bir problemi nasÄ±l fark edebilirsiniz? Bunu **karÄ±ÅŸÄ±klÄ±k matrisi (confusion matrix)** kullanarak kolayca gÃ¶rebilirsiniz. KarÄ±ÅŸÄ±klÄ±k matrisinde, gerÃ§ek sÄ±nÄ±flar satÄ±rlara, tahmin edilen sÄ±nÄ±flar sÃ¼tunlara yerleÅŸtirilerek iki yÃ¶nlÃ¼ bir tablo oluÅŸturulur. Scikit-learnâ€™Ã¼n **confusion_matrix** fonksiyonu ile basitÃ§e oluÅŸturabilirsiniz:

```python
sklearn.metrics.confusion_matrix(
    y_true, y_pred, *, labels=None, sample_weight=None,
    normalize=None
)
```

Sadece **y_true** ve **y_pred** vektÃ¶rlerini saÄŸlamak anlamlÄ± bir tablo oluÅŸturmak iÃ§in yeterlidir, fakat satÄ±r/sÃ¼tun etiketleri, Ã¶rnekler iÃ§in aÄŸÄ±rlÄ±klar ve normalize etme seÃ§enekleri de eklenebilir. Normalize iÅŸlemi, gerÃ§ek Ã¶rnekler (satÄ±rlar), tahmin edilen Ã¶rnekler (sÃ¼tunlar) veya tÃ¼m Ã¶rnekler Ã¼zerinde yapÄ±labilir.

MÃ¼kemmel bir sÄ±nÄ±flandÄ±rÄ±cÄ±, tÃ¼m Ã¶rnekleri matrisin ana kÃ¶ÅŸegeninde toplar. EÄŸer kÃ¶ÅŸegendeki hÃ¼crelerde Ã§ok az veya hiÃ§ Ã¶rnek yoksa, bu durum tahminleyicinin geÃ§erliliÄŸiyle ilgili ciddi sorunlarÄ± gÃ¶sterir.

NasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha iyi anlamak iÃ§in Scikit-learn tarafÄ±ndan sunulan grafiksel Ã¶rneÄŸi inceleyebilirsiniz:
[Scikit-learn plot_confusion_matrix Ã¶rneÄŸi](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)

![](im/1043.png)

DoÄŸruluÄŸun kullanÄ±labilirliÄŸini artÄ±rmak iÃ§in, her sÄ±nÄ±fa gÃ¶re doÄŸruluÄŸu dikkate alÄ±p bunlarÄ±n ortalamasÄ±nÄ± almayÄ± deneyebilirsiniz; ancak, **precision (kesinlik)**, **recall (duyarlÄ±lÄ±k)** ve **F1-score** gibi diÄŸer metriklere gÃ¼venmek genellikle daha faydalÄ± olacaktÄ±r.

#### Precision and recall *(Kesinlik ve duyarlÄ±lÄ±k)*

#### The F1 score *(F1 skoru)*

#### Log loss and ROC-AUC *(Log kaybÄ± ve ROC-AUC)*

#### Matthews correlation coefficient (MCC) *(Matthews korelasyon katsayÄ±sÄ±)*

### Metrics for multi-class classification *(Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri)*

### Metrics for object detection problems *(Nesne tespiti problemleri iÃ§in metrikler)*

#### Intersection over union (IoU) *(KesiÅŸim/BirleÅŸim oranÄ±)*

#### Dice *(Dice katsayÄ±sÄ±)*

### Metrics for multi-label classification and recommendation problems *(Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri problemleri iÃ§in metrikler)*

#### MAP@K *(MAP@K metriÄŸi)*

### Optimizing evaluation metrics *(DeÄŸerlendirme metriklerini optimize etme)*

### Custom metrics and custom objective functions *(Ã–zel metrikler ve Ã¶zel hedef fonksiyonlarÄ±)*

### Post-processing your predictions *(Tahminleri sonradan iÅŸleme)*

### Predicted probability and its adjustment *(Tahmin edilen olasÄ±lÄ±ÄŸÄ±n ayarlanmasÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 6: Designing Good Validation *(BÃ¶lÃ¼m 6: Ä°yi Bir DoÄŸrulama Sistemi Tasarlama)*

### Snooping on the leaderboard *(Liderlik tablosunu gÃ¶zetlemek)*

### The importance of validation in competitions *(YarÄ±ÅŸmalarda doÄŸrulamanÄ±n Ã¶nemi)*

### Bias and variance *(Ã–nyargÄ± ve varyans)*

### Trying different splitting strategies *(FarklÄ± veri bÃ¶lme stratejilerini denemek)*

#### The basic train-test split *(Temel eÄŸitim-test bÃ¶lÃ¼nmesi)*

#### Probabilistic evaluation methods *(OlasÄ±lÄ±ksal deÄŸerlendirme yÃ¶ntemleri)*

#### k-fold cross-validation *(k-katlÄ± Ã§apraz doÄŸrulama)*

#### Subsampling *(Alt Ã¶rnekleme)*

#### The bootstrap *(Bootstrap yÃ¶ntemi)*

### Tuning your model validation system *(Model doÄŸrulama sistemini ayarlamak)*

### Using adversarial validation *(ZÄ±t doÄŸrulama yÃ¶ntemini kullanmak)*

#### Example implementation *(Uygulama Ã¶rneÄŸi)*

### Handling different distributions of training and test data *(EÄŸitim ve test verilerindeki farklÄ± daÄŸÄ±lÄ±mlarla baÅŸa Ã§Ä±kma)*

### Handling leakage *(Veri sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nleme)*

### Summary *(Ã–zet)*

---

## Chapter 7: Modeling for Tabular Competitions *(BÃ¶lÃ¼m 7: Tablo Verisi YarÄ±ÅŸmalarÄ± Ä°Ã§in Modellemede YaklaÅŸÄ±mlar)*

### The Tabular Playground Series *(Tabular Playground Serisi)*

### Setting a random state for reproducibility *(Tekrarlanabilirlik iÃ§in rastgele durum belirleme)*

### The importance of EDA *(KeÅŸifsel veri analizinin Ã¶nemi)*

### Dimensionality reduction with t-SNE and UMAP *(t-SNE ve UMAP ile boyut indirgeme)*

### Reducing the size of your data *(Veri boyutunu kÃ¼Ã§Ã¼ltme)*

### Applying feature engineering *(Ã–zellik mÃ¼hendisliÄŸi uygulama)*

#### Easily derived features *(Kolay tÃ¼retilen Ã¶zellikler)*

#### Meta-features based on rows and columns *(SatÄ±r ve sÃ¼tunlara dayalÄ± meta-Ã¶zellikler)*

#### Target encoding *(Hedef kodlama)*

### Using feature importance to evaluate your work *(Ã–zellik Ã¶nemini kullanarak Ã§alÄ±ÅŸmanÄ± deÄŸerlendirme)*

### Pseudo-labeling *(Sahte etiketleme)*

### Denoising with autoencoders *(Otoenkoderlerle gÃ¼rÃ¼ltÃ¼ giderme)*

### Neural networks for tabular competitions *(Tablo verisi yarÄ±ÅŸmalarÄ± iÃ§in sinir aÄŸlarÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 8: Hyperparameter Optimization *(BÃ¶lÃ¼m 8: Hiperparametre Optimizasyonu)*

### Basic optimization techniques *(Temel optimizasyon teknikleri)*

#### Grid search *(Izgara aramasÄ±)*

#### Random search *(Rastgele arama)*

#### Halving search *(YarÄ±ya indirme aramasÄ±)*

### Key parameters and how to use them *(Temel parametreler ve nasÄ±l kullanÄ±lacaklarÄ±)*

#### Linear models *(DoÄŸrusal modeller)*

#### Support-vector machines *(Destek vektÃ¶r makineleri)*

#### Random forests and extremely randomized trees *(Rastgele ormanlar ve aÅŸÄ±rÄ± rastgele aÄŸaÃ§lar)*

#### Gradient tree boosting *(Gradyan aÄŸaÃ§ gÃ¼Ã§lendirmesi)*

#### LightGBM *(LightGBM algoritmasÄ±)*

#### XGBoost *(XGBoost algoritmasÄ±)*

#### CatBoost *(CatBoost algoritmasÄ±)*

#### HistGradientBoosting *(Histogram tabanlÄ± gradyan gÃ¼Ã§lendirme)*

### Bayesian optimization *(Bayesyen optimizasyon)*

#### Using Scikit-optimize *(Scikit-optimize kullanÄ±mÄ±)*

#### Customizing a Bayesian optimization search *(Bayesyen aramayÄ± Ã¶zelleÅŸtirme)*

#### Extending Bayesian optimization to neural architecture search *(Bayesyen optimizasyonu sinir aÄŸÄ± mimarisi aramasÄ±na geniÅŸletme)*

#### Creating lighter and faster models with KerasTuner *(KerasTuner ile daha hafif ve hÄ±zlÄ± modeller oluÅŸturma)*

#### The TPE approach in Optuna *(Optunaâ€™daki TPE yaklaÅŸÄ±mÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 9: Ensembling with Blending and Stacking Solutions *(BÃ¶lÃ¼m 9: KarÄ±ÅŸtÄ±rma ve YÄ±ÄŸÄ±nlama (Ensemble) Ã‡Ã¶zÃ¼mleri)*

### A brief introduction to ensemble algorithms *(Topluluk (ensemble) algoritmalarÄ±na kÄ±sa bir giriÅŸ)*

### Averaging models into an ensemble *(Modelleri ortalama alarak birleÅŸtirme)*

#### Majority voting *(Ã‡oÄŸunluk oylamasÄ±)*

#### Averaging of model predictions *(Model tahminlerinin ortalamasÄ±)*

#### Weighted averages *(AÄŸÄ±rlÄ±klÄ± ortalamalar)*

#### Averaging in your cross-validation strategy *(Ã‡apraz doÄŸrulama stratejinde ortalama alma)*

#### Correcting averaging for ROC-AUC evaluations *(ROC-AUC deÄŸerlendirmeleri iÃ§in ortalamayÄ± dÃ¼zeltme)*

### Blending models using a meta-model *(Meta-model kullanarak modelleri karÄ±ÅŸtÄ±rma)*

#### Best practices for blending *(KarÄ±ÅŸtÄ±rma iÃ§in en iyi uygulamalar)*

### Stacking models together *(Modelleri yÄ±ÄŸÄ±nlama)*

#### Stacking variations *(YÄ±ÄŸÄ±nlama varyasyonlarÄ±)*

### Creating complex stacking and blending solutions *(KarmaÅŸÄ±k karÄ±ÅŸtÄ±rma ve yÄ±ÄŸÄ±nlama Ã§Ã¶zÃ¼mleri oluÅŸturma)*

### Summary *(Ã–zet)*

---

## Chapter 10: Modeling for Computer Vision *(BÃ¶lÃ¼m 10: BilgisayarlÄ± GÃ¶rÃ¼ (Computer Vision) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Augmentation strategies *(Veri artÄ±rma stratejileri)*

#### Keras built-in augmentations *(Kerasâ€™Ä±n yerleÅŸik artÄ±rmalarÄ±)*

#### ImageDataGenerator approach *(ImageDataGenerator yaklaÅŸÄ±mÄ±)*

#### Preprocessing layers *(Ã–n iÅŸleme katmanlarÄ±)*

#### albumentations *(Albumentations kÃ¼tÃ¼phanesi)*

### Classification *(SÄ±nÄ±flandÄ±rma)*

### Object detection *(Nesne tespiti)*

### Semantic segmentation *(Anlamsal segmentasyon)*

### Summary *(Ã–zet)*

---

## Chapter 11: Modeling for NLP *(BÃ¶lÃ¼m 11: DoÄŸal Dil Ä°ÅŸleme (NLP) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Sentiment analysis *(Duygu analizi)*

### Open domain Q&A *(AÃ§Ä±k alan soru-cevap)*

### Text augmentation strategies *(Metin artÄ±rma stratejileri)*

#### Basic techniques *(Temel teknikler)*

#### nlpaug *(nlpaug kÃ¼tÃ¼phanesi)*

### Summary *(Ã–zet)*

---

## Chapter 12: Simulation and Optimization Competitions *(BÃ¶lÃ¼m 12: SimÃ¼lasyon ve Optimizasyon YarÄ±ÅŸmalarÄ±)*

### Connect X *(Connect X oyunu)*

### Rock-paper-scissors *(TaÅŸ-kaÄŸÄ±t-makas)*

### Santa competition 2020 *(Santa yarÄ±ÅŸmasÄ± 2020)*

### The name of the game *(Oyunun Ã¶zÃ¼)*

### Summary *(Ã–zet)*

---

# Part III: Leveraging Competitions for Your Career *(BÃ¶lÃ¼m III: YarÄ±ÅŸmalarÄ± Kariyerinde Avantaja DÃ¶nÃ¼ÅŸtÃ¼rme)*

## Chapter 13: Creating Your Portfolio of Projects and Ideas *(BÃ¶lÃ¼m 13: Proje ve Fikir PortfÃ¶yÃ¼ OluÅŸturma)*

### Building your portfolio with Kaggle *(Kaggle ile portfÃ¶y oluÅŸturma)*

### Leveraging Notebooks and discussions *(Defterler ve tartÄ±ÅŸmalardan yararlanma)*

### Leveraging Datasets *(Veri setlerinden yararlanma)*

### Arranging your online presence beyond Kaggle *(Kaggle dÄ±ÅŸÄ±nda Ã§evrimiÃ§i varlÄ±ÄŸÄ±nÄ± dÃ¼zenleme)*

#### Blogs and publications *(Bloglar ve yayÄ±nlar)*

#### GitHub *(GitHub)*

### Monitoring competition updates and newsletters *(YarÄ±ÅŸma gÃ¼ncellemelerini ve bÃ¼ltenleri takip etme)*

### Summary *(Ã–zet)*

---

## Chapter 14: Finding New Professional Opportunities *(BÃ¶lÃ¼m 14: Yeni Profesyonel FÄ±rsatlar Bulmak)*

### Building connections with other competition data scientists *(DiÄŸer yarÄ±ÅŸmacÄ± veri bilimcilerle baÄŸlantÄ± kurma)*

### Participating in Kaggle Days and other Kaggle meetups *(Kaggle Days ve diÄŸer Kaggle buluÅŸmalarÄ±na katÄ±lma)*

### Getting spotted and other job opportunities *(Fark edilmek ve diÄŸer iÅŸ fÄ±rsatlarÄ±)*

#### The STAR approach *(STAR yaklaÅŸÄ±mÄ±)*

### Summary (and some parting words) *(Ã–zet ve kapanÄ±ÅŸ notlarÄ±)*

---

## Other Books You May Enjoy *(HoÅŸunuza Gidebilecek DiÄŸer Kitaplar)*

## Index *(Dizin)*
