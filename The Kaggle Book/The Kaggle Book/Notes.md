# Part I: Introduction to Competitions *(BÃ¶lÃ¼m I: YarÄ±ÅŸmalara GiriÅŸ)*

## Chapter 1: Introducing Kaggle and Other Data Science Competitions *(BÃ¶lÃ¼m 1: Kaggle ve DiÄŸer Veri Bilimi YarÄ±ÅŸmalarÄ±na GiriÅŸ)*

Veri bilimi yarÄ±ÅŸmalarÄ± uzun zamandÄ±r var ve zaman iÃ§inde giderek artan bir baÅŸarÄ± elde ettiler. Tutkulu bir yarÄ±ÅŸmacÄ± topluluÄŸundan doÄŸan bu yarÄ±ÅŸmalar, giderek daha fazla ilgi Ã§ekmeye ve milyonlarca veri bilimciden oluÅŸan Ã§ok daha geniÅŸ bir kitleye ulaÅŸmaya baÅŸladÄ±. En popÃ¼ler veri bilimi yarÄ±ÅŸma platformu olan **Kaggle**â€™da uzun yÄ±llardÄ±r yarÄ±ÅŸmacÄ± olarak yer aldÄ±ÄŸÄ±mÄ±z iÃ§in, bu deÄŸiÅŸimlerin tÃ¼mÃ¼ne yÄ±llar boyunca doÄŸrudan tanÄ±klÄ±k ettik ve bizzat deneyimledik.

BugÃ¼n, Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ± hakkÄ±nda bilgi ararsanÄ±z, Ã§ok sayÄ±da **buluÅŸma (meetup)**, **tartÄ±ÅŸma paneli**, **podcast**, **rÃ¶portaj** ve hatta bu tÃ¼r yarÄ±ÅŸmalarda nasÄ±l kazanÄ±lacaÄŸÄ±nÄ± anlatan **Ã§evrimiÃ§i kurslar** bulabilirsiniz. (Genellikle bu kurslar size azim, hesaplama kaynaklarÄ± ve harcanan zamanÄ±n doÄŸru karÄ±ÅŸÄ±mÄ±nÄ± kullanmanÄ±zÄ± tavsiye eder.) Ancak, ÅŸu anda okumakta olduÄŸunuz kitap dÄ±ÅŸÄ±nda, bu kadar Ã§ok veri bilimi yarÄ±ÅŸmasÄ±nÄ± nasÄ±l yÃ¶neteceÄŸinizi ve onlardan nasÄ±l en iyi ÅŸekilde yararlanabileceÄŸinizi â€” yalnÄ±zca puan veya sÄ±ralama aÃ§Ä±sÄ±ndan deÄŸil, **profesyonel deneyim** bakÄ±mÄ±ndan da â€” sistematik bir ÅŸekilde anlatan bir rehber bulmanÄ±z oldukÃ§a zordur.

Bu kitapta amacÄ±mÄ±z, Kaggle veya diÄŸer veri bilimi yarÄ±ÅŸmalarÄ±nda nasÄ±l yÃ¼ksek puan alacaÄŸÄ±nÄ±zÄ± anlatan birkaÃ§ ipucu vermek deÄŸil. Bunun yerine, **Kaggleâ€™da daha etkili yarÄ±ÅŸmanÄ±z** ve yarÄ±ÅŸma deneyimlerinizden â€” Ã¶zellikle de profesyonel hayatÄ±nÄ±z aÃ§Ä±sÄ±ndan â€” **en fazla faydayÄ± elde etmeniz** iÃ§in kapsamlÄ± bir rehber sunmak istiyoruz. Kitap iÃ§eriÄŸine, **Kaggle Master** ve **Grandmaster**â€™larla yapÄ±lan rÃ¶portajlar da eÅŸlik ediyor. Bu rÃ¶portajlarÄ±n size Kaggleâ€™da yarÄ±ÅŸmanÄ±n belirli yÃ¶nleri hakkÄ±nda farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve iÃ§gÃ¶rÃ¼ler sunacaÄŸÄ±nÄ± ve rekabetÃ§i veri bilimi yaparken kendinizi sÄ±nama ve Ã¶ÄŸrenme biÃ§iminize ilham vereceÄŸini umuyoruz.

Bu kitabÄ±n sonunda, **kendi deneyimlerimizden**, **yarÄ±ÅŸmalardan edindiÄŸimiz bilgilerden** ve **kaynaklardan** doÄŸrudan derlediÄŸimiz bilgileri iÃ§selleÅŸtirmiÅŸ olacaksÄ±nÄ±z. BÃ¶ylece yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã¶ÄŸrenmenizi ve geliÅŸmenizi saÄŸlayacak bir yol haritasÄ±na sahip olacaksÄ±nÄ±z.

BaÅŸlangÄ±Ã§ noktasÄ± olarak, bu bÃ¶lÃ¼mde ÅŸunlarÄ± inceleyeceÄŸiz:

* RekabetÃ§i programlamanÄ±n nasÄ±l veri bilimi yarÄ±ÅŸmalarÄ±na evrildiÄŸini,
* Neden Kaggle platformunun bu tÃ¼r yarÄ±ÅŸmalar iÃ§in en popÃ¼ler site olduÄŸunu,
* Ve bu platformun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±.

Bu bÃ¶lÃ¼mde aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

* Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi
* **Common Task Framework** (Ortak GÃ¶rev Ã‡erÃ§evesi) paradigmasÄ±
* Kaggle platformu ve bazÄ± alternatifleri
* Bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸi: aÅŸamalarÄ±, yarÄ±ÅŸma tÃ¼rleri, gÃ¶nderim ve liderlik tablosu dinamikleri, hesaplama kaynaklarÄ±, aÄŸ oluÅŸturma ve daha fazlasÄ±

### The rise of data science competition platforms *(Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi)*

RekabetÃ§i programlamanÄ±n kÃ¶klÃ¼ bir geÃ§miÅŸi vardÄ±r; 1970â€™lerde dÃ¼zenlenen ilk **ICPC (International Collegiate Programming Contest â€“ UluslararasÄ± ÃœniversitelerarasÄ± Programlama YarÄ±ÅŸmasÄ±)** ile baÅŸlamÄ±ÅŸtÄ±r. Ä°lk ICPCâ€™de, Ã¼niversitelerden ve ÅŸirketlerden gelen kÃ¼Ã§Ã¼k takÄ±mlar, bir dizi problemi bilgisayar programÄ± kullanarak Ã§Ã¶zmeleri gereken bir yarÄ±ÅŸmaya katÄ±lÄ±yordu (baÅŸlangÄ±Ã§ta katÄ±lÄ±mcÄ±lar **FORTRAN** dilinde kodlama yapÄ±yordu). Ä°yi bir final sÄ±ralamasÄ± elde etmek iÃ§in takÄ±mlarÄ±n gÃ¼Ã§lÃ¼ **takÄ±m Ã§alÄ±ÅŸmasÄ±**, **problem Ã§Ã¶zme** ve **programlama** becerileri sergilemeleri gerekiyordu.

Bu tÃ¼r bir yarÄ±ÅŸmanÄ±n yoÄŸun atmosferinde yer almak ve iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§ekme fÄ±rsatÄ±, Ã¶ÄŸrencilere bÃ¼yÃ¼k bir motivasyon saÄŸladÄ± ve yarÄ±ÅŸmanÄ±n yÄ±llar boyunca popÃ¼ler kalmasÄ±na neden oldu. ICPC finalistleri arasÄ±nda, gÃ¼nÃ¼mÃ¼zde oldukÃ§a tanÄ±nmÄ±ÅŸ isimler vardÄ±r: **Adam Dâ€™Angelo** (Facebookâ€™un eski CTOâ€™su ve Quoraâ€™nÄ±n kurucusu), **Nikolai Durov** (Telegram Messengerâ€™Ä±n kurucu ortaÄŸÄ±) ve **Matei Zaharia** (Apache Sparkâ€™Ä±n yaratÄ±cÄ±sÄ±). Bu isimlerin yanÄ± sÄ±ra birÃ§ok profesyonel aynÄ± ortak deneyimi paylaÅŸÄ±r: bir ICPC yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸlardÄ±r.

ICPCâ€™nin ardÄ±ndan, Ã¶zellikle 2000 yÄ±lÄ±ndan sonra uzaktan katÄ±lÄ±mÄ±n kolaylaÅŸmasÄ±yla programlama yarÄ±ÅŸmalarÄ± bÃ¼yÃ¼k bir geliÅŸme gÃ¶sterdi. Bu sayede uluslararasÄ± yarÄ±ÅŸmalarÄ±n dÃ¼zenlenmesi hem daha kolay hem de daha dÃ¼ÅŸÃ¼k maliyetli hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸunun formatÄ± benzerdir: bir dizi problem verilir ve katÄ±lÄ±mcÄ±larÄ±n bunlarÄ± Ã§Ã¶zmek iÃ§in kod yazmasÄ± gerekir. Kazananlar sadece Ã¶dÃ¼l kazanmakla kalmaz, aynÄ± zamanda iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§eker veya kendi alanlarÄ±nda tanÄ±nÄ±r hale gelirler.

RekabetÃ§i programlamadaki problemler genellikle **kombinatorik**, **sayÄ± teorisi**, **graf teorisi**, **algoritmik oyun teorisi**, **hesaplamalÄ± geometri**, **dizgi analizi** ve **veri yapÄ±larÄ±** gibi konulardan oluÅŸur. Son yÄ±llarda ise **yapay zekÃ¢** ile ilgili problemler de bu yarÄ±ÅŸmalarda yer almaya baÅŸlamÄ±ÅŸtÄ±r. Ã–zellikle **KDD Cup**â€™Ä±n (Knowledge Discovery and Data Mining Cup â€“ Bilgi KeÅŸfi ve Veri MadenciliÄŸi YarÄ±ÅŸmasÄ±) baÅŸlatÄ±lmasÄ±ndan sonra bu tÃ¼r problemler oldukÃ§a popÃ¼ler hale gelmiÅŸtir. Bu yarÄ±ÅŸma, her yÄ±l **Association for Computing Machinery (ACM)** tarafÄ±ndan dÃ¼zenlenen konferans kapsamÄ±nda **Ã–zel Ä°lgi Grubu (SIG)** tarafÄ±ndan yÃ¼rÃ¼tÃ¼lmektedir. (Kaynak: [https://kdd.org/conferences](https://kdd.org/conferences))

Ä°lk **KDD Cup**, 1997 yÄ±lÄ±nda dÃ¼zenlenmiÅŸ ve **doÄŸrudan pazarlamada lift eÄŸrisi optimizasyonu** konusundaki bir problemi iÃ§ermiÅŸtir. Bu yarÄ±ÅŸma, gÃ¼nÃ¼mÃ¼zde hÃ¢lÃ¢ devam eden uzun bir yarÄ±ÅŸma serisinin baÅŸlangÄ±cÄ±nÄ± oluÅŸturmuÅŸtur. Veri kÃ¼meleri, yÃ¶nergeler ve kazananlar dÃ¢hil olmak Ã¼zere tÃ¼m arÅŸivlere ÅŸu adresten ulaÅŸabilirsiniz: [https://www.kdd.org/kdd-cup](https://www.kdd.org/kdd-cup). YazÄ±m sÄ±rasÄ±nda en son mevcut olan yarÄ±ÅŸma ise [https://ogb.stanford.edu/kddcup2021/](https://ogb.stanford.edu/kddcup2021/).
KDD Cup yarÄ±ÅŸmalarÄ±, en iyi uygulamalarÄ± belirlemede oldukÃ§a etkili olmuÅŸtur. BirÃ§ok makalede yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri, teknikler ve veri kÃ¼meleri paylaÅŸÄ±lmÄ±ÅŸ, bu da araÅŸtÄ±rmacÄ±lar ve uygulayÄ±cÄ±lar iÃ§in **deney**, **eÄŸitim** ve **karÅŸÄ±laÅŸtÄ±rma (benchmarking)** aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k fayda saÄŸlamÄ±ÅŸtÄ±r.

Hem rekabetÃ§i programlama etkinliklerinin hem de KDD Cupâ€™Ä±n baÅŸarÄ±sÄ±, ÅŸirketleri (Ã¶rneÄŸin **Netflix**) ve giriÅŸimcileri (Ã¶rneÄŸin Kaggleâ€™Ä±n kurucusu **Anthony Goldbloom**) **veri bilimi yarÄ±ÅŸma platformlarÄ±** kurmaya teÅŸvik etti. Bu platformlar, ÅŸirketlerin Ã§Ã¶zÃ¼lmesi zor veri bilimi problemlerini kitle kaynaklÄ± Ã§Ã¶zÃ¼mlerle Ã§Ã¶zebilmesine olanak tanÄ±dÄ±. GerÃ§ekten de veri bilimi alanÄ±nda her problem iÃ§in iÅŸe yarayan tek bir â€œaltÄ±nâ€ yÃ¶ntem yoktur; Ã§oÄŸu zaman, **â€œdeneyebileceÄŸin her ÅŸeyi deneâ€** yaklaÅŸÄ±mÄ± gerekir.

AslÄ±nda, uzun vadede hiÃ§bir algoritma tÃ¼m problemler iÃ§in diÄŸerlerini alt edemez. Bu durum, **David Wolpert** ve **William Macready** tarafÄ±ndan ortaya konan **No Free Lunch Teoremi (Bedava Ã–ÄŸle YemeÄŸi Yok Teoremi)** ile aÃ§Ä±klanÄ±r. Bu teoreme gÃ¶re, her makine Ã¶ÄŸrenimi algoritmasÄ± yalnÄ±zca Ã§Ã¶zÃ¼mÃ¼ iÃ§eren bir hipotez uzayÄ±na sahipse baÅŸarÄ±lÄ± olur. DolayÄ±sÄ±yla, bir algoritmanÄ±n belirli bir problemi en iyi ÅŸekilde Ã§Ã¶zebileceÄŸini Ã¶nceden bilemezsiniz; bunu Ã¶ÄŸrenmenin tek yolu, algoritmayÄ± doÄŸrudan o problem Ã¼zerinde test etmektir.
Makine Ã¶ÄŸreniminde herhangi bir â€œkutsal kÃ¢seâ€ veya teorik kestirme yoktur â€” yalnÄ±zca **ampirik deneyler** size neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶sterebilir.

Bu konuda daha fazla bilgi edinmek iÃ§in **No Free Lunch Teoremi** Ã¼zerine kuramsal aÃ§Ä±klamalarÄ± inceleyebilirsiniz. AÅŸaÄŸÄ±da bu konuyu detaylÄ± anlatan bir makaleye baÄŸlantÄ± verilmiÅŸtir:
ğŸ‘‰ [Analytics India Magazine â€“ What are the No Free Lunch Theorems in Data Science?](https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/)

Bu tÃ¼r durumlarda **crowdsourcing (kitle kaynak kullanÄ±mÄ±)** mÃ¼kemmel bir yÃ¶ntemdir; Ã§Ã¼nkÃ¼ algoritmalarÄ± ve veri dÃ¶nÃ¼ÅŸÃ¼mlerini kapsamlÄ± bir ÅŸekilde test etmeniz gerekir, ancak bunu yapacak insan gÃ¼cÃ¼ ve iÅŸlem gÃ¼cÃ¼nÃ¼z yoktur. Bu nedenle, hÃ¼kÃ¼metler ve ÅŸirketler belirli alanlarda ilerleme kaydetmek iÃ§in yarÄ±ÅŸmalara baÅŸvurur:

* **Kamu tarafÄ±nda:** ABDâ€™nin **DARPA** kuruluÅŸu tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalarda; **otonom araÃ§lar**, **robotik operasyonlar**, **makine Ã§evirisi**, **konuÅŸmacÄ± tanÄ±ma**, **parmak izi tanÄ±ma**, **bilgi eriÅŸimi**, **OCR (Optik Karakter TanÄ±ma)**, **otomatik hedef tanÄ±ma** gibi birÃ§ok alanda yarÄ±ÅŸmalar dÃ¼zenlenmiÅŸtir.
* **Åirket tarafÄ±nda:** Ã–rneÄŸin **Netflix**, kullanÄ±cÄ±larÄ±n film tercihlerinin tahmin edilmesini iyileÅŸtirmek amacÄ±yla dÃ¼zenlenen bir yarÄ±ÅŸmanÄ±n sonucuna gÃ¶re algoritmasÄ±nÄ± geliÅŸtirmiÅŸtir.

**Netflix YarÄ±ÅŸmasÄ± (Netflix Prize)**, mevcut **Ã¶neri sistemini** (collaborative filtering) geliÅŸtirmeyi amaÃ§lÄ±yordu. YarÄ±ÅŸmanÄ±n hedefi, bir kullanÄ±cÄ±nÄ±n bir filme vereceÄŸi puanÄ±, yalnÄ±zca daha Ã¶nce puanladÄ±ÄŸÄ± filmlerden yola Ã§Ä±karak tahmin etmekti â€” yani kullanÄ±cÄ± kimliÄŸi veya film aÃ§Ä±klamalarÄ± hakkÄ±nda hiÃ§bir bilgi yoktu (bunlarÄ±n tÃ¼mÃ¼ kimlik kodlarÄ±yla deÄŸiÅŸtirilmiÅŸti). KatÄ±lÄ±mcÄ±lardan, mevcut puan geÃ§miÅŸini akÄ±llÄ±ca kullanarak tahmin yapan modeller geliÅŸtirmeleri istendi.
**1.000.000 ABD DolarÄ±** tutarÄ±ndaki bÃ¼yÃ¼k Ã¶dÃ¼l, yalnÄ±zca geliÅŸtirilen modelin Netflixâ€™in mevcut algoritmasÄ± **Cinematch**â€™i belirli bir eÅŸiÄŸin Ã¼zerinde iyileÅŸtirmesi durumunda verilecekti.

YarÄ±ÅŸma 2006â€™dan 2009â€™a kadar sÃ¼rdÃ¼ ve kazanan takÄ±m, Ã¶nceki yarÄ±ÅŸmalardan birÃ§ok takÄ±mÄ±n birleÅŸmesiyle oluÅŸtu: **Commendo Research & Consulting GmbH**â€™den **Andreas TÃ¶scher** ve **Michael Jahrer** (aynÄ± zamanda Kaggleâ€™da da tanÄ±nan yarÄ±ÅŸmacÄ±lar), **AT&T Labs**â€™tan iki araÅŸtÄ±rmacÄ± ve **Yahoo!**â€™dan iki araÅŸtÄ±rmacÄ±.
YarÄ±ÅŸmayÄ± kazanmak, o kadar bÃ¼yÃ¼k bir hesaplama gÃ¼cÃ¼ ve farklÄ± Ã§Ã¶zÃ¼mlerin birleÅŸtirilmesini (ensemble) gerektirdi ki, takÄ±mlar rekabeti sÃ¼rdÃ¼rebilmek iÃ§in birleÅŸmek zorunda kaldÄ±lar. SonuÃ§ta, **Netflix** bu Ã§Ã¶zÃ¼mÃ¼ doÄŸrudan uygulamak yerine, yarÄ±ÅŸmadan elde edilen en deÄŸerli iÃ§gÃ¶rÃ¼leri alÄ±p mevcut **Cinematch algoritmasÄ±nÄ±** geliÅŸtirmede kullandÄ±.
Bu konuda daha fazla bilgi iÃ§in ÅŸu **Wired** makalesini okuyabilirsiniz:
ğŸ‘‰ [https://www.wired.com/2012/04/netflix-prize-costs/](https://www.wired.com/2012/04/netflix-prize-costs/)

Netflix yarÄ±ÅŸmasÄ±nÄ±n sonunda Ã¶nemli olan ÅŸey, Ã§Ã¶zÃ¼mÃ¼n kendisi deÄŸil, **Netflixâ€™in iÅŸ modelinin DVD kiralamadan Ã§evrimiÃ§i yayÄ±n platformuna geÃ§mesiyle** birlikte elde edilen **bilgi ve deneyimdi**. YarÄ±ÅŸmadan hem katÄ±lÄ±mcÄ±lar (Ã¶neri sistemleri alanÄ±nda bÃ¼yÃ¼k bir Ã¼n kazandÄ±lar) hem de Netflix (geliÅŸtirilmiÅŸ Ã¶neri sistemi bilgisini yeni iÅŸ modeline aktardÄ±) bÃ¼yÃ¼k fayda saÄŸladÄ±.

### The Kaggle competition platform *(Kaggle yarÄ±ÅŸma platformu)*

**Netflix dÄ±ÅŸÄ±ndaki birÃ§ok ÅŸirket de veri bilimi yarÄ±ÅŸmalarÄ±ndan fayda saÄŸlamÄ±ÅŸtÄ±r.** Liste oldukÃ§a uzundur, ancak yarÄ±ÅŸmayÄ± dÃ¼zenleyen ÅŸirketlerin aÃ§Ä±k bir ÅŸekilde fayda elde ettiÄŸini bildirdiÄŸi birkaÃ§ Ã¶rneÄŸi verebiliriz. Ã–rneÄŸin:

* **Allstate** adlÄ± sigorta ÅŸirketi, yÃ¼zlerce veri bilimcinin katÄ±ldÄ±ÄŸÄ± bir yarÄ±ÅŸma sayesinde ([https://www.kaggle.com/c/ClaimPredictionChallenge](https://www.kaggle.com/c/ClaimPredictionChallenge)), kendi uzmanlarÄ± tarafÄ±ndan geliÅŸtirilen aktÃ¼eryal modellerini Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirebilmiÅŸtir.
* BaÅŸka iyi belgelenmiÅŸ bir Ã¶rnek olarak, **General Electric**, havayolu uÃ§uÅŸlarÄ±nÄ±n varÄ±ÅŸ zamanlarÄ±nÄ± tahmin etmede kullanÄ±lan sektÃ¶r standardÄ± performans Ã¶lÃ§Ã¼tÃ¼ne gÃ¶re (kÃ¶k ortalama kare hatasÄ± â€“ *root mean squared error* metriÄŸiyle Ã¶lÃ§Ã¼lÃ¼r) %40â€™lÄ±k bir geliÅŸme saÄŸlamÄ±ÅŸtÄ±r. Bu baÅŸarÄ±, benzer bir yarÄ±ÅŸma sayesinde elde edilmiÅŸtir ([https://www.kaggle.com/c/flight](https://www.kaggle.com/c/flight)).

**Kaggle yarÄ±ÅŸma platformu** bugÃ¼ne kadar yÃ¼zlerce yarÄ±ÅŸma dÃ¼zenlemiÅŸtir ve bu iki Ã¶rnek, platformu baÅŸarÄ±yla kullanan ÅŸirketlerden yalnÄ±zca birkaÃ§Ä±dÄ±r.
Åimdi, belirli yarÄ±ÅŸmalarÄ±n Ã¶tesine geÃ§ip bu kitabÄ±n da merkezinde yer alan **Kaggle ÅŸirketi** hakkÄ±nda konuÅŸalÄ±m.

### A history of Kaggle *(Kaggleâ€™Ä±n tarihÃ§esi)*

**Kaggle**, ilk adÄ±mlarÄ±nÄ± **Åubat 2010â€™da**, ekonomist ve ekonometrikÃ§i olarak eÄŸitim almÄ±ÅŸ AvustralyalÄ± **Anthony Goldbloom** sayesinde attÄ±. Goldbloom, Avustralya Hazine BakanlÄ±ÄŸÄ±â€™nda (*Department of the Treasury*) ve Avustralya Merkez BankasÄ±â€™nÄ±n (*Reserve Bank of Australia*) AraÅŸtÄ±rma DepartmanÄ±â€™nda Ã§alÄ±ÅŸtÄ±ktan sonra, Londraâ€™da haftalÄ±k uluslararasÄ± dergi **The Economist**â€™te staj yaptÄ±.

The Economistâ€™te Ã§alÄ±ÅŸtÄ±ÄŸÄ± dÃ¶nemde â€œ**bÃ¼yÃ¼k veri (big data)**â€ Ã¼zerine bir makale yazma fÄ±rsatÄ± buldu. Bu makale, onun aklÄ±na **ilginÃ§ makine Ã¶ÄŸrenimi problemlerini Ã§Ã¶zmek iÃ§in en iyi analitik uzmanlarÄ± kitlesel katÄ±lÄ±mla (crowdsourcing) bir araya getirecek bir yarÄ±ÅŸma platformu kurma fikrini** getirdi ([kaynak](https://www.smh.com.au/technology/from-bondi-to-the-big-bucks-the-28yearold-whos-making-datascience-a-sport-20111104-1myq1.html)).

Bu platformun iÅŸ fikrinde â€œcrowdsourcingâ€ dinamiklerinin Ã¶nemli bir rol oynamasÄ±ndan dolayÄ±, Goldbloom platformun adÄ±nÄ± **Kaggle** koydu. Bu isim, Ä°ngilizce â€œ**gaggle**â€ (kaz sÃ¼rÃ¼sÃ¼) kelimesine bir gÃ¶nderme yapÄ±yor; kaz figÃ¼rÃ¼ de zaten Kaggle platformunun sembolÃ¼dÃ¼r.

Goldbloom, daha sonra **ABDâ€™nin Silikon Vadisiâ€™ne taÅŸÄ±ndÄ±** ve Kaggle giriÅŸimi, iki tanÄ±nmÄ±ÅŸ risk sermayesi ÅŸirketi olan **Khosla Ventures** ve **Index Ventures** tarafÄ±ndan yÃ¶netilen bir yatÄ±rÄ±m turunda **11,25 milyon dolar** tutarÄ±nda **A Serisi yatÄ±rÄ±m** aldÄ±. Ä°lk yarÄ±ÅŸmalar baÅŸlatÄ±ldÄ±, topluluk hÄ±zla bÃ¼yÃ¼dÃ¼ ve bazÄ± erken dÃ¶nem yarÄ±ÅŸmacÄ±lar dikkat Ã§ekici baÅŸarÄ±lara ulaÅŸtÄ±. Bunlardan biri olan **Jeremy Howard**, AvustralyalÄ± bir veri bilimci ve giriÅŸimciydi. Kaggleâ€™da birkaÃ§ yarÄ±ÅŸma kazandÄ±ktan sonra ÅŸirketin **BaÅŸkanÄ± (President)** ve **BaÅŸ Bilimcisi (Chief Scientist)** oldu.

Jeremy Howard, **AralÄ±k 2013â€™te** gÃ¶revinden ayrÄ±ldÄ± ve daha sonra **fast.ai** ([www.fast.ai](http://www.fast.ai)) adlÄ± yeni bir giriÅŸim kurdu. Bu giriÅŸim, **makine Ã¶ÄŸrenimi kurslarÄ±** ve **geliÅŸtiriciler iÃ§in derin Ã¶ÄŸrenme (deep learning) kÃ¼tÃ¼phanesi** sunmaktadÄ±r.

O dÃ¶nemde Ã¶ne Ã§Ä±kan diÄŸer bazÄ± **Kaggle yarÄ±ÅŸmacÄ±larÄ± (Kagglers)** arasÄ±nda **Jeremy Achin** ve **Thomas de Godoy** da bulunuyordu. Platformda **ilk 20 kÃ¼resel sÄ±ralama** arasÄ±na girdikten sonra emekli olmaya karar verdiler ve **DataRobot** adlÄ± kendi ÅŸirketlerini kurdular. KÄ±sa sÃ¼re sonra, geliÅŸtirdikleri yazÄ±lÄ±ma en iyi makine Ã¶ÄŸrenimi bilgilerini ve uygulamalarÄ±nÄ± kazandÄ±rmak amacÄ±yla **Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmuÅŸ katÄ±lÄ±mcÄ±larÄ± iÅŸe almaya** baÅŸladÄ±lar. BugÃ¼n **DataRobot**, **AutoML (otomatik makine Ã¶ÄŸrenimi)** Ã§Ã¶zÃ¼mleri geliÅŸtiren Ã¶nde gelen ÅŸirketlerden biridir.

Kaggle yarÄ±ÅŸmalarÄ±, giderek artan bir ilgiyle bÃ¼yÃ¼meye devam etti. **Derin Ã¶ÄŸrenmenin â€œbabasÄ±â€ Geoffrey Hinton**, 2012â€™de **Merck** tarafÄ±ndan dÃ¼zenlenen bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ± ve kazandÄ± ([kaynak](https://www.kaggle.com/c/MerckActivity/overview/winners)).

AyrÄ±ca Kaggle, **FranÃ§ois Chollet**â€™nin derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi **Keras**â€™Ä± tanÄ±ttÄ±ÄŸÄ± **Otto Group Product Classification Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13632)) yarÄ±ÅŸmasÄ±nÄ±n ve **Tianqi Chen**â€™in **XGBoost** adlÄ± daha hÄ±zlÄ± ve daha doÄŸru bir **gradient boosting** algoritmasÄ±nÄ± tanÄ±ttÄ±ÄŸÄ± **Higgs Boson Machine Learning Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/higgs-boson/discussion/10335)) yarÄ±ÅŸmasÄ±nÄ±n da dÃ¼zenlendiÄŸi platformdur.

FranÃ§ois Chollet ayrÄ±ca **Quora** sitesinde â€œKaggle yarÄ±ÅŸmalarÄ±nda neden Keras bu kadar baÅŸarÄ±lÄ± oldu?â€ sorusuna verdiÄŸi cevapta, Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmanÄ±n Ã¶zÃ¼nÃ¼ mÃ¼kemmel bir ÅŸekilde aÃ§Ä±klamÄ±ÅŸtÄ±r ([kaynak](https://www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions)).
Ona gÃ¶re, **Ã§ok sayÄ±da denemeyi hÄ±zlÄ± ÅŸekilde yapmak ve teoriden ziyade ampirik kanÄ±tlarla yÃ¶nlenmek**, Kaggleâ€™da baÅŸarÄ±lÄ± olmanÄ±n temelidir. Biz de onun belirttiÄŸi noktalarÄ±n dÄ±ÅŸÄ±nda baÅŸka bir â€œgizli sÄ±râ€ olduÄŸuna inanmÄ±yoruz.

FranÃ§ois Chollet ayrÄ±ca Kaggleâ€™da kendi yarÄ±ÅŸmasÄ±nÄ± da dÃ¼zenlemiÅŸtir ([Abstraction and Reasoning Challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge/)) â€” bu yarÄ±ÅŸma, **dÃ¼nyanÄ±n ilk genel yapay zekÃ¢ (general AI) yarÄ±ÅŸmasÄ±** olarak kabul edilir.

YarÄ±ÅŸma Ã¼stÃ¼ne yarÄ±ÅŸma geldikÃ§e, Kaggle etrafÄ±ndaki topluluk bÃ¼yÃ¼meye devam etti ve **2017 yÄ±lÄ±nda 1 milyon kullanÄ±cÄ±ya** ulaÅŸtÄ±. AynÄ± yÄ±l, **Google BaÅŸ Bilimcisi Fei-Fei Li**, **Google Next** etkinliÄŸinde yaptÄ±ÄŸÄ± aÃ§Ä±lÄ±ÅŸ konuÅŸmasÄ±nda **Googleâ€™Ä±n Kaggleâ€™Ä± satÄ±n alacaÄŸÄ±nÄ±** duyurdu.
O tarihten bu yana **Kaggle, Google Ã§atÄ±sÄ± altÄ±nda** faaliyet gÃ¶stermektedir.

BugÃ¼n, **Kaggle topluluÄŸu hÃ¢lÃ¢ aktif ve bÃ¼yÃ¼meye devam ediyor.**
Anthony Goldbloomâ€™un bir tweetâ€™inde ([kaynak](https://twitter.com/antgoldbloom/status/1400119591246852096)) belirttiÄŸi Ã¼zere, kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k bir kÄ±smÄ± sadece yarÄ±ÅŸmalara katÄ±lmakla kalmÄ±yor; aynÄ± zamanda **Kaggleâ€™Ä±n herkese aÃ§Ä±k veri setlerini indiriyor** (Kaggle artÄ±k Ã¶nemli bir **veri merkezi** haline gelmiÅŸtir), **Python veya R ile herkese aÃ§Ä±k Notebooks oluÅŸturuyor** ya da **platformun sunduÄŸu kurslardan yeni bir ÅŸeyler Ã¶ÄŸreniyor.**

![](im/1001.png)

YÄ±llar boyunca Kaggle, katÄ±lÄ±mcÄ±larÄ±na aÅŸaÄŸÄ±daki gibi **daha pek Ã§ok fÄ±rsat** sunmuÅŸtur:

* **Kendi ÅŸirketlerini kurmak**
* **Makine Ã¶ÄŸrenimi yazÄ±lÄ±mlarÄ± ve paketleri baÅŸlatmak**
* **Dergilerde rÃ¶portajlar yapmak** ([kaynak](https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/))
* **Makine Ã¶ÄŸrenimi kitaplarÄ± yazmak** ([kaynak](https://twitter.com/antgoldbloom/status/745662719588589568))
* **Hayallerindeki iÅŸi bulmak**

Ve en Ã¶nemlisi, **veri bilimi ile ilgili beceriler ve teknik detaylar hakkÄ±nda daha fazla bilgi edinmek**.

### Other competition platforms *(DiÄŸer yarÄ±ÅŸma platformlarÄ±)*

Bu kitap Kaggleâ€™daki yarÄ±ÅŸmalara odaklansa da, birÃ§ok veri yarÄ±ÅŸmasÄ±nÄ±n Ã¶zel platformlarda veya diÄŸer yarÄ±ÅŸma platformlarÄ±nda dÃ¼zenlendiÄŸini unutmamak gerekir. AslÄ±nda, bu kitapta bulacaÄŸÄ±nÄ±z bilgilerin Ã§oÄŸu diÄŸer yarÄ±ÅŸmalar iÃ§in de geÃ§erlidir; Ã§Ã¼nkÃ¼ temelde hepsi benzer prensiplerle Ã§alÄ±ÅŸÄ±r ve katÄ±lÄ±mcÄ±lara saÄŸladÄ±klarÄ± faydalar da aÅŸaÄŸÄ± yukarÄ± aynÄ±dÄ±r.

BirÃ§ok diÄŸer platform belirli Ã¼lkelere odaklanmÄ±ÅŸ ya da yalnÄ±zca belirli tÃ¼rde yarÄ±ÅŸmalarda uzmanlaÅŸmÄ±ÅŸtÄ±r. Yine de, tamlÄ±k aÃ§Ä±sÄ±ndan, en azÄ±ndan deneyim ve bilgimizin bulunduÄŸu bazÄ±larÄ±nÄ± kÄ±saca tanÄ±tmakta fayda var:

â€¢ **DrivenData** ([https://www.drivendata.org/competitions/](https://www.drivendata.org/competitions/)) sosyal problemlere yÃ¶nelik yarÄ±ÅŸmalar dÃ¼zenleyen bir kitle kaynaklÄ± (crowdsourcing) yarÄ±ÅŸma platformudur (bkz. [https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/](https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/)). Åirketin kendisi, dÃ¼nyanÄ±n en bÃ¼yÃ¼k sorunlarÄ±yla mÃ¼cadele eden kuruluÅŸlara veri bilimi Ã§Ã¶zÃ¼mleri sunmayÄ± amaÃ§layan bir sosyal giriÅŸimdir. Veri bilimciler, sosyal fayda iÃ§in algoritmalar geliÅŸtirir. Ã–rneÄŸin, [https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html](https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html) adresindeki makalede okuyabileceÄŸiniz gibi, Facebook nefret sÃ¶ylemi ve yanlÄ±ÅŸ bilgiyle mÃ¼cadele iÃ§in dÃ¼zenlediÄŸi yarÄ±ÅŸmada DrivenDataâ€™yÄ± seÃ§miÅŸtir.

â€¢ **Numerai** ([https://numer.ai/](https://numer.ai/)) San Francisco merkezli, yapay zekÃ¢ destekli bir kitle kaynaklÄ± hedge fonudur. KatÄ±lÄ±mcÄ±lar her hafta fonun anonimleÅŸtirilmiÅŸ verileri Ã¼zerinde tahmin modelleri gÃ¶nderir ve ÅŸirketin kendi kripto para birimi olan *Numeraire* ile Ã¶dÃ¼ller kazanÄ±rlar.

â€¢ **CrowdANALYTIX** ([https://www.crowdanalytix.com/community](https://www.crowdanalytix.com/community)) artÄ±k eskisi kadar aktif olmasa da, bir sÃ¼re Ã¶nce birÃ§ok zorlu yarÄ±ÅŸmaya ev sahipliÄŸi yapmÄ±ÅŸtÄ±r (bkz. [https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1](https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1)). AyrÄ±ca topluluk blogu, bu platformda ne tÃ¼r zorluklarla karÅŸÄ±laÅŸabileceÄŸinize dair fikir edinmek iÃ§in oldukÃ§a ilginÃ§tir: [https://www.crowdanalytix.com/jq/communityBlog/listBlog.html](https://www.crowdanalytix.com/jq/communityBlog/listBlog.html).

â€¢ **Signate** ([https://signate.jp/competitions](https://signate.jp/competitions)) Japonya merkezli bir veri bilimi yarÄ±ÅŸma platformudur. BirÃ§ok yarÄ±ÅŸmaya ev sahipliÄŸi yapar ve Kaggleâ€™a benzer bir sÄ±ralama sistemi sunar ([https://signate.jp/users/rankings](https://signate.jp/users/rankings)).

â€¢ **Zindi** ([https://zindi.africa/competitions](https://zindi.africa/competitions)) Afrika merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Afrikaâ€™nÄ±n en acil sosyal, ekonomik ve Ã§evresel sorunlarÄ±nÄ± Ã§Ã¶zmeye odaklÄ± yarÄ±ÅŸmalar dÃ¼zenler.

â€¢ **Alibaba Cloud** ([https://www.alibabacloud.com/campaign/tianchi-competitions](https://www.alibabacloud.com/campaign/tianchi-competitions)) Ã‡in merkezli bir bulut biliÅŸim ve yapay zekÃ¢ saÄŸlayÄ±cÄ±sÄ±dÄ±r. SIGKDD, IJCAI-PRICAI ve CVPR gibi akademik konferanslarla ortaklaÅŸa dÃ¼zenlenen *Tianchi Academic* yarÄ±ÅŸmalarÄ±nÄ± baÅŸlatmÄ±ÅŸtÄ±r. GÃ¶rsel tabanlÄ± 3D ÅŸekil tanÄ±ma, 3D nesne yeniden oluÅŸturma ve Ã¶rnek segmentasyonu gibi zorluklar iÃ§eren yarÄ±ÅŸmalar dÃ¼zenler.

â€¢ **Analytics Vidhya** ([https://datahack.analyticsvidhya.com/](https://datahack.analyticsvidhya.com/)) Hindistanâ€™Ä±n en bÃ¼yÃ¼k veri bilimi topluluÄŸudur ve veri bilimi hackathonâ€™larÄ± iÃ§in bir platform sunar.

â€¢ **CodaLab** ([https://codalab.lri.fr/](https://codalab.lri.fr/)) 2013 yÄ±lÄ±nda Microsoft ve Stanford Ãœniversitesiâ€™nin ortak giriÅŸimiyle kurulmuÅŸ, Fransa merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Bilgi paylaÅŸÄ±mÄ± ve yeniden Ã¼retilebilir modelleme iÃ§in **Worksheets** ([https://worksheets.codalab.org/](https://worksheets.codalab.org/)) adlÄ± Ã¼cretsiz bulut tabanlÄ± bir defter sunar.

DiÄŸer daha kÃ¼Ã§Ã¼k platformlar arasÄ±nda Ä°sviÃ§reâ€™deki Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne tarafÄ±ndan geliÅŸtirilen **CrowdAI** ([https://www.crowdai.org/](https://www.crowdai.org/)), **InnoCentive** ([https://www.innocentive.com/](https://www.innocentive.com/)), biyomedikal gÃ¶rÃ¼ntÃ¼leme iÃ§in **Grand-Challenge** ([https://grand-challenge.org/](https://grand-challenge.org/)), **DataFountain** ([https://www.datafountain.cn/business?lang=en-US](https://www.datafountain.cn/business?lang=en-US)), **OpenML** ([https://www.openml.org/](https://www.openml.org/)) gibi platformlar yer alÄ±r. AyrÄ±ca, Rus topluluÄŸu **Open Data Science** ([https://ods.ai/competitions](https://ods.ai/competitions)) sitesinde devam eden bÃ¼yÃ¼k yarÄ±ÅŸmalarÄ±n kapsamlÄ± bir listesini bulabilir ve zaman zaman yeni yarÄ±ÅŸma platformlarÄ±nÄ± keÅŸfedebilirsiniz.

Kaggle, hÃ¢lÃ¢ en ilginÃ§ yarÄ±ÅŸmalarÄ± bulabileceÄŸiniz ve yarÄ±ÅŸma Ã§abalarÄ±nÄ±zla en geniÅŸ tanÄ±nÄ±rlÄ±ÄŸÄ± elde edebileceÄŸiniz en iyi platformdur. Ancak, Kaggle dÄ±ÅŸÄ±ndaki bir yarÄ±ÅŸmayÄ± seÃ§mek de anlamlÄ± olabilir; Ã¶zellikle kiÅŸisel veya profesyonel ilgi alanlarÄ±nÄ±za uyan bir yarÄ±ÅŸma bulduÄŸunuzda. GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, Kaggle dÄ±ÅŸÄ±nda da oldukÃ§a fazla alternatif ve fÄ±rsat mevcut. Bu da, Kaggle ile birlikte diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± da dikkate alarak, ilginizi Ã§ekebilecek Ã¶zel veri veya temalÄ± bir yarÄ±ÅŸma bulma olasÄ±lÄ±ÄŸÄ±nÄ±zÄ± artÄ±rÄ±r.

AyrÄ±ca, bu tÃ¼r platformlarda rekabetin genellikle daha az olduÄŸunu (dolayÄ±sÄ±yla daha iyi bir sÄ±ralama veya Ã¶dÃ¼l kazanma ÅŸansÄ±nÄ±zÄ±n daha yÃ¼ksek olabileceÄŸini) bekleyebilirsiniz; ancak katÄ±lÄ±mcÄ±lar arasÄ±nda bilgi paylaÅŸÄ±mÄ±nÄ±n Kaggleâ€™daki kadar zengin olmadÄ±ÄŸÄ±nÄ± da unutmamalÄ±sÄ±nÄ±z.

### Introducing Kaggle *(Kaggleâ€™a giriÅŸ)*

Bu noktada, Ã¶zellikle **Kaggle**â€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha derinlemesine incelememiz gerekiyor.
AÅŸaÄŸÄ±daki paragraflarda, Kaggle platformunun ve yarÄ±ÅŸmalarÄ±nÄ±n Ã§eÅŸitli yÃ¶nlerini ele alacaÄŸÄ±z ve Kaggleâ€™daki bir yarÄ±ÅŸmada yer almanÄ±n ne anlama geldiÄŸine dair bir fikir edineceksiniz.
Daha sonra, kitabÄ±n geri kalan bÃ¶lÃ¼mlerinde bu konularÄ±n Ã§oÄŸuna Ã§ok daha ayrÄ±ntÄ±lÄ± biÃ§imde geri dÃ¶nerek, ek Ã¶neriler ve stratejilerle birlikte tartÄ±ÅŸacaÄŸÄ±z.

### Stages of a competition *(Bir yarÄ±ÅŸmanÄ±n aÅŸamalarÄ±)*

Kaggleâ€™daki bir yarÄ±ÅŸma, farklÄ± adÄ±mlardan oluÅŸacak ÅŸekilde dÃ¼zenlenir.
Bu adÄ±mlarÄ±n her birine gÃ¶z atarak, bir veri bilimi yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸini ve sizden neler beklenebileceÄŸini daha iyi anlayabilirsiniz.

Bir yarÄ±ÅŸma baÅŸlatÄ±ldÄ±ÄŸÄ±nda, genellikle sosyal medyada â€” Ã¶rneÄŸin Kaggleâ€™Ä±n Twitter hesabÄ±nda ([https://twitter.com/kaggle](https://twitter.com/kaggle)) â€” yarÄ±ÅŸmayÄ± duyuran paylaÅŸÄ±mlar yapÄ±lÄ±r. AyrÄ±ca, **Competitions** sayfasÄ±nda ([https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)) **Active Competitions** (aktif yarÄ±ÅŸmalar) bÃ¶lÃ¼mÃ¼nde yeni bir sekme gÃ¶rÃ¼nÃ¼r.

Belirli bir yarÄ±ÅŸmanÄ±n sekmesine tÄ±kladÄ±ÄŸÄ±nÄ±zda, o yarÄ±ÅŸmanÄ±n sayfasÄ±na yÃ¶nlendirilirsiniz. Ä°lk bakÄ±ÅŸta, yarÄ±ÅŸmanÄ±n Ã¶dÃ¼l verip vermediÄŸini (ve yarÄ±ÅŸmaya katÄ±lmanÄ±n bir sonucu olarak puan ve madalya kazandÄ±rÄ±p kazandÄ±rmadÄ±ÄŸÄ±nÄ±), ÅŸu anda kaÃ§ takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ±nÄ± ve Ã§Ã¶zÃ¼mÃ¼nÃ¼z Ã¼zerinde Ã§alÄ±ÅŸmak iÃ§in ne kadar sÃ¼reniz kaldÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz.

![](im/1002.png)

Orada, Ã¶ncelikle **Overview (Genel BakÄ±ÅŸ)** menÃ¼sÃ¼nÃ¼ inceleyebilirsiniz. Bu menÃ¼ size ÅŸu konularda bilgi verir:

* YarÄ±ÅŸmanÄ±n konusu
* DeÄŸerlendirme metriÄŸi (modellerinizin deÄŸerlendirileceÄŸi Ã¶lÃ§Ã¼t)
* YarÄ±ÅŸmanÄ±n zaman Ã§izelgesi
* Ã–dÃ¼ller
* Yasal veya yarÄ±ÅŸma gereklilikleri

Genellikle zaman Ã§izelgesi Ã§ok dikkat edilmeyen bir kÄ±sÄ±mdÄ±r, ancak kontrol etmeniz gereken ilk ÅŸeylerden biri olmalÄ±dÄ±r; Ã§Ã¼nkÃ¼ yalnÄ±zca yarÄ±ÅŸmanÄ±n ne zaman baÅŸlayÄ±p biteceÄŸini deÄŸil, aynÄ± zamanda **kural kabul etme son tarihini** de gÃ¶sterir. Bu tarih genellikle yarÄ±ÅŸma kapanmadan **7 ila 14 gÃ¼n Ã¶nce** olur ve yarÄ±ÅŸmaya katÄ±labileceÄŸiniz (kurallarÄ± kabul edebileceÄŸiniz) son gÃ¼nÃ¼ belirtir.

AyrÄ±ca bir **takÄ±m birleÅŸtirme son tarihi (team merger deadline)** de bulunur: Bu tarihten Ã¶nce istediÄŸiniz herhangi bir zamanda ekibinizi baÅŸka bir yarÄ±ÅŸmacÄ±nÄ±n ekibiyle birleÅŸtirebilirsiniz; ancak bu tarihten sonra artÄ±k mÃ¼mkÃ¼n deÄŸildir.

**Rules (Kurallar)** menÃ¼sÃ¼ de sÄ±klÄ±kla gÃ¶z ardÄ± edilir (Ã§oÄŸu kiÅŸi doÄŸrudan **Data** kÄ±smÄ±na geÃ§er), ancak kontrol edilmesi Ã¶nemlidir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n gereklilikleri hakkÄ±nda bilgi verir. Kurallar kÄ±smÄ±ndan edinebileceÄŸiniz Ã¶nemli bilgiler arasÄ±nda ÅŸunlar yer alÄ±r:

* Ã–dÃ¼l almaya uygun olup olmadÄ±ÄŸÄ±nÄ±z
* PuanÄ±nÄ±zÄ± artÄ±rmak iÃ§in harici veri kullanÄ±p kullanamayacaÄŸÄ±nÄ±z
* GÃ¼nde kaÃ§ tane gÃ¶nderim (Ã§Ã¶zÃ¼m testi) yapabileceÄŸiniz
* KaÃ§ tane nihai Ã§Ã¶zÃ¼m seÃ§ebileceÄŸiniz

KurallarÄ± kabul ettikten sonra, **Data** menÃ¼sÃ¼nden verileri indirebilir veya doÄŸrudan **Code** menÃ¼sÃ¼nden Kaggle Notebooks (Ã§evrimiÃ§i, bulut tabanlÄ± defterler) Ã¼zerinde Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz. Burada diÄŸerlerinin paylaÅŸtÄ±ÄŸÄ± kodlarÄ± yeniden kullanabilir veya sÄ±fÄ±rdan kendi kodunuzu oluÅŸturabilirsiniz.

EÄŸer verileri indirmeye karar verirseniz, **Kaggle API**â€™sini de kullanabileceÄŸinizi unutmayÄ±n. Bu API, indirme ve gÃ¶nderim iÅŸlemlerini neredeyse otomatik hale getirmenize yardÄ±mcÄ± olur. Yerel bilgisayarÄ±nÄ±zda veya bulut sunucunuzda modellerinizi Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z, bu araÃ§ oldukÃ§a faydalÄ±dÄ±r. API hakkÄ±nda daha fazla bilgiyi ÅŸu adreste bulabilirsiniz:
ğŸ‘‰ [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)
Kaynak koduna ise GitHub Ã¼zerinden ulaÅŸabilirsiniz:
ğŸ‘‰ [https://github.com/Kaggle/kaggle-api](https://github.com/Kaggle/kaggle-api)

Kaggleâ€™Ä±n GitHub deposunu daha yakÄ±ndan incelerseniz, **Kaggle Notebooks** (Ã§evrimiÃ§i defterler) iÃ§in kullanÄ±lan tÃ¼m **Docker imajlarÄ±nÄ±** da bulabilirsiniz.

![](im/1003.png)

Bu noktada, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirirken **tek baÅŸÄ±nÄ±za devam etmemenizi**, diÄŸer yarÄ±ÅŸmacÄ±larla **Discussion (TartÄ±ÅŸma)** forumu Ã¼zerinden iletiÅŸime geÃ§menizi iÃ§tenlikle tavsiye ederiz. Bu forumda yarÄ±ÅŸmaya Ã¶zgÃ¼ sorular sorabilir ve diÄŸer katÄ±lÄ±mcÄ±larÄ±n sorularÄ±nÄ± yanÄ±tlayabilirsiniz.
Ã‡oÄŸu zaman burada, veriyle ilgili belirli problemlere dair faydalÄ± ipuÃ§larÄ± veya kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirmeye yardÄ±mcÄ± olabilecek fikirler bulabilirsiniz.
BirÃ§ok baÅŸarÄ±lÄ± Kaggle kullanÄ±cÄ±sÄ± (*Kaggler*), forumlarda edindikleri fikirlerin kendilerine daha iyi performans saÄŸladÄ±ÄŸÄ±nÄ± ve daha da Ã¶nemlisi, veri bilimi modelleme konusunda Ã§ok ÅŸey Ã¶ÄŸrenmelerine yardÄ±mcÄ± olduÄŸunu belirtmiÅŸtir.

Ã‡Ã¶zÃ¼mÃ¼nÃ¼z hazÄ±r olduÄŸunda, yarÄ±ÅŸmanÄ±n yÃ¶nergelerine uygun ÅŸekilde **Kaggle deÄŸerlendirme sistemine** gÃ¶nderebilirsiniz.
BazÄ± yarÄ±ÅŸmalar Ã§Ã¶zÃ¼mleri **CSV dosyasÄ±** olarak kabul ederken, bazÄ±larÄ± **Kaggle Notebook** Ã¼zerinde kod yazmanÄ±zÄ± ve sonuÃ§larÄ± orada Ã¼retmenizi ister.
YarÄ±ÅŸma sÃ¼resince Ã§Ã¶zÃ¼m gÃ¶ndermeye devam edebilirsiniz.

Her gÃ¶nderim yaptÄ±ÄŸÄ±nÄ±zda, kÄ±sa bir sÃ¼re sonra **liderlik tablosu (leaderboard)** size bir puan ve yarÄ±ÅŸmacÄ±lar arasÄ±ndaki konumunuzu gÃ¶sterecektir (bekleme sÃ¼resi, puan hesaplamasÄ± iÃ§in gereken iÅŸlem sÃ¼resine baÄŸlÄ± olarak deÄŸiÅŸir).
Ancak bu sÄ±ralama yalnÄ±zca yaklaÅŸÄ±k bir gÃ¶stergedir; Ã§Ã¼nkÃ¼ modelinizin performansÄ±nÄ±, test verisinin yalnÄ±zca bir kÄ±smÄ± olan **public test set (genel test kÃ¼mesi)** Ã¼zerinde yansÄ±tÄ±r. Bu kÃ¼medeki sonuÃ§lar yarÄ±ÅŸma boyunca herkesin gÃ¶rebileceÄŸi ÅŸekilde paylaÅŸÄ±lÄ±r.

YarÄ±ÅŸma kapanmadan Ã¶nce, her yarÄ±ÅŸmacÄ± **nihai deÄŸerlendirme** iÃ§in kendi Ã§Ã¶zÃ¼mleri arasÄ±ndan belirli bir sayÄ±da (genellikle iki) Ã§Ã¶zÃ¼m seÃ§ebilir.

![](im/1004.png)

YarÄ±ÅŸma ancak kapandÄ±ktan sonra, yarÄ±ÅŸmacÄ±larÄ±n deÄŸerlendirilmesini istedikleri modeller temel alÄ±narak, **test veri setinin baÅŸka bir kÄ±smÄ±** olan **private test set (Ã¶zel test kÃ¼mesi)** Ã¼zerindeki puanlarÄ± aÃ§Ä±klanÄ±r.
Bu yeni sÄ±ralama tablosu **private leaderboard (Ã¶zel liderlik tablosu)** olarak adlandÄ±rÄ±lÄ±r ve yarÄ±ÅŸmanÄ±n **nihai, gerÃ§ek puanlarÄ±nÄ±** gÃ¶sterir; ancak bu sÄ±ralama henÃ¼z **resmÃ® ve kesin** deÄŸildir.

GerÃ§ekte, Kaggle ekibi her ÅŸeyin doÄŸru olduÄŸunu ve tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n yarÄ±ÅŸma kurallarÄ±na uyduÄŸunu kontrol etmek iÃ§in bir sÃ¼re ayÄ±rÄ±r.
Bir sÃ¼re sonra (ve bazen bazÄ± yarÄ±ÅŸmacÄ±larÄ±n diskalifiye edilmesine baÄŸlÄ± olarak sÄ±ralamalarda deÄŸiÅŸiklikler olduktan sonra), **private leaderboard** resmÃ® ve kesin hale gelir.
Kazananlar aÃ§Ä±klanÄ±r ve birÃ§ok katÄ±lÄ±mcÄ±, yarÄ±ÅŸma tartÄ±ÅŸma forumunda kendi stratejilerini, Ã§Ã¶zÃ¼mlerini ve kodlarÄ±nÄ± paylaÅŸÄ±r.

Bu noktada, diÄŸer katÄ±lÄ±mcÄ±larÄ±n Ã§Ã¶zÃ¼mlerini incelemek ve kendi yaklaÅŸÄ±mÄ±nÄ±zÄ± geliÅŸtirmeye Ã§alÄ±ÅŸmak tamamen size kalmÄ±ÅŸtÄ±r.
Bunu yapmanÄ±zÄ± **ÅŸiddetle tavsiye ederiz**, Ã§Ã¼nkÃ¼ bu sÃ¼reÃ§ Kaggleâ€™daki en Ã¶nemli Ã¶ÄŸrenme kaynaklarÄ±ndan bir diÄŸeridir.

### Types of competitions and examples *(YarÄ±ÅŸma tÃ¼rleri ve Ã¶rnekleri)*

Kaggle yarÄ±ÅŸmalarÄ±, **yarÄ±ÅŸma kategorilerine** gÃ¶re sÄ±nÄ±flandÄ±rÄ±lÄ±r ve her kategori, yarÄ±ÅŸma biÃ§imi ve beklentiler aÃ§Ä±sÄ±ndan farklÄ±lÄ±k gÃ¶sterir.
Veri tÃ¼rÃ¼, problem zorluÄŸu, verilen Ã¶dÃ¼ller ve yarÄ±ÅŸma dinamikleri bu kategoriler iÃ§inde oldukÃ§a Ã§eÅŸitlidir; bu nedenle her kategorinin ne anlama geldiÄŸini Ã¶nceden anlamak Ã¶nemlidir.

Kaggleâ€™daki yarÄ±ÅŸmalarÄ± filtrelemek iÃ§in kullanabileceÄŸiniz **resmÃ® kategoriler** ÅŸunlardÄ±r:

* **Featured**
* **Masters**
* **Annuals**
* **Research**
* **Recruitment**
* **Getting Started**
* **Playground**
* **Analytics**
* **Community**

---

#### ğŸ† Featured (Ã–ne Ã‡Ä±kan) YarÄ±ÅŸmalar

Bunlar en yaygÄ±n yarÄ±ÅŸma tÃ¼rÃ¼dÃ¼r. Genellikle sponsor bir ÅŸirketin iÅŸ ile ilgili bir problemini iÃ§erir ve en iyi performans gÃ¶sterenlere Ã¶dÃ¼l verilir.
Kazananlar, Ã§Ã¶zÃ¼mlerinin **lisanssÄ±z (non-exclusive)** kullanÄ±m hakkÄ±nÄ± sponsor ÅŸirkete verirler; ayrÄ±ca ayrÄ±ntÄ±lÄ± bir rapor hazÄ±rlamalarÄ± ve bazen sponsor ÅŸirketle toplantÄ±lara katÄ±lmalarÄ± gerekebilir.

Kaggleâ€™da neredeyse her zaman Featured yarÄ±ÅŸmalara rastlayabilirsiniz. GÃ¼nÃ¼mÃ¼zde Ã§oÄŸu, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veriler** (metin, gÃ¶rÃ¼ntÃ¼, video, ses gibi) Ã¼zerinde derin Ã¶ÄŸrenme yÃ¶ntemlerinin uygulanmasÄ±na yÃ¶neliktir.
GeÃ§miÅŸte ise daha Ã§ok **tablo biÃ§iminde veriler (tabular data)** Ã¼zerine kurulu yarÄ±ÅŸmalar yapÄ±lÄ±rdÄ± â€” yani veritabanlarÄ±nda bulunan yapÄ±landÄ±rÄ±lmÄ±ÅŸ veriler Ã¼zerinde Ã§alÄ±ÅŸan problemlerdi.
Ä°lk zamanlarda rastgele ormanlar (random forests), daha sonra ise akÄ±llÄ± Ã¶zellik mÃ¼hendisliÄŸiyle birlikte **gradient boosting** yÃ¶ntemleri Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar vermiÅŸtir.
Ancak gÃ¼nÃ¼mÃ¼zde, geliÅŸmiÅŸ yazÄ±lÄ±mlar ve **AutoML** araÃ§larÄ± sayesinde bu tÃ¼r problemlerde yarÄ±ÅŸmalardan elde edilen geliÅŸmeler genellikle marjinaldir.
Buna karÅŸÄ±lÄ±k, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veri** dÃ¼nyasÄ±nda iyi bir derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mÃ¼ hÃ¢lÃ¢ bÃ¼yÃ¼k fark yaratabilir.
Ã–rneÄŸin, **BERT** gibi Ã¶nceden eÄŸitilmiÅŸ aÄŸlar, birÃ§ok NLP gÃ¶revinde Ã¶nceki standartlara gÃ¶re Ã§ift haneli performans artÄ±ÅŸlarÄ± saÄŸlamÄ±ÅŸtÄ±r.

---

#### ğŸ§  Masters (Ustalar) YarÄ±ÅŸmalarÄ±

ArtÄ±k daha az dÃ¼zenlenmektedir, ancak bunlar **Ã¶zel (invite-only)** yarÄ±ÅŸmalardÄ±r.
AmaÃ§, yalnÄ±zca uzmanlar (genellikle Kaggle sÄ±ralamasÄ±nda **Master** veya **Grandmaster** unvanÄ±na sahip yarÄ±ÅŸmacÄ±lar) iÃ§in yarÄ±ÅŸmalar dÃ¼zenlemektir.

---

#### ğŸ“… Annuals (YÄ±llÄ±k) YarÄ±ÅŸmalar

Her yÄ±l belirli dÃ¶nemlerde dÃ¼zenlenen yarÄ±ÅŸmalardÄ±r.
Bunlar arasÄ±nda:

* **Santa Claus Competitions** (genellikle algoritmik optimizasyon problemleri Ã¼zerine),
* **March Machine Learning Mania** (2014â€™ten beri her yÄ±l ABD Kolej Basketbol TurnuvalarÄ± sÄ±rasÄ±nda dÃ¼zenlenir) bulunur.

---

#### ğŸ”¬ Research (AraÅŸtÄ±rma) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarÄ±n amacÄ± ticari deÄŸil, **bilimsel veya araÅŸtÄ±rma odaklÄ±dÄ±r**, bazen de kamu yararÄ±na hizmet eder.
Bu nedenle genellikle para Ã¶dÃ¼lÃ¼ sunmazlar.
AyrÄ±ca kazananlardan Ã§Ã¶zÃ¼mlerini **aÃ§Ä±k kaynak (open-source)** olarak paylaÅŸmalarÄ± istenebilir.

Ã–rneÄŸin, **Google Landmark Recognition 2020** ([https://www.kaggle.com/c/landmark-recognition-2020](https://www.kaggle.com/c/landmark-recognition-2020)) yarÄ±ÅŸmasÄ±nda, Ã¼nlÃ¼ (veya pek tanÄ±nmamÄ±ÅŸ) yapÄ±tlarÄ±n fotoÄŸraflarÄ±nÄ± tanÄ±mlamak hedeflenmiÅŸtir.

---

#### ğŸ’¼ Recruitment (Ä°ÅŸe AlÄ±m) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar, sponsor ÅŸirketlerin **potansiyel iÅŸ adaylarÄ±nÄ±n yeteneklerini test etmek** iÃ§in dÃ¼zenlenir.
Genellikle tek kiÅŸilik takÄ±mlarla sÄ±nÄ±rlÄ±dÄ±r ve en iyi performans gÃ¶steren yarÄ±ÅŸmacÄ±lara **iÅŸ gÃ¶rÃ¼ÅŸmesi** Ã¶dÃ¼lÃ¼ sunulur.
YarÄ±ÅŸma sonunda, deÄŸerlendirilmek isteyen yarÄ±ÅŸmacÄ±larÄ±n **Ã¶zgeÃ§miÅŸlerini (CV)** yÃ¼klemeleri gerekir.

Ã–rnekler:

* **Facebook Recruiting Competition** ([https://www.kaggle.com/c/FacebookRecruiting](https://www.kaggle.com/c/FacebookRecruiting))
* **Yelp Recruiting Competition** ([https://www.kaggle.com/c/yelp-recruiting](https://www.kaggle.com/c/yelp-recruiting))

---

#### ğŸš€ Getting Started (BaÅŸlangÄ±Ã§) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar Ã¶dÃ¼l sunmaz, ancak **yeni baÅŸlayanlarÄ±n** Kaggle prensiplerine ve dinamiklerine alÄ±ÅŸmalarÄ± iÃ§in **kolay ve Ã¶ÄŸretici problemler** iÃ§erir.
Genellikle **yarÄ± kalÄ±cÄ±dÄ±rlar** ve liderlik tablolarÄ± zaman zaman yenilenir.
Makine Ã¶ÄŸrenmesine giriÅŸ yapmak istiyorsanÄ±z, bu yarÄ±ÅŸmalar mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r; Ã§Ã¼nkÃ¼ oldukÃ§a **iÅŸbirlikÃ§i bir ortam** sunarlar ve veri iÅŸleme ile model oluÅŸturma adÄ±mlarÄ±nÄ± gÃ¶steren birÃ§ok **Kaggle Notebook** mevcuttur.

BazÄ± Ã¼nlÃ¼ Getting Started yarÄ±ÅŸmalarÄ±:

* [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer)
* [Titanic â€” Machine Learning from Disaster](https://www.kaggle.com/c/titanic)
* [House Prices â€” Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

---

#### ğŸ® Playground (Oyun AlanÄ±) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar **Getting Started** yarÄ±ÅŸmalarÄ±ndan biraz daha zordur, ancak hÃ¢lÃ¢ Ã¶ÄŸrenme ve pratik yapma odaklÄ±dÄ±r.
Tam Ã¶lÃ§ekli Featured yarÄ±ÅŸmalar kadar baskÄ± oluÅŸturmazlar, fakat bazen rekabet oldukÃ§a kÄ±zÄ±ÅŸabilir.
Ã–dÃ¼ller genellikle **Kaggle logolu hediyelikler (swag: kupa, tiÅŸÃ¶rt, Ã§orap vb.)** veya kÃ¼Ã§Ã¼k miktarlarda paradÄ±r.

ÃœnlÃ¼ bir Playground yarÄ±ÅŸmasÄ± Ã¶rneÄŸi:

* [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats) â€” kÃ¶pekleri ve kedileri ayÄ±rt eden bir algoritma geliÅŸtirme gÃ¶revi.

---

#### ğŸ“Š Analytics (Analiz) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarda deÄŸerlendirme **niteliksel (qualitative)** olup, katÄ±lÄ±mcÄ±lardan fikirler, Ã§Ã¶zÃ¼m taslaklarÄ±, PowerPoint sunumlarÄ±, grafikler vb. hazÄ±rlamalarÄ± beklenir.

---

#### ğŸ‘¥ Community (Topluluk) YarÄ±ÅŸmalarÄ±

Eskiden **InClass** olarak bilinen bu yarÄ±ÅŸmalar, **akademik kurumlar** veya bireysel **Kagglerâ€™lar** tarafÄ±ndan dÃ¼zenlenir.
Topluluk yarÄ±ÅŸmalarÄ±nÄ±n duyurusu iÃ§in:
ğŸ”— [https://www.kaggle.com/product-feedback/294337](https://www.kaggle.com/product-feedback/294337)
Kendi yarÄ±ÅŸmanÄ±zÄ± dÃ¼zenleme rehberleri iÃ§in:
ğŸ”— [https://www.kaggle.com/c/about/host](https://www.kaggle.com/c/about/host)
ğŸ”— [https://www.kaggle.com/community-competitions-setup-guide](https://www.kaggle.com/community-competitions-setup-guide)


> **Parul Pandey**
> 
> [https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey)
> 
> 
> 
> Kaggle Notebooks Grandmasterâ€™Ä±, Datasets Masterâ€™Ä± ve H2O.aiâ€™de veri bilimci olan **Parul Pandey** ile analitik yarÄ±ÅŸmalar ve deneyimleri hakkÄ±nda konuÅŸtuk.
> 
> ---
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±n nedir?**
> 
> Veri analizi yapmanÄ±zÄ± ve sonunda kapsamlÄ± bir analiz raporu sunmanÄ±zÄ± gerektiren **Veri AnalitiÄŸi yarÄ±ÅŸmalarÄ±nÄ±** gerÃ§ekten Ã§ok seviyorum. Bunlara *Data Science for Good* (DS4G) yarÄ±ÅŸmalarÄ±, spor analitiÄŸi yarÄ±ÅŸmalarÄ± (Ã¶rneÄŸin NFL) ve genel anket temelli yarÄ±ÅŸmalar dÃ¢hildir. Geleneksel yarÄ±ÅŸmalardan farklÄ± olarak, bu tÃ¼r yarÄ±ÅŸmalarda performansÄ±nÄ±zÄ± baÅŸkalarÄ±yla kÄ±yaslayabileceÄŸiniz bir **liderlik tablosu (leaderboard)** bulunmaz; ayrÄ±ca madalya veya puan da kazanmazsÄ±nÄ±z.
> 
> Ã–te yandan bu yarÄ±ÅŸmalar, veri biliminin Ã§ok yÃ¶nlÃ¼ alanlarÄ±na â€“ veri temizleme, veri madenciliÄŸi, gÃ¶rselleÅŸtirme ve iÃ§gÃ¶rÃ¼ iletimi gibi â€“ dokunan uÃ§tan uca Ã§Ã¶zÃ¼mler gerektirir. Bu tÃ¼r problemler, gerÃ§ek hayattaki senaryolarÄ± taklit etmenizi ve kendi iÃ§gÃ¶rÃ¼nÃ¼zÃ¼, bakÄ±ÅŸ aÃ§Ä±nÄ±zÄ± sunmanÄ±zÄ± saÄŸlar. Tek bir â€œen iyiâ€ Ã§Ã¶zÃ¼m olmayabilir, ancak bu size Ã§eÅŸitli yaklaÅŸÄ±mlarÄ± tartÄ±p deÄŸerlendirerek kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼ze entegre etme fÄ±rsatÄ± verir.
> 
> ---
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinden ne kadar farklÄ±?**
> 
> Ä°lk adÄ±mÄ±m her zaman **EDA (keÅŸifsel veri analizi)** yapmaktÄ±r. Bu, iÅŸ rutinimin de bir parÃ§asÄ±dÄ±r. Genellikle verideki tutarsÄ±zlÄ±klarÄ±, eksik deÄŸerleri, aykÄ±rÄ± noktalarÄ± vb. belirlemek iÃ§in veriyi incelerim; Ã§Ã¼nkÃ¼ bunlar ileride sorun yaratabilir. Sonra **iyi ve gÃ¼venilir bir Ã§apraz doÄŸrulama stratejisi** oluÅŸtururum. ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±nÄ± okur ve diÄŸer kullanÄ±cÄ±larÄ±n paylaÅŸtÄ±ÄŸÄ± Notebookâ€™lara gÃ¶z atarÄ±m. Bu genelde iyi bir baÅŸlangÄ±Ã§ noktasÄ± olur; sonra Ã¶nceki deneyimlerimden edindiÄŸim ÅŸeyleri bu sÃ¼rece eklerim. AyrÄ±ca **model performansÄ±nÄ± izlemek** de Ã§ok Ã¶nemlidir.
> 
> Analitik yarÄ±ÅŸmalar sÃ¶z konusu olduÄŸunda ise problemi genellikle birkaÃ§ adÄ±ma ayÄ±rmayÄ± severim. Ã–rneÄŸin, ilk kÄ±sÄ±m problemi anlamakla ilgilidir ve bu birkaÃ§ gÃ¼n sÃ¼rebilir. SonrasÄ±nda veriyi keÅŸfederim, ardÄ±ndan temel bir baÅŸlangÄ±Ã§ Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururum. Daha sonra bu Ã§Ã¶zÃ¼mÃ¼, her seferinde bir parÃ§a ekleyerek geliÅŸtiririm. Bu, Lego parÃ§alarÄ±nÄ± tek tek ekleyerek son eseri oluÅŸturmak gibidir.
> 
> ---
> 
> **KatÄ±ldÄ±ÄŸÄ±n zorlu bir yarÄ±ÅŸmadan ve bu gÃ¶revi nasÄ±l ele aldÄ±ÄŸÄ±ndan bahseder misin?**
> 
> Daha Ã¶nce de belirttiÄŸim gibi genellikle Analitik yarÄ±ÅŸmalara katÄ±lmayÄ± tercih ediyorum, ama bazen klasik yarÄ±ÅŸmalarda da ÅŸansÄ±mÄ± deniyorum. Ã–zellikle **Environmental Insights Explorer** adlÄ± *Data Science for Good* yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/ds4g-environmental-insightsexplorer](https://www.kaggle.com/c/ds4g-environmental-insightsexplorer)) Ã§ok ilgimi Ã§ekmiÅŸti. GÃ¶rev, mevcut metodolojilerdeki emisyon katsayÄ±larÄ±nÄ± hesaplamak yerine, **uzaktan algÄ±lama (remote sensing)** tekniklerini kullanarak Ã§evresel emisyonlarÄ± anlamaktÄ±.
> 
> Beni en Ã§ok etkileyen ÅŸey, bu yarÄ±ÅŸmanÄ±n ele aldÄ±ÄŸÄ± konuydu. Gezegenimiz iklim deÄŸiÅŸikliÄŸiyle mÃ¼cadele ediyor ve bu yarÄ±ÅŸma tam da bu konuya odaklanmÄ±ÅŸtÄ±. YarÄ±ÅŸma iÃ§in araÅŸtÄ±rma yaparken, **uydu gÃ¶rÃ¼ntÃ¼leme teknolojilerindeki ilerlemeyi** gÃ¶rÃ¼nce hayran kaldÄ±m. Bu sayede bu konuyu daha derinlemesine anlama fÄ±rsatÄ± buldum. Landsat, Modis ve Sentinel gibi uydularÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve bu verilerin nasÄ±l eriÅŸilebilir hale getirildiÄŸini Ã¶ÄŸrendim. Bu yarÄ±ÅŸma, Ã¶nceden Ã§ok az bilgim olan bir alan hakkÄ±nda bilgi edinmemi saÄŸlayan harika bir deneyimdi.
> 
> ---
> 
> **YarÄ±ÅŸma biÃ§imleri Ã¼zerine**
> 
> Kaggle yarÄ±ÅŸmalarÄ±nÄ±n kendi iÃ§inde farklÄ± biÃ§imleri de vardÄ±r. En yaygÄ±n olanÄ±, katÄ±lÄ±mcÄ±nÄ±n Ã§Ã¶zÃ¼mÃ¼nÃ¼ sunup deÄŸerlendirildiÄŸi **â€œbasit formatâ€tÄ±r.** Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸmalarda**, yarÄ±ÅŸma ikiye ayrÄ±lÄ±r: Ä°lk kÄ±sÄ±m tamamlandÄ±ktan sonra ikinci kÄ±sma Ã¶zel bir veri seti yalnÄ±zca ilk kÄ±sÄ±m katÄ±lÄ±mcÄ±larÄ±na verilir. Bu format, yarÄ±ÅŸmacÄ±larÄ±n hile yapma ihtimalini azaltmak iÃ§in tasarlanmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼reliÄŸine eriÅŸilebilen, daha Ã¶nce hiÃ§ gÃ¶rÃ¼lmemiÅŸ bir test setinde yapÄ±lÄ±r. Bu nedenle katÄ±lÄ±mcÄ±larÄ±n deneme sayÄ±sÄ± ve zamanÄ± daha sÄ±nÄ±rlÄ±dÄ±r.
> 
> ---
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nda bilmek isteyeceÄŸin ÅŸey ne olurdu?**
> 
> Kaggleâ€™daki ilk yÄ±llarÄ±mda yaptÄ±ÄŸÄ±m bazÄ± hatalardan bahsedebilirim.
> 
> Ã–ncelikle, Ã§oÄŸu yeni baÅŸlayan **Kaggleâ€™Ä± sadece yarÄ±ÅŸma platformu** olarak gÃ¶rÃ¼r. EÄŸer yarÄ±ÅŸmalarÄ± seviyorsanÄ±z, burada fazlasÄ±yla var; ama Kaggle aynÄ± zamanda baÅŸka alanlarda da katkÄ± yapabileceÄŸiniz bir platformdur. Kod yazabilir, baÅŸkalarÄ±yla paylaÅŸabilir, saÄŸlÄ±klÄ± tartÄ±ÅŸmalara katÄ±labilir ve aÄŸÄ±nÄ±zÄ± geniÅŸletebilirsiniz. Toplulukla kaliteli veri setleri oluÅŸturup paylaÅŸabilirsiniz. BaÅŸlangÄ±Ã§ta Kaggleâ€™Ä± yalnÄ±zca veri seti indirmek iÃ§in kullanÄ±yordum; ancak birkaÃ§ yÄ±l Ã¶nce aktif oldum. Geriye dÃ¶nÃ¼p baktÄ±ÄŸÄ±mda, daha Ã¶nce ne kadar yanÄ±ldÄ±ÄŸÄ±mÄ± gÃ¶rÃ¼yorum.
> 
> BirÃ§ok kiÅŸi yarÄ±ÅŸmalardan Ã§ekiniyor. Ã–nce platforma alÄ±ÅŸÄ±p, sonra yavaÅŸ yavaÅŸ yarÄ±ÅŸmalara katÄ±labilirsiniz.
> 
> AyrÄ±ca birÃ§ok kiÅŸi **tek baÅŸÄ±na Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in motivasyonunu kaybedip bÄ±rakÄ±yor.** Kaggleâ€™da takÄ±m kurmanÄ±n birÃ§ok gÃ¶rÃ¼nmeyen avantajÄ± var. TakÄ±m Ã§alÄ±ÅŸmasÄ± Ã¶ÄŸrenmenizi, deneyim paylaÅŸmanÄ±zÄ± ve sÄ±nÄ±rlÄ± bir zaman diliminde ortak bir hedefe ulaÅŸmayÄ± Ã¶ÄŸretir.
> 
> ---
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± da kullanÄ±yor musun? Bunlar Kaggle ile nasÄ±l kÄ±yaslanÄ±r?**
> 
> Åu anda zamanÄ±mÄ±n Ã§oÄŸunu Kaggleâ€™a ayÄ±rÄ±yorum, ancak geÃ§miÅŸte **Zindi** adlÄ± platformu da kullandÄ±m. Zindi, Afrika odaklÄ± veri bilimi yarÄ±ÅŸmalarÄ±na yoÄŸunlaÅŸan bir platform. Afrikaâ€™ya Ã¶zel veri setlerine eriÅŸmek iÃ§in harika bir yer.
> 
> Kaggle Ã§ok yÃ¶nlÃ¼ bir platform olsa da, dÃ¼nyanÄ±n farklÄ± bÃ¶lgelerinden gelen problem ifadeleri konusunda eksiklikler var. Son zamanlarda bu Ã§eÅŸitlilik artmaya baÅŸladÄ±; Ã¶rneÄŸin **chaii yarÄ±ÅŸmasÄ±** â€“ Hint dillerine odaklanan bir NLP yarÄ±ÅŸmasÄ± â€“ buna iyi bir Ã¶rnektir. Benzer ÅŸekilde, farklÄ± Ã¼lkelere odaklanan yarÄ±ÅŸmalarÄ±n da hem araÅŸtÄ±rma hem de genel veri bilimi topluluÄŸu iÃ§in faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.

Kaggle yarÄ±ÅŸmalarÄ±nÄ±n bu sÄ±nÄ±flandÄ±rmasÄ±nÄ±n Ã¶tesinde, yarÄ±ÅŸmalarÄ±n farklÄ± **formatlarda** dÃ¼zenlenebileceÄŸini de dikkate almak gerekir.
En yaygÄ±n format, daha Ã¶nce aÃ§Ä±klandÄ±ÄŸÄ± gibi, bir Ã§Ã¶zÃ¼m sunduÄŸunuz ve bu Ã§Ã¶zÃ¼mÃ¼n deÄŸerlendirildiÄŸi **â€œbasit (simple)â€ formattÄ±r.**
Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸma (two-stage competition)** formatÄ±nda ise yarÄ±ÅŸma iki bÃ¶lÃ¼me ayrÄ±lÄ±r. Son veri seti yalnÄ±zca ilk bÃ¶lÃ¼m tamamlandÄ±ktan sonra ve sadece bu ilk bÃ¶lÃ¼me katÄ±lan yarÄ±ÅŸmacÄ±lara sunulur.
Bu iki aÅŸamalÄ± yarÄ±ÅŸma formatÄ±, bazÄ± yarÄ±ÅŸmacÄ±larÄ±n **hile yapma veya kurallarÄ± ihlal etme olasÄ±lÄ±ÄŸÄ±nÄ± azaltmak** amacÄ±yla ortaya Ã§Ä±kmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼re iÃ§in eriÅŸilebilen ve daha Ã¶nce hiÃ§ test edilmemiÅŸ bir test seti Ã¼zerinde yapÄ±lÄ±r.
Orijinal Kaggle yarÄ±ÅŸma formatÄ±nÄ±n aksine, bu durumda yarÄ±ÅŸmacÄ±larÄ±n **Ã§ok daha az zamanÄ±** ve test setindeki Ã¶rÃ¼ntÃ¼leri (pattern) keÅŸfetmek iÃ§in **Ã§ok daha az sayÄ±da gÃ¶nderim hakkÄ±** vardÄ±r.

AynÄ± nedenle, son zamanlarda **Code yarÄ±ÅŸmalarÄ±** da ortaya Ã§Ä±kmÄ±ÅŸtÄ±r.
Bu yarÄ±ÅŸmalarda tÃ¼m gÃ¶nderimler doÄŸrudan bir **Kaggle Notebook** Ã¼zerinden yapÄ±lÄ±r ve herhangi bir dÄ±ÅŸ dosya yÃ¼kleme seÃ§eneÄŸi devre dÄ±ÅŸÄ± bÄ±rakÄ±lmÄ±ÅŸtÄ±r.

Kaggle yarÄ±ÅŸma kariyerlerinin farklÄ± aÅŸamalarÄ±nda olan kullanÄ±cÄ±larÄ±n her tÃ¼r yarÄ±ÅŸmaya katÄ±lmasÄ±nda hiÃ§bir kÄ±sÄ±tlama yoktur.
Ancak, **veri bilimi konusundaki deneyim dÃ¼zeyinize** ve **hesaplama kaynaklarÄ±nÄ±za** baÄŸlÄ± olarak, belirli yarÄ±ÅŸma tÃ¼rleri veya formatlarÄ± lehine veya aleyhine bazÄ± Ã¶nerilerimiz vardÄ±r:

* **Tamamen yeni baÅŸlayanlar** iÃ§in, *Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± iyi bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r.
  Bu yarÄ±ÅŸmalar, yÃ¼ksek rekabet baskÄ±sÄ± olmadan Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmenizi saÄŸlar.
  Bununla birlikte, birÃ§ok yeni baÅŸlayan da *Featured* veya *Research* yarÄ±ÅŸmalarÄ±ndan baÅŸlamÄ±ÅŸ ve rekabet baskÄ±sÄ±nÄ±n altÄ±nda daha hÄ±zlÄ± Ã¶ÄŸrendiklerini fark etmiÅŸtir.
  Bu nedenle Ã¶nerimiz, **Ã¶ÄŸrenme tarzÄ±nÄ±za gÃ¶re karar vermenizdir:**

  * BazÄ± Kaggle kullanÄ±cÄ±larÄ± keÅŸfederek ve iÅŸ birliÄŸi yaparak Ã¶ÄŸrenir (*Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± bu kiÅŸiler iÃ§in idealdir).
  * DiÄŸerleri ise hÄ±zlÄ± tempolu bir yarÄ±ÅŸmanÄ±n rekabet ortamÄ±nda motive olur.

* *Featured* ve *Research* yarÄ±ÅŸmalarÄ±nda ise ÅŸunu da gÃ¶z Ã¶nÃ¼nde bulundurmak gerekir:
  Bu yarÄ±ÅŸmalar genellikle yapay zekÃ¢ ve makine Ã¶ÄŸrenmesinin **uÃ§ (deneysel) uygulamalarÄ±yla** ilgilidir.
  DolayÄ±sÄ±yla bu yarÄ±ÅŸmalarda baÅŸarÄ±lÄ± olabilmek iÃ§in ya bu alanda **saÄŸlam bir altyapÄ±ya sahip olmanÄ±z** ya da yarÄ±ÅŸmanÄ±n uygulama alanÄ±yla ilgili araÅŸtÄ±rmalarÄ± Ã¶ÄŸrenmeye istekli olmanÄ±z gerekir.

Son olarak, Ã§oÄŸu yarÄ±ÅŸmanÄ±n, birÃ§ok veri bilimcisinin iÅŸ yerinde eriÅŸemediÄŸi **hesaplama kaynaklarÄ±na** ihtiyaÃ§ duyduÄŸunu unutmayÄ±n.
Kaggle dÄ±ÅŸÄ±ndaki bulut platformlarÄ±nÄ± kullanÄ±rsanÄ±z bu, **artan maliyetlere** yol aÃ§abilir.
Bu nedenle, **Code yarÄ±ÅŸmalarÄ±** veya **zaman ve kaynak sÄ±nÄ±rlamalarÄ± olan yarÄ±ÅŸmalar**, tÃ¼m katÄ±lÄ±mcÄ±larÄ± aynÄ± kaynak dÃ¼zeyine getirmeyi amaÃ§ladÄ±klarÄ± iÃ§in Ã§abalarÄ±nÄ±zÄ± yoÄŸunlaÅŸtÄ±rmak aÃ§Ä±sÄ±ndan ideal bir seÃ§enek olabilir.

### Submission and leaderboard dynamics *(GÃ¶nderim ve liderlik tablosu dinamikleri)*

Kaggleâ€™Ä±n Ã§alÄ±ÅŸma biÃ§imi basit gÃ¶rÃ¼nebilir: Test seti katÄ±lÄ±mcÄ±lardan gizlenir; modelinizi eÄŸitirsiniz; eÄŸer modeliniz test setindeki sonuÃ§larÄ± en iyi ÅŸekilde tahmin ederse yÃ¼ksek puan alÄ±r ve muhtemelen kazanÄ±rsÄ±nÄ±z.
Ne yazÄ±k ki, bu tanÄ±m Kaggle yarÄ±ÅŸmalarÄ±nÄ±n iÃ§ iÅŸleyiÅŸini **fazla basitleÅŸtirilmiÅŸ** bir ÅŸekilde aÃ§Ä±klar.
Bu aÃ§Ä±klama, yarÄ±ÅŸmacÄ±larÄ±n doÄŸrudan ve dolaylÄ± etkileÅŸimleriyle ilgili dinamikleri ya da karÅŸÄ± karÅŸÄ±ya olduÄŸunuz problemin, eÄŸitim ve test setinin **ince ayrÄ±ntÄ±larÄ±nÄ± (nÃ¼anslarÄ±nÄ±)** dikkate almaz.

### Explaining the Common Task Framework paradigm *(Ortak GÃ¶rev Ã‡erÃ§evesi paradigmasÄ±nÄ±n aÃ§Ä±klanmasÄ±)*

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair daha kapsamlÄ± bir aÃ§Ä±klama, **Stanford Ãœniversitesi Ä°statistik ProfesÃ¶rÃ¼ David Donoho** tarafÄ±ndan *50 Years of Data Science* (Veri Biliminin 50 YÄ±lÄ±) adlÄ± makalesinde verilmiÅŸtir.
Bu makale ilk olarak *Journal of Computational and Graphical Statistics* dergisinde yayÄ±mlanmÄ±ÅŸ, ardÄ±ndan MIT Bilgisayar Bilimi ve Yapay ZekÃ¢ LaboratuvarÄ± sitesinde paylaÅŸÄ±lmÄ±ÅŸtÄ±r (bkz. [http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)).

ProfesÃ¶r Donoho doÄŸrudan Kaggleâ€™dan deÄŸil, genel olarak **veri bilimi yarÄ±ÅŸma platformlarÄ±ndan** bahseder.
BilgisayarlÄ± dilbilimci **Mark Liberman**â€™dan alÄ±ntÄ± yaparak, veri bilimi yarÄ±ÅŸmalarÄ±nÄ± ve platformlarÄ±nÄ± **â€œCommon Task Framework (CTF)â€ â€” Ortak GÃ¶rev Ã‡erÃ§evesi** paradigmasÄ±nÄ±n bir parÃ§asÄ± olarak tanÄ±mlar.
Bu paradigma, son on yÄ±llarda birÃ§ok alanda veri biliminin sessiz ama istikrarlÄ± bir ÅŸekilde ilerlemesini saÄŸlamÄ±ÅŸtÄ±r.

Donoho, CTFâ€™nin veri bilimi problemlerine **ampirik (deneysel)** aÃ§Ä±dan Ã§Ã¶zÃ¼m getirmede son derece etkili olduÄŸunu sÃ¶yler ve bunu desteklemek iÃ§in **Netflix yarÄ±ÅŸmasÄ±** ile Ã§eÅŸitli **DARPA yarÄ±ÅŸmalarÄ±nÄ±** baÅŸarÄ±lÄ± Ã¶rnekler olarak gÃ¶sterir.
CTF paradigmasÄ±, birÃ§ok alanda en iyi Ã§Ã¶zÃ¼mleri yeniden ÅŸekillendirmeye katkÄ±da bulunmuÅŸtur.

---

### CTFâ€™nin bileÅŸenleri ve â€œgizli sosuâ€

Bir CTF, bazÄ± bileÅŸenlerden ve â€œgizli bir sostanâ€ oluÅŸur.
BileÅŸenler ÅŸunlardÄ±r:

1. Herkese aÃ§Ä±k bir veri seti ve bununla iliÅŸkili bir tahmin gÃ¶revi,
2. Bu gÃ¶reve en iyi tahmini Ã¼retmek iÃ§in ortak bir amaÃ§la Ã§alÄ±ÅŸan yarÄ±ÅŸmacÄ±lar,
3. KatÄ±lÄ±mcÄ±larÄ±n tahminlerini adil ve objektif biÃ§imde puanlayan, ancak Ã§Ã¶zÃ¼me dair fazla ipucu vermeyen (ya da en azÄ±ndan bunu sÄ±nÄ±rlayan) bir deÄŸerlendirme sistemi.

Bu sistem, gÃ¶rev aÃ§Ä±k ÅŸekilde tanÄ±mlandÄ±ÄŸÄ±nda ve veri kaliteli olduÄŸunda en iyi ÅŸekilde Ã§alÄ±ÅŸÄ±r.
Zaman iÃ§inde Ã§Ã¶zÃ¼mlerin performansÄ± kÃ¼Ã§Ã¼k artÄ±ÅŸlarla geliÅŸir ve sonunda bir **asimptota (doyum noktasÄ±na)** ulaÅŸÄ±r.
Bu sÃ¼reÃ§, katÄ±lÄ±mcÄ±lar arasÄ±nda belli bir dÃ¼zeyde paylaÅŸÄ±mÄ±n teÅŸvik edilmesiyle hÄ±zlanabilir.
Kaggleâ€™da bu paylaÅŸÄ±m; **tartÄ±ÅŸmalar, paylaÅŸÄ±lan Kaggle Notebookâ€™larÄ±** ve **Datasets** bÃ¶lÃ¼mÃ¼ndeki ek veriler aracÄ±lÄ±ÄŸÄ±yla gerÃ§ekleÅŸir.

CTF paradigmasÄ±na gÃ¶re, bir yarÄ±ÅŸmadaki **rekabet baskÄ±sÄ±**, Ã§Ã¶zÃ¼mlerin sÃ¼rekli olarak geliÅŸmesi iÃ§in tek baÅŸÄ±na yeterlidir.
Bu rekabet baskÄ±sÄ±, katÄ±lÄ±mcÄ±lar arasÄ±nda belli Ã¶lÃ§Ã¼de **bilgi paylaÅŸÄ±mÄ±yla** birleÅŸtiÄŸinde, geliÅŸme Ã§ok daha hÄ±zlÄ± gerÃ§ekleÅŸir.
Ä°ÅŸte bu nedenle Kaggle, paylaÅŸÄ±mÄ± teÅŸvik eden birÃ§ok Ã¶dÃ¼l ve mekanizma getirmiÅŸtir.

---

### CTFâ€™nin gizli sosu: rekabetin kendisi

CTF paradigmasÄ±ndaki â€œgizli sosâ€, **bizzat yarÄ±ÅŸmanÄ±n kendisidir**.
Bu yapÄ±, ampirik performansÄ±n artÄ±rÄ±lmasÄ±nÄ±n hedeflendiÄŸi pratik bir problem Ã§erÃ§evesinde, her zaman yeni **Ã¶lÃ§Ã¼tlerin (benchmark)**, **veri ve modelleme Ã§Ã¶zÃ¼mlerinin**, ve genel anlamda **makine Ã¶ÄŸrenmesinin daha iyi uygulanma biÃ§imlerinin** ortaya Ã§Ä±kmasÄ±nÄ± saÄŸlar.

Bir yarÄ±ÅŸma, dolayÄ±sÄ±yla bir tahmin problemini Ã§Ã¶zmenin yeni yollarÄ±nÄ±, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** iÃ§in yeni yÃ¶ntemleri ve yeni **algoritmik veya modelleme Ã§Ã¶zÃ¼mlerini** sunabilir.
Ã–rneÄŸin, **derin Ã¶ÄŸrenme (deep learning)** yalnÄ±zca akademik araÅŸtÄ±rmalardan doÄŸmamÄ±ÅŸtÄ±r; tersine, etkinliÄŸini kanÄ±tlayan baÅŸarÄ±lÄ± yarÄ±ÅŸmalar sayesinde bÃ¼yÃ¼k bir ivme kazanmÄ±ÅŸtÄ±r.
(Ã–rneÄŸin, Geoffrey Hinton ekibinin kazandÄ±ÄŸÄ± **Merck yarÄ±ÅŸmasÄ±nÄ±** hatÄ±rlayalÄ±m: [https://www.kaggle.com/c/MerckActivity/overview/winners](https://www.kaggle.com/c/MerckActivity/overview/winners)).

---

### CTF ve aÃ§Ä±k yazÄ±lÄ±m hareketi

**AÃ§Ä±k kaynak yazÄ±lÄ±m hareketi** ile birleÅŸtiÄŸinde (Ã¶rneÄŸin Scikit-learn, TensorFlow veya PyTorch gibi gÃ¼Ã§lÃ¼ analitik araÃ§lara herkesin eriÅŸebilmesi), CTF paradigmasÄ± Ã§ok daha iyi sonuÃ§lar Ã¼retir.
Bunun nedeni, tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n baÅŸlangÄ±Ã§ta **aynÄ± dÃ¼zeyde olanaklara sahip** olmasÄ±dÄ±r.

Ancak, bir yarÄ±ÅŸmadaki Ã§Ã¶zÃ¼mÃ¼n **Ã¶zel donanÄ±m veya yÃ¼ksek iÅŸlem gÃ¼cÃ¼ne** dayanmasÄ±, elde edilebilecek sonuÃ§larÄ± sÄ±nÄ±rlayabilir.
Ã‡Ã¼nkÃ¼ bu durum, bu tÃ¼r kaynaklara eriÅŸimi olmayan yarÄ±ÅŸmacÄ±larÄ±n doÄŸru ÅŸekilde katÄ±lÄ±m gÃ¶stermesini ya da diÄŸer katÄ±lÄ±mcÄ±lar Ã¼zerinde **rekabet baskÄ±sÄ±** oluÅŸturarak dolaylÄ± katkÄ± saÄŸlamasÄ±nÄ± engelleyebilir.

Ä°ÅŸte bu nedenle Kaggle, yarÄ±ÅŸmalara katÄ±lanlar iÃ§in **Ã¼cretsiz bulut hizmetleri** (Ã¶rneÄŸin **Kaggle Notebooks**) sunmaya baÅŸlamÄ±ÅŸtÄ±r.
Bu uygulama, Ã¶zellikle donanÄ±m yoÄŸun yarÄ±ÅŸmalarda (Ã¶rneÄŸin derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ± gibi) bazÄ± farklarÄ± azaltabilir ve genel anlamda rekabeti artÄ±rabilir.

### Understanding what can go wrong in a competition *(Bir yarÄ±ÅŸmada nelerin ters gidebileceÄŸini anlamak)*

#### CTF ParadigmasÄ± ve YarÄ±ÅŸma BaÅŸarÄ±sÄ±zlÄ±klarÄ±nÄ±n Nedenleri

CTF paradigmasÄ±na dair Ã¶nceki aÃ§Ä±klamamÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurursak, bir yarÄ±ÅŸmanÄ±n tek ihtiyacÄ± uygun bir platformda dÃ¼zenlenmekmiÅŸ gibi gÃ¶rÃ¼nebilir. BÃ¶yle olursa, katÄ±lÄ±mcÄ±lar iÃ§in olumlu bir katÄ±lÄ±m ve sponsor ÅŸirket iÃ§in olaÄŸanÃ¼stÃ¼ modeller gibi iyi sonuÃ§larÄ±n kendiliÄŸinden ortaya Ã§Ä±kacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

Ancak, hem katÄ±lÄ±mcÄ±lar hem de yarÄ±ÅŸmayÄ± dÃ¼zenleyen kurum aÃ§Ä±sÄ±ndan **hayal kÄ±rÄ±klÄ±ÄŸÄ±na yol aÃ§abilecek** bazÄ± durumlar da meydana gelebilir:

* Veri sÄ±zÄ±ntÄ±sÄ± (data leakage)
* Liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼m denemesi (probing)
* AÅŸÄ±rÄ± uyum (overfitting) ve buna baÄŸlÄ± liderlik tablosu deÄŸiÅŸimleri
* Ã–zel paylaÅŸÄ±m (private sharing)

---

#### Veri SÄ±zÄ±ntÄ±sÄ± (Data Leakage)

**Veri sÄ±zÄ±ntÄ±sÄ±**, Ã§Ã¶zÃ¼mÃ¼n bir kÄ±smÄ±nÄ±n bizzat verinin kendisinden geri izlenebilmesi durumudur.
Ã–rneÄŸin, bazÄ± deÄŸiÅŸkenler hedef deÄŸiÅŸkenden (target variable) sonra oluÅŸmuÅŸ olabilir ve bu da hedef hakkÄ±nda bilgi sÄ±zdÄ±rÄ±r.

Bu durum, Ã¶rneÄŸin dolandÄ±rÄ±cÄ±lÄ±k tespitinde, dolandÄ±rÄ±cÄ±lÄ±k gerÃ§ekleÅŸtikten sonra gÃ¼ncellenen deÄŸiÅŸkenleri kullandÄ±ÄŸÄ±nÄ±zda; veya satÄ±ÅŸ tahmini yaparken, bir Ã¼rÃ¼nÃ¼n **gerÃ§ek daÄŸÄ±tÄ±m bilgilerini** iÅŸlediÄŸinizde (daha fazla daÄŸÄ±tÄ±m â†’ daha fazla talep â†’ daha fazla satÄ±ÅŸ) ortaya Ã§Ä±kar.

BaÅŸka bir Ã¶rnek de, **eÄŸitim ve test Ã¶rneklerinin tahmin edilebilir bir sÄ±rada dÃ¼zenlenmiÅŸ olmasÄ±** ya da Ã¶rnek kimliklerinin (identifier) deÄŸerlerinin Ã§Ã¶zÃ¼me dair ipuÃ§larÄ± iÃ§ermesidir.
Ã–rneÄŸin, kimlik numarasÄ± hedef deÄŸiÅŸkenin sÄ±rasÄ±na gÃ¶re belirlenmiÅŸse ya da kimlik deÄŸeri zamanla iliÅŸkiliyse ve zaman hedef deÄŸiÅŸkenin olasÄ±lÄ±ÄŸÄ±nÄ± etkiliyorsa bu da bir sÄ±zÄ±ntÄ±dÄ±r.

Bu tÃ¼r veri sÄ±zÄ±ntÄ±larÄ±na, bazÄ± yarÄ±ÅŸmacÄ±lar tarafÄ±ndan **â€œaltÄ±n Ã¶zellikler (golden features)â€** adÄ± verilir â€” Ã§Ã¼nkÃ¼ verideki bu tÃ¼r kÃ¼Ã§Ã¼k ipuÃ§larÄ±nÄ± fark etmek, katÄ±lÄ±mcÄ±lar iÃ§in adeta altÄ±n deÄŸerinde Ã¶dÃ¼ller kazandÄ±rabilir.
Ancak bu durum genellikle **yeniden kullanÄ±labilir olmayan Ã§Ã¶zÃ¼mler** Ã¼retir.
Bu da sponsor iÃ§in **optimal olmayan sonuÃ§lar** anlamÄ±na gelir, ancak en azÄ±ndan sponsor hangi deÄŸiÅŸkenlerin sÄ±zÄ±ntÄ±ya yol aÃ§abileceÄŸini Ã¶ÄŸrenmiÅŸ olur.

---

#### Liderlik Tablosu Ãœzerinden Ã‡Ã¶zÃ¼m Denemesi (Leaderboard Probing)

Bir diÄŸer problem, **liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼mÃ¼ test etmek veya â€œdeÅŸifre etmekâ€** olasÄ±lÄ±ÄŸÄ±dÄ±r.
Bu durumda, yarÄ±ÅŸmacÄ±lar deÄŸerlendirme metriklerinden yararlanarak sÃ¼rekli denemeler yapabilir ve bu yolla Ã§Ã¶zÃ¼m hakkÄ±nda bilgi elde edebilir.
Yine bu tÃ¼r Ã§Ã¶zÃ¼mler, farklÄ± koÅŸullarda tamamen **kullanÄ±lamaz** hale gelir.

Bunun aÃ§Ä±k bir Ã¶rneÄŸi **â€œDonâ€™t Overfit IIâ€** yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r.
Kazanan katÄ±lÄ±mcÄ± **Zachary Mayers**, her bir deÄŸiÅŸkeni tek tek gÃ¶ndererek her birinin model Ã¼zerindeki etkisini analiz etmiÅŸ ve bu yolla modelinin katsayÄ±larÄ±nÄ± doÄŸru tahmin edebilmiÅŸtir.
(Zachâ€™Ä±n detaylÄ± Ã§Ã¶zÃ¼mÃ¼nÃ¼ burada okuyabilirsiniz: [https://www.kaggle.com/c/dont-overfit-ii/discussion/91766](https://www.kaggle.com/c/dont-overfit-ii/discussion/91766))

Genellikle **zaman serisi problemleri** veya test verisinde sistematik deÄŸiÅŸimler olan diÄŸer problemler, bu tÃ¼r probingâ€™den ciddi ÅŸekilde etkilenebilir.
Ã‡Ã¼nkÃ¼ bu durum, yarÄ±ÅŸmacÄ±larÄ±n tahminlerini Ã¶rneÄŸin sabit bir sayÄ± ile Ã§arpmak gibi bir **son iÅŸleme (post-processing)** adÄ±mÄ±yla puanlarÄ±nÄ± artÄ±rmalarÄ±na olanak tanÄ±yabilir.

---

#### Liderlik Tablosuna AÅŸÄ±rÄ± GÃ¼venme ve AÅŸÄ±rÄ± Uyum (Overfitting)

Liderlik tablosuna aÅŸÄ±rÄ± gÃ¼venmek, bir baÅŸka tÃ¼r **aÅŸÄ±rÄ± uyum (overfitting)** Ã¶rneÄŸidir.
KatÄ±lÄ±mcÄ±lar kendi doÄŸrulama testlerinden Ã§ok liderlik tablosundaki geri bildirimlere gÃ¶re hareket ettiklerinde bu durum ortaya Ã§Ä±kar.

Bazen bu durum yarÄ±ÅŸmanÄ±n **tamamen baÅŸarÄ±sÄ±z olmasÄ±na**, yani nihai liderlik tablosunda **beklenmedik ve rastlantÄ±sal sÄ±ralama deÄŸiÅŸikliklerine (shake-up)** yol aÃ§abilir.
BÃ¶yle bir durumda kazanan Ã§Ã¶zÃ¼mler, aslÄ±nda probleme uygun olmayan veya tamamen tesadÃ¼fi Ã§Ã¶zÃ¼mler olabilir.

Bu tÃ¼r olaylar, **eÄŸitim seti ile test seti arasÄ±ndaki farklarÄ± analiz eden** bazÄ± tekniklerin geliÅŸtirilmesine yol aÃ§mÄ±ÅŸtÄ±r.
Bu tÃ¼r analizlere **adversarial testing** denir ve liderlik tablosuna ne kadar gÃ¼venileceÄŸi veya eÄŸitim ve test setleri arasÄ±nda tamamen kaÃ§Ä±nÄ±lmasÄ± gereken Ã¶zellikler olup olmadÄ±ÄŸÄ± konusunda fikir verir.
Ã–rnek olarak, **Bojan Tunguz**â€™un ÅŸu Notebookâ€™una gÃ¶z atabilirsiniz:
[https://www.kaggle.com/tunguz/adversarial-ieee](https://www.kaggle.com/tunguz/adversarial-ieee).

---

#### Overfittingâ€™e KarÅŸÄ± Savunma Stratejileri

Liderlik tablosuna aÅŸÄ±rÄ± uyumu Ã¶nlemenin bir baÅŸka yolu, **gÃ¼venli stratejiler** kullanmaktÄ±r.
Ã–rneÄŸin, genellikle her katÄ±lÄ±mcÄ±nÄ±n **final deÄŸerlendirmesi iÃ§in iki Ã§Ã¶zÃ¼m** gÃ¶ndermesine izin verilir.
Bu durumda iyi bir strateji, birini liderlik tablosuna gÃ¶re en baÅŸarÄ±lÄ± olan Ã§Ã¶zÃ¼m olarak, diÄŸerini ise **kendi Ã§apraz doÄŸrulama testlerinde** en iyi performans gÃ¶steren Ã§Ã¶zÃ¼m olarak gÃ¶ndermektir.

Liderlik tablosu probingâ€™i ve overfittingâ€™i Ã¶nlemek iÃ§in Kaggle, daha Ã¶nce de bahsettiÄŸimiz gibi, **iki aÅŸamalÄ± deÄŸerlendirme sistemi** iÃ§eren **Code yarÄ±ÅŸmalarÄ±na** yÃ¶nelik Ã§eÅŸitli yenilikler getirmiÅŸtir.
Bu yarÄ±ÅŸmalarda katÄ±lÄ±mcÄ±lar test verisini hiÃ§ gÃ¶rmedikleri iÃ§in, kendi **yerel doÄŸrulama testlerine** daha fazla Ã¶nem vermek zorunda kalÄ±rlar.

---

#### Ã–zel PaylaÅŸÄ±m (Private Sharing) ve Etik DÄ±ÅŸÄ± DavranÄ±ÅŸlar

Bir yarÄ±ÅŸmayÄ± bozabilecek bir diÄŸer unsur, **Ã¶zel paylaÅŸÄ±m (private sharing)** yani fikir ve Ã§Ã¶zÃ¼mlerin yalnÄ±zca kapalÄ± bir grup arasÄ±nda paylaÅŸÄ±lmasÄ±dÄ±r.
Buna ek olarak, **birden fazla hesapla yarÄ±ÅŸmak**, **birden fazla takÄ±ma katÄ±lÄ±p fikir Ã§almak** gibi etik dÄ±ÅŸÄ± davranÄ±ÅŸlar da olabilir.

Bu tÃ¼r durumlar, bazÄ± katÄ±lÄ±mcÄ±lar iÃ§in avantaj yaratÄ±rken Ã§oÄŸunluk iÃ§in dezavantaj doÄŸurur â€” yani **bilgi asimetrisi** oluÅŸur.
BÃ¶ylece, yarÄ±ÅŸma boyunca paylaÅŸÄ±m eksik kalÄ±r ve az sayÄ±da takÄ±m tam rekabet baskÄ±sÄ± yaratabilir.

AyrÄ±ca, bu tÃ¼r durumlar katÄ±lÄ±mcÄ±larÄ±n farkÄ±na vardÄ±ÄŸÄ±nda (Ã¶rneÄŸin ÅŸu tartÄ±ÅŸmaya bakÄ±labilir: [https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503](https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503)), yarÄ±ÅŸmaya ve sonraki yarÄ±ÅŸmalara olan gÃ¼ven ve katÄ±lÄ±m da azalabilir.

### Computational resources *(Hesaplama kaynaklarÄ±)*

### Kaggle Notebooks *(Kaggle Defterleri)*

### Teaming and networking *(TakÄ±m kurma ve aÄŸ oluÅŸturma)*

### Performance tiers and rankings *(Performans seviyeleri ve sÄ±ralamalar)*

### Criticism and opportunities *(EleÅŸtiriler ve fÄ±rsatlar)*

### Summary *(Ã–zet)*

---

## Chapter 2: Organizing Data with Datasets *(BÃ¶lÃ¼m 2: Veri Setleriyle Veriyi DÃ¼zenleme)*

### Setting up a dataset *(Bir veri seti oluÅŸturma)*

### Gathering the data *(Veri toplama)*

### Working with datasets *(Veri setleriyle Ã§alÄ±ÅŸma)*

### Using Kaggle Datasets in Google Colab *(Google Colabâ€™da Kaggle veri setlerini kullanma)*

### Legal caveats *(Yasal uyarÄ±lar)*

### Summary *(Ã–zet)*

---

## Chapter 3: Working and Learning with Kaggle Notebooks *(BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek)*

### Setting up a Notebook *(Bir defter oluÅŸturma)*

### Running your Notebook *(Defterinizi Ã§alÄ±ÅŸtÄ±rma)*

### Saving Notebooks to GitHub *(Defterleri GitHubâ€™a kaydetme)*

### Getting the most out of Notebooks *(Defterlerden en iyi ÅŸekilde yararlanma)*

### Upgrading to Google Cloud Platform (GCP) *(Google Cloud Platformâ€™a (GCP) yÃ¼kseltme)*

### One step beyond *(Bir adÄ±m Ã¶teye geÃ§mek)*

### Kaggle Learn courses *(Kaggle Learn kurslarÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 4: Leveraging Discussion Forums *(BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±nÄ± Etkin Kullanma)*

### How forums work *(Forumlar nasÄ±l Ã§alÄ±ÅŸÄ±r)*

### Example discussion approaches *(TartÄ±ÅŸma Ã¶rnekleri ve yaklaÅŸÄ±mlar)*

### Netiquette *(Ä°nternet gÃ¶rgÃ¼ kurallarÄ±)*

### Summary *(Ã–zet)*

---

# Part II: Sharpening Your Skills for Competitions *(BÃ¶lÃ¼m II: YarÄ±ÅŸmalar Ä°Ã§in Becerilerini GeliÅŸtirme)*

## Chapter 5: Competition Tasks and Metrics *(BÃ¶lÃ¼m 5: YarÄ±ÅŸma GÃ¶revleri ve Ã–lÃ§Ã¼tleri)*

### Evaluation metrics and objective functions *(DeÄŸerlendirme metrikleri ve hedef fonksiyonlar)*

### Basic types of tasks *(Temel gÃ¶rev tÃ¼rleri)*

#### Regression *(Regresyon)*

#### Classification *(SÄ±nÄ±flandÄ±rma)*

#### Ordinal *(SÄ±ralÄ± veriler)*

### The Meta Kaggle dataset *(Meta Kaggle veri seti)*

### Handling never-before-seen metrics *(Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerle baÅŸa Ã§Ä±kma)*

### Metrics for regression (standard and ordinal) *(Regresyon iÃ§in metrikler - standart ve sÄ±ralÄ±)*

#### Mean squared error (MSE) and RÂ² *(Ortalama kare hata (MSE) ve RÂ²)*

#### Root mean squared error (RMSE) *(KÃ¶k ortalama kare hata (RMSE))*

#### Root mean squared log error (RMSLE) *(KÃ¶k ortalama log kare hata (RMSLE))*

#### Mean absolute error (MAE) *(Ortalama mutlak hata (MAE))*

### Metrics for classification (label prediction and probability) *(SÄ±nÄ±flandÄ±rma metrikleri - etiket tahmini ve olasÄ±lÄ±k)*

#### Accuracy *(DoÄŸruluk)*

#### Precision and recall *(Kesinlik ve duyarlÄ±lÄ±k)*

#### The F1 score *(F1 skoru)*

#### Log loss and ROC-AUC *(Log kaybÄ± ve ROC-AUC)*

#### Matthews correlation coefficient (MCC) *(Matthews korelasyon katsayÄ±sÄ±)*

### Metrics for multi-class classification *(Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri)*

### Metrics for object detection problems *(Nesne tespiti problemleri iÃ§in metrikler)*

#### Intersection over union (IoU) *(KesiÅŸim/BirleÅŸim oranÄ±)*

#### Dice *(Dice katsayÄ±sÄ±)*

### Metrics for multi-label classification and recommendation problems *(Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri problemleri iÃ§in metrikler)*

#### MAP@K *(MAP@K metriÄŸi)*

### Optimizing evaluation metrics *(DeÄŸerlendirme metriklerini optimize etme)*

### Custom metrics and custom objective functions *(Ã–zel metrikler ve Ã¶zel hedef fonksiyonlarÄ±)*

### Post-processing your predictions *(Tahminleri sonradan iÅŸleme)*

### Predicted probability and its adjustment *(Tahmin edilen olasÄ±lÄ±ÄŸÄ±n ayarlanmasÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 6: Designing Good Validation *(BÃ¶lÃ¼m 6: Ä°yi Bir DoÄŸrulama Sistemi Tasarlama)*

### Snooping on the leaderboard *(Liderlik tablosunu gÃ¶zetlemek)*

### The importance of validation in competitions *(YarÄ±ÅŸmalarda doÄŸrulamanÄ±n Ã¶nemi)*

### Bias and variance *(Ã–nyargÄ± ve varyans)*

### Trying different splitting strategies *(FarklÄ± veri bÃ¶lme stratejilerini denemek)*

#### The basic train-test split *(Temel eÄŸitim-test bÃ¶lÃ¼nmesi)*

#### Probabilistic evaluation methods *(OlasÄ±lÄ±ksal deÄŸerlendirme yÃ¶ntemleri)*

#### k-fold cross-validation *(k-katlÄ± Ã§apraz doÄŸrulama)*

#### Subsampling *(Alt Ã¶rnekleme)*

#### The bootstrap *(Bootstrap yÃ¶ntemi)*

### Tuning your model validation system *(Model doÄŸrulama sistemini ayarlamak)*

### Using adversarial validation *(ZÄ±t doÄŸrulama yÃ¶ntemini kullanmak)*

#### Example implementation *(Uygulama Ã¶rneÄŸi)*

### Handling different distributions of training and test data *(EÄŸitim ve test verilerindeki farklÄ± daÄŸÄ±lÄ±mlarla baÅŸa Ã§Ä±kma)*

### Handling leakage *(Veri sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nleme)*

### Summary *(Ã–zet)*

---

## Chapter 7: Modeling for Tabular Competitions *(BÃ¶lÃ¼m 7: Tablo Verisi YarÄ±ÅŸmalarÄ± Ä°Ã§in Modellemede YaklaÅŸÄ±mlar)*

### The Tabular Playground Series *(Tabular Playground Serisi)*

### Setting a random state for reproducibility *(Tekrarlanabilirlik iÃ§in rastgele durum belirleme)*

### The importance of EDA *(KeÅŸifsel veri analizinin Ã¶nemi)*

### Dimensionality reduction with t-SNE and UMAP *(t-SNE ve UMAP ile boyut indirgeme)*

### Reducing the size of your data *(Veri boyutunu kÃ¼Ã§Ã¼ltme)*

### Applying feature engineering *(Ã–zellik mÃ¼hendisliÄŸi uygulama)*

#### Easily derived features *(Kolay tÃ¼retilen Ã¶zellikler)*

#### Meta-features based on rows and columns *(SatÄ±r ve sÃ¼tunlara dayalÄ± meta-Ã¶zellikler)*

#### Target encoding *(Hedef kodlama)*

### Using feature importance to evaluate your work *(Ã–zellik Ã¶nemini kullanarak Ã§alÄ±ÅŸmanÄ± deÄŸerlendirme)*

### Pseudo-labeling *(Sahte etiketleme)*

### Denoising with autoencoders *(Otoenkoderlerle gÃ¼rÃ¼ltÃ¼ giderme)*

### Neural networks for tabular competitions *(Tablo verisi yarÄ±ÅŸmalarÄ± iÃ§in sinir aÄŸlarÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 8: Hyperparameter Optimization *(BÃ¶lÃ¼m 8: Hiperparametre Optimizasyonu)*

### Basic optimization techniques *(Temel optimizasyon teknikleri)*

#### Grid search *(Izgara aramasÄ±)*

#### Random search *(Rastgele arama)*

#### Halving search *(YarÄ±ya indirme aramasÄ±)*

### Key parameters and how to use them *(Temel parametreler ve nasÄ±l kullanÄ±lacaklarÄ±)*

#### Linear models *(DoÄŸrusal modeller)*

#### Support-vector machines *(Destek vektÃ¶r makineleri)*

#### Random forests and extremely randomized trees *(Rastgele ormanlar ve aÅŸÄ±rÄ± rastgele aÄŸaÃ§lar)*

#### Gradient tree boosting *(Gradyan aÄŸaÃ§ gÃ¼Ã§lendirmesi)*

#### LightGBM *(LightGBM algoritmasÄ±)*

#### XGBoost *(XGBoost algoritmasÄ±)*

#### CatBoost *(CatBoost algoritmasÄ±)*

#### HistGradientBoosting *(Histogram tabanlÄ± gradyan gÃ¼Ã§lendirme)*

### Bayesian optimization *(Bayesyen optimizasyon)*

#### Using Scikit-optimize *(Scikit-optimize kullanÄ±mÄ±)*

#### Customizing a Bayesian optimization search *(Bayesyen aramayÄ± Ã¶zelleÅŸtirme)*

#### Extending Bayesian optimization to neural architecture search *(Bayesyen optimizasyonu sinir aÄŸÄ± mimarisi aramasÄ±na geniÅŸletme)*

#### Creating lighter and faster models with KerasTuner *(KerasTuner ile daha hafif ve hÄ±zlÄ± modeller oluÅŸturma)*

#### The TPE approach in Optuna *(Optunaâ€™daki TPE yaklaÅŸÄ±mÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 9: Ensembling with Blending and Stacking Solutions *(BÃ¶lÃ¼m 9: KarÄ±ÅŸtÄ±rma ve YÄ±ÄŸÄ±nlama (Ensemble) Ã‡Ã¶zÃ¼mleri)*

### A brief introduction to ensemble algorithms *(Topluluk (ensemble) algoritmalarÄ±na kÄ±sa bir giriÅŸ)*

### Averaging models into an ensemble *(Modelleri ortalama alarak birleÅŸtirme)*

#### Majority voting *(Ã‡oÄŸunluk oylamasÄ±)*

#### Averaging of model predictions *(Model tahminlerinin ortalamasÄ±)*

#### Weighted averages *(AÄŸÄ±rlÄ±klÄ± ortalamalar)*

#### Averaging in your cross-validation strategy *(Ã‡apraz doÄŸrulama stratejinde ortalama alma)*

#### Correcting averaging for ROC-AUC evaluations *(ROC-AUC deÄŸerlendirmeleri iÃ§in ortalamayÄ± dÃ¼zeltme)*

### Blending models using a meta-model *(Meta-model kullanarak modelleri karÄ±ÅŸtÄ±rma)*

#### Best practices for blending *(KarÄ±ÅŸtÄ±rma iÃ§in en iyi uygulamalar)*

### Stacking models together *(Modelleri yÄ±ÄŸÄ±nlama)*

#### Stacking variations *(YÄ±ÄŸÄ±nlama varyasyonlarÄ±)*

### Creating complex stacking and blending solutions *(KarmaÅŸÄ±k karÄ±ÅŸtÄ±rma ve yÄ±ÄŸÄ±nlama Ã§Ã¶zÃ¼mleri oluÅŸturma)*

### Summary *(Ã–zet)*

---

## Chapter 10: Modeling for Computer Vision *(BÃ¶lÃ¼m 10: BilgisayarlÄ± GÃ¶rÃ¼ (Computer Vision) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Augmentation strategies *(Veri artÄ±rma stratejileri)*

#### Keras built-in augmentations *(Kerasâ€™Ä±n yerleÅŸik artÄ±rmalarÄ±)*

#### ImageDataGenerator approach *(ImageDataGenerator yaklaÅŸÄ±mÄ±)*

#### Preprocessing layers *(Ã–n iÅŸleme katmanlarÄ±)*

#### albumentations *(Albumentations kÃ¼tÃ¼phanesi)*

### Classification *(SÄ±nÄ±flandÄ±rma)*

### Object detection *(Nesne tespiti)*

### Semantic segmentation *(Anlamsal segmentasyon)*

### Summary *(Ã–zet)*

---

## Chapter 11: Modeling for NLP *(BÃ¶lÃ¼m 11: DoÄŸal Dil Ä°ÅŸleme (NLP) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Sentiment analysis *(Duygu analizi)*

### Open domain Q&A *(AÃ§Ä±k alan soru-cevap)*

### Text augmentation strategies *(Metin artÄ±rma stratejileri)*

#### Basic techniques *(Temel teknikler)*

#### nlpaug *(nlpaug kÃ¼tÃ¼phanesi)*

### Summary *(Ã–zet)*

---

## Chapter 12: Simulation and Optimization Competitions *(BÃ¶lÃ¼m 12: SimÃ¼lasyon ve Optimizasyon YarÄ±ÅŸmalarÄ±)*

### Connect X *(Connect X oyunu)*

### Rock-paper-scissors *(TaÅŸ-kaÄŸÄ±t-makas)*

### Santa competition 2020 *(Santa yarÄ±ÅŸmasÄ± 2020)*

### The name of the game *(Oyunun Ã¶zÃ¼)*

### Summary *(Ã–zet)*

---

# Part III: Leveraging Competitions for Your Career *(BÃ¶lÃ¼m III: YarÄ±ÅŸmalarÄ± Kariyerinde Avantaja DÃ¶nÃ¼ÅŸtÃ¼rme)*

## Chapter 13: Creating Your Portfolio of Projects and Ideas *(BÃ¶lÃ¼m 13: Proje ve Fikir PortfÃ¶yÃ¼ OluÅŸturma)*

### Building your portfolio with Kaggle *(Kaggle ile portfÃ¶y oluÅŸturma)*

### Leveraging Notebooks and discussions *(Defterler ve tartÄ±ÅŸmalardan yararlanma)*

### Leveraging Datasets *(Veri setlerinden yararlanma)*

### Arranging your online presence beyond Kaggle *(Kaggle dÄ±ÅŸÄ±nda Ã§evrimiÃ§i varlÄ±ÄŸÄ±nÄ± dÃ¼zenleme)*

#### Blogs and publications *(Bloglar ve yayÄ±nlar)*

#### GitHub *(GitHub)*

### Monitoring competition updates and newsletters *(YarÄ±ÅŸma gÃ¼ncellemelerini ve bÃ¼ltenleri takip etme)*

### Summary *(Ã–zet)*

---

## Chapter 14: Finding New Professional Opportunities *(BÃ¶lÃ¼m 14: Yeni Profesyonel FÄ±rsatlar Bulmak)*

### Building connections with other competition data scientists *(DiÄŸer yarÄ±ÅŸmacÄ± veri bilimcilerle baÄŸlantÄ± kurma)*

### Participating in Kaggle Days and other Kaggle meetups *(Kaggle Days ve diÄŸer Kaggle buluÅŸmalarÄ±na katÄ±lma)*

### Getting spotted and other job opportunities *(Fark edilmek ve diÄŸer iÅŸ fÄ±rsatlarÄ±)*

#### The STAR approach *(STAR yaklaÅŸÄ±mÄ±)*

### Summary (and some parting words) *(Ã–zet ve kapanÄ±ÅŸ notlarÄ±)*

---

## Other Books You May Enjoy *(HoÅŸunuza Gidebilecek DiÄŸer Kitaplar)*

## Index *(Dizin)*
