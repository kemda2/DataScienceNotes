# Part I: Introduction to Competitions *(BÃ¶lÃ¼m I: YarÄ±ÅŸmalara GiriÅŸ)*

## Chapter 1: Introducing Kaggle and Other Data Science Competitions *(BÃ¶lÃ¼m 1: Kaggle ve DiÄŸer Veri Bilimi YarÄ±ÅŸmalarÄ±na GiriÅŸ)*

Veri bilimi yarÄ±ÅŸmalarÄ± uzun zamandÄ±r var ve zaman iÃ§inde giderek artan bir baÅŸarÄ± elde ettiler. Tutkulu bir yarÄ±ÅŸmacÄ± topluluÄŸundan doÄŸan bu yarÄ±ÅŸmalar, giderek daha fazla ilgi Ã§ekmeye ve milyonlarca veri bilimciden oluÅŸan Ã§ok daha geniÅŸ bir kitleye ulaÅŸmaya baÅŸladÄ±. En popÃ¼ler veri bilimi yarÄ±ÅŸma platformu olan **Kaggle**â€™da uzun yÄ±llardÄ±r yarÄ±ÅŸmacÄ± olarak yer aldÄ±ÄŸÄ±mÄ±z iÃ§in, bu deÄŸiÅŸimlerin tÃ¼mÃ¼ne yÄ±llar boyunca doÄŸrudan tanÄ±klÄ±k ettik ve bizzat deneyimledik.

BugÃ¼n, Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ± hakkÄ±nda bilgi ararsanÄ±z, Ã§ok sayÄ±da **buluÅŸma (meetup)**, **tartÄ±ÅŸma paneli**, **podcast**, **rÃ¶portaj** ve hatta bu tÃ¼r yarÄ±ÅŸmalarda nasÄ±l kazanÄ±lacaÄŸÄ±nÄ± anlatan **Ã§evrimiÃ§i kurslar** bulabilirsiniz. (Genellikle bu kurslar size azim, hesaplama kaynaklarÄ± ve harcanan zamanÄ±n doÄŸru karÄ±ÅŸÄ±mÄ±nÄ± kullanmanÄ±zÄ± tavsiye eder.) Ancak, ÅŸu anda okumakta olduÄŸunuz kitap dÄ±ÅŸÄ±nda, bu kadar Ã§ok veri bilimi yarÄ±ÅŸmasÄ±nÄ± nasÄ±l yÃ¶neteceÄŸinizi ve onlardan nasÄ±l en iyi ÅŸekilde yararlanabileceÄŸinizi â€” yalnÄ±zca puan veya sÄ±ralama aÃ§Ä±sÄ±ndan deÄŸil, **profesyonel deneyim** bakÄ±mÄ±ndan da â€” sistematik bir ÅŸekilde anlatan bir rehber bulmanÄ±z oldukÃ§a zordur.

Bu kitapta amacÄ±mÄ±z, Kaggle veya diÄŸer veri bilimi yarÄ±ÅŸmalarÄ±nda nasÄ±l yÃ¼ksek puan alacaÄŸÄ±nÄ±zÄ± anlatan birkaÃ§ ipucu vermek deÄŸil. Bunun yerine, **Kaggleâ€™da daha etkili yarÄ±ÅŸmanÄ±z** ve yarÄ±ÅŸma deneyimlerinizden â€” Ã¶zellikle de profesyonel hayatÄ±nÄ±z aÃ§Ä±sÄ±ndan â€” **en fazla faydayÄ± elde etmeniz** iÃ§in kapsamlÄ± bir rehber sunmak istiyoruz. Kitap iÃ§eriÄŸine, **Kaggle Master** ve **Grandmaster**â€™larla yapÄ±lan rÃ¶portajlar da eÅŸlik ediyor. Bu rÃ¶portajlarÄ±n size Kaggleâ€™da yarÄ±ÅŸmanÄ±n belirli yÃ¶nleri hakkÄ±nda farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve iÃ§gÃ¶rÃ¼ler sunacaÄŸÄ±nÄ± ve rekabetÃ§i veri bilimi yaparken kendinizi sÄ±nama ve Ã¶ÄŸrenme biÃ§iminize ilham vereceÄŸini umuyoruz.

Bu kitabÄ±n sonunda, **kendi deneyimlerimizden**, **yarÄ±ÅŸmalardan edindiÄŸimiz bilgilerden** ve **kaynaklardan** doÄŸrudan derlediÄŸimiz bilgileri iÃ§selleÅŸtirmiÅŸ olacaksÄ±nÄ±z. BÃ¶ylece yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã¶ÄŸrenmenizi ve geliÅŸmenizi saÄŸlayacak bir yol haritasÄ±na sahip olacaksÄ±nÄ±z.

BaÅŸlangÄ±Ã§ noktasÄ± olarak, bu bÃ¶lÃ¼mde ÅŸunlarÄ± inceleyeceÄŸiz:

* RekabetÃ§i programlamanÄ±n nasÄ±l veri bilimi yarÄ±ÅŸmalarÄ±na evrildiÄŸini,
* Neden Kaggle platformunun bu tÃ¼r yarÄ±ÅŸmalar iÃ§in en popÃ¼ler site olduÄŸunu,
* Ve bu platformun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±.

Bu bÃ¶lÃ¼mde aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

* Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi
* **Common Task Framework** (Ortak GÃ¶rev Ã‡erÃ§evesi) paradigmasÄ±
* Kaggle platformu ve bazÄ± alternatifleri
* Bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸi: aÅŸamalarÄ±, yarÄ±ÅŸma tÃ¼rleri, gÃ¶nderim ve liderlik tablosu dinamikleri, hesaplama kaynaklarÄ±, aÄŸ oluÅŸturma ve daha fazlasÄ±

### The rise of data science competition platforms *(Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi)*

RekabetÃ§i programlamanÄ±n kÃ¶klÃ¼ bir geÃ§miÅŸi vardÄ±r; 1970â€™lerde dÃ¼zenlenen ilk **ICPC (International Collegiate Programming Contest â€“ UluslararasÄ± ÃœniversitelerarasÄ± Programlama YarÄ±ÅŸmasÄ±)** ile baÅŸlamÄ±ÅŸtÄ±r. Ä°lk ICPCâ€™de, Ã¼niversitelerden ve ÅŸirketlerden gelen kÃ¼Ã§Ã¼k takÄ±mlar, bir dizi problemi bilgisayar programÄ± kullanarak Ã§Ã¶zmeleri gereken bir yarÄ±ÅŸmaya katÄ±lÄ±yordu (baÅŸlangÄ±Ã§ta katÄ±lÄ±mcÄ±lar **FORTRAN** dilinde kodlama yapÄ±yordu). Ä°yi bir final sÄ±ralamasÄ± elde etmek iÃ§in takÄ±mlarÄ±n gÃ¼Ã§lÃ¼ **takÄ±m Ã§alÄ±ÅŸmasÄ±**, **problem Ã§Ã¶zme** ve **programlama** becerileri sergilemeleri gerekiyordu.

Bu tÃ¼r bir yarÄ±ÅŸmanÄ±n yoÄŸun atmosferinde yer almak ve iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§ekme fÄ±rsatÄ±, Ã¶ÄŸrencilere bÃ¼yÃ¼k bir motivasyon saÄŸladÄ± ve yarÄ±ÅŸmanÄ±n yÄ±llar boyunca popÃ¼ler kalmasÄ±na neden oldu. ICPC finalistleri arasÄ±nda, gÃ¼nÃ¼mÃ¼zde oldukÃ§a tanÄ±nmÄ±ÅŸ isimler vardÄ±r: **Adam Dâ€™Angelo** (Facebookâ€™un eski CTOâ€™su ve Quoraâ€™nÄ±n kurucusu), **Nikolai Durov** (Telegram Messengerâ€™Ä±n kurucu ortaÄŸÄ±) ve **Matei Zaharia** (Apache Sparkâ€™Ä±n yaratÄ±cÄ±sÄ±). Bu isimlerin yanÄ± sÄ±ra birÃ§ok profesyonel aynÄ± ortak deneyimi paylaÅŸÄ±r: bir ICPC yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸlardÄ±r.

ICPCâ€™nin ardÄ±ndan, Ã¶zellikle 2000 yÄ±lÄ±ndan sonra uzaktan katÄ±lÄ±mÄ±n kolaylaÅŸmasÄ±yla programlama yarÄ±ÅŸmalarÄ± bÃ¼yÃ¼k bir geliÅŸme gÃ¶sterdi. Bu sayede uluslararasÄ± yarÄ±ÅŸmalarÄ±n dÃ¼zenlenmesi hem daha kolay hem de daha dÃ¼ÅŸÃ¼k maliyetli hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸunun formatÄ± benzerdir: bir dizi problem verilir ve katÄ±lÄ±mcÄ±larÄ±n bunlarÄ± Ã§Ã¶zmek iÃ§in kod yazmasÄ± gerekir. Kazananlar sadece Ã¶dÃ¼l kazanmakla kalmaz, aynÄ± zamanda iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§eker veya kendi alanlarÄ±nda tanÄ±nÄ±r hale gelirler.

RekabetÃ§i programlamadaki problemler genellikle **kombinatorik**, **sayÄ± teorisi**, **graf teorisi**, **algoritmik oyun teorisi**, **hesaplamalÄ± geometri**, **dizgi analizi** ve **veri yapÄ±larÄ±** gibi konulardan oluÅŸur. Son yÄ±llarda ise **yapay zekÃ¢** ile ilgili problemler de bu yarÄ±ÅŸmalarda yer almaya baÅŸlamÄ±ÅŸtÄ±r. Ã–zellikle **KDD Cup**â€™Ä±n (Knowledge Discovery and Data Mining Cup â€“ Bilgi KeÅŸfi ve Veri MadenciliÄŸi YarÄ±ÅŸmasÄ±) baÅŸlatÄ±lmasÄ±ndan sonra bu tÃ¼r problemler oldukÃ§a popÃ¼ler hale gelmiÅŸtir. Bu yarÄ±ÅŸma, her yÄ±l **Association for Computing Machinery (ACM)** tarafÄ±ndan dÃ¼zenlenen konferans kapsamÄ±nda **Ã–zel Ä°lgi Grubu (SIG)** tarafÄ±ndan yÃ¼rÃ¼tÃ¼lmektedir. (Kaynak: [https://kdd.org/conferences](https://kdd.org/conferences))

Ä°lk **KDD Cup**, 1997 yÄ±lÄ±nda dÃ¼zenlenmiÅŸ ve **doÄŸrudan pazarlamada lift eÄŸrisi optimizasyonu** konusundaki bir problemi iÃ§ermiÅŸtir. Bu yarÄ±ÅŸma, gÃ¼nÃ¼mÃ¼zde hÃ¢lÃ¢ devam eden uzun bir yarÄ±ÅŸma serisinin baÅŸlangÄ±cÄ±nÄ± oluÅŸturmuÅŸtur. Veri kÃ¼meleri, yÃ¶nergeler ve kazananlar dÃ¢hil olmak Ã¼zere tÃ¼m arÅŸivlere ÅŸu adresten ulaÅŸabilirsiniz: [https://www.kdd.org/kdd-cup](https://www.kdd.org/kdd-cup). YazÄ±m sÄ±rasÄ±nda en son mevcut olan yarÄ±ÅŸma ise [https://ogb.stanford.edu/kddcup2021/](https://ogb.stanford.edu/kddcup2021/).
KDD Cup yarÄ±ÅŸmalarÄ±, en iyi uygulamalarÄ± belirlemede oldukÃ§a etkili olmuÅŸtur. BirÃ§ok makalede yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri, teknikler ve veri kÃ¼meleri paylaÅŸÄ±lmÄ±ÅŸ, bu da araÅŸtÄ±rmacÄ±lar ve uygulayÄ±cÄ±lar iÃ§in **deney**, **eÄŸitim** ve **karÅŸÄ±laÅŸtÄ±rma (benchmarking)** aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k fayda saÄŸlamÄ±ÅŸtÄ±r.

Hem rekabetÃ§i programlama etkinliklerinin hem de KDD Cupâ€™Ä±n baÅŸarÄ±sÄ±, ÅŸirketleri (Ã¶rneÄŸin **Netflix**) ve giriÅŸimcileri (Ã¶rneÄŸin Kaggleâ€™Ä±n kurucusu **Anthony Goldbloom**) **veri bilimi yarÄ±ÅŸma platformlarÄ±** kurmaya teÅŸvik etti. Bu platformlar, ÅŸirketlerin Ã§Ã¶zÃ¼lmesi zor veri bilimi problemlerini kitle kaynaklÄ± Ã§Ã¶zÃ¼mlerle Ã§Ã¶zebilmesine olanak tanÄ±dÄ±. GerÃ§ekten de veri bilimi alanÄ±nda her problem iÃ§in iÅŸe yarayan tek bir â€œaltÄ±nâ€ yÃ¶ntem yoktur; Ã§oÄŸu zaman, **â€œdeneyebileceÄŸin her ÅŸeyi deneâ€** yaklaÅŸÄ±mÄ± gerekir.

AslÄ±nda, uzun vadede hiÃ§bir algoritma tÃ¼m problemler iÃ§in diÄŸerlerini alt edemez. Bu durum, **David Wolpert** ve **William Macready** tarafÄ±ndan ortaya konan **No Free Lunch Teoremi (Bedava Ã–ÄŸle YemeÄŸi Yok Teoremi)** ile aÃ§Ä±klanÄ±r. Bu teoreme gÃ¶re, her makine Ã¶ÄŸrenimi algoritmasÄ± yalnÄ±zca Ã§Ã¶zÃ¼mÃ¼ iÃ§eren bir hipotez uzayÄ±na sahipse baÅŸarÄ±lÄ± olur. DolayÄ±sÄ±yla, bir algoritmanÄ±n belirli bir problemi en iyi ÅŸekilde Ã§Ã¶zebileceÄŸini Ã¶nceden bilemezsiniz; bunu Ã¶ÄŸrenmenin tek yolu, algoritmayÄ± doÄŸrudan o problem Ã¼zerinde test etmektir.
Makine Ã¶ÄŸreniminde herhangi bir â€œkutsal kÃ¢seâ€ veya teorik kestirme yoktur â€” yalnÄ±zca **ampirik deneyler** size neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶sterebilir.

Bu konuda daha fazla bilgi edinmek iÃ§in **No Free Lunch Teoremi** Ã¼zerine kuramsal aÃ§Ä±klamalarÄ± inceleyebilirsiniz. AÅŸaÄŸÄ±da bu konuyu detaylÄ± anlatan bir makaleye baÄŸlantÄ± verilmiÅŸtir:
ğŸ‘‰ [Analytics India Magazine â€“ What are the No Free Lunch Theorems in Data Science?](https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/)

Bu tÃ¼r durumlarda **crowdsourcing (kitle kaynak kullanÄ±mÄ±)** mÃ¼kemmel bir yÃ¶ntemdir; Ã§Ã¼nkÃ¼ algoritmalarÄ± ve veri dÃ¶nÃ¼ÅŸÃ¼mlerini kapsamlÄ± bir ÅŸekilde test etmeniz gerekir, ancak bunu yapacak insan gÃ¼cÃ¼ ve iÅŸlem gÃ¼cÃ¼nÃ¼z yoktur. Bu nedenle, hÃ¼kÃ¼metler ve ÅŸirketler belirli alanlarda ilerleme kaydetmek iÃ§in yarÄ±ÅŸmalara baÅŸvurur:

* **Kamu tarafÄ±nda:** ABDâ€™nin **DARPA** kuruluÅŸu tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalarda; **otonom araÃ§lar**, **robotik operasyonlar**, **makine Ã§evirisi**, **konuÅŸmacÄ± tanÄ±ma**, **parmak izi tanÄ±ma**, **bilgi eriÅŸimi**, **OCR (Optik Karakter TanÄ±ma)**, **otomatik hedef tanÄ±ma** gibi birÃ§ok alanda yarÄ±ÅŸmalar dÃ¼zenlenmiÅŸtir.
* **Åirket tarafÄ±nda:** Ã–rneÄŸin **Netflix**, kullanÄ±cÄ±larÄ±n film tercihlerinin tahmin edilmesini iyileÅŸtirmek amacÄ±yla dÃ¼zenlenen bir yarÄ±ÅŸmanÄ±n sonucuna gÃ¶re algoritmasÄ±nÄ± geliÅŸtirmiÅŸtir.

**Netflix YarÄ±ÅŸmasÄ± (Netflix Prize)**, mevcut **Ã¶neri sistemini** (collaborative filtering) geliÅŸtirmeyi amaÃ§lÄ±yordu. YarÄ±ÅŸmanÄ±n hedefi, bir kullanÄ±cÄ±nÄ±n bir filme vereceÄŸi puanÄ±, yalnÄ±zca daha Ã¶nce puanladÄ±ÄŸÄ± filmlerden yola Ã§Ä±karak tahmin etmekti â€” yani kullanÄ±cÄ± kimliÄŸi veya film aÃ§Ä±klamalarÄ± hakkÄ±nda hiÃ§bir bilgi yoktu (bunlarÄ±n tÃ¼mÃ¼ kimlik kodlarÄ±yla deÄŸiÅŸtirilmiÅŸti). KatÄ±lÄ±mcÄ±lardan, mevcut puan geÃ§miÅŸini akÄ±llÄ±ca kullanarak tahmin yapan modeller geliÅŸtirmeleri istendi.
**1.000.000 ABD DolarÄ±** tutarÄ±ndaki bÃ¼yÃ¼k Ã¶dÃ¼l, yalnÄ±zca geliÅŸtirilen modelin Netflixâ€™in mevcut algoritmasÄ± **Cinematch**â€™i belirli bir eÅŸiÄŸin Ã¼zerinde iyileÅŸtirmesi durumunda verilecekti.

YarÄ±ÅŸma 2006â€™dan 2009â€™a kadar sÃ¼rdÃ¼ ve kazanan takÄ±m, Ã¶nceki yarÄ±ÅŸmalardan birÃ§ok takÄ±mÄ±n birleÅŸmesiyle oluÅŸtu: **Commendo Research & Consulting GmbH**â€™den **Andreas TÃ¶scher** ve **Michael Jahrer** (aynÄ± zamanda Kaggleâ€™da da tanÄ±nan yarÄ±ÅŸmacÄ±lar), **AT&T Labs**â€™tan iki araÅŸtÄ±rmacÄ± ve **Yahoo!**â€™dan iki araÅŸtÄ±rmacÄ±.
YarÄ±ÅŸmayÄ± kazanmak, o kadar bÃ¼yÃ¼k bir hesaplama gÃ¼cÃ¼ ve farklÄ± Ã§Ã¶zÃ¼mlerin birleÅŸtirilmesini (ensemble) gerektirdi ki, takÄ±mlar rekabeti sÃ¼rdÃ¼rebilmek iÃ§in birleÅŸmek zorunda kaldÄ±lar. SonuÃ§ta, **Netflix** bu Ã§Ã¶zÃ¼mÃ¼ doÄŸrudan uygulamak yerine, yarÄ±ÅŸmadan elde edilen en deÄŸerli iÃ§gÃ¶rÃ¼leri alÄ±p mevcut **Cinematch algoritmasÄ±nÄ±** geliÅŸtirmede kullandÄ±.
Bu konuda daha fazla bilgi iÃ§in ÅŸu **Wired** makalesini okuyabilirsiniz:
ğŸ‘‰ [https://www.wired.com/2012/04/netflix-prize-costs/](https://www.wired.com/2012/04/netflix-prize-costs/)

Netflix yarÄ±ÅŸmasÄ±nÄ±n sonunda Ã¶nemli olan ÅŸey, Ã§Ã¶zÃ¼mÃ¼n kendisi deÄŸil, **Netflixâ€™in iÅŸ modelinin DVD kiralamadan Ã§evrimiÃ§i yayÄ±n platformuna geÃ§mesiyle** birlikte elde edilen **bilgi ve deneyimdi**. YarÄ±ÅŸmadan hem katÄ±lÄ±mcÄ±lar (Ã¶neri sistemleri alanÄ±nda bÃ¼yÃ¼k bir Ã¼n kazandÄ±lar) hem de Netflix (geliÅŸtirilmiÅŸ Ã¶neri sistemi bilgisini yeni iÅŸ modeline aktardÄ±) bÃ¼yÃ¼k fayda saÄŸladÄ±.

#### The Kaggle competition platform *(Kaggle yarÄ±ÅŸma platformu)*

**Netflix dÄ±ÅŸÄ±ndaki birÃ§ok ÅŸirket de veri bilimi yarÄ±ÅŸmalarÄ±ndan fayda saÄŸlamÄ±ÅŸtÄ±r.** Liste oldukÃ§a uzundur, ancak yarÄ±ÅŸmayÄ± dÃ¼zenleyen ÅŸirketlerin aÃ§Ä±k bir ÅŸekilde fayda elde ettiÄŸini bildirdiÄŸi birkaÃ§ Ã¶rneÄŸi verebiliriz. Ã–rneÄŸin:

* **Allstate** adlÄ± sigorta ÅŸirketi, yÃ¼zlerce veri bilimcinin katÄ±ldÄ±ÄŸÄ± bir yarÄ±ÅŸma sayesinde ([https://www.kaggle.com/c/ClaimPredictionChallenge](https://www.kaggle.com/c/ClaimPredictionChallenge)), kendi uzmanlarÄ± tarafÄ±ndan geliÅŸtirilen aktÃ¼eryal modellerini Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirebilmiÅŸtir.
* BaÅŸka iyi belgelenmiÅŸ bir Ã¶rnek olarak, **General Electric**, havayolu uÃ§uÅŸlarÄ±nÄ±n varÄ±ÅŸ zamanlarÄ±nÄ± tahmin etmede kullanÄ±lan sektÃ¶r standardÄ± performans Ã¶lÃ§Ã¼tÃ¼ne gÃ¶re (kÃ¶k ortalama kare hatasÄ± â€“ *root mean squared error* metriÄŸiyle Ã¶lÃ§Ã¼lÃ¼r) %40â€™lÄ±k bir geliÅŸme saÄŸlamÄ±ÅŸtÄ±r. Bu baÅŸarÄ±, benzer bir yarÄ±ÅŸma sayesinde elde edilmiÅŸtir ([https://www.kaggle.com/c/flight](https://www.kaggle.com/c/flight)).

**Kaggle yarÄ±ÅŸma platformu** bugÃ¼ne kadar yÃ¼zlerce yarÄ±ÅŸma dÃ¼zenlemiÅŸtir ve bu iki Ã¶rnek, platformu baÅŸarÄ±yla kullanan ÅŸirketlerden yalnÄ±zca birkaÃ§Ä±dÄ±r.
Åimdi, belirli yarÄ±ÅŸmalarÄ±n Ã¶tesine geÃ§ip bu kitabÄ±n da merkezinde yer alan **Kaggle ÅŸirketi** hakkÄ±nda konuÅŸalÄ±m.

##### A history of Kaggle *(Kaggleâ€™Ä±n tarihÃ§esi)*

**Kaggle**, ilk adÄ±mlarÄ±nÄ± **Åubat 2010â€™da**, ekonomist ve ekonometrikÃ§i olarak eÄŸitim almÄ±ÅŸ AvustralyalÄ± **Anthony Goldbloom** sayesinde attÄ±. Goldbloom, Avustralya Hazine BakanlÄ±ÄŸÄ±â€™nda (*Department of the Treasury*) ve Avustralya Merkez BankasÄ±â€™nÄ±n (*Reserve Bank of Australia*) AraÅŸtÄ±rma DepartmanÄ±â€™nda Ã§alÄ±ÅŸtÄ±ktan sonra, Londraâ€™da haftalÄ±k uluslararasÄ± dergi **The Economist**â€™te staj yaptÄ±.

The Economistâ€™te Ã§alÄ±ÅŸtÄ±ÄŸÄ± dÃ¶nemde â€œ**bÃ¼yÃ¼k veri (big data)**â€ Ã¼zerine bir makale yazma fÄ±rsatÄ± buldu. Bu makale, onun aklÄ±na **ilginÃ§ makine Ã¶ÄŸrenimi problemlerini Ã§Ã¶zmek iÃ§in en iyi analitik uzmanlarÄ± kitlesel katÄ±lÄ±mla (crowdsourcing) bir araya getirecek bir yarÄ±ÅŸma platformu kurma fikrini** getirdi ([kaynak](https://www.smh.com.au/technology/from-bondi-to-the-big-bucks-the-28yearold-whos-making-datascience-a-sport-20111104-1myq1.html)).

Bu platformun iÅŸ fikrinde â€œcrowdsourcingâ€ dinamiklerinin Ã¶nemli bir rol oynamasÄ±ndan dolayÄ±, Goldbloom platformun adÄ±nÄ± **Kaggle** koydu. Bu isim, Ä°ngilizce â€œ**gaggle**â€ (kaz sÃ¼rÃ¼sÃ¼) kelimesine bir gÃ¶nderme yapÄ±yor; kaz figÃ¼rÃ¼ de zaten Kaggle platformunun sembolÃ¼dÃ¼r.

Goldbloom, daha sonra **ABDâ€™nin Silikon Vadisiâ€™ne taÅŸÄ±ndÄ±** ve Kaggle giriÅŸimi, iki tanÄ±nmÄ±ÅŸ risk sermayesi ÅŸirketi olan **Khosla Ventures** ve **Index Ventures** tarafÄ±ndan yÃ¶netilen bir yatÄ±rÄ±m turunda **11,25 milyon dolar** tutarÄ±nda **A Serisi yatÄ±rÄ±m** aldÄ±. Ä°lk yarÄ±ÅŸmalar baÅŸlatÄ±ldÄ±, topluluk hÄ±zla bÃ¼yÃ¼dÃ¼ ve bazÄ± erken dÃ¶nem yarÄ±ÅŸmacÄ±lar dikkat Ã§ekici baÅŸarÄ±lara ulaÅŸtÄ±. Bunlardan biri olan **Jeremy Howard**, AvustralyalÄ± bir veri bilimci ve giriÅŸimciydi. Kaggleâ€™da birkaÃ§ yarÄ±ÅŸma kazandÄ±ktan sonra ÅŸirketin **BaÅŸkanÄ± (President)** ve **BaÅŸ Bilimcisi (Chief Scientist)** oldu.

Jeremy Howard, **AralÄ±k 2013â€™te** gÃ¶revinden ayrÄ±ldÄ± ve daha sonra **fast.ai** ([www.fast.ai](http://www.fast.ai)) adlÄ± yeni bir giriÅŸim kurdu. Bu giriÅŸim, **makine Ã¶ÄŸrenimi kurslarÄ±** ve **geliÅŸtiriciler iÃ§in derin Ã¶ÄŸrenme (deep learning) kÃ¼tÃ¼phanesi** sunmaktadÄ±r.

O dÃ¶nemde Ã¶ne Ã§Ä±kan diÄŸer bazÄ± **Kaggle yarÄ±ÅŸmacÄ±larÄ± (Kagglers)** arasÄ±nda **Jeremy Achin** ve **Thomas de Godoy** da bulunuyordu. Platformda **ilk 20 kÃ¼resel sÄ±ralama** arasÄ±na girdikten sonra emekli olmaya karar verdiler ve **DataRobot** adlÄ± kendi ÅŸirketlerini kurdular. KÄ±sa sÃ¼re sonra, geliÅŸtirdikleri yazÄ±lÄ±ma en iyi makine Ã¶ÄŸrenimi bilgilerini ve uygulamalarÄ±nÄ± kazandÄ±rmak amacÄ±yla **Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmuÅŸ katÄ±lÄ±mcÄ±larÄ± iÅŸe almaya** baÅŸladÄ±lar. BugÃ¼n **DataRobot**, **AutoML (otomatik makine Ã¶ÄŸrenimi)** Ã§Ã¶zÃ¼mleri geliÅŸtiren Ã¶nde gelen ÅŸirketlerden biridir.

Kaggle yarÄ±ÅŸmalarÄ±, giderek artan bir ilgiyle bÃ¼yÃ¼meye devam etti. **Derin Ã¶ÄŸrenmenin â€œbabasÄ±â€ Geoffrey Hinton**, 2012â€™de **Merck** tarafÄ±ndan dÃ¼zenlenen bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ± ve kazandÄ± ([kaynak](https://www.kaggle.com/c/MerckActivity/overview/winners)).

AyrÄ±ca Kaggle, **FranÃ§ois Chollet**â€™nin derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi **Keras**â€™Ä± tanÄ±ttÄ±ÄŸÄ± **Otto Group Product Classification Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13632)) yarÄ±ÅŸmasÄ±nÄ±n ve **Tianqi Chen**â€™in **XGBoost** adlÄ± daha hÄ±zlÄ± ve daha doÄŸru bir **gradient boosting** algoritmasÄ±nÄ± tanÄ±ttÄ±ÄŸÄ± **Higgs Boson Machine Learning Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/higgs-boson/discussion/10335)) yarÄ±ÅŸmasÄ±nÄ±n da dÃ¼zenlendiÄŸi platformdur.

FranÃ§ois Chollet ayrÄ±ca **Quora** sitesinde â€œKaggle yarÄ±ÅŸmalarÄ±nda neden Keras bu kadar baÅŸarÄ±lÄ± oldu?â€ sorusuna verdiÄŸi cevapta, Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmanÄ±n Ã¶zÃ¼nÃ¼ mÃ¼kemmel bir ÅŸekilde aÃ§Ä±klamÄ±ÅŸtÄ±r ([kaynak](https://www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions)).
Ona gÃ¶re, **Ã§ok sayÄ±da denemeyi hÄ±zlÄ± ÅŸekilde yapmak ve teoriden ziyade ampirik kanÄ±tlarla yÃ¶nlenmek**, Kaggleâ€™da baÅŸarÄ±lÄ± olmanÄ±n temelidir. Biz de onun belirttiÄŸi noktalarÄ±n dÄ±ÅŸÄ±nda baÅŸka bir â€œgizli sÄ±râ€ olduÄŸuna inanmÄ±yoruz.

FranÃ§ois Chollet ayrÄ±ca Kaggleâ€™da kendi yarÄ±ÅŸmasÄ±nÄ± da dÃ¼zenlemiÅŸtir ([Abstraction and Reasoning Challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge/)) â€” bu yarÄ±ÅŸma, **dÃ¼nyanÄ±n ilk genel yapay zekÃ¢ (general AI) yarÄ±ÅŸmasÄ±** olarak kabul edilir.

YarÄ±ÅŸma Ã¼stÃ¼ne yarÄ±ÅŸma geldikÃ§e, Kaggle etrafÄ±ndaki topluluk bÃ¼yÃ¼meye devam etti ve **2017 yÄ±lÄ±nda 1 milyon kullanÄ±cÄ±ya** ulaÅŸtÄ±. AynÄ± yÄ±l, **Google BaÅŸ Bilimcisi Fei-Fei Li**, **Google Next** etkinliÄŸinde yaptÄ±ÄŸÄ± aÃ§Ä±lÄ±ÅŸ konuÅŸmasÄ±nda **Googleâ€™Ä±n Kaggleâ€™Ä± satÄ±n alacaÄŸÄ±nÄ±** duyurdu.
O tarihten bu yana **Kaggle, Google Ã§atÄ±sÄ± altÄ±nda** faaliyet gÃ¶stermektedir.

BugÃ¼n, **Kaggle topluluÄŸu hÃ¢lÃ¢ aktif ve bÃ¼yÃ¼meye devam ediyor.**
Anthony Goldbloomâ€™un bir tweetâ€™inde ([kaynak](https://twitter.com/antgoldbloom/status/1400119591246852096)) belirttiÄŸi Ã¼zere, kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k bir kÄ±smÄ± sadece yarÄ±ÅŸmalara katÄ±lmakla kalmÄ±yor; aynÄ± zamanda **Kaggleâ€™Ä±n herkese aÃ§Ä±k veri setlerini indiriyor** (Kaggle artÄ±k Ã¶nemli bir **veri merkezi** haline gelmiÅŸtir), **Python veya R ile herkese aÃ§Ä±k Notebooks oluÅŸturuyor** ya da **platformun sunduÄŸu kurslardan yeni bir ÅŸeyler Ã¶ÄŸreniyor.**

![](im/1001.png)

YÄ±llar boyunca Kaggle, katÄ±lÄ±mcÄ±larÄ±na aÅŸaÄŸÄ±daki gibi **daha pek Ã§ok fÄ±rsat** sunmuÅŸtur:

* **Kendi ÅŸirketlerini kurmak**
* **Makine Ã¶ÄŸrenimi yazÄ±lÄ±mlarÄ± ve paketleri baÅŸlatmak**
* **Dergilerde rÃ¶portajlar yapmak** ([kaynak](https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/))
* **Makine Ã¶ÄŸrenimi kitaplarÄ± yazmak** ([kaynak](https://twitter.com/antgoldbloom/status/745662719588589568))
* **Hayallerindeki iÅŸi bulmak**

Ve en Ã¶nemlisi, **veri bilimi ile ilgili beceriler ve teknik detaylar hakkÄ±nda daha fazla bilgi edinmek**.

#### Other competition platforms *(DiÄŸer yarÄ±ÅŸma platformlarÄ±)*

Bu kitap Kaggleâ€™daki yarÄ±ÅŸmalara odaklansa da, birÃ§ok veri yarÄ±ÅŸmasÄ±nÄ±n Ã¶zel platformlarda veya diÄŸer yarÄ±ÅŸma platformlarÄ±nda dÃ¼zenlendiÄŸini unutmamak gerekir. AslÄ±nda, bu kitapta bulacaÄŸÄ±nÄ±z bilgilerin Ã§oÄŸu diÄŸer yarÄ±ÅŸmalar iÃ§in de geÃ§erlidir; Ã§Ã¼nkÃ¼ temelde hepsi benzer prensiplerle Ã§alÄ±ÅŸÄ±r ve katÄ±lÄ±mcÄ±lara saÄŸladÄ±klarÄ± faydalar da aÅŸaÄŸÄ± yukarÄ± aynÄ±dÄ±r.

BirÃ§ok diÄŸer platform belirli Ã¼lkelere odaklanmÄ±ÅŸ ya da yalnÄ±zca belirli tÃ¼rde yarÄ±ÅŸmalarda uzmanlaÅŸmÄ±ÅŸtÄ±r. Yine de, tamlÄ±k aÃ§Ä±sÄ±ndan, en azÄ±ndan deneyim ve bilgimizin bulunduÄŸu bazÄ±larÄ±nÄ± kÄ±saca tanÄ±tmakta fayda var:

* **DrivenData** ([https://www.drivendata.org/competitions/](https://www.drivendata.org/competitions/)) sosyal problemlere yÃ¶nelik yarÄ±ÅŸmalar dÃ¼zenleyen bir kitle kaynaklÄ± (crowdsourcing) yarÄ±ÅŸma platformudur (bkz. [https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/](https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/)). Åirketin kendisi, dÃ¼nyanÄ±n en bÃ¼yÃ¼k sorunlarÄ±yla mÃ¼cadele eden kuruluÅŸlara veri bilimi Ã§Ã¶zÃ¼mleri sunmayÄ± amaÃ§layan bir sosyal giriÅŸimdir. Veri bilimciler, sosyal fayda iÃ§in algoritmalar geliÅŸtirir. Ã–rneÄŸin, [https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html](https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html) adresindeki makalede okuyabileceÄŸiniz gibi, Facebook nefret sÃ¶ylemi ve yanlÄ±ÅŸ bilgiyle mÃ¼cadele iÃ§in dÃ¼zenlediÄŸi yarÄ±ÅŸmada DrivenDataâ€™yÄ± seÃ§miÅŸtir.

* **Numerai** ([https://numer.ai/](https://numer.ai/)) San Francisco merkezli, yapay zekÃ¢ destekli bir kitle kaynaklÄ± hedge fonudur. KatÄ±lÄ±mcÄ±lar her hafta fonun anonimleÅŸtirilmiÅŸ verileri Ã¼zerinde tahmin modelleri gÃ¶nderir ve ÅŸirketin kendi kripto para birimi olan *Numeraire* ile Ã¶dÃ¼ller kazanÄ±rlar.

* **CrowdANALYTIX** ([https://www.crowdanalytix.com/community](https://www.crowdanalytix.com/community)) artÄ±k eskisi kadar aktif olmasa da, bir sÃ¼re Ã¶nce birÃ§ok zorlu yarÄ±ÅŸmaya ev sahipliÄŸi yapmÄ±ÅŸtÄ±r (bkz. [https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1](https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1)). AyrÄ±ca topluluk blogu, bu platformda ne tÃ¼r zorluklarla karÅŸÄ±laÅŸabileceÄŸinize dair fikir edinmek iÃ§in oldukÃ§a ilginÃ§tir: [https://www.crowdanalytix.com/jq/communityBlog/listBlog.html](https://www.crowdanalytix.com/jq/communityBlog/listBlog.html).

* **Signate** ([https://signate.jp/competitions](https://signate.jp/competitions)) Japonya merkezli bir veri bilimi yarÄ±ÅŸma platformudur. BirÃ§ok yarÄ±ÅŸmaya ev sahipliÄŸi yapar ve Kaggleâ€™a benzer bir sÄ±ralama sistemi sunar ([https://signate.jp/users/rankings](https://signate.jp/users/rankings)).

* **Zindi** ([https://zindi.africa/competitions](https://zindi.africa/competitions)) Afrika merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Afrikaâ€™nÄ±n en acil sosyal, ekonomik ve Ã§evresel sorunlarÄ±nÄ± Ã§Ã¶zmeye odaklÄ± yarÄ±ÅŸmalar dÃ¼zenler.

* **Alibaba Cloud** ([https://www.alibabacloud.com/campaign/tianchi-competitions](https://www.alibabacloud.com/campaign/tianchi-competitions)) Ã‡in merkezli bir bulut biliÅŸim ve yapay zekÃ¢ saÄŸlayÄ±cÄ±sÄ±dÄ±r. SIGKDD, IJCAI-PRICAI ve CVPR gibi akademik konferanslarla ortaklaÅŸa dÃ¼zenlenen *Tianchi Academic* yarÄ±ÅŸmalarÄ±nÄ± baÅŸlatmÄ±ÅŸtÄ±r. GÃ¶rsel tabanlÄ± 3D ÅŸekil tanÄ±ma, 3D nesne yeniden oluÅŸturma ve Ã¶rnek segmentasyonu gibi zorluklar iÃ§eren yarÄ±ÅŸmalar dÃ¼zenler.

* **Analytics Vidhya** ([https://datahack.analyticsvidhya.com/](https://datahack.analyticsvidhya.com/)) Hindistanâ€™Ä±n en bÃ¼yÃ¼k veri bilimi topluluÄŸudur ve veri bilimi hackathonâ€™larÄ± iÃ§in bir platform sunar.

* **CodaLab** ([https://codalab.lri.fr/](https://codalab.lri.fr/)) 2013 yÄ±lÄ±nda Microsoft ve Stanford Ãœniversitesiâ€™nin ortak giriÅŸimiyle kurulmuÅŸ, Fransa merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Bilgi paylaÅŸÄ±mÄ± ve yeniden Ã¼retilebilir modelleme iÃ§in **Worksheets** ([https://worksheets.codalab.org/](https://worksheets.codalab.org/)) adlÄ± Ã¼cretsiz bulut tabanlÄ± bir defter sunar.

DiÄŸer daha kÃ¼Ã§Ã¼k platformlar arasÄ±nda Ä°sviÃ§reâ€™deki Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne tarafÄ±ndan geliÅŸtirilen **CrowdAI** ([https://www.crowdai.org/](https://www.crowdai.org/)), **InnoCentive** ([https://www.innocentive.com/](https://www.innocentive.com/)), biyomedikal gÃ¶rÃ¼ntÃ¼leme iÃ§in **Grand-Challenge** ([https://grand-challenge.org/](https://grand-challenge.org/)), **DataFountain** ([https://www.datafountain.cn/business?lang=en-US](https://www.datafountain.cn/business?lang=en-US)), **OpenML** ([https://www.openml.org/](https://www.openml.org/)) gibi platformlar yer alÄ±r. AyrÄ±ca, Rus topluluÄŸu **Open Data Science** ([https://ods.ai/competitions](https://ods.ai/competitions)) sitesinde devam eden bÃ¼yÃ¼k yarÄ±ÅŸmalarÄ±n kapsamlÄ± bir listesini bulabilir ve zaman zaman yeni yarÄ±ÅŸma platformlarÄ±nÄ± keÅŸfedebilirsiniz.

Kaggle, hÃ¢lÃ¢ en ilginÃ§ yarÄ±ÅŸmalarÄ± bulabileceÄŸiniz ve yarÄ±ÅŸma Ã§abalarÄ±nÄ±zla en geniÅŸ tanÄ±nÄ±rlÄ±ÄŸÄ± elde edebileceÄŸiniz en iyi platformdur. Ancak, Kaggle dÄ±ÅŸÄ±ndaki bir yarÄ±ÅŸmayÄ± seÃ§mek de anlamlÄ± olabilir; Ã¶zellikle kiÅŸisel veya profesyonel ilgi alanlarÄ±nÄ±za uyan bir yarÄ±ÅŸma bulduÄŸunuzda. GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, Kaggle dÄ±ÅŸÄ±nda da oldukÃ§a fazla alternatif ve fÄ±rsat mevcut. Bu da, Kaggle ile birlikte diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± da dikkate alarak, ilginizi Ã§ekebilecek Ã¶zel veri veya temalÄ± bir yarÄ±ÅŸma bulma olasÄ±lÄ±ÄŸÄ±nÄ±zÄ± artÄ±rÄ±r.

AyrÄ±ca, bu tÃ¼r platformlarda rekabetin genellikle daha az olduÄŸunu (dolayÄ±sÄ±yla daha iyi bir sÄ±ralama veya Ã¶dÃ¼l kazanma ÅŸansÄ±nÄ±zÄ±n daha yÃ¼ksek olabileceÄŸini) bekleyebilirsiniz; ancak katÄ±lÄ±mcÄ±lar arasÄ±nda bilgi paylaÅŸÄ±mÄ±nÄ±n Kaggleâ€™daki kadar zengin olmadÄ±ÄŸÄ±nÄ± da unutmamalÄ±sÄ±nÄ±z.

### Introducing Kaggle *(Kaggleâ€™a giriÅŸ)*

Bu noktada, Ã¶zellikle **Kaggle**â€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha derinlemesine incelememiz gerekiyor.
AÅŸaÄŸÄ±daki paragraflarda, Kaggle platformunun ve yarÄ±ÅŸmalarÄ±nÄ±n Ã§eÅŸitli yÃ¶nlerini ele alacaÄŸÄ±z ve Kaggleâ€™daki bir yarÄ±ÅŸmada yer almanÄ±n ne anlama geldiÄŸine dair bir fikir edineceksiniz.
Daha sonra, kitabÄ±n geri kalan bÃ¶lÃ¼mlerinde bu konularÄ±n Ã§oÄŸuna Ã§ok daha ayrÄ±ntÄ±lÄ± biÃ§imde geri dÃ¶nerek, ek Ã¶neriler ve stratejilerle birlikte tartÄ±ÅŸacaÄŸÄ±z.

#### Stages of a competition *(Bir yarÄ±ÅŸmanÄ±n aÅŸamalarÄ±)*

Kaggleâ€™daki bir yarÄ±ÅŸma, farklÄ± adÄ±mlardan oluÅŸacak ÅŸekilde dÃ¼zenlenir.
Bu adÄ±mlarÄ±n her birine gÃ¶z atarak, bir veri bilimi yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸini ve sizden neler beklenebileceÄŸini daha iyi anlayabilirsiniz.

Bir yarÄ±ÅŸma baÅŸlatÄ±ldÄ±ÄŸÄ±nda, genellikle sosyal medyada â€” Ã¶rneÄŸin Kaggleâ€™Ä±n Twitter hesabÄ±nda ([https://twitter.com/kaggle](https://twitter.com/kaggle)) â€” yarÄ±ÅŸmayÄ± duyuran paylaÅŸÄ±mlar yapÄ±lÄ±r. AyrÄ±ca, **Competitions** sayfasÄ±nda ([https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)) **Active Competitions** (aktif yarÄ±ÅŸmalar) bÃ¶lÃ¼mÃ¼nde yeni bir sekme gÃ¶rÃ¼nÃ¼r.

Belirli bir yarÄ±ÅŸmanÄ±n sekmesine tÄ±kladÄ±ÄŸÄ±nÄ±zda, o yarÄ±ÅŸmanÄ±n sayfasÄ±na yÃ¶nlendirilirsiniz. Ä°lk bakÄ±ÅŸta, yarÄ±ÅŸmanÄ±n Ã¶dÃ¼l verip vermediÄŸini (ve yarÄ±ÅŸmaya katÄ±lmanÄ±n bir sonucu olarak puan ve madalya kazandÄ±rÄ±p kazandÄ±rmadÄ±ÄŸÄ±nÄ±), ÅŸu anda kaÃ§ takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ±nÄ± ve Ã§Ã¶zÃ¼mÃ¼nÃ¼z Ã¼zerinde Ã§alÄ±ÅŸmak iÃ§in ne kadar sÃ¼reniz kaldÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz.

![](im/1002.png)

Orada, Ã¶ncelikle **Overview (Genel BakÄ±ÅŸ)** menÃ¼sÃ¼nÃ¼ inceleyebilirsiniz. Bu menÃ¼ size ÅŸu konularda bilgi verir:

* YarÄ±ÅŸmanÄ±n konusu
* DeÄŸerlendirme metriÄŸi (modellerinizin deÄŸerlendirileceÄŸi Ã¶lÃ§Ã¼t)
* YarÄ±ÅŸmanÄ±n zaman Ã§izelgesi
* Ã–dÃ¼ller
* Yasal veya yarÄ±ÅŸma gereklilikleri

Genellikle zaman Ã§izelgesi Ã§ok dikkat edilmeyen bir kÄ±sÄ±mdÄ±r, ancak kontrol etmeniz gereken ilk ÅŸeylerden biri olmalÄ±dÄ±r; Ã§Ã¼nkÃ¼ yalnÄ±zca yarÄ±ÅŸmanÄ±n ne zaman baÅŸlayÄ±p biteceÄŸini deÄŸil, aynÄ± zamanda **kural kabul etme son tarihini** de gÃ¶sterir. Bu tarih genellikle yarÄ±ÅŸma kapanmadan **7 ila 14 gÃ¼n Ã¶nce** olur ve yarÄ±ÅŸmaya katÄ±labileceÄŸiniz (kurallarÄ± kabul edebileceÄŸiniz) son gÃ¼nÃ¼ belirtir.

AyrÄ±ca bir **takÄ±m birleÅŸtirme son tarihi (team merger deadline)** de bulunur: Bu tarihten Ã¶nce istediÄŸiniz herhangi bir zamanda ekibinizi baÅŸka bir yarÄ±ÅŸmacÄ±nÄ±n ekibiyle birleÅŸtirebilirsiniz; ancak bu tarihten sonra artÄ±k mÃ¼mkÃ¼n deÄŸildir.

**Rules (Kurallar)** menÃ¼sÃ¼ de sÄ±klÄ±kla gÃ¶z ardÄ± edilir (Ã§oÄŸu kiÅŸi doÄŸrudan **Data** kÄ±smÄ±na geÃ§er), ancak kontrol edilmesi Ã¶nemlidir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n gereklilikleri hakkÄ±nda bilgi verir. Kurallar kÄ±smÄ±ndan edinebileceÄŸiniz Ã¶nemli bilgiler arasÄ±nda ÅŸunlar yer alÄ±r:

* Ã–dÃ¼l almaya uygun olup olmadÄ±ÄŸÄ±nÄ±z
* PuanÄ±nÄ±zÄ± artÄ±rmak iÃ§in harici veri kullanÄ±p kullanamayacaÄŸÄ±nÄ±z
* GÃ¼nde kaÃ§ tane gÃ¶nderim (Ã§Ã¶zÃ¼m testi) yapabileceÄŸiniz
* KaÃ§ tane nihai Ã§Ã¶zÃ¼m seÃ§ebileceÄŸiniz

KurallarÄ± kabul ettikten sonra, **Data** menÃ¼sÃ¼nden verileri indirebilir veya doÄŸrudan **Code** menÃ¼sÃ¼nden Kaggle Notebooks (Ã§evrimiÃ§i, bulut tabanlÄ± defterler) Ã¼zerinde Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz. Burada diÄŸerlerinin paylaÅŸtÄ±ÄŸÄ± kodlarÄ± yeniden kullanabilir veya sÄ±fÄ±rdan kendi kodunuzu oluÅŸturabilirsiniz.

EÄŸer verileri indirmeye karar verirseniz, **Kaggle API**â€™sini de kullanabileceÄŸinizi unutmayÄ±n. Bu API, indirme ve gÃ¶nderim iÅŸlemlerini neredeyse otomatik hale getirmenize yardÄ±mcÄ± olur. Yerel bilgisayarÄ±nÄ±zda veya bulut sunucunuzda modellerinizi Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z, bu araÃ§ oldukÃ§a faydalÄ±dÄ±r. API hakkÄ±nda daha fazla bilgiyi ÅŸu adreste bulabilirsiniz:
ğŸ‘‰ [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)
Kaynak koduna ise GitHub Ã¼zerinden ulaÅŸabilirsiniz:
ğŸ‘‰ [https://github.com/Kaggle/kaggle-api](https://github.com/Kaggle/kaggle-api)

Kaggleâ€™Ä±n GitHub deposunu daha yakÄ±ndan incelerseniz, **Kaggle Notebooks** (Ã§evrimiÃ§i defterler) iÃ§in kullanÄ±lan tÃ¼m **Docker imajlarÄ±nÄ±** da bulabilirsiniz.

![](im/1003.png)

Bu noktada, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirirken **tek baÅŸÄ±nÄ±za devam etmemenizi**, diÄŸer yarÄ±ÅŸmacÄ±larla **Discussion (TartÄ±ÅŸma)** forumu Ã¼zerinden iletiÅŸime geÃ§menizi iÃ§tenlikle tavsiye ederiz. Bu forumda yarÄ±ÅŸmaya Ã¶zgÃ¼ sorular sorabilir ve diÄŸer katÄ±lÄ±mcÄ±larÄ±n sorularÄ±nÄ± yanÄ±tlayabilirsiniz.
Ã‡oÄŸu zaman burada, veriyle ilgili belirli problemlere dair faydalÄ± ipuÃ§larÄ± veya kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirmeye yardÄ±mcÄ± olabilecek fikirler bulabilirsiniz.
BirÃ§ok baÅŸarÄ±lÄ± Kaggle kullanÄ±cÄ±sÄ± (*Kaggler*), forumlarda edindikleri fikirlerin kendilerine daha iyi performans saÄŸladÄ±ÄŸÄ±nÄ± ve daha da Ã¶nemlisi, veri bilimi modelleme konusunda Ã§ok ÅŸey Ã¶ÄŸrenmelerine yardÄ±mcÄ± olduÄŸunu belirtmiÅŸtir.

Ã‡Ã¶zÃ¼mÃ¼nÃ¼z hazÄ±r olduÄŸunda, yarÄ±ÅŸmanÄ±n yÃ¶nergelerine uygun ÅŸekilde **Kaggle deÄŸerlendirme sistemine** gÃ¶nderebilirsiniz.
BazÄ± yarÄ±ÅŸmalar Ã§Ã¶zÃ¼mleri **CSV dosyasÄ±** olarak kabul ederken, bazÄ±larÄ± **Kaggle Notebook** Ã¼zerinde kod yazmanÄ±zÄ± ve sonuÃ§larÄ± orada Ã¼retmenizi ister.
YarÄ±ÅŸma sÃ¼resince Ã§Ã¶zÃ¼m gÃ¶ndermeye devam edebilirsiniz.

Her gÃ¶nderim yaptÄ±ÄŸÄ±nÄ±zda, kÄ±sa bir sÃ¼re sonra **liderlik tablosu (leaderboard)** size bir puan ve yarÄ±ÅŸmacÄ±lar arasÄ±ndaki konumunuzu gÃ¶sterecektir (bekleme sÃ¼resi, puan hesaplamasÄ± iÃ§in gereken iÅŸlem sÃ¼resine baÄŸlÄ± olarak deÄŸiÅŸir).
Ancak bu sÄ±ralama yalnÄ±zca yaklaÅŸÄ±k bir gÃ¶stergedir; Ã§Ã¼nkÃ¼ modelinizin performansÄ±nÄ±, test verisinin yalnÄ±zca bir kÄ±smÄ± olan **public test set (genel test kÃ¼mesi)** Ã¼zerinde yansÄ±tÄ±r. Bu kÃ¼medeki sonuÃ§lar yarÄ±ÅŸma boyunca herkesin gÃ¶rebileceÄŸi ÅŸekilde paylaÅŸÄ±lÄ±r.

YarÄ±ÅŸma kapanmadan Ã¶nce, her yarÄ±ÅŸmacÄ± **nihai deÄŸerlendirme** iÃ§in kendi Ã§Ã¶zÃ¼mleri arasÄ±ndan belirli bir sayÄ±da (genellikle iki) Ã§Ã¶zÃ¼m seÃ§ebilir.

![](im/1004.png)

YarÄ±ÅŸma ancak kapandÄ±ktan sonra, yarÄ±ÅŸmacÄ±larÄ±n deÄŸerlendirilmesini istedikleri modeller temel alÄ±narak, **test veri setinin baÅŸka bir kÄ±smÄ±** olan **private test set (Ã¶zel test kÃ¼mesi)** Ã¼zerindeki puanlarÄ± aÃ§Ä±klanÄ±r.
Bu yeni sÄ±ralama tablosu **private leaderboard (Ã¶zel liderlik tablosu)** olarak adlandÄ±rÄ±lÄ±r ve yarÄ±ÅŸmanÄ±n **nihai, gerÃ§ek puanlarÄ±nÄ±** gÃ¶sterir; ancak bu sÄ±ralama henÃ¼z **resmÃ® ve kesin** deÄŸildir.

GerÃ§ekte, Kaggle ekibi her ÅŸeyin doÄŸru olduÄŸunu ve tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n yarÄ±ÅŸma kurallarÄ±na uyduÄŸunu kontrol etmek iÃ§in bir sÃ¼re ayÄ±rÄ±r.
Bir sÃ¼re sonra (ve bazen bazÄ± yarÄ±ÅŸmacÄ±larÄ±n diskalifiye edilmesine baÄŸlÄ± olarak sÄ±ralamalarda deÄŸiÅŸiklikler olduktan sonra), **private leaderboard** resmÃ® ve kesin hale gelir.
Kazananlar aÃ§Ä±klanÄ±r ve birÃ§ok katÄ±lÄ±mcÄ±, yarÄ±ÅŸma tartÄ±ÅŸma forumunda kendi stratejilerini, Ã§Ã¶zÃ¼mlerini ve kodlarÄ±nÄ± paylaÅŸÄ±r.

Bu noktada, diÄŸer katÄ±lÄ±mcÄ±larÄ±n Ã§Ã¶zÃ¼mlerini incelemek ve kendi yaklaÅŸÄ±mÄ±nÄ±zÄ± geliÅŸtirmeye Ã§alÄ±ÅŸmak tamamen size kalmÄ±ÅŸtÄ±r.
Bunu yapmanÄ±zÄ± **ÅŸiddetle tavsiye ederiz**, Ã§Ã¼nkÃ¼ bu sÃ¼reÃ§ Kaggleâ€™daki en Ã¶nemli Ã¶ÄŸrenme kaynaklarÄ±ndan bir diÄŸeridir.

#### Types of competitions and examples *(YarÄ±ÅŸma tÃ¼rleri ve Ã¶rnekleri)*

Kaggle yarÄ±ÅŸmalarÄ±, **yarÄ±ÅŸma kategorilerine** gÃ¶re sÄ±nÄ±flandÄ±rÄ±lÄ±r ve her kategori, yarÄ±ÅŸma biÃ§imi ve beklentiler aÃ§Ä±sÄ±ndan farklÄ±lÄ±k gÃ¶sterir.
Veri tÃ¼rÃ¼, problem zorluÄŸu, verilen Ã¶dÃ¼ller ve yarÄ±ÅŸma dinamikleri bu kategoriler iÃ§inde oldukÃ§a Ã§eÅŸitlidir; bu nedenle her kategorinin ne anlama geldiÄŸini Ã¶nceden anlamak Ã¶nemlidir.

Kaggleâ€™daki yarÄ±ÅŸmalarÄ± filtrelemek iÃ§in kullanabileceÄŸiniz **resmÃ® kategoriler** ÅŸunlardÄ±r:

* **Featured**
* **Masters**
* **Annuals**
* **Research**
* **Recruitment**
* **Getting Started**
* **Playground**
* **Analytics**
* **Community**

---

> ğŸ† Featured (Ã–ne Ã‡Ä±kan) YarÄ±ÅŸmalar

Bunlar en yaygÄ±n yarÄ±ÅŸma tÃ¼rÃ¼dÃ¼r. Genellikle sponsor bir ÅŸirketin iÅŸ ile ilgili bir problemini iÃ§erir ve en iyi performans gÃ¶sterenlere Ã¶dÃ¼l verilir.
Kazananlar, Ã§Ã¶zÃ¼mlerinin **lisanssÄ±z (non-exclusive)** kullanÄ±m hakkÄ±nÄ± sponsor ÅŸirkete verirler; ayrÄ±ca ayrÄ±ntÄ±lÄ± bir rapor hazÄ±rlamalarÄ± ve bazen sponsor ÅŸirketle toplantÄ±lara katÄ±lmalarÄ± gerekebilir.

Kaggleâ€™da neredeyse her zaman Featured yarÄ±ÅŸmalara rastlayabilirsiniz. GÃ¼nÃ¼mÃ¼zde Ã§oÄŸu, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veriler** (metin, gÃ¶rÃ¼ntÃ¼, video, ses gibi) Ã¼zerinde derin Ã¶ÄŸrenme yÃ¶ntemlerinin uygulanmasÄ±na yÃ¶neliktir.
GeÃ§miÅŸte ise daha Ã§ok **tablo biÃ§iminde veriler (tabular data)** Ã¼zerine kurulu yarÄ±ÅŸmalar yapÄ±lÄ±rdÄ± â€” yani veritabanlarÄ±nda bulunan yapÄ±landÄ±rÄ±lmÄ±ÅŸ veriler Ã¼zerinde Ã§alÄ±ÅŸan problemlerdi.
Ä°lk zamanlarda rastgele ormanlar (random forests), daha sonra ise akÄ±llÄ± Ã¶zellik mÃ¼hendisliÄŸiyle birlikte **gradient boosting** yÃ¶ntemleri Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar vermiÅŸtir.
Ancak gÃ¼nÃ¼mÃ¼zde, geliÅŸmiÅŸ yazÄ±lÄ±mlar ve **AutoML** araÃ§larÄ± sayesinde bu tÃ¼r problemlerde yarÄ±ÅŸmalardan elde edilen geliÅŸmeler genellikle marjinaldir.
Buna karÅŸÄ±lÄ±k, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veri** dÃ¼nyasÄ±nda iyi bir derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mÃ¼ hÃ¢lÃ¢ bÃ¼yÃ¼k fark yaratabilir.
Ã–rneÄŸin, **BERT** gibi Ã¶nceden eÄŸitilmiÅŸ aÄŸlar, birÃ§ok NLP gÃ¶revinde Ã¶nceki standartlara gÃ¶re Ã§ift haneli performans artÄ±ÅŸlarÄ± saÄŸlamÄ±ÅŸtÄ±r.

---

> ğŸ§  Masters (Ustalar) YarÄ±ÅŸmalarÄ±

ArtÄ±k daha az dÃ¼zenlenmektedir, ancak bunlar **Ã¶zel (invite-only)** yarÄ±ÅŸmalardÄ±r.
AmaÃ§, yalnÄ±zca uzmanlar (genellikle Kaggle sÄ±ralamasÄ±nda **Master** veya **Grandmaster** unvanÄ±na sahip yarÄ±ÅŸmacÄ±lar) iÃ§in yarÄ±ÅŸmalar dÃ¼zenlemektir.

---

> ğŸ“… Annuals (YÄ±llÄ±k) YarÄ±ÅŸmalar

Her yÄ±l belirli dÃ¶nemlerde dÃ¼zenlenen yarÄ±ÅŸmalardÄ±r.
Bunlar arasÄ±nda:

* **Santa Claus Competitions** (genellikle algoritmik optimizasyon problemleri Ã¼zerine),
* **March Machine Learning Mania** (2014â€™ten beri her yÄ±l ABD Kolej Basketbol TurnuvalarÄ± sÄ±rasÄ±nda dÃ¼zenlenir) bulunur.

---

> ğŸ”¬ Research (AraÅŸtÄ±rma) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarÄ±n amacÄ± ticari deÄŸil, **bilimsel veya araÅŸtÄ±rma odaklÄ±dÄ±r**, bazen de kamu yararÄ±na hizmet eder.
Bu nedenle genellikle para Ã¶dÃ¼lÃ¼ sunmazlar.
AyrÄ±ca kazananlardan Ã§Ã¶zÃ¼mlerini **aÃ§Ä±k kaynak (open-source)** olarak paylaÅŸmalarÄ± istenebilir.

Ã–rneÄŸin, **Google Landmark Recognition 2020** ([https://www.kaggle.com/c/landmark-recognition-2020](https://www.kaggle.com/c/landmark-recognition-2020)) yarÄ±ÅŸmasÄ±nda, Ã¼nlÃ¼ (veya pek tanÄ±nmamÄ±ÅŸ) yapÄ±tlarÄ±n fotoÄŸraflarÄ±nÄ± tanÄ±mlamak hedeflenmiÅŸtir.

---

> ğŸ’¼ Recruitment (Ä°ÅŸe AlÄ±m) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar, sponsor ÅŸirketlerin **potansiyel iÅŸ adaylarÄ±nÄ±n yeteneklerini test etmek** iÃ§in dÃ¼zenlenir.
Genellikle tek kiÅŸilik takÄ±mlarla sÄ±nÄ±rlÄ±dÄ±r ve en iyi performans gÃ¶steren yarÄ±ÅŸmacÄ±lara **iÅŸ gÃ¶rÃ¼ÅŸmesi** Ã¶dÃ¼lÃ¼ sunulur.
YarÄ±ÅŸma sonunda, deÄŸerlendirilmek isteyen yarÄ±ÅŸmacÄ±larÄ±n **Ã¶zgeÃ§miÅŸlerini (CV)** yÃ¼klemeleri gerekir.

Ã–rnekler:

* **Facebook Recruiting Competition** ([https://www.kaggle.com/c/FacebookRecruiting](https://www.kaggle.com/c/FacebookRecruiting))
* **Yelp Recruiting Competition** ([https://www.kaggle.com/c/yelp-recruiting](https://www.kaggle.com/c/yelp-recruiting))

---

> ğŸš€ Getting Started (BaÅŸlangÄ±Ã§) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar Ã¶dÃ¼l sunmaz, ancak **yeni baÅŸlayanlarÄ±n** Kaggle prensiplerine ve dinamiklerine alÄ±ÅŸmalarÄ± iÃ§in **kolay ve Ã¶ÄŸretici problemler** iÃ§erir.
Genellikle **yarÄ± kalÄ±cÄ±dÄ±rlar** ve liderlik tablolarÄ± zaman zaman yenilenir.
Makine Ã¶ÄŸrenmesine giriÅŸ yapmak istiyorsanÄ±z, bu yarÄ±ÅŸmalar mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r; Ã§Ã¼nkÃ¼ oldukÃ§a **iÅŸbirlikÃ§i bir ortam** sunarlar ve veri iÅŸleme ile model oluÅŸturma adÄ±mlarÄ±nÄ± gÃ¶steren birÃ§ok **Kaggle Notebook** mevcuttur.

BazÄ± Ã¼nlÃ¼ Getting Started yarÄ±ÅŸmalarÄ±:

* [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer)
* [Titanic â€” Machine Learning from Disaster](https://www.kaggle.com/c/titanic)
* [House Prices â€” Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

---

> ğŸ® Playground (Oyun AlanÄ±) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar **Getting Started** yarÄ±ÅŸmalarÄ±ndan biraz daha zordur, ancak hÃ¢lÃ¢ Ã¶ÄŸrenme ve pratik yapma odaklÄ±dÄ±r.
Tam Ã¶lÃ§ekli Featured yarÄ±ÅŸmalar kadar baskÄ± oluÅŸturmazlar, fakat bazen rekabet oldukÃ§a kÄ±zÄ±ÅŸabilir.
Ã–dÃ¼ller genellikle **Kaggle logolu hediyelikler (swag: kupa, tiÅŸÃ¶rt, Ã§orap vb.)** veya kÃ¼Ã§Ã¼k miktarlarda paradÄ±r.

ÃœnlÃ¼ bir Playground yarÄ±ÅŸmasÄ± Ã¶rneÄŸi:

* [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats) â€” kÃ¶pekleri ve kedileri ayÄ±rt eden bir algoritma geliÅŸtirme gÃ¶revi.

---

> ğŸ“Š Analytics (Analiz) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarda deÄŸerlendirme **niteliksel (qualitative)** olup, katÄ±lÄ±mcÄ±lardan fikirler, Ã§Ã¶zÃ¼m taslaklarÄ±, PowerPoint sunumlarÄ±, grafikler vb. hazÄ±rlamalarÄ± beklenir.

---

> ğŸ‘¥ Community (Topluluk) YarÄ±ÅŸmalarÄ±

Eskiden **InClass** olarak bilinen bu yarÄ±ÅŸmalar, **akademik kurumlar** veya bireysel **Kagglerâ€™lar** tarafÄ±ndan dÃ¼zenlenir.
Topluluk yarÄ±ÅŸmalarÄ±nÄ±n duyurusu iÃ§in:
ğŸ”— [https://www.kaggle.com/product-feedback/294337](https://www.kaggle.com/product-feedback/294337)
Kendi yarÄ±ÅŸmanÄ±zÄ± dÃ¼zenleme rehberleri iÃ§in:
ğŸ”— [https://www.kaggle.com/c/about/host](https://www.kaggle.com/c/about/host)
ğŸ”— [https://www.kaggle.com/community-competitions-setup-guide](https://www.kaggle.com/community-competitions-setup-guide)


> **Parul Pandey**
> 
> [https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey)
> 
> 
> 
> Kaggle Notebooks Grandmasterâ€™Ä±, Datasets Masterâ€™Ä± ve H2O.aiâ€™de veri bilimci olan **Parul Pandey** ile analitik yarÄ±ÅŸmalar ve deneyimleri hakkÄ±nda konuÅŸtuk.
> 
> ---
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±n nedir?**
> 
> Veri analizi yapmanÄ±zÄ± ve sonunda kapsamlÄ± bir analiz raporu sunmanÄ±zÄ± gerektiren **Veri AnalitiÄŸi yarÄ±ÅŸmalarÄ±nÄ±** gerÃ§ekten Ã§ok seviyorum. Bunlara *Data Science for Good* (DS4G) yarÄ±ÅŸmalarÄ±, spor analitiÄŸi yarÄ±ÅŸmalarÄ± (Ã¶rneÄŸin NFL) ve genel anket temelli yarÄ±ÅŸmalar dÃ¢hildir. Geleneksel yarÄ±ÅŸmalardan farklÄ± olarak, bu tÃ¼r yarÄ±ÅŸmalarda performansÄ±nÄ±zÄ± baÅŸkalarÄ±yla kÄ±yaslayabileceÄŸiniz bir **liderlik tablosu (leaderboard)** bulunmaz; ayrÄ±ca madalya veya puan da kazanmazsÄ±nÄ±z.
> 
> Ã–te yandan bu yarÄ±ÅŸmalar, veri biliminin Ã§ok yÃ¶nlÃ¼ alanlarÄ±na â€“ veri temizleme, veri madenciliÄŸi, gÃ¶rselleÅŸtirme ve iÃ§gÃ¶rÃ¼ iletimi gibi â€“ dokunan uÃ§tan uca Ã§Ã¶zÃ¼mler gerektirir. Bu tÃ¼r problemler, gerÃ§ek hayattaki senaryolarÄ± taklit etmenizi ve kendi iÃ§gÃ¶rÃ¼nÃ¼zÃ¼, bakÄ±ÅŸ aÃ§Ä±nÄ±zÄ± sunmanÄ±zÄ± saÄŸlar. Tek bir â€œen iyiâ€ Ã§Ã¶zÃ¼m olmayabilir, ancak bu size Ã§eÅŸitli yaklaÅŸÄ±mlarÄ± tartÄ±p deÄŸerlendirerek kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼ze entegre etme fÄ±rsatÄ± verir.
> 
> ---
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinden ne kadar farklÄ±?**
> 
> Ä°lk adÄ±mÄ±m her zaman **EDA (keÅŸifsel veri analizi)** yapmaktÄ±r. Bu, iÅŸ rutinimin de bir parÃ§asÄ±dÄ±r. Genellikle verideki tutarsÄ±zlÄ±klarÄ±, eksik deÄŸerleri, aykÄ±rÄ± noktalarÄ± vb. belirlemek iÃ§in veriyi incelerim; Ã§Ã¼nkÃ¼ bunlar ileride sorun yaratabilir. Sonra **iyi ve gÃ¼venilir bir Ã§apraz doÄŸrulama stratejisi** oluÅŸtururum. ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±nÄ± okur ve diÄŸer kullanÄ±cÄ±larÄ±n paylaÅŸtÄ±ÄŸÄ± Notebookâ€™lara gÃ¶z atarÄ±m. Bu genelde iyi bir baÅŸlangÄ±Ã§ noktasÄ± olur; sonra Ã¶nceki deneyimlerimden edindiÄŸim ÅŸeyleri bu sÃ¼rece eklerim. AyrÄ±ca **model performansÄ±nÄ± izlemek** de Ã§ok Ã¶nemlidir.
> 
> Analitik yarÄ±ÅŸmalar sÃ¶z konusu olduÄŸunda ise problemi genellikle birkaÃ§ adÄ±ma ayÄ±rmayÄ± severim. Ã–rneÄŸin, ilk kÄ±sÄ±m problemi anlamakla ilgilidir ve bu birkaÃ§ gÃ¼n sÃ¼rebilir. SonrasÄ±nda veriyi keÅŸfederim, ardÄ±ndan temel bir baÅŸlangÄ±Ã§ Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururum. Daha sonra bu Ã§Ã¶zÃ¼mÃ¼, her seferinde bir parÃ§a ekleyerek geliÅŸtiririm. Bu, Lego parÃ§alarÄ±nÄ± tek tek ekleyerek son eseri oluÅŸturmak gibidir.
> 
> ---
> 
> **KatÄ±ldÄ±ÄŸÄ±n zorlu bir yarÄ±ÅŸmadan ve bu gÃ¶revi nasÄ±l ele aldÄ±ÄŸÄ±ndan bahseder misin?**
> 
> Daha Ã¶nce de belirttiÄŸim gibi genellikle Analitik yarÄ±ÅŸmalara katÄ±lmayÄ± tercih ediyorum, ama bazen klasik yarÄ±ÅŸmalarda da ÅŸansÄ±mÄ± deniyorum. Ã–zellikle **Environmental Insights Explorer** adlÄ± *Data Science for Good* yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/ds4g-environmental-insightsexplorer](https://www.kaggle.com/c/ds4g-environmental-insightsexplorer)) Ã§ok ilgimi Ã§ekmiÅŸti. GÃ¶rev, mevcut metodolojilerdeki emisyon katsayÄ±larÄ±nÄ± hesaplamak yerine, **uzaktan algÄ±lama (remote sensing)** tekniklerini kullanarak Ã§evresel emisyonlarÄ± anlamaktÄ±.
> 
> Beni en Ã§ok etkileyen ÅŸey, bu yarÄ±ÅŸmanÄ±n ele aldÄ±ÄŸÄ± konuydu. Gezegenimiz iklim deÄŸiÅŸikliÄŸiyle mÃ¼cadele ediyor ve bu yarÄ±ÅŸma tam da bu konuya odaklanmÄ±ÅŸtÄ±. YarÄ±ÅŸma iÃ§in araÅŸtÄ±rma yaparken, **uydu gÃ¶rÃ¼ntÃ¼leme teknolojilerindeki ilerlemeyi** gÃ¶rÃ¼nce hayran kaldÄ±m. Bu sayede bu konuyu daha derinlemesine anlama fÄ±rsatÄ± buldum. Landsat, Modis ve Sentinel gibi uydularÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve bu verilerin nasÄ±l eriÅŸilebilir hale getirildiÄŸini Ã¶ÄŸrendim. Bu yarÄ±ÅŸma, Ã¶nceden Ã§ok az bilgim olan bir alan hakkÄ±nda bilgi edinmemi saÄŸlayan harika bir deneyimdi.
> 
> ---
> 
> **YarÄ±ÅŸma biÃ§imleri Ã¼zerine**
> 
> Kaggle yarÄ±ÅŸmalarÄ±nÄ±n kendi iÃ§inde farklÄ± biÃ§imleri de vardÄ±r. En yaygÄ±n olanÄ±, katÄ±lÄ±mcÄ±nÄ±n Ã§Ã¶zÃ¼mÃ¼nÃ¼ sunup deÄŸerlendirildiÄŸi **â€œbasit formatâ€tÄ±r.** Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸmalarda**, yarÄ±ÅŸma ikiye ayrÄ±lÄ±r: Ä°lk kÄ±sÄ±m tamamlandÄ±ktan sonra ikinci kÄ±sma Ã¶zel bir veri seti yalnÄ±zca ilk kÄ±sÄ±m katÄ±lÄ±mcÄ±larÄ±na verilir. Bu format, yarÄ±ÅŸmacÄ±larÄ±n hile yapma ihtimalini azaltmak iÃ§in tasarlanmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼reliÄŸine eriÅŸilebilen, daha Ã¶nce hiÃ§ gÃ¶rÃ¼lmemiÅŸ bir test setinde yapÄ±lÄ±r. Bu nedenle katÄ±lÄ±mcÄ±larÄ±n deneme sayÄ±sÄ± ve zamanÄ± daha sÄ±nÄ±rlÄ±dÄ±r.
> 
> ---
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nda bilmek isteyeceÄŸin ÅŸey ne olurdu?**
> 
> Kaggleâ€™daki ilk yÄ±llarÄ±mda yaptÄ±ÄŸÄ±m bazÄ± hatalardan bahsedebilirim.
> 
> Ã–ncelikle, Ã§oÄŸu yeni baÅŸlayan **Kaggleâ€™Ä± sadece yarÄ±ÅŸma platformu** olarak gÃ¶rÃ¼r. EÄŸer yarÄ±ÅŸmalarÄ± seviyorsanÄ±z, burada fazlasÄ±yla var; ama Kaggle aynÄ± zamanda baÅŸka alanlarda da katkÄ± yapabileceÄŸiniz bir platformdur. Kod yazabilir, baÅŸkalarÄ±yla paylaÅŸabilir, saÄŸlÄ±klÄ± tartÄ±ÅŸmalara katÄ±labilir ve aÄŸÄ±nÄ±zÄ± geniÅŸletebilirsiniz. Toplulukla kaliteli veri setleri oluÅŸturup paylaÅŸabilirsiniz. BaÅŸlangÄ±Ã§ta Kaggleâ€™Ä± yalnÄ±zca veri seti indirmek iÃ§in kullanÄ±yordum; ancak birkaÃ§ yÄ±l Ã¶nce aktif oldum. Geriye dÃ¶nÃ¼p baktÄ±ÄŸÄ±mda, daha Ã¶nce ne kadar yanÄ±ldÄ±ÄŸÄ±mÄ± gÃ¶rÃ¼yorum.
> 
> BirÃ§ok kiÅŸi yarÄ±ÅŸmalardan Ã§ekiniyor. Ã–nce platforma alÄ±ÅŸÄ±p, sonra yavaÅŸ yavaÅŸ yarÄ±ÅŸmalara katÄ±labilirsiniz.
> 
> AyrÄ±ca birÃ§ok kiÅŸi **tek baÅŸÄ±na Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in motivasyonunu kaybedip bÄ±rakÄ±yor.** Kaggleâ€™da takÄ±m kurmanÄ±n birÃ§ok gÃ¶rÃ¼nmeyen avantajÄ± var. TakÄ±m Ã§alÄ±ÅŸmasÄ± Ã¶ÄŸrenmenizi, deneyim paylaÅŸmanÄ±zÄ± ve sÄ±nÄ±rlÄ± bir zaman diliminde ortak bir hedefe ulaÅŸmayÄ± Ã¶ÄŸretir.
> 
> ---
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± da kullanÄ±yor musun? Bunlar Kaggle ile nasÄ±l kÄ±yaslanÄ±r?**
> 
> Åu anda zamanÄ±mÄ±n Ã§oÄŸunu Kaggleâ€™a ayÄ±rÄ±yorum, ancak geÃ§miÅŸte **Zindi** adlÄ± platformu da kullandÄ±m. Zindi, Afrika odaklÄ± veri bilimi yarÄ±ÅŸmalarÄ±na yoÄŸunlaÅŸan bir platform. Afrikaâ€™ya Ã¶zel veri setlerine eriÅŸmek iÃ§in harika bir yer.
> 
> Kaggle Ã§ok yÃ¶nlÃ¼ bir platform olsa da, dÃ¼nyanÄ±n farklÄ± bÃ¶lgelerinden gelen problem ifadeleri konusunda eksiklikler var. Son zamanlarda bu Ã§eÅŸitlilik artmaya baÅŸladÄ±; Ã¶rneÄŸin **chaii yarÄ±ÅŸmasÄ±** â€“ Hint dillerine odaklanan bir NLP yarÄ±ÅŸmasÄ± â€“ buna iyi bir Ã¶rnektir. Benzer ÅŸekilde, farklÄ± Ã¼lkelere odaklanan yarÄ±ÅŸmalarÄ±n da hem araÅŸtÄ±rma hem de genel veri bilimi topluluÄŸu iÃ§in faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.

Kaggle yarÄ±ÅŸmalarÄ±nÄ±n bu sÄ±nÄ±flandÄ±rmasÄ±nÄ±n Ã¶tesinde, yarÄ±ÅŸmalarÄ±n farklÄ± **formatlarda** dÃ¼zenlenebileceÄŸini de dikkate almak gerekir.
En yaygÄ±n format, daha Ã¶nce aÃ§Ä±klandÄ±ÄŸÄ± gibi, bir Ã§Ã¶zÃ¼m sunduÄŸunuz ve bu Ã§Ã¶zÃ¼mÃ¼n deÄŸerlendirildiÄŸi **â€œbasit (simple)â€ formattÄ±r.**
Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸma (two-stage competition)** formatÄ±nda ise yarÄ±ÅŸma iki bÃ¶lÃ¼me ayrÄ±lÄ±r. Son veri seti yalnÄ±zca ilk bÃ¶lÃ¼m tamamlandÄ±ktan sonra ve sadece bu ilk bÃ¶lÃ¼me katÄ±lan yarÄ±ÅŸmacÄ±lara sunulur.
Bu iki aÅŸamalÄ± yarÄ±ÅŸma formatÄ±, bazÄ± yarÄ±ÅŸmacÄ±larÄ±n **hile yapma veya kurallarÄ± ihlal etme olasÄ±lÄ±ÄŸÄ±nÄ± azaltmak** amacÄ±yla ortaya Ã§Ä±kmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼re iÃ§in eriÅŸilebilen ve daha Ã¶nce hiÃ§ test edilmemiÅŸ bir test seti Ã¼zerinde yapÄ±lÄ±r.
Orijinal Kaggle yarÄ±ÅŸma formatÄ±nÄ±n aksine, bu durumda yarÄ±ÅŸmacÄ±larÄ±n **Ã§ok daha az zamanÄ±** ve test setindeki Ã¶rÃ¼ntÃ¼leri (pattern) keÅŸfetmek iÃ§in **Ã§ok daha az sayÄ±da gÃ¶nderim hakkÄ±** vardÄ±r.

AynÄ± nedenle, son zamanlarda **Code yarÄ±ÅŸmalarÄ±** da ortaya Ã§Ä±kmÄ±ÅŸtÄ±r.
Bu yarÄ±ÅŸmalarda tÃ¼m gÃ¶nderimler doÄŸrudan bir **Kaggle Notebook** Ã¼zerinden yapÄ±lÄ±r ve herhangi bir dÄ±ÅŸ dosya yÃ¼kleme seÃ§eneÄŸi devre dÄ±ÅŸÄ± bÄ±rakÄ±lmÄ±ÅŸtÄ±r.

Kaggle yarÄ±ÅŸma kariyerlerinin farklÄ± aÅŸamalarÄ±nda olan kullanÄ±cÄ±larÄ±n her tÃ¼r yarÄ±ÅŸmaya katÄ±lmasÄ±nda hiÃ§bir kÄ±sÄ±tlama yoktur.
Ancak, **veri bilimi konusundaki deneyim dÃ¼zeyinize** ve **hesaplama kaynaklarÄ±nÄ±za** baÄŸlÄ± olarak, belirli yarÄ±ÅŸma tÃ¼rleri veya formatlarÄ± lehine veya aleyhine bazÄ± Ã¶nerilerimiz vardÄ±r:

* **Tamamen yeni baÅŸlayanlar** iÃ§in, *Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± iyi bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r.
  Bu yarÄ±ÅŸmalar, yÃ¼ksek rekabet baskÄ±sÄ± olmadan Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmenizi saÄŸlar.
  Bununla birlikte, birÃ§ok yeni baÅŸlayan da *Featured* veya *Research* yarÄ±ÅŸmalarÄ±ndan baÅŸlamÄ±ÅŸ ve rekabet baskÄ±sÄ±nÄ±n altÄ±nda daha hÄ±zlÄ± Ã¶ÄŸrendiklerini fark etmiÅŸtir.
  Bu nedenle Ã¶nerimiz, **Ã¶ÄŸrenme tarzÄ±nÄ±za gÃ¶re karar vermenizdir:**

  * BazÄ± Kaggle kullanÄ±cÄ±larÄ± keÅŸfederek ve iÅŸ birliÄŸi yaparak Ã¶ÄŸrenir (*Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± bu kiÅŸiler iÃ§in idealdir).
  * DiÄŸerleri ise hÄ±zlÄ± tempolu bir yarÄ±ÅŸmanÄ±n rekabet ortamÄ±nda motive olur.

* *Featured* ve *Research* yarÄ±ÅŸmalarÄ±nda ise ÅŸunu da gÃ¶z Ã¶nÃ¼nde bulundurmak gerekir:
  Bu yarÄ±ÅŸmalar genellikle yapay zekÃ¢ ve makine Ã¶ÄŸrenmesinin **uÃ§ (deneysel) uygulamalarÄ±yla** ilgilidir.
  DolayÄ±sÄ±yla bu yarÄ±ÅŸmalarda baÅŸarÄ±lÄ± olabilmek iÃ§in ya bu alanda **saÄŸlam bir altyapÄ±ya sahip olmanÄ±z** ya da yarÄ±ÅŸmanÄ±n uygulama alanÄ±yla ilgili araÅŸtÄ±rmalarÄ± Ã¶ÄŸrenmeye istekli olmanÄ±z gerekir.

Son olarak, Ã§oÄŸu yarÄ±ÅŸmanÄ±n, birÃ§ok veri bilimcisinin iÅŸ yerinde eriÅŸemediÄŸi **hesaplama kaynaklarÄ±na** ihtiyaÃ§ duyduÄŸunu unutmayÄ±n.
Kaggle dÄ±ÅŸÄ±ndaki bulut platformlarÄ±nÄ± kullanÄ±rsanÄ±z bu, **artan maliyetlere** yol aÃ§abilir.
Bu nedenle, **Code yarÄ±ÅŸmalarÄ±** veya **zaman ve kaynak sÄ±nÄ±rlamalarÄ± olan yarÄ±ÅŸmalar**, tÃ¼m katÄ±lÄ±mcÄ±larÄ± aynÄ± kaynak dÃ¼zeyine getirmeyi amaÃ§ladÄ±klarÄ± iÃ§in Ã§abalarÄ±nÄ±zÄ± yoÄŸunlaÅŸtÄ±rmak aÃ§Ä±sÄ±ndan ideal bir seÃ§enek olabilir.

#### Submission and leaderboard dynamics *(GÃ¶nderim ve liderlik tablosu dinamikleri)*

Kaggleâ€™Ä±n Ã§alÄ±ÅŸma biÃ§imi basit gÃ¶rÃ¼nebilir: Test seti katÄ±lÄ±mcÄ±lardan gizlenir; modelinizi eÄŸitirsiniz; eÄŸer modeliniz test setindeki sonuÃ§larÄ± en iyi ÅŸekilde tahmin ederse yÃ¼ksek puan alÄ±r ve muhtemelen kazanÄ±rsÄ±nÄ±z.
Ne yazÄ±k ki, bu tanÄ±m Kaggle yarÄ±ÅŸmalarÄ±nÄ±n iÃ§ iÅŸleyiÅŸini **fazla basitleÅŸtirilmiÅŸ** bir ÅŸekilde aÃ§Ä±klar.
Bu aÃ§Ä±klama, yarÄ±ÅŸmacÄ±larÄ±n doÄŸrudan ve dolaylÄ± etkileÅŸimleriyle ilgili dinamikleri ya da karÅŸÄ± karÅŸÄ±ya olduÄŸunuz problemin, eÄŸitim ve test setinin **ince ayrÄ±ntÄ±larÄ±nÄ± (nÃ¼anslarÄ±nÄ±)** dikkate almaz.

##### Explaining the Common Task Framework paradigm *(Ortak GÃ¶rev Ã‡erÃ§evesi paradigmasÄ±nÄ±n aÃ§Ä±klanmasÄ±)*

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair daha kapsamlÄ± bir aÃ§Ä±klama, **Stanford Ãœniversitesi Ä°statistik ProfesÃ¶rÃ¼ David Donoho** tarafÄ±ndan *50 Years of Data Science* (Veri Biliminin 50 YÄ±lÄ±) adlÄ± makalesinde verilmiÅŸtir.
Bu makale ilk olarak *Journal of Computational and Graphical Statistics* dergisinde yayÄ±mlanmÄ±ÅŸ, ardÄ±ndan MIT Bilgisayar Bilimi ve Yapay ZekÃ¢ LaboratuvarÄ± sitesinde paylaÅŸÄ±lmÄ±ÅŸtÄ±r (bkz. [http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)).

ProfesÃ¶r Donoho doÄŸrudan Kaggleâ€™dan deÄŸil, genel olarak **veri bilimi yarÄ±ÅŸma platformlarÄ±ndan** bahseder.
BilgisayarlÄ± dilbilimci **Mark Liberman**â€™dan alÄ±ntÄ± yaparak, veri bilimi yarÄ±ÅŸmalarÄ±nÄ± ve platformlarÄ±nÄ± **â€œCommon Task Framework (CTF)â€ â€” Ortak GÃ¶rev Ã‡erÃ§evesi** paradigmasÄ±nÄ±n bir parÃ§asÄ± olarak tanÄ±mlar.
Bu paradigma, son on yÄ±llarda birÃ§ok alanda veri biliminin sessiz ama istikrarlÄ± bir ÅŸekilde ilerlemesini saÄŸlamÄ±ÅŸtÄ±r.

Donoho, CTFâ€™nin veri bilimi problemlerine **ampirik (deneysel)** aÃ§Ä±dan Ã§Ã¶zÃ¼m getirmede son derece etkili olduÄŸunu sÃ¶yler ve bunu desteklemek iÃ§in **Netflix yarÄ±ÅŸmasÄ±** ile Ã§eÅŸitli **DARPA yarÄ±ÅŸmalarÄ±nÄ±** baÅŸarÄ±lÄ± Ã¶rnekler olarak gÃ¶sterir.
CTF paradigmasÄ±, birÃ§ok alanda en iyi Ã§Ã¶zÃ¼mleri yeniden ÅŸekillendirmeye katkÄ±da bulunmuÅŸtur.

---

**CTFâ€™nin bileÅŸenleri ve â€œgizli sosuâ€**

Bir CTF, bazÄ± bileÅŸenlerden ve â€œgizli bir sostanâ€ oluÅŸur.
BileÅŸenler ÅŸunlardÄ±r:

1. Herkese aÃ§Ä±k bir veri seti ve bununla iliÅŸkili bir tahmin gÃ¶revi,
2. Bu gÃ¶reve en iyi tahmini Ã¼retmek iÃ§in ortak bir amaÃ§la Ã§alÄ±ÅŸan yarÄ±ÅŸmacÄ±lar,
3. KatÄ±lÄ±mcÄ±larÄ±n tahminlerini adil ve objektif biÃ§imde puanlayan, ancak Ã§Ã¶zÃ¼me dair fazla ipucu vermeyen (ya da en azÄ±ndan bunu sÄ±nÄ±rlayan) bir deÄŸerlendirme sistemi.

Bu sistem, gÃ¶rev aÃ§Ä±k ÅŸekilde tanÄ±mlandÄ±ÄŸÄ±nda ve veri kaliteli olduÄŸunda en iyi ÅŸekilde Ã§alÄ±ÅŸÄ±r.
Zaman iÃ§inde Ã§Ã¶zÃ¼mlerin performansÄ± kÃ¼Ã§Ã¼k artÄ±ÅŸlarla geliÅŸir ve sonunda bir **asimptota (doyum noktasÄ±na)** ulaÅŸÄ±r.
Bu sÃ¼reÃ§, katÄ±lÄ±mcÄ±lar arasÄ±nda belli bir dÃ¼zeyde paylaÅŸÄ±mÄ±n teÅŸvik edilmesiyle hÄ±zlanabilir.
Kaggleâ€™da bu paylaÅŸÄ±m; **tartÄ±ÅŸmalar, paylaÅŸÄ±lan Kaggle Notebookâ€™larÄ±** ve **Datasets** bÃ¶lÃ¼mÃ¼ndeki ek veriler aracÄ±lÄ±ÄŸÄ±yla gerÃ§ekleÅŸir.

CTF paradigmasÄ±na gÃ¶re, bir yarÄ±ÅŸmadaki **rekabet baskÄ±sÄ±**, Ã§Ã¶zÃ¼mlerin sÃ¼rekli olarak geliÅŸmesi iÃ§in tek baÅŸÄ±na yeterlidir.
Bu rekabet baskÄ±sÄ±, katÄ±lÄ±mcÄ±lar arasÄ±nda belli Ã¶lÃ§Ã¼de **bilgi paylaÅŸÄ±mÄ±yla** birleÅŸtiÄŸinde, geliÅŸme Ã§ok daha hÄ±zlÄ± gerÃ§ekleÅŸir.
Ä°ÅŸte bu nedenle Kaggle, paylaÅŸÄ±mÄ± teÅŸvik eden birÃ§ok Ã¶dÃ¼l ve mekanizma getirmiÅŸtir.

---

**CTFâ€™nin gizli sosu: rekabetin kendisi**

CTF paradigmasÄ±ndaki â€œgizli sosâ€, **bizzat yarÄ±ÅŸmanÄ±n kendisidir**.
Bu yapÄ±, ampirik performansÄ±n artÄ±rÄ±lmasÄ±nÄ±n hedeflendiÄŸi pratik bir problem Ã§erÃ§evesinde, her zaman yeni **Ã¶lÃ§Ã¼tlerin (benchmark)**, **veri ve modelleme Ã§Ã¶zÃ¼mlerinin**, ve genel anlamda **makine Ã¶ÄŸrenmesinin daha iyi uygulanma biÃ§imlerinin** ortaya Ã§Ä±kmasÄ±nÄ± saÄŸlar.

Bir yarÄ±ÅŸma, dolayÄ±sÄ±yla bir tahmin problemini Ã§Ã¶zmenin yeni yollarÄ±nÄ±, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** iÃ§in yeni yÃ¶ntemleri ve yeni **algoritmik veya modelleme Ã§Ã¶zÃ¼mlerini** sunabilir.
Ã–rneÄŸin, **derin Ã¶ÄŸrenme (deep learning)** yalnÄ±zca akademik araÅŸtÄ±rmalardan doÄŸmamÄ±ÅŸtÄ±r; tersine, etkinliÄŸini kanÄ±tlayan baÅŸarÄ±lÄ± yarÄ±ÅŸmalar sayesinde bÃ¼yÃ¼k bir ivme kazanmÄ±ÅŸtÄ±r.
(Ã–rneÄŸin, Geoffrey Hinton ekibinin kazandÄ±ÄŸÄ± **Merck yarÄ±ÅŸmasÄ±nÄ±** hatÄ±rlayalÄ±m: [https://www.kaggle.com/c/MerckActivity/overview/winners](https://www.kaggle.com/c/MerckActivity/overview/winners)).

---

**CTF ve aÃ§Ä±k yazÄ±lÄ±m hareketi**

**AÃ§Ä±k kaynak yazÄ±lÄ±m hareketi** ile birleÅŸtiÄŸinde (Ã¶rneÄŸin Scikit-learn, TensorFlow veya PyTorch gibi gÃ¼Ã§lÃ¼ analitik araÃ§lara herkesin eriÅŸebilmesi), CTF paradigmasÄ± Ã§ok daha iyi sonuÃ§lar Ã¼retir.
Bunun nedeni, tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n baÅŸlangÄ±Ã§ta **aynÄ± dÃ¼zeyde olanaklara sahip** olmasÄ±dÄ±r.

Ancak, bir yarÄ±ÅŸmadaki Ã§Ã¶zÃ¼mÃ¼n **Ã¶zel donanÄ±m veya yÃ¼ksek iÅŸlem gÃ¼cÃ¼ne** dayanmasÄ±, elde edilebilecek sonuÃ§larÄ± sÄ±nÄ±rlayabilir.
Ã‡Ã¼nkÃ¼ bu durum, bu tÃ¼r kaynaklara eriÅŸimi olmayan yarÄ±ÅŸmacÄ±larÄ±n doÄŸru ÅŸekilde katÄ±lÄ±m gÃ¶stermesini ya da diÄŸer katÄ±lÄ±mcÄ±lar Ã¼zerinde **rekabet baskÄ±sÄ±** oluÅŸturarak dolaylÄ± katkÄ± saÄŸlamasÄ±nÄ± engelleyebilir.

Ä°ÅŸte bu nedenle Kaggle, yarÄ±ÅŸmalara katÄ±lanlar iÃ§in **Ã¼cretsiz bulut hizmetleri** (Ã¶rneÄŸin **Kaggle Notebooks**) sunmaya baÅŸlamÄ±ÅŸtÄ±r.
Bu uygulama, Ã¶zellikle donanÄ±m yoÄŸun yarÄ±ÅŸmalarda (Ã¶rneÄŸin derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ± gibi) bazÄ± farklarÄ± azaltabilir ve genel anlamda rekabeti artÄ±rabilir.

##### Understanding what can go wrong in a competition *(Bir yarÄ±ÅŸmada nelerin ters gidebileceÄŸini anlamak)*

**CTF ParadigmasÄ± ve YarÄ±ÅŸma BaÅŸarÄ±sÄ±zlÄ±klarÄ±nÄ±n Nedenleri**

CTF paradigmasÄ±na dair Ã¶nceki aÃ§Ä±klamamÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurursak, bir yarÄ±ÅŸmanÄ±n tek ihtiyacÄ± uygun bir platformda dÃ¼zenlenmekmiÅŸ gibi gÃ¶rÃ¼nebilir. BÃ¶yle olursa, katÄ±lÄ±mcÄ±lar iÃ§in olumlu bir katÄ±lÄ±m ve sponsor ÅŸirket iÃ§in olaÄŸanÃ¼stÃ¼ modeller gibi iyi sonuÃ§larÄ±n kendiliÄŸinden ortaya Ã§Ä±kacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

Ancak, hem katÄ±lÄ±mcÄ±lar hem de yarÄ±ÅŸmayÄ± dÃ¼zenleyen kurum aÃ§Ä±sÄ±ndan **hayal kÄ±rÄ±klÄ±ÄŸÄ±na yol aÃ§abilecek** bazÄ± durumlar da meydana gelebilir:

* Veri sÄ±zÄ±ntÄ±sÄ± (data leakage)
* Liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼m denemesi (probing)
* AÅŸÄ±rÄ± uyum (overfitting) ve buna baÄŸlÄ± liderlik tablosu deÄŸiÅŸimleri
* Ã–zel paylaÅŸÄ±m (private sharing)

---

**Veri SÄ±zÄ±ntÄ±sÄ± (Data Leakage)**

**Veri sÄ±zÄ±ntÄ±sÄ±**, Ã§Ã¶zÃ¼mÃ¼n bir kÄ±smÄ±nÄ±n bizzat verinin kendisinden geri izlenebilmesi durumudur.
Ã–rneÄŸin, bazÄ± deÄŸiÅŸkenler hedef deÄŸiÅŸkenden (target variable) sonra oluÅŸmuÅŸ olabilir ve bu da hedef hakkÄ±nda bilgi sÄ±zdÄ±rÄ±r.

Bu durum, Ã¶rneÄŸin dolandÄ±rÄ±cÄ±lÄ±k tespitinde, dolandÄ±rÄ±cÄ±lÄ±k gerÃ§ekleÅŸtikten sonra gÃ¼ncellenen deÄŸiÅŸkenleri kullandÄ±ÄŸÄ±nÄ±zda; veya satÄ±ÅŸ tahmini yaparken, bir Ã¼rÃ¼nÃ¼n **gerÃ§ek daÄŸÄ±tÄ±m bilgilerini** iÅŸlediÄŸinizde (daha fazla daÄŸÄ±tÄ±m â†’ daha fazla talep â†’ daha fazla satÄ±ÅŸ) ortaya Ã§Ä±kar.

BaÅŸka bir Ã¶rnek de, **eÄŸitim ve test Ã¶rneklerinin tahmin edilebilir bir sÄ±rada dÃ¼zenlenmiÅŸ olmasÄ±** ya da Ã¶rnek kimliklerinin (identifier) deÄŸerlerinin Ã§Ã¶zÃ¼me dair ipuÃ§larÄ± iÃ§ermesidir.
Ã–rneÄŸin, kimlik numarasÄ± hedef deÄŸiÅŸkenin sÄ±rasÄ±na gÃ¶re belirlenmiÅŸse ya da kimlik deÄŸeri zamanla iliÅŸkiliyse ve zaman hedef deÄŸiÅŸkenin olasÄ±lÄ±ÄŸÄ±nÄ± etkiliyorsa bu da bir sÄ±zÄ±ntÄ±dÄ±r.

Bu tÃ¼r veri sÄ±zÄ±ntÄ±larÄ±na, bazÄ± yarÄ±ÅŸmacÄ±lar tarafÄ±ndan **â€œaltÄ±n Ã¶zellikler (golden features)â€** adÄ± verilir â€” Ã§Ã¼nkÃ¼ verideki bu tÃ¼r kÃ¼Ã§Ã¼k ipuÃ§larÄ±nÄ± fark etmek, katÄ±lÄ±mcÄ±lar iÃ§in adeta altÄ±n deÄŸerinde Ã¶dÃ¼ller kazandÄ±rabilir.
Ancak bu durum genellikle **yeniden kullanÄ±labilir olmayan Ã§Ã¶zÃ¼mler** Ã¼retir.
Bu da sponsor iÃ§in **optimal olmayan sonuÃ§lar** anlamÄ±na gelir, ancak en azÄ±ndan sponsor hangi deÄŸiÅŸkenlerin sÄ±zÄ±ntÄ±ya yol aÃ§abileceÄŸini Ã¶ÄŸrenmiÅŸ olur.

---

**Liderlik Tablosu Ãœzerinden Ã‡Ã¶zÃ¼m Denemesi (Leaderboard Probing)**

Bir diÄŸer problem, **liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼mÃ¼ test etmek veya â€œdeÅŸifre etmekâ€** olasÄ±lÄ±ÄŸÄ±dÄ±r.
Bu durumda, yarÄ±ÅŸmacÄ±lar deÄŸerlendirme metriklerinden yararlanarak sÃ¼rekli denemeler yapabilir ve bu yolla Ã§Ã¶zÃ¼m hakkÄ±nda bilgi elde edebilir.
Yine bu tÃ¼r Ã§Ã¶zÃ¼mler, farklÄ± koÅŸullarda tamamen **kullanÄ±lamaz** hale gelir.

Bunun aÃ§Ä±k bir Ã¶rneÄŸi **â€œDonâ€™t Overfit IIâ€** yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r.
Kazanan katÄ±lÄ±mcÄ± **Zachary Mayers**, her bir deÄŸiÅŸkeni tek tek gÃ¶ndererek her birinin model Ã¼zerindeki etkisini analiz etmiÅŸ ve bu yolla modelinin katsayÄ±larÄ±nÄ± doÄŸru tahmin edebilmiÅŸtir.
(Zachâ€™Ä±n detaylÄ± Ã§Ã¶zÃ¼mÃ¼nÃ¼ burada okuyabilirsiniz: [https://www.kaggle.com/c/dont-overfit-ii/discussion/91766](https://www.kaggle.com/c/dont-overfit-ii/discussion/91766))

Genellikle **zaman serisi problemleri** veya test verisinde sistematik deÄŸiÅŸimler olan diÄŸer problemler, bu tÃ¼r probingâ€™den ciddi ÅŸekilde etkilenebilir.
Ã‡Ã¼nkÃ¼ bu durum, yarÄ±ÅŸmacÄ±larÄ±n tahminlerini Ã¶rneÄŸin sabit bir sayÄ± ile Ã§arpmak gibi bir **son iÅŸleme (post-processing)** adÄ±mÄ±yla puanlarÄ±nÄ± artÄ±rmalarÄ±na olanak tanÄ±yabilir.

---

**Liderlik Tablosuna AÅŸÄ±rÄ± GÃ¼venme ve AÅŸÄ±rÄ± Uyum (Overfitting)**

Liderlik tablosuna aÅŸÄ±rÄ± gÃ¼venmek, bir baÅŸka tÃ¼r **aÅŸÄ±rÄ± uyum (overfitting)** Ã¶rneÄŸidir.
KatÄ±lÄ±mcÄ±lar kendi doÄŸrulama testlerinden Ã§ok liderlik tablosundaki geri bildirimlere gÃ¶re hareket ettiklerinde bu durum ortaya Ã§Ä±kar.

Bazen bu durum yarÄ±ÅŸmanÄ±n **tamamen baÅŸarÄ±sÄ±z olmasÄ±na**, yani nihai liderlik tablosunda **beklenmedik ve rastlantÄ±sal sÄ±ralama deÄŸiÅŸikliklerine (shake-up)** yol aÃ§abilir.
BÃ¶yle bir durumda kazanan Ã§Ã¶zÃ¼mler, aslÄ±nda probleme uygun olmayan veya tamamen tesadÃ¼fi Ã§Ã¶zÃ¼mler olabilir.

Bu tÃ¼r olaylar, **eÄŸitim seti ile test seti arasÄ±ndaki farklarÄ± analiz eden** bazÄ± tekniklerin geliÅŸtirilmesine yol aÃ§mÄ±ÅŸtÄ±r.
Bu tÃ¼r analizlere **adversarial testing** denir ve liderlik tablosuna ne kadar gÃ¼venileceÄŸi veya eÄŸitim ve test setleri arasÄ±nda tamamen kaÃ§Ä±nÄ±lmasÄ± gereken Ã¶zellikler olup olmadÄ±ÄŸÄ± konusunda fikir verir.
Ã–rnek olarak, **Bojan Tunguz**â€™un ÅŸu Notebookâ€™una gÃ¶z atabilirsiniz:
[https://www.kaggle.com/tunguz/adversarial-ieee](https://www.kaggle.com/tunguz/adversarial-ieee).

---

**Overfittingâ€™e KarÅŸÄ± Savunma Stratejileri**

Liderlik tablosuna aÅŸÄ±rÄ± uyumu Ã¶nlemenin bir baÅŸka yolu, **gÃ¼venli stratejiler** kullanmaktÄ±r.
Ã–rneÄŸin, genellikle her katÄ±lÄ±mcÄ±nÄ±n **final deÄŸerlendirmesi iÃ§in iki Ã§Ã¶zÃ¼m** gÃ¶ndermesine izin verilir.
Bu durumda iyi bir strateji, birini liderlik tablosuna gÃ¶re en baÅŸarÄ±lÄ± olan Ã§Ã¶zÃ¼m olarak, diÄŸerini ise **kendi Ã§apraz doÄŸrulama testlerinde** en iyi performans gÃ¶steren Ã§Ã¶zÃ¼m olarak gÃ¶ndermektir.

Liderlik tablosu probingâ€™i ve overfittingâ€™i Ã¶nlemek iÃ§in Kaggle, daha Ã¶nce de bahsettiÄŸimiz gibi, **iki aÅŸamalÄ± deÄŸerlendirme sistemi** iÃ§eren **Code yarÄ±ÅŸmalarÄ±na** yÃ¶nelik Ã§eÅŸitli yenilikler getirmiÅŸtir.
Bu yarÄ±ÅŸmalarda katÄ±lÄ±mcÄ±lar test verisini hiÃ§ gÃ¶rmedikleri iÃ§in, kendi **yerel doÄŸrulama testlerine** daha fazla Ã¶nem vermek zorunda kalÄ±rlar.

---

**Ã–zel PaylaÅŸÄ±m (Private Sharing) ve Etik DÄ±ÅŸÄ± DavranÄ±ÅŸlar**

Bir yarÄ±ÅŸmayÄ± bozabilecek bir diÄŸer unsur, **Ã¶zel paylaÅŸÄ±m (private sharing)** yani fikir ve Ã§Ã¶zÃ¼mlerin yalnÄ±zca kapalÄ± bir grup arasÄ±nda paylaÅŸÄ±lmasÄ±dÄ±r.
Buna ek olarak, **birden fazla hesapla yarÄ±ÅŸmak**, **birden fazla takÄ±ma katÄ±lÄ±p fikir Ã§almak** gibi etik dÄ±ÅŸÄ± davranÄ±ÅŸlar da olabilir.

Bu tÃ¼r durumlar, bazÄ± katÄ±lÄ±mcÄ±lar iÃ§in avantaj yaratÄ±rken Ã§oÄŸunluk iÃ§in dezavantaj doÄŸurur â€” yani **bilgi asimetrisi** oluÅŸur.
BÃ¶ylece, yarÄ±ÅŸma boyunca paylaÅŸÄ±m eksik kalÄ±r ve az sayÄ±da takÄ±m tam rekabet baskÄ±sÄ± yaratabilir.

AyrÄ±ca, bu tÃ¼r durumlar katÄ±lÄ±mcÄ±larÄ±n farkÄ±na vardÄ±ÄŸÄ±nda (Ã¶rneÄŸin ÅŸu tartÄ±ÅŸmaya bakÄ±labilir: [https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503](https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503)), yarÄ±ÅŸmaya ve sonraki yarÄ±ÅŸmalara olan gÃ¼ven ve katÄ±lÄ±m da azalabilir.

#### Computational resources *(Hesaplama kaynaklarÄ±)*

BazÄ± yarÄ±ÅŸmalar, **Ã¼retim ortamÄ±nda uygulanabilir Ã§Ã¶zÃ¼mler** elde edebilmek iÃ§in belirli sÄ±nÄ±rlamalar getirir.
Ã–rneÄŸin, **Bosch Production Line Performance** yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/bosch-production-line-performance](https://www.kaggle.com/c/bosch-production-line-performance)) Ã§Ã¶zÃ¼m modelleri iÃ§in **Ã§alÄ±ÅŸma sÃ¼resi**, **Ã§Ä±ktÄ± dosyasÄ± boyutu** ve **bellek kullanÄ±mÄ±** aÃ§Ä±sÄ±ndan katÄ± sÄ±nÄ±rlamalara sahipti.

**Notebook tabanlÄ± yarÄ±ÅŸmalar** (Ã¶nceden *Kernel-Only* yarÄ±ÅŸmalarÄ± olarak biliniyordu), hem eÄŸitimin hem de Ã§Ä±karÄ±mÄ±n (inference) **Kaggle Notebooks** Ã¼zerinde gerÃ§ekleÅŸtirilmesini zorunlu kÄ±lar.
Bu durumda, kullanmanÄ±z gereken kaynaklarla ilgili bir sorun oluÅŸmaz; Ã§Ã¼nkÃ¼ **Kaggle size tÃ¼m gerekli donanÄ±m kaynaklarÄ±nÄ± saÄŸlar**.
Bu yaklaÅŸÄ±m aynÄ± zamanda, **tÃ¼m katÄ±lÄ±mcÄ±larÄ±n aynÄ± baÅŸlangÄ±Ã§ noktasÄ±nda yarÄ±ÅŸmasÄ±nÄ±** saÄŸlamak amacÄ±yla da tasarlanmÄ±ÅŸtÄ±r.

Sorunlar, yalnÄ±zca **Ã§Ä±karÄ±m (inference)** aÅŸamasÄ±nda Notebook kullanÄ±mÄ±nÄ± zorunlu kÄ±lan yarÄ±ÅŸmalarda ortaya Ã§Ä±kar.
Bu tÃ¼r yarÄ±ÅŸmalarda modellerinizi kendi bilgisayarÄ±nÄ±zda eÄŸitebilir, ancak **test aÅŸamasÄ±nda** model sayÄ±sÄ± ve karmaÅŸÄ±klÄ±ÄŸÄ± aÃ§Ä±sÄ±ndan sÄ±nÄ±rlamalara tabi olursunuz.

GÃ¼nÃ¼mÃ¼zde yarÄ±ÅŸmalarÄ±n Ã§oÄŸu **derin Ã¶ÄŸrenme (deep learning)** Ã§Ã¶zÃ¼mleri gerektirdiÄŸinden, **rekabetÃ§i sonuÃ§lar elde edebilmek iÃ§in GPU gibi Ã¶zel donanÄ±mlara** ihtiyaÃ§ duyacaÄŸÄ±nÄ±zÄ± bilmelisiniz.

GÃ¼nÃ¼mÃ¼zde nadirleÅŸmiÅŸ olsa da, bazÄ± **tabular veri yarÄ±ÅŸmalarÄ±nda** bile, **Ã§ok Ã§ekirdekli iÅŸlemcilere** ve **yÃ¼ksek belleÄŸe** sahip gÃ¼Ã§lÃ¼ bir makineye ihtiyacÄ±nÄ±z olduÄŸunu fark edeceksiniz.
Bu kaynaklar, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** uygulamak, **deneyler yÃ¼rÃ¼tmek** ve **modelleri hÄ±zlÄ± bir ÅŸekilde inÅŸa etmek** iÃ§in gereklidir.

Standartlar hÄ±zla deÄŸiÅŸtiÄŸi iÃ§in, tÃ¼m katÄ±lÄ±mcÄ±larla aynÄ± seviyede rekabet edebilmek adÄ±na **net bir donanÄ±m standardÄ± tanÄ±mlamak zordur**.
Ancak, diÄŸer yarÄ±ÅŸmacÄ±larÄ±n hangi makineleri kullandÄ±ÄŸÄ±na bakarak gÃ¼ncel standartlar hakkÄ±nda fikir edinebilirsiniz â€” ister kendi bilgisayarlarÄ± olsun, ister bulut tabanlÄ± makineler.

Ã–rneÄŸin, **HP**, marka gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼ karÅŸÄ±lÄ±ÄŸÄ±nda bazÄ± seÃ§ilmiÅŸ Kaggle yarÄ±ÅŸmacÄ±larÄ±na **HP Z4 veya Z8** makineleri hediye ettiÄŸi bir program baÅŸlatmÄ±ÅŸtÄ±r.
Bir **Z8 makinesi**,

* 72 Ã§ekirdeÄŸe kadar CPU,
* 3 TB bellek,
* 48 TB depolama (Ã§oÄŸunluÄŸu SSD),
* ve genellikle **Ã§ift NVIDIA RTX GPU** barÄ±ndÄ±rÄ±r.

Bu dÃ¼zeyde bir sistemin birÃ§ok kiÅŸi iÃ§in eriÅŸilemez olduÄŸunu anlamak zor deÄŸildir.
Benzer Ã¶zelliklerde bir makineyi kÄ±sa sÃ¼reliÄŸine bile **Google Cloud (GCP)** veya **Amazon AWS** gibi platformlarda kiralamak bile **yÃ¼ksek maliyetler** doÄŸurabilir.

Bu nedenle, **Kaggleâ€™da Ã¼st sÄ±ralara tÄ±rmanma yolculuÄŸunuza baÅŸlarken**, en iyi yaklaÅŸÄ±m **Kaggleâ€™Ä±n Ã¼cretsiz sunduÄŸu altyapÄ±yÄ±**, yani **Kaggle Notebooksâ€™u (Ã¶nceki adÄ±yla Kaggle Kernels)** kullanmaktÄ±r.

##### Kaggle Notebooks *(Kaggle Defterleri)*

**Kaggle Notebooks**, bulut makinelerinde Ã§alÄ±ÅŸan **Docker konteynerleri** tabanlÄ±, sÃ¼rÃ¼mlenebilir (versioned) hesaplama ortamlarÄ±dÄ±r.
Bu ortamlar, **R** ve **Python** dillerinde hem **script** hem de **notebook** yazÄ±p Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r.

Kaggle Notebooks:

* **Kaggle ortamÄ±na entegredir:** Bu sayede doÄŸrudan notebookâ€™tan yarÄ±ÅŸmaya gÃ¶nderim (submission) yapabilir ve hangi gÃ¶nderimin hangi notebookâ€™tan geldiÄŸini takip edebilirsiniz.
* **Ã‡oÄŸu veri bilimi paketini Ã¶nceden yÃ¼klÃ¼ olarak iÃ§erir.**
* **KÄ±sÄ±tlÄ± Ã¶zelleÅŸtirme olanaÄŸÄ± sunar:** Dosya indirebilir ve ek Python/R paketleri yÃ¼kleyebilirsiniz.

Temel **Kaggle Notebook**, yalnÄ±zca CPU tabanlÄ±dÄ±r. Ancak, isterseniz:

* **NVIDIA Tesla P100 GPU**,
* veya **TPU v3-8** (Ã¶zellikle derin Ã¶ÄŸrenme gÃ¶revleri iÃ§in optimize edilmiÅŸ donanÄ±m hÄ±zlandÄ±rÄ±cÄ±sÄ±)
  desteÄŸiyle gÃ¼Ã§lendirilmiÅŸ sÃ¼rÃ¼mleri de kullanabilirsiniz.

Her yarÄ±ÅŸmanÄ±n bulut maliyeti, **iÅŸlenecek veri miktarÄ±na**, **kurduÄŸunuz model sayÄ±sÄ±na ve tÃ¼rÃ¼ne** baÄŸlÄ±dÄ±r.
Kaggle yarÄ±ÅŸmalarÄ±nda, **GCP (Google Cloud Platform)** veya **AWS** Ã¼zerinde kullanÄ±lmak Ã¼zere genellikle **200 â€“ 500 ABD DolarÄ±** aralÄ±ÄŸÄ±nda **Ã¼cretsiz bulut kredisi** daÄŸÄ±tÄ±lÄ±r.

Kaggle Notebooks, belirli **kullanÄ±m ve sÃ¼re sÄ±nÄ±rlamalarÄ±** altÄ±nda Ã§alÄ±ÅŸÄ±r; ancak bu sÄ±nÄ±rlar dahilinde yarÄ±ÅŸmalarda **temel modellerinizi geliÅŸtirmek iÃ§in yeterli hesaplama gÃ¼cÃ¼nÃ¼** saÄŸlar.

| Notebook tÃ¼rÃ¼ | CPU Ã§ekirdeÄŸi | Bellek | AynÄ± anda Ã§alÄ±ÅŸtÄ±rÄ±labilen notebook sayÄ±sÄ± | HaftalÄ±k kota |
| ------------- | ------------- | ------ | ------------------------------------------ | ------------- |
| **CPU**       | 4             | 16 GB  | 10                                         | SÄ±nÄ±rsÄ±z      |
| **GPU**       | 2             | 13 GB  | 2                                          | 30 saat       |
| **TPU**       | 4             | 16 GB  | 2                                          | 30 saat       |

* **CPU ve GPU notebookâ€™larÄ±**, **maksimum 12 saat** boyunca kesintisiz Ã§alÄ±ÅŸabilir.
* **TPU notebookâ€™larÄ±** ise **en fazla 9 saat** boyunca Ã§alÄ±ÅŸtÄ±rÄ±labilir.
  Bu sÃ¼reler dolduÄŸunda, diske kaydedilmemiÅŸ hiÃ§bir Ã§Ä±ktÄ± alÄ±namaz.

KullanÄ±cÄ±larÄ±n **20 GB kalÄ±cÄ± disk alanÄ±** bulunur (model ve sonuÃ§larÄ± saklamak iÃ§in).
Buna ek olarak, geÃ§ici dosyalar iÃ§in **20 GBâ€™tan fazla geÃ§ici (scratchpad) alan** kullanÄ±labilir.

BazÄ± durumlarda, Kaggleâ€™Ä±n sunduÄŸu **GPU destekli makineler** yeterli olmayabilir.
Ã–rneÄŸin, **Deepfake Detection Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/deepfake-detection-challenge](https://www.kaggle.com/c/deepfake-detection-challenge)) yaklaÅŸÄ±k **500 GB video verisi** iÅŸlenmesi gerekiyordu.

Bu, iki aÃ§Ä±dan zorluk yaratÄ±yordu:

1. HaftalÄ±k **30 saatlik kullanÄ±m sÃ¼resi** sÄ±nÄ±rlamasÄ±,
2. AynÄ± anda **en fazla iki GPU destekli makine** Ã§alÄ±ÅŸtÄ±rÄ±labilmesi.

Kodunuzu **GPU yerine TPU kullanacak ÅŸekilde optimize ederek** (bunun iÃ§in rehber: [https://www.kaggle.com/docs/tpu](https://www.kaggle.com/docs/tpu)) sÃ¼reyi iki katÄ±na Ã§Ä±karabilirsiniz.
Ancak bu bile, **bÃ¼yÃ¼k veri setlerine sahip yarÄ±ÅŸmalarda** (Ã¶rneÄŸin Deepfake Detection Challenge gibi) **hÄ±zlÄ± denemeler** yapmak iÃ§in yeterli olmayabilir.

Bu nedenle, **BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek** kÄ±smÄ±nda, bu tÃ¼r sÄ±nÄ±rlamalarla nasÄ±l baÅŸa Ã§Ä±kabileceÄŸinize dair **ipuÃ§larÄ±** vereceÄŸiz.
AmaÃ§, **yÃ¼ksek performanslÄ± donanÄ±m satÄ±n almadan** tatmin edici sonuÃ§lar elde etmenize yardÄ±mcÄ± olmaktÄ±r.

AyrÄ±ca, **Kaggle Notebooksâ€™u GCP ile entegre etme** yÃ¶ntemlerini gÃ¶stereceÄŸiz.
Alternatif olarak, **BÃ¶lÃ¼m 2: Datasets ile Verileri Organize Etmek** kÄ±smÄ±nda, tÃ¼m Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± **Google Colab** gibi baÅŸka bir bulut tabanlÄ± ortama nasÄ±l taÅŸÄ±yabileceÄŸinizi anlatacaÄŸÄ±z.

#### Teaming and networking *(TakÄ±m kurma ve aÄŸ oluÅŸturma)*

Hesaplama gÃ¼cÃ¼ (computational power) Ã¶nemli bir rol oynasa da, bir Kaggle yarÄ±ÅŸmasÄ±nda **gerÃ§ek farkÄ± yaratan unsur, insan uzmanlÄ±ÄŸÄ± ve yeteneÄŸidir.**
Bir yarÄ±ÅŸmanÄ±n baÅŸarÄ±lÄ± bir ÅŸekilde yÃ¼rÃ¼tÃ¼lebilmesi bazen bir **takÄ±mÄ±n ortak Ã§alÄ±ÅŸmasÄ±nÄ±** gerektirir.

**Recruitment (Ä°ÅŸe AlÄ±m)** yarÄ±ÅŸmalarÄ± hariÃ§ â€” ki bu yarÄ±ÅŸmalarda sponsor ÅŸirket, katÄ±lÄ±mcÄ±larÄ±n bireysel yeteneklerini daha iyi deÄŸerlendirebilmek iÃ§in yalnÄ±z katÄ±lÄ±m talep edebilir â€” Kaggleâ€™da genellikle **takÄ±m kurmaya dair herhangi bir kÄ±sÄ±tlama yoktur.**
Bir takÄ±m genellikle **en fazla beÅŸ kiÅŸiden** oluÅŸabilir.

TakÄ±m kurmanÄ±n birÃ§ok avantajÄ± vardÄ±r; Ã§Ã¼nkÃ¼ **farklÄ± becerilerin birleÅŸmesi**, daha iyi Ã§Ã¶zÃ¼mler Ã¼retilmesini saÄŸlar.
Bir ekip, **probleme daha fazla zaman ayÄ±rabilir** ve her Ã¼yenin sahip olduÄŸu farklÄ± uzmanlÄ±k alanlarÄ± (Ã¶rneÄŸin modelleme, veri Ã¶n iÅŸleme, gÃ¶rselleÅŸtirme) ortak hedefe katkÄ± saÄŸlar.
Her veri bilimcisi aynÄ± becerilere veya aynÄ± seviyede uzmanlÄ±ÄŸa sahip deÄŸildir; dolayÄ±sÄ±yla ekip iÃ§indeki **beceri Ã§eÅŸitliliÄŸi**, yarÄ±ÅŸma performansÄ±nÄ± artÄ±rÄ±r.

Yine de, takÄ±m Ã§alÄ±ÅŸmasÄ±nÄ±n dezavantajlarÄ± da vardÄ±r.
**FarklÄ± bireyleri ortak bir hedef doÄŸrultusunda koordine etmek her zaman kolay deÄŸildir** ve bazen verimsiz durumlar yaÅŸanabilir.

YaygÄ±n sorunlardan biri, bazÄ± ekip Ã¼yelerinin **aktif katÄ±lÄ±m gÃ¶stermemesi** veya **tamamen pasif kalmasÄ±dÄ±r.**
Ancak en kÃ¶tÃ¼ senaryo, ekip Ã¼yelerinden birinin yarÄ±ÅŸma kurallarÄ±nÄ± ihlal etmesidir; bu durumda **tÃ¼m ekip diskalifiye edilebilir.**
Daha da kÃ¶tÃ¼sÃ¼, bazen bir ekip Ã¼yesi **diÄŸer bir takÄ±ma avantaj saÄŸlamak iÃ§in casusluk** bile yapabilir â€” ki bu durum geÃ§miÅŸte yaÅŸanmÄ±ÅŸtÄ±r.

Olumsuzluklara raÄŸmen, Kaggleâ€™da takÄ±m olmak harika bir fÄ±rsattÄ±r.
DiÄŸer veri bilimcileriyle tanÄ±ÅŸmak, **ortak bir amaÃ§ iÃ§in iÅŸ birliÄŸi yapmak** ve **bireysel olarak elde edilemeyecek sonuÃ§lara ulaÅŸmak** iÃ§in Ã¶nemli bir deneyimdir.

AyrÄ±ca Kaggle, **takÄ±m katÄ±lÄ±mcÄ±larÄ±nÄ± bireysel katÄ±lÄ±mcÄ±lara gÃ¶re Ã¶dÃ¼llendirme aÃ§Ä±sÄ±ndan avantajlÄ±** kÄ±lar.
KÃ¼Ã§Ã¼k takÄ±mlar, Ã¶dÃ¼l havuzundan **eÅŸit paydan daha yÃ¼ksek bir yÃ¼zde** alabilir.

TakÄ±m kurmak, Kaggleâ€™da **aÄŸ kurmanÄ±n (networking)** tek yolu deÄŸildir, ancak katÄ±lÄ±mcÄ±lar iÃ§in kesinlikle **daha faydalÄ± ve etkileÅŸimli** bir yoldur.
Bunun dÄ±ÅŸÄ±nda, **forum tartÄ±ÅŸmalarÄ±**, **dataset paylaÅŸÄ±mÄ±** ve **notebook paylaÅŸÄ±mÄ±** aracÄ±lÄ±ÄŸÄ±yla da diÄŸer katÄ±lÄ±mcÄ±larla baÄŸlantÄ± kurabilirsiniz.
Bu olanaklar, **diÄŸer veri bilimcileriyle tanÄ±ÅŸmanÄ±za** ve **toplulukta tanÄ±nmanÄ±za** yardÄ±mcÄ± olur.

Kaggle platformunun dÄ±ÅŸÄ±nda da Kaggle topluluÄŸuyla iletiÅŸim kurabileceÄŸiniz birÃ§ok ortam bulunmaktadÄ±r.
Ã–ncelikle, **Slack kanallarÄ±** oldukÃ§a faydalÄ±dÄ±r.

Ã–rneÄŸin, **KaggleNoobs** ([https://www.kaggle.com/getting-started/20577](https://www.kaggle.com/getting-started/20577)) adlÄ± kanal 2016 yÄ±lÄ±nda aÃ§Ä±lmÄ±ÅŸtÄ±r ve Kaggle yarÄ±ÅŸmalarÄ± Ã¼zerine birÃ§ok tartÄ±ÅŸmayÄ± barÄ±ndÄ±rÄ±r.
Burada, **kod veya model ile ilgili Ã¶zel bir probleminiz varsa**, size yardÄ±mcÄ± olabilecek destekleyici bir topluluk vardÄ±r.

Bunun dÄ±ÅŸÄ±nda da birÃ§ok Slack kanalÄ±, **Kaggle yarÄ±ÅŸmalarÄ±** ve **veri bilimi konularÄ±nda gÃ¶rÃ¼ÅŸ alÄ±ÅŸveriÅŸi** yapmak iÃ§in kurulmuÅŸtur.
BazÄ±larÄ± **bÃ¶lgesel veya ulusal dÃ¼zeyde** organize edilmiÅŸtir; Ã¶rneÄŸin:

* **Japon topluluÄŸu:** [Kaggler-ja](http://kaggler-ja-wiki.herokuapp.com/)
* **Rus topluluÄŸu:** [Open Data Science Network (ODS)](https://ods.ai/) â€” 2015 yÄ±lÄ±nda kurulmuÅŸ, daha sonra **RusÃ§a bilmeyen katÄ±lÄ±mcÄ±lara da aÃ§Ä±lmÄ±ÅŸtÄ±r.**

**ODS Network**, yalnÄ±zca bir Slack kanalÄ± deÄŸildir; aynÄ± zamanda:

* **YarÄ±ÅŸma kazanma stratejileri Ã¼zerine kurslar**,
* **Etkinlikler**,
* **TÃ¼m veri bilimi platformlarÄ±nda aktif yarÄ±ÅŸmalar hakkÄ±nda raporlar**
  da sunar.
  (Bkz. [https://ods.ai/competitions](https://ods.ai/competitions))

Slack dÄ±ÅŸÄ±nda, **Kaggle temalÄ± yerel buluÅŸmalar (meetup)** da giderek yaygÄ±nlaÅŸmaktadÄ±r.
BazÄ±larÄ± belirli yarÄ±ÅŸmalar etrafÄ±nda, bazÄ±larÄ± ise genel Kaggle topluluÄŸu odaÄŸÄ±nda dÃ¼zenlenir.
BazÄ±larÄ± **geÃ§ici**, bazÄ±larÄ± ise **dÃ¼zenli ve kalÄ±cÄ± etkinlikler** haline gelmiÅŸtir.

Bu buluÅŸmalar genellikle, **deneyimlerini paylaÅŸmak isteyen yarÄ±ÅŸmacÄ±larÄ±n sunumlarÄ±** etrafÄ±nda ÅŸekillenir.
KatÄ±lÄ±mcÄ±lar, bu tÃ¼r etkinliklerde **diÄŸer Kaggle kullanÄ±cÄ±larÄ±yla yÃ¼z yÃ¼ze tanÄ±ÅŸabilir**, **fikir alÄ±ÅŸveriÅŸinde bulunabilir** ve **ortak yarÄ±ÅŸma ekipleri kurabilir.**

Bu alanda Ã¶zellikle **Kaggle Days** ([https://kaggledays.com/](https://kaggledays.com/)) etkinliklerinden bahsetmek gerekir.
Bu etkinlikler, **Maria Parysz** ve **PaweÅ‚ Jankiewicz** tarafÄ±ndan organize edilmiÅŸtir.

**Kaggle Days**, dÃ¼nyanÄ±n dÃ¶rt bir yanÄ±nda dÃ¼zenlenen (bkz. [https://kaggledays.com/about-us/](https://kaggledays.com/about-us/)) konferanslar aracÄ±lÄ±ÄŸÄ±yla **Kaggle uzmanlarÄ±nÄ± bir araya getirmeyi** amaÃ§lar.
AyrÄ±ca, farklÄ± Ã¼lkelerde hÃ¢lÃ¢ aktif olan **yerel Kaggle meetup aÄŸlarÄ±** da oluÅŸturmuÅŸtur (bkz. [https://kaggledays.com/meetups/](https://kaggledays.com/meetups/)).

> PaweÅ‚ Jankiewicz ile RÃ¶portaj
> 
> 
> 
> **Profil:** [PaweÅ‚ Jankiewicz](https://www.kaggle.com/paweljankiewicz)
> 
> PaweÅ‚, **Kaggle Competitions Grandmaster** ve **LogicAIâ€™nin kurucu ortaklarÄ±ndan** biridir. Kaggle deneyimleri hakkÄ±nda kendisiyle konuÅŸma fÄ±rsatÄ± bulduk.
> 
> 
> 
> **Soru:** En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?
> 
> 
> 
> En sevdiÄŸim yarÄ±ÅŸma tÃ¼rÃ¼ **kod yarÄ±ÅŸmalarÄ±dÄ±r**. Ã‡Ã¼nkÃ¼ sÄ±nÄ±rlÄ± bir ortamda Ã§alÄ±ÅŸmak, farklÄ± tÃ¼rde bÃ¼tÃ§eleri dÃ¼ÅŸÃ¼nmeye zorlar: zaman, CPU, bellek. Ã–nceki yarÄ±ÅŸmalarda Ã§oÄŸu zaman **3-4 gÃ¼Ã§lÃ¼ sanal makine** kullanmam gerekiyordu. Bunu sevmiyordum; Ã§Ã¼nkÃ¼ kazanÃ§ iÃ§in bu kadar kaynak kullanmak, yarÄ±ÅŸmayÄ± adaletsiz hale getiriyor.
> 
> 
> 
> **Soru:** Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±?
> 
> 
> 
> Her yarÄ±ÅŸmaya biraz farklÄ± yaklaÅŸÄ±rÄ±m. Her yarÄ±ÅŸma iÃ§in **mÃ¼mkÃ¼n olduÄŸunca Ã§ok deney oluÅŸturmayÄ± saÄŸlayan bir Ã§erÃ§eve (framework) kurarÄ±m.**
> 
> 
> 
> Ã–rneÄŸin, bir yarÄ±ÅŸmada **derin Ã¶ÄŸrenme konvolÃ¼syonel sinir aÄŸÄ± (CNN)** kurmamÄ±z gerekiyordu. Ben, aÄŸlarÄ± **C4-MP4-C3-MP3** formatÄ±nda yapÄ±landÄ±rmayÄ± saÄŸlayan bir yÃ¶ntem geliÅŸtirdim (her harf farklÄ± bir katmanÄ± temsil ediyordu).
> 
> Bu olay yÄ±llar Ã¶nce oldu; artÄ±k muhtemelen sinir aÄŸlarÄ± yapÄ±landÄ±rmasÄ±, **backbone model seÃ§imiyle** yapÄ±lÄ±yor. Ama kural hÃ¢lÃ¢ geÃ§erli: **Pipelineâ€™daki en hassas bÃ¶lÃ¼mleri hÄ±zlÄ±ca deÄŸiÅŸtirebileceÄŸiniz bir Ã§erÃ§eve oluÅŸturmalÄ±sÄ±nÄ±z.**
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ, modelleme yaklaÅŸÄ±mÄ± ve doÄŸru validasyon aÃ§Ä±sÄ±ndan Kaggle yarÄ±ÅŸmalarÄ±yla benzerlik gÃ¶sterir.
> 
> Kaggle yarÄ±ÅŸmalarÄ±ndan Ã¶ÄŸrendiÄŸim en Ã¶nemli ÅŸey: **validasyonun Ã¶nemi ve veri sÄ±zÄ±ntÄ±sÄ±nÄ± (data leakage) Ã¶nlemenin gerekliliÄŸi.**
> 
> Ã–rneÄŸin, veri sÄ±zÄ±ntÄ±larÄ± Ã§ok sayÄ±da yarÄ±ÅŸmada gÃ¶rÃ¼lÃ¼yor; ve bunlarÄ± hazÄ±rlayan kiÅŸiler alanÄ±n en iyileri. Bu durum, Ã¼retimde kullanÄ±lan modellerin **%80â€™den fazlasÄ±nÄ±n doÄŸru ÅŸekilde validasyon edilmediÄŸini** dÃ¼ÅŸÃ¼ndÃ¼rÃ¼yor (kiÅŸisel gÃ¶rÃ¼ÅŸ).
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ ile farklÄ±lÄ±k: kimse size **modelleme problemini nasÄ±l tanÄ±mlayacaÄŸÄ±nÄ±zÄ±** sÃ¶ylemez.
> 
> Ã–rneÄŸin:
> 
> 
> 
> 1. RaporlayacaÄŸÄ±nÄ±z veya optimize edeceÄŸiniz metrik **RMSE, RMSLE, SMAPE, MAPE** hangisi olmalÄ±?
> 
> 2. Problem zaman bazlÄ±ysa, modeli en gerÃ§ekÃ§i ÅŸekilde deÄŸerlendirmek iÃ§in veriyi nasÄ±l bÃ¶lmelisiniz?
> 
> 
> 
> Bunlar sadece iÅŸ aÃ§Ä±sÄ±ndan Ã¶nemli olan noktalar deÄŸil; ayrÄ±ca **seÃ§imlerinizi aÃ§Ä±klayabilme ve neden yaptÄ±ÄŸÄ±nÄ±zÄ± anlatabilme** becerisine de sahip olmalÄ±sÄ±nÄ±z.
> 
> 
> 
> **Soru:** KatÄ±ldÄ±ÄŸÄ±nÄ±z en zorlu yarÄ±ÅŸma hangisiydi ve problemi Ã§Ã¶zmek iÃ§in hangi yaklaÅŸÄ±mlarÄ± kullandÄ±nÄ±z?
> 
> 
> 
> **PaweÅ‚â€™Ä±n CevabÄ±:**
> 
> En zorlu ve ilginÃ§ yarÄ±ÅŸma, **Mercari Price Prediction Code** yarÄ±ÅŸmasÄ±ydÄ±.
> 
> DiÄŸer yarÄ±ÅŸmalardan farklÄ±ydÄ± Ã§Ã¼nkÃ¼ **sadece 1 saat hesaplama sÃ¼resi ve 4 Ã§ekirdek ile 16 GB bellek** ile sÄ±nÄ±rlÄ±ydÄ±. Bu kÄ±sÄ±tlarÄ± aÅŸmak, yarÄ±ÅŸmanÄ±n en heyecan verici kÄ±smÄ±ydÄ±.
> 
> 
> 
> Bu yarÄ±ÅŸmadan Ã¶ÄŸrendiÄŸim: **tabular veri iÃ§in aÄŸlara daha fazla gÃ¼venmek** gerekir.
> 
> TakÄ±m arkadaÅŸÄ±m **Konstantin Lopukhin** ile birleÅŸmeden Ã¶nce, karmaÅŸÄ±k modellerim vardÄ± (neural networkâ€™ler ve bazÄ± boosting algoritmalarÄ±).
> 
> BirleÅŸtiÄŸimizde, Konstantin sadece **Ã§ok optimize edilmiÅŸ tek bir mimari** kullanÄ±yordu (epoch sayÄ±sÄ±, Ã¶ÄŸrenme hÄ±zÄ± vb.).
> 
> 
> 
> Bu yarÄ±ÅŸmada ayrÄ±ca, **sadece Ã§Ã¶zÃ¼mleri ortalamak yeterli deÄŸildi.**
> 
> Workflowâ€™u yeniden organize edip, **tek bir uyumlu Ã§Ã¶zÃ¼m** Ã¼retmemiz gerekiyordu. Ã‡Ã¶zÃ¼mlerimizi birleÅŸtirmemiz **3 hafta** sÃ¼rdÃ¼.
> 
> 
> 
> **Soru:** TecrÃ¼besiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r?
> 
> 
> 
> **YazÄ±lÄ±m mÃ¼hendisliÄŸi becerileri (software engineering skills)** genellikle fazla Ã¶nemsenmez.
> 
> Her yarÄ±ÅŸma ve problem biraz farklÄ±dÄ±r ve Ã§Ã¶zÃ¼mÃ¼ **dÃ¼zene sokacak bir framework** gerektirir.
> 
> Ã–rnek: [https://github.com/bestfitting/instance_level_recognition](https://github.com/bestfitting/instance_level_recognition)
> 
> Ä°yi kod organizasyonu, **daha hÄ±zlÄ± iterasyon ve daha fazla deneme** yapmanÄ±za olanak saÄŸlar.
> 
> 
> 
> **PaweÅ‚â€™Ä±n Tavsiyesi:**
> 
> En Ã¶nemli ÅŸey **yarÄ±ÅŸmadan keyif almak.**

#### Performance tiers and rankings *(Performans seviyeleri ve sÄ±ralamalar)*

Parasal Ã¶dÃ¼ller ve kupa, tiÅŸÃ¶rt, hoodie veya sticker gibi maddi Ã¶dÃ¼llerin yanÄ± sÄ±ra, Kaggle birÃ§ok **maddi olmayan Ã¶dÃ¼l** de sunar.

Kagglers yarÄ±ÅŸmalar sÄ±rasÄ±nda Ã§ok **zaman ve Ã§aba harcar** (yarÄ±ÅŸmada kullandÄ±klarÄ± beceriler, genel nÃ¼fus arasÄ±nda oldukÃ§a nadirdir). Parasal Ã¶dÃ¼ller genellikle sadece en iyi birkaÃ§ Kaggle katÄ±lÄ±mcÄ±sÄ±nÄ±n Ã§abasÄ±nÄ± karÅŸÄ±lar, Ã§oÄŸu zaman sadece **birinciyi**. DiÄŸer katÄ±lÄ±mcÄ±lar ise saatlerce gÃ¶nÃ¼llÃ¼ Ã§alÄ±ÅŸÄ±r ama karÅŸÄ±lÄ±ÄŸÄ±nda Ã§ok az ÅŸey alÄ±r. Uzun vadede, somut bir Ã¶dÃ¼l olmadan yarÄ±ÅŸmalara katÄ±lmak, **ilgi kaybÄ±na ve motivasyon dÃ¼ÅŸÃ¼ÅŸÃ¼ne** yol aÃ§abilir.

Bu nedenle Kaggle, yarÄ±ÅŸmacÄ±larÄ± **madalya ve puan temelli bir onur sistemiyle** Ã¶dÃ¼llendirmeyi bulmuÅŸtur. AmaÃ§: ne kadar Ã§ok madalya ve puan kazanÄ±rsanÄ±z, becerileriniz o kadar tanÄ±nÄ±r ve iÅŸ arayÄ±ÅŸÄ± veya diÄŸer ilgili aktivitelerde fÄ±rsatlar elde edebilirsiniz.

Kaggleâ€™de bir **genel lider tablosu** vardÄ±r. Bu tablo, tÃ¼m bireysel yarÄ±ÅŸmalarÄ±n lider tablolarÄ±nÄ± birleÅŸtirir: [https://www.kaggle.com/rankings](https://www.kaggle.com/rankings).

* Her yarÄ±ÅŸmadaki pozisyonunuza gÃ¶re puan kazanÄ±rsÄ±nÄ±z.
* Bu puanlar toplandÄ±ÄŸÄ±nda genel lider tablosundaki sÄ±ralamanÄ±zÄ± belirler.

Ä°lk bakÄ±ÅŸta puan hesaplama formÃ¼lÃ¼ karmaÅŸÄ±k gÃ¶rÃ¼nebilir:

[
\left[ \frac{100000}{\sqrt{N_{\text{total}}}} \right] * [RRR - 0.75] * [\log_{10}(1 + \log_{10}(N_{\text{total}}))] * [e^{-t/500}]
]

Ama aslÄ±nda puanlar **temel birkaÃ§ unsur** Ã¼zerine kuruludur:

* YarÄ±ÅŸmadaki sÄ±ralamanÄ±z
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼z
* YarÄ±ÅŸmanÄ±n popÃ¼lerliÄŸi
* YarÄ±ÅŸmanÄ±n yaÅŸÄ±

**Ä°puÃ§larÄ±:**

* PopÃ¼ler yarÄ±ÅŸmalarda yÃ¼ksek sÄ±ralama, daha Ã§ok puan kazandÄ±rÄ±r.
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ **doÄŸrusal olmayan bir ÅŸekilde** puanlarÄ± etkiler. FormÃ¼ldeki **ters kare kÃ¶k** nedeniyle, takÄ±m bÃ¼yÃ¼dÃ¼kÃ§e kaybedilen puan oranÄ± artar.
* TakÄ±mÄ±nÄ±z **kÃ¼Ã§Ã¼k (2-3 kiÅŸi)** ise iÅŸbirliÄŸi ve hesaplama avantajÄ± aÃ§Ä±sÄ±ndan daha iyidir.
* Puanlar **zamanla azalÄ±r**; lineer olmasa da, bir yÄ±l sonra kazandÄ±ÄŸÄ±nÄ±z puanlarÄ±n Ã§oÄŸu kaybolur.

Yine de, profilinizde **ulaÅŸtÄ±ÄŸÄ±nÄ±z en yÃ¼ksek sÄ±ralamayÄ±** her zaman saklarsÄ±nÄ±z.

Daha kalÄ±cÄ± olan, Kaggleâ€™daki dÃ¶rt alanÄ± kapsayan **madalya sistemidir**:

* **Competitions (YarÄ±ÅŸmalar)**
* **Notebooks (Not Defterleri)**
* **Discussion (Forum KatkÄ±larÄ±)**
* **Datasets (Veri Setleri)**

**Competitions:** Madalyalar, lider tablodaki sÄ±ralamanÄ±za gÃ¶re verilir.
**DiÄŸer Ã¼Ã§ alan:** Madalyalar, diÄŸer katÄ±lÄ±mcÄ±larÄ±n **upvoteâ€™larÄ±** ile verilir. (Upvoteâ€™lar popÃ¼lerliÄŸe baÄŸlÄ± ve daha az objektif olabilir.)

Daha fazla madalya kazandÄ±kÃ§a **Kaggle uzmanlÄ±k sÄ±ralamalarÄ±** yÃ¼kselir:

* **Novice (Acemi)**
* **Contributor (KatÄ±lÄ±mcÄ±)**
* **Expert (Uzman)**
* **Master (Usta)**
* **Grandmaster (BÃ¼yÃ¼k Usta)**

DetaylÄ± bilgi ve gerekli madalya sayÄ±larÄ± iÃ§in: [https://www.kaggle.com/progression](https://www.kaggle.com/progression)

> Not: Bu sÄ±ralamalar **her zaman gÃ¶recelidir** ve zamanla deÄŸiÅŸebilir. BirkaÃ§ yÄ±l Ã¶nce puanlama sistemi ve sÄ±ralamalar oldukÃ§a farklÄ±ydÄ±. Muhtemelen gelecekte de, Ã¼st sÄ±ralar **daha nadir ve deÄŸerli** olacak ÅŸekilde deÄŸiÅŸtirilecektir.

#### Criticism and opportunities *(EleÅŸtiriler ve fÄ±rsatlar)*

Kaggle, baÅŸladÄ±ÄŸÄ± gÃ¼nden bu yana pek Ã§ok eleÅŸtiri aldÄ±. Veri bilimi yarÄ±ÅŸmalarÄ±na katÄ±lmak hÃ¢lÃ¢ tartÄ±ÅŸmalÄ± bir konu olup, bu konuda hem olumlu hem de olumsuz pek Ã§ok farklÄ± gÃ¶rÃ¼ÅŸ bulunmaktadÄ±r.

**Olumsuz eleÅŸtiriler aÃ§Ä±sÄ±ndan:**

* Kaggle, makine Ã¶ÄŸreniminin gerÃ§ekte ne olduÄŸuna dair yanlÄ±ÅŸ bir algÄ± yaratÄ±yor Ã§Ã¼nkÃ¼ sadece liderlik tablosu dinamiklerine odaklanÄ±yor.
* Kaggle, aslÄ±nda sadece biraz daha yÃ¼ksek doÄŸruluk elde etmek iÃ§in birÃ§ok modeli bir araya getirip hiperparametre optimizasyonu yapmak Ã¼zerine kurulu bir oyun gibi (gerÃ§ekte test setine fazla uyum saÄŸlama/overfitting yapÄ±yor).
* Kaggle, puan ve dikkat Ã§ekme umuduyla her ÅŸeyi denemeye hazÄ±r deneyimsiz meraklÄ±larla dolu.
* SonuÃ§ olarak, yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri Ã§ok karmaÅŸÄ±k ve genellikle yalnÄ±zca test setine Ã¶zgÃ¼ olup uygulanmasÄ± zor.

BirÃ§ok kiÅŸi Kaggle ve diÄŸer veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ± gerÃ§ek veri bilimine oldukÃ§a uzak olarak gÃ¶rÃ¼yor. EleÅŸtirmenlerin vurguladÄ±ÄŸÄ± nokta ÅŸudur: Ä°ÅŸ problemleri boÅŸluktan ortaya Ã§Ä±kmaz ve nadiren Ã¶nceden iyi hazÄ±rlanmÄ±ÅŸ bir veri setine sahip olursunuz; Ã§Ã¼nkÃ¼ genellikle bunu, iÅŸ gereksinimlerini ve problem anlayÄ±ÅŸÄ±nÄ± geliÅŸtirerek oluÅŸturursunuz. AyrÄ±ca, birÃ§ok eleÅŸtirmen, kazanan Ã§Ã¶zÃ¼mlerin kaynak sÄ±nÄ±rlamalarÄ± veya teknik borÃ§ gibi kÄ±sÄ±tlamalarla sÄ±nÄ±rlandÄ±rÄ±lamayacaÄŸÄ± iÃ§in Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n Ã¼retim odaklÄ± modeller yaratmada yeterince Ã¶ÄŸrenmediÄŸini vurguluyor (her yarÄ±ÅŸma iÃ§in bu doÄŸru olmasa da).

TÃ¼m bu eleÅŸtiriler, nihayetinde Kaggle sÄ±ralamalarÄ±nÄ±n iÅŸveren gÃ¶zÃ¼nde diÄŸer deneyim tÃ¼rleriyle karÅŸÄ±laÅŸtÄ±rÄ±labilirliÄŸi ile ilgilidir; Ã¶zellikle veri bilimi eÄŸitimi ve iÅŸ deneyimi ile kÄ±yaslandÄ±ÄŸÄ±nda. SÃ¼regelen bir mit, Kaggle yarÄ±ÅŸmalarÄ±nÄ±n size iÅŸ bulmada veya daha iyi bir iÅŸ elde etmede yardÄ±mcÄ± olmayacaÄŸÄ± ve Kaggleâ€™a katÄ±lmayan veri bilimcilerden sizi farklÄ± bir seviyeye taÅŸÄ±yamayacaÄŸÄ±dÄ±r.

Bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼z, Kaggle sÄ±ralamalarÄ±nÄ±n Kaggle topluluÄŸunun Ã¶tesinde otomatik bir deÄŸeri olmadÄ±ÄŸÄ±na dair bu inanÄ±ÅŸÄ±n yanÄ±ltÄ±cÄ± olduÄŸudur. Ã–rneÄŸin, iÅŸ ararken Kaggle size veri ve problem modelleme ile etkili model test etme konusunda Ã§ok faydalÄ± beceriler kazandÄ±rabilir. AyrÄ±ca, sizi mevcut deneyim ve konfor alanÄ±nÄ±zÄ±n Ã¶tesinde birÃ§ok teknik ve farklÄ± veri/iÅŸ problemleriyle tanÄ±ÅŸtÄ±rabilir; ancak bir ÅŸirkette veri bilimci olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken her ÅŸeyi tek baÅŸÄ±na saÄŸlayamaz.

Kaggleâ€™Ä± Ã¶ÄŸrenmek iÃ§in (web sitesinde yalnÄ±zca Ã¶ÄŸrenmeye ayrÄ±lmÄ±ÅŸ â€œCoursesâ€ bÃ¶lÃ¼mÃ¼ de vardÄ±r) ve iÅŸ arayÄ±ÅŸÄ±nda kendinizi diÄŸer adaylardan farklÄ± kÄ±lmak iÃ§in kullanabilirsiniz; fakat bunun nasÄ±l deÄŸerlendirileceÄŸi ÅŸirketten ÅŸirkete oldukÃ§a deÄŸiÅŸir. Yine de, Kaggleâ€™da Ã¶ÄŸrendikleriniz kariyeriniz boyunca kesinlikle faydalÄ± olacaktÄ±r ve veri modelleme ile karmaÅŸÄ±k ve alÄ±ÅŸÄ±lmadÄ±k problemleri Ã§Ã¶zmeniz gerektiÄŸinde size bir avantaj saÄŸlayacaktÄ±r. Kaggle yarÄ±ÅŸmalarÄ±na katÄ±larak modelleme ve doÄŸrulama konusunda gÃ¼Ã§lÃ¼ yetkinlikler kazanÄ±rsÄ±nÄ±z. AyrÄ±ca, diÄŸer veri bilimcilerle aÄŸ kurabilir, bu sayede bir iÅŸ referansÄ± elde etmeniz kolaylaÅŸÄ±r ve kendi becerilerinizin Ã¶tesinde zor problemleri Ã§Ã¶zmek iÃ§in baÅŸkalarÄ±nÄ±n yetkinliklerinden ve gÃ¶rÃ¼ÅŸlerinden faydalanabilirsiniz.

Bu nedenle, bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼ze gÃ¶re Kaggle, veri bilimci olarak kariyerinize dolaylÄ± yollardan pek Ã§ok ÅŸekilde katkÄ± saÄŸlar. Elbette, bazen Kaggle, baÅŸarÄ±larÄ±nÄ±z Ã¼zerinden doÄŸrudan bir iÅŸ teklifi almanÄ±za yardÄ±mcÄ± olabilir; fakat Ã§oÄŸu zaman Kaggle, Ã¶nce bir aday olarak, sonra bir uygulayÄ±cÄ± olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken entelektÃ¼el beceri ve deneyimi saÄŸlar.

AslÄ±nda, Kaggleâ€™da bir sÃ¼re veri ve modellerle uÄŸraÅŸtÄ±ktan sonra, farklÄ± veri setleri, problemler ve bunlarla baÅŸa Ã§Ä±kma yÃ¶ntemlerini zaman baskÄ±sÄ± altÄ±nda gÃ¶rmÃ¼ÅŸ olursunuz; bu da benzer problemlerle gerÃ§ek ortamda karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda hÄ±zlÄ± ve etkili Ã§Ã¶zÃ¼mler bulma konusunda sizi yetkin kÄ±lar.

Ä°ÅŸte bu beceri geliÅŸimi fÄ±rsatÄ±, bizi bu kitabÄ± yazmaya motive eden ve kitabÄ±n temel amacÄ±nÄ± oluÅŸturan ÅŸeydir. Burada yalnÄ±zca Kaggle yarÄ±ÅŸmalarÄ±nÄ± kazanma veya yÃ¼ksek puan alma rehberi bulamayacaksÄ±nÄ±z; fakat yarÄ±ÅŸmalarda daha iyi nasÄ±l rekabet edeceÄŸinizi ve yarÄ±ÅŸma deneyimlerinden en iyi ÅŸekilde nasÄ±l faydalanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz.

Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± akÄ±llÄ±ca kullanÄ±n. Kaggle bir sihirli anahtar deÄŸildir â€“ bir yarÄ±ÅŸmada birinci olmak, yÃ¼ksek maaÅŸ veya Kaggle topluluÄŸu dÄ±ÅŸÄ±nda ÅŸan getirmez. Ancak, yarÄ±ÅŸmalara dÃ¼zenli olarak katÄ±lmak, veri bilimi iÅŸ arayÄ±ÅŸÄ±nÄ±zda ilgi ve tutkuyu gÃ¶stermek ve bazÄ± Ã¶zel becerileri geliÅŸtirerek sizi diÄŸer veri bilimcilerden farklÄ± kÄ±lmak iÃ§in stratejik bir karttÄ±r; ayrÄ±ca sizi AutoML Ã§Ã¶zÃ¼mlerine karÅŸÄ± modasÄ± geÃ§miÅŸ hÃ¢le getirmez.

EÄŸer kitabÄ±n ilerleyen bÃ¶lÃ¼mlerini takip ederseniz, bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± gÃ¶stereceÄŸiz.

### Summary *(Ã–zet)*

Bu baÅŸlangÄ±Ã§ bÃ¶lÃ¼mÃ¼nde, Ã¶ncelikle veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n nasÄ±l ortaya Ã§Ä±ktÄ±ÄŸÄ±nÄ± ve hem yarÄ±ÅŸmacÄ±lar hem de bu platformlarÄ± iÅŸleten kurumlar aÃ§Ä±sÄ±ndan nasÄ±l iÅŸlediÄŸini tartÄ±ÅŸtÄ±k; Ã¶zellikle ProfesÃ¶r David Donoho tarafÄ±ndan ele alÄ±nan ikna edici CTF (Capture The Flag) paradigmasÄ±na atÄ±fta bulunduk.

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶rneklerle gÃ¶sterdik, aynÄ± zamanda diÄŸer kayda deÄŸer yarÄ±ÅŸma platformlarÄ±ndan da bahsederek, Kaggle dÄ±ÅŸÄ±ndaki meydan okumalarÄ± da denemenin size nasÄ±l fayda saÄŸlayabileceÄŸini anlattÄ±k. Kaggle ile ilgili olarak, bir yarÄ±ÅŸmanÄ±n farklÄ± aÅŸamalarÄ±nÄ±n nasÄ±l iÅŸlediÄŸini, yarÄ±ÅŸmalarÄ±n birbirinden nasÄ±l farklÄ±laÅŸtÄ±ÄŸÄ±nÄ± ve Kaggle platformunun size sunabileceÄŸi kaynaklarÄ± detaylÄ± ÅŸekilde ele aldÄ±k.

Bir sonraki birkaÃ§ bÃ¶lÃ¼mde, Kaggleâ€™Ä± daha ayrÄ±ntÄ±lÄ± olarak incelemeye baÅŸlayacaÄŸÄ±z; bunun ilk adÄ±mÄ± olarak veri setleri (Datasets) ile nasÄ±l Ã§alÄ±ÅŸÄ±lacaÄŸÄ±nÄ± ele alacaÄŸÄ±z.

---

## Chapter 2: Organizing Data with Datasets *(BÃ¶lÃ¼m 2: Veri Setleriyle Veriyi DÃ¼zenleme)*

Arthur Conan Doyleâ€™un *The Adventure of the Copper Beeches* (BakÄ±r KayÄ±n AÄŸaÃ§larÄ±nÄ±n MacerasÄ±) adlÄ± hikÃ¢yesinde Sherlock Holmes, â€œVeri! Veri! Veri! Kil olmadan tuÄŸla yapamam.â€ diye baÄŸÄ±rÄ±r. EdebiyatÄ±n en Ã¼nlÃ¼ dedektifine bu kadar iyi hizmet eden bu bakÄ±ÅŸ aÃ§Ä±sÄ±, her veri bilimcinin benimsemesi gereken bir yaklaÅŸÄ±m olmalÄ±dÄ±r. Bu nedenle, kitabÄ±n daha teknik bÃ¶lÃ¼mÃ¼ne veri odaklÄ± bir bÃ¶lÃ¼mle baÅŸlÄ±yoruz: Ã¶zellikle Kaggle baÄŸlamÄ±nda, amaÃ§larÄ±mÄ±z doÄŸrultusunda Kaggle Datasets (Veri Setleri) fonksiyonunun gÃ¼cÃ¼nden yararlanmayÄ± ele alacaÄŸÄ±z.

Bu bÃ¶lÃ¼mde ÅŸu konularÄ± ele alacaÄŸÄ±z:

* Bir veri seti oluÅŸturma
* Veriyi toplama
* Veri setleriyle Ã§alÄ±ÅŸma
* Kaggle Datasetsâ€™i Google Colabâ€™de kullanma
* Hukuki uyarÄ±lar

### Setting up a dataset *(Bir veri seti oluÅŸturma)*

Ä°lke olarak, kullanabileceÄŸiniz herhangi bir veriyi Kaggleâ€™a yÃ¼kleyebilirsiniz (sÄ±nÄ±rlamalara tabi; daha sonra â€œHukuki UyarÄ±larâ€ bÃ¶lÃ¼mÃ¼ne bakÄ±nÄ±z). YazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihteki Ã¶zel sÄ±nÄ±rlamalar, her Ã¶zel veri seti iÃ§in 100 GB ve toplam kota olarak 100 GBâ€™dÄ±r. Tek bir veri seti iÃ§in boyut sÄ±nÄ±rÄ±nÄ±n sÄ±kÄ±ÅŸtÄ±rÄ±lmamÄ±ÅŸ hÃ¢liyle hesaplandÄ±ÄŸÄ±nÄ± unutmayÄ±n; sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ versiyonlarÄ± yÃ¼klemek aktarÄ±mÄ± hÄ±zlandÄ±rÄ±r ancak sÄ±nÄ±rlamalara karÅŸÄ± bir avantaj saÄŸlamaz. Veri setleri ile ilgili en gÃ¼ncel dokÃ¼mantasyonu bu baÄŸlantÄ±dan kontrol edebilirsiniz: [Kaggle Datasets Documentation](https://www.kaggle.com/docs/datasets).

Kaggle kendini â€œveri biliminin eviâ€ olarak tanÄ±tÄ±r ve sitede bulunan etkileyici veri seti koleksiyonu bu iddiaya bÃ¼yÃ¼k Ã¶lÃ§Ã¼de gÃ¼venilirlik kazandÄ±rÄ±r. Sadece petrol fiyatlarÄ±ndan anime Ã¶nerilerine kadar Ã§eÅŸitli konularda veri bulmakla kalmazsÄ±nÄ±z; verilerin ne kadar hÄ±zlÄ± bir ÅŸekilde siteye ulaÅŸtÄ±ÄŸÄ± da etkileyicidir. Ã–rneÄŸin, Anthony Fauciâ€™nin e-postalarÄ± 2021 MayÄ±s ayÄ±nda Bilgi Edinme HakkÄ± YasasÄ± kapsamÄ±nda yayÄ±mlandÄ±ÄŸÄ±nda ([link](https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/)), yalnÄ±zca 48 saat iÃ§inde bir Kaggle veri seti olarak yÃ¼klenmiÅŸti.

![](im/1005.png)

Projeniz iÃ§in verileri bir veri setine yÃ¼klemeden Ã¶nce, mevcut iÃ§erikleri kontrol ettiÄŸinizden emin olun.
BazÄ± popÃ¼ler uygulamalar iÃ§in (gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, NLP, finansal zaman serileri) verilerin zaten orada depolanmÄ±ÅŸ olma ihtimali vardÄ±r.

Bu giriÅŸ iÃ§in, projenizde kullanacaÄŸÄ±nÄ±z veri tÃ¼rÃ¼nÃ¼n henÃ¼z orada bulunmadÄ±ÄŸÄ±nÄ± varsayalÄ±m; bu durumda yeni bir veri seti oluÅŸturmanÄ±z gerekir. Sol taraftaki Ã¼Ã§ Ã§izgili menÃ¼ye gidip â€œDataâ€ (Veri) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, Datasets (Veri Setleri) sayfasÄ±na yÃ¶nlendirileceksiniz:

![](im/1006.png)

â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, sizden temel bilgileri girmeniz istenecektir: veriyi yÃ¼klemek ve bir baÅŸlÄ±k vermek.

![](im/1007.png)

Sol taraftaki simgeler, veri setiniz iÃ§in kullanabileceÄŸiniz farklÄ± kaynaklara karÅŸÄ±lÄ±k gelir. BunlarÄ± sayfada gÃ¶sterildikleri sÄ±rayla aÃ§Ä±klÄ±yoruz:

* Yerel bir sÃ¼rÃ¼cÃ¼den dosya yÃ¼kleme (ÅŸekilde gÃ¶sterilmiÅŸtir)
* Uzak bir URLâ€™den oluÅŸturma
* Bir GitHub deposunu iÃ§e aktarma
* Mevcut bir Notebookâ€™tan Ã§Ä±ktÄ± dosyalarÄ±nÄ± kullanma
* Google Cloud Storage dosyasÄ±nÄ± iÃ§e aktarma

GitHub seÃ§eneÄŸi ile ilgili Ã¶nemli bir nokta: Bu Ã¶zellik, Ã¶zellikle deneysel kÃ¼tÃ¼phaneler sÃ¶z konusu olduÄŸunda oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r. HenÃ¼z mevcut olmayan iÅŸlevsellikler sunmalarÄ±na sÄ±kÃ§a raÄŸmen, bu kÃ¼tÃ¼phaneler genellikle Kaggle ortamÄ±na dahil edilmez; bu nedenle, kodunuzda bÃ¶yle bir kÃ¼tÃ¼phaneyi kullanmak istiyorsanÄ±z, aÅŸaÄŸÄ±da gÃ¶sterildiÄŸi gibi veri seti olarak iÃ§e aktarabilirsiniz:

1. Datasets (Veri Setleri) sayfasÄ±na gidin ve â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±klayÄ±n.
2. GitHub simgesini seÃ§in.
3. Depo baÄŸlantÄ±sÄ±nÄ± ve veri seti iÃ§in baÅŸlÄ±ÄŸÄ± girin.
4. SaÄŸ alt kÃ¶ÅŸedeki â€œCreateâ€ (OluÅŸtur) butonuna tÄ±klayÄ±n.

![](im/1008.png)

â€œCreateâ€ (OluÅŸtur) butonunun yanÄ±nda bir de â€œPrivateâ€ (Ã–zel) olarak iÅŸaretlenmiÅŸ baÅŸka bir buton vardÄ±r. VarsayÄ±lan olarak oluÅŸturduÄŸunuz herhangi bir veri seti Ã¶zeldir: yalnÄ±zca siz, yani veri setinin yaratÄ±cÄ±sÄ±, onu gÃ¶rÃ¼ntÃ¼leyip dÃ¼zenleyebilirsiniz. Veri seti oluÅŸturma aÅŸamasÄ±nda bu ayarÄ± varsayÄ±lan hÃ¢lde bÄ±rakmak ve yalnÄ±zca daha sonraki bir aÅŸamada veri setini halka aÃ§mak (ya belirli bir katkÄ±da bulunanlar listesi iÃ§in ya da herkes iÃ§in) muhtemelen iyi bir fikirdir.

Kaggleâ€™Ä±n popÃ¼ler bir platform olduÄŸunu ve birÃ§ok kiÅŸinin veri setlerini â€“ Ã¶zel olanlar da dahil â€“ yÃ¼klediÄŸini unutmayÄ±n; bu nedenle, veri setiniz iÃ§in genel olmayan bir baÅŸlÄ±k dÃ¼ÅŸÃ¼nmeye Ã§alÄ±ÅŸÄ±n. Bu, veri setinizin gerÃ§ekten fark edilme ÅŸansÄ±nÄ± artÄ±racaktÄ±r.

TÃ¼m adÄ±mlarÄ± tamamlayÄ±p â€œCreateâ€ (OluÅŸtur) butonuna tÄ±kladÄ±ÄŸÄ±nÄ±zda, voilÃ ! Ä°lk veri setiniz hazÄ±r. ArdÄ±ndan â€œDataâ€ sekmesine gidebilirsiniz:

![](im/1009.png)

YukarÄ±daki ekran gÃ¶rÃ¼ntÃ¼sÃ¼, veri setinizle ilgili saÄŸlayabileceÄŸiniz farklÄ± bilgileri gÃ¶stermektedir; saÄŸladÄ±ÄŸÄ±nÄ±z bilgi ne kadar Ã§ok olursa, kullanÄ±labilirlik indeksi o kadar yÃ¼ksek olur. Bu indeks, veri setinizin ne kadar iyi tanÄ±mlandÄ±ÄŸÄ±nÄ± Ã¶zetleyen sentetik bir Ã¶lÃ§Ã¼dÃ¼r. YÃ¼ksek kullanÄ±labilirlik indeksine sahip veri setleri, arama sonuÃ§larÄ±nda daha Ã¼st sÄ±ralarda gÃ¶rÃ¼nÃ¼r. Her veri seti iÃ§in kullanÄ±labilirlik indeksi, dokÃ¼mantasyon seviyesi, Notebooks gibi ilgili kamuya aÃ§Ä±k iÃ§eriklerin referans olarak bulunabilirliÄŸi, dosya tÃ¼rleri ve temel meta verilerin kapsanmasÄ± gibi Ã§eÅŸitli faktÃ¶rlere dayanÄ±r.

Ä°lke olarak, yukarÄ±daki gÃ¶rselde gÃ¶sterilen tÃ¼m alanlarÄ± doldurmak zorunda deÄŸilsiniz; yeni oluÅŸturduÄŸunuz veri seti bunlar olmadan da tamamen kullanÄ±labilir (ve eÄŸer Ã¶zel bir veri seti ise, muhtemelen Ã¶nemsemezsiniz; sonuÃ§ta iÃ§eriÄŸini siz biliyorsunuz). Ancak, topluluk gÃ¶rgÃ¼ kurallarÄ±, veri setlerinizi halka aÃ§tÄ±ÄŸÄ±nÄ±zda bilgileri doldurmanÄ±zÄ± Ã¶nerir: ne kadar Ã§ok bilgi belirtirseniz, veri baÅŸkalarÄ± iÃ§in o kadar kullanÄ±ÅŸlÄ± olur.

### Gathering the data *(Veri toplama)*

Hukuki boyutlar dÄ±ÅŸÄ±nda, veri setlerinde saklayabileceÄŸiniz iÃ§erik tÃ¼rÃ¼ konusunda gerÃ§ek bir sÄ±nÄ±r yoktur: tablo verileri, gÃ¶rseller, metin; eÄŸer boyut gereksinimlerine uyuyorsa, bunlarÄ± saklayabilirsiniz. Bu, diÄŸer kaynaklardan elde edilen verileri de kapsar; yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihte popÃ¼ler veri setleri arasÄ±nda hashtag veya konuya gÃ¶re toplanmÄ±ÅŸ tweetler yer almaktadÄ±r:

![](im/1010.png)

Sosyal medyadan (Twitter, Reddit ve benzeri) veri toplamak iÃ§in kullanÄ±lan farklÄ± Ã§erÃ§evelerin tartÄ±ÅŸÄ±lmasÄ±, bu kitabÄ±n kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r.

> **Andrew MaranhÃ£o**
> 
> [https://www.kaggle.com/andrewmvd](https://www.kaggle.com/andrewmvd)
> 
> 
> 
> Andrew MaranhÃ£o (diÄŸer adÄ±yla Larxel), Datasets Grandmaster (yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± sÄ±rada Datasetsâ€™te bir numara) ve SÃ£o Pauloâ€™daki Hospital Albert Einsteinâ€™da KÄ±demli Veri Bilimci, bize Datasets baÅŸarÄ±sÄ±na nasÄ±l ulaÅŸtÄ±ÄŸÄ±nÄ±, veri seti oluÅŸturma ipuÃ§larÄ±nÄ± ve Kaggleâ€™daki genel deneyimlerini anlattÄ±.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Genellikle en sevdiÄŸim alan tÄ±bbi gÃ¶rÃ¼ntÃ¼lemedir. Hem iÅŸimle hem de amacÄ±mla Ã¶rtÃ¼ÅŸÃ¼yor. TÄ±bbi yarÄ±ÅŸmalarda NLP dil ile sÄ±nÄ±rlÄ±dÄ±r, tablo verileri hastaneler arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±k gÃ¶sterir, fakat gÃ¶rÃ¼ntÃ¼leme Ã§oÄŸunlukla aynÄ±dÄ±r; bu nedenle bu baÄŸlamda yapÄ±lan herhangi bir geliÅŸme, dÃ¼nya genelinde birÃ§ok Ã¼lke iÃ§in fayda saÄŸlayabilir ve bu etki potansiyelini seviyorum. AyrÄ±ca NLP ve tablo verilerini de severim, ama sanÄ±rÄ±m bu oldukÃ§a standart bir tercih.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸmayÄ± ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemleri anlatÄ±r mÄ±sÄ±nÄ±z?**
> 
> Bir tÃ¼berkÃ¼loz tespit yarÄ±ÅŸmasÄ±nda, yaklaÅŸÄ±k 1.000 rÃ¶ntgen gÃ¶rÃ¼ntÃ¼sÃ¼ vardÄ±; bu sayÄ±, hastalÄ±ÄŸÄ±n tÃ¼m belirtilerini yakalamak iÃ§in oldukÃ§a kÃ¼Ã§Ã¼ktÃ¼. Bunu telafi etmek iÃ§in iki fikir geliÅŸtirdim:
> 
> 
> 
> 1. DÄ±ÅŸ veri ile pnÃ¶moni tespiti iÃ§in Ã¶n eÄŸitim (~20k gÃ¶rÃ¼ntÃ¼), Ã§Ã¼nkÃ¼ pnÃ¶moni tÃ¼berkÃ¼loz ile karÄ±ÅŸtÄ±rÄ±labilir.
> 
> 2. AkciÄŸer anomalilerinin Ã§ok etiketli sÄ±nÄ±flandÄ±rmasÄ± (~600k gÃ¶rÃ¼ntÃ¼) Ã¼zerinde Ã¶n eÄŸitim ve basit bir SSD ile sÄ±nÄ±flandÄ±rma etiketlerinin bounding box anotasyonlarÄ±nÄ± oluÅŸturmak iÃ§in grad-CAM kullanÄ±mÄ±.
> 
> 
> 
> SonuÃ§ta, bu iki yaklaÅŸÄ±mÄ±n basit bir karÄ±ÅŸÄ±mÄ±, ikinci sÄ±radaki takÄ±mÄ±n sonucuna gÃ¶re %22 daha iyi bir performans saÄŸladÄ±. Bu yarÄ±ÅŸma, yaklaÅŸÄ±k 100 takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ± bir tÄ±bbi kongrede gerÃ§ekleÅŸti.
> 
> 
> 
> **Dataset Grandmaster oldunuz ve Datasetsâ€™te 1 numara oldunuz. Veri setleri iÃ§in konu seÃ§imi, veri bulma, toplama ve yayÄ±mlama sÃ¼reciniz nasÄ±l iÅŸliyor?**
> 
> Bu bÃ¼yÃ¼k bir soru; parÃ§alar hÃ¢linde aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m:
> 
> 
> 
> 1. **Kendinize bir amaÃ§ belirleyin**
> 
>    Konu seÃ§erken aklÄ±mda tuttuÄŸum ilk ÅŸey, bunu yapmamÄ±n temel nedenidir. Derin bir amaÃ§ olduÄŸunda, mÃ¼kemmel veri setleri bir sonuÃ§ olarak ortaya Ã§Ä±kar, hedef olarak deÄŸil.
> 
> 
> 
> 2. **Harika bir veri seti, harika bir sorunun vÃ¼cut bulmuÅŸ hÃ¢lidir**
> 
>    En iyi veri setlerinde ortak temalar:
> 
> 
> 
> * Cesur ve ilgili bir soru, bÃ¼yÃ¼k potansiyele sahip
> 
> * Veriler iyi toplanmÄ±ÅŸ, kalite kontrolÃ¼ yapÄ±lmÄ±ÅŸ ve iyi belgelenmiÅŸ
> 
> * Mevcut donanÄ±m iÃ§in yeterli veri ve Ã§eÅŸitlilik
> 
> * Veriye sÃ¼rekli katkÄ±da bulunan aktif bir topluluk
> 
> 
> 
> 3. **Sadece baÅŸarÄ±ya odaklanmayÄ±n; baÅŸarÄ± iÃ§in sÃ¼reci oluÅŸturun**
> 
>    Kalite, nicelikten Ã§ok daha Ã¶nemlidir. Grandmaster olmak iÃ§in sadece 15 veri setine ihtiyacÄ±nÄ±z vardÄ±r ve Ã¶ne Ã§Ä±kan veri setleri az ve iyi hazÄ±rlanmÄ±ÅŸ olmalÄ±dÄ±r. AyrÄ±ca veri setlerinin bakÄ±m ve sÃ¼rekli geliÅŸtirme gerektirdiÄŸini unutmayÄ±n. Topluluk desteÄŸi de Ã§ok Ã¶nemlidir; veri setinizi analiz edenlerin ihtiyaÃ§larÄ±nÄ± ve seÃ§imlerini anlamak, Ã¶n iÅŸleme adÄ±mlarÄ±nÄ±zÄ± ve belgelerinizi geliÅŸtirebilir.
> 
> 
> 
> **Ã–rnek sÃ¼reÃ§:**
> 
> Sosyal refahÄ± artÄ±rmak istiyorsunuz â†’ hedef: Ä±rksal eÅŸitlik â†’ konular: Black Lives Matter hareketi â†’ soru: Milyonlarca sesin ne dediÄŸini nasÄ±l anlayabilirim? â†’ veri tÃ¼rÃ¼: NLP â†’ veri toplama: haber makaleleri, YouTube yorumlarÄ±, tweetler â†’ Ã¶n iÅŸleme ve anonimleÅŸtirme â†’ yayÄ±nlama â†’ topluluk desteÄŸi ve geliÅŸtirme.
> 
> 
> 
> 4. **Ä°yi iÅŸ yapmak, kontrolÃ¼nÃ¼zde olan tek ÅŸeydir**
> 
>    Grandmaster olmanÄ±zÄ± baÅŸkalarÄ± saÄŸlar; oylar her zaman Ã§abaya veya etkiye dÃ¶nÃ¼ÅŸmez. Ã–nemli olan sizin Ã§abanÄ±z, Ã¶ÄŸrenmeniz ve denemenizdir.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz araÃ§lar/lisanslar nelerdir?**
> 
> LightGBM, CatBoost, Optuna, Streamlit, Gradio, FastAPI, Plotly, PyTorch gibi kÃ¼tÃ¼phaneleri Ã¶neriyor. AyrÄ±ca, kendi Ã§Ã¶zÃ¼mlerinizi uygulamak, derinlemesine bilgi edinmek aÃ§Ä±sÄ±ndan Ã§ok deÄŸerli.
> 
> 
> 
> **Deneyimsiz Kagglers neyi sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rÄ±r?**
> 
> 
> 
> * YarÄ±ÅŸmanÄ±n sonunda bilgiyi tam olarak absorbe etmek
> 
> * BitmiÅŸ yarÄ±ÅŸmalarda kazanan Ã§Ã¶zÃ¼mleri tekrar etmek
> 
> 
> 
> **Kaggle kariyerinize nasÄ±l katkÄ± saÄŸladÄ±?**
> 
> Kaggle bilgi, deneyim ve portfÃ¶y kazandÄ±rdÄ±. Ä°lk veri bilimi iÅŸim bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Kaggle ve DrivenData yarÄ±ÅŸmalarÄ± sayesinde oldu.
> 
> 
> 
> **PortfÃ¶yÃ¼nÃ¼zÃ¼ potansiyel iÅŸverenlere gÃ¶stermek iÃ§in Kaggle deneyimlerinizi kullandÄ±nÄ±z mÄ±?**
> 
> Kesinlikle. Ä°lk iÅŸimi Kaggle portfÃ¶yÃ¼ sayesinde aldÄ±m. PortfÃ¶y, eÄŸitim geÃ§miÅŸinden daha iyi veri bilimi bilgisi ve deneyimi temsil eder.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musunuz? Kaggle ile karÅŸÄ±laÅŸtÄ±rmasÄ± nasÄ±l?**
> 
> DrivenData ve AICrowdâ€™u da kullanÄ±yorum. Kaggle daha bÃ¼yÃ¼k ve aktif bir topluluk sunuyor, donanÄ±m ve veri/Notebook Ã¶zellikleri ile en iyi seÃ§enek. Ancak diÄŸer platformlar da ilginÃ§ ve Ã§eÅŸitli zorluklar sunuyor.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya girerken en Ã¶nemli ÅŸey nedir?**
> 
> GeliÅŸim odaklÄ±ysanÄ±z, ilginizi Ã§eken ve daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z bir konuyu seÃ§in. Derinlik ve Ã§eÅŸitlilik kritik; derinlik, odaklanarak ve en iyinizi vererek; Ã§eÅŸitlilik ise daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z veya farklÄ± yaptÄ±ÄŸÄ±nÄ±z ÅŸeyleri deneyerek elde edilir.

### Working with datasets *(Veri setleriyle Ã§alÄ±ÅŸma)*

Bir veri seti oluÅŸturduktan sonra, muhtemelen onu analizlerinizde kullanmak isteyeceksiniz. Bu bÃ¶lÃ¼mde, bunu yapmanÄ±n farklÄ± yÃ¶ntemlerini ele alÄ±yoruz.

Muhtemelen en Ã¶nemli yÃ¶ntem, veri setinizi birincil kaynak olarak kullanacaÄŸÄ±nÄ±z bir Notebook baÅŸlatmaktÄ±r. Bunu yapmak iÃ§in veri seti sayfasÄ±na gidip ardÄ±ndan **New Notebook** Ã¼zerine tÄ±klayabilirsiniz.

![](im/1011.png)

Bunu yaptÄ±ktan sonra, Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![](im/1012.png)

Ä°ÅŸte bununla ilgili birkaÃ§ ipucu:

* AlfasayÄ±sal baÅŸlÄ±k otomatik olarak oluÅŸturulur; Ã¼zerine tÄ±klayarak dÃ¼zenleyebilirsiniz.
* SaÄŸ tarafta, **Data** altÄ±nda Notebookâ€™unuza baÄŸlÄ± veri kaynaklarÄ±nÄ±n listesini gÃ¶rÃ¼rsÃ¼nÃ¼z; seÃ§tiÄŸim veri setine **../input/** veya **/kaggle/input/** Ã¼zerinden eriÅŸilebilir.
* AÃ§Ä±lÄ±ÅŸ bloÄŸu (iÃ§e aktarÄ±lan paketler, aÃ§Ä±klayÄ±cÄ± yorumlar ve mevcut dosyalarÄ±n listesi) yeni bir Python Notebookâ€™a otomatik olarak eklenir.

Bu temel kurulumla, analiziniz iÃ§in bir Notebook yazmaya baÅŸlayabilir ve veri setinizi veri kaynaÄŸÄ± olarak kullanabilirsiniz. Notebookâ€™larÄ± daha ayrÄ±ntÄ±lÄ± olarak **BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±ndan Yararlanmak** kÄ±smÄ±nda ele alacaÄŸÄ±z.

### Using Kaggle Datasets in Google Colab *(Google Colabâ€™da Kaggle veri setlerini kullanma)*

Kaggle Notebookâ€™larÄ± Ã¼cretsizdir, ancak sÄ±nÄ±rsÄ±z deÄŸildir (buna BÃ¶lÃ¼m 4â€™te daha ayrÄ±ntÄ±lÄ± deÄŸineceÄŸiz) ve karÅŸÄ±laÅŸabileceÄŸiniz ilk sÄ±nÄ±rlama muhtemelen **zaman limitidir**. PopÃ¼ler bir alternatif, tamamen bulutta Ã§alÄ±ÅŸan Ã¼cretsiz bir Jupyter Notebook ortamÄ± olan **Google Colab**â€™a geÃ§mektir: [https://colab.research.google.com](https://colab.research.google.com).

HesaplamalarÄ± Colabâ€™a taÅŸÄ±dÄ±ktan sonra bile Kaggle veri setlerine eriÅŸmek isteyebiliriz; bu yÃ¼zden onlarÄ± Colabâ€™a aktarmak oldukÃ§a kullanÄ±ÅŸlÄ± bir Ã¶zelliktir. Bu bÃ¶lÃ¼mÃ¼n geri kalanÄ±nda, Kaggle Datasetsâ€™i Colab Ã¼zerinden kullanmak iÃ§in gerekli adÄ±mlarÄ± ele alacaÄŸÄ±z.

Ä°lk olarak, Kaggleâ€™a zaten kayÄ±tlÄ± olduÄŸumuzu varsayarak, **API token** (giriÅŸ oturumu, kullanÄ±cÄ± kimliÄŸi, yetkiler vb. iÃ§in gÃ¼venlik bilgilerini iÃ§eren eriÅŸim belirteci) oluÅŸturmak iÃ§in hesap sayfasÄ±na gideriz:

1. HesabÄ±nÄ±za gidin: [https://www.kaggle.com/USERNAME/account](https://www.kaggle.com/USERNAME/account)

**Create New API Token** butonuna tÄ±klayÄ±n.

![](im/1013.png)

Bir **kaggle.json** dosyasÄ± oluÅŸturulacak; bu dosya kullanÄ±cÄ± adÄ±nÄ±zÄ± ve API tokenâ€™Ä±nÄ±zÄ± iÃ§erir.

2. Google Driveâ€™Ä±nÄ±zda **Kaggle** adÄ±nda bir klasÃ¶r oluÅŸturun ve **.json** dosyasÄ±nÄ± bu klasÃ¶re yÃ¼kleyin.

![](im/1014.png)

3. Ä°ÅŸlem tamamlandÄ±ktan sonra, yeni bir Colab defteri oluÅŸturmanÄ±z ve Google Driveâ€™Ä±nÄ±zÄ± baÄŸlamanÄ±z gerekir. Bunu yapmak iÃ§in defterde aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rÄ±n:

```python
from google.colab import drive
drive.mount('/content/gdrive')
```

4. URL isteminden yetkilendirme kodunu alÄ±n ve aÃ§Ä±lan boÅŸ kutuya girin, ardÄ±ndan aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rarak `.json` yapÄ±landÄ±rma dosyasÄ±nÄ±n yolunu belirtin:

```python
import os
# content/gdrive/My Drive/Kaggle is the path where kaggle.json is
# present in the Google Drive
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
# change the working directory
%cd /content/gdrive/My Drive/Kaggle
# check the present working directory using the pwd command
```

5. ArtÄ±k veri setini indirebiliriz. Bunun iÃ§in Kaggleâ€™daki veri seti sayfasÄ±na gidin, **New Notebook** yanÄ±ndaki Ã¼Ã§ noktaya tÄ±klayÄ±n ve **Copy API command** seÃ§eneÄŸini seÃ§in:

![alt text](im/1015.png)

6. Veri setini indirmek iÃ§in API komutunu Ã§alÄ±ÅŸtÄ±rÄ±n (komutlarÄ±n detaylarÄ±yla ilgilenenler resmi dokÃ¼mantasyona bakabilir: [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)):

```python
!kaggle datasets download -d ajaypalsinghlo/world-happinessreport-2021
```
7. Veri seti, Kaggle klasÃ¶rÃ¼ne bir .zip arÅŸivi olarak indirilecektir â€“ arÅŸivi aÃ§Ä±n ve kullanÄ±ma hazÄ±r hale gelmiÅŸ olacaktÄ±r.

YukarÄ±daki listeden de gÃ¶rebileceÄŸiniz gibi, bir Kaggle veri setini Colabâ€™da kullanmak oldukÃ§a basit bir sÃ¼reÃ§tir â€“ tek ihtiyacÄ±nÄ±z olan bir API tokenâ€™Ä±dÄ±r ve bu geÃ§iÅŸ size Kaggleâ€™Ä±n saÄŸladÄ±ÄŸÄ±ndan daha fazla GPU saatini kullanma imkÃ¢nÄ± verir.

### Legal caveats *(Yasal uyarÄ±lar)*

Sadece bazÄ± verileri Kaggleâ€™a yÃ¼kleyebilmeniz, bunu yapmanÄ±z gerektiÄŸi anlamÄ±na gelmez. MÃ¼kemmel bir Ã¶rnek, **People of Tinder** veri setidir. 2017â€™de bir geliÅŸtirici, Tinder APIâ€™sini kullanarak web sitesinden yarÄ±-Ã¶zel profilleri Ã§ekmiÅŸ ve veriyi Kaggleâ€™a yÃ¼klemiÅŸti. Bu durum ortaya Ã§Ä±ktÄ±ktan sonra, Kaggle veri setini kaldÄ±rdÄ±. Tam hikÃ¢yeyi ÅŸuradan okuyabilirsiniz: [Forbes makalesi](https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454).

Genel olarak, Kaggleâ€™a herhangi bir ÅŸey yÃ¼klemeden Ã¶nce kendinize ÅŸu iki soruyu sorun:

1. **Telif hakkÄ± aÃ§Ä±sÄ±ndan izinli mi?** LisanslarÄ± her zaman kontrol edin. ÅÃ¼phe durumunda [Open Definition Guide](https://opendefinition.org/guide/data/) veya Kaggle ile iletiÅŸime geÃ§ebilirsiniz.
2. **Bu veri setiyle ilgili gizlilik riskleri var mÄ±?** Belirli bilgileri paylaÅŸmak, teknik olarak yasadÄ±ÅŸÄ± olmasa da, baÅŸka bir kiÅŸinin gizliliÄŸine zarar verebilir.

Bu sÄ±nÄ±rlamalar aslÄ±nda saÄŸduyuya dayanmaktadÄ±r, bu yÃ¼zden Kaggleâ€™daki Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± engellemesi pek olasÄ± deÄŸildir.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle platformunda verileri depolamanÄ±n ve kullanmanÄ±n standart yolu olan **Kaggle Datasets**â€™i tanÄ±ttÄ±k. Veri seti oluÅŸturmayÄ±, Kaggle dÄ±ÅŸÄ±ndaki ortamlarda Ã§alÄ±ÅŸma yÃ¶ntemlerini ve en Ã¶nemli iÅŸlevi olan **veri setini Notebookâ€™ta kullanmayÄ±** ele aldÄ±k. Bu, bir sonraki bÃ¶lÃ¼mde odaklanacaÄŸÄ±mÄ±z **Kaggle Notebooks** konusuna geÃ§iÅŸ iÃ§in gÃ¼zel bir kÃ¶prÃ¼ oluÅŸturuyor.

---

## Chapter 3: Working and Learning with Kaggle Notebooks *(BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek)*

Kaggle Notebooks â€” yakÄ±n zamana kadar **Kernels** olarak adlandÄ±rÄ±lÄ±yordu â€” tarayÄ±cÄ± Ã¼zerinden Ã§alÄ±ÅŸan ve Ã¼cretsiz olan **Jupyter Notebook**â€™lardÄ±r. Bu, internet baÄŸlantÄ±sÄ± olan herhangi bir cihazdan deneylerinizi Ã§alÄ±ÅŸtÄ±rabileceÄŸiniz anlamÄ±na gelir; ancak mobil telefondan daha bÃ¼yÃ¼k bir cihaz kullanmak muhtemelen daha iyi olacaktÄ±r. OrtamÄ±n teknik Ã¶zellikleri (yazÄ±m tarihi itibarÄ±yla) Kaggle web sitesinden alÄ±nmÄ±ÅŸtÄ±r; en gÃ¼ncel sÃ¼rÃ¼mÃ¼ **[https://www.kaggle.com/docs/notebooks](https://www.kaggle.com/docs/notebooks)** adresinden doÄŸrulanabilir:

* CPU/GPU iÃ§in 12 saat Ã§alÄ±ÅŸma sÃ¼resi, TPU iÃ§in 9 saat
* 20 GB otomatik kaydedilen disk alanÄ± (/kaggle/working)
* Ek geÃ§ici disk alanÄ± ( /kaggle/working dÄ±ÅŸÄ±nda) â€” bu alan mevcut oturum dÄ±ÅŸÄ±nda kaydedilmez

**CPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

**GPU Ã¶zellikleri:**

* 2 CPU Ã§ekirdeÄŸi
* 13 GB RAM

**TPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

Bu bÃ¶lÃ¼mde ele alacaÄŸÄ±mÄ±z konular:

* Notebook kurulumunu yapmak
* Notebookâ€™unuzu Ã§alÄ±ÅŸtÄ±rmak
* Notebookâ€™larÄ± GitHubâ€™a kaydetmek
* Notebookâ€™lardan en iyi ÅŸekilde faydalanmak
* Kaggle Learn kurslarÄ±

Hadi baÅŸlayalÄ±m. Ä°lk yapmamÄ±z gereken, bir Notebookâ€™un nasÄ±l kurulacaÄŸÄ±nÄ± Ã¶ÄŸrenmek.

### Setting up a Notebook *(Bir defter oluÅŸturma)*

Bir Notebook oluÅŸturmanÄ±n iki temel yÃ¶ntemi vardÄ±r: **ana sayfadan** veya **bir Dataset Ã¼zerinden**.

Ä°lk yÃ¶ntemi kullanmak iÃ§in:

1. [https://www.kaggle.com/](https://www.kaggle.com/) adresindeki ana sayfada, sol menÃ¼deki **Code** bÃ¶lÃ¼mÃ¼ne gidin.
2. ArdÄ±ndan **+ New Notebook** butonuna tÄ±klayÄ±n.

Bu yÃ¶ntem, kendi veri setinizi yÃ¼klemeyi iÃ§eren bir deneme planlÄ±yorsanÄ±z tercih edilen yÃ¶ntemdir.

![alt text](im/1016.png)

Alternatif olarak, ilgilendiÄŸiniz Datasetâ€™in sayfasÄ±na gidip oradaki **New Notebook** butonuna tÄ±klayabilirsiniz; bu yÃ¶ntemi bir Ã¶nceki bÃ¶lÃ¼mde gÃ¶rmÃ¼ÅŸtÃ¼k.

![alt text](im/1017.png)

Hangi yÃ¶ntemi seÃ§erseniz seÃ§in, **New Notebook** butonuna tÄ±kladÄ±ktan sonra Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![alt text](im/1018.png)

YukarÄ±da gÃ¶sterilen yeni Notebook sayfasÄ±nÄ±n saÄŸ tarafÄ±nda, ayarlanabilecek birkaÃ§ farklÄ± ayar bulunmaktadÄ±r:

![alt text](im/1019.png)

AyarlarÄ± kÄ±saca ele alalÄ±m:

1. **Kodlama Dili (Language)**:
   Kaggle ortamÄ±, yazÄ±ldÄ±ÄŸÄ± tarihte yalnÄ±zca Python ve R dillerini destekliyor. Yeni bir Notebook varsayÄ±lan olarak Python ile aÃ§Ä±lÄ±r. R kullanmak isterseniz aÃ§Ä±lÄ±r menÃ¼den Râ€™yi seÃ§ebilirsiniz.

2. **Ortam (Environment)**:
   Bu seÃ§enek, Notebookâ€™un hangi Docker ortamÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirler.

   * **Latest Docker**: En gÃ¼ncel ortamÄ± kullanÄ±r; hÄ±zlÄ± gÃ¼ncellemeler alÄ±rsÄ±nÄ±z ama baÄŸÄ±mlÄ±lÄ±klar bozulabilir (riskli).
   * **Original Kaggle environment**: Kaggle tarafÄ±ndan saÄŸlanan orijinal ortamÄ± kullanÄ±r (gÃ¼venli ve varsayÄ±lan).

3. **HÄ±zlandÄ±rÄ±cÄ± (Accelerator)**:
   Kodun hangi donanÄ±mda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± seÃ§menizi saÄŸlar:

   * **CPU**: HÄ±zlandÄ±rmasÄ±z
   * **GPU**: Derin Ã¶ÄŸrenme uygulamalarÄ± iÃ§in gereklidir
   * **TPU**: TPUâ€™ya taÅŸÄ±mak iÃ§in veri iÅŸleme ve kodda daha kapsamlÄ± deÄŸiÅŸiklik gerekir

   CPU, GPU veya TPU arasÄ±nda geÃ§iÅŸ yapabilirsiniz; fakat geÃ§iÅŸ yaptÄ±ÄŸÄ±nÄ±zda ortam yeniden baÅŸlatÄ±lÄ±r ve tÃ¼m kodu baÅŸtan Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekir.

4. **Ä°nternet (Internet) AÃ§ma/Kapama**:
   Ä°nternete eriÅŸimi aÃ§Ä±p kapatmanÄ±zÄ± saÄŸlar. Ã–rneÄŸin, ek paket yÃ¼klemek gerektiÄŸinde internet aÃ§Ä±k olmalÄ±dÄ±r. BazÄ± yarÄ±ÅŸmalarda, teslim sÄ±rasÄ±nda internetin kapalÄ± olmasÄ± zorunludur.

AyrÄ±ca, mevcut bir Notebookâ€™u (kendinizin veya baÅŸkasÄ±nÄ±n oluÅŸturduÄŸu) **kopyalayÄ±p dÃ¼zenleyebilirsiniz**. Bunun iÃ§in Notebook sayfasÄ±nÄ±n saÄŸ Ã¼stÃ¼ndeki **Copy and Edit** butonuna tÄ±klamanÄ±z yeterlidir. Kaggleâ€™da bu iÅŸlem **forking** olarak adlandÄ±rÄ±lÄ±r.

![alt text](im/1020.png)

> Bir gÃ¶rgÃ¼ notu: EÄŸer daha Ã¶nce bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ±ysanÄ±z, sÄ±ralama tablosunun (leaderboard) iyi puan alan Notebookâ€™larÄ±n kopyalarÄ±yla (forks of forks) dolu olduÄŸunu fark etmiÅŸsinizdir. BaÅŸkasÄ±nÄ±n Ã§alÄ±ÅŸmasÄ± Ã¼zerine inÅŸa etmek yanlÄ±ÅŸ deÄŸildir; ancak bunu yaparken **orijinal yazara oy vermeyi (upvote) ve referans alÄ±nan Ã§alÄ±ÅŸmanÄ±n sahibine aÃ§Ä±kÃ§a kredi vermeyi** unutmayÄ±n.

OluÅŸturduÄŸunuz bir Notebook varsayÄ±lan olarak **Ã¶zel**dir (sadece siz gÃ¶rebilirsiniz). EÄŸer baÅŸkalarÄ±nÄ±n eriÅŸmesini istiyorsanÄ±z iki seÃ§enek vardÄ±r:

1. **Ä°ÅŸbirlikÃ§ileri eklemek (adding collaborators):** Sadece aÃ§Ä±kÃ§a eklenen kullanÄ±cÄ±lar Notebookâ€™u gÃ¶rebilir veya dÃ¼zenleyebilir.
2. **Notebookâ€™u herkese aÃ§Ä±k yapmak (making public):** Bu durumda herkes Notebookâ€™u gÃ¶rebilir.

### Running your Notebook *(Defterinizi Ã§alÄ±ÅŸtÄ±rma)*

TÃ¼m kodlamalar tamamlandÄ±, Notebook sorunsuz Ã§alÄ±ÅŸÄ±yor gibi gÃ¶rÃ¼nÃ¼yor ve Ã§alÄ±ÅŸtÄ±rmaya hazÄ±rsÄ±nÄ±z. Bunu yapmak iÃ§in, Notebook sayfanÄ±zÄ±n **saÄŸ Ã¼st kÃ¶ÅŸesine** gidin ve **Save Version** (SÃ¼rÃ¼mÃ¼ Kaydet) dÃ¼ÄŸmesine tÄ±klayÄ±n.

![](im/1021.png)

**Save & Run All** genellikle tÃ¼m scripti Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r, ancak **Quick Save** seÃ§eneÄŸi de vardÄ±r; bu, script henÃ¼z gÃ¶nderime hazÄ±r olmadan Ã¶nce ara bir sÃ¼rÃ¼mÃ¼ kaydetmek iÃ§in kullanÄ±labilir.

![](im/1022.png)

Scriptinizi baÅŸlattÄ±ktan sonra, sol alt kÃ¶ÅŸeye gidip **Active Events** (Aktif Etkinlikler) butonuna tÄ±klayabilirsiniz. Bu bÃ¶lÃ¼m, Ã§alÄ±ÅŸmakta olan Notebook sÃ¼rÃ¼mlerinizin durumunu ve ilerlemesini izlemenizi saÄŸlar.

![](im/1023.png)

Bu ÅŸekilde, Notebookâ€™larÄ±nÄ±zÄ±n Ã§alÄ±ÅŸma durumunu takip edebilirsiniz. Normal bir yÃ¼rÃ¼tme sÄ±rasÄ±nda **Running** mesajÄ± gÃ¶rÃ¼nÃ¼r; aksi durumda **Failed** olarak gÃ¶rÃ¼ntÃ¼lenir.

EÄŸer herhangi bir nedenle (Ã¶rneÄŸin en gÃ¼ncel veriyi kullanmayÄ± unuttuÄŸunuzu fark ederseniz) Ã§alÄ±ÅŸan bir oturumu sonlandÄ±rmak isterseniz, **Active Events** altÄ±nda script giriÅŸinizin saÄŸ tarafÄ±ndaki Ã¼Ã§ noktaya tÄ±klayabilirsiniz. Bu iÅŸlem size aÅŸaÄŸÄ±daki ÅŸekilde bir aÃ§Ä±lÄ±r pencere (pop-up) gÃ¶sterecektir ve oturumu durdurmanÄ±za olanak tanÄ±r.

![](im/1024.png)

### Saving Notebooks to GitHub *(Defterleri GitHubâ€™a kaydetme)*

YakÄ±n zamanda eklenen bir Ã¶zellik (bkz. [https://www.kaggle.com/product-feedback/295170](https://www.kaggle.com/product-feedback/295170)), kodunuzu veya Notebookâ€™unuzu GitHub sÃ¼rÃ¼m kontrol deposuna ([https://github.com/](https://github.com/)) kaydetmenize olanak tanÄ±r. Ã‡alÄ±ÅŸmanÄ±zÄ± hem **public** hem de **private** depolara kaydedebilirsiniz ve bu iÅŸlem, kodunuzun bir versiyonunu kaydettiÄŸinizde otomatik olarak gerÃ§ekleÅŸir.

Bu Ã¶zellik, hem Kaggle takÄ±m arkadaÅŸlarÄ±nÄ±zla Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± paylaÅŸmak hem de Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± daha geniÅŸ bir kitleye sergilemek iÃ§in oldukÃ§a faydalÄ± olabilir.

Bu Ã¶zelliÄŸi etkinleÅŸtirmek iÃ§in:

1. Notebookâ€™unuzu aÃ§Ä±n.
2. Ãœst menÃ¼den **File** menÃ¼sÃ¼ne gidin.
3. **Link to GitHub** seÃ§eneÄŸini tÄ±klayÄ±n.

![](im/1025.png)

Bu seÃ§eneÄŸi seÃ§tikten sonra, GitHub hesabÄ±nÄ±zÄ± Notebook ile baÄŸlamanÄ±z gerekecek. Ä°lk kez baÄŸlama iÅŸlemi yaptÄ±ÄŸÄ±nÄ±zda, aÃ§Ä±kÃ§a **baÄŸlantÄ± izinleri** sorulacaktÄ±r. Sonraki yeni Notebookâ€™larda ise bu iÅŸlem otomatik olarak gerÃ§ekleÅŸtirilecektir.

![](im/1026.png)

Notebookâ€™unuzu ancak baÄŸladÄ±ktan sonra, kaydettiÄŸinizde Ã§alÄ±ÅŸmanÄ±zÄ± seÃ§tiÄŸiniz bir GitHub deposuyla senkronize etme izniniz olur.

![](im/1027.png)

Bir depo ve dal (branch) seÃ§tikten sonra, Ã§alÄ±ÅŸmanÄ±zÄ±n farklÄ± geliÅŸtirme aÅŸamalarÄ±nÄ± saklamanÄ±za olanak tanÄ±r ve depoya gÃ¶ndereceÄŸiniz dosyanÄ±n adÄ±nÄ± deÄŸiÅŸtirebilir ve commit mesajÄ±nÄ± dÃ¼zenleyebilirsiniz.

ArtÄ±k belirli bir Notebookâ€™u GitHub ile senkronize etmek istemiyorsanÄ±z, tek yapmanÄ±z gereken Dosya menÃ¼sÃ¼nden **Unlink from GitHub** seÃ§eneÄŸini tÄ±klamaktÄ±r.

Son olarak, Kaggleâ€™Ä±n GitHub hesabÄ±nÄ±za baÄŸlanmasÄ±nÄ± tamamen durdurmak isterseniz, hesaplarÄ±nÄ±zÄ± ya Kaggleâ€™daki **My linked accounts** sayfasÄ±ndan ya da GitHubâ€™daki [ayarlar](https://github.com/settings/applications) sayfasÄ±ndan ayÄ±rabilirsiniz.

### Getting the most out of Notebooks *(Defterlerden en iyi ÅŸekilde yararlanma)*

Kaggle, belirli miktarda kaynaklarÄ± Ã¼cretsiz olarak saÄŸlar ve bu kotlar haftalÄ±k olarak sÄ±fÄ±rlanÄ±r. GPU ve TPU kullanÄ±mÄ± iÃ§in belli bir saat hakkÄ±nÄ±z vardÄ±r; TPU iÃ§in bu sÃ¼re 30 saattir, GPU iÃ§in ise haftadan haftaya deÄŸiÅŸen bir kota uygulanÄ±r (resmÃ® aÃ§Ä±klamayÄ± ve â€œfloatingâ€ kotalar politikasÄ±nÄ± [buradan](https://www.kaggle.com/product-feedback/173129) inceleyebilirsiniz).

Kendi kullanÄ±mÄ±nÄ±zÄ± her zaman profilinizden takip edebilirsiniz.

![](im/1028.png)

Ä°lk bakÄ±ÅŸta kaynak miktarlarÄ± bÃ¼yÃ¼k gÃ¶rÃ¼nebilir, ancak bu izlenim yanÄ±ltÄ±cÄ± olabilir; kotanÄ±zÄ± oldukÃ§a hÄ±zlÄ± bir ÅŸekilde tÃ¼ketmek kolaydÄ±r. Kaynak kullanÄ±mÄ±nÄ± kontrol etmenize yardÄ±mcÄ± olacak bazÄ± pratik Ã¶neriler:

* Kota sayacÄ± (GPU veya TPU gibi seÃ§tiÄŸiniz hÄ±zlandÄ±rÄ±cÄ±yÄ± ne kadar sÃ¼re kullandÄ±ÄŸÄ±nÄ±zÄ± Ã¶lÃ§en sayaÃ§) Notebookâ€™u baÅŸlattÄ±ÄŸÄ±nÄ±z anda Ã§alÄ±ÅŸmaya baÅŸlar.
* Bu nedenle, Ã¶ncelikle ayarlardan GPUâ€™nun devre dÄ±ÅŸÄ± olduÄŸundan emin olun (bkz. Åekil 3.6). Ã–nce temel kodu yazÄ±n, sÃ¶zdizimini kontrol edin ve yalnÄ±zca GPU gerektiren kod parÃ§alarÄ±nÄ± eklediÄŸinizde GPUâ€™yu etkinleÅŸtirin. HatÄ±rlatma: HÄ±zlandÄ±rÄ±cÄ±yÄ± deÄŸiÅŸtirdiÄŸinizde Notebook yeniden baÅŸlatÄ±lÄ±r.
* Kodun tamamÄ±nÄ± kÃ¼Ã§Ã¼k bir veri alt kÃ¼mesi Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmak genellikle iyi bir fikirdir; bÃ¶ylece Ã§alÄ±ÅŸtÄ±rma sÃ¼resini tahmin edebilir ve kotayÄ± aÅŸarak kodun Ã§Ã¶kmesi riskini en aza indirirsiniz.

Bazen Kaggleâ€™Ä±n Ã¼cretsiz olarak saÄŸladÄ±ÄŸÄ± kaynaklar, yapÄ±lacak iÅŸ iÃ§in yeterli olmayabilir ve daha gÃ¼Ã§lÃ¼ bir makineye geÃ§meniz gerekir. Ã–rneÄŸin, yakÄ±n zamanda yapÄ±lan bir tÃ¼mÃ¶r sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmasÄ±: [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data).

EÄŸer ham veriniz 100GBâ€™dan bÃ¼yÃ¼kse, ya gÃ¶rÃ¼ntÃ¼leri yeniden boyutlandÄ±rmalÄ±/aÅŸaÄŸÄ± Ã¶rneklemeli (bu model performansÄ±nÄ± olumsuz etkileyebilir) ya da yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼leri iÅŸleyebilecek bir ortamda model eÄŸitmelisiniz. BÃ¼tÃ¼n ortamÄ± kendiniz kurabilirsiniz (Ã¶rnek olarak, BÃ¶lÃ¼m 2â€™deki â€œGoogle Colabâ€™da Kaggle Datasets KullanÄ±mÄ±â€ kÄ±smÄ±na bakabilirsiniz) veya Notebooks Ã§erÃ§evesinde kalÄ±p, altyapÄ± makinesini deÄŸiÅŸtirebilirsiniz. Ä°ÅŸte burada Google Cloud AI Notebooks devreye girer.

### Upgrading to Google Cloud Platform (GCP) *(Google Cloud Platformâ€™a (GCP) yÃ¼kseltme)*

GCPâ€™ye (Google Cloud Platform) geÃ§menin bariz avantajÄ±, daha gÃ¼Ã§lÃ¼ donanÄ±ma eriÅŸim saÄŸlamaktÄ±r: Kaggle tarafÄ±ndan saÄŸlanan Tesla P100 GPU birÃ§ok uygulama iÃ§in yeterli olsa da performans aÃ§Ä±sÄ±ndan en Ã¼st seviye deÄŸildir ve 16 GB RAM de Ã¶zellikle bÃ¼yÃ¼k NLP modelleri veya yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼ iÅŸleme gibi kaynak yoÄŸun uygulamalarda sÄ±nÄ±rlayÄ±cÄ± olabilir. Ã‡alÄ±ÅŸtÄ±rma sÃ¼resindeki iyileÅŸme, geliÅŸtirme dÃ¶ngÃ¼sÃ¼nde daha hÄ±zlÄ± iterasyon imkÃ¢nÄ± saÄŸlarken, bunun bir maliyeti vardÄ±r: Ne kadar harcamaya hazÄ±r olduÄŸunuzu belirlemeniz gerekir. GÃ¼Ã§lÃ¼ bir makine ile veri iÅŸlemek sÃ¶z konusu olduÄŸunda zaman, kelimenin tam anlamÄ±yla paradÄ±r.

Notebookâ€™unuzu GCP ortamÄ±na taÅŸÄ±mak iÃ§in, saÄŸ taraftaki yan menÃ¼den **Upgrade to Google Cloud AI Notebooks** seÃ§eneÄŸine tÄ±klayÄ±n.

![](im/1029.png)

Åu ifadeyle karÅŸÄ±lanacaksÄ±nÄ±z:

![](im/1030.png)

â€œDevam Etâ€e tÄ±kladÄ±ÄŸÄ±nÄ±zda, faturalandÄ±rma seÃ§eneklerinizi yapÄ±landÄ±rmanÄ±z gereken Google Cloud Platform konsoluna yÃ¶nlendirileceksiniz. HatÄ±rlatma: GCP Ã¼cretsiz deÄŸildir. Ä°lk kez kullanÄ±yorsanÄ±z, gerekli adÄ±mlar boyunca size rehberlik edecek bir Ã¶ÄŸreticiyi (tutorial) tamamlamanÄ±z gerekecektir.

### One step beyond *(Bir adÄ±m Ã¶teye geÃ§mek)*

Bu bÃ¶lÃ¼mÃ¼n Ã¶nceki kÄ±sÄ±mlarÄ±nda da belirtildiÄŸi gibi, **Kaggle Notebooks** (Kaggle Defterleri) eÄŸitim ve yarÄ±ÅŸmalara katÄ±lÄ±m iÃ§in harika bir araÃ§tÄ±r; ancak aynÄ± zamanda bir baÅŸka son derece faydalÄ± amaca da hizmet eder: **veri bilimi becerilerinizi sergileyebileceÄŸiniz bir portfÃ¶yÃ¼n parÃ§asÄ±** olarak kullanÄ±labilirler.

Bir veri bilimi portfÃ¶yÃ¼ oluÅŸtururken dikkate alÄ±nabilecek birÃ§ok potansiyel kriter vardÄ±r (markalaÅŸma, hedef kitleye ulaÅŸma, potansiyel iÅŸvereninize kendinizi tanÄ±tma vb.); ancak kimse portfÃ¶yÃ¼nÃ¼zÃ¼ bulamazsa, bunlarÄ±n hiÃ§birinin Ã¶nemi kalmaz. Kaggle, Googleâ€™Ä±n bir parÃ§asÄ± olduÄŸu iÃ§in Notebooks (defterler), dÃ¼nyanÄ±n en popÃ¼ler arama motoru tarafÄ±ndan dizine eklenir; dolayÄ±sÄ±yla biri kodunuzla ilgili bir konuyu aradÄ±ÄŸÄ±nda, Ã§alÄ±ÅŸmanÄ±z arama sonuÃ§larÄ±nda gÃ¶rÃ¼nebilir.

AÅŸaÄŸÄ±da kiÅŸisel bir Ã¶rnek gÃ¶steriyorum: birkaÃ§ yÄ±l Ã¶nce bir yarÄ±ÅŸma iÃ§in bir Notebook yazmÄ±ÅŸtÄ±m. Ãœzerinde Ã§alÄ±ÅŸmak istediÄŸim problem, **adversarial validation** (karÅŸÄ±t doÄŸrulama) idi. (Bu konuya aÅŸina olmayanlar iÃ§in kÄ±sa bir aÃ§Ä±klama: eÄŸitim ve test veri kÃ¼melerinizin benzer bir daÄŸÄ±lÄ±ma sahip olup olmadÄ±ÄŸÄ±nÄ± anlamanÄ±n oldukÃ§a kolay bir yolu, onlarÄ± ayÄ±rt etmeyi Ã¶ÄŸrenen ikili bir sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturmaktÄ±r; bu kavram 6. BÃ¶lÃ¼mâ€™de, *Ä°yi Bir DoÄŸrulama Tasarlama* kÄ±smÄ±nda daha ayrÄ±ntÄ±lÄ± olarak ele alÄ±nmÄ±ÅŸtÄ±r.)

Bu bÃ¶lÃ¼mÃ¼ yazarken, o defteri aramayÄ± denedim ve tahmin edin ne oldu â€” arama sonuÃ§larÄ±nda oldukÃ§a Ã¼st sÄ±ralarda gÃ¶rÃ¼ndÃ¼. (Dikkat ederseniz, arama sorguma â€œKaggleâ€ veya adÄ±m gibi kiÅŸisel bilgiler eklemedim.)

![](im/1031.png)

Notebooks kullanarak becerilerinizi sergilemenin diÄŸer avantajlarÄ±na geÃ§elim: **Competitions (YarÄ±ÅŸmalar)**, **Datasets (Veri KÃ¼meleri)** ve **Discussions (TartÄ±ÅŸmalar)** bÃ¶lÃ¼mlerinde olduÄŸu gibi, **Notebooks** da oy (vote) ve madalya (medal) alabilir. Bu sayede Kaggleâ€™daki ilerleme sisteminde ve sÄ±ralamalarda yerinizi alabilirsiniz.

YarÄ±ÅŸmalara hiÃ§ katÄ±lmadan da, yalnÄ±zca topluluk tarafÄ±ndan beÄŸenilen yÃ¼ksek kaliteli kodlara odaklanarak **Expert (Uzman)**, **Master (Usta)** veya **Grandmaster (BÃ¼yÃ¼k Usta)** unvanlarÄ±na ulaÅŸabilirsiniz.

Ä°lerleme gereksinimlerinin en gÃ¼ncel hÃ¢lini [https://www.kaggle.com/progression](https://www.kaggle.com/progression) adresinde bulabilirsiniz; aÅŸaÄŸÄ±da ise **Expert** ve **Master** seviyeleriyle ilgili bir Ã¶zet yer almaktadÄ±r:

![](im/1032.png)

**Notebooks** kategorisinde ilerlemek zorlu bir deneyim olabilir; **Competitions (YarÄ±ÅŸmalar)** bÃ¶lÃ¼mÃ¼ne gÃ¶re biraz daha kolay olsa da, **Discussions (TartÄ±ÅŸmalar)** bÃ¶lÃ¼mÃ¼nden kesinlikle daha zordur. En popÃ¼ler Notebooks genellikle belirli bir yarÄ±ÅŸmayla baÄŸlantÄ±lÄ± olanlardÄ±r: **keÅŸifsel veri analizi (exploratory data analysis)**, **uÃ§tan uca kavramsal kanÄ±t Ã§Ã¶zÃ¼mleri (end-to-end proof of concept)** ve **liderlik tablosu kovalamaca (leaderboard chasing)** gibi konulara odaklanÄ±rlar.

Ne yazÄ±k ki, sÄ±kÃ§a rastlanan bir uygulama da ÅŸudur: bazÄ± kiÅŸiler en yÃ¼ksek puanÄ± alan herkese aÃ§Ä±k bir Notebookâ€™u kopyalar (clone eder), birkaÃ§ parametreyi deÄŸiÅŸtirerek skoru biraz artÄ±rÄ±r ve ardÄ±ndan bunu bÃ¼yÃ¼k beÄŸeniyle (upvoteâ€™lar bir beÄŸeni Ã¶lÃ§Ã¼sÃ¼ olarak kabul edilirse) yayÄ±mlar. Bu durum, okuyucunun Kaggleâ€™da kaliteli Ã§alÄ±ÅŸmalar yayÄ±mlama isteÄŸini kÄ±rmak iÃ§in sÃ¶ylenmemektedir â€” Ã§Ã¼nkÃ¼ Kaggle topluluÄŸunun bÃ¼yÃ¼k bir kÄ±smÄ± yenilikÃ§i Ã§alÄ±ÅŸmalarÄ± gerÃ§ekten takdir eder ve uzun vadede kalite her zaman Ã¶ne Ã§Ä±kar â€” ancak **beklentilerin gerÃ§ekÃ§i bir ÅŸekilde ayarlanmasÄ±** gerekir.

Kaggle profilinizin takipÃ§ileri (followers) olur ve **LinkedIn** veya **GitHub** gibi diÄŸer profesyonel aÄŸlarla baÄŸlantÄ± kurma olanaÄŸÄ± sunar; bÃ¶ylece topluluk iÃ§inde kazandÄ±ÄŸÄ±nÄ±z baÄŸlantÄ±larÄ± **fÄ±rsata dÃ¶nÃ¼ÅŸtÃ¼rebilirsiniz**.

![](im/1033.png)

GÃ¼nÃ¼mÃ¼zde â€œtopluluk oluÅŸturmaâ€ iddialarÄ±na karÅŸÄ± kuÅŸkucu olmak oldukÃ§a kolaydÄ±r, ancak **Kaggle** sÃ¶z konusu olduÄŸunda bu durum gerÃ§ekten doÄŸrudur. Kaggleâ€™Ä±n veri bilimi dÃ¼nyasÄ±ndaki marka bilinirliÄŸi, hem uygulayÄ±cÄ±lar (practitioners) hem de iÅŸini gerÃ§ekten iyi yapan iÅŸe alÄ±m uzmanlarÄ± (recruiters) arasÄ±nda rakipsizdir.

Pratikte bu ÅŸu anlama gelir: **yeterince iyi bir Kaggle profili**, sizi zaten â€œkapÄ±dan iÃ§eri sokabilirâ€ â€” ki hepimizin bildiÄŸi gibi, bu genellikle en zor adÄ±mdÄ±r.

> **Martin Henze**
> 
> [https://www.kaggle.com/headsortails](https://www.kaggle.com/headsortails)
> 
> 
> 
> Martin Henze, yani â€œHeads or Tailsâ€ ile konuÅŸma fÄ±rsatÄ±nÄ± bulduk. Kendisi Notebooks ve Discussion alanlarÄ±nda bir **Kaggle Grandmaster** (bÃ¼yÃ¼k usta) ve **Edison Software**â€™da bir veri bilimci. Martin aynÄ± zamanda, her hafta gÃ¶zden kaÃ§mÄ±ÅŸ en iyi Notebooksâ€™larÄ± bir araya getirdiÄŸi **â€œNotebooks of the Week: Hidden Gemsâ€** adlÄ± koleksiyonun yazarÄ±. Yeni â€œHidden Gemsâ€ paylaÅŸÄ±mlarÄ±ndan haberdar olmak iÃ§in Kaggle profilini veya Twitter ve LinkedIn hesaplarÄ±nÄ± takip edebilirsiniz.
> 
> 
> 
> ---
> 
> 
> 
> En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ hangisi ve neden? Teknik aÃ§Ä±dan ya da Ã§Ã¶zÃ¼m yaklaÅŸÄ±mÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™daki uzmanlÄ±k alanÄ±n nedir?
> 
> 
> 
> Uzun bir sÃ¼re boyunca odak noktam, sÄ±ralama tablolarÄ±ndaki tahminlerden ziyade **EDA (exploratory data analysis â€“ keÅŸifsel veri analizi)** not defterleri oldu. Kaggleâ€™dan Ã¶nceki deneyimlerimin Ã§oÄŸu tablo (tabular) verilerleydi ve EDA not defterlerimin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu da yeni baÅŸlayan tablo tabanlÄ± yarÄ±ÅŸmalardan karmaÅŸÄ±k iÃ§gÃ¶rÃ¼ler Ã§Ä±karmak Ã¼zerineydi. Bunu hÃ¢lÃ¢ Kaggleâ€™daki uzmanlÄ±k alanÄ±m olarak gÃ¶rÃ¼yorum ve not defterlerimin yapÄ±sÄ±nÄ±, veri gÃ¶rselleÅŸtirmelerini ve anlatÄ±m biÃ§imini tasarlamaya Ã§ok zaman harcadÄ±m.
> 
> 
> 
> ---
> 
> 
> 
> Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m gÃ¼nlÃ¼k iÅŸinde yaptÄ±klarÄ±ndan ne kadar farklÄ±?
> 
> 
> 
> Kaggle her ne kadar tablo tabanlÄ± yarÄ±ÅŸmalardan uzaklaÅŸmÄ±ÅŸ olsa da, ben hÃ¢lÃ¢ bir yarÄ±ÅŸmadaki en Ã¶nemli unsurun **verinin kendisi** olduÄŸuna inanÄ±yorum. Model mimarilerine ve hiperparametre ayarlamalarÄ±na fazla erken odaklanmak kolaydÄ±r. Ancak birÃ§ok yarÄ±ÅŸmada baÅŸarÄ±ya ulaÅŸmanÄ±n anahtarÄ±, verisetinin ayrÄ±ntÄ±lÄ± ÅŸekilde anlaÅŸÄ±lmasÄ±na dayanan veri merkezli bir yaklaÅŸÄ±mdÄ±r. Bu; gÃ¶rÃ¼ntÃ¼ verisi, NLP, zaman serisi ya da baÅŸka veri tÃ¼rleri iÃ§in de geÃ§erlidir.
> 
> Bu yÃ¼zden, her zaman kapsamlÄ± bir **EDA** ile baÅŸlarÄ±m; ardÄ±ndan basit bir temel model, bir Ã§apraz doÄŸrulama (CV) Ã§erÃ§evesi kurar ve bu yapÄ±nÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yavaÅŸ yavaÅŸ artÄ±rÄ±rÄ±m.
> 
> 
> 
> GÃ¼nlÃ¼k veri bilimi iÅŸimle en bÃ¼yÃ¼k fark muhtemelen ÅŸu: Deneyimli Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n, yeni bir yarÄ±ÅŸmanÄ±n ilk haftasÄ±nda kurduÄŸu temel modeller, endÃ¼stride Ã¼retime alÄ±nacak dÃ¼zeyde kabul edilir. Ã‡oÄŸu durumda, o ilk birkaÃ§ gÃ¼nÃ¼n sonunda nihai kazananÄ±n puanÄ±na %80 oranÄ±nda yaklaÅŸmÄ±ÅŸ oluruz.
> 
> Elbette Kaggleâ€™daki eÄŸlence ve zorluk, o son birkaÃ§ yÃ¼zde puanlÄ±k farkÄ± yaratacak yaratÄ±cÄ± yollar bulmaktÄ±r. Ancak bir ÅŸirkette, o zamanÄ± genellikle yeni bir projeye baÅŸlamak iÃ§in harcamak daha verimlidir.
> 
> 
> 
> ---
> 
> 
> 
> Kaggle kariyerine yardÄ±mcÄ± oldu mu? Olduysa nasÄ±l?
> 
> 
> 
> Kaggle kariyerimi olaÄŸanÃ¼stÃ¼ derecede ÅŸekillendirdi ve destekledi. Kaggle topluluÄŸundaki harika deneyimim beni akademiden endÃ¼striye geÃ§meye motive etti. Åu anda bir teknoloji giriÅŸiminde veri bilimci olarak Ã§alÄ±ÅŸÄ±yorum ve Kaggle yarÄ±ÅŸmalarÄ± aracÄ±lÄ±ÄŸÄ±yla becerilerimi sÃ¼rekli geliÅŸtiriyorum.
> 
> 
> 
> Benim durumumda, kapsamlÄ± Kaggle Notebooksâ€™larÄ± oluÅŸturma odaÄŸÄ±m Ã§ok faydalÄ± oldu; Ã§Ã¼nkÃ¼ bunlarÄ± kolayca **portfÃ¶yÃ¼m** olarak kullanabildim.
> 
> Bir iÅŸe alÄ±m yÃ¶neticisinin gerÃ§ekten bu kaynaklara ne kadar baktÄ±ÄŸÄ±nÄ± bilmiyorum ama sÄ±klÄ±kla â€œGrandmasterâ€ unvanÄ±mÄ±n, doktora (PhD) derecemden daha fazla kapÄ± aÃ§tÄ±ÄŸÄ± izlenimini edindim. Ya da belki ikisinin birleÅŸimi iÅŸe yaradÄ±.
> 
> Her durumda, herkese kamuya aÃ§Ä±k bir Notebooks portfÃ¶yÃ¼ne sahip olmayÄ± tavsiye ederim. AyrÄ±ca iÅŸ arayÄ±ÅŸÄ±m sÄ±rasÄ±nda, Kaggleâ€™da Ã¶ÄŸrendiÄŸim stratejileri ev Ã¶devi tarzÄ± deÄŸerlendirmelerde uyguladÄ±m ve bunlar bana Ã§ok yardÄ±mcÄ± oldu.
> 
> 
> 
> ---
> 
> 
> 
> Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ± ÅŸey nedir? BaÅŸlarken bilmediÄŸin ama ÅŸimdi bildiÄŸin bir ÅŸey var mÄ±?
> 
> 
> 
> Hepimiz sÃ¼rekli deneyim kazanÄ±yoruz. On yÄ±l, beÅŸ yÄ±l ya da bir yÄ±l Ã¶ncesine gÃ¶re hepimiz daha bilgeyiz.
> 
> Bunu bir kenara koyarsak, sÄ±klÄ±kla gÃ¶zden kaÃ§an en Ã¶nemli ÅŸeylerden biri, **ne yaptÄ±ÄŸÄ±nÄ±za dair bir planÄ±nÄ±zÄ±n olmasÄ±** ve bu planÄ± **uygulayÄ±p belgelemeniz** gerektiÄŸidir.
> 
> Yeni baÅŸlayan Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n bunu atlamasÄ± anlaÅŸÄ±lÄ±r bir durum, Ã§Ã¼nkÃ¼ her ÅŸey yeni, karmaÅŸÄ±k ve kafa karÄ±ÅŸtÄ±rÄ±cÄ±dÄ±r. Kaggleâ€™a ilk katÄ±ldÄ±ÄŸÄ±mda benim iÃ§in de Ã¶yleydi: forumlar, veri setleri, yarÄ±ÅŸmalar, kurslarâ€¦ Hepsi birbirine karÄ±ÅŸÄ±yordu.
> 
> Ve yarÄ±ÅŸmalar bazen gerÃ§ekten gÃ¶z korkutucu: *NÃ¶ronal HÃ¼cre Segmentasyonu*, *Borsa OynaklÄ±ÄŸÄ± Tahmini*â€¦ Bunlar ne ki?
> 
> Ama yarÄ±ÅŸmalar aynÄ± zamanda baÅŸlamanÄ±n da en iyi yoludur.
> 
> 
> 
> Bir yarÄ±ÅŸma baÅŸladÄ±ÄŸÄ±nda aslÄ±nda kimsenin tam bir fikri yoktur. Belki konuyla neredeyse aynÄ± konuda doktora yapmÄ±ÅŸ biri vardÄ±r ama bu nadirdir. Geri kalan herkes sÄ±fÄ±rdan baÅŸlar.
> 
> Veriyi inceleyerek, kayÄ±p fonksiyonlarÄ±yla oynayarak, basit baÅŸlangÄ±Ã§ modelleri Ã§alÄ±ÅŸtÄ±rarak Ã¶ÄŸrenirsiniz.
> 
> Bir yarÄ±ÅŸmaya en baÅŸÄ±nda katÄ±ldÄ±ÄŸÄ±nÄ±zda, bu Ã¶ÄŸrenme sÃ¼recini hÄ±zlandÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde, topluluÄŸun bir parÃ§asÄ± olarak yaÅŸarsÄ±nÄ±z. Topluluktaki diÄŸerleri size tonlarca fikir saÄŸlar. Ama yine de bir **planÄ±nÄ±zÄ±n** olmasÄ± gerekir.
> 
> 
> 
> Plan Ã¶nemlidir; Ã§Ã¼nkÃ¼ bazen sadece rastgele deneyler Ã§alÄ±ÅŸtÄ±rÄ±r, GPU belleÄŸinin dolduÄŸunu gÃ¶rÃ¼p mutlu olursunuz ama sonra en iyi modeli hangisiydi unutur, yerel doÄŸrulama ile lider tablosu arasÄ±nda korelasyon var mÄ±ydÄ± hatÄ±rlamazsÄ±nÄ±z.
> 
> Bu yÃ¼zden ne yapacaÄŸÄ±nÄ±zÄ± yazÄ±n ve sonuÃ§larÄ± kaydedin.
> 
> Bunun iÃ§in otomatik loglama araÃ§larÄ± giderek artÄ±yor ama basit bir Ã¶zel betik (script) ile de yapÄ±labilir.
> 
> 
> 
> Makine Ã¶ÄŸrenimi hÃ¢lÃ¢ bÃ¼yÃ¼k Ã¶lÃ§Ã¼de **deneysel bir bilimdir**, ve verimli deneylerin anahtarÄ± onlarÄ± iyi planlamak ve sonuÃ§larÄ± yazarak karÅŸÄ±laÅŸtÄ±rabilmektir.
> 
> 
> 
> ---
> 
> 
> 
> GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±n hatalar nelerdi?
> 
> 
> 
> BirÃ§ok hata yaptÄ±m ve onlardan ders Ã§Ä±karmayÄ± baÅŸardÄ±ÄŸÄ±mÄ± umuyorum.
> 
> SaÄŸlam bir **Ã§apraz doÄŸrulama (CV) Ã§erÃ§evesi** kurmamak bunlardan biriydi.
> 
> EÄŸitim ve test setleri arasÄ±ndaki farklarÄ± hesaba katmamak, Ã§ok fazla EDA yapÄ±p model kurulumunu ihmal etmek â€” bu ilk birkaÃ§ yarÄ±ÅŸmadaki â€œimza hatamâ€ olabilir.
> 
> Yeterince EDA yapmayÄ±p Ã¶nemli bir ÅŸeyi kaÃ§Ä±rmak â€” evet, onu da yaptÄ±m.
> 
> Finalde gÃ¶ndereceÄŸim iki modeli seÃ§meyi unutmak â€” Ã§ok fark yaratmadÄ± ama bir daha asla unutmam.
> 
> 
> 
> Ama hatalarla ilgili Ã¶nemli nokta ÅŸu: Deney ve plan konusundaki Ã¶nceki dÃ¼ÅŸÃ¼ncemle aynÄ±.
> 
> Hatalar **Ã¶ÄŸreniyorsanÄ±z** ve sizi geliÅŸtirmeye yardÄ±mcÄ± oluyorsa sorun deÄŸildir.
> 
> Tabii ki Ã¶ngÃ¶rÃ¼yle Ã¶nlenebilecek basit hatalardan kaÃ§Ä±nmak istersiniz.
> 
> Ama makine Ã¶ÄŸreniminde (ve bilimde!) baÅŸarÄ±sÄ±zlÄ±k sÃ¼recin bir parÃ§asÄ±dÄ±r.
> 
> Her ÅŸey her zaman iÅŸe yaramayacaktÄ±r â€” ve bu normaldir.
> 
> Ancak aynÄ± hatalarÄ± tekrar tekrar yapmak istemezsiniz.
> 
> DolayÄ±sÄ±yla gerÃ§ek hata, hatalarÄ±nÄ±zdan **ders almamaktÄ±r**.
> 
> Bu hem Kaggle yarÄ±ÅŸmalarÄ± hem de hayat iÃ§in geÃ§erlidir.
> 
> 
> 
> ---
> 
> 
> 
> Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸin araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?
> 
> 
> 
> Evet, gÃ¼nÃ¼mÃ¼zde giderek daha fazla **Python** kullanÄ±yoruz; ancak tablo verileriyle Ã§alÄ±ÅŸmak ve veri gÃ¶rselleÅŸtirmek sÃ¶z konusu olduÄŸunda hÃ¢lÃ¢ **R** ve **tidyverse** (Ã¶r. `dplyr`, `ggplot2`, `lubridate`) tercih ediyorum.
> 
> Yeni **tidymodels** Ã§erÃ§evesi de `sklearn`â€™e ciddi bir rakip.
> 
> SÄ±kÄ± bir Python hayranÄ± olsanÄ±z bile, zaman zaman `pandas` ve benzeri araÃ§larÄ±n Ã¶tesine bakmak faydalÄ±dÄ±r.
> 
> FarklÄ± araÃ§lar farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve daha fazla yaratÄ±cÄ±lÄ±k getirir.
> 
> 
> 
> Derin Ã¶ÄŸrenim aÃ§Ä±sÄ±ndan **PyTorch**â€™u en sezgisel buluyorum, Ã¶zellikle de **FastAI** arayÃ¼zÃ¼yle birlikte.
> 
> Ve tabii ki gÃ¼nÃ¼mÃ¼zde herkesin sevdiÄŸi **Hugging Face** â€” hem de Ã§ok haklÄ± sebeplerle.
> 
> 
> 
> ---
> 
> 
> 
> Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± veya yapÄ±lmasÄ± gereken en Ã¶nemli ÅŸey nedir?
> 
> 
> 
> En Ã¶nemlisi **eÄŸlenmek** ve **bir ÅŸeyler Ã¶ÄŸrenmek**.
> 
> Bir yarÄ±ÅŸma sÄ±rasÄ±nda ve sonrasÄ±nda paylaÅŸÄ±lan o kadar Ã§ok deÄŸerli bilgi ve deneyim var ki, bunlardan yararlanmamak bÃ¼yÃ¼k bir kayÄ±p olur.
> 
> Sadece kazanmak isteseniz bile, bunu ancak Ã¶ÄŸrenerek, deneyerek ve topluluÄŸun desteÄŸinden faydalanarak baÅŸarabilirsiniz.
> 
> Ama Kaggle, lider tablolarÄ±ndan Ã§ok daha fazlasÄ±dÄ±r; topluluÄŸa katkÄ± yapmaya baÅŸladÄ±ÄŸÄ±nÄ±zda, Ã§ok daha bÃ¼tÃ¼nsel bir ÅŸekilde geliÅŸirsiniz.
> 
> Buna garanti verebilirim.
> 
> 

### Kaggle Learn courses *(Kaggle Learn kurslarÄ±)*

Kaggle hakkÄ±nda pek Ã§ok ÅŸey bilgi edinme ile ilgilidir. Ä°ster bir yarÄ±ÅŸmada Ã¶ÄŸrendikleriniz, ister hÄ±zla bÃ¼yÃ¼yen veri seti deposunda bulduÄŸunuz veriler, isterse de henÃ¼z keÅŸfedilmemiÅŸ bir model sÄ±nÄ±fÄ±nÄ± gÃ¶steren bir ÅŸey olsun, her zaman Ã¶ÄŸrenilecek yeni bir ÅŸey vardÄ±r. Bu koleksiyona en yeni eklenen ÅŸey, Kaggle Learn etiketinde toplanan kurslardÄ±r: [https://www.kaggle.com/learn](https://www.kaggle.com/learn). Bu kurslar, Kaggle tarafÄ±ndan "baÄŸÄ±msÄ±z veri bilimi projeleri yapmanÄ±z iÃ§in gerekli becerileri kazanmanÄ±n en hÄ±zlÄ± yolu" olarak tanÄ±tÄ±lmaktadÄ±r; ana tema, Ã§eÅŸitli konularda hÄ±zlÄ± bir giriÅŸ kursu sunmaktÄ±r. Her kurs, kÃ¼Ã§Ã¼k bÃ¶lÃ¼mlere ayrÄ±lmÄ±ÅŸtÄ±r ve ardÄ±ndan kodlama uygulama sorularÄ± gelir. Kurslar, gerekli teori ve aÃ§Ä±klamalarÄ±n, kod yazÄ±p uygulamanÄ±z gereken kÄ±sÄ±mlarla iÃ§ iÃ§e geÃ§tiÄŸi Notebooks kullanÄ±larak sunulmaktadÄ±r.

AÅŸaÄŸÄ±da, en kullanÄ±ÅŸlÄ± olanlarÄ±nÄ±n kÄ±sa bir Ã¶zeti yer almaktadÄ±r:

* **Intro to ML / Intermediate ML**: [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning) ve [https://www.kaggle.com/learn/intermediate-machine-learning](https://www.kaggle.com/learn/intermediate-machine-learning)
Bu iki kurs, birbirini tamamlayan birer parÃ§a olarak gÃ¶rÃ¼lebilir: ilki, makine Ã¶ÄŸrenmesinde kullanÄ±lan farklÄ± model sÄ±nÄ±flarÄ±nÄ± tanÄ±tarak baÅŸlar ve ardÄ±ndan farklÄ± modeller iÃ§in ortak olan konularÄ± (aÅŸÄ±rÄ±/eksik Ã¶ÄŸrenme veya model doÄŸrulama gibi) tartÄ±ÅŸÄ±r. Ä°kincisi, Ã¶zellik mÃ¼hendisliÄŸine daha derinlemesine bir bakÄ±ÅŸ sunar, eksik deÄŸerlerle baÅŸa Ã§Ä±kma ve kategorik deÄŸiÅŸkenleri ele alma gibi konularÄ± iÅŸler. Makine Ã¶ÄŸrenmesine yeni baÅŸlayanlar iÃ§in faydalÄ±dÄ±r.

* **pandas**: [https://www.kaggle.com/learn/pandas](https://www.kaggle.com/learn/pandas)
Bu kurs, modern veri biliminin en temel araÃ§larÄ±ndan birine hÄ±zlÄ± bir giriÅŸ saÄŸlar. Ä°lk olarak veri oluÅŸturma, okuma ve yazma konularÄ±nÄ± Ã¶ÄŸrenirsiniz, ardÄ±ndan veri temizleme (indeksleme, seÃ§me, birleÅŸtirme, gruplama vb.) Ã¼zerine Ã§alÄ±ÅŸÄ±rsÄ±nÄ±z. Hem yeni baÅŸlayanlar (pandas'Ä±n fonksiyonelliÄŸi zaman zaman bunaltÄ±cÄ± olabilir) hem de uygulayÄ±cÄ±lar (yeniden gÃ¶zden geÃ§irme/referans olarak) iÃ§in faydalÄ±dÄ±r.

* **Game AI**: [https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning)
Bu kurs, Kaggleâ€™Ä±n Ã¶ÄŸrenme modÃ¼llerinde sunulan teknoloji odaklÄ± kÄ±smÄ±n gÃ¼zel bir tamamlayÄ±cÄ±sÄ±dÄ±r. Bir oyun oynama ajanÄ± yazacak, performansÄ±nÄ± inceleyecek ve minimax algoritmasÄ±nÄ± kullanacaksÄ±nÄ±z. Bu kurs, muhtemelen pekiÅŸtirmeli Ã¶ÄŸrenmeye yÃ¶nelik bir uygulamalÄ± tanÄ±tÄ±m olarak gÃ¶rÃ¼lmelidir.

* **Machine Learning Explainability**: [https://www.kaggle.com/learn/machine-learning-explainability](https://www.kaggle.com/learn/machine-learning-explainability)
Modeller oluÅŸturmak eÄŸlenceli olabilir, ancak gerÃ§ek dÃ¼nyada herkes veri bilimcisi deÄŸildir, bu yÃ¼zden yaptÄ±klarÄ±nÄ±zÄ± baÅŸkalarÄ±na aÃ§Ä±klamanÄ±z gereken bir durumda olabilirsiniz. Ä°ÅŸte bu noktada model aÃ§Ä±klanabilirliÄŸi Ã¼zerine olan bu mini kurs devreye giriyor: Ã¼Ã§ farklÄ± yÃ¶ntemle (permutasyon Ã¶nemi, SHAP ve kÄ±smi baÄŸÄ±mlÄ±lÄ±k grafikleri) Ã¶zelliklerinizi nasÄ±l deÄŸerlendireceÄŸinizi Ã¶ÄŸrenirsiniz. Ã–zellikle ticari bir ortamda ML ile Ã§alÄ±ÅŸan herkes iÃ§in son derece faydalÄ±dÄ±r; burada projeler, mesajÄ±n ne kadar iyi iletildiÄŸine baÄŸlÄ± olarak varlÄ±klarÄ±nÄ± sÃ¼rdÃ¼rebilir.

* **AI Ethics**: [https://www.kaggle.com/learn/intro-to-ai-ethics](https://www.kaggle.com/learn/intro-to-ai-ethics)
Bu son kurs, sunumun oldukÃ§a ilginÃ§ bir eklemesi olarak karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor: AI sistemlerinin ahlaki tasarÄ±mÄ±na rehberlik edecek pratik araÃ§larÄ± tartÄ±ÅŸmaktadÄ±r. AI modellerindeki Ã¶nyargÄ±yÄ± nasÄ±l tanÄ±yacaÄŸÄ±nÄ±zÄ±, AI adaleti kavramÄ±nÄ± incelemenizi ve ML model bilgilerini nasÄ±l ileterek ÅŸeffaflÄ±ÄŸÄ± artÄ±racaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenirsiniz. UygulayÄ±cÄ±lar iÃ§in Ã§ok faydalÄ±dÄ±r, Ã§Ã¼nkÃ¼ "sorumlu yapay zeka" artÄ±k daha sÄ±k duyacaÄŸÄ±mÄ±z bir kavram olacaktÄ±r.

Kaggle tarafÄ±ndan oluÅŸturulan orijinal iÃ§eriÄŸin dÄ±ÅŸÄ±nda, platformda kullanÄ±cÄ±lar tarafÄ±ndan oluÅŸturulmuÅŸ Notebooks aracÄ±lÄ±ÄŸÄ±yla baÅŸka Ã¶ÄŸrenme fÄ±rsatlarÄ± da bulunmaktadÄ±r; okuyucularÄ±n bunlarÄ± kendi baÅŸlarÄ±na keÅŸfetmeleri teÅŸvik edilir.

> **Andrada Olteanu**
> 
> [https://www.kaggle.com/andradaolteanu](https://www.kaggle.com/andradaolteanu)
> 
> Andrada Olteanu, Kaggle Notebooks Grandmaster'larÄ±ndan biridir ve Notebooks'tan Ã¶ÄŸrenmeyi Ã§ok teÅŸvik etmektedir. Andrada, Z by HP Global Data Science Ambassador, Endava'da Veri Bilimci ve Weights & Biases'ta Dev Expert olarak gÃ¶rev yapmaktadÄ±r. Andrada ile Notebook yarÄ±ÅŸmalarÄ±, kariyeri ve daha fazlasÄ± hakkÄ±nda sohbet ettik.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Kaggle'da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Kaggle'daki uzmanlÄ±ÄŸÄ±m, verileri gÃ¶rselleÅŸtirme konusunda yoÄŸunlaÅŸÄ±yor, Ã§Ã¼nkÃ¼ bu alan bana sanatÄ± ve yaratÄ±cÄ±lÄ±ÄŸÄ± verilerle birleÅŸtirme imkanÄ± veriyor.
> 
> Kesinlikle favori bir yarÄ±ÅŸma tÃ¼rÃ¼m yok, ama daha Ã§ok zaman zaman deÄŸiÅŸim yapmak ve ilginÃ§ bulduÄŸum yarÄ±ÅŸmalarÄ± seÃ§mek hoÅŸuma gidiyor.
> 
> Kaggleâ€™Ä±n gÃ¼zelliÄŸi, bir kiÅŸinin Veri Biliminin birÃ§ok alanÄ±nÄ± (bilgisayarla gÃ¶rme, NLP, keÅŸifsel veri analizi ve istatistik, zaman serileri vb.) Ã¶ÄŸrenebilmesinin yanÄ± sÄ±ra birÃ§ok konuya (spor, tÄ±p, finans ve kripto paralar, dÃ¼nya Ã§apÄ±ndaki olaylar vb.) da aÅŸina olma fÄ±rsatÄ± sunmasÄ±dÄ±r.
> 
> AyrÄ±ca, Ã¶rneÄŸin metin verileriyle daha fazla deneyim kazanmak isteyen biri iÃ§in, neredeyse her zaman bir Kaggle YarÄ±ÅŸmasÄ±'nda NLP gereksinimi vardÄ±r. Ya da ses dosyalarÄ±yla nasÄ±l Ã¶n iÅŸleme yapÄ±lacaÄŸÄ± ve modellerin nasÄ±l kurulacaÄŸÄ± Ã¶ÄŸrenmek isteyen biri iÃ§in de bu beceriyi geliÅŸtirecek yarÄ±ÅŸmalar bulunabilir.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlu bir yarÄ±ÅŸmadan ve gÃ¶revi ele almak iÃ§in kullandÄ±ÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼lerden bahseder misiniz?**
> 
> KatÄ±ldÄ±ÄŸÄ±m en zorlu â€œyarÄ±ÅŸmaâ€ Kaggleâ€™Ä±n â€œVeri Bilimi ve Makine Ã–ÄŸrenimi YÄ±llÄ±k Anketiâ€ydi. Bu bir â€œgerÃ§ekâ€ yarÄ±ÅŸma deÄŸil â€“ yani bir liderlik tablosu ve aÄŸÄ±r makine Ã¶ÄŸrenimi gerekmiyor â€“ ancak benim iÃ§in katÄ±ldÄ±ÄŸÄ±m ve en Ã§ok ÅŸey Ã¶ÄŸrendiÄŸim yarÄ±ÅŸmalardan biriydi.
> 
> Bu bir Notebook yarÄ±ÅŸmasÄ±dÄ±r ve katÄ±lÄ±mcÄ±larÄ±n kazanmak iÃ§in yaratÄ±cÄ± olmalarÄ± gerekmektedir. Bu yarÄ±ÅŸmaya 2 yÄ±l Ã¼st Ã¼ste katÄ±ldÄ±m. Ä°lk yÄ±l (2020), daha â€œtemelâ€ gÃ¶rselleÅŸtirme becerilerimi test etti ve bana kutunun dÄ±ÅŸÄ±na Ã§Ä±kmamÄ± saÄŸladÄ± (3. oldum); ikinci yÄ±l (2021), 4 ay boyunca D3 Ã¶ÄŸrenerek bu alandaki gÃ¶rselleÅŸtirme becerilerimi bir Ã¼st seviyeye Ã§Ä±karmayÄ± hedefledim (hala incelemede; ÅŸu ana kadar â€œErken Notebook Ã–dÃ¼lÃ¼â€nÃ¼ kazandÄ±m). Burada verebileceÄŸim en iyi iÃ§gÃ¶rÃ¼ler ÅŸunlar:
> 
> * Ã–ncelikle veriye kaybolmayÄ±n ve olabildiÄŸince doÄŸru grafikler oluÅŸturmaya Ã§alÄ±ÅŸÄ±n; gerekirse, neyi temsil ettiÄŸinizin net ve Ã¶z olduÄŸundan emin olmak iÃ§in Ã§ift doÄŸrulama yÃ¶ntemleri oluÅŸturun. GÃ¼zel bir grafiÄŸin yanÄ±ltÄ±cÄ± iÃ§gÃ¶rÃ¼ler sunduÄŸu bir ÅŸeyden daha kÃ¶tÃ¼ bir ÅŸey yoktur.
> 
> * Ã‡evrenizde ilham kaynaÄŸÄ± arayÄ±n: doÄŸadan, filmlerden, iÅŸinizden. GÃ¶rselleÅŸtirmelerinizi canlandÄ±rmak iÃ§in harika temalar ve ilginÃ§ yollar bulabilirsiniz.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? YardÄ±mcÄ± olduysa nasÄ±l?**
> 
> Evet. MÃ¼him Ã¶lÃ§Ã¼de. Åu anda bulunduÄŸum noktada Kaggle'a bÃ¼yÃ¼k bir borcum olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum ve bunun iÃ§in sonsuza dek minnettarÄ±m. Kaggle sayesinde Z by HP Ambassador'Ä± oldum; ayrÄ±ca harika bir makine Ã¶ÄŸrenimi deney platformu olan Weights & Biases'Ä± keÅŸfettim ve ÅŸu anda onlarÄ±n gururlu bir Dev Expert'Ä±yÄ±m. Son olarak, bu platform sayesinde ÅŸu anda Endava'da Lead Data Scientist olarak gÃ¶rev yapan kiÅŸiyle tanÄ±ÅŸtÄ±m, o beni iÅŸe aldÄ± ve o zamandan beri onunla Ã§alÄ±ÅŸÄ±yorum. KÄ±sacasÄ±, Endava'daki pozisyonum ve HP ile Weights & Biases gibi 2 bÃ¼yÃ¼k ÅŸirketle olan baÄŸlantÄ±larÄ±m, Kaggle platformundaki faaliyetlerimin doÄŸrudan bir sonucu.
> 
> Bence Kaggle'Ä±n en gÃ¶zden kaÃ§an yÃ¶nÃ¼, topluluktur. Kaggle, birbirleriyle baÄŸlantÄ± kurup etkileÅŸimde bulunabilecek ve birbirlerinden Ã¶ÄŸrenebilecek dev bir insan havuzuna sahiptir.
> 
> Bunun en iyi ÅŸekilde nasÄ±l deÄŸerlendirileceÄŸiyle ilgili bir Ã¶rnek: Kaggleâ€™daki her bÃ¶lÃ¼mden (YarÄ±ÅŸmalar, Veri Setleri, Notebooks â€“ ve eÄŸer isterseniz, TartÄ±ÅŸmalar) ilk 100 kiÅŸiyi alÄ±n ve profilinde bu bilgiyi paylaÅŸan herkesin Twitter/LinkedIn hesaplarÄ±nÄ± takip edin. Bu ÅŸekilde, bu harika insanlarla dÃ¼zenli olarak etkileÅŸimde bulunabilir, iÃ§gÃ¶rÃ¼ ve bilgilerinden faydalanabilirsiniz.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±m en bÃ¼yÃ¼k hata, onlara katÄ±lmamaktÄ±. Bence bu, baÅŸlangÄ±Ã§ seviyesindeki kullanÄ±cÄ±larÄ±n platforma girdiÄŸinde yaptÄ±klarÄ± en bÃ¼yÃ¼k ve en temel hatadÄ±r.
> 
> Korku nedeniyle (ve burada kiÅŸisel deneyimimden konuÅŸuyorum), hazÄ±r olmadÄ±klarÄ±nÄ± veya nasÄ±l baÅŸlayacaklarÄ±nÄ± bilmediklerini dÃ¼ÅŸÃ¼nÃ¼yorlar. Neyse ki, basit bir sistem takip ederseniz, herhangi bir yarÄ±ÅŸmaya katÄ±lmak oldukÃ§a kolay hale gelir:
> 
> * Ä°lginizi Ã§eken herhangi bir yarÄ±ÅŸmaya katÄ±lÄ±n.
> 
> * TanÄ±tÄ±m sayfasÄ±nÄ± ve verileri keÅŸfedin.
> 
> * BaÅŸlamak iÃ§in fikriniz yoksa, endiÅŸelenmeyin! â€œKodâ€ kÄ±smÄ±na girin ve Ã§ok fazla oy almÄ±ÅŸ, ya da deneyimli kiÅŸiler tarafÄ±ndan yapÄ±lmÄ±ÅŸ Notebooks'larÄ± inceleyin, Ã¶rneÄŸin Grandmasters.
> 
> Bir â€œkodla birlikte Ã§alÄ±ÅŸâ€ Notebookâ€™u yapmaya baÅŸlayÄ±n, burada baÅŸkalarÄ±nÄ±n ne yaptÄ±ÄŸÄ±nÄ± inceleyin ve â€œkopyalayÄ±n,â€ araÅŸtÄ±rÄ±n ve kendiniz geliÅŸtirmeye Ã§alÄ±ÅŸÄ±n. Bence bu, Ã¶ÄŸrenmenin en iyi yoludur â€“ hiÃ§ takÄ±lmazsÄ±nÄ±z ve belirli bir projede yaparak Ã¶ÄŸrenirsiniz.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> UnutulmamasÄ± gereken en Ã¶nemli ÅŸey, baÅŸarÄ±sÄ±z olmanÄ±n tamamen normal olduÄŸudur, Ã§Ã¼nkÃ¼ genellikle en iyi Ã¶ÄŸrenme yolu budur.
> 
> AyrÄ±ca her zaman YarÄ±ÅŸma Grandmastersâ€™larÄ±ndan Ã¶ÄŸrenmeyi unutmamalÄ±dÄ±rlar, Ã§Ã¼nkÃ¼ genellikle, bir kiÅŸinin aklÄ±na gelmeyecek makine Ã¶ÄŸrenimi tekniklerini paylaÅŸan ve aÃ§Ä±klayan kiÅŸilerdir. Bir ÅŸeyi Ã¶ÄŸrenmenin en iyi yolu, zaten â€œbaÅŸarÄ±sÄ±nÄ±â€ kanÄ±tlamÄ±ÅŸ olanlarÄ± incelemektir, bÃ¶ylece baÅŸarÄ± yolunuz daha az engebeli, daha rahat, pÃ¼rÃ¼zsÃ¼z ve hÄ±zlÄ± olur. GerÃ§ekten hayran olduÄŸunuz 2-3 Grandmasterâ€™Ä± seÃ§in ve onlarÄ± Ã¶ÄŸretmenleriniz yapÄ±n; onlarÄ±n Notebooksâ€™larÄ±nÄ± inceleyin, birlikte kod yazÄ±n ve olabildiÄŸince Ã§ok ÅŸey Ã¶ÄŸrenin.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musunuz? Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±rsÄ±nÄ±z?**
> 
> HiÃ§ baÅŸka bir yarÄ±ÅŸma platformu kullanmadÄ±m â€“ Ã§Ã¼nkÃ¼ bence Kaggle her ÅŸeyi sunuyor.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, eÄŸitim ve deney yapma amacÄ±yla kullanÄ±labilen, ayrÄ±ca veri bilimi proje portfÃ¶yÃ¼nÃ¼zÃ¼ tanÄ±tmak iÃ§in de kullanÄ±labilen Ã§ok amaÃ§lÄ±, aÃ§Ä±k kodlama ortamlarÄ± olan Kaggle Notebooks'tan bahsettik. ArtÄ±k kendi Notebook'unuzu oluÅŸturma, mevcut kaynaklarÄ± verimli bir ÅŸekilde kullanma ve sonuÃ§larÄ± yarÄ±ÅŸmalar veya bireysel projeleriniz iÃ§in kullanma aÅŸamasÄ±na geldiniz.

Bir sonraki bÃ¶lÃ¼mde, Kaggle'da fikir ve gÃ¶rÃ¼ÅŸlerinizi paylaÅŸmanÄ±n birincil yolu olan tartÄ±ÅŸma forumlarÄ±nÄ± tanÄ±tacaÄŸÄ±z.

---

## Chapter 4: Leveraging Discussion Forums *(BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±nÄ± Etkin Kullanma)*

TartÄ±ÅŸma forumlarÄ±, Kaggle'daki bilgi alÄ±ÅŸveriÅŸinin birincil aracÄ±dÄ±r. Ä°ster devam eden bir yarÄ±ÅŸmayÄ± tartÄ±ÅŸmak, ister bir Veri Seti hakkÄ±nda konuÅŸmak, isterse yeni bir yaklaÅŸÄ±m sunan bir Notebook'u ele almak olsun, Kaggle kullanÄ±cÄ±larÄ± her zaman bir ÅŸeyler hakkÄ±nda konuÅŸurlar.

Bu bÃ¶lÃ¼mde, tartÄ±ÅŸma forumlarÄ±nÄ± tanÄ±tÄ±yoruz: nasÄ±l organize olduklarÄ±nÄ± ve iÃ§indeki bilgilerin nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± dÃ¼zenleyen davranÄ±ÅŸ kurallarÄ±nÄ±. AÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:
* ForumlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±
* Ã–rnek yarÄ±ÅŸmalar iÃ§in tartÄ±ÅŸma yaklaÅŸÄ±mlarÄ±
* Ä°nternette uygun davranÄ±ÅŸ (Netik)

### How forums work *(Forumlar nasÄ±l Ã§alÄ±ÅŸÄ±r)*

TartÄ±ÅŸma forumuna birkaÃ§ farklÄ± ÅŸekilde girebilirsiniz. En doÄŸrudan yol, sol paneldeki **TartÄ±ÅŸmalar** sekmesine tÄ±klamaktÄ±r:

![](im/1034.png)

Ãœst kÄ±sÄ±mda, genel konularÄ±n bir araya getirildiÄŸi **Forumlar** bulunur. Bunlara gÃ¶z atmak, ister ilk yarÄ±ÅŸmanÄ±za katÄ±lÄ±yor olun, ister bir Ã¶neriniz olsun, ister sadece kafanÄ±z karÄ±ÅŸtÄ±ÄŸÄ± iÃ§in genel bir soru sormak isteyin, oldukÃ§a faydalÄ±dÄ±r.

ForumlarÄ±n altÄ±nda, **Kaggle genelinde yapÄ±lan tartÄ±ÅŸmalarÄ±n birleÅŸik gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼** bulabilirsiniz. Bunlar Ã§oÄŸunlukla yarÄ±ÅŸmalarla ilgili sohbetlerdir (Ã§Ã¼nkÃ¼ Kaggleâ€™daki etkinliÄŸin bÃ¼yÃ¼k kÄ±smÄ±nÄ± yarÄ±ÅŸmalar oluÅŸturur), ancak bazen Notebooks (defterler) veya dikkat Ã§ekici veri kÃ¼meleriyle ilgili konuÅŸmalar da yer alÄ±r. VarsayÄ±lan olarak bu tartÄ±ÅŸmalar **"Hotness" (PopÃ¼lerlik)** sÄ±rasÄ±na gÃ¶re listelenir; yani katÄ±lÄ±mÄ± en yÃ¼ksek ve en aktif olanlar Ã¼st sÄ±ralarda gÃ¶rÃ¼nÃ¼r.

Bu bÃ¶lÃ¼m, alanÄ±n dinamik doÄŸasÄ±na daha uygun iÃ§erikleri bulabileceÄŸiniz yerdir: Kaggleâ€™Ä±n farklÄ± alt bÃ¶lÃ¼mlerinden gelen tartÄ±ÅŸmalarÄ±n bir koleksiyonu olup, belirli Ã¶lÃ§Ã¼tlere gÃ¶re **filtreleme yapma** olanaÄŸÄ± da sunar.

![](im/1035.png)

Ä°lgi alanlarÄ±nÄ±za baÄŸlÄ± olarak, iÃ§erikleri **filtreleri kullanarak kiÅŸiselleÅŸtirmeye** baÅŸlayabilirsiniz. Tercihlerinize gÃ¶re ÅŸu Ã¶lÃ§Ã¼tlere gÃ¶re filtreleme yapabilirsiniz:

* **RECENCY (GÃ¼ncellik):** Takip ettiÄŸiniz bilgilerin zaman aralÄ±ÄŸÄ±nÄ± kontrol etmenizi saÄŸlar.
* **MY ACTIVITY (Benim EtkinliÄŸim):** TÃ¼m forumlardaki yorumlarÄ±nÄ±zÄ±n, paylaÅŸÄ±mlarÄ±nÄ±zÄ±n ve gÃ¶rÃ¼ntÃ¼lemelerinizin genel bir Ã¶zetini verir; birden fazla tartÄ±ÅŸmaya aynÄ± anda katÄ±lÄ±yorsanÄ±z oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r.
* **ADMIN (YÃ¶netici):** Kaggle yÃ¶neticilerinin duyurularÄ±na hÄ±zlÄ± bir genel bakÄ±ÅŸ saÄŸlar.
* **TYPES (TÃ¼rler):** TartÄ±ÅŸmalar genel forumlarda, belirli yarÄ±ÅŸmalarda veya veri kÃ¼meleri etrafÄ±nda gerÃ§ekleÅŸebilir.
* **TAGS (Etiketler):** Her yerde bulunmasa da birÃ§ok tartÄ±ÅŸma etiketlenmiÅŸtir; bu iÅŸlev, kullanÄ±cÄ±larÄ±n bu Ã¶zelliÄŸi kullanarak belirli konulara gÃ¶re filtreleme yapmasÄ±na olanak tanÄ±r.

![](im/1036.png)

AÅŸaÄŸÄ±daki ÅŸekil, **Beginner (Yeni BaÅŸlayan)** etiketiyle filtrelenmiÅŸ tartÄ±ÅŸmalarÄ±n Ã¶rnek bir Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶stermektedir.

![](im/1037.png)

Alternatif olarak, belirli bir konuya da odaklanabilirsiniz; Ã¶rneÄŸin **bilgisayarla gÃ¶rme (computer vision)** gibi konular bÃ¼yÃ¼k ilgi Ã§ektiÄŸinden, konularÄ± **sÄ±ralamak** faydalÄ± olabilir. KonularÄ± ÅŸu Ã¶lÃ§Ã¼tlere gÃ¶re sÄ±ralayabilirsiniz:

* **Hotness (PopÃ¼lerlik):** En fazla ilgi ve katÄ±lÄ±m gÃ¶ren konular Ã¼stte gÃ¶sterilir.
* **Recent Comments (Son Yorumlar):** En son yorum yapÄ±lan konulara gÃ¶re sÄ±ralar.
* **Recently Posted (Yeni PaylaÅŸÄ±lanlar):** YakÄ±n zamanda oluÅŸturulan konulara Ã¶ncelik verir.
* **Most Votes (En Ã‡ok Oy Alanlar):** En fazla oyu almÄ±ÅŸ konularÄ± Ã¼stte gÃ¶sterir.
* **Most Comments (En Ã‡ok Yorum Alanlar):** En fazla yorum yapÄ±lan konularÄ± sÄ±ralar.

![](im/1038.png)

Ä°nsanlar **Kaggleâ€™a** farklÄ± nedenlerle gelirler; ancak **Notebooks**â€™larÄ±n popÃ¼laritesinin artmasÄ±na raÄŸmen, **yarÄ±ÅŸmalar** hÃ¢lÃ¢ temel Ã§ekim noktasÄ± olmaya devam etmektedir. Her Kaggle yarÄ±ÅŸmasÄ±nÄ±n kendine ait Ã¶zel bir **tartÄ±ÅŸma forumu** vardÄ±r. Bu foruma, yarÄ±ÅŸmanÄ±n sayfasÄ±na gidip **Discussion (TartÄ±ÅŸma)** sekmesini seÃ§erek eriÅŸebilirsiniz.

![](im/1039.png)

Eskiden bu her zaman bÃ¶yle deÄŸildi, ancak gÃ¼nÃ¼mÃ¼zde neredeyse tÃ¼m yarÄ±ÅŸmalarÄ±n, kendilerine ait tartÄ±ÅŸma forumlarÄ±nÄ±n en Ã¼st kÄ±smÄ±na sabitlenmiÅŸ bir **SSS (SÄ±kÃ§a Sorulan Sorular)** konusu bulunmaktadÄ±r. Bu bÃ¶lÃ¼mden baÅŸlamak iki temel nedenle iyi bir fikirdir:

* **Zamandan tasarruf edersiniz;** en popÃ¼ler sorularÄ±n yanÄ±tlarÄ± bÃ¼yÃ¼k olasÄ±lÄ±kla burada yer alÄ±r.
* **Gereksiz veya yinelenen sorular sormaktan kaÃ§Ä±nÄ±rsÄ±nÄ±z,** bÃ¶ylece forumdaki herkes iÃ§in daha iyi bir deneyim saÄŸlanmÄ±ÅŸ olur.

**Notebooks**â€™larda olduÄŸu gibi, tartÄ±ÅŸma forumlarÄ±nda da daha sonra tekrar bakmak Ã¼zere **Ã¶zellikle Ã¶nemli konularÄ± yer imlerine ekleme (bookmark)** seÃ§eneÄŸi bulunur.

![](im/1040.png)

Yer iÅŸareti eklediÄŸiniz (bookmarkladÄ±ÄŸÄ±nÄ±z) tÃ¼m konularÄ±n genel bir Ã¶zetini, **profil sayfanÄ±zda** bulabilirsiniz.

![](im/1041.png)

### Example discussion approaches *(TartÄ±ÅŸma Ã¶rnekleri ve yaklaÅŸÄ±mlar)*

Bir yarÄ±ÅŸmada kendinizi bir noktada kaybolmuÅŸ hissetmeniz tamamen normaldir: Geldiniz, birkaÃ§ fikir denediniz, sÄ±ralamada bir ilerleme kaydettiniz ve sonra Kaggle versiyonu ile koÅŸucularÄ±n duvarÄ±na Ã§arptÄ±nÄ±z. Ä°ÅŸte bu noktada tartÄ±ÅŸma forumlarÄ± baÅŸvurulacak yerdir.

Ã–rnek olarak, Optiver Realized Volatility Prediction yarÄ±ÅŸmasÄ±na bakalÄ±m ([https://www.kaggle.com/c/optiver-realized-volatility-prediction](https://www.kaggle.com/c/optiver-realized-volatility-prediction)). Organizasyon tarafÄ±ndan ÅŸÃ¶yle tanÄ±mlanmÄ±ÅŸ:

> Ä°lk Ã¼Ã§ ay boyunca, farklÄ± sektÃ¶rlerde yÃ¼zlerce hisse senedi iÃ§in kÄ±sa vadeli volatiliteyi tahmin eden modeller geliÅŸtireceksiniz. Elinizde yÃ¼z milyonlarca detaylÄ± finansal veri olacak ve bu verilerle 10 dakikalÄ±k periyotlar iÃ§in volatiliteyi tahmin eden bir model tasarlayacaksÄ±nÄ±z. Modelleriniz, eÄŸitim sonrasÄ± Ã¼Ã§ aylÄ±k deÄŸerlendirme dÃ¶neminde gerÃ§ek piyasa verileriyle karÅŸÄ±laÅŸtÄ±rÄ±larak deÄŸerlendirilecektir.

Burada ele alÄ±nacak Ã§ok ÅŸey var; bu yÃ¼zden bu zorluÄŸun ana bileÅŸenlerini inceleyip, tartÄ±ÅŸma forumlarÄ± aracÄ±lÄ±ÄŸÄ±yla nasÄ±l yaklaÅŸÄ±labileceÄŸini gÃ¶stereceÄŸiz. Ã–ncelikle, bu yarÄ±ÅŸmaya katÄ±lÄ±m belirli bir finansal bilgi gerektiriyor; belki deneyimli bir trader seviyesinde olmanÄ±z gerekmiyor, ama volatilitenin farklÄ± hesaplama yÃ¶ntemlerini anlamak, Ã§oÄŸu Kaggle katÄ±lÄ±mcÄ±sÄ± iÃ§in oldukÃ§a karmaÅŸÄ±ktÄ±r. Neyse ki organizatÃ¶rler yarÄ±ÅŸma boyunca oldukÃ§a aktifti ve yeni baÅŸlayanlar iÃ§in kaynaklar sundular: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273923](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273923)

EÄŸer baÅŸlangÄ±Ã§ bilgisi yeterli deÄŸilse, kamuya aÃ§Ä±k ÅŸekilde sorularÄ±nÄ±zÄ± sormaktan Ã§ekinmeyin, Ã¶rneÄŸin:
[https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/263039](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/263039)
veya
[https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250612](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250612)

YarÄ±ÅŸma ilerledikÃ§e, katÄ±lÄ±mcÄ±lar problemi Ã§Ã¶zmek iÃ§in giderek daha sofistike modeller geliÅŸtirmeye baÅŸladÄ±lar. Burada bir denge kurmak gerekiyor: bir yandan, veteriner katÄ±lÄ±mcÄ±lardan Ã¶ÄŸrendiklerinizi paylaÅŸarak geri vermek isteyebilirsiniz; diÄŸer yandan, tÃ¼m harika kodlarÄ±nÄ±zÄ± Notebook olarak paylaÅŸarak potansiyel avantajÄ±nÄ±zÄ± kaybetmek istemezsiniz. Makul bir orta yol, Ã¶rneÄŸin forumda Ã¶zellik fikirlerinizi paylaÅŸmak olabilir: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273915](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273915)

Son yÄ±llarda, daha fazla yarÄ±ÅŸma sabit test veri seti formatÄ±ndan uzaklaÅŸÄ±p farklÄ± yaklaÅŸÄ±mlar getirdi: bazÄ±larÄ± Kaggle API kullanÄ±mÄ±nÄ± zorunlu kÄ±lÄ±yor (Notebook Ã¼zerinden gÃ¶nderim yapmanÄ±z gerekiyor), bazÄ±larÄ± ise eÄŸitim ve canlÄ± veri deÄŸerlendirmesi olarak Ã¶zel bir zaman Ã§izelgesi sunuyor. Optiver yarÄ±ÅŸmasÄ± da bÃ¶yleydi:

> Final gÃ¶nderim tarihinden sonra, seÃ§ilen notebookâ€™lar Ã¼zerinde piyasa verisi gÃ¼ncellemelerine baÄŸlÄ± olarak sÄ±ralama tablosu periyodik olarak gÃ¼ncellenecektir. GÃ¼ncellemeler yaklaÅŸÄ±k iki haftada bir yapÄ±lacak ve tatil dÃ¶nemlerinden kaÃ§Ä±nmak iÃ§in ayarlamalar yapÄ±lacaktÄ±r.

Bu kurulum, modellerin yeniden eÄŸitilmesi ve gÃ¼ncellenmesi konusunda bazÄ± zorluklar yarattÄ±. Bu tÃ¼r bir durumla karÅŸÄ±laÅŸÄ±rsanÄ±z, katÄ±lÄ±mcÄ±larÄ±n yaptÄ±ÄŸÄ± gibi sorular sormaktan Ã§ekinmeyin: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/249752](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/249752)

EÄŸitilen modeliniz iÃ§in bir doÄŸrulama ÅŸemasÄ± her zaman Ã¶nemli bir konudur ve genellikle â€œCV vs LBâ€ (Ã§apraz doÄŸrulama vs sÄ±ralama tablosu) tartÄ±ÅŸmasÄ± ile baÄŸlantÄ±lÄ±dÄ±r. Optiver yarÄ±ÅŸmasÄ± da bu kuralÄ±n istisnasÄ± deÄŸildi: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250650](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250650)

EÄŸer ilgili baÅŸlÄ±k zaten yoksa â€“ ve bunu kontrol etmek her zaman iyi bir fikirdir â€“ tek model performansÄ±yla ilgili bir baÅŸlÄ±ÄŸÄ± dÃ¼ÅŸÃ¼nmek isteyebilirsiniz. Er ya da geÃ§ herkes model ansambllarÄ±nÄ± kullanmaya baÅŸlar, ancak iyi tek model bileÅŸenleri olmadan bunlar Ã§ok verimli deÄŸildir.

EÄŸer problemi Ã§Ã¶zmenin daha iyi bir yolunu bulduysanÄ±z, paylaÅŸmak genellikle iyi bir fikirdir. Ya baÅŸkalarÄ± iÃ§in faydalÄ± bir ÅŸey yapmÄ±ÅŸ olursunuz, ya da neden yanlÄ±ÅŸ olduÄŸunuzu Ã¶ÄŸrenirsiniz (zaman ve Ã§aba tasarrufu saÄŸlar); her iki durumda da kazanÃ§lÄ± Ã§Ä±karsÄ±nÄ±z: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/260694](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/260694)

Bunun dÄ±ÅŸÄ±nda, diÄŸer katÄ±lÄ±mcÄ±larÄ±n ne yaptÄ±ÄŸÄ±na gÃ¶z atmak ve topluluk iÃ§inde bilgi paylaÅŸÄ±mÄ±na katkÄ±da bulunmak kiÅŸisel fayda saÄŸlar ve Ã¶zellikle yeni baÅŸlayanlar iÃ§in yararlÄ±dÄ±r: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250695](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250695)

TÃ¼m bu konulara gÃ¶z attÄ±ysanÄ±z, hÃ¢lÃ¢ â€œÃ–nemli bir ÅŸeyi mi kaÃ§Ä±rÄ±yorum?â€ diye dÃ¼ÅŸÃ¼nebilirsiniz. Kaggle, bu tÃ¼r sorularÄ± sormanÄ±n tamamen kabul edildiÄŸi bir platformdur: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/262203](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/262203)

DiÄŸer yarÄ±ÅŸmalara gÃ¶z atalÄ±m. Daha Ã¶nce doÄŸrulama konusundan bahsettik; bu genellikle bilgi sÄ±zÄ±ntÄ±sÄ± ve aÅŸÄ±rÄ± uyum (overfitting) ile baÄŸlantÄ±lÄ±dÄ±r. SÄ±zÄ±ntÄ±lar, doÄŸrulama ÅŸemalarÄ±nÄ±n tasarlanmasÄ±na ayrÄ±lmÄ±ÅŸ olan 6. bÃ¶lÃ¼mde ayrÄ±ntÄ±lÄ± olarak ele alÄ±nmÄ±ÅŸtÄ±r. Burada, forumlar aracÄ±lÄ±ÄŸÄ±yla nasÄ±l ele alÄ±ndÄ±ÄŸÄ±nÄ± kÄ±saca inceleyeceÄŸiz. Kaggle, meraklÄ± katÄ±lÄ±mcÄ±lardan oluÅŸan bir topluluk olduÄŸundan, sÄ±zÄ±ntÄ± ÅŸÃ¼phesi varsa, biri konuyu muhtemelen gÃ¼ndeme getirir.

Ã–rneÄŸin, dosya adlarÄ± veya kayÄ±t IDâ€™leri zaman damgalarÄ± iÃ§erebilir, bu da geleceÄŸe bakmak ve hatalÄ± ÅŸekilde dÃ¼ÅŸÃ¼k hata metriÄŸi elde etmek iÃ§in tersine mÃ¼hendislik yapÄ±labileceÄŸi anlamÄ±na gelir. Bu durum, Two Sigma Connect yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870#176513](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870#176513)

BaÅŸka bir Ã¶rnek, Airbus Ship Detection Challengeâ€™dÄ±r, katÄ±lÄ±mcÄ±larÄ±n uydu gÃ¶rÃ¼ntÃ¼lerinde gemileri bulmasÄ± gerekiyordu. Test gÃ¶rÃ¼ntÃ¼lerinin Ã¶nemli bir kÄ±smÄ±, eÄŸitim gÃ¶rÃ¼ntÃ¼lerinden rastgele kÄ±rpÄ±lmÄ±ÅŸtÄ± ve eÅŸleÅŸtirmek oldukÃ§a kolaydÄ±: [https://www.kaggle.com/c/airbus-ship-detection/discussion/64355#377037](https://www.kaggle.com/c/airbus-ship-detection/discussion/64355#377037)

Santander tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalar da oldukÃ§a Ã¼nlÃ¼dÃ¼r. Åirketin dÃ¼zenlediÄŸi Ã¼Ã§ yarÄ±ÅŸmadan ikisinde veri sÄ±zÄ±ntÄ±sÄ± yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61172](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61172)

Sonraki adÄ±mlar yarÄ±ÅŸmadan yarÄ±ÅŸmaya deÄŸiÅŸir: BazÄ± durumlarda Kaggle, yarÄ±ÅŸmayÄ± yeni veya temizlenmiÅŸ verilerle yeniden baÅŸlatmÄ±ÅŸtÄ±r; bazen ise minimal etki algÄ±ladÄ±klarÄ± iÃ§in devam ettirmiÅŸtir. Ã–rneÄŸin, Predicting Red Hat Business Value yarÄ±ÅŸmasÄ±nda bÃ¶yle bir durum yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/23788](https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/23788)

Veri sÄ±zÄ±ntÄ±larÄ± yarÄ±ÅŸmayÄ± ciddi ÅŸekilde bozabilir, ancak iyi haber ÅŸu ki, son 2-3 yÄ±lda Kaggleâ€™da sÄ±zÄ±ntÄ±lar neredeyse tamamen ortadan kalkmÄ±ÅŸtÄ±r â€“ dolayÄ±sÄ±yla bu bÃ¶lÃ¼m, bir kez okunacak ama platformdaki deneyiminizin sÃ¼rekli bir parÃ§asÄ± olmayacaktÄ±r.

Platformdaki deneyim konusuna gelince, bu Grandmaster rÃ¶portajÄ±na mÃ¼kemmel bir geÃ§iÅŸtir.

> **Yifan Xie**
> 
> [https://www.kaggle.com/yifanxie](https://www.kaggle.com/yifanxie)
> 
> 
> 
> Yifan Xie, **Discussions ve Competitions Master** unvanÄ±na sahip ve aynÄ± zamanda **Arion.ai**â€™nin kurucu ortaÄŸÄ±dÄ±r. Ä°ÅŸte yarÄ±ÅŸmalara katÄ±lma ve diÄŸer Kaggle kullanÄ±cÄ±larÄ±yla Ã§alÄ±ÅŸma konusundaki gÃ¶rÃ¼ÅŸleri:
> 
> 
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™da uzmanlÄ±ÄŸÄ±n nedir?**
> 
> AslÄ±nda Ã¶zel bir favorim yok; her tÃ¼r problemi Ã§Ã¶zmeyi seviyorum. Teknik aÃ§Ä±dan, Ã§oÄŸu veri problemi Ã¼zerinde hÄ±zlÄ±ca uygulanabilecek tipik teknikleri ve algoritmalarÄ± kapsayan saÄŸlam bir **makine Ã¶ÄŸrenimi pipelineâ€™Ä±** geliÅŸtirdim. Bunu, iÅŸ rutinleri ve teknik araÃ§lar aÃ§Ä±sÄ±ndan standartlaÅŸtÄ±rmaya odaklanmÄ±ÅŸ bir **rekabet avantajÄ±** olarak gÃ¶rÃ¼yorum. Bu sayede daha hÄ±zlÄ± iterasyonlar yapabiliyor ve veri deneyleri sÄ±rasÄ±nda verimliliÄŸi artÄ±rabiliyorum; bu da Kaggle iÃ§in temel bir bileÅŸendir.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±n? Bu yaklaÅŸÄ±m gÃ¼nlÃ¼k iÅŸlerinden ne kadar farklÄ±?**
> 
> Zamanla, bÃ¼yÃ¼k veri projelerimin Ã§oÄŸu iÃ§in **bilgi yÃ¶netimi ve toplama** konusunda Ã¶zel bir yÃ¶ntem geliÅŸtirdim. Bu yaklaÅŸÄ±m, iÅŸ projeleri, Kaggle yarÄ±ÅŸmalarÄ± ve diÄŸer yan projeler iÃ§in uygulanabilir. Genellikle yararlÄ± bilgileri (bookmarkâ€™lar, veri sÃ¶zlÃ¼kleri, yapÄ±lacaklar listesi, komutlar, deney sonuÃ§larÄ±) her yarÄ±ÅŸma iÃ§in standart bir formatta toplarÄ±m ve bir takÄ±mda yarÄ±ÅŸÄ±yorsam bu bilgileri takÄ±m arkadaÅŸlarÄ±mla paylaÅŸÄ±rÄ±m.
> 
> 
> 
> **GirdiÄŸin Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±n iÃ§gÃ¶rÃ¼lerden bahseder misin?**
> 
> Benim iÃ§in yarÄ±ÅŸmanÄ±n **genel baÄŸlamÄ±nÄ± anlamak** her zaman faydalÄ± olmuÅŸtur; Ã¶rneÄŸin, verinin ortaya Ã§Ä±kmasÄ±na neden olan sosyal/mÃ¼hendislik/finans sÃ¼reÃ§leri nedir? Deepfake Detection Challenge gibi bireysel veri noktalarÄ±nÄ±n anlamlÄ± ÅŸekilde gÃ¶zlemlenebildiÄŸi yarÄ±ÅŸmalarda, genellikle **Streamlit** kullanarak Ã¶zel bir dashboard hazÄ±rlardÄ±m. Bu dashboard ile bireysel veri noktalarÄ±nÄ± (Ã¶rneÄŸin gerÃ§ek ve sahte video Ã§iftleri) kontrol edebilir ve basit istatistik toplama ile veriyi daha iyi anlayabilirdim.
> 
> 
> 
> **Kaggle kariyerine yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?**
> 
> Kaggle, ÅŸu anki kariyerimde, veri bilimi danÄ±ÅŸmanlÄ±k firmasÄ±nda eÅŸ sahip olarak yer almamda en bÃ¼yÃ¼k katkÄ±yÄ± saÄŸlayan platform oldu diyebilirim. YÄ±llar iÃ§inde farklÄ± alanlardaki veri problemlerini Ã§Ã¶zmek iÃ§in gerekli **beceri ve metodolojiyi** kazanmamÄ± saÄŸladÄ±. Hem mÃ¼ÅŸterilerim hem de ekip arkadaÅŸlarÄ±m, Kaggle yarÄ±ÅŸmalarÄ±nda kurduÄŸum takÄ±mlardan tanÄ±ÅŸtÄ±ÄŸÄ±m kiÅŸiler. Bu platform, bilgi kaynaÄŸÄ± olarak her zaman Ã§ok faydalÄ± oldu; gÃ¼nÃ¼mÃ¼zde daha az aktif olsam da.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r? BaÅŸladÄ±ÄŸÄ±nda bilmek istediÄŸin ÅŸey neydi?**
> 
> Yeni baÅŸlayanlarÄ±n sÄ±k yaptÄ±ÄŸÄ± hata, **kritik teknik olmayan konularÄ±** gÃ¶z ardÄ± etmeleridir: takÄ±m kurallarÄ±, veri kullanÄ±mÄ±, Ã¶zel bilgilerin paylaÅŸÄ±mÄ±, masum sebeplerle birden fazla hesap kullanÄ±mÄ± vb. Bu tÃ¼r hatalar, Ã§oÄŸu zaman aylardÄ±r sÃ¼ren yarÄ±ÅŸma Ã§alÄ±ÅŸmalarÄ±nÄ± tamamen geÃ§ersiz kÄ±labilir.
> 
> 
> 
> BaÅŸladÄ±ÄŸÄ±mda bilmek istediÄŸim bir diÄŸer ÅŸey ise, **gÃ¼nlÃ¼k public leaderboard pozisyonuna takÄ±lmamak** olurdu. Bu gereksiz baskÄ± yaratÄ±r ve overfittingâ€™e yol aÃ§ar.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nereceÄŸin araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Standart araÃ§lar: **Scikit-learn, XGB/LGB, PyTorch** vb.
> 
> Ancak temel kullanÄ±mÄ±n Ã¶tesinde herkesin **NumPyâ€™yi** iyi Ã¶ÄŸrenmesini Ã¶neririm; Ã¶zellikle verileri daha geliÅŸmiÅŸ ÅŸekilde sÄ±ralamak ve alt kÃ¼melere ayÄ±rmak iÃ§in. Pandas kolaylaÅŸtÄ±rÄ±r, ama NumPy ile daha verimli yÃ¶ntemler uygulanabilir.
> 
> 
> 
> **YarÄ±ÅŸmaya girerken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Bana gÃ¶re veri bilimi ile ilgili iÅŸleri yapmanÄ±n dÃ¶rt nedeni vardÄ±r: **kar, bilgi, eÄŸlence ve iyilik**. Kaggle benim iÃ§in her zaman **bÃ¼yÃ¼k bir bilgi kaynaÄŸÄ±** ve hatÄ±rlanacak bir hafÄ±za deposu olmuÅŸtur. Bu yÃ¼zden Ã¶nerim: **SÄ±ralamanÄ±n geÃ§ici, bilginin ve hafÄ±zanÄ±n kalÄ±cÄ± olduÄŸunu hatÄ±rlayÄ±n.**
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musun? Kaggle ile karÅŸÄ±laÅŸtÄ±rÄ±nca?**
> 
> Numeraiâ€™da oldukÃ§a aktifim. DÃ¶rt nedenim aÃ§Ä±sÄ±ndan, Numerai daha Ã§ok **kar amacÄ±yla** oluyor Ã§Ã¼nkÃ¼ Ã¶demeyi kripto para ile yapÄ±yorlar. Daha Ã§ok **bireysel Ã§aba** gerektiriyor; takÄ±m kurmak Ã§ok avantaj saÄŸlamÄ±yor.
> 
> 
> 
> Numerai, yoÄŸun iÅŸ takvimimde **Kaggleâ€™dan daha sÃ¼rdÃ¼rÃ¼lebilir** bir etkinlik Ã§Ã¼nkÃ¼ her turda eÄŸitim verisi genellikle deÄŸiÅŸmiyor. Ä°lk modeller kurulduktan sonra tahmin ve gÃ¶nderim sÃ¼reÃ§lerini **yÃ¼ksek derecede otomatikleÅŸtirebilirim**. AyrÄ±ca Numerai, tabular veri setleri iÃ§in Ã¶zel makine Ã¶ÄŸrenimi pipelineâ€™larÄ± geliÅŸtirmek isteyenler iÃ§in daha uygun bir platform.

### Netiquette *(Ä°nternet gÃ¶rgÃ¼ kurallarÄ±)*

Ä°nternette 15 dakikadan uzun sÃ¼re vakit geÃ§iren herkes bunu bilir: Bir tartÄ±ÅŸma sÄ±rasÄ±nda, konunun ne kadar masum olursa olsun, insanlarÄ±n duygusal tepkiler vermesi ve sohbetin medeni sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±na taÅŸmasÄ± her zaman mÃ¼mkÃ¼ndÃ¼r. Kaggle da bu kuralÄ±n istisnasÄ± deÄŸildir; bu yÃ¼zden topluluÄŸun **uygun davranÄ±ÅŸ kurallarÄ±** vardÄ±r: [https://www.kaggle.com/community-guidelines](https://www.kaggle.com/community-guidelines).

Bu kurallar yalnÄ±zca tartÄ±ÅŸmalara deÄŸil, **Notebooks** ve diÄŸer iletiÅŸim biÃ§imlerine de uygulanÄ±r. Kaggleâ€™da etkileÅŸimde bulunurken akÄ±lda tutulmasÄ± gereken baÅŸlÄ±ca noktalar ÅŸunlardÄ±r:

* **Zihinsel okuma yanÄ±lgÄ±sÄ±na dÃ¼ÅŸmeyin:** Scott Adamsâ€™Ä±n adlandÄ±rdÄ±ÄŸÄ± bu yanÄ±lgÄ±, insanlarÄ±n ne dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼ varsayma eÄŸilimidir. Kaggle, dÃ¼nyanÄ±n dÃ¶rt bir yanÄ±ndan gelen Ã§ok Ã§eÅŸitli bir topluluktur (Ã§oÄŸu iÃ§in Ä°ngilizce ikinci dil), bu nedenle nÃ¼ansÄ± korumak bÃ¼yÃ¼k bir zorluktur. VarsayÄ±mlarda bulunmayÄ±n ve mÃ¼mkÃ¼n olduÄŸunca netleÅŸtirmeye Ã§alÄ±ÅŸÄ±n.
* **Åahsi saldÄ±rÄ±lardan kaÃ§Ä±nÄ±n:** Godwinâ€™in yasasÄ± boÅŸuna yoktur. Ã–zellikle korunan ve deÄŸiÅŸtirilemez Ã¶zelliklere yÃ¶nelik referanslar kesinlikle yasaktÄ±r.
* **AÅŸaÄŸÄ±lamalardan kaÃ§Ä±nÄ±n:** Deneyimleriniz farklÄ± olabilir, ancak internetin 1990â€™larda â€œRTFMâ€ demenin normal olduÄŸu vahÅŸi batÄ± ortamÄ± artÄ±k yok. AÅŸaÄŸÄ±lamalar insanlarÄ± uzaklaÅŸtÄ±rÄ±r.
* **Ä°lerleme sistemini manipÃ¼le etmeye Ã§alÄ±ÅŸmayÄ±n:** Kaggle madalyalarÄ±nÄ±n verildiÄŸi bu sistemin manipÃ¼lasyonu, aÃ§Ä±kÃ§a oy istemekten, gizli anlaÅŸmalara, hatta doÄŸrudan hileye kadar platform kÃ¶tÃ¼ye kullanÄ±mÄ±nÄ±n tÃ¼m yelpazesini kapsar.

KÄ±saca, baÅŸkalarÄ±na kendinize davranÄ±lmasÄ±nÄ± istediÄŸiniz ÅŸekilde davranÄ±n, her ÅŸey yolunda gider.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle platformunda iletiÅŸimin birincil yolu olan **tartÄ±ÅŸma forumlarÄ±nÄ±** ele aldÄ±k. Forum mekaniklerini gÃ¶sterdik, tartÄ±ÅŸmalarÄ±n daha geliÅŸmiÅŸ yarÄ±ÅŸmalarda nasÄ±l kullanÄ±labileceÄŸine dair Ã¶rnekler sunduk ve tartÄ±ÅŸma **netiketi**ni kÄ±saca Ã¶zetledik.

Bu, kitabÄ±n ilk ve giriÅŸ niteliÄŸindeki bÃ¶lÃ¼mÃ¼nÃ¼n sonunu iÅŸaret ediyor. Bir sonraki bÃ¶lÃ¼m, Kaggleâ€™dan elde edeceÄŸiniz verimi **maksimize etme** konusunda daha derin bir incelemenin baÅŸlangÄ±cÄ±nÄ± oluÅŸturuyor ve yarÄ±ÅŸmalarda karÅŸÄ±laÅŸmanÄ±z gereken Ã§ok Ã§eÅŸitli gÃ¶revler ve metriklerle baÅŸa Ã§Ä±kmayÄ± ele alÄ±yor.

---

# Part II: Sharpening Your Skills for Competitions *(BÃ¶lÃ¼m II: YarÄ±ÅŸmalar Ä°Ã§in Becerilerini GeliÅŸtirme)*

## Chapter 5: Competition Tasks and Metrics *(BÃ¶lÃ¼m 5: YarÄ±ÅŸma GÃ¶revleri ve Ã–lÃ§Ã¼tleri)*

Bir yarÄ±ÅŸmada, iÅŸe hedef metriÄŸi inceleyerek baÅŸlarsÄ±nÄ±z. Modelinizin hatalarÄ±nÄ±n nasÄ±l deÄŸerlendirildiÄŸini anlamak, her yarÄ±ÅŸmada yÃ¼ksek puan alabilmek iÃ§in kritik Ã¶neme sahiptir. Tahminleriniz Kaggle platformuna gÃ¶nderildiÄŸinde, hedef metrik temel alÄ±narak gerÃ§ek deÄŸerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

Ã–rneÄŸin, Titanic yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/titanic/](https://www.kaggle.com/c/titanic/)) tÃ¼m gÃ¶nderimleriniz doÄŸruluk (accuracy) temelinde deÄŸerlendirilir; yani, hayatta kalan yolcularÄ± doÄŸru tahmin etme yÃ¼zdesi. Organizasyon bu metriÄŸi seÃ§miÅŸtir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n amacÄ±, benzer koÅŸullar altÄ±nda bir yolcunun hayatta kalma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin edebilen bir model bulmaktÄ±r.

BaÅŸka bir bilgi yarÄ±ÅŸmasÄ±nda, House Prices - Advanced Regression Techniques ([https://www.kaggle.com/c/house-prices-advanced-regression-techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)), Ã§alÄ±ÅŸmalarÄ±nÄ±z tahmininiz ile gerÃ§ek deÄŸer arasÄ±ndaki ortalama fark temelinde deÄŸerlendirilir. Bu, logaritmayÄ± almayÄ±, karesini almayÄ± ve karekÃ¶kÃ¼nÃ¼ hesaplamayÄ± iÃ§erir; Ã§Ã¼nkÃ¼ modelden, satÄ±ÅŸta olan bir evin fiyat sÄ±rasÄ±nÄ± olabildiÄŸince doÄŸru bir ÅŸekilde tahmin etmesi beklenir.

GerÃ§ek dÃ¼nyadaki veri bilimi projelerinde de hedef metrikler, projenin baÅŸarÄ±sÄ± iÃ§in kritiktir; ancak gerÃ§ek dÃ¼nya ile Kaggle yarÄ±ÅŸmalarÄ± arasÄ±nda bazÄ± farklÄ±lÄ±klar vardÄ±r. Ã–zetle, gerÃ§ek dÃ¼nyada iÅŸler daha karmaÅŸÄ±ktÄ±r. GerÃ§ek dÃ¼nya projelerinde modeliniz genellikle yalnÄ±zca bir deÄŸil, birden fazla metrikle deÄŸerlendirilecektir. SÄ±klÄ±kla bazÄ± deÄŸerlendirme metrikleri, test iÃ§in kullandÄ±ÄŸÄ±nÄ±z gerÃ§ek deÄŸerlerle tahminlerinizin performansÄ± ile doÄŸrudan iliÅŸkili olmayabilir.

Ã–rneÄŸin, Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z bilgi alanÄ±, projenin kapsamÄ±, modelinizin dikkate aldÄ±ÄŸÄ± Ã¶zellik sayÄ±sÄ±, genel bellek kullanÄ±mÄ±, Ã¶zel donanÄ±m gereksinimleri (Ã¶r. GPU), tahmin sÃ¼recinin gecikmesi, modelin karmaÅŸÄ±klÄ±ÄŸÄ± ve diÄŸer birÃ§ok faktÃ¶r, yalnÄ±zca tahmin performansÄ±ndan daha fazla Ã¶nem taÅŸÄ±yabilir.

GerÃ§ek dÃ¼nyadaki problemler, dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼zden Ã§ok daha fazla iÅŸ ve teknik altyapÄ± kaygÄ±larÄ± tarafÄ±ndan ÅŸekillendirilir.

Yine de, hem gerÃ§ek dÃ¼nya projelerinde hem de Kaggle yarÄ±ÅŸmalarÄ±nda temel prensip aynÄ±dÄ±r: Ã‡alÄ±ÅŸmanÄ±z belirli kriterlere gÃ¶re deÄŸerlendirilecektir. Bu kriterlerin detaylarÄ±nÄ± anlamak, modelinizi akÄ±llÄ±ca optimize etmek veya parametrelerini bu kriterlere gÃ¶re seÃ§mek baÅŸarÄ± getirir. Kaggleâ€™da model deÄŸerlendirmesinin nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenebilirseniz, gerÃ§ek dÃ¼nyadaki veri bilimi iÅŸiniz de bundan fayda saÄŸlar.

Bu bÃ¶lÃ¼mde, belirli problem tÃ¼rleri iÃ§in deÄŸerlendirme metriklerinin, veri bilimi yarÄ±ÅŸmalarÄ±nda model Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururken nasÄ±l hareket edebileceÄŸinizi gÃ¼Ã§lÃ¼ bir ÅŸekilde etkilediÄŸini detaylÄ± olarak inceleyeceÄŸiz. AyrÄ±ca, Kaggle yarÄ±ÅŸmalarÄ±nda bulunan Ã§eÅŸitli metrikleri ele alarak, hangi metriklerin daha Ã¶nemli olduÄŸunu anlamanÄ±zÄ± saÄŸlayacaÄŸÄ±z ve yan not olarak metriklerin tahmin performansÄ± Ã¼zerindeki farklÄ± etkilerini ve bunlarÄ± projelerinize nasÄ±l doÄŸru ÅŸekilde aktarabileceÄŸinizi tartÄ±ÅŸacaÄŸÄ±z.

Bu bÃ¶lÃ¼mde ele alÄ±nacak konular:

* DeÄŸerlendirme metrikleri ve amaÃ§ fonksiyonlarÄ±
* Temel gÃ¶rev tÃ¼rleri: regresyon, sÄ±nÄ±flandÄ±rma ve sÄ±ralÄ± (ordinal)
* Meta Kaggle veri seti
* Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerin ele alÄ±nmasÄ±
* Regresyon metrikleri (standart ve ordinal)
* Ä°kili sÄ±nÄ±flandÄ±rma metrikleri (etiket tahmini ve olasÄ±lÄ±k)
* Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri
* Nesne tespit problemleri iÃ§in metrikler
* Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri sistemleri metrikleri
* DeÄŸerlendirme metriklerini optimize etme

### Evaluation metrics and objective functions *(DeÄŸerlendirme metrikleri ve hedef fonksiyonlar)*

Bir Kaggle yarÄ±ÅŸmasÄ±nda, deÄŸerlendirme metriÄŸini yarÄ±ÅŸmanÄ±n **Overview (Genel BakÄ±ÅŸ)** sayfasÄ±nÄ±n sol menÃ¼sÃ¼nden bulabilirsiniz. **Evaluation (DeÄŸerlendirme)** sekmesini seÃ§tiÄŸinizde, metriÄŸe iliÅŸkin detaylarÄ± gÃ¶rebilirsiniz. Bazen burada metrik formÃ¼lÃ¼, metrikle ilgili yeniden Ã¼retim kodu ve metrik hakkÄ±nda bazÄ± tartÄ±ÅŸmalar da bulunur. AynÄ± sayfada, ayrÄ±ca gÃ¶nderim dosyasÄ± formatÄ± hakkÄ±nda aÃ§Ä±klamalar yer alÄ±r; dosyanÄ±n baÅŸlÄ±k satÄ±rÄ± ve birkaÃ§ Ã¶rnek satÄ±r gÃ¶sterilir.

DeÄŸerlendirme metriÄŸi ile gÃ¶nderim dosyasÄ± arasÄ±ndaki iliÅŸki Ã¶nemlidir, Ã§Ã¼nkÃ¼ metrik esasen modelinizi eÄŸitip tahminleri Ã¼rettikten sonra iÅŸler. DolayÄ±sÄ±yla ilk adÄ±m olarak, **deÄŸerlendirme metriÄŸi ile amaÃ§ fonksiyonu arasÄ±ndaki farkÄ±** anlamalÄ±sÄ±nÄ±z.

Temel olarak Ã¶zetlersek:

* **AmaÃ§ fonksiyonu (objective function)**, modelinizi eÄŸitirken kullanÄ±lÄ±r; hata minimizasyonu veya skor maksimizasyonu sÃ¼recinde yer alÄ±r.
* **DeÄŸerlendirme metriÄŸi (evaluation metric)** ise model eÄŸitildikten sonra bir skor saÄŸlar. Bu nedenle doÄŸrudan modelin veriyle uyumunu etkilemez, ancak dolaylÄ± olarak etkiler: en iyi hiperparametre ayarlarÄ±nÄ± seÃ§menize ve rekabet eden modeller arasÄ±nda en iyi modelleri belirlemenize yardÄ±mcÄ± olur.

BÃ¶lÃ¼mÃ¼n geri kalanÄ±nda, bunun bir Kaggle yarÄ±ÅŸmasÄ±nÄ± nasÄ±l etkileyebileceÄŸini ve neden yarÄ±ÅŸmadaki deÄŸerlendirme metriÄŸinin analizinin ilk adÄ±mÄ±nÄ±z olmasÄ± gerektiÄŸini gÃ¶stereceÄŸiz. Ã–nce, tartÄ±ÅŸma forumlarÄ±nda sÄ±kÃ§a karÅŸÄ±laÅŸabileceÄŸiniz bazÄ± terimleri ele alalÄ±m.

Genellikle **objective function, cost function ve loss function** terimlerini birbirinin yerine duyarÄ±z, ama hepsi tam olarak aynÄ± ÅŸey deÄŸildir:

* **Loss function (KayÄ±p fonksiyonu):** Tek bir veri noktasÄ± Ã¼zerine tanÄ±mlanÄ±r ve modelin tahmini ile gerÃ§ek deÄŸer arasÄ±ndaki ceza miktarÄ±nÄ± hesaplar.
* **Cost function (Maliyet fonksiyonu):** EÄŸitim iÃ§in kullanÄ±lan tÃ¼m veri setini (veya bir batchâ€™ini) dikkate alÄ±r ve veri noktalarÄ±nÄ±n kayÄ±p fonksiyonlarÄ± Ã¼zerinden toplam veya ortalama hesaplar. L1 veya L2 ceza terimleri gibi ek kÄ±sÄ±tlamalarÄ± iÃ§erebilir. Maliyet fonksiyonu doÄŸrudan eÄŸitim sÃ¼recini etkiler.
* **Objective function (AmaÃ§ fonksiyonu):** Makine Ã¶ÄŸrenimi eÄŸitiminde optimizasyon kapsamÄ±yla ilgili en genel terimdir; maliyet fonksiyonlarÄ±nÄ± iÃ§erir ama onlarla sÄ±nÄ±rlÄ± deÄŸildir. Ã–rneÄŸin, tahmin edilen modelin katsayÄ±larÄ±nÄ±n seyrek olmasÄ±nÄ± veya katsayÄ± deÄŸerlerinin minimize edilmesini gerektiren L1/L2 regularizasyonlarÄ± gibi hedefleri de iÃ§erebilir. Loss ve cost fonksiyonlarÄ± genellikle minimizasyona dayalÄ± iken, amaÃ§ fonksiyonu nÃ¶trdÃ¼r ve hem maximizasyon hem minimizasyon amaÃ§lÄ± optimizasyonu kapsayabilir.

Benzer ÅŸekilde, deÄŸerlendirme metriklerinde de **scoring function (skor fonksiyonu)** ve **error function (hata fonksiyonu)** terimlerini duyabilirsiniz:

* **Scoring function:** Fonksiyonun skoru yÃ¼ksek olduÄŸunda tahminler daha iyi kabul edilir; bu bir **maksimizasyon** sÃ¼recini ifade eder.
* **Error function:** Fonksiyonun hata deÄŸeri daha kÃ¼Ã§Ã¼k olduÄŸunda tahminler daha iyi kabul edilir; bu bir **minimizasyon** sÃ¼recini ifade eder.

### Basic types of tasks *(Temel gÃ¶rev tÃ¼rleri)*

TÃ¼m amaÃ§ fonksiyonlarÄ± her problem iÃ§in uygun deÄŸildir. Genel bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla, Kaggle yarÄ±ÅŸmalarÄ±nda iki tÃ¼r problem bulursunuz: **regresyon gÃ¶revleri** ve **sÄ±nÄ±flandÄ±rma gÃ¶revleri**.

Son zamanlarda, bazÄ± yarÄ±ÅŸmalarda **reinforcement learning (RL â€“ pekiÅŸtirmeli Ã¶ÄŸrenme)** gÃ¶revleri de gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Ancak RL, deÄŸerlendirme iÃ§in metrik kullanmaz; bunun yerine, Ã§Ã¶zÃ¼mleri sizin Ã§Ã¶zÃ¼mÃ¼nÃ¼z kadar iyi olduÄŸu varsayÄ±lan diÄŸer katÄ±lÄ±mcÄ±larla doÄŸrudan karÅŸÄ±laÅŸtÄ±rmalardan tÃ¼retilen bir sÄ±ralamaya dayanÄ±r. Bu karÅŸÄ±laÅŸtÄ±rmada diÄŸer katÄ±lÄ±mcÄ±lardan daha iyi performans gÃ¶sterirseniz sÄ±ralamanÄ±z yÃ¼kselir, daha kÃ¶tÃ¼ performans gÃ¶sterirseniz dÃ¼ÅŸer.

RL metrik kullanmadÄ±ÄŸÄ± iÃ§in, biz hÃ¢lÃ¢ **regresyon-sÄ±nÄ±flandÄ±rma ikiliÄŸini** temel alacaÄŸÄ±z. Ancak **ordinal gÃ¶revler** (sÄ±ralÄ± etiketleri, genellikle tamsayÄ±larla temsil edilen, tahmin ettiÄŸiniz gÃ¶revler) bu kategorilere tam olarak uymayabilir. Ordinal gÃ¶revler, regresyon veya sÄ±nÄ±flandÄ±rma yaklaÅŸÄ±mlarÄ±ndan biriyle baÅŸarÄ±yla ele alÄ±nabilir.

#### Regression *(Regresyon)*

**Regresyon**, gerÃ§ek bir sayÄ± tahmin edebilen bir model kurmanÄ±zÄ± gerektirir; Ã§oÄŸunlukla pozitif bir sayÄ± tahmin edilir, ancak negatif sayÄ± tahmini yapÄ±lan Ã¶rnekler de olmuÅŸtur.

Regresyon problemlerine klasik bir Ã¶rnek, **House Prices - Advanced Regression Techniques** yarÄ±ÅŸmasÄ±dÄ±r; Ã§Ã¼nkÃ¼ burada bir evin deÄŸerini tahmin etmeniz gerekir.

Bir regresyon gÃ¶revinde deÄŸerlendirme, tahminleriniz ile gerÃ§ek deÄŸerler arasÄ±ndaki **farkÄ±n Ã¶lÃ§Ã¼lmesi** ile yapÄ±lÄ±r. Bu fark farklÄ± yollarla deÄŸerlendirilebilir:

* **Karesini almak**, yani hatalarÄ± daha bÃ¼yÃ¼k olan tahminleri daha fazla cezalandÄ±rmak,
* **Logaritma uygulamak**, yani yanlÄ±ÅŸ Ã¶lÃ§eklerdeki tahminleri cezalandÄ±rmak iÃ§in.

#### Classification *(SÄ±nÄ±flandÄ±rma)*

Kaggleâ€™da bir **sÄ±nÄ±flandÄ±rma (classification)** gÃ¶revi ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda dikkate alÄ±nmasÄ± gereken daha fazla nÃ¼ans vardÄ±r. SÄ±nÄ±flandÄ±rma, aslÄ±nda **ikili (binary), Ã§ok sÄ±nÄ±flÄ± (multi-class) veya Ã§ok etiketli (multi-label)** olabilir.

* **Ä°kili sÄ±nÄ±flandÄ±rma (binary problems):**
  Bir Ã¶rneÄŸin belirli bir sÄ±nÄ±fa ait olup olmadÄ±ÄŸÄ±nÄ± tahmin etmeniz gerekir (genellikle â€œpozitif sÄ±nÄ±fâ€ olarak adlandÄ±rÄ±lÄ±r ve â€œnegatif sÄ±nÄ±fâ€ ile karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r).
  Burada deÄŸerlendirme, doÄŸrudan sÄ±nÄ±f tahminine dayanabilir veya sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ±nÄ±n tahmin edilmesini gerektirebilir.
  Ã–rnek: **Titanic** yarÄ±ÅŸmasÄ±; burada ikili bir sonuÃ§ tahmin edersiniz: hayatta kalma veya kalmama. YarÄ±ÅŸma Ã§oÄŸu zaman sadece tahmini ister, ancak bazÄ± alanlardaâ€”Ã¶zellikle tÄ±p uygulamalarÄ±ndaâ€”pozitif tahminleri farklÄ± seÃ§enekler ve durumlar arasÄ±nda sÄ±ralamak gerekebilir, bu yÃ¼zden olasÄ±lÄ±k tahmini gerekir.

* **Dengesiz sÄ±nÄ±flar (imbalanced classes):**
  Ä°kili sÄ±nÄ±flandÄ±rmada doÄŸru eÅŸleÅŸmelerin sayÄ±sÄ±nÄ± doÄŸrudan saymak mantÄ±klÄ± gÃ¶rÃ¼nse de, pozitif ve negatif sÄ±nÄ±flar arasÄ±nda Ã¶rnek sayÄ±sÄ± farklÄ± olduÄŸunda bu yÃ¶ntem iyi Ã§alÄ±ÅŸmaz.
  Dengesiz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±, model geliÅŸtirmelerini doÄŸru ÅŸekilde takip edebilmek iÃ§in **dengeyi dikkate alan deÄŸerlendirme metrikleri** gerektirir.

* **Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma (multi-class):**
  Ä°ki sÄ±nÄ±ftan fazlasÄ± varsa, bu bir **Ã§ok sÄ±nÄ±flÄ± tahmin problemi**dir. Bu durumda, modelin genel performansÄ±nÄ± izlemek ve sÄ±nÄ±flar arasÄ±ndaki performansÄ±n karÅŸÄ±laÅŸtÄ±rÄ±labilir olmasÄ±nÄ± saÄŸlamak iÃ§in uygun metrikler kullanmak gerekir.
  Ã–rnek: **Leaf Classification** yarÄ±ÅŸmasÄ±; burada her yaprak Ã¶rneÄŸinin doÄŸru bitki tÃ¼rÃ¼ ile eÅŸleÅŸtirilmesi gerekir.

* **Ã‡ok etiketli sÄ±nÄ±flandÄ±rma (multi-label):**
  EÄŸer her Ã¶rnek iÃ§in birden fazla sÄ±nÄ±f tahmin edilebiliyorsa, bu bir **Ã§ok etiketli problem**dir. Bu durumda, modelin doÄŸru sÄ±nÄ±flarÄ±, doÄŸru sayÄ± ve karÄ±ÅŸÄ±mÄ± tahmin edip etmediÄŸini kontrol etmek iÃ§in ek deÄŸerlendirmeler gerekir.
  Ã–rnek: **Greek Media Monitoring Multilabel Classification (WISE 2014)**; burada her makale, iÅŸlediÄŸi tÃ¼m konularla iliÅŸkilendirilmeliydi.

#### Ordinal *(SÄ±ralÄ± veriler)*

Bir **ordinal Ã¶lÃ§ekli tahmin probleminde**, tam sayÄ± ÅŸeklinde etiketleri tahmin etmeniz gerekir; bu etiketler doÄŸal olarak sÄ±ralÄ±dÄ±r.
Ã–rnek: Bir depremin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ordinal bir Ã¶lÃ§ektedir.
AyrÄ±ca, pazarlama araÅŸtÄ±rmalarÄ± anketlerinden elde edilen veriler de sÄ±klÄ±kla ordinal Ã¶lÃ§ekle kaydedilir (Ã¶rneÄŸin, tÃ¼ketici tercihleri veya fikir uyumu).

Ordinal Ã¶lÃ§ek **sÄ±ralÄ± deÄŸerlerden** oluÅŸtuÄŸu iÃ§in, ordinal gÃ¶revler hem regresyon hem de sÄ±nÄ±flandÄ±rma yÃ¶ntemleriyle Ã§Ã¶zÃ¼lebilir; yani adeta bu iki yÃ¶ntem arasÄ±nda bir geÃ§iÅŸ niteliÄŸindedir.

* **Ã‡ok sÄ±nÄ±flÄ± problem olarak yaklaÅŸmak:**
  Ordinal gÃ¶revi Ã§ok sÄ±nÄ±flÄ± bir problem gibi ele almak en yaygÄ±n yaklaÅŸÄ±mdÄ±r. Bu durumda, bir tam sayÄ± deÄŸeri (sÄ±nÄ±f etiketi) tahmin edersiniz, ancak tahmin **sÄ±nÄ±flarÄ±n sÄ±ralÄ± olduÄŸunu dikkate almaz**.
  EÄŸer sÄ±nÄ±flar iÃ§in tahmin olasÄ±lÄ±klarÄ±nÄ± incelerseniz, problem Ã¼zerinde Ã§ok sÄ±nÄ±flÄ± bir yaklaÅŸÄ±mÄ±n eksiklerini fark edebilirsiniz. OlasÄ±lÄ±klar genellikle tÃ¼m olasÄ± deÄŸerler boyunca daÄŸÄ±lÄ±r; bu, **Ã§ok modlu ve genellikle simetrik olmayan bir daÄŸÄ±lÄ±m** oluÅŸturur. Halbuki doÄŸru yaklaÅŸÄ±mda, maksimum olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±f etrafÄ±nda **Gaussian benzeri bir daÄŸÄ±lÄ±m** beklenir.

* **Regresyon problemine dÃ¶nÃ¼ÅŸtÃ¼rmek:**
  Ordinal tahmin problemini regresyon olarak ele alÄ±p ardÄ±ndan post-processing yapmak baÅŸka bir yaklaÅŸÄ±mdÄ±r. Bu yÃ¶ntemle, sÄ±nÄ±flar arasÄ±ndaki sÄ±ralama dikkate alÄ±nÄ±r, ancak tahmin Ã§Ä±ktÄ±sÄ± hemen deÄŸerlendirme metriÄŸinde kullanÄ±labilir deÄŸildir.
  Regresyonda Ã§Ä±ktÄ± bir tam sayÄ± deÄŸil, **float bir sayÄ±**dÄ±r ve bu sayÄ± ordinal daÄŸÄ±lÄ±mÄ±nÄ±zdaki tam sayÄ±lar arasÄ±ndaki tÃ¼m deÄŸerleri (ve hatta bazen sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±ndaki deÄŸerleri) iÃ§erebilir. Ã‡Ä±ktÄ± deÄŸerlerini kÄ±rpÄ±p birim yuvarlamasÄ±yla tam sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rmek iÅŸe yarayabilir, ancak bu yÃ¶ntem bazÄ± hatalara yol aÃ§abilir ve daha sofistike bir post-processing gerekebilir (bunun detaylarÄ± ilerleyen bÃ¶lÃ¼mlerde ele alÄ±nacaktÄ±r).

Åimdi muhtemelen merak ediyorsunuz: **Kaggleâ€™da baÅŸarÄ±lÄ± olmak iÃ§in hangi deÄŸerlendirme metriklerini bilmemiz gerekir?**
AÃ§Ä±kÃ§a, her zaman katÄ±ldÄ±ÄŸÄ±nÄ±z yarÄ±ÅŸmanÄ±n **deÄŸerlendirme metriÄŸini** iyi bilmelisiniz. Ancak bazÄ± metrikler diÄŸerlerinden daha yaygÄ±ndÄ±r; bu bilgiyi kendi avantajÄ±nÄ±za kullanabilirsiniz.

* **SÄ±k kullanÄ±lan metrikler nelerdir?**
* **Benzer deÄŸerlendirme metrikleri kullanan yarÄ±ÅŸmalardan ipuÃ§larÄ±nÄ± nasÄ±l bulabilirsiniz?**

Bunun cevabÄ±: **Meta Kaggle veri setini** incelemektir.

### The Meta Kaggle dataset *(Meta Kaggle veri seti)*

**Meta Kaggle veri seti** ([https://www.kaggle.com/kaggle/meta-kaggle](https://www.kaggle.com/kaggle/meta-kaggle)), Kaggle topluluÄŸu ve aktiviteleri hakkÄ±nda zengin veri iÃ§eren, Kaggle tarafÄ±ndan yayÄ±mlanmÄ±ÅŸ bir halka aÃ§Ä±k veri setidir.
Veri seti, **Competitions, Datasets, Notebooks ve Discussions** gibi Kaggleâ€™daki kamuya aÃ§Ä±k aktiviteleri iÃ§eren CSV tablolarÄ±ndan oluÅŸur.

KullanÄ±mÄ± oldukÃ§a basittir:

1. Bir **Kaggle Notebook** baÅŸlatÄ±n (BÃ¶lÃ¼m 2 ve 3â€™te gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi).
2. Notebookâ€™a **Meta Kaggle veri setini** ekleyin.
3. Verileri analiz etmeye baÅŸlayÄ±n.

CSV tablolarÄ± gÃ¼nlÃ¼k olarak gÃ¼ncellenir, bu yÃ¼zden analizlerinizi sÄ±k sÄ±k yenilemeniz gerekir, ama Ã§Ä±karacaÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼ler buna deÄŸecektir.

Bu kitapta, Meta Kaggle veri setine hem **yarÄ±ÅŸmalardaki dinamikler iÃ§in ilginÃ§ Ã¶rnekler bulmak** hem de **Ã¶ÄŸrenme ve yarÄ±ÅŸma stratejileriniz iÃ§in faydalÄ± Ã¶rnekler Ã§Ä±karmak** iÃ§in atÄ±fta bulunacaÄŸÄ±z.

Burada veri setini, **son yedi yÄ±lda hangi deÄŸerlendirme metriklerinin en sÄ±k kullanÄ±ldÄ±ÄŸÄ±nÄ±** anlamak iÃ§in kullanacaÄŸÄ±z. Bu metrikleri gÃ¶rerek:

* Herhangi bir yarÄ±ÅŸmaya saÄŸlam bir temel ile baÅŸlayabilir,
* ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±ndan elde ettiÄŸiniz bilgilerle metrik hakkÄ±nda yarÄ±ÅŸmaya Ã¶zgÃ¼ ince ayrÄ±ntÄ±larÄ± Ã¶ÄŸrenebilirsiniz.

---

AÅŸaÄŸÄ±daki kod, **yÄ±llara gÃ¶re kullanÄ±lan metriklerin ve sayÄ±larÄ±nÄ± tablo hÃ¢line getirmek** iÃ§in gerekli Ã¶rnek kodu gÃ¶stermektedir. Kod, doÄŸrudan Kaggle platformunda Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r:

```python
import numpy as np
import pandas as pd

# Competitions CSV tablosunu oku
comps = pd.read_csv("/kaggle/input/meta-kaggle/Competitions.csv")

# Ä°lgilenilen sÃ¼tunlar
evaluation = ['EvaluationAlgorithmAbbreviation',
              'EvaluationAlgorithmName',
              'EvaluationAlgorithmDescription',]

compt = ['Title', 'EnabledDate', 'HostSegmentTitle']

# Analiz iÃ§in kopya DataFrame oluÅŸtur
df = comps[compt + evaluation].copy()
df['year'] = pd.to_datetime(df.EnabledDate).dt.year.values
df['comps'] = 1

# 2015 ve sonrasÄ± yarÄ±ÅŸmalarÄ± seÃ§
time_select = df.year >= 2015

# Featured ve Research tÃ¼rÃ¼ndeki yarÄ±ÅŸmalar
competition_type_select = df.HostSegmentTitle.isin(['Featured', 'Research'])

# Pivot tablo oluÅŸtur ve yÄ±llara gÃ¶re metrik sayÄ±sÄ±nÄ± hesapla
pd.pivot_table(df[time_select & competition_type_select],
               values='comps',
               index=['EvaluationAlgorithmAbbreviation'],
               columns=['year'],
               fill_value=0.0,
               aggfunc=np.sum,
               margins=True
              ).sort_values(by=('All'), ascending=False).iloc[1:, :].head(20)
```

Kodun iÅŸleyiÅŸi:

1. Competitions CSVâ€™si okunur.
2. Sadece analiz iÃ§in gerekli sÃ¼tunlar seÃ§ilir: **deÄŸerlendirme algoritmasÄ±, yarÄ±ÅŸma adÄ±, baÅŸlama tarihi ve yarÄ±ÅŸma tÃ¼rÃ¼**.
3. SatÄ±rlar, 2015 sonrasÄ± ve **Featured veya Research tÃ¼rÃ¼ndeki yarÄ±ÅŸmalar** ile sÄ±nÄ±rlanÄ±r (en yaygÄ±n olanlar).
4. **Pivot tablo** ile deÄŸerlendirme algoritmalarÄ± yÄ±llara gÃ¶re gruplanÄ±r ve her birinin kaÃ§ yarÄ±ÅŸmada kullanÄ±ldÄ±ÄŸÄ± sayÄ±lÄ±r.
5. Son olarak **en Ã§ok kullanÄ±lan 20 algoritma** gÃ¶rÃ¼ntÃ¼lenir.

![](im/1042.png)

AynÄ± tablolarÄ± oluÅŸturmak iÃ§in az Ã¶nce baÅŸlattÄ±ÄŸÄ±mÄ±z deÄŸiÅŸkenleri kullanarak, ayrÄ±ca veriyi kontrol edip seÃ§tiÄŸiniz metriÄŸin kullanÄ±ldÄ±ÄŸÄ± yarÄ±ÅŸmalarÄ± da bulabilirsiniz:

```python
metric = 'AUC'
metric_select = df['EvaluationAlgorithmAbbreviation'] == metric
print(df[time_select & competition_type_select & metric_select][['Title', 'year']])
```

YukarÄ±daki Ã¶rnekte, AUC metriÄŸini kullanan yarÄ±ÅŸmalarÄ± temsil etmeye karar verdik. Sadece seÃ§tiÄŸiniz metriÄŸi temsil eden stringâ€™i deÄŸiÅŸtirmeniz yeterlidir; bÃ¶ylece ortaya Ã§Ä±kan liste buna gÃ¶re gÃ¼ncellenecektir.

Tabloya geri dÃ¶nersek, Kaggleâ€™da dÃ¼zenlenen yarÄ±ÅŸmalarda en popÃ¼ler deÄŸerlendirme metriklerini inceleyebiliriz:

* Ä°lk iki metrik birbirine ve ikili olasÄ±lÄ±k sÄ±nÄ±flandÄ±rma problemlerine yakÄ±ndan iliÅŸkilidir. AUC metriÄŸi, modelinizin tahmin ettiÄŸi olasÄ±lÄ±klarÄ±n pozitif Ã¶rnekleri yÃ¼ksek olasÄ±lÄ±kla tahmin etme eÄŸilimini Ã¶lÃ§meye yardÄ±mcÄ± olur. Log Loss ise tahmin edilen olasÄ±lÄ±klarÄ±n gerÃ§ek deÄŸerlerden ne kadar uzak olduÄŸunu Ã¶lÃ§er (ve Log Lossâ€™u optimize ettikÃ§e AUC metriÄŸini de optimize etmiÅŸ olursunuz).
* 3\. sÄ±rada MAP@{K} bulunur; bu metrik Ã¶neri sistemleri ve arama motorlarÄ±nda yaygÄ±n olarak kullanÄ±lÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda bu metrik, Ã§oÄŸunlukla bilgi getirme (information retrieval) deÄŸerlendirmeleri iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Ã–rneÄŸin, **Humpback Whale Identification** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/humpback-whale-identification](https://www.kaggle.com/c/humpback-whale-identification)) bir balinayÄ± tam olarak tanÄ±mlamanÄ±z gerekir ve beÅŸ tahmin hakkÄ±nÄ±z vardÄ±r. BaÅŸka bir Ã¶rnek, **Quick, Draw! Doodle Recognition Challenge** yarÄ±ÅŸmasÄ±dÄ±r ([https://www.kaggle.com/c/quickdraw-doodle-recognition/](https://www.kaggle.com/c/quickdraw-doodle-recognition/)), burada Ã§izilen bir karenin iÃ§eriÄŸini tahmin etmeniz gerekir ve Ã¼Ã§ deneme hakkÄ±nÄ±z vardÄ±r. Temelde, MAP@{K} metriÄŸi kullanÄ±ldÄ±ÄŸÄ±nda, sadece doÄŸru tahmin yapÄ±p yapmadÄ±ÄŸÄ±nÄ±z deÄŸil, aynÄ± zamanda doÄŸru tahmininizin belirli bir sayÄ±da (â€œKâ€ adÄ±yla belirtilen) yanlÄ±ÅŸ tahmin arasÄ±nda olup olmadÄ±ÄŸÄ± da deÄŸerlendirilir.
* 6\. sÄ±rada bir regresyon metriÄŸi olan RMSLE (Root Mean Squared Logarithmic Error) yer alÄ±r ve 7. sÄ±rada Quadratic Weighted Kappa bulunur; bu metrik, ardÄ±ÅŸÄ±k tamsayÄ± tahminleri gerektiren problemler (ordinal Ã¶lÃ§ek problemleri) iÃ§in Ã¶zellikle faydalÄ±dÄ±r.

Listeye gÃ¶z attÄ±ÄŸÄ±nÄ±zda, karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z metriklerin Ã§oÄŸunun makine Ã¶ÄŸrenmesi ders kitaplarÄ±nda sÄ±kÃ§a tartÄ±ÅŸÄ±lan metrikler olduÄŸunu gÃ¶receksiniz. Ã–nÃ¼mÃ¼zdeki birkaÃ§ bÃ¶lÃ¼mde, daha Ã¶nce hiÃ§ karÅŸÄ±laÅŸmadÄ±ÄŸÄ±nÄ±z bir metriÄŸi gÃ¶rdÃ¼ÄŸÃ¼nÃ¼zde ne yapmanÄ±z gerektiÄŸini tartÄ±ÅŸtÄ±ktan sonra, regresyon ve sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmalarÄ±nda en yaygÄ±n olarak kullanÄ±lan metrikleri gÃ¶zden geÃ§ireceÄŸiz.

### Handling never-before-seen metrics *(Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerle baÅŸa Ã§Ä±kma)*

Ä°lerlemeye baÅŸlamadan Ã¶nce, en popÃ¼ler 20 metriÄŸi gÃ¶steren tablonun yarÄ±ÅŸmalarda kullanÄ±lan tÃ¼m metrikleri kapsamadÄ±ÄŸÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±yÄ±z. Son yÄ±llarda yalnÄ±zca bir kez kullanÄ±lmÄ±ÅŸ metrikler de vardÄ±r.

**YarÄ±ÅŸma GÃ¶revleri ve Metrikler**

Ã–nceki kod sonuÃ§larÄ±nÄ± kullanarak, bu nadir kullanÄ±lan metriklerin neler olduÄŸunu bulmaya devam edelim:

```python
counts = (df[time_select & competition_type_select]
          .groupby('EvaluationAlgorithmAbbreviation'))
total_comps_per_year = (df[time_select & competition_type_select]
                        .groupby('year').sum())
single_metrics_per_year = (counts.sum()[counts.sum().comps == 1]
                           .groupby('year').sum())
single_metrics_per_year
table = (total_comps_per_year.rename(columns={'comps': 'n_comps'})
         .join(single_metrics_per_year / total_comps_per_year)
         .rename(columns={'comps': 'pct_comps'}))
print(table)
```

SonuÃ§ olarak, her yÄ±l iÃ§in aÅŸaÄŸÄ±daki tabloyu elde ederiz. Bu tabloda, her yÄ±l kaÃ§ yarÄ±ÅŸmanÄ±n daha sonra bir daha kullanÄ±lmamÄ±ÅŸ bir metrik kullandÄ±ÄŸÄ±nÄ± (`n_comps`) ve bu yarÄ±ÅŸmalarÄ±n toplam yarÄ±ÅŸmalara oranÄ±nÄ± (`pct_comps`) gÃ¶rebiliriz:

| year | n_comps | pct_comps |
| ---- | ------- | --------- |
| 2015 | 28      | 0.179     |
| 2016 | 19      | 0.158     |
| 2017 | 34      | 0.177     |
| 2018 | 35      | 0.229     |
| 2019 | 36      | 0.278     |
| 2020 | 43      | 0.302     |
| 2021 | 8       | 0.250     |

Daha sonra bir daha kullanÄ±lmamÄ±ÅŸ metriklerin payÄ±na baktÄ±ÄŸÄ±mÄ±zda, bu oranÄ±n yÄ±l geÃ§tikÃ§e arttÄ±ÄŸÄ±nÄ± ve son yÄ±llarda %25â€“%30 seviyelerine ulaÅŸtÄ±ÄŸÄ±nÄ± hemen fark ederiz. Bu, genellikle her Ã¼Ã§ veya dÃ¶rt yarÄ±ÅŸmadan birinin size metrikleri baÅŸtan Ã¶ÄŸrenip anlamayÄ± gerektirdiÄŸini gÃ¶sterir.

GeÃ§miÅŸte kullanÄ±lmÄ±ÅŸ ve bir daha tekrar edilmeyen metriklerin listesini ÅŸu kÄ±sa kodla alabilirsiniz:

```python
print(counts.sum()[counts.sum().comps == 1].index.values)
```

Bu kodu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, benzer bir liste elde edersiniz:

```
['AHD@{Type}', 'CVPRAutoDrivingAveragePrecision', 'CernWeightedAuc',
 'FScore_1', 'GroupMeanLogMAE', 'ImageNetObjectLocalization',
 'IndoorLocalization', 'IntersectionOverUnionObjectSegmentationBeta',
 'IntersectionOverUnionObjectSegmentationWithClassification',
 'IntersectionOverUnionObjectSegmentationWithF1', 'Jaccard',
 'JaccardDSTLParallel', 'JigsawBiasAUC', 'LaplaceLogLikelihood',
 'LevenshteinMean', 'Lyft3DObjectDetectionAP', 'M5_WRMSSE', 'MASpearmanR',
 'MCRMSE', 'MCSpearmanR', 'MWCRMSE', 'MeanColumnwiseLogLoss',
 'MulticlassLossOld', 'NDCG@{K}', 'NQMicroF1', 'NWRMSLE', 'PKUAutoDrivingAP',
 'R2Score', 'RValue', 'RootMeanSquarePercentageError', 'SIIMDice', 'SMAPE',
 'SantaResident', 'SantaRideShare', 'SantaWorkshopSchedule2019', 'TrackML',
 'TravelingSanta2', 'TwoSigmaNews', 'WeightedAUC', 'WeightedMulticlassLoss',
 'WeightedPinballLoss', 'WeightedRowwisePinballLoss', 'YT8M_MeanAveragePrecisionAtK',
 'ZillowMAE', 'football', 'halite', 'mab']
```

YakÄ±ndan incelendiÄŸinde, listede derin Ã¶ÄŸrenme ve pekiÅŸtirmeli Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ±na iliÅŸkin birÃ§ok metrik bulabilirsiniz.

Peki, daha Ã¶nce hiÃ§ karÅŸÄ±laÅŸmadÄ±ÄŸÄ±nÄ±z bir metrikle karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda ne yapmalÄ±sÄ±nÄ±z?

* Tabii ki, Kaggle tartÄ±ÅŸma forumlarÄ±ndaki paylaÅŸÄ±mlara gÃ¼venebilirsiniz; burada her zaman iyi fikirler ve size yardÄ±mcÄ± olacak birÃ§ok Kaggle katÄ±lÄ±mcÄ±sÄ± bulabilirsiniz.
* Ancak metriÄŸi kendi baÅŸÄ±nÄ±za anlamak istiyorsanÄ±z, Googleâ€™da arama yapmanÄ±n yanÄ± sÄ±ra, deÄŸerlendirme fonksiyonunu kendi kodunuzla denemeyi tavsiye ederiz. Bunu mÃ¼kemmel olmasa bile yapabilir, modelin farklÄ± hata tÃ¼rlerine karÅŸÄ± metrik nasÄ±l tepki veriyor simÃ¼le edebilirsiniz. AyrÄ±ca metrik fonksiyonunu yarÄ±ÅŸma eÄŸitim verisi Ã¶rnekleri Ã¼zerinde veya sizin hazÄ±rladÄ±ÄŸÄ±nÄ±z sentetik veri Ã¼zerinde test edebilirsiniz.

BazÄ± Kaggle kullanÄ±cÄ±larÄ±nÄ±n bu yaklaÅŸÄ±mÄ± nasÄ±l kullandÄ±ÄŸÄ±na Ã¶rnekler:

* **Carlo Lepelaars** ile Spearmanâ€™s Rho: [Link](https://www.kaggle.com/carlolepelaars/understanding-the-metric-spearman-s-rho)
* **Carlo Lepelaars** ile Quadratic Weighted Kappa: [Link](https://www.kaggle.com/carlolepelaars/understanding-the-metric-quadratic-weighted-kappa)
* **Rohan Rao** ile Laplace Log Likelihood: [Link](https://www.kaggle.com/rohanrao/osic-understanding-laplace-log-likelihood)

Bu yaklaÅŸÄ±m, deÄŸerlendirme sÃ¼reci hakkÄ±nda daha derin bir anlayÄ±ÅŸ kazandÄ±rÄ±r ve sadece Google ve forumlardan gelen cevaplara gÃ¼venen rakiplere karÅŸÄ± size avantaj saÄŸlar.

> **Rohan Rao**
> 
> [Kaggle Profili](https://www.kaggle.com/rohanrao)
> 
> 
> 
> FarklÄ± metrikleri keÅŸfetmeye baÅŸlamadan Ã¶nce, Quadruple Grandmaster ve H2O.aiâ€™de KÄ±demli Veri Bilimcisi olan Rohan Rao (namÄ± diÄŸer Vopani) ile Kaggleâ€™daki baÅŸarÄ±larÄ±nÄ± ve bizlerle paylaÅŸmak istediÄŸi bilgeliÄŸi konuÅŸalÄ±m.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±ÄŸÄ±nÄ±z nedir?**
> 
> FarklÄ± yarÄ±ÅŸma tÃ¼rleriyle ilgilenmeyi seviyorum, ama en favorim kesinlikle zaman serisi yarÄ±ÅŸmalarÄ±. EndÃ¼strideki tipik zaman serisi yaklaÅŸÄ±mlarÄ±nÄ± ve kavramlarÄ±nÄ± pek sevmiyorum, bu yÃ¼zden Ã§Ã¶zÃ¼mleri alÄ±ÅŸÄ±lmÄ±ÅŸÄ±n dÄ±ÅŸÄ±nda, yenilikÃ§i bir ÅŸekilde kurmayÄ± tercih ediyorum ve bu bana Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar getirdi.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±?**
> 
> Her Kaggle yarÄ±ÅŸmasÄ± iÃ§in tipik iÅŸ akÄ±ÅŸÄ±m ÅŸÃ¶yle:
> 
> 
> 
> * Problem tanÄ±mÄ±nÄ± anlamak ve kurallar, format, zaman Ã§izelgesi, veri setleri, metrikler ve teslimatlar ile ilgili tÃ¼m bilgileri okumak.
> 
> * Veriye derinlemesine dalmak. Veriyi her aÃ§Ä±dan inceleyip dilimleyip gÃ¶rselleÅŸtirerek her tÃ¼rlÃ¼ soruya cevap verebilecek hÃ¢le gelmek.
> 
> * Basit bir pipeline ve temel bir model kurup, sÃ¼recin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrulamak iÃ§in bir gÃ¶nderim yapmak.
> 
> * Ã–zellik mÃ¼hendisliÄŸi yapmak, hiperparametreleri ayarlamak ve hangi modellerin genellikle iÅŸe yaradÄ±ÄŸÄ±nÄ± anlamak iÃ§in Ã§eÅŸitli modellerle denemeler yapmak.
> 
> * Veriyi analiz etmeye, forum tartÄ±ÅŸmalarÄ±nÄ± okumaya ve Ã¶zellikleri ile modelleri sÃ¼rekli olarak geliÅŸtirmeye devam etmek. Belki bir noktada ekip kurmak.
> 
> * Birden fazla modeli ensemble yapmak ve hangi gÃ¶nderimleri final olarak kullanacaÄŸÄ±nÄ±za karar vermek.
> 
> 
> 
> GÃ¼nlÃ¼k veri bilimi Ã§alÄ±ÅŸmalarÄ±mda bunlarÄ±n Ã§oÄŸu da gerÃ§ekleÅŸiyor. Ama ek olarak iki kritik unsur var:
> 
> 
> 
> * Problem tanÄ±mÄ± iÃ§in veri setlerini hazÄ±rlamak ve dÃ¼zenlemek.
> 
> * Nihai model veya Ã§Ã¶zÃ¼mÃ¼ Ã¼retime almak.
> 
> 
> 
> GeÃ§miÅŸte Ã§alÄ±ÅŸtÄ±ÄŸÄ±m projelerin Ã§oÄŸunda zamanÄ±mÄ±n bÃ¼yÃ¼k kÄ±smÄ± bu iki aktiviteye harcandÄ±.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? Olduysa nasÄ±l?**
> 
> Makine Ã¶ÄŸrenmesinde Ã¶ÄŸrendiÄŸim ÅŸeylerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu Kaggleâ€™dan geldi. Topluluk, platform ve iÃ§erik gerÃ§ekten paha biÃ§ilemez; Ã¶ÄŸrenilecek inanÄ±lmaz miktarda bilgi var.
> 
> Kaggle yarÄ±ÅŸmalarÄ±na katÄ±lmak, sorunlarÄ± anlamak, yapÄ±landÄ±rmak ve Ã§Ã¶zmek konusunda bana bÃ¼yÃ¼k gÃ¼ven kazandÄ±rdÄ±. Bu deneyimi, Kaggle dÄ±ÅŸÄ±nda Ã§alÄ±ÅŸtÄ±ÄŸÄ±m ÅŸirketler ve projelerde baÅŸarÄ±yla uygulayabildim.
> 
> BirÃ§ok iÅŸe alÄ±m gÃ¶revlisi, Kaggleâ€™daki baÅŸarÄ±larÄ±mÄ± (Ã¶zellikle yarÄ±ÅŸmalarda) gÃ¶rerek benimle iletiÅŸime geÃ§ti. Bu, adayÄ±n veri bilimi problemlerini Ã§Ã¶zme yeteneÄŸini gÃ¶steren iyi bir gÃ¶stergedir ve yeteneklerinizi sergilemek ve portfÃ¶y oluÅŸturmak iÃ§in harika bir platformdur.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar oldu mu?**
> 
> Her yarÄ±ÅŸmada bazÄ± hatalar yaptÄ±m! BÃ¶ylece Ã¶ÄŸrenip geliÅŸiyorsunuz. Bazen bir kod hatasÄ±, bazen yanlÄ±ÅŸ bir doÄŸrulama kurulumu, bazen de yanlÄ±ÅŸ bir gÃ¶nderim seÃ§imi olabiliyor.
> 
> Ã–nemli olan bu hatalardan ders almak ve tekrar etmemeyi saÄŸlamaktÄ±r. Bu sÃ¼reci tekrar etmek, Kaggleâ€™daki genel performansÄ±nÄ±zÄ± otomatik olarak artÄ±rÄ±r.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> HiÃ§bir teknolojiye â€œbaÄŸlanmamakâ€ gerektiÄŸine inanÄ±yorum. En iyi Ã§alÄ±ÅŸan, en rahat ve en etkili olanÄ± kullanÄ±n, ama sÃ¼rekli olarak yeni araÃ§lar ve kÃ¼tÃ¼phaneler Ã¶ÄŸrenmeye aÃ§Ä±k olun.

### Metrics for regression (standard and ordinal) *(Regresyon iÃ§in metrikler - standart ve sÄ±ralÄ±)*

Regresyon problemleriyle Ã§alÄ±ÅŸÄ±rken, yani sÃ¼rekli bir deÄŸeri tahmin etmeyi gerektiren (eksi sonsuzdan artÄ± sonsuza kadar deÄŸiÅŸebilen) problemlerle uÄŸraÅŸÄ±rken, en yaygÄ±n kullanÄ±lan hata Ã¶lÃ§Ã¼leri RMSE (karekÃ¶k ortalama kare hata) ve MAE (ortalama mutlak hata) yÃ¶ntemleridir. Ancak, RMSLE veya MCRMSLE gibi biraz farklÄ± hata Ã¶lÃ§Ã¼leri de faydalÄ± olabilir.

#### Mean squared error (MSE) and RÂ² *(Ortalama kare hata (MSE) ve RÂ²)*

KarekÃ¶k ortalama kare hata (RMSE), ortalama kare hatanÄ±n (MSE) karekÃ¶kÃ¼dÃ¼r. MSE, aslÄ±nda regresyon Ã§alÄ±ÅŸmasÄ±nÄ± Ã¶ÄŸrenirken tanÄ±ÅŸtÄ±ÄŸÄ±nÄ±z eski iyi hata kareleri toplamÄ±nÄ±n (SSE) ortalamasÄ±ndan baÅŸka bir ÅŸey deÄŸildir.

**MSE formÃ¼lÃ¼ ÅŸu ÅŸekildedir:**

$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (\hat{y_i} - y_i)^2
$$

FormÃ¼lÃ¼n iÅŸleyiÅŸini aÃ§Ä±klayalÄ±m:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.
* Ã–nce tahminler ile gerÃ§ek deÄŸerler arasÄ±ndaki farkÄ± alÄ±rsÄ±nÄ±z.
* FarklarÄ± kareye alÄ±rsÄ±nÄ±z (pozitif ya da sÄ±fÄ±r olur).
* TÃ¼m kareleri toplarsÄ±nÄ±z; iÅŸte bu sizin SSEâ€™nizdir.
* Son olarak, SSEâ€™yi tahmin sayÄ±sÄ±na bÃ¶lerek ortalama deÄŸeri (MSE) elde edersiniz.

Genellikle tÃ¼m regresyon modelleri SSEâ€™yi minimize eder, bu yÃ¼zden MSEâ€™yi veya MSEâ€™den tÃ¼retilmiÅŸ RÂ² (determinasyon katsayÄ±sÄ±) gibi metrikleri minimize etmekte bÃ¼yÃ¼k sorun yaÅŸamazsÄ±nÄ±z. RÂ² ÅŸÃ¶yle hesaplanÄ±r:

$$
R^2 = 1 - \frac{\sum_{i=1}^{n} (\hat{y_i} - y_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

Burada SSE (hata kareleri toplamÄ±), toplam kareler toplamÄ±na (SST) karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r. SST, aslÄ±nda hedef deÄŸiÅŸkenin varyansÄ±dÄ±r ve ÅŸu ÅŸekilde tanÄ±mlanÄ±r:

$$
SST = \sum_{i=1}^{n} (y_i - \bar{y})^2
$$

BaÅŸka bir deyiÅŸle, RÂ² modelin hata karelerini, en basit model olan hedefin ortalamasÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±r. SSE ve SST aynÄ± Ã¶lÃ§eÄŸe sahip olduÄŸu iÃ§in RÂ², hedef deÄŸiÅŸkeni dÃ¶nÃ¼ÅŸtÃ¼rmenin tahminleri iyileÅŸtirip iyileÅŸtirmediÄŸini anlamanÄ±za yardÄ±mcÄ± olabilir.

> UnutmayÄ±n: min-max Ã¶lÃ§ekleme veya standardizasyon gibi lineer dÃ¶nÃ¼ÅŸÃ¼mler, herhangi bir regresyon modelinin performansÄ±nÄ± deÄŸiÅŸtirmez; Ã§Ã¼nkÃ¼ bunlar hedefin lineer dÃ¶nÃ¼ÅŸÃ¼mÃ¼dÃ¼r. Ancak karekÃ¶k, kÃ¼p kÃ¶k, logaritma, Ã¼s alma gibi **lineer olmayan dÃ¶nÃ¼ÅŸÃ¼mler** ve bunlarÄ±n kombinasyonlarÄ±, regresyon modelinizin deÄŸerlendirme metriÄŸi Ã¼zerindeki performansÄ±nÄ± kesinlikle deÄŸiÅŸtirebilir (doÄŸru dÃ¶nÃ¼ÅŸÃ¼mÃ¼ seÃ§erseniz genellikle daha iyi olur).

MSE, aynÄ± probleme uygulanan regresyon modellerini karÅŸÄ±laÅŸtÄ±rmak iÃ§in mÃ¼kemmel bir araÃ§tÄ±r. Ancak kÃ¶tÃ¼ haber ÅŸu ki, Kaggle yarÄ±ÅŸmalarÄ±nda genellikle MSE kullanÄ±lmaz; RMSE tercih edilir. Ã‡Ã¼nkÃ¼ MSEâ€™nin karekÃ¶kÃ¼nÃ¼ almak, deÄŸerleri hedefin orijinal Ã¶lÃ§eÄŸine yaklaÅŸtÄ±rÄ±r ve modelinizin performansÄ±nÄ± gÃ¶zle kontrol etmek kolaylaÅŸÄ±r. AyrÄ±ca, farklÄ± veri problemleri veya yarÄ±ÅŸmalar arasÄ±nda aynÄ± regresyon modelini deÄŸerlendiriyorsanÄ±z, RÂ² daha kullanÄ±ÅŸlÄ±dÄ±r; Ã§Ã¼nkÃ¼ MSE ile tamamen iliÅŸkili olup 0 ile 1 arasÄ±nda deÄŸer alÄ±r ve tÃ¼m karÅŸÄ±laÅŸtÄ±rmalarÄ± kolaylaÅŸtÄ±rÄ±r.

#### Root mean squared error (RMSE) *(KÃ¶k ortalama kare hata (RMSE))*

RMSE (KarekÃ¶k Ortalama Kare Hata), MSEâ€™nin karekÃ¶kÃ¼ olmakla birlikte bazÄ± ince farklÄ±lÄ±klar ortaya Ã§Ä±kar. FormÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{y_i} - y_i)^2}
$$

Bu formÃ¼lde:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.

MSEâ€™de, bÃ¼yÃ¼k tahmin hatalarÄ± kare alma iÅŸlemi nedeniyle Ã§ok fazla cezalandÄ±rÄ±lÄ±r. RMSEâ€™de ise bu etki karekÃ¶k sayesinde biraz azaltÄ±lÄ±r. Ancak yine de uÃ§ deÄŸerler (outlier) performansÄ± ciddi ÅŸekilde etkileyebilir; MSE veya RMSE ile deÄŸerlendiriyor olmanÄ±z fark etmez.

SonuÃ§ olarak, probleme baÄŸlÄ± olarak, MSEâ€™yi hedef fonksiyonu olarak kullanan bir algoritmayla daha iyi bir uyum elde edebilirsiniz. Bunun iÃ§in Ã¶nce hedef deÄŸiÅŸkenin karekÃ¶kÃ¼nÃ¼ almak (pozitif deÄŸerler gerektirir), ardÄ±ndan sonuÃ§larÄ± kareye almak iÅŸe yarayabilir. Scikit-learnâ€™daki **TransformedTargetRegressor** gibi fonksiyonlar, regresyon hedefinizi uygun ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rmenize yardÄ±mcÄ± olarak deÄŸerlendirme metriÄŸinize gÃ¶re daha iyi uyumlu sonuÃ§lar almanÄ±zÄ± saÄŸlar.

> Son zamanlarda RMSEâ€™nin kullanÄ±ldÄ±ÄŸÄ± bazÄ± yarÄ±ÅŸmalar ÅŸunlardÄ±r:
> 
> 
> 
> * **Avito Demand Prediction Challenge**: [Kaggle linki](https://www.kaggle.com/c/avitodemand-prediction)
> 
> * **Google Analytics Customer Revenue Prediction**: [Kaggle linki](https://www.kaggle.com/c/ga-customer-revenue-prediction)
> 
> * **Elo Merchant Category Recommendation**: [Kaggle linki](https://www.kaggle.com/c/elo-merchant-category-recommendation)

#### Root mean squared log error (RMSLE) *(KÃ¶k ortalama log kare hata (RMSLE))*

MSEâ€™nin bir diÄŸer yaygÄ±n dÃ¶nÃ¼ÅŸÃ¼mÃ¼, **karekÃ¶k ortalama log hatasÄ± (RMSLE)**â€™dir. **MCRMSLE**, COVID-19 tahmin yarÄ±ÅŸmalarÄ±nda popÃ¼ler olan bir varyanttÄ±r ve birden fazla hedef deÄŸiÅŸken olduÄŸunda her bir hedefin RMSLE deÄŸerlerinin sÃ¼tun bazÄ±nda ortalamasÄ±nÄ± alÄ±r.

RMSLE formÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
RMSLE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\log(\hat{y_i}+1) - \log(y_i+1))^2}
$$

FormÃ¼lde:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.

Logaritmik dÃ¶nÃ¼ÅŸÃ¼m, tahminlerinize ve gerÃ§ek deÄŸerlere uygulanÄ±r; ardÄ±ndan kare alma, ortalama alma ve karekÃ¶k iÅŸlemleri yapÄ±lÄ±r. Bu sayede, Ã¶zellikle bÃ¼yÃ¼k deÄŸerler iÃ§in tahmin edilen ve gerÃ§ek deÄŸerler arasÄ±ndaki bÃ¼yÃ¼k farklar Ã§ok fazla cezalandÄ±rÄ±lmaz. Yani RMSLE kullanÄ±rken en Ã§ok Ã¶nem verdiÄŸiniz ÅŸey, tahminlerinizin Ã¶lÃ§eÄŸinin gerÃ§ek deÄŸerlerin Ã¶lÃ§eÄŸiyle ne kadar uyumlu olduÄŸudur.

RMSEâ€™de olduÄŸu gibi, regresyon algoritmalarÄ± RMSLEâ€™yi daha iyi optimize edebilir. Bunun iÃ§in hedef deÄŸiÅŸkene logaritmik dÃ¶nÃ¼ÅŸÃ¼m uygulayÄ±p modeli eÄŸitmek ve ardÄ±ndan ters dÃ¶nÃ¼ÅŸÃ¼m olarak Ã¼stel fonksiyonu kullanmak gerekir.

> Son dÃ¶nemde RMSLE kullanÄ±lan bazÄ± Kaggle yarÄ±ÅŸmalarÄ±:
> 
> 
> 
> * **ASHRAE - Great Energy Predictor III**: [Kaggle linki](https://www.kaggle.com/c/ashrae-energy-prediction)
> 
> * **Santander Value Prediction Challenge**: [Kaggle linki](https://www.kaggle.com/c/santander-value-prediction-challenge)
> 
> * **Mercari Price Suggestion Challenge**: [Kaggle linki](https://www.kaggle.com/c/mercari-price-suggestion-challenge)
> 
> * **Sberbank Russian Housing Market**: [Kaggle linki](https://www.kaggle.com/olgabelitskaya/sberbank-russian-housing-market)
> 
> * **Recruit Restaurant Visitor Forecasting**: [Kaggle linki](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting)

Åu anda, Kaggle yarÄ±ÅŸmalarÄ±nda regresyon iÃ§in en yaygÄ±n kullanÄ±lan deÄŸerlendirme metriÄŸi **RMSLE**â€™dir.

#### Mean absolute error (MAE) *(Ortalama mutlak hata (MAE))*

**MAE (Mean Absolute Error â€“ Ortalama Mutlak Hata)**, tahminler ile gerÃ§ek deÄŸerler arasÄ±ndaki farkÄ±n **mutlak deÄŸerini** alÄ±r. FormÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |\hat{y_i} - y_i|
$$

FormÃ¼lde:

* ($n$) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir,
* ($y_i$) gerÃ§ek deÄŸer (ground truth),
* ($\hat{y_i}$) modelin tahminidir.

**Ã–zellikleri ve avantajlarÄ±:**

* MAE, **outlierâ€™lara (aykÄ±rÄ± deÄŸerlere) karÅŸÄ± duyarlÄ± deÄŸildir**, Ã§Ã¼nkÃ¼ hatalar karelenmez. Bu nedenle outlier iÃ§eren veri setlerinde MAE sÄ±klÄ±kla tercih edilen bir deÄŸerlendirme metriÄŸidir.
* BirÃ§ok algoritma, MAEâ€™yi doÄŸrudan **objective function** olarak kullanabilir. EÄŸer algoritma bunu doÄŸrudan desteklemiyorsa, hedef deÄŸiÅŸkene karekÃ¶k uygulayÄ±p ardÄ±ndan tahminleri karesini alarak dolaylÄ± optimizasyon yapÄ±labilir.

**DezavantajlarÄ±:**

* MAE ile optimize etmek, daha yavaÅŸ **convergence** (yakÄ±nsama) saÄŸlar. Bunun nedeni, MAE ile aslÄ±nda hedefin ortalamasÄ± yerine **medyanÄ±nÄ±** tahmin etmeye Ã§alÄ±ÅŸmanÄ±zdÄ±r (L1 normu). Oysa MSE ile optimize edildiÄŸinde hedefin ortalamasÄ± (L2 normu) minimize edilir.
* Bu durum optimizasyon sÃ¼recini daha karmaÅŸÄ±k hale getirir ve eÄŸitim sÃ¼resi, gÃ¶zlem sayÄ±sÄ±na baÄŸlÄ± olarak Ã¼stel biÃ§imde artabilir. Ã–rneÄŸin, MAE kriteri ile bir Random Forest regressor eÄŸitmek, MSE kriterine gÃ¶re Ã§ok daha yavaÅŸ olabilir ([Stack Overflow Ã¶rneÄŸi](https://stackoverflow.com/questions/57243267/why-is-training-a-random-forest-regressor-with-mae-criterion-so-slow-compared-to)).

> **MAE kullanÄ±lan Ã¶nemli yarÄ±ÅŸmalar:**
> 
> 
> 
> * **LANL Earthquake Prediction**: [Kaggle linki](https://www.kaggle.com/c/LANL-Earthquake-Prediction)
> 
> * **How Much Did It Rain? II**: [Kaggle linki](https://www.kaggle.com/c/how-much-did-it-rain-ii)

Tahmin yarÄ±ÅŸmalarÄ±nda (forecasting competitions), kullanÄ±lan regresyon Ã¶lÃ§Ã¼tleri bÃ¼yÃ¼k Ã¶lÃ§Ã¼de benzerdir. Ã–rneÄŸin:

* **M5 Forecasting Competition**: [Link](https://mofc.unic.ac.cy/m5-competition/)
* DiÄŸer M serisi yarÄ±ÅŸmalar: [Hyndsight Ã¶zetleri](https://robjhyndman.com/hyndsight/forecasting-competitions/)

Forecasting yarÄ±ÅŸmalarÄ±nda bazen daha Ã¶zel Ã¶lÃ§Ã¼tler de kullanÄ±lÄ±r, Ã¶rneÄŸin:

* **Weighted Root Mean Squared Scaled Error (WRMSSE)**: [Kaggle linki](https://www.kaggle.com/c/m5-forecasting-accuracy/overview/evaluation)
* **Symmetric Mean Absolute Percentage Error (sMAPE)**: [Kaggle linki](https://www.kaggle.com/c/demand-forecasting-kernels-only/overview/evaluation)

Ancak, temel olarak bunlar RMSE veya MAEâ€™nin varyasyonlarÄ±dÄ±r ve doÄŸru hedef dÃ¶nÃ¼ÅŸÃ¼mleri ile yÃ¶netilebilirler.

### Metrics for classification (label prediction and probability) *(SÄ±nÄ±flandÄ±rma metrikleri - etiket tahmini ve olasÄ±lÄ±k)*

Regresyon problemleri iÃ§in metrikleri tartÄ±ÅŸtÄ±ktan sonra, ÅŸimdi sÄ±nÄ±flandÄ±rma problemleri iÃ§in metrikleri aÃ§Ä±klamaya geÃ§iyoruz; Ã¶nce ikili sÄ±nÄ±flandÄ±rma problemlerinden baÅŸlÄ±yoruz (iki sÄ±nÄ±ftan birini tahmin etmeniz gerektiÄŸinde), sonra Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmaya (iki sÄ±nÄ±ftan fazla olduÄŸunda) ve en sonunda Ã§ok etiketli sÄ±nÄ±flandÄ±rmaya (sÄ±nÄ±flarÄ±n birbirinin Ã¼zerine bindiÄŸi durumlarda).

#### Accuracy *(DoÄŸruluk)*

Ä°kili bir sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n performansÄ±nÄ± analiz ederken, en yaygÄ±n ve eriÅŸilebilir metrik **doÄŸruluk (accuracy)** olarak kullanÄ±lÄ±r. **YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma hatasÄ±**, modelinizin bir Ã¶rnek iÃ§in yanlÄ±ÅŸ sÄ±nÄ±fÄ± tahmin etmesi durumudur. DoÄŸruluk ise yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma hatasÄ±nÄ±n tamamlayÄ±cÄ±sÄ±dÄ±r ve doÄŸru tahmin edilen Ã¶rneklerin sayÄ±sÄ±nÄ±n toplam tahmin sayÄ±sÄ±na bÃ¶lÃ¼nmesiyle hesaplanabilir:

$$
\text{Accuracy} = \frac{\text{Correct Answers}}{\text{Total Answers}}
$$

> Bu metrik, Ã¶rneÄŸin **Cassava Leaf Disease Classification** ([https://www.kaggle.com/c/cassava-leaf-disease-classification](https://www.kaggle.com/c/cassava-leaf-disease-classification)) ve **Text Normalization Challenge - English Language** ([https://www.kaggle.com/c/text-normalization-challenge-english-language](https://www.kaggle.com/c/text-normalization-challenge-english-language)) gibi yarÄ±ÅŸmalarda kullanÄ±lmÄ±ÅŸtÄ±r. Bu yarÄ±ÅŸmalarda doÄŸru bir tahmin, yalnÄ±zca tahmin edilen metin gerÃ§ek metinle tamamen eÅŸleÅŸtiÄŸinde sayÄ±lmÄ±ÅŸtÄ±r.

Bir metrik olarak doÄŸruluk, modelin gerÃ§ek dÃ¼nyadaki etkili performansÄ±na gÃ¼Ã§lÃ¼ bir ÅŸekilde odaklanÄ±r; modelin beklendiÄŸi gibi Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± gÃ¶sterir. Ancak, eÄŸer amacÄ±nÄ±z modeli deÄŸerlendirmek, karÅŸÄ±laÅŸtÄ±rmak ve yaklaÅŸÄ±mÄ±nÄ±zÄ±n gerÃ§ekten ne kadar etkili olduÄŸunu net bir ÅŸekilde gÃ¶rmekse, doÄŸruluÄŸu kullanÄ±rken dikkatli olmanÄ±z gerekir. Ã‡Ã¼nkÃ¼ sÄ±nÄ±flar **dengesiz** olduÄŸunda (farklÄ± frekanslara sahip olduÄŸunda) yanlÄ±ÅŸ sonuÃ§lara yol aÃ§abilir. Ã–rneÄŸin, bir sÄ±nÄ±f verinin yalnÄ±zca %10â€™unu oluÅŸturuyorsa, yalnÄ±zca Ã§oÄŸunluk sÄ±nÄ±fÄ±nÄ± tahmin eden bir model %90 doÄŸruluk gÃ¶sterebilir; yÃ¼ksek doÄŸruluk gÃ¶rÃ¼nmesine raÄŸmen oldukÃ§a iÅŸe yaramaz olur.

BÃ¶yle bir problemi nasÄ±l fark edebilirsiniz? Bunu **karÄ±ÅŸÄ±klÄ±k matrisi (confusion matrix)** kullanarak kolayca gÃ¶rebilirsiniz. KarÄ±ÅŸÄ±klÄ±k matrisinde, gerÃ§ek sÄ±nÄ±flar satÄ±rlara, tahmin edilen sÄ±nÄ±flar sÃ¼tunlara yerleÅŸtirilerek iki yÃ¶nlÃ¼ bir tablo oluÅŸturulur. Scikit-learnâ€™Ã¼n **confusion_matrix** fonksiyonu ile basitÃ§e oluÅŸturabilirsiniz:

```python
sklearn.metrics.confusion_matrix(
    y_true, y_pred, *, labels=None, sample_weight=None,
    normalize=None
)
```

Sadece **y_true** ve **y_pred** vektÃ¶rlerini saÄŸlamak anlamlÄ± bir tablo oluÅŸturmak iÃ§in yeterlidir, fakat satÄ±r/sÃ¼tun etiketleri, Ã¶rnekler iÃ§in aÄŸÄ±rlÄ±klar ve normalize etme seÃ§enekleri de eklenebilir. Normalize iÅŸlemi, gerÃ§ek Ã¶rnekler (satÄ±rlar), tahmin edilen Ã¶rnekler (sÃ¼tunlar) veya tÃ¼m Ã¶rnekler Ã¼zerinde yapÄ±labilir.

MÃ¼kemmel bir sÄ±nÄ±flandÄ±rÄ±cÄ±, tÃ¼m Ã¶rnekleri matrisin ana kÃ¶ÅŸegeninde toplar. EÄŸer kÃ¶ÅŸegendeki hÃ¼crelerde Ã§ok az veya hiÃ§ Ã¶rnek yoksa, bu durum tahminleyicinin geÃ§erliliÄŸiyle ilgili ciddi sorunlarÄ± gÃ¶sterir.

NasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha iyi anlamak iÃ§in Scikit-learn tarafÄ±ndan sunulan grafiksel Ã¶rneÄŸi inceleyebilirsiniz:
[Scikit-learn plot_confusion_matrix Ã¶rneÄŸi](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)

![](im/1043.png)

DoÄŸruluÄŸun kullanÄ±labilirliÄŸini artÄ±rmak iÃ§in, her sÄ±nÄ±fa gÃ¶re doÄŸruluÄŸu dikkate alÄ±p bunlarÄ±n ortalamasÄ±nÄ± almayÄ± deneyebilirsiniz; ancak, **precision (kesinlik)**, **recall (duyarlÄ±lÄ±k)** ve **F1-score** gibi diÄŸer metriklere gÃ¼venmek genellikle daha faydalÄ± olacaktÄ±r.

#### Precision and recall *(Kesinlik ve duyarlÄ±lÄ±k)*

Precision ve recall metriklerini elde etmek iÃ§in yine **karÄ±ÅŸÄ±klÄ±k matrisinden (confusion matrix)** baÅŸlÄ±yoruz. Ã–ncelikle, matrisin her bir hÃ¼cresine isim vermemiz gerekiyor:

![](im/1044.png)

Ä°ÅŸte hÃ¼crelerin nasÄ±l tanÄ±mlandÄ±ÄŸÄ±:

* **True Positive (TP)**: Bu hÃ¼cre, doÄŸru bir ÅŸekilde pozitif olarak tahmin edilen Ã¶rnekleri iÃ§erir. Yani, modelin doÄŸru bir ÅŸekilde pozitif sÄ±nÄ±fÄ± tahmin ettiÄŸi durumlar.
* **False Positive (FP)**: Bu hÃ¼cre, aslÄ±nda negatif olan ancak model tarafÄ±ndan pozitif olarak tahmin edilen Ã¶rnekleri iÃ§erir.
* **False Negative (FN)**: Bu hÃ¼cre, aslÄ±nda pozitif olan ancak model tarafÄ±ndan negatif olarak tahmin edilen Ã¶rnekleri iÃ§erir.
* **True Negative (TN)**: Bu hÃ¼cre, doÄŸru bir ÅŸekilde negatif olarak tahmin edilen Ã¶rnekleri iÃ§erir. Yani, modelin doÄŸru bir ÅŸekilde negatif sÄ±nÄ±fÄ± tahmin ettiÄŸi durumlar.

Bu hÃ¼creleri kullanarak, sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±zÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ± hakkÄ±nda daha hassas bilgiler elde edebilir ve modelinizi daha iyi ayarlayabilirsiniz. Ä°lk olarak, doÄŸruluk formÃ¼lÃ¼nÃ¼ kolayca gÃ¶zden geÃ§irebiliriz:

**DoÄŸruluk (Accuracy) FormÃ¼lÃ¼**
$$ \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} $$

ArdÄ±ndan, ilk Ã¶nemli metrik **precision (kesinlik)** veya **specificity (Ã¶zgÃ¼llÃ¼k)** olarak adlandÄ±rÄ±lÄ±r ve aslÄ±nda pozitif vakalarÄ±n doÄŸruluÄŸunu Ã¶lÃ§er:

**Kesinlik (Precision) FormÃ¼lÃ¼**
$$ \text{Precision} = \frac{TP}{TP + FP} $$

Hesaplamada sadece **true positives (TP)** ve **false positives (FP)** sayÄ±larÄ± dikkate alÄ±nÄ±r. Temelde, bu metrik, modelin pozitif tahminlerde ne kadar doÄŸru olduÄŸunu gÃ¶sterir. AÃ§Ä±kÃ§a, modeliniz yalnÄ±zca yÃ¼ksek gÃ¼vene sahip olduÄŸu Ã¶rneklerde pozitif tahmin yaparak yÃ¼ksek skorlar alabilir. Bu Ã¶lÃ§Ã¼mÃ¼n amacÄ± da aslÄ±nda ÅŸudur: Modeli, yalnÄ±zca kesin olduÄŸunda ve bunu yapmak gÃ¼venliyse pozitif sÄ±nÄ±fÄ± tahmin etmeye zorlamak.

Ancak, eÄŸer amacÄ±nÄ±z mÃ¼mkÃ¼n olduÄŸunca fazla pozitif tahmin yapmaksa, o zaman **recall (duyarlÄ±lÄ±k)** veya **coverage (kapsama)** veya **sensitivity (hassasiyet)** ya da **true positive rate (doÄŸru pozitif oranÄ±)** metriklerini de takip etmeniz gerekir:

**DuyarlÄ±lÄ±k (Recall) FormÃ¼lÃ¼**
$$ \text{Recall} = \frac{TP}{TP + FN} $$

Burada, **false negatives (FN)** hakkÄ±nda da bilgi sahibi olmanÄ±z gerekecek. Bu iki metriÄŸin ilginÃ§ olan yanÄ±, Ã¶rneklerin sÄ±nÄ±flandÄ±rÄ±lmasÄ±na dayalÄ± olmalarÄ±dÄ±r ve bir sÄ±nÄ±flandÄ±rma aslÄ±nda olasÄ±lÄ±ÄŸa dayanÄ±r (bu genellikle pozitif ve negatif sÄ±nÄ±f arasÄ±ndaki 0.5 eÅŸiÄŸiyle belirlenir). Bu eÅŸiÄŸi deÄŸiÅŸtirdiÄŸinizde, bir metriÄŸi diÄŸerinin pahasÄ±na iyileÅŸtirebilirsiniz. Ã–rneÄŸin, eÅŸiÄŸi arttÄ±rÄ±rsanÄ±z, daha yÃ¼ksek **precision** (kesinlik) elde edersiniz (sÄ±nÄ±flandÄ±rÄ±cÄ± daha gÃ¼venlidir) ancak **recall** azalÄ±r. EÅŸiÄŸi dÃ¼ÅŸÃ¼rÃ¼rseniz, daha dÃ¼ÅŸÃ¼k **precision** ancak daha yÃ¼ksek **recall** elde edersiniz. Bu, **precision/recall trade-off (kesinlik/duyarlÄ±lÄ±k dengesi)** olarak bilinir.

Scikit-learn sitesi, bu dengeyi anlamanÄ±zÄ± saÄŸlayacak pratik bir bakÄ±ÅŸ aÃ§Ä±sÄ± sunar ([https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)), burada **precision/recall** eÄŸrisini izleyebilir ve bu iki metriÄŸin nasÄ±l deÄŸiÅŸtirilebileceÄŸini anlayarak ihtiyaÃ§larÄ±nÄ±za daha uygun bir sonuÃ§ elde edebilirsiniz.

![](im/1045.png)

**Precision/Recall dengesine** baÄŸlÄ± bir metrik de **ortalama kesinlik (average precision)**'tir. Ortalama kesinlik, **recall** deÄŸerleri 0'dan 1'e kadar olan bir aralÄ±kta (temelde eÅŸiÄŸi 1'den 0'a deÄŸiÅŸtirirken) hesaplanan ortalama kesinliÄŸi ifade eder. Ortalama kesinlik, Ã¶zellikle **nesne tespiti** ile ilgili gÃ¶revlerde oldukÃ§a popÃ¼lerdir ve bu konuyu biraz sonra tartÄ±ÅŸacaÄŸÄ±z, ancak aynÄ± zamanda **tablo verisiyle yapÄ±lan sÄ±nÄ±flandÄ±rma** iÃ§in de oldukÃ§a faydalÄ±dÄ±r.

Pratikte, **ortalama kesinlik**, model performansÄ±nÄ± Ã§ok nadir bir sÄ±nÄ±f Ã¼zerinde daha hassas ve doÄŸru bir ÅŸekilde izlemek istediÄŸinizde deÄŸerli bir metrik haline gelir. Bu, genellikle **dolandÄ±rÄ±cÄ±lÄ±k tespiti** gibi dengesiz veri setlerinde karÅŸÄ±laÅŸÄ±lan bir durumdur.

Bu konuda daha spesifik bilgiler iÃ§in Gael Varoquaux'nin tartÄ±ÅŸmasÄ±nÄ± okuyabilirsiniz:
[Gael Varoquaux'nin tartÄ±ÅŸmasÄ±](http://gael-varoquaux.info/interpreting_ml_tuto/content/01_how_well/01_metrics.html#average-precision).

#### The F1 score *(F1 skoru)*

Bu noktada, **kesinlik** (precision) veya **duyarlÄ±lÄ±k** (recall) gibi metriklerin bir deÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼ olarak ideal bir seÃ§im olmadÄ±ÄŸÄ±nÄ± muhtemelen fark etmiÅŸsinizdir, Ã§Ã¼nkÃ¼ birini optimize ettiÄŸinizde diÄŸeri pahasÄ±na olur. Bu nedenle, yalnÄ±zca bir metrik kullanarak yapÄ±lan Kaggle yarÄ±ÅŸmalarÄ± yoktur. Bu metrikleri birleÅŸtirmeniz gerekir (Ã¶rneÄŸin, **ortalama kesinlik** gibi). **F1 skoru**, kesinlik ve duyarlÄ±lÄ±ÄŸÄ±n harmonik ortalamasÄ± olarak, genellikle en iyi Ã§Ã¶zÃ¼m olarak kabul edilir:

**F1 Skoru FormÃ¼lÃ¼:**
$$ \text{F1} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} $$

EÄŸer yÃ¼ksek bir **F1 skoru** elde ediyorsanÄ±z, bu modelinizin **kesinlik** veya **duyarlÄ±lÄ±k** veya her ikisinde birden geliÅŸme gÃ¶sterdiÄŸi anlamÄ±na gelir. Bu metriÄŸin kullanÄ±mÄ±na gÃ¼zel bir Ã¶rnek, **Quora Insincere Questions Classification** yarÄ±ÅŸmasÄ±nda gÃ¶rÃ¼lebilir:
[Quora Insincere Questions Classification YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/quora-insincere-questions-classification).

BazÄ± yarÄ±ÅŸmalarda, **F-beta skoru** da kullanÄ±lÄ±r. Bu, kesinlik ve duyarlÄ±lÄ±ÄŸÄ±n aÄŸÄ±rlÄ±klÄ± harmonik ortalamasÄ±dÄ±r ve **beta** deÄŸeri, **recall**'in birleÅŸik skordaki aÄŸÄ±rlÄ±ÄŸÄ±nÄ± belirler:

**F-beta Skoru FormÃ¼lÃ¼:**
$$ \text{F}_\beta = \frac{(1 + \beta^2) \times (\text{Precision} \times \text{Recall})}{\beta^2 \times \text{Precision} + \text{Recall}} $$

Burada, **beta** parametresi, recall'un nasÄ±l aÄŸÄ±rlÄ±klÄ± olarak deÄŸerlendirileceÄŸini belirler. **F1 skoru**, **beta = 1** olduÄŸunda, yani **kesinlik** ve **duyarlÄ±lÄ±k** eÅŸit derecede Ã¶nemli kabul edildiÄŸinde elde edilir.

Åimdi, **eÅŸik** (threshold) ve **sÄ±nÄ±flandÄ±rma olasÄ±lÄ±ÄŸÄ±** kavramlarÄ±nÄ± zaten tanÄ±ttÄ±ÄŸÄ±mÄ±za gÃ¶re, yaygÄ±n kullanÄ±lan diÄŸer iki sÄ±nÄ±flandÄ±rma metriÄŸi olan **log loss** ve **ROC-AUC**'yi de tartÄ±ÅŸabiliriz.

#### Log loss and ROC-AUC *(Log kaybÄ± ve ROC-AUC)*

**Log Loss** ile baÅŸlayalÄ±m, ki bu derin Ã¶ÄŸrenme modellerinde **cross-entropy** (Ã§apraz entropi) olarak da bilinir. **Log loss**, tahmin edilen olasÄ±lÄ±k ile gerÃ§ek (ground truth) olasÄ±lÄ±k arasÄ±ndaki farkÄ± Ã¶lÃ§er:

**Log Loss FormÃ¼lÃ¼:**
$$ L = \sum_{i=1}^{n} \left[ y_i \cdot \log(\hat{y_i}) + (1 - y_i) \cdot \log(1 - \hat{y_i}) \right] $$

Burada, ( n ) Ã¶rnek sayÄ±sÄ±nÄ±, ( y_i ) ith Ã¶rneÄŸin gerÃ§ek etiketini (0 veya 1) ve ( \hat{y_i} ) ise modelin ith Ã¶rnek iÃ§in tahmin ettiÄŸi olasÄ±lÄ±ÄŸÄ± temsil eder.

EÄŸer bir yarÄ±ÅŸma **log loss** kullanÄ±yorsa, bu, amacÄ±n bir Ã¶rneÄŸin pozitif sÄ±nÄ±fa ait olma olasÄ±lÄ±ÄŸÄ±nÄ± mÃ¼mkÃ¼n olduÄŸunca doÄŸru bir ÅŸekilde tahmin etmek olduÄŸu anlamÄ±na gelir. GerÃ§ekten de log loss, birÃ§ok yarÄ±ÅŸmada kullanÄ±lan bir metriktir.

Ã–rneÄŸin, **Deepfake Detection Challenge** ([https://www.kaggle.com/c/deepfake-detection-challenge](https://www.kaggle.com/c/deepfake-detection-challenge)) veya daha eski **Quora Question Pairs** ([https://www.kaggle.com/c/quora-question-pairs](https://www.kaggle.com/c/quora-question-pairs)) gibi yarÄ±ÅŸmalarda log loss metriÄŸini bulabilirsiniz.

**ROC (Receiver Operating Characteristic)** eÄŸrisi, bir ikili sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n performansÄ±nÄ± deÄŸerlendirmek ve birden fazla sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lan grafiksel bir diyagramdÄ±r. ROC-AUC metriÄŸi, bu eÄŸrinin altÄ±ndaki alanÄ± ifade eder. ROC eÄŸrisi, **true positive rate** (doÄŸru pozitif oranÄ±, yani recall) ile **false positive rate** (yanlÄ±ÅŸ pozitif oranÄ±, yani negatif Ã¶rneklerin pozitif olarak sÄ±nÄ±flandÄ±rÄ±lmasÄ± oranÄ±) arasÄ±ndaki iliÅŸkiyi gÃ¶sterir. AyrÄ±ca, doÄŸru negatif oranÄ±nÄ±n (negatif Ã¶rneklerin doÄŸru ÅŸekilde sÄ±nÄ±flandÄ±rÄ±lma oranÄ±) bir eksiÄŸi ile eÅŸdeÄŸerdir.

![](im/1046.png)

Ä°yi bir sÄ±nÄ±flandÄ±rÄ±cÄ±ya ait **ROC eÄŸrisi**, **false positive rate** (yanlÄ±ÅŸ pozitif oranÄ±) dÃ¼ÅŸÃ¼kken **true positive rate** (doÄŸru pozitif oranÄ±, yani recall) hÄ±zla artmalÄ±dÄ±r. **ROC-AUC** deÄŸeri 0.9 ile 1.0 arasÄ±nda olan bir model, Ã§ok iyi kabul edilir.

KÃ¶tÃ¼ bir sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ±, **ROC eÄŸrisinin**, yukarÄ±daki ÅŸekilde, yalnÄ±zca rastgele bir sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n performansÄ±nÄ± temsil eden diyagonal ile Ã§ok benzer veya aynÄ± olmasÄ±yla fark edebilirsiniz. **ROC-AUC** skorlarÄ± 0.5'e yakÄ±n olduÄŸunda, sonuÃ§lar neredeyse rastgele kabul edilir.

FarklÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± karÅŸÄ±laÅŸtÄ±rÄ±rken ve **AUC** kullanÄ±yorsanÄ±z, **daha yÃ¼ksek AUC** deÄŸeri olan sÄ±nÄ±flandÄ±rÄ±cÄ± daha performanslÄ±dÄ±r.

EÄŸer sÄ±nÄ±flar dengeliyse veya Ã§ok fazla dengesiz deÄŸilse, **AUC**'deki artÄ±ÅŸlar, eÄŸitimli modelin etkinliÄŸiyle orantÄ±lÄ±dÄ±r ve modelin **doÄŸru pozitifler** iÃ§in daha yÃ¼ksek olasÄ±lÄ±klar Ã¼retme yeteneÄŸi olarak dÃ¼ÅŸÃ¼nÃ¼lebilir. AyrÄ±ca, bu, Ã¶rnekleri pozitiften negatife doÄŸru daha dÃ¼zgÃ¼n sÄ±ralama yeteneÄŸi olarak da deÄŸerlendirilebilir. Ancak, pozitif sÄ±nÄ±f nadir olduÄŸunda, **AUC** baÅŸlangÄ±Ã§ta yÃ¼ksek olur ve artÄ±ÅŸlar, nadir sÄ±nÄ±fÄ± daha iyi tahmin etme aÃ§Ä±sÄ±ndan Ã§ok fazla ÅŸey ifade etmeyebilir. Bu durumda, daha Ã¶nce de belirttiÄŸimiz gibi, **ortalama kesinlik (average precision)** daha faydalÄ± bir metrik olabilir.

> Son zamanlarda, **AUC** birÃ§ok farklÄ± yarÄ±ÅŸmada kullanÄ±lmÄ±ÅŸtÄ±r. Bu Ã¼Ã§ yarÄ±ÅŸmaya gÃ¶z atmanÄ±zÄ± Ã¶neririz:
> 
> 
> 
> * **IEEE-CIS Fraud Detection**: [https://www.kaggle.com/c/ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection)
> 
> * **Riiid Answer Correctness Prediction**: [https://www.kaggle.com/c/riiid-test-answer-prediction](https://www.kaggle.com/c/riiid-test-answer-prediction)
> 
> * **Jigsaw Multilingual Toxic Comment Classification**: [https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification)

**AUC ve ortalama kesinlik arasÄ±ndaki iliÅŸkiyi** daha ayrÄ±ntÄ±lÄ± olarak aÃ§Ä±klayan bir makale iÃ§in ÅŸu kaynaÄŸa gÃ¶z atabilirsiniz:
Su, W., Yuan, Y., ve Zhu, M. "A relationship between the average precision and the area under the ROC curve." Proceedings of the 2015 International Conference on The Theory of Information Retrieval, 2015.

#### Matthews correlation coefficient (MCC) *(Matthews korelasyon katsayÄ±sÄ±)*

Binary sÄ±nÄ±flandÄ±rma metriklerinin sonuna yaklaÅŸÄ±rken, **Matthews korelasyon katsayÄ±sÄ±** (MCC) Ã¶nemli bir yere sahiptir. MCC, **VSB Power Line Fault Detection** ([https://www.kaggle.com/c/vsb-power-line-fault-detection](https://www.kaggle.com/c/vsb-power-line-fault-detection)) ve **Bosch Production Line Performance** ([https://www.kaggle.com/c/bosch-production-line-performance](https://www.kaggle.com/c/bosch-production-line-performance)) gibi yarÄ±ÅŸmalarda kullanÄ±lmÄ±ÅŸtÄ±r.

MCC formÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
MCC = \frac{(TP \cdot TN) - (FP \cdot FN)}{\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}
$$

Burada **TP** true positives (doÄŸru pozitifler), **TN** true negatives (doÄŸru negatifler), **FP** false positives (yanlÄ±ÅŸ pozitifler) ve **FN** false negatives (yanlÄ±ÅŸ negatifler) temsil eder. Bu, **precision** ve **recall** ile ilgili Ã¶nceki aÃ§Ä±klamalarda gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z aynÄ± terminolojidir.

MCC, bir korelasyon katsayÄ±sÄ± gibi davranÄ±r ve +1 (mÃ¼kemmel tahmin) ile -1 (tersine tahmin) arasÄ±nda deÄŸiÅŸir. Bu metrik, Ã¶zellikle sÄ±nÄ±flar oldukÃ§a dengesiz olduÄŸunda bile sÄ±nÄ±flandÄ±rmanÄ±n kalitesini Ã¶lÃ§mek iÃ§in kullanÄ±labilir.

FormÃ¼lÃ¼n karmaÅŸÄ±klÄ±ÄŸÄ±na raÄŸmen, **Neuron Engineer** adlÄ± bir Kaggle kullanÄ±cÄ±sÄ±, bu metriÄŸin daha anlaÅŸÄ±lÄ±r bir formÃ¼lle yeniden yapÄ±landÄ±rÄ±lmasÄ±nÄ± saÄŸlamÄ±ÅŸtÄ±r. Neuron Engineer'in reformÃ¼le ettiÄŸi MCC ÅŸu ÅŸekildedir:

Ä°ÅŸte MCC (Matthews Korelasyon KatsayÄ±sÄ±) formÃ¼lÃ¼nÃ¼n basitleÅŸtirilmiÅŸ hali ve her bir bileÅŸenin aÃ§Ä±klamalarÄ±:

$$MCC = (Posprecision + Negprecision - 1) * PosNegRatio$$

FormÃ¼ldeki her bir eleman ÅŸudur:

* **Posprecision**: Pozitif sÄ±nÄ±fÄ±n kesinliÄŸi
  $$
  \text{Posprecision} = \frac{TP}{TP + FP}
  $$

* **Negprecision**: Negatif sÄ±nÄ±fÄ±n kesinliÄŸi
  $$
  \text{Negprecision} = \frac{TN}{TN + FN}
  $$

* **PosNegRatio**: Pozitif ve negatif tahmin oranÄ±
  $$
  \text{PosNegRatio} = \sqrt{\frac{\text{PosPredictionCount} \times \text{NegPredictionCount}}{\text{PosLabelCount} \times \text{NegLabelCount}}}
  $$

  Buradaki bileÅŸenler ÅŸunlardÄ±r:

  * **PosPredictionCount**: Pozitif sÄ±nÄ±f tahmin sayÄ±sÄ±
    $$
    \text{PosPredictionCount} = TP + FP
    $$

  * **NegPredictionCount**: Negatif sÄ±nÄ±f tahmin sayÄ±sÄ±
    $$
    \text{NegPredictionCount} = TN + FN
    $$

  * **PosLabelCount**: Pozitif etiket sayÄ±sÄ±
  * **NegLabelCount**: Negatif etiket sayÄ±sÄ±

Bu reformÃ¼lasyon, hem pozitif hem de negatif sÄ±nÄ±flarÄ±n doÄŸruluÄŸunu artÄ±rarak daha iyi bir performans elde edebileceÄŸinizi gÃ¶steriyor. Ancak, bunun yeterli olmadÄ±ÄŸÄ±nÄ± da belirtiyor: Pozitif ve negatif tahminlerin, **gerÃ§ek daÄŸÄ±lÄ±mla** orantÄ±lÄ± olmasÄ± gerekir. Aksi takdirde, modeliniz bÃ¼yÃ¼k bir ÅŸekilde cezalandÄ±rÄ±lÄ±r.

### Metrics for multi-class classification *(Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri)*

**Ã‡oklu SÄ±nÄ±f SÄ±nÄ±flandÄ±rmasÄ±**na geÃ§tiÄŸimizde, daha Ã¶nce incelediÄŸimiz ikili sÄ±nÄ±flandÄ±rma metriklerini her sÄ±nÄ±f iÃ§in ayrÄ± ayrÄ± uygularÄ±z ve sonra bu metrikleri, Ã§oklu sÄ±nÄ±f durumlarÄ±nda yaygÄ±n olarak kullanÄ±lan bazÄ± ortalama stratejileriyle Ã¶zetleriz.

Ã–rneÄŸin, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ **F1 skoru** Ã¼zerinden deÄŸerlendirmek istiyorsanÄ±z, Ã¼Ã§ olasÄ± ortalama seÃ§eneÄŸiniz vardÄ±r:

* **Makro ortalama (Macro averaging)**: Her sÄ±nÄ±f iÃ§in F1 skorunu hesaplar ve ardÄ±ndan tÃ¼m sonuÃ§larÄ±n ortalamasÄ±nÄ± alÄ±rsÄ±nÄ±z. Bu ÅŸekilde, her sÄ±nÄ±f, pozitif vakalarÄ±nÄ±n sÄ±klÄ±ÄŸÄ±na veya sorununuz iÃ§in ne kadar Ã¶nemli olduÄŸuna bakÄ±lmaksÄ±zÄ±n eÅŸit ÅŸekilde deÄŸerlendirilir ve modelin her sÄ±nÄ±fta kÃ¶tÃ¼ performans gÃ¶sterdiÄŸinde eÅŸit cezalar verilmiÅŸ olur.

  $$
  \text{Macro-F1} = \frac{F1_{class1} + F1_{class2} + \dots + F1_{classn}}{N}
  $$

* **Mikro ortalama (Micro averaging)**: Bu yaklaÅŸÄ±m, her sÄ±nÄ±fÄ±n katkÄ±sÄ±nÄ± toplayarak birleÅŸtirilmiÅŸ bir F1 skoru hesaplar. Bu yÃ¶ntem, hiÃ§bir sÄ±nÄ±fa Ã¶zel bir favori veya ceza uygulamaz, Ã§Ã¼nkÃ¼ tÃ¼m hesaplamalar her sÄ±nÄ±fÄ± dikkate almadan yapÄ±lÄ±r ve bÃ¶ylece sÄ±nÄ±f dengesizliklerini daha doÄŸru bir ÅŸekilde hesaba katar:

  $$
  \text{Micro-F1} = F1_{class1+class2+\dots+classn}
  $$

* **AÄŸÄ±rlÄ±klÄ± ortalama (Weighting)**: Makro ortalama gibi, her sÄ±nÄ±f iÃ§in F1 skoru hesaplanÄ±r, ancak ardÄ±ndan tÃ¼m F1 skorlarÄ±nÄ±n, her sÄ±nÄ±fÄ±n doÄŸru etiket sayÄ±sÄ±na baÄŸlÄ± bir aÄŸÄ±rlÄ±klÄ± ortalamasÄ± alÄ±nÄ±r. Bu aÄŸÄ±rlÄ±k seti, her sÄ±nÄ±fÄ±n pozitif vakalarÄ±nÄ±n sÄ±klÄ±ÄŸÄ±nÄ± veya o sÄ±nÄ±fÄ±n sorununuz iÃ§in Ã¶nemini dikkate almanÄ±za olanak tanÄ±r. Bu yaklaÅŸÄ±m aÃ§Ä±kÃ§a Ã§oÄŸunluk sÄ±nÄ±flarÄ±na Ã¶ncelik verir, Ã§Ã¼nkÃ¼ bu sÄ±nÄ±flar hesaplamalarda daha fazla aÄŸÄ±rlÄ±k alÄ±r:

  $$
  \text{Weighted-F1} = \frac{F1_{class1} \cdot W_{class1} + F1_{class2} \cdot W_{class2} + \dots + F1_{classn} \cdot W_{classn}}

  {W_1 + W_2 + \dots + W_n = 1}
  $$

Kaggle yarÄ±ÅŸmalarÄ±nda karÅŸÄ±laÅŸabileceÄŸiniz bazÄ± yaygÄ±n Ã§oklu sÄ±nÄ±f metrikleri ÅŸunlardÄ±r:

* **Ã‡oklu sÄ±nÄ±f doÄŸruluÄŸu (Weighted Accuracy)**: **Bengali.AI Handwritten Grapheme Classification** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/bengaliai-cv19))
* **Ã‡oklu sÄ±nÄ±f log kaybÄ± (Multiclass log loss)**: **Mechanisms of Action (MoA) Prediction** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/lish-moa/))
* **Makro-F1 ve Mikro-F1 (Macro-F1, Micro-F1)**: **University of Liverpool - Ion Switching** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/liverpool-ion-switching)), **Human Protein Atlas Image Classification** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/human-protein-atlas-image-classification/)), **TensorFlow 2.0 Question Answering** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/tensorflow2-question-answering))
* **Ortalama F1 (Mean-F1)**: **Shopee - Price Match Guarantee** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/shopee-product-matching/))

---

**Kareli AÄŸÄ±rlÄ±klÄ± Kappa (Quadratic Weighted Kappa)**, sÄ±ralÄ± tahmin problemleri iÃ§in akÄ±llÄ±ca bir deÄŸerlendirme metriÄŸi olarak daha sonra inceleyeceÄŸimiz bir diÄŸer metriktir. En basit haliyle **Cohen Kappa skoru**, tahminlerinizin ve gerÃ§eklerin arasÄ±ndaki uyumu Ã¶lÃ§er. Bu metrik aslÄ±nda, **annotasyonlar arasÄ± uyumu** Ã¶lÃ§mek iÃ§in geliÅŸtirilmiÅŸtir, ancak oldukÃ§a esnek olup daha iyi kullanÄ±mlar bulmuÅŸtur.

**Annotasyonlar arasÄ± uyum** nedir? Bir etiketleme gÃ¶reviniz olduÄŸunu varsayalÄ±m: FotoÄŸraflarÄ± **kedi**, **kÃ¶pek** veya **hiÃ§biri** olarak sÄ±nÄ±flandÄ±rmak. Bir grup kiÅŸiye bu gÃ¶revi verirseniz, yanlÄ±ÅŸ etiketler alabilirsiniz, Ã§Ã¼nkÃ¼ bir kiÅŸi (bu tÃ¼r gÃ¶revlerde "hakem" olarak adlandÄ±rÄ±lÄ±r) bir kÃ¶peÄŸi kedi olarak ya da tam tersini yanlÄ±ÅŸ tanÄ±mlayabilir. Bu iÅŸi doÄŸru yapmak iÃ§in, aynÄ± fotoÄŸraflarÄ± etiketlemek iÃ§in birden fazla hakem kullanmak ve ardÄ±ndan **Cohen Kappa skoru**na gÃ¶re uyum dÃ¼zeylerini Ã¶lÃ§mek en akÄ±llÄ±ca yoldur.

**Cohen Kappa**, iki etiketleyici arasÄ±ndaki uyum dÃ¼zeyini belirten bir skordur:

$$
\kappa = \frac{p_0 - p_e}{1 - p_e}
$$

Burada ( p_0 ) gÃ¶zlemlenen relatif uyum oranÄ±nÄ±, ( p_e ) ise olasÄ±lÄ±k aÃ§Ä±sÄ±ndan tesadÃ¼fi uyum oranÄ±nÄ± ifade eder. **KarÄ±ÅŸÄ±klÄ±k matrisi** terimlerini kullanarak bu ÅŸu ÅŸekilde yazÄ±labilir:

$$
\kappa = \frac{2 \cdot (TP \cdot TN - FP \cdot FN)}{(TP + FP) \cdot (TN + FP) + (TP + FN) \cdot (FN + TN)}
$$

Bu formÃ¼lÃ¼n ilginÃ§ yanÄ±, skoru oluÅŸtururken, uyumun sadece ÅŸans sonucu gerÃ§ekleÅŸmiÅŸ olma olasÄ±lÄ±ÄŸÄ±nÄ± hesaba katmasÄ±dÄ±r. Bu sayede, Ã¶lÃ§Ã¼m en olasÄ± sÄ±nÄ±flandÄ±rmalara gÃ¶re dÃ¼zeltilmiÅŸ olur. Metrik, **tam uyum** iÃ§in 1, **tam karÅŸÄ±tlÄ±k** (tam uyumsuzluk) iÃ§in -1 olarak tanÄ±mlanÄ±r. 0 civarÄ±ndaki deÄŸerler, hakemler arasÄ±ndaki uyum ve uyumsuzluÄŸun tesadÃ¼fen gerÃ§ekleÅŸtiÄŸini gÃ¶sterir.

Bu, modelin Ã§oÄŸu durumda ÅŸansa karÅŸÄ± gerÃ§ekten daha iyi performans gÃ¶sterip gÃ¶stermediÄŸini anlamanÄ±za yardÄ±mcÄ± olur.

> **Andrey Lukyanenko**
> 
> [https://www.kaggle.com/artgor](https://www.kaggle.com/artgor)
> 
> 
> 
> Bu bÃ¶lÃ¼mdeki ikinci rÃ¶portajÄ±mÄ±z, **Notebooklar ve TartÄ±ÅŸmalar Grandmaster'Ä±** ve **YarÄ±ÅŸmalar Master'Ä±** Andrey Lukyanenko ile. GÃ¼nlÃ¼k iÅŸinde, **MTS Group**â€™ta bir **Makine Ã–ÄŸrenimi MÃ¼hendisi ve TechLead** olarak Ã§alÄ±ÅŸmaktadÄ±r. Kaggle deneyimleri hakkÄ±nda ilginÃ§ pek Ã§ok ÅŸey paylaÅŸtÄ±!
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan, Kaggleâ€™daki uzmanlÄ±ÄŸÄ±nÄ±z nedir?**
> 
> Genel olarak baÅŸka veri setlerine/alanlara transfer edilebilecek kadar genel Ã§Ã¶zÃ¼mler gerektiren yarÄ±ÅŸmalarÄ± tercih ediyorum. FarklÄ± sinir aÄŸÄ± mimarilerini, en son teknikleri ve post-processing tekniklerini denemekle ilgileniyorum. Ters mÃ¼hendislik veya "altÄ±n Ã¶zellikler" yaratmak gibi yarÄ±ÅŸmalar hoÅŸuma gitmiyor Ã§Ã¼nkÃ¼ bu tÃ¼r yaklaÅŸÄ±mlar baÅŸka veri setlerinde uygulanamaz.
> 
> 
> 
> **Kaggleâ€™da yarÄ±ÅŸÄ±rken, aynÄ± zamanda Notebooks ve Discussions kategorilerinde Grandmaster oldunuz (ve 1. sÄ±raya yerleÅŸtiniz). Bu iki hedefe yatÄ±rÄ±m yaptÄ±nÄ±z mÄ±?**
> 
> Notebooklar yazmaya Ã§ok zaman ve emek harcadÄ±m, ancak Discussions Grandmaster sÄ±ralamam kendiliÄŸinden oldu.
> 
> 
> 
> **Notebook sÄ±ralamasÄ±na nasÄ±l baÅŸladÄ±nÄ±z?**
> 
> 2018â€™de **DonorsChoose.org Application Screening** adlÄ± Ã¶zel bir yarÄ±ÅŸma vardÄ±. DonorsChoose, Ã¼lke genelindeki kamu okulu Ã¶ÄŸretmenlerinin Ã¶ÄŸrencileri iÃ§in ihtiyaÃ§ duyduklarÄ± malzemeleri ve deneyimleri talep etmelerini saÄŸlayan bir fon. Kazanan Ã§Ã¶zÃ¼mler, leaderboardâ€™daki puanlardan ziyade, Notebookâ€™a yapÄ±lan upvote sayÄ±sÄ±na gÃ¶re belirlendi. Bu ilginÃ§ geldi ve yarÄ±ÅŸma iÃ§in bir Notebook yazdÄ±m. BirÃ§ok katÄ±lÄ±mcÄ± analizlerini sosyal medya Ã¼zerinden duyurdu, ben de aynÄ± ÅŸekilde yaptÄ±m. SonuÃ§ta ikinci sÄ±raya yerleÅŸtim ve bir **Pixelbook** kazandÄ±m (hala kullanÄ±yorum!). Bu baÅŸarÄ± beni Ã§ok motive etti ve Notebook yazmaya devam ettim. Ä°lk baÅŸta yalnÄ±zca analizimi paylaÅŸmak ve geri bildirim almak istiyordum, Ã§Ã¼nkÃ¼ analiz ve gÃ¶rselleÅŸtirme becerilerimi diÄŸer insanlarla karÅŸÄ±laÅŸtÄ±rmak istiyordum. Ä°nsanlar kernelâ€™lerimi beÄŸendi ve becerilerimi daha da geliÅŸtirmek istedim. Bir diÄŸer motivasyonum ise hÄ±zlÄ± bir **MVP** (minimum viable product) yapma becerimi geliÅŸtirmekti. Yeni bir yarÄ±ÅŸma baÅŸladÄ±ÄŸÄ±nda, birÃ§ok kiÅŸi Notebook yazmaya baÅŸlar, eÄŸer ilk olmanÄ±z gerekiyorsa, kaliteden Ã¶dÃ¼n vermeden hÄ±zlÄ± bir ÅŸekilde bunu yapabilmeniz gerekir. Bu zorlu, ancak eÄŸlenceli ve Ã¶dÃ¼llendirici bir sÃ¼reÃ§ti.
> 
> 
> 
> **2019â€™un Åubat ayÄ±nda Notebook Grandmaster sÄ±ralamasÄ±na ulaÅŸtÄ±m ve bir sÃ¼re 1. sÄ±rada kaldÄ±m. Åu anda Notebook yazma sÄ±klÄ±ÄŸÄ±m azaldÄ± ama yine de keyif alÄ±yorum.**
> 
> TartÄ±ÅŸmalar konusunda ise, aslÄ±nda kendiliÄŸinden geliÅŸti. Notebookâ€™larÄ±ma yapÄ±lan yorumlarÄ± yanÄ±tladÄ±m, katÄ±ldÄ±ÄŸÄ±m yarÄ±ÅŸmalarla ilgili fikirlerimi paylaÅŸtÄ±m ve tartÄ±ÅŸmalara katÄ±ldÄ±m, bu da sÄ±ralamamÄ±n sÃ¼rekli artmasÄ±nÄ± saÄŸladÄ±.
> 
> 
> 
> **KarÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlu bir yarÄ±ÅŸma hakkÄ±nda bilgi verir misiniz? Bu gÃ¶revi nasÄ±l ele aldÄ±nÄ±z?**
> 
> Bu, **Predicting Molecular Properties** yarÄ±ÅŸmasÄ±ydÄ±. Bu yarÄ±ÅŸmayÄ± daha detaylÄ± bir ÅŸekilde yazdÄ±m ve [burada](https://towardsdatascience.com/a-story-of-my-first-gold-medal-in-one-kaggle-competition-things-done-and-lessons-learned-c269d9c233d1) okuyabilirsiniz. Bu yarÄ±ÅŸma, molekÃ¼llerdeki atomlar arasÄ±ndaki etkileÅŸimleri tahmin etmeye yÃ¶nelik bir yarÄ±ÅŸmaydÄ±. **NÃ¼kleer Manyetik Rezonans (NMR)**, MRIâ€™ye benzer ilkeler kullanarak proteinlerin ve molekÃ¼llerin yapÄ±sÄ±nÄ± ve dinamiklerini anlamaya yarayan bir teknoloji. AraÅŸtÄ±rmacÄ±lar, dÃ¼nya Ã§apÄ±nda NMR deneyleri yaparak molekÃ¼llerin yapÄ±sÄ± ve dinamikleri hakkÄ±nda daha fazla bilgi edinmeye Ã§alÄ±ÅŸÄ±yor. Bu yarÄ±ÅŸmada, molekÃ¼ldeki iki atom arasÄ±ndaki manyetik etkileÅŸimi tahmin etmeye Ã§alÄ±ÅŸtÄ±k (skaler baÄŸlama sabiti). Kuantum mekaniÄŸinden gelen en son yÃ¶ntemler, yalnÄ±zca 3D molekÃ¼ler yapÄ± verisi kullanarak bu baÄŸlama sabitlerini hesaplayabiliyor. Ancak bu hesaplamalar kaynak aÃ§Ä±sÄ±ndan Ã§ok yoÄŸun olduÄŸu iÃ§in her zaman kullanÄ±labilir deÄŸil. Makine Ã¶ÄŸrenimi yaklaÅŸÄ±mlarÄ± bu deÄŸerleri tahmin edebilirse, bu gerÃ§ekten ilaÃ§ kimyacÄ±larÄ±nÄ±n yapÄ±sal iÃ§gÃ¶rÃ¼leri daha hÄ±zlÄ± ve daha ucuza elde etmelerine yardÄ±mcÄ± olabilir.
> 
> 
> 
> YarÄ±ÅŸmalara genellikle **EDA** (Exploratory Data Analysis) kernelâ€™leri yazarÄ±m, bu yarÄ±ÅŸmada da aynÄ± ÅŸekilde baÅŸladÄ±m. Kaggle yarÄ±ÅŸmalarÄ±nda tabular veriler iÃ§in yaygÄ±n bir yaklaÅŸÄ±m **Ã¶zellik mÃ¼hendisliÄŸi** yapmak ve **gradient boosting modelleri** kullanmaktÄ±r. Erken denemelerimde **LGBM** kullandÄ±m, ancak grafikleri daha iyi kullanmanÄ±n bir yolunun olduÄŸunu biliyordum. Alan bilgisi burada ciddi bir avantaj saÄŸlayacaktÄ±, bu yÃ¼zden bu bilgileri toplamaya baÅŸladÄ±m. Tabii ki, forumda yazan ve kernelâ€™ler oluÅŸturan birkaÃ§ aktif uzman fark ettim, bu yÃ¼zden onlardan her ÅŸeyi okudum. Bir gÃ¼n, bu alandaki bir uzmandan bir e-posta aldÄ±m ve becerilerimizin birbirini tamamlayabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼. Genelde yarÄ±ÅŸmalara yalnÄ±z baÅŸÄ±ma Ã§alÄ±ÅŸmayÄ± tercih ederim, ama bu durumda gÃ¼Ã§lerimizi birleÅŸtirmek iyi bir fikir gibi gÃ¶rÃ¼nÃ¼yordu. Bu karar Ã§ok iyi bir karar oldu! Zamanla harika bir ekip kurmayÄ± baÅŸardÄ±k.
> 
> 
> 
> Bir sÃ¼re sonra yarÄ±ÅŸmada **sinir aÄŸlarÄ±nÄ±n** potansiyelini fark ettik: TanÄ±nmÄ±ÅŸ bir Kaggle katÄ±lÄ±mcÄ±sÄ±, **MPNN (Message Passing Neural Network)** modelinin bir Ã¶rneÄŸini paylaÅŸtÄ±. Bir sÃ¼re sonra bunu Ã§alÄ±ÅŸtÄ±rmayÄ± baÅŸardÄ±m ama sonuÃ§lar bizim modellerimizden daha kÃ¶tÃ¼ydÃ¼. Yine de, ekibimiz bu modellerle yÃ¼ksek hedeflere ulaÅŸmak istiyorsa bu sinir aÄŸlarÄ±yla Ã§alÄ±ÅŸmamÄ±z gerektiÄŸini biliyordu. Christofâ€™un yeni sinir aÄŸlarÄ±nÄ± son derece hÄ±zlÄ± bir ÅŸekilde kurma yeteneÄŸi inanÄ±lmazdÄ±. KÄ±sa sÃ¼re sonra, yalnÄ±zca bu modelleri geliÅŸtirmeye odaklandÄ±k.
> 
> 
> 
> **Ekip olarak 8. sÄ±raya yerleÅŸtik ve bu yarÄ±ÅŸma boyunca Ã§ok ÅŸey Ã¶ÄŸrendim.**
> 
> 
> 
> **Kaggle kariyerinize nasÄ±l yardÄ±mcÄ± oldu?**
> 
> Kaggle kesinlikle hem becerilerime hem de kiÅŸisel markama Ã§ok yardÄ±mcÄ± oldu. Kaggle Notebookâ€™larÄ± yazmak, sadece **EDA** ve **ML** becerilerini Ã¶ÄŸrenmemi saÄŸlamakla kalmadÄ±, aynÄ± zamanda yeni konularÄ± ve gÃ¶revleri hÄ±zla anlayabilme, yaklaÅŸÄ±mlar arasÄ±nda daha verimli bir ÅŸekilde iterasyon yapabilme yeteneÄŸi kazandÄ±rdÄ±. AynÄ± zamanda, yaptÄ±ÄŸÄ±m iÅŸler takdir gÃ¶rdÃ¼ ve bu bana bir gÃ¶rÃ¼nÃ¼rlÃ¼k saÄŸladÄ±. Ä°lk portfÃ¶yÃ¼mde ([erlemar.github.io](https://erlemar.github.io/)) birÃ§ok farklÄ± Notebook vardÄ± ve bunlarÄ±n yarÄ±sÄ± eski Kaggle yarÄ±ÅŸmalarÄ±na dayalÄ±ydÄ±. Bu kesinlikle ilk iÅŸimi bulmamda yardÄ±mcÄ± oldu. Kaggle baÅŸarÄ±larÄ±m, iyi ÅŸirketlerden iÅŸe alÄ±mcÄ±larÄ± cezbetmemi saÄŸladÄ±, bazen mÃ¼lakat sÃ¼recinin bazÄ± adÄ±mlarÄ±nÄ± atlamama yardÄ±mcÄ± oldu ve birkaÃ§ danÄ±ÅŸmanlÄ±k iÅŸi almama da yol aÃ§tÄ±.
> 
> 
> 
> **Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n genellikle gÃ¶z ardÄ± ettikleri ÅŸeyler nelerdir? Åu anda bildiÄŸiniz, ilk baÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz neyi farklÄ± yapardÄ±nÄ±z?**
> 
> Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ± iki gruba ayÄ±rmak gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum: Veri bilimi konusunda deneyimsiz olanlar ve Kaggleâ€™da deneyimsiz olanlar.
> 
> Veri bilimi konusunda deneyimsiz olanlar Ã§eÅŸitli hatalar yapar (ve bu normal, herkes bir yerden baÅŸlamak zorunda):
> 
> 
> 
> * **En ciddi sorunlardan biri:** EleÅŸtirel dÃ¼ÅŸÃ¼nce eksikliÄŸi ve kendi araÅŸtÄ±rmalarÄ±nÄ± yapamama;
> 
> * Hangi araÃ§larÄ±/yaklaÅŸÄ±mlarÄ± ne zaman kullanacaklarÄ±nÄ± bilememe;
> 
> * Kamuya aÃ§Ä±k Notebookâ€™larÄ± kÃ¶rÃ¼ kÃ¶rÃ¼ne alÄ±p, nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamadan kullanma;
> 
> * Bir fikre takÄ±lÄ±p kalma ve bir ÅŸey iÅŸe yaramadÄ±ÄŸÄ±nda bile Ã§ok fazla zaman harcama;
> 
> * Denemeler baÅŸarÄ±sÄ±z olduÄŸunda umutsuzluÄŸa kapÄ±lma ve motivasyonu kaybetme.
> 
> 
> 
> Veri bilimi konusunda deneyimi olan ama Kaggle konusunda deneyimsiz olanlar iÃ§inse ÅŸunu sÃ¶yleyebilirim: **Kaggleâ€™Ä±n zorluÄŸunu kÃ¼Ã§Ã¼msemek** en ciddi hatalarÄ±ndan biridir. Kaggleâ€™Ä±n Ã§ok rekabetÃ§i olduÄŸunu, baÅŸarÄ±lÄ± olmak iÃ§in birÃ§ok farklÄ± ÅŸey denemeniz gerektiÄŸini, sadece yarÄ±ÅŸmalara Ã¶zgÃ¼ birÃ§ok numara olduÄŸunu ve profesyonel olarak yarÄ±ÅŸmalara katÄ±lan insanlar olduÄŸunu beklemiyorlar.
> 
> 
> 
> **YarÄ±ÅŸmalarda geÃ§miÅŸte yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> 
> 
> * Veriye yeterince dikkat etmemek. Bazen daha iyi Ã¶zellikler Ã¼retemedim veya daha iyi post-processing uygulayamadÄ±m.
> 
> * Bir fikre Ã§ok fazla zaman harcamak Ã§Ã¼nkÃ¼ bunun iÅŸe yarayacaÄŸÄ±nÄ± umuyordum (bu bir **sunk-cost** yanÄ±lgÄ±sÄ±).
> 
> * Yeterince deneme yapmamak. Ã‡aba karÅŸÄ±lÄ±ÄŸÄ±nÄ± verir â€“ yarÄ±ÅŸmaya yeterince zaman ve kaynak ayÄ±rmazsanÄ±z, leaderboardâ€™da Ã¼st sÄ±ralarda yer alamazsÄ±nÄ±z.
> 
> * "YanlÄ±ÅŸ" yarÄ±ÅŸmalara katÄ±lmak. SÄ±zdÄ±rma, ters mÃ¼hendislik, vb. iÃ§eren yarÄ±ÅŸmalar oldu.
> 
> * YanlÄ±ÅŸ kiÅŸilerle takÄ±m kurmak. BazÄ± takÄ±m arkadaÅŸlarÄ±m beklediÄŸim kadar aktif deÄŸildi ve bu, takÄ±m sÄ±ralamamÄ±zÄ± kÃ¶tÃ¼leÅŸtirdi.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken en Ã¶nemli ÅŸey nedir?**
> 
> Bence, hedefinizi hatÄ±rlamak, bu yarÄ±ÅŸmaya ne kadar zaman ve Ã§aba yatÄ±rmaya hazÄ±r olduÄŸunuzu bilmek ve olasÄ± sonuÃ§larÄ± dÃ¼ÅŸÃ¼nmek Ã¶nemlidir. Bir yarÄ±ÅŸmaya katÄ±lÄ±rken birÃ§ok farklÄ± hedefiniz olabilir:
> 
> 
> 
> * Para kazanmak ya da madalya almak;
> 
> * Yeni beceriler kazanmak veya mevcut becerileri geliÅŸtirmek;
> 
> * Yeni bir gÃ¶rev/alan Ã¼zerinde Ã§alÄ±ÅŸmak;
> 
> * AÄŸ kurmak;
> 
> * PR yapmak;
> 
> * vb.
> 
> 
> 
> Tabii ki, birden fazla motivasyonunuz olabilir.
> 
> 
> 
> **YarÄ±ÅŸma bittiÄŸinde olacaklarÄ± dÃ¼ÅŸÃ¼nmek Ã¶nemli.** YarÄ±ÅŸmaya Ã§ok yatÄ±rÄ±m yapabilir ve kazanabilirsiniz, ancak kaybedebilirsiniz de. Bu gerÃ§eÄŸe hazÄ±rlÄ±klÄ± mÄ±sÄ±nÄ±z? Kazanmak sizin iÃ§in kritik mi? Belki daha fazla Ã§aba harcamaya hazÄ±rlÄ±klÄ± olmanÄ±z gerekebilir; diÄŸer taraftan belki uzun vadeli hedefleriniz var ve bir baÅŸarÄ±sÄ±z yarÄ±ÅŸma sizi fazla etkilemez.

### Metrics for object detection problems *(Nesne tespiti problemleri iÃ§in metrikler)*

Son yÄ±llarda, derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ± Kaggle'da giderek daha yaygÄ±n hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸu, gÃ¶rÃ¼ntÃ¼ tanÄ±ma veya doÄŸal dil iÅŸleme gÃ¶revlerine odaklanmÄ±ÅŸ olup, ÅŸimdiye kadar incelediÄŸimiz deÄŸerlendirme metriklerinden Ã§ok farklÄ± metrikler kullanmayÄ± gerektirmemiÅŸtir. Ancak, bazÄ± Ã¶zel problemler, doÄŸru bir ÅŸekilde deÄŸerlendirilmesi iÃ§in Ã¶zel bir metrik kullanÄ±lmasÄ±nÄ± gerektirmiÅŸtir: bunlar, nesne tespiti ve segmentasyonla ilgili olanlardÄ±r.

![](im/1047.png)

Nesne tespitinde, bir resmi sÄ±nÄ±flandÄ±rmak yerine, resmin ilgili bÃ¶lÃ¼mlerini bulmanÄ±z ve bunlarÄ± uygun ÅŸekilde etiketlemeniz gerekir. Ã–rneÄŸin, Åekil 5.4'te, bir nesne tespit sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±na, bir fotoÄŸraf iÃ§inde kÃ¶peklerin veya kedilerin bulunduÄŸu bÃ¶lÃ¼mleri yerleÅŸtirip her birini doÄŸru etiketlemesi gÃ¶revi verilmiÅŸtir. Sol taraftaki Ã¶rnek, bir kedinin konumlandÄ±rÄ±lmasÄ±nÄ±, dikdÃ¶rtgen bir kutu (bu kutuya **bounding box** denir) kullanarak gÃ¶steriyor. SaÄŸdaki Ã¶rnek ise, bir fotoÄŸraf iÃ§inde birden fazla kedi ve kÃ¶peÄŸin nasÄ±l tespit edildiÄŸini ve ardÄ±ndan doÄŸru bir ÅŸekilde sÄ±nÄ±flandÄ±rÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶steriyor (mavi kutular kÃ¶pekler iÃ§in, kÄ±rmÄ±zÄ± kutular ise kediler iÃ§in).

Nesne tespitinde, bir nesnenin mekansal konumunu tanÄ±mlamak iÃ§in **bounding box**'lar kullanÄ±lÄ±r; bu kutular, nesnenin bulunduÄŸu dikdÃ¶rtgen alanÄ± tanÄ±mlar. Bir **bounding box** genellikle iki (x, y) koordinatÄ±yla belirtilir: Ã¼st-sol kÃ¶ÅŸe ve alt-saÄŸ kÃ¶ÅŸe. Bir makine Ã¶ÄŸrenimi algoritmasÄ± aÃ§Ä±sÄ±ndan, bounding box'larÄ±n koordinatlarÄ±nÄ± bulmak, birden fazla hedefe uygulanan bir regresyon problemine karÅŸÄ±lÄ±k gelir. Ancak, problemi sÄ±fÄ±rdan Ã§Ã¶zmeyeceksiniz; bunun yerine genellikle **Mask R-CNN** ([https://arxiv.org/abs/1703.06870](https://arxiv.org/abs/1703.06870)), **RetinaNet** ([https://arxiv.org/abs/2106.05624v1](https://arxiv.org/abs/2106.05624v1)), **FPN** ([https://arxiv.org/abs/1612.03144v2](https://arxiv.org/abs/1612.03144v2)), **YOLO** ([https://arxiv.org/abs/1506.02640v1](https://arxiv.org/abs/1506.02640v1)), **Faster R-CNN** ([https://arxiv.org/abs/1506.01497v1](https://arxiv.org/abs/1506.01497v1)) veya **SSD** ([https://arxiv.org/abs/1512.02325](https://arxiv.org/abs/1512.02325)) gibi Ã¶nceden oluÅŸturulmuÅŸ ve Ã§oÄŸu zaman Ã¶nceden eÄŸitilmiÅŸ modellere baÅŸvuracaksÄ±nÄ±z.

**Segmentasyonda** ise, piksel seviyesinde bir sÄ±nÄ±flandÄ±rma yapÄ±lÄ±r. Yani, eÄŸer 320x200 boyutlarÄ±nda bir resminiz varsa, aslÄ±nda 64.000 piksel sÄ±nÄ±flandÄ±rmasÄ± yapmanÄ±z gerekir. GÃ¶reve baÄŸlÄ± olarak, her pikseli bir fotoÄŸrafÄ±n iÃ§inde sÄ±nÄ±flandÄ±rmanÄ±z gereken **semantik segmentasyon** olabilir ya da yalnÄ±zca belirli bir ilgi tÃ¼rÃ¼ndeki nesneleri (Ã¶rneÄŸin, Åekil 5.5'teki gibi bir kedi) temsil eden pikselleri sÄ±nÄ±flandÄ±rmanÄ±z gereken **instance segmentasyon** olabilir.

![](im/1048.png)

Bu gÃ¶revler iÃ§in Ã¶zel metriklerin genel bir gÃ¶rÃ¼nÃ¼mÃ¼ne baÅŸlayalÄ±m; Ã§Ã¼nkÃ¼ her iki problemde de (nesne tespitinde dikdÃ¶rtgen, segmentasyonda ise Ã§okgen olan) bir resmin tamamÄ±nÄ± tahmin ediyorsunuz ve tahminlerinizi gerÃ§ek etiketlerle karÅŸÄ±laÅŸtÄ±rmanÄ±z gerekiyor, bu etiketler de yine alanlar olarak ifade ediliyor. Segmentasyon tarafÄ±nda, en basit metrik **piksel doÄŸruluÄŸu**dur; adÄ± Ã¼zerinde, bu metrik, piksel sÄ±nÄ±flandÄ±rmasÄ±ndaki doÄŸruluÄŸu Ã¶lÃ§er.

Bu metrik mÃ¼kemmel bir seÃ§im deÄŸildir, Ã§Ã¼nkÃ¼ **ikili ve Ã§ok sÄ±nÄ±flÄ± problemlerdeki doÄŸruluk** gibi, eÄŸer ilgili pikseller resmin Ã§ok kÃ¼Ã§Ã¼k bir kÄ±smÄ±nÄ± oluÅŸturuyorsa, skoru yÃ¼ksek gÃ¶rÃ¼nebilir (sadece Ã§oÄŸunluk sÄ±nÄ±fÄ±nÄ± tahmin edersiniz, bu da segmentasyon yapmadÄ±ÄŸÄ±nÄ±z anlamÄ±na gelir).

Bu nedenle, Ã¶zellikle yarÄ±ÅŸmalarda daha sÄ±k kullanÄ±lan iki metrik vardÄ±r: **intersection over union** (IoU) ve **dice katsayÄ±sÄ±** (Dice coefficient).

#### Intersection over union (IoU) *(KesiÅŸim/BirleÅŸim oranÄ±)*

**Intersection over union (IoU)**, aynÄ± zamanda **Jaccard indeksi** olarak da bilinir. Segmentasyon problemlerinde IoU kullanmak, karÅŸÄ±laÅŸtÄ±rmanÄ±z gereken iki resminiz olduÄŸu anlamÄ±na gelir: biri sizin tahmininiz, diÄŸeri ise genellikle **1** deÄŸeriyle doÄŸru etiketleri (ground truth) temsil eden ve **0** ile diÄŸer bÃ¶lgeleri gÃ¶steren bir **binary maske**dir. Birden fazla nesne olduÄŸunda, her bir nesne iÃ§in ayrÄ± bir maske olur ve her maske, nesnenin sÄ±nÄ±fÄ±yla etiketlenir.

Nesne tespiti problemlerinde IoU kullanÄ±ldÄ±ÄŸÄ±nda ise, tahmin ve doÄŸru etiketin (ground truth) dikdÃ¶rtgen alanlarÄ±nÄ±n sÄ±nÄ±rlarÄ± vardÄ±r, bu sÄ±nÄ±rlar da kÃ¶ÅŸe noktalarÄ±nÄ±n koordinatlarÄ±yla ifade edilir. Her bir sÄ±nÄ±flandÄ±rÄ±lan sÄ±nÄ±f iÃ§in, tahmininiz ile doÄŸru etiketin maskesi arasÄ±ndaki Ã¶rtÃ¼ÅŸen alanÄ± hesaplar ve bunu, tahmininiz ile doÄŸru etiket arasÄ±ndaki birleÅŸim alanÄ±na (yani her iki alanÄ±n toplamÄ±) bÃ¶lersiniz; bu toplam, herhangi bir Ã¶rtÃ¼ÅŸmeyi dikkate alÄ±r. Bu ÅŸekilde, tahmin ettiÄŸiniz alan fazla bÃ¼yÃ¼kse (payda daha bÃ¼yÃ¼k olur) veya Ã§ok kÃ¼Ã§Ã¼kse (pay daha kÃ¼Ã§Ã¼k olur) orantÄ±lÄ± olarak cezalandÄ±rÄ±lÄ±rsÄ±nÄ±z.

![](im/1049.png)

Åekil 5.6'da, hesaplamada yer alan alanlarÄ±n gÃ¶rsel bir temsilini gÃ¶rebilirsiniz. Karelerin daha fazla Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ hayal ederek, metriklerin, tahmininiz doÄŸru etiketi kapsasa bile, bunu aÅŸtÄ±ÄŸÄ±nda (birleÅŸim alanÄ± bÃ¼yÃ¼dÃ¼ÄŸÃ¼nde) Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ nasÄ±l etkili bir ÅŸekilde cezalandÄ±rdÄ±ÄŸÄ±nÄ± anlayabilirsiniz.

> Ä°ÅŸte IoU'nun kullanÄ±ldÄ±ÄŸÄ± bazÄ± yarÄ±ÅŸmalarÄ±n Ã¶rnekleri:
> 
> 
> 
> * **TGS Salt Identification Challenge** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/tgs-salt-identification-challenge/)) â€” Intersection Over Union Nesne Segmentasyonu
> 
> * **iMaterialist (Fashion) 2019 at FGVC6** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6)) â€” Intersection Over Union Nesne Segmentasyonu ve SÄ±nÄ±flandÄ±rma
> 
> * **Airbus Ship Detection Challenge** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/airbus-ship-detection)) â€” Intersection Over Union Nesne Segmentasyonu Beta
> 
> 

#### Dice *(Dice katsayÄ±sÄ±)*

DiÄŸer yararlÄ± metrik ise **Dice katsayÄ±sÄ±**dÄ±r; bu, tahmin ile doÄŸru etiket arasÄ±ndaki Ã¶rtÃ¼ÅŸen alanÄ±n iki katÄ±na Ã§Ä±karÄ±lmasÄ± ve ardÄ±ndan tahmin ile doÄŸru etiket alanlarÄ±nÄ±n toplamÄ±na bÃ¶lÃ¼nmesiyle hesaplanÄ±r.

![](im/1050.png)

Bu durumda, **Jaccard indeksi**ne kÄ±yasla, tahminin doÄŸru etiketle Ã¶rtÃ¼ÅŸen kÄ±smÄ± paydada dikkate alÄ±nmaz. Burada beklenti, Ã¶rtÃ¼ÅŸen alanÄ± maksimize ederken doÄŸru alan boyutunu tahmin etmenizdir. Yine, tahmin ettiÄŸiniz alanlar olmasÄ± gerekenden daha bÃ¼yÃ¼kse cezalandÄ±rÄ±lÄ±rsÄ±nÄ±z. AslÄ±nda, bu iki metrik pozitif olarak korelasyonlu olup, tek bir sÄ±nÄ±flandÄ±rma problemi iÃ§in neredeyse aynÄ± sonuÃ§larÄ± Ã¼retir.

Farklar, aslÄ±nda birden fazla sÄ±nÄ±fla Ã§alÄ±ÅŸÄ±rken ortaya Ã§Ä±kar. Hem IoU hem de Dice katsayÄ±sÄ± ile birden fazla sÄ±nÄ±f olduÄŸunda, tÃ¼m sÄ±nÄ±flarÄ±n sonuÃ§larÄ±nÄ±n ortalamasÄ±nÄ± alÄ±rsÄ±nÄ±z. Ancak, bunu yaparken, **IoU** metrik, bir sÄ±nÄ±f tahmini yanlÄ±ÅŸ olduÄŸunda genel ortalamayÄ± daha fazla cezalandÄ±rma eÄŸilimindeyken, **Dice katsayÄ±sÄ±** daha hoÅŸgÃ¶rÃ¼lÃ¼ olup, ortalama performansÄ± temsil etme eÄŸilimindedir.

> **Dice katsayÄ±sÄ±nÄ± kullanan bazÄ± Kaggle yarÄ±ÅŸmalarÄ±nÄ±n Ã¶rnekleri** (genellikle tÄ±bbi amaÃ§lÄ± yarÄ±ÅŸmalarda sÄ±kÃ§a karÅŸÄ±laÅŸÄ±lsa da, sadece orada deÄŸil, bulutlar ve arabalar gibi diÄŸer alanlarda da kullanÄ±labilir):
> 
> 
> 
> * **HuBMAP - Hacking the Kidney**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/hubmap-kidney-segmentation)
> 
> * **Ultrasound Nerve Segmentation**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/ultrasound-nerve-segmentation)
> 
> * **Understanding Clouds from Satellite Images**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/understanding_cloud_organization)
> 
> * **Carvana Image Masking Challenge**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/carvana-image-masking-challenge)

**IoU** ve **Dice katsayÄ±sÄ±**, segmentasyon ve nesne tespiti alanÄ±ndaki daha karmaÅŸÄ±k metriklerin temelini oluÅŸturur. IoU veya Dice iÃ§in uygun bir eÅŸik seviyesi (genellikle 0.5) seÃ§erek, bir tespiti onaylayÄ±p onaylamayacaÄŸÄ±nÄ±za karar verebilirsiniz, dolayÄ±sÄ±yla bir sÄ±nÄ±flandÄ±rma yapabilirsiniz. Bu noktada, daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z sÄ±nÄ±flandÄ±rma metriklerini (kesinlik, duyarlÄ±lÄ±k, F1 gibi) kullanabilirsiniz; bu, **Pascal VOC** ([http://host.robots.ox.ac.uk/pascal/VOC/voc2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012)) veya **COCO** ([https://cocodataset.org](https://cocodataset.org)) gibi popÃ¼ler nesne tespiti ve segmentasyon yarÄ±ÅŸmalarÄ±nda olduÄŸu gibi yapÄ±lÄ±r.

### Metrics for multi-label classification and recommendation problems *(Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri problemleri iÃ§in metrikler)*

**Ã–neri sistemleri**, veri analizi ve makine Ã¶ÄŸreniminin en popÃ¼ler uygulamalarÄ±ndan biridir ve Kaggle'da bu tÃ¼r Ã¶neri yaklaÅŸÄ±mlarÄ±nÄ± kullanan birÃ§ok yarÄ±ÅŸma bulunmaktadÄ±r. Ã–rneÄŸin, **Quick, Draw! Doodle Recognition Challenge**, bir Ã¶neri sistemi olarak deÄŸerlendirilen bir tahmin yarÄ±ÅŸmasÄ±ydÄ±. Ancak, Kaggle'daki diÄŸer bazÄ± yarÄ±ÅŸmalar gerÃ§ekten etkili Ã¶neri sistemleri oluÅŸturmayÄ± hedeflemiÅŸtir (Ã¶rneÄŸin, **Expedia Hotel Recommendations**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/expedia-hotel-recommendations)) ve **RecSYS**, Ã¶neri sistemleri konferansÄ± ([https://recsys.acm.org/](https://recsys.acm.org/)), her yÄ±l dÃ¼zenlediÄŸi yarÄ±ÅŸmalardan birini Kaggle Ã¼zerinde gerÃ§ekleÅŸtirmiÅŸtir (RecSYS 2013: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/yelp-recsys-2013)).

**MAP@K (Mean Average Precision at K)**, Ã¶neri sistemlerinin performansÄ±nÄ± deÄŸerlendirmek iÃ§in tipik olarak tercih edilen metrik olup, Kaggle'da, Ã¶neri sistemleriyle ilgili yarÄ±ÅŸmalarÄ±n Ã§oÄŸunda karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z en yaygÄ±n metriktir. Bunun yanÄ± sÄ±ra, **P@K (precision at k)** veya **AP@K (average precision at k)** gibi bazÄ± diÄŸer metrikler de vardÄ±r; bunlar kayÄ±p fonksiyonlarÄ±dÄ±r, yani her bir tekil tahmin dÃ¼zeyinde hesaplanÄ±rlar. Bu metriklerin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamak, MAP@K'yi daha iyi anlamanÄ±zÄ± saÄŸlayabilir ve bu metriklerin hem Ã¶nerilerde hem de Ã§oklu etiketli sÄ±nÄ±flandÄ±rmada nasÄ±l performans gÃ¶sterdiÄŸi konusunda size yardÄ±mcÄ± olabilir.

AslÄ±nda, Ã¶neri sistemleriyle benzer ÅŸekilde, **Ã§oklu etiketli sÄ±nÄ±flandÄ±rmalar**, modelinizin bir dizi sÄ±nÄ±f tahmini Ã¼retmesini ima eder. Bu tÃ¼r sonuÃ§lar, bazÄ± **ikili sÄ±nÄ±flandÄ±rma metriklerinin** ortalamasÄ± (Ã¶rneÄŸin, **Greek Media Monitoring Multilabel Classification** (WISE 2014), bu yarÄ±ÅŸma **ortalama F1 skoru**nu kullandÄ±: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/wise-2014)) ve Ã¶neri sistemlerine daha Ã¶zgÃ¼ metrikler, Ã¶rneÄŸin **MAP@K** gibi metrikler kullanÄ±larak deÄŸerlendirilebilir. SonuÃ§ olarak, hem Ã¶neri sistemleri hem de Ã§oklu etiketli tahminler, bir **sÄ±ralama gÃ¶revi** olarak ele alÄ±nabilir; bu, Ã¶neri sistemlerinde sÄ±ralanmÄ±ÅŸ Ã¶neriler ve Ã§oklu etiketli sÄ±nÄ±flandÄ±rmada (belirli bir sÄ±ralama olmadan) etiketlerin bir setine dÃ¶nÃ¼ÅŸÃ¼r.

#### MAP@K *(MAP@K metriÄŸi)*

**MAP@K**, karmaÅŸÄ±k bir metriktir ve birÃ§ok hesaplamadan tÃ¼retilir. MAP@K metriÄŸini tam olarak anlayabilmek iÃ§in, Ã¶nce en basit bileÅŸeni olan **precision at k (P@K)** ile baÅŸlayalÄ±m. Bu durumda, bir Ã¶rneÄŸin tahmini, sÄ±ralanmÄ±ÅŸ tahminler dizisi (en olasÄ±dan en az olasÄ±lÄ±klÄ±ya kadar) olduÄŸundan, fonksiyon yalnÄ±zca en Ã¼stteki **k** tahmini dikkate alÄ±r ve ardÄ±ndan, doÄŸru etiketle ne kadar eÅŸleÅŸme saÄŸladÄ±ÄŸÄ±nÄ± hesaplar ve bu sayÄ±yÄ± **k**'ye bÃ¶ler. KÄ±sacasÄ±, bu, **k** tahmini Ã¼zerinden ortalama alÄ±nmÄ±ÅŸ bir doÄŸruluk Ã¶lÃ§Ã¼sÃ¼ne oldukÃ§a benzer.

Biraz daha karmaÅŸÄ±k bir hesaplama gerektiren ama kavramsal olarak basit olan **average precision at k (AP@K)**, **P@K**'nin **1**'den **k**'ye kadar olan tÃ¼m deÄŸerler Ã¼zerinde hesaplanÄ±p ortalamasÄ±nÄ±n alÄ±nmasÄ±dÄ±r. Bu ÅŸekilde, metrik, tahminin ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± genel olarak deÄŸerlendirir; ilk tahmin, ardÄ±ndan ilk iki tahmin, ve devam ederek **k** tahmine kadar.

Son olarak, **MAP@K**, tÃ¼m tahmin Ã¶rnekleri iÃ§in AP@K'nin ortalamasÄ±dÄ±r ve bu metrik, tÃ¼m tahminleri deÄŸerlendirdiÄŸi iÃ§in bir metriktir. Ä°ÅŸte **MAP@5** formÃ¼lasyonu, **Expedia Hotel Recommendations** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/expedia-hotel-recommendations](https://www.kaggle.com/c/expedia-hotel-recommendations)) bulabileceÄŸiniz formÃ¼l:

GÃ¶rÃ¼ntÃ¼de, **MAP@5** metriÄŸi iÃ§in kullanÄ±lan formÃ¼lÃ¼n bir versiyonu yer alÄ±yor. Bu formÃ¼l, Ã¶neri sistemlerinde doÄŸruluÄŸun deÄŸerlendirilmesi iÃ§in kullanÄ±lÄ±r ve ÅŸu ÅŸekilde ifade edilebilir:

$$
\text{MAP@5} = \frac{1}{|U|} \sum_{u=1}^{|U|} \sum_{k=1}^{\min(5, n)} P(k)
$$

Bu formÃ¼lde:

* **|U|**, kullanÄ±cÄ± sayÄ±sÄ±nÄ±,
* **P(k)**, k'ncÄ± tahminin doÄŸruluÄŸunu,
* **n**, tahmin edilen Ã¶ÄŸe sayÄ±sÄ±nÄ±,
* **min(5, n)**, en fazla 5 tahmin yapÄ±lmasÄ±nÄ± belirler.

Bu aÃ§Ä±klama biraz daha karmaÅŸÄ±k olsa da, formÃ¼l aslÄ±nda **MAP@K**'nin tÃ¼m tahminler Ã¼zerindeki **AP@K** deÄŸerlendirmelerinin ortalamasÄ±nÄ± ifade ettiÄŸini gÃ¶sterir.

Bu Ã¶zel metriklerin, regresyon ve sÄ±nÄ±flandÄ±rma metrikleri Ã¼zerindeki genel bakÄ±ÅŸÄ±mÄ±zÄ± tamamladÄ±ktan sonra, bir **Kaggle yarÄ±ÅŸmasÄ±nda** deÄŸerlendirme metrikleriyle nasÄ±l baÅŸa Ã§Ä±kÄ±lacaÄŸÄ±na dair tartÄ±ÅŸmaya geÃ§elim.

### Optimizing evaluation metrics *(DeÄŸerlendirme metriklerini optimize etme)*

Åimdiye kadar tartÄ±ÅŸtÄ±klarÄ±mÄ±zÄ± Ã¶zetleyecek olursak, **amaÃ§ fonksiyonu**, Ã¶ÄŸrenme algoritmanÄ±zÄ±n iÃ§inde, algoritmanÄ±n iÃ§ modelinin saÄŸlanan verilere ne kadar iyi uyduÄŸunu Ã¶lÃ§en bir fonksiyondur. AmaÃ§ fonksiyonu ayrÄ±ca algoritmaya, ardÄ±ÅŸÄ±k iterasyonlar boyunca uyumunu iyileÅŸtirebilmesi iÃ§in geri bildirim saÄŸlar. AÃ§Ä±kÃ§a sÃ¶ylemek gerekirse, algoritmanÄ±n tÃ¼m Ã§abalarÄ±, amaÃ§ fonksiyonuna dayanarak iyi performans gÃ¶stermeye yÃ¶nlendirilir. EÄŸer Kaggle deÄŸerlendirme metriÄŸi, algoritmanÄ±zÄ±n amaÃ§ fonksiyonu ile mÃ¼kemmel bir ÅŸekilde Ã¶rtÃ¼ÅŸÃ¼yorsa, en iyi sonuÃ§larÄ± alÄ±rsÄ±nÄ±z.

Ne yazÄ±k ki, bu durum sÄ±kÃ§a geÃ§erli deÄŸildir. Ã‡oÄŸu zaman, saÄŸlanan deÄŸerlendirme metriÄŸi yalnÄ±zca mevcut amaÃ§ fonksiyonlarÄ±yla yaklaÅŸÄ±k olarak elde edilebilir. Ä°yi bir yaklaÅŸÄ±k sonuÃ§ elde etmek veya tahminlerinizi deÄŸerlendirme kriterlerine gÃ¶re daha iyi hale getirmek, Kaggle yarÄ±ÅŸmalarÄ±nda iyi performans gÃ¶stermek iÃ§in sÄ±rrÄ±nÄ±zdÄ±r. AmaÃ§ fonksiyonunuz, deÄŸerlendirme metriÄŸinizle Ã¶rtÃ¼ÅŸmÃ¼yorsa, birkaÃ§ alternatifiniz vardÄ±r:

1. **Ã–ÄŸrenme algoritmanÄ±zÄ± deÄŸiÅŸtirmek** ve deÄŸerlendirme metriÄŸinizle uyumlu bir amaÃ§ fonksiyonu eklemek; ancak bu, tÃ¼m algoritmalar iÃ§in mÃ¼mkÃ¼n deÄŸildir (Ã¶rneÄŸin, **LightGBM** ve **XGBoost** gibi algoritmalar, Ã¶zel amaÃ§ fonksiyonlarÄ± ayarlamanÄ±za izin verir, ancak Ã§oÄŸu **Scikit-learn** modeli bunu desteklemez).

2. **Modelinizin hiperparametrelerini ayarlamak**, deÄŸerlendirme metriÄŸi kullanÄ±ldÄ±ÄŸÄ±nda en iyi sonucu veren parametreleri seÃ§mek.

3. **SonuÃ§larÄ±nÄ±zÄ± post-process etmek**, bÃ¶ylece deÄŸerlendirme kriterlerine daha yakÄ±n hale gelmesini saÄŸlamak. Ã–rneÄŸin, tahminleriniz Ã¼zerinde dÃ¶nÃ¼ÅŸÃ¼mler yapan bir optimizasyon algoritmasÄ± yazabilirsiniz (Ã¶rneÄŸin, **probabilite kalibrasyonu algoritmalarÄ±**, bu algoritmalarÄ± bÃ¶lÃ¼mÃ¼n sonunda tartÄ±ÅŸacaÄŸÄ±z).

YarÄ±ÅŸma metriÄŸini, makine Ã¶ÄŸrenimi algoritmanÄ±za entegre etmek, daha iyi tahminler elde etmenin gerÃ§ekten en etkili yÃ¶ntemidir; ancak yalnÄ±zca birkaÃ§ algoritma, yarÄ±ÅŸma metriÄŸini amaÃ§ fonksiyonu olarak kullanacak ÅŸekilde hacklenebilir. Bu nedenle, ikinci yaklaÅŸÄ±m daha yaygÄ±n olanÄ±dÄ±r ve birÃ§ok yarÄ±ÅŸma, modelinizin deÄŸerlendirme metriÄŸi Ã¼zerinde en iyi performansÄ± gÃ¶sterebilmesi iÃ§in doÄŸru hiperparametreleri bulma mÃ¼cadelesine dÃ¶nÃ¼ÅŸÃ¼r.

EÄŸer deÄŸerlendirme fonksiyonunuz kodlanmÄ±ÅŸsa, doÄŸru **cross-validation** yapmak veya uygun test setini seÃ§mek bÃ¼yÃ¼k bir fark yaratacaktÄ±r. EÄŸer kodlanmÄ±ÅŸ bir fonksiyonunuz yoksa, Ã¶nce Kaggle tarafÄ±ndan saÄŸlanan formÃ¼lleri takip ederek uygun ÅŸekilde kodlamanÄ±z gerekir.

Her zaman, ÅŸu adÄ±mlar fark yaratacaktÄ±r:

* DeÄŸerlendirme metriÄŸi ve kodlanmÄ±ÅŸ fonksiyonu hakkÄ±nda arama motorlarÄ±ndan tÃ¼m ilgili bilgileri aramak
* En yaygÄ±n paketleri incelemek (Ã¶rneÄŸin, **Scikit-learn**: [model deÄŸerlendirme](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation) veya **TensorFlow**: [keras kayÄ±plarÄ±](https://www.tensorflow.org/api_docs/python/tf/keras/losses))
* **GitHub projelerini** taramak (Ã¶rneÄŸin, **Ben Hammerâ€™Ä±n Metrics** projesi: [Ben Hammer Metrics GitHub](https://github.com/benhamner/Metrics))
* Forumlarda ve mevcut Kaggle Notebooks'larda (hem mevcut yarÄ±ÅŸma iÃ§in hem de benzer yarÄ±ÅŸmalar iÃ§in) sormak veya bakmak
* AyrÄ±ca, daha Ã¶nce belirttiÄŸimiz gibi, **Meta Kaggle veri setini** sorgulamak ([Meta Kaggle](https://www.kaggle.com/kaggle/meta-kaggle)) ve **Competitions** tablosuna bakmak, aynÄ± deÄŸerlendirme metriÄŸini kullanan diÄŸer Kaggle yarÄ±ÅŸmalarÄ±nÄ± bulmanÄ±za yardÄ±mcÄ± olacaktÄ±r ve bu size hemen kullanÄ±ÅŸlÄ± kodlar ve fikirler saÄŸlayacaktÄ±r.

DeÄŸerlendirme metriÄŸiniz, algoritmanÄ±zÄ±n amaÃ§ fonksiyonu ile Ã¶rtÃ¼ÅŸmediÄŸinde, sahip olduÄŸunuz alternatifleri daha ayrÄ±ntÄ±lÄ± olarak tartÄ±ÅŸalÄ±m. **Ã–zel metrikler** ile baÅŸlayalÄ±m.

### Custom metrics and custom objective functions *(Ã–zel metrikler ve Ã¶zel hedef fonksiyonlarÄ±)*

**AmaÃ§ fonksiyonunuz, deÄŸerlendirme metriÄŸinizle Ã¶rtÃ¼ÅŸmediÄŸinde ilk seÃ§enek olarak**, yukarÄ±da Ã¶ÄŸrendiÄŸimiz gibi, kendi **Ã¶zel amaÃ§ fonksiyonunuzu** yaratabilirsiniz, ancak sadece bazÄ± algoritmalar, Ã¶zel bir amaÃ§ fonksiyonunu kolayca entegre etmenize izin verir.

Ä°yi haber ÅŸu ki, bu tÃ¼r fonksiyonlarÄ± ekleyebilen birkaÃ§ algoritma, Kaggle yarÄ±ÅŸmalarÄ±nda ve veri bilimi projelerinde en etkili olanlar arasÄ±ndadÄ±r. Tabii ki, kendi Ã¶zel amaÃ§ fonksiyonunuzu oluÅŸturmak biraz karmaÅŸÄ±k gÃ¶rÃ¼nebilir, ancak bu yaklaÅŸÄ±m, bir yarÄ±ÅŸmada puanÄ±nÄ±zÄ± artÄ±rmak iÃ§in inanÄ±lmaz derecede Ã¶dÃ¼llendirici olabilir. Ã–rneÄŸin, **gradient boosting** algoritmalarÄ±nda (**XGBoost**, **CatBoost**, **LightGBM**) ve **TensorFlow** veya **PyTorch** tabanlÄ± tÃ¼m derin Ã¶ÄŸrenme modellerinde, kendi Ã¶zel amaÃ§ fonksiyonlarÄ±nÄ±zÄ± oluÅŸturma seÃ§eneÄŸiniz vardÄ±r.

**TensorFlow** ve **PyTorch**'ta Ã¶zel metrikler ve amaÃ§ fonksiyonlarÄ± iÃ§in harika Ã¶ÄŸreticiler bulabilirsiniz:

* [Custom Metrics in Keras and How Simple They Are to Use in TensorFlow2](https://towardsdatascience.com/custom-metrics-in-keras-and-how-simple-they-are-to-use-in-tensorflow2-2-6d079c2ca279)
* [Advanced Keras Custom Loss Functions](https://petamind.com/advanced-keras-custom-loss-functions/)
* [PyTorch Metric Learning Custom Loss Functions](https://kevinmusgrave.github.io/pytorch-metric-learning/extend/losses/)

Bu kaynaklar, size Ã¶zel bir amaÃ§ veya deÄŸerlendirme fonksiyonu kodlamanÄ±n temel ÅŸablonlarÄ±nÄ± ve bazÄ± kullanÄ±ÅŸlÄ± Ã¶nerileri sunacaktÄ±r.

> **Ã–zel bir amaÃ§ fonksiyonu oluÅŸturmak iÃ§in ihtiyacÄ±nÄ±z olanÄ± hemen almak isterseniz**, RNA tarafÄ±ndan yazÄ±lmÄ±ÅŸ bu Notebook'u ([https://www.kaggle.com/bigironsphere](https://www.kaggle.com/bigironsphere)): [Loss Function Library Keras/PyTorch](https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch/) inceleyebilirsiniz. Bu Notebook, farklÄ± yarÄ±ÅŸmalarda kullanÄ±lan, **TensorFlow** ve **PyTorch** iÃ§in Ã§ok sayÄ±da Ã¶zel kayÄ±p fonksiyonu iÃ§ermektedir.

**LightGBM, XGBoost veya CatBoost'ta Ã¶zel bir kayÄ±p fonksiyonu oluÅŸturmanÄ±z gerektiÄŸinde**, ilgili dokÃ¼mantasyonlarÄ±nda belirtildiÄŸi gibi, tahmin ve doÄŸru etiketleri (ground truth) girdi olarak alan ve Ã§Ä±ktÄ±larÄ±nda **gradient** ve **hessian** dÃ¶ndÃ¼ren bir fonksiyon yazmanÄ±z gerekecektir.

> Gradient ve hessian'Ä±n ne olduÄŸunu daha iyi anlamak iÃ§in ÅŸu Stack Overflow yazÄ±sÄ±nÄ± inceleyebilirsiniz: [Gradient ve Hessian HesaplamasÄ±](https://stats.stackexchange.com/questions/231220/how-to-compute-the-gradient-and-hessian-of-logarithmic-loss-question-is-based).

Kod uygulama aÃ§Ä±sÄ±ndan, yapmanÄ±z gereken tek ÅŸey, fonksiyonu yaratmak ve gerekirse daha fazla parametre geÃ§mek iÃ§in **closures** kullanmaktÄ±r. Ä°ÅŸte, **focal loss** adlÄ± bir kayÄ±p fonksiyonu Ã¶rneÄŸi (bu kayÄ±p, sÄ±nÄ±f dengesizliÄŸini dikkate alarak kayÄ±p hesaplamalarÄ±na daha fazla aÄŸÄ±rlÄ±k verir, Lin, T-Y. et al.'Ä±n **Focal loss for dense object detection** adlÄ± makalesinde aÃ§Ä±klandÄ±ÄŸÄ± gibi: [Focal Loss Makalesi](https://arxiv.org/abs/1708.02002)):

```python
from scipy.misc import derivative
import xgboost as xgb

def focal_loss(alpha, gamma):
    def loss_func(y_pred, y_true):
        a, g = alpha, gamma
        def get_loss(y_pred, y_true):
            p = 1 / (1 + np.exp(-y_pred))
            loss = (-(a * y_true + (1 - a)*(1 - y_true)) *
                    ((1 - (y_true * p + (1 - y_true) * (1 - p)))**g) *
                    (y_true * np.log(p) + (1 - y_true) * np.log(1 - p)))
            return loss
        partial_focal = lambda y_pred: get_loss(y_pred, y_true)
        grad = derivative(partial_focal, y_pred, n=1, dx=1e-6)
        hess = derivative(partial_focal, y_pred, n=2, dx=1e-6)
        return grad, hess
    return loss_func

xgb = xgb.XGBClassifier(objective=focal_loss(alpha=0.25, gamma=1))
```

YukarÄ±daki kod Ã¶rneÄŸinde, **focal_loss** adlÄ± yeni bir maliyet fonksiyonu tanÄ±mladÄ±k, ardÄ±ndan bunu bir **XGBoost** Ã¶rneÄŸine yerleÅŸtirdik. Bu Ã¶rnek, focal loss'un dÃ¼zgÃ¼n Ã§alÄ±ÅŸabilmesi iÃ§in bazÄ± parametrelerin (alpha ve gamma) doÄŸru ÅŸekilde tanÄ±mlanmasÄ±nÄ± gerektirir. Fonksiyonun iÃ§inde bu parametrelerin doÄŸrudan kodlanmasÄ± yerine, parametreler fonksiyona girildiÄŸinde bellekte saklanÄ±r ve **loss_func** fonksiyonu tarafÄ±ndan referans alÄ±nÄ±r.

Bir diÄŸer ilginÃ§ nokta ise, SciPyâ€™nin **derivative** fonksiyonu aracÄ±lÄ±ÄŸÄ±yla, maliyet fonksiyonunun **gradient** ve **hessian**'Ä±nÄ± hesaplamanÄ±n oldukÃ§a kolay olmasÄ±dÄ±r. EÄŸer maliyet fonksiyonunuz tÃ¼revlenebilir ise, herhangi bir hesaplama yapmanÄ±z gerekmez.

**Ã–zel bir amaÃ§ fonksiyonu oluÅŸturmak, matematiksel bilgi ve Ã§ok fazla Ã§aba gerektirir**, ancak bunu baÅŸarmak, Kaggle yarÄ±ÅŸmalarÄ±nda modelinizden maksimum sonucu almanÄ±zda gerÃ§ekten belirleyici olabilir.

EÄŸer kendi amaÃ§ fonksiyonunuzu oluÅŸturmak iÅŸe yaramazsa, daha az iddialÄ± olabilirsiniz, fonksiyonu **deÄŸerlendirme metriÄŸi** olarak kullanarak bunu doÄŸrudan **optimizer** iÃ§inde kullanmak yerine, bir **Ã¶zel deÄŸerlendirme metriÄŸi** olarak kodlayabilirsiniz. Modeliniz bu fonksiyonla doÄŸrudan optimize edilmemiÅŸ olsa da, yine de hiperparametre optimizasyonu yaparak tahmin performansÄ±nÄ± iyileÅŸtirebilirsiniz. Bu, Ã¶nceki bÃ¶lÃ¼mde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ikinci seÃ§enektir.

EÄŸer sÄ±fÄ±rdan bir metrik yazÄ±yorsanÄ±z, bazen fonksiyonunuzun dÃ¼zgÃ¼n Ã§alÄ±ÅŸabilmesi iÃ§in belirli kodlama kurallarÄ±na uymanÄ±z gerektiÄŸini unutmayÄ±n. Ã–rneÄŸin, **Scikit-learn** kullanÄ±yorsanÄ±z, fonksiyonlarÄ±nÄ±zÄ± **make_scorer** fonksiyonu ile dÃ¶nÃ¼ÅŸtÃ¼rmeniz gerekir. **make_scorer** fonksiyonu, deÄŸerlendirme fonksiyonunuzu **Scikit-learn** API'si ile uyumlu hale getiren bir sarmalayÄ±cÄ±dÄ±r. Bu fonksiyon, bazÄ± meta-bilgileri dikkate alarak fonksiyonunuzu sarar, Ã¶rneÄŸin, tahminler iÃ§in eÅŸik belirleme gerekip gerekmediÄŸi veya optimizasyonun yÃ¶nÃ¼ (skoru maksimize etmek mi yoksa minimize etmek mi istediÄŸiniz gibi):

```python
from sklearn.metrics import make_scorer
from sklearn.metrics import average_precision_score

scorer = make_scorer(average_precision_score, 
                     average='weighted', greater_is_better=True, needs_proba=False)
```

YukarÄ±daki Ã¶rnekte, **average_precision_score** metriÄŸi kullanÄ±larak bir scorer hazÄ±rlanmÄ±ÅŸtÄ±r, burada Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma problemleriyle Ã§alÄ±ÅŸÄ±rken **weighted** hesaplama kullanÄ±lmasÄ± gerektiÄŸi belirtilmiÅŸtir.

> DeÄŸerlendirme metriÄŸinizi optimize ediyorsanÄ±z, **grid search**, **random search** veya daha sofistike optimizasyon tekniklerini, Ã¶rneÄŸin **Bayesian optimizasyonu** kullanarak hiperparametrelerinizi optimize edebilir ve algoritmanÄ±zÄ±, farklÄ± bir maliyet fonksiyonu kullanÄ±yor olsa bile, deÄŸerlendirme metriÄŸi iÃ§in en iyi performansÄ± gÃ¶sterecek ÅŸekilde parametreleri bulabilirsiniz. Model doÄŸrulamasÄ±nÄ± tartÄ±ÅŸtÄ±ktan sonra, Kaggle yarÄ±ÅŸmalarÄ±nda parametre optimizasyonunu nasÄ±l en iyi ÅŸekilde dÃ¼zenleyeceÄŸimizi ve en iyi sonuÃ§larÄ± nasÄ±l alacaÄŸÄ±mÄ±zÄ± inceleyeceÄŸiz.

### Post-processing your predictions *(Tahminleri sonradan iÅŸleme)*

**Post-processing ayarlamasÄ±**, tahminlerinizin, bir fonksiyon aracÄ±lÄ±ÄŸÄ±yla, daha iyi bir deÄŸerlendirme sunacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesini ifade eder. Kendi Ã¶zel kayÄ±p fonksiyonunuzu oluÅŸturduktan veya deÄŸerlendirme metriÄŸi iÃ§in optimize ettikten sonra, tahminleriniz Ã¼zerinde belirli bir fonksiyon kullanarak deÄŸerlendirme kriterinize uygun sonuÃ§lar elde etmek iÃ§in de performansÄ±nÄ±zÄ± artÄ±rabilirsiniz. Ã–rneÄŸin, **Quadratic Weighted Kappa** metriÄŸinden bahsedelim. Daha Ã¶nce bu metrik, **ordinal deÄŸer** tahminlerinde kullanÄ±ÅŸlÄ± olduÄŸunu belirtmiÅŸtik. KÄ±saca hatÄ±rlamak gerekirse, orijinal **Kappa katsayÄ±sÄ±**, algoritma ile gerÃ§ek etiket arasÄ±ndaki uyumun, ÅŸansÄ±n etkisiyle dÃ¼zeltilmiÅŸ bir Ã¶lÃ§Ã¼sÃ¼dÃ¼r. Bu, tahmin ile gerÃ§ek etiket arasÄ±ndaki eÅŸleÅŸmenin, ÅŸans sonucu olup olmadÄ±ÄŸÄ±nÄ±n olasÄ±lÄ±klarÄ± ile dÃ¼zeltilmiÅŸ bir doÄŸruluk Ã¶lÃ§Ã¼sÃ¼dÃ¼r.

Ä°ÅŸte Ã¶nceki bÃ¶lÃ¼mlerde gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z orijinal **Kappa katsayÄ±sÄ±** formÃ¼lÃ¼:

$$
\kappa = \frac{p_0 - p_e}{1 - p_e}
$$

FormÃ¼lde, **p0**, deÄŸerlendirenler arasÄ±ndaki gÃ¶zlemlenen gÃ¶reli uyumu, **pe** ise ÅŸansla olan uyum olasÄ±lÄ±ÄŸÄ±nÄ± ifade eder. Burada sadece iki matrise ihtiyacÄ±nÄ±z vardÄ±r: birisi gÃ¶zlemlenen puanlarla, diÄŸeri ise ÅŸansla uyumlu beklenen puanlarla. Kappa katsayÄ±sÄ± aÄŸÄ±rlÄ±klÄ± olduÄŸunda, ayrÄ±ca bir aÄŸÄ±rlÄ±k matrisi de dikkate alÄ±nÄ±r ve formÃ¼l ÅŸu hale gelir:

$$
\kappa = \frac{p_0 - p_e}{1 - p_e} \times p_p
$$

**pp** matrisi, hatalarÄ± farklÄ± ÅŸekilde aÄŸÄ±rlamak iÃ§in cezalandÄ±rmalarÄ± iÃ§erir ve bu, **ordinal tahminlerde** oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r Ã§Ã¼nkÃ¼ bu matris, tahminler gerÃ§ek etiketlerden daha fazla saparsa Ã§ok daha fazla ceza verebilir. **Kareli formu** kullanmak, yani sonucu kareye almak, cezalandÄ±rmayÄ± daha da ÅŸiddetli hale getirir. Ancak, bÃ¶yle bir metriÄŸi optimize etmek gerÃ§ekten kolay deÄŸildir, Ã§Ã¼nkÃ¼ bunu bir maliyet fonksiyonu olarak uygulamak oldukÃ§a zordur. Ä°ÅŸte burada **post-processing** yardÄ±ma gelir.

Bir Ã¶rnek, **PetFinder.my Adoption Prediction** yarÄ±ÅŸmasÄ±nda bulunabilir ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/petfinder-adoption-prediction)). Bu yarÄ±ÅŸmada, sonuÃ§lar 5 olasÄ± puana sahip olabilirdi (0, 1, 2, 3 veya 4), bunlarÄ± ya bir sÄ±nÄ±flandÄ±rma olarak ya da bir regresyon olarak ele alabilirsiniz. EÄŸer bir regresyon kullanÄ±yorsanÄ±z, regresyon sonuÃ§larÄ±nÄ±n post-processing dÃ¶nÃ¼ÅŸÃ¼mÃ¼, **Quadratic Weighted Kappa** metriÄŸi karÅŸÄ±sÄ±nda modelinizin performansÄ±nÄ± iyileÅŸtirebilir, bu da doÄŸrudan **sÄ±nÄ±flandÄ±rma** ile yapÄ±lan tahminlerden daha iyi sonuÃ§lar verebilir.

**PetFinder** yarÄ±ÅŸmasÄ±nda post-processing, regresyon sonuÃ§larÄ±nÄ± Ã¶nce [0.5, 1.5, 2.5, 3.5] sÄ±nÄ±rlarÄ±nÄ± kullanarak tam sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmekle baÅŸlayarak, daha iyi bir sÄ±nÄ±r seti bulmak iÃ§in iteratif ince ayar yapmayÄ± iÃ§eren bir optimizasyon sÃ¼recinden oluÅŸuyordu. Bu sÄ±nÄ±rlarÄ±n ince ayarÄ±, **SciPy optimize.minimize** gibi bir optimizasyon aracÄ±nÄ±n kullanÄ±lmasÄ±yla yapÄ±lmÄ±ÅŸtÄ±r ve bu, **Nelder-Mead algoritmasÄ±**na dayanmaktadÄ±r. Optimizasyon aracÄ± tarafÄ±ndan bulunan sÄ±nÄ±rlar, bir **cross-validation** ÅŸemasÄ±yla doÄŸrulandÄ±. Bu post-processing hakkÄ±nda daha fazla detayÄ±, yarÄ±ÅŸma sÄ±rasÄ±nda **Abhishek Thakur** tarafÄ±ndan yapÄ±lan ÅŸu gÃ¶nderide okuyabilirsiniz: [PetFinder Post-Processing Discussion](https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/76107).

> **PetFinder** yarÄ±ÅŸmasÄ± dÄ±ÅŸÄ±nda, birÃ§ok diÄŸer yarÄ±ÅŸma, akÄ±llÄ± post-processing'in daha iyi sonuÃ§lar ve sÄ±ralamalarla sonuÃ§lanabileceÄŸini gÃ¶stermiÅŸtir. Ä°ÅŸte bazÄ± Ã¶rnekler:
> 
> 
> 
> * [https://www.kaggle.com/khoongweihao/post-processing-technique-c-f-1st-place-jigsaw](https://www.kaggle.com/khoongweihao/post-processing-technique-c-f-1st-place-jigsaw)
> 
> * [https://www.kaggle.com/tomooinubushi/postprocessing-based-on-leakage](https://www.kaggle.com/tomooinubushi/postprocessing-based-on-leakage)
> 
> * [https://www.kaggle.com/saitodevel01/indoor-post-processing-by-cost-minimization](https://www.kaggle.com/saitodevel01/indoor-post-processing-by-cost-minimization)

Ne yazÄ±k ki, **post-processing** Ã§oÄŸunlukla kullandÄ±ÄŸÄ±nÄ±z metriÄŸe baÄŸlÄ±dÄ±r (metriÄŸi anlamak, iyi bir post-processing tasarlamak iÃ§in Ã§ok Ã¶nemlidir) ve genellikle veriye Ã¶zgÃ¼dÃ¼r; Ã¶rneÄŸin, zaman serisi verileri ve sÄ±zÄ±ntÄ±lar gibi durumlarda. Bu nedenle, herhangi bir yarÄ±ÅŸma iÃ§in doÄŸru post-processing yÃ¶ntemini bulmak Ã§ok zordur. Yine de, her zaman bu olasÄ±lÄ±ÄŸÄ±n farkÄ±nda olun ve bir yarÄ±ÅŸmada post-processing'in sonuÃ§larÄ± iyileÅŸtirdiÄŸine dair herhangi bir ipucu arayÄ±n. Benzer yarÄ±ÅŸmalarda daha Ã¶nceki post-processing ile ilgili her zaman ipuÃ§larÄ± bulabilirsiniz ve forum tartÄ±ÅŸmalarÄ± yoluyla â€“ eninde sonunda biri bu konuyu gÃ¼ndeme getirecektir.

### Predicted probability and its adjustment *(Tahmin edilen olasÄ±lÄ±ÄŸÄ±n ayarlanmasÄ±)*

YukarÄ±daki tartÄ±ÅŸmamÄ±zÄ± tamamlamak iÃ§in, doÄŸru **olasÄ±lÄ±klarÄ±** tahmin etmenin Ã§ok Ã¶nemli olduÄŸu durumlarÄ± ele alacaÄŸÄ±z, ancak kullandÄ±ÄŸÄ±nÄ±z algoritmanÄ±n bu iÅŸi iyi yapÄ±p yapmadÄ±ÄŸÄ±ndan emin olamÄ±yorsunuz. Daha Ã¶nce ayrÄ±ntÄ±lÄ± olarak aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z gibi, **sÄ±nÄ±flandÄ±rma olasÄ±lÄ±klarÄ±** hem ikili hem de Ã§oklu sÄ±nÄ±f sÄ±nÄ±flandÄ±rma problemleriyle ilgilidir ve genellikle **logaritmik kayÄ±p** (diÄŸer adÄ±yla log loss, lojistik kayÄ±p veya Ã§apraz entropi kaybÄ±) kullanÄ±larak deÄŸerlendirilir ve optimize edilir (daha fazla ayrÄ±ntÄ± iÃ§in, sÄ±nÄ±flandÄ±rma metrikleri ve Ã§oklu sÄ±nÄ±f sÄ±nÄ±flandÄ±rma metrikleri baÅŸlÄ±klarÄ±ndaki Ã¶nceki bÃ¶lÃ¼mlere bakabilirsiniz).

Ancak, sadece log kaybÄ± ile deÄŸerlendirme yapmak veya optimize etmek yeterli olmayabilir. DoÄŸru olasÄ±lÄ±k tahminleri elde etmeye Ã§alÄ±ÅŸÄ±rken dikkat etmeniz gereken ana sorunlar ÅŸunlardÄ±r:

* GerÃ§ekten olasÄ±lÄ±k tahmini yapmayan modeller
* Probleminizde sÄ±nÄ±flarÄ±n dengesiz daÄŸÄ±lÄ±mÄ±
* EÄŸitim veriniz ile test veriniz (hem public hem de private leaderboardâ€™lar) arasÄ±nda farklÄ± sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±

Ä°lk madde, modelinizin **belirtilen belirsizliÄŸe gÃ¶re sÄ±nÄ±flandÄ±rma tahminlerinin kalitesini** kontrol etme ve doÄŸrulama gerekliliÄŸini tek baÅŸÄ±na saÄŸlamaktadÄ±r. AslÄ±nda, **Scikit-learn** paketinde birÃ§ok algoritma, **predict_proba** yÃ¶ntemi ile birlikte sunulsa da, bu, gerÃ§ek bir olasÄ±lÄ±k dÃ¶ndÃ¼recekleri konusunda zayÄ±f bir teminattÄ±r.

Ã–rneÄŸin, **karar aÄŸaÃ§larÄ±nÄ±** ele alalÄ±m. Karar aÄŸaÃ§larÄ±, tabular verileri modellemek iÃ§in oldukÃ§a etkili bir yÃ¶ntemdir ve **Scikit-learn**â€™deki sÄ±nÄ±flandÄ±rma karar aÄŸaÃ§larÄ±, terminal yapraklarÄ±na dayalÄ± olarak tahminler yapar. Yani, tahmin edilen olasÄ±lÄ±k, tahmin edilecek Ã¶rneÄŸin bulunduÄŸu yapraÄŸÄ±n sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±na dayanÄ±r. EÄŸer aÄŸaÃ§ tamamen bÃ¼yÃ¼tÃ¼lmÃ¼ÅŸse, Ã¶rneÄŸin Ã§ok kÃ¼Ã§Ã¼k bir yapraya sahip olma olasÄ±lÄ±ÄŸÄ± yÃ¼ksektir ve bu da tahmin edilen olasÄ±lÄ±ÄŸÄ±n Ã§ok yÃ¼ksek olmasÄ±na yol aÃ§ar. **max_depth**, **max_leaf_nodes** veya **min_samples_leaf** gibi parametreleri deÄŸiÅŸtirirseniz, aÄŸacÄ±n bÃ¼yÃ¼mesine baÄŸlÄ± olarak tahmin edilen olasÄ±lÄ±k bÃ¼yÃ¼k Ã¶lÃ§Ã¼de deÄŸiÅŸir.

Karar aÄŸaÃ§larÄ±, **bagging** modelleri ve **random forest** gibi topluluk modelleri iÃ§in en yaygÄ±n temel modeldir, ayrÄ±ca **gradient boosting** modelleri (Ã¶rneÄŸin, **XGBoost**, **LightGBM**, ve **CatBoost**) de karar aÄŸaÃ§larÄ±nÄ± kullanÄ±r. Ancak, aynÄ± sebeplerden dolayÄ±â€”gerÃ§ekten saÄŸlam olasÄ±lÄ±k tahminleri yapmayan olasÄ±lÄ±k tahminleriâ€”bu sorun, **destek vektÃ¶r makineleri** (SVM) ve **k-en yakÄ±n komÅŸu** (k-NN) gibi yaygÄ±n olarak kullanÄ±lan diÄŸer modelleri de etkiler. Bu konular, **Otto Group Product Classification Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/otto-group-product-classification-challenge/overview/](https://www.kaggle.com/c/otto-group-product-classification-challenge/overview/)) **Christophe Bourguignat** ve diÄŸerleri tarafÄ±ndan gÃ¼ndeme getirildiÄŸinde, **Scikit-learn**â€™e yeni eklenen **kalibrasyon fonksiyonlarÄ±** kullanÄ±larak kolayca Ã§Ã¶zÃ¼ldÃ¼.

KullanacaÄŸÄ±nÄ±z model dÄ±ÅŸÄ±nda, probleminizdeki sÄ±nÄ±flar arasÄ±nda dengesizlik bulunmasÄ±, modellerinizin hiÃ§ gÃ¼venilir olmamasÄ±na yol aÃ§abilir. Bu nedenle, dengesiz sÄ±nÄ±flandÄ±rma problemlerinde iyi bir yaklaÅŸÄ±m, **undersampling** veya **oversampling** stratejileri kullanarak sÄ±nÄ±flarÄ± dengelemektir; ya da her sÄ±nÄ±f iÃ§in kaybÄ± hesaplanÄ±rken algoritmanÄ±n uygulayacaÄŸÄ± **Ã¶zel aÄŸÄ±rlÄ±klar** belirlemektir. Bu stratejiler modelinizi daha performanslÄ± hale getirebilir, ancak kesinlikle olasÄ±lÄ±k tahminlerinizi bozarlar ve bu tahminleri, leaderboard'da daha iyi bir model skoru elde etmek iÃ§in ayarlamanÄ±z gerekebilir.

Son olarak, Ã¼Ã§Ã¼ncÃ¼ Ã¶nemli nokta, **test seti**nin nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ± ile ilgilidir. Bu tÃ¼r bilgiler genellikle gizli tutulur, ancak Ã§oÄŸu zaman bunu tahmin etmenin yollarÄ± vardÄ±r (Ã¶rneÄŸin, **public leaderboard** sonuÃ§larÄ±na dayalÄ± deneme yanÄ±lma yÃ¶ntemi kullanarak, **BÃ¶lÃ¼m 1**'de **Kaggle ve Veri Bilimi YarÄ±ÅŸmalarÄ±nÄ± TanÄ±tmak** baÅŸlÄ±ÄŸÄ±nda bahsettiÄŸimiz gibi).

Ã–rneÄŸin, bu durum, **iMaterialist Furniture Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/imaterialist-challenge-furniture-2018/](https://www.kaggle.com/c/imaterialist-challenge-furniture-2018/)) ve daha popÃ¼ler olan **Quora Question Pairs** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/quora-question-pairs](https://www.kaggle.com/c/quora-question-pairs)) yaÅŸanmÄ±ÅŸtÄ±r. Her iki yarÄ±ÅŸma da, test beklentilerine uygun olasÄ±lÄ±klarÄ± ayarlamak iÃ§in **post-processing** yapmanÄ±n nasÄ±l olacaÄŸÄ±na dair Ã§eÅŸitli tartÄ±ÅŸmalar yaratmÄ±ÅŸtÄ±r (bu metodun kullanÄ±ldÄ±ÄŸÄ±na dair daha fazla bilgi iÃ§in [Burada](https://swarbrickjones.wordpress.com/2017/03/28/cross-entropy-and-training-test-class-imbalance/) ve [Burada](https://www.kaggle.com/dowakin/probability-calibration-0-005-to-lb) tartÄ±ÅŸmalarÄ± bulabilirsiniz). Genel bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla, sÄ±nÄ±flarÄ± tahmin etmek iÃ§in test daÄŸÄ±lÄ±mÄ± hakkÄ±nda bir fikriniz olmasa bile, **eÄŸitim verilerinden aldÄ±ÄŸÄ±nÄ±z Ã¶ncÃ¼lleri** kullanarak doÄŸru olasÄ±lÄ±k tahmin etmek hala Ã§ok faydalÄ±dÄ±r (ve karÅŸÄ±t bir delil elde edene kadar, bu, modelinizin taklit etmesi gereken olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±dÄ±r). GerÃ§ekten de, tahmin edilen olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ±z, eÄŸitim setindekilerle uyuÅŸuyorsa, tahmin edilen olasÄ±lÄ±klarÄ± dÃ¼zeltmek Ã§ok daha kolay olacaktÄ±r.

Tahmin edilen olasÄ±lÄ±klarÄ±n, hedefin eÄŸitim daÄŸÄ±lÄ±mÄ±yla uyumsuz olduÄŸu durumdaki Ã§Ã¶zÃ¼m, **Scikit-learn** tarafÄ±ndan saÄŸlanan **calibration fonksiyonunu** kullanmaktÄ±r:

```python
sklearn.calibration.CalibratedClassifierCV(base_estimator=None, *, method='sigmoid', cv=None, n_jobs=None, ensemble=True)
```

Kalibrasyon fonksiyonunun amacÄ±, tahmin edilen olasÄ±lÄ±klarÄ±nÄ±za bir **post-processing** fonksiyonu uygulayarak onlarÄ±, gerÃ§ek etiketlerde gÃ¶zlemlenen ampirik olasÄ±lÄ±klarla daha yakÄ±n hale getirmektir. Modeliniz **Scikit-learn** tabanlÄ±ysa veya ona benzer ÅŸekilde Ã§alÄ±ÅŸÄ±yorsa, fonksiyon, modelinizi sarmalayacak ve tahminlerini doÄŸrudan bir post-processing fonksiyonuna yÃ¶nlendirecektir. Post-processing iÃ§in iki yÃ¶ntem arasÄ±ndan seÃ§im yapabilirsiniz: ilki **sigmoid** yÃ¶ntemi (diÄŸer adÄ±yla **Platâ€™s scaling**), bu sadece bir **lojistik regresyon**dur. Ä°kinci yÃ¶ntem ise **izotonik regresyon**, parametrik olmayan bir regresyondur; ancak dikkat edin, eÄŸer Ã¶rnek sayÄ±sÄ± azsa aÅŸÄ±rÄ± Ã¶ÄŸrenmeye yatkÄ±ndÄ±r.

Bu kalibratÃ¶rÃ¼ nasÄ±l fit edeceÄŸinizi de seÃ§meniz gerekir. UnutmayÄ±n ki bu bir modeldir ve modelinizin sonuÃ§larÄ±na uygulanÄ±r, bu yÃ¼zden tahminlerinizi sistematik olarak yeniden iÅŸlemekten kaÃ§Ä±narak aÅŸÄ±rÄ± Ã¶ÄŸrenmeden kaÃ§Ä±nmalÄ±sÄ±nÄ±z. **Cross-validation** kullanabilir ve bir dizi model Ã¼reterek, bunlarÄ± ortalayÄ±p tahminlerinizi elde edebilirsiniz (**ensemble=True**). Aksi takdirde, genellikle bizim tercih ettiÄŸimiz yaklaÅŸÄ±m, **out-of-fold** tahminini kullanmak ve tÃ¼m mevcut verilerle bunu kalibre etmektir (**ensemble=False**).

**CalibratedClassifierCV**, Ã§oÄŸu durumu yÃ¶netebilecek olsa da, en iyi performansÄ± test zamanÄ±nda elde etmek iÃ§in olasÄ±lÄ±k tahminlerini dÃ¼zeltmenin ampirik bir yolunu da keÅŸfetebilirsiniz. Kendi baÅŸÄ±nÄ±za geliÅŸtirilmiÅŸ herhangi bir dÃ¶nÃ¼ÅŸÃ¼m fonksiyonunu, hatta genetik algoritmalarla tÃ¼retilmiÅŸ sofistike bir fonksiyonu kullanabilirsiniz. Tek sÄ±nÄ±rÄ±nÄ±z, bunu **cross-validation** ile test etmeniz ve **public leaderboard'dan iyi bir sonuÃ§** almanÄ±zdÄ±r (ancak kesinlikle gerekli deÄŸildir, Ã§Ã¼nkÃ¼ **yerel cross-validation** skoru daha gÃ¼venilir olmalÄ±dÄ±r, bunu bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸacaÄŸÄ±z). BÃ¶yle bir stratejinin iyi bir Ã¶rneÄŸini, **Silogram** ([https://www.kaggle.com/psilogram](https://www.kaggle.com/psilogram)) **Microsoft Malware Classification Challenge** yarÄ±ÅŸmasÄ±nda bulmuÅŸ ve **random forests** algoritmasÄ±nÄ±n gÃ¼venilir olmayan olasÄ±lÄ±k Ã§Ä±ktÄ±larÄ±nÄ±n Ã¼zerine, **grid search** ile belirlenen bir gÃ¼Ã§ uygulayarak olasÄ±lÄ±klarÄ±nÄ± doÄŸru hale getirmiÅŸtir (daha fazla bilgi iÃ§in [Burada](https://www.kaggle.com/c/malware-classification/discussion/13509) bulabilirsiniz).

> **Sudalai Rajkumar**
> 
> [https://www.kaggle.com/sudalairajkumar](https://www.kaggle.com/sudalairajkumar)
> 
> 
> 
> BÃ¶lÃ¼mÃ¼mÃ¼zÃ¼n son rÃ¶portajÄ±nda, yarÄ±ÅŸmalarda, veri setlerinde ve not defterlerinde Grandmaster olan Sudalai Rajkumar (SRK) ile konuÅŸuyoruz. Analytics Vidhya veri bilimi platformunda #1 sÄ±ralamasÄ±na sahip olan SRK, ÅŸu anda start-upâ€™lar iÃ§in bir AI/ML danÄ±ÅŸmanÄ± olarak Ã§alÄ±ÅŸÄ±yor.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Kaggle'daki teknikleriniz ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ±nÄ±z hakkÄ±nda ne sÃ¶ylersiniz?**
> 
> 
> 
> Favori yarÄ±ÅŸmalarÄ±m, iyi bir Ã¶zellik mÃ¼hendisliÄŸi gerektiren yarÄ±ÅŸmalardÄ±r. Bu da benim gÃ¼Ã§lÃ¼ yÃ¶nÃ¼m diyebilirim. Genellikle, veriyi derinlemesine anlamak iÃ§in veri keÅŸfi yapmaktan ilgi duyuyorum (bunu, basit keÅŸif Not defterlerimden [https://www.kaggle.com/sudalairajkumar/code](https://www.kaggle.com/sudalairajkumar/code) gÃ¶rebilirsiniz) ve sonrasÄ±nda bu veriye dayalÄ± Ã¶zellikler yaratÄ±yorum.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±dÄ±r?**
> 
> 
> 
> Bir yarÄ±ÅŸma iÃ§in genel Ã§erÃ§eve, veri keÅŸfi, doÄŸru doÄŸrulama yÃ¶ntemini bulma, Ã¶zellik mÃ¼hendisliÄŸi, model kurma ve toplama/katmanlama (ensembling/stacking) aÅŸamalarÄ±nÄ± iÃ§erir. Bunlar gÃ¼nlÃ¼k iÅŸimde de yer alÄ±r. Ancak, gÃ¼nlÃ¼k iÅŸimde bunun dÄ±ÅŸÄ±nda daha fazla paydaÅŸ gÃ¶rÃ¼ÅŸmesi, veri toplama, veri etiketleme, model daÄŸÄ±tÄ±mÄ±, model izleme ve veri hikayeleÅŸtirme gibi unsurlar da vardÄ±r.
> 
> 
> 
> **GirdiÄŸiniz Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu zorluÄŸu nasÄ±l aÅŸtÄ±ÄŸÄ±nÄ±zdan bahseder misiniz?**
> 
> 
> 
> Santander ÃœrÃ¼n Ã–nerisi, girdiÄŸimiz hatÄ±rladÄ±ÄŸÄ±m bir yarÄ±ÅŸmadÄ±r. Rohan ile birlikte Ã§ok fazla Ã¶zellik mÃ¼hendisliÄŸi yaptÄ±k ve birden fazla model kurduk. Final toplama aÅŸamasÄ±nda, farklÄ± Ã¼rÃ¼nler iÃ§in farklÄ± aÄŸÄ±rlÄ±klar kullandÄ±k ve bazÄ±larÄ± toplamda 1â€™e eÅŸit deÄŸildi. Veri keÅŸfi ve anlayÄ±ÅŸÄ±ndan yola Ã§Ä±karak bu aÄŸÄ±rlÄ±klarÄ± manuel olarak seÃ§tik ve bu bize yardÄ±mcÄ± oldu. Bu deneyim, veri biliminin bilim olduÄŸu kadar bir sanat olduÄŸunu ve verinin/alanÄ±n problemleri Ã§Ã¶zmedeki Ã¶nemini anlamamÄ±za yardÄ±mcÄ± oldu.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? YardÄ±mcÄ± olduysa nasÄ±l?**
> 
> 
> 
> Kaggle kariyerimde Ã§ok Ã¶nemli bir rol oynadÄ±. Son iki iÅŸimi, bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Kaggle sayesinde kazandÄ±m. AyrÄ±ca, Kaggle'daki baÅŸarÄ±larÄ±m, veri bilimi alanÄ±ndaki diÄŸer Ã¶nemli kiÅŸilerle kolayca baÄŸlantÄ± kurmama ve onlardan Ã¶ÄŸrenmeme yardÄ±mcÄ± oldu. Åu anki AI/ML danÄ±ÅŸmanlÄ±k rolÃ¼mde de, Kaggleâ€™daki baÅŸarÄ±larÄ±m bÃ¼yÃ¼k bir gÃ¼venilirlik saÄŸlÄ±yor.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ±nÄ±n genellikle gÃ¶z ardÄ± ettiÄŸi ÅŸeyler nedir? BaÅŸlangÄ±Ã§ta bilseydiniz ÅŸimdi neyi farklÄ± yapardÄ±nÄ±z?**
> 
> 
> 
> Veriyi derinlemesine anlamak. Ã‡oÄŸu zaman insanlar hemen model kurmaya baÅŸlÄ±yorlar. Oysa veri keÅŸfi yapmak, herhangi bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n baÅŸarÄ±sÄ± iÃ§in Ã§ok Ã¶nemli bir rol oynar. Bu, doÄŸru Ã§apraz doÄŸrulama yapmanÄ±za, daha iyi Ã¶zellikler oluÅŸturmanÄ±za ve veriden daha fazla deÄŸer elde etmenize yardÄ±mcÄ± olur.
> 
> 
> 
> **GeÃ§miÅŸte katÄ±ldÄ±ÄŸÄ±nÄ±z yarÄ±ÅŸmalarda hangi hatalarÄ± yaptÄ±nÄ±z?**
> 
> 
> 
> Ã‡ok uzun bir liste var, ama bunlar Ã¶ÄŸrenme fÄ±rsatlarÄ±ydÄ±. Her yarÄ±ÅŸmada, denediÄŸim 20-30 fikirden sadece biri iÅŸe yarayabiliyor. Bu hatalar/baÅŸarÄ±sÄ±zlÄ±klar, gerÃ§ek baÅŸarÄ±dan veya iÅŸe yarayan ÅŸeylerden Ã§ok daha fazla Ã¶ÄŸretici oldu. Ã–rneÄŸin, Ã§ok fazla overfitting (aÅŸÄ±rÄ± uyum saÄŸlama) yapmayÄ± birinci yarÄ±ÅŸmamda Ã¶ÄŸrendim; baÅŸlangÄ±Ã§taki en iyi sÄ±ralamalardan, en kÃ¶tÃ¼ sÄ±ralamalara dÃ¼ÅŸmÃ¼ÅŸtÃ¼m. Ama bu ders, hayatÄ±m boyunca benimle kaldÄ±.
> 
> 
> 
> **Veri analizi/makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> 
> 
> Tabular (tablosal) veriler iÃ§in genellikle XGBoost/LightGBM kullanÄ±yorum. Son zamanlarda, erken benchmark (ilk performans testi) almak iÃ§in aÃ§Ä±k kaynak AutoML kÃ¼tÃ¼phaneleri ve Driverless AI de kullanÄ±yorum. Derin Ã¶ÄŸrenme modelleri iÃ§in ise Keras, Transformers ve PyTorch kullanÄ±yorum.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya girerken, birinin aklÄ±nda tutmasÄ± veya yapmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> 
> 
> TutarlÄ±lÄ±k en Ã¶nemli ÅŸeydir. Her yarÄ±ÅŸmanÄ±n kendi iniÅŸ Ã§Ä±kÄ±ÅŸlarÄ± olacaktÄ±r. BirkaÃ§ gÃ¼n boyunca hiÃ§ ilerleme kaydedemeyebilirsiniz, ama pes etmemeli ve denemeye devam etmelisiniz. Bu sadece Kaggle yarÄ±ÅŸmalarÄ± iÃ§in deÄŸil, her ÅŸey iÃ§in geÃ§erlidir.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ±nÄ± kullanÄ±yor musunuz? Bunlar Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r?**
> 
> 
> 
> Analytics Vidhya DataHack platformu, Driven Data, CrowdAnalytix gibi diÄŸer platformlarda da yer aldÄ±m. Onlar da oldukÃ§a iyi, ama Kaggle daha geniÅŸ Ã§apta kabul gÃ¶rmÃ¼ÅŸ ve kÃ¼resel bir platform olduÄŸu iÃ§in, diÄŸer platformlarla karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda Kaggleâ€™daki rekabet daha yÃ¼ksektir.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle yarÄ±ÅŸmalarÄ±ndaki deÄŸerlendirme metriklerini tartÄ±ÅŸtÄ±k. Ä°lk olarak, bir deÄŸerlendirme metriÄŸinin objektif fonksiyondan nasÄ±l farklÄ± olabileceÄŸini aÃ§Ä±kladÄ±k. AyrÄ±ca, regresyon ve sÄ±nÄ±flandÄ±rma problemleri arasÄ±ndaki farklara da deÄŸindik. Her bir problem tÃ¼rÃ¼ iÃ§in, Kaggle yarÄ±ÅŸmalarÄ±nda karÅŸÄ±nÄ±za Ã§Ä±kabilecek en yaygÄ±n metrikleri inceledik.

SonrasÄ±nda, daha Ã¶nce hiÃ§bir yarÄ±ÅŸmada karÅŸÄ±laÅŸÄ±lmamÄ±ÅŸ ve muhtemelen bir daha karÅŸÄ±laÅŸmayacaÄŸÄ±nÄ±z metrikleri ele aldÄ±k. Son olarak, farklÄ± yaygÄ±n metrikleri inceledik ve bunlarÄ±n Ã¶nceki Kaggle yarÄ±ÅŸmalarÄ±nda nasÄ±l kullanÄ±ldÄ±ÄŸÄ±na dair Ã¶rnekler verdik. ArdÄ±ndan, bir deÄŸerlendirme metriÄŸini optimize etmek iÃ§in birkaÃ§ strateji Ã¶nerdik. Ã–zellikle, kendi Ã¶zel maliyet fonksiyonlarÄ±nÄ±zÄ± kodlamayÄ± denemenizi Ã¶nerdik ve faydalÄ± olabilecek bazÄ± son iÅŸleme adÄ±mlarÄ± hakkÄ±nda tavsiyelerde bulunduk.

Åimdi, bir deÄŸerlendirme metriÄŸinin Kaggle yarÄ±ÅŸmasÄ±ndaki rolÃ¼nÃ¼ kavramÄ±ÅŸ olmalÄ±sÄ±nÄ±z. AyrÄ±ca, geÃ§miÅŸ yarÄ±ÅŸmalarÄ± inceleyerek ve bir metriÄŸin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± tam anlamak suretiyle her yaygÄ±n veya yaygÄ±n olmayan metriÄŸi nasÄ±l ele alacaÄŸÄ±nÄ±z konusunda bir stratejiniz olmalÄ±. Bir sonraki bÃ¶lÃ¼mde, deÄŸerlendirme metriklerini nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± ve Kaggle Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼n performansÄ±nÄ± dÃ¼zgÃ¼n bir ÅŸekilde nasÄ±l tahmin edeceÄŸimizi, bir doÄŸrulama stratejisi aracÄ±lÄ±ÄŸÄ±yla tartÄ±ÅŸacaÄŸÄ±z.

---

## Chapter 6: Designing Good Validation *(BÃ¶lÃ¼m 6: Ä°yi Bir DoÄŸrulama Sistemi Tasarlama)*

Bir Kaggle yarÄ±ÅŸmasÄ±nda, modelleme yaparken ve sonuÃ§larÄ± gÃ¶nderdikten sonra, liderlik tablosundan aldÄ±ÄŸÄ±nÄ±z sonuÃ§larÄ± yÃ¼zeysel bir ÅŸekilde kabul etmek yeterli gibi gÃ¶rÃ¼nebilir. SonuÃ§ta, bir yarÄ±ÅŸmada Ã¶nemli olanÄ±n sÄ±ralamanÄ±z olduÄŸunu dÃ¼ÅŸÃ¼nebilirsiniz. Bu, yarÄ±ÅŸmalarda sÄ±kÃ§a yapÄ±lan ve tekrarlanan yaygÄ±n bir hatadÄ±r. GerÃ§ekte, yarÄ±ÅŸma sona erene kadar gerÃ§ek liderlik tablosunun (Ã¶zel olan) nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ bilemezsiniz ve bunun yerine yalnÄ±zca halka aÃ§Ä±k olan kÄ±smÄ±na gÃ¼venmek tavsiye edilmez, Ã§Ã¼nkÃ¼ bu genellikle yanÄ±ltÄ±cÄ± olabilir.

Bu bÃ¶lÃ¼mde, veri yarÄ±ÅŸmalarÄ±nda doÄŸrulamanÄ±n Ã¶nemini tanÄ±tacaÄŸÄ±z. ÅunlarÄ± Ã¶ÄŸreneceksiniz:

* AÅŸÄ±rÄ± uyum (overfitting) nedir ve bir halka aÃ§Ä±k liderlik tablosu nasÄ±l yanÄ±ltÄ±cÄ± olabilir?
* KorkunÃ§ sÄ±ralama deÄŸiÅŸiklikleri (shake-ups)
* FarklÄ± doÄŸrulama stratejileri
* Adversarial doÄŸrulama
* SÄ±zÄ±ntÄ±larÄ± nasÄ±l tespit edebilir ve bunlardan nasÄ±l yararlanabilirsiniz?
* Son gÃ¶nderilerinizi seÃ§erken hangi stratejileri uygulamanÄ±z gerektiÄŸi

Modelleme sÄ±rasÄ±nda performansÄ±nÄ±zÄ± izlemek ve aÅŸÄ±rÄ± uyum yapÄ±p yapmadÄ±ÄŸÄ±nÄ±zÄ± ayÄ±rt etmek, sadece veri bilimi yarÄ±ÅŸmalarÄ±nda deÄŸil, tÃ¼m veri bilimi projelerinde anahtar bir yetkinliktir. Modellerinizi doÄŸru ÅŸekilde doÄŸrulamak, bir Kaggle yarÄ±ÅŸmasÄ±ndan Ã¶ÄŸrenebileceÄŸiniz ve profesyonel dÃ¼nyada yeniden kullanabileceÄŸiniz en Ã¶nemli becerilerden biridir.

### Snooping on the leaderboard *(Liderlik tablosunu gÃ¶zetlemek)*

Daha Ã¶nce aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z gibi, her yarÄ±ÅŸmada Kaggle, test setini bir halkaya aÃ§Ä±k bÃ¶lÃ¼m (genellikle ÅŸu anki liderlik tablosunda gÃ¶rÃ¼len) ve bir Ã¶zel bÃ¶lÃ¼m olarak ayÄ±rÄ±r. Ã–zel bÃ¶lÃ¼m, yarÄ±ÅŸma sonuÃ§larÄ± iÃ§in nihai puanlarÄ± hesaplamak iÃ§in kullanÄ±lÄ±r. Bu test bÃ¶lÃ¼mleri genellikle rastgele belirlenir (zaman serisi yarÄ±ÅŸmalarÄ±nda ise zaman bazÄ±nda belirlenir) ve tÃ¼m test seti, halka aÃ§Ä±k ve Ã¶zel bÃ¶lÃ¼mler arasÄ±nda herhangi bir ayrÄ±m yapÄ±lmadan yayÄ±nlanÄ±r.

> Son zamanlarda, belirli yarÄ±ÅŸmalarda test verilerinin Ã§ok dikkatlice incelenmesini engellemek amacÄ±yla, Kaggle test verilerini geri Ã§ekmiÅŸ ve yalnÄ±zca bazÄ± Ã¶rneklerini saÄŸlamÄ±ÅŸ, gerÃ§ek test seti ise gÃ¶nderim yapÄ±ldÄ±ÄŸÄ±nda yerine konmuÅŸtur. Bu tÃ¼r yarÄ±ÅŸmalara "Kod yarÄ±ÅŸmalarÄ±" denir Ã§Ã¼nkÃ¼ burada aslÄ±nda tahminler deÄŸil, tahminleri oluÅŸturacak kodu iÃ§eren bir Notebook sunulmaktadÄ±r.

Buna gÃ¶re, bir modelden tÃ¼retilen bir gÃ¶nderi, tÃ¼m test setini kapsayacaktÄ±r, ancak yalnÄ±zca halka aÃ§Ä±k bÃ¶lÃ¼m hemen puanlanacak, Ã¶zel bÃ¶lÃ¼mÃ¼n puanlanmasÄ± ise yarÄ±ÅŸma sona erene kadar bekleyecektir.

Bundan dolayÄ± Ã¼Ã§ Ã¶nemli nokta ortaya Ã§Ä±kmaktadÄ±r:

* Bir yarÄ±ÅŸmanÄ±n dÃ¼zgÃ¼n iÅŸleyebilmesi iÃ§in eÄŸitim verisi ve test verisi aynÄ± daÄŸÄ±lÄ±mdan gelmelidir. AyrÄ±ca, test verisinin halka aÃ§Ä±k ve Ã¶zel bÃ¶lÃ¼mleri, daÄŸÄ±lÄ±m aÃ§Ä±sÄ±ndan birbirine benzer olmalÄ±dÄ±r.
* EÄŸitim ve test verisi gÃ¶rÃ¼nÃ¼ÅŸte aynÄ± daÄŸÄ±lÄ±mdan gelmiÅŸ olsa bile, her iki sette de yeterli Ã¶rnek bulunmamasÄ±, eÄŸitim verisi ile halka aÃ§Ä±k ve Ã¶zel test verisi arasÄ±nda uyumlu sonuÃ§lar elde etmeyi zorlaÅŸtÄ±rabilir.
* Halka aÃ§Ä±k test verisi, bir veri bilimi projesinde olduÄŸu gibi yalnÄ±zca son doÄŸrulama iÃ§in kullanÄ±lacak bir "holdout" test olarak deÄŸerlendirilmelidir. Bu yÃ¼zden, "adaptif aÅŸÄ±rÄ± uyum" denilen durumu engellemek iÃ§in fazla sorgulanmamalÄ±dÄ±r. Adaptif aÅŸÄ±rÄ± uyum, bir modelin belirli bir test seti Ã¼zerinde iyi Ã§alÄ±ÅŸÄ±rken, diÄŸer test setlerinde dÃ¼ÅŸÃ¼k performans gÃ¶stermesi anlamÄ±na gelir.

Bu Ã¼Ã§ Ã¶nemli noktayÄ± akÄ±lda tutmak, bir yarÄ±ÅŸmanÄ±n dinamiklerini anlamak iÃ§in Ã§ok Ã¶nemlidir. Ã‡oÄŸu yarÄ±ÅŸmada, eÄŸitim, halka aÃ§Ä±k ve Ã¶zel test verilerinin birbirine nasÄ±l baÄŸlÄ± olduÄŸu hakkÄ±nda tartÄ±ÅŸma forumlarÄ±nda her zaman birÃ§ok soru vardÄ±r ve genellikle yÃ¼zlerce Ã§Ã¶zÃ¼m, yalnÄ±zca halka aÃ§Ä±k liderlik tablosu Ã¼zerindeki etkinliÄŸine gÃ¶re deÄŸerlendirilerek gÃ¶nderilir.

AyrÄ±ca, sÄ±ralamalarÄ± devrim niteliÄŸinde deÄŸiÅŸtiren "shake-up" (sÄ±ralama deÄŸiÅŸikliÄŸi) tartÄ±ÅŸmalarÄ±na da sÄ±kÃ§a rastlanÄ±r. AslÄ±nda, bunlar, daha Ã¶nce halka aÃ§Ä±k liderlik tablosunda daha iyi pozisyonlar elde etmiÅŸ olan birÃ§ok kiÅŸinin hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸramasÄ±na neden olabilen, nihai sÄ±ralamalarÄ±n yeniden dÃ¼zenlenmesidir. Anektodal olarak, shake-up'lar genellikle eÄŸitim verisi ile test seti arasÄ±ndaki farklardan ya da test verisinin halka aÃ§Ä±k ve Ã¶zel bÃ¶lÃ¼mleri arasÄ±ndaki farklardan kaynaklandÄ±ÄŸÄ±na inanÄ±lÄ±r. Bunlar, rakiplerin beklenen yerel puanlarÄ±nÄ±n liderlik tablosu geri bildirimiyle ne kadar iliÅŸkilendiÄŸine bakarak ex ante (yarÄ±ÅŸma baÅŸlamadan Ã¶nce) ve iki sayÄ±ya dayalÄ± yapÄ±lan analizlerle ex post (yarÄ±ÅŸma sona erdikten sonra) Ã¶lÃ§Ã¼lÃ¼r:

* Genel bir shake-up sayÄ±sÄ±, **mean(abs(private_rank-public_rank)/number_of_teams)** formÃ¼lÃ¼ ile hesaplanÄ±r.
* Sadece halka aÃ§Ä±k sÄ±ralamanÄ±n en Ã¼st %10'unu dikkate alarak hesaplanan Ã¼st sÄ±ralama shake-up sayÄ±sÄ±.

> Bu ex post sayÄ±larÄ±, ilk olarak Steve Donoho ([https://www.kaggle.com/breakfastpirate](https://www.kaggle.com/breakfastpirate)) tarafÄ±ndan geliÅŸtirilmiÅŸ ve Kaggle shake-up'larÄ±nÄ±n en kÃ¶tÃ¼ sÄ±ralamalarÄ±nÄ± iÃ§eren bir liste hazÄ±rlamÄ±ÅŸtÄ±r (buna ÅŸu baÄŸlantÄ±dan ulaÅŸabilirsiniz: [Kaggle shake-ups](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/49106#278831)). Bu sayÄ±lar gÃ¼nÃ¼mÃ¼zde, Chapter 5â€™te tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z Meta Kaggle veriseti kullanÄ±larak Ã§oÄŸu Notebook tarafÄ±ndan kolayca yeniden oluÅŸturulabilir (buna ÅŸu baÄŸlantÄ±dan eriÅŸebilirsiniz: [Meta Kaggle Competition Shake-up](https://www.kaggle.com/jtrotman/meta-kaggle-competition-shake-up)).

Ã–rneÄŸin, bu verilere bakarak RSNA Intracranial Hemorrhage Detection yarÄ±ÅŸmasÄ±nÄ±n shake-up'larÄ± nedeniyle ne kadar zorlayÄ±cÄ± olduÄŸunu anlayabilirsiniz, Ã¶zellikle de Ã¼st sÄ±ralamalarda.

Ancak, bir ex post deÄŸerlendirmesinin Ã¶tesinde, Ã¶nceki shake-up'lardan edindiÄŸimiz bazÄ± dersler, Kaggle yarÄ±ÅŸmalarÄ±nda size yardÄ±mcÄ± olabilir. UC Berkeley'den bazÄ± araÅŸtÄ±rmacÄ±lar da bu ÅŸekilde dÃ¼ÅŸÃ¼nÃ¼yor. 2019'da NIPS'te sunduklarÄ± makalelerinde, Roelofs, Fridovich-Keil ve diÄŸerleri, Kaggle yarÄ±ÅŸmalarÄ±ndaki halka aÃ§Ä±k ve Ã¶zel liderlik tablosu dinamiklerine dair iÃ§gÃ¶rÃ¼ler kazanmak amacÄ±yla birkaÃ§ bin Kaggle yarÄ±ÅŸmasÄ±nÄ± incelediler. Her ne kadar sÄ±nÄ±rlÄ± bir yarÄ±ÅŸma kÃ¼mesine odaklansalar da (120 yarÄ±ÅŸma, belirli bir katÄ±lÄ±mcÄ± sayÄ±sÄ±nÄ±n Ã¼zerindeki, ikili sÄ±nÄ±flandÄ±rmaya dayalÄ± yarÄ±ÅŸmalar), bazÄ± ilginÃ§ bulgular elde ettiler:

* Adaptif aÅŸÄ±rÄ± uyum Ã§ok azdÄ±r; diÄŸer bir deyiÅŸle, halka aÃ§Ä±k sÄ±ralamalar genellikle aÃ§Ä±ÄŸa Ã§Ä±kan Ã¶zel liderlik tablosunda tutar.
* Ã‡oÄŸu shake-up, rastgele dalgalanmalardan ve rakiplerin sÄ±ralamalarÄ±nÄ±n Ã§ok yakÄ±n olduÄŸu aÅŸÄ±rÄ± kalabalÄ±k sÄ±ralamalardan kaynaklanÄ±r; Ã¶zel test setlerindeki kÃ¼Ã§Ã¼k bir performans deÄŸiÅŸikliÄŸi, sÄ±ralamalarda bÃ¼yÃ¼k deÄŸiÅŸikliklere neden olabilir.
* Shake-up'lar, eÄŸitim seti Ã§ok kÃ¼Ã§Ã¼k olduÄŸunda veya eÄŸitim verisi baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±ma sahip deÄŸilse (i.i.d.) gerÃ§ekleÅŸir.

> Tam makale, *Roelofs, R., Fridovich-Keil, S. et al. A meta-analysis of overfitting in machine learning. Proceedings of the 33rd International Conference on Neural Information Processing Systems. 2019* ÅŸu baÄŸlantÄ±dan bulunabilir: [Makale Linki](https://papers.nips.cc/paper/2019/file/ee39e503b6bedf0c98c388b7e8589aca-Paper.pdf).

Ancak, bizim uzun Kaggle yarÄ±ÅŸmalarÄ±ndaki deneyimimize gÃ¶re, adaptif aÅŸÄ±rÄ± uyum ile ilgili oldukÃ§a fazla problem gÃ¶rdÃ¼k. Ã–rneÄŸin, Greg Park'Ä±n ilk katÄ±ldÄ±ÄŸÄ±mÄ±z yarÄ±ÅŸmalardan birinin analizini okuyabilirsiniz: [Kaggle Psychopathy Postmortem](http://gregpark.io/blog/Kaggle-PsychopathyPostmortem/). Bu, pek Ã§ok Kaggle katÄ±lÄ±mcÄ±sÄ± iÃ§in yaygÄ±n ve sÃ¼rekli bir sorun olduÄŸu iÃ§in, yalnÄ±zca halka aÃ§Ä±k liderlik tablosuna bakmak yerine daha sofistike bir strateji Ã¶neriyoruz:

* Her zaman gÃ¼venilir bir Ã§apraz doÄŸrulama sistemi kurarak yerel puanlama yapÄ±n.
* Duruma baÄŸlÄ± olarak en iyi doÄŸrulama ÅŸemasÄ±nÄ± kullanarak i.i.d. olmayan daÄŸÄ±lÄ±mlarÄ± kontrol etmeye Ã§alÄ±ÅŸÄ±n. YarÄ±ÅŸma aÃ§Ä±klamasÄ±nda aÃ§Ä±kÃ§a belirtilmedikÃ§e, i.i.d. olmayan daÄŸÄ±lÄ±mlarÄ± fark etmek kolay bir iÅŸ deÄŸildir, ancak tartÄ±ÅŸmalardan veya stratifiye doÄŸrulama ÅŸemalarÄ± kullanarak deney yaparak ipuÃ§larÄ± elde edebilirsiniz (Ã¶rneÄŸin, belirli bir Ã¶zelliÄŸe gÃ¶re sÄ±nÄ±flandÄ±rma yapÄ±ldÄ±ÄŸÄ±nda sonuÃ§lar Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸir).
* Yerel puanlama ile halka aÃ§Ä±k liderlik tablosunu iliÅŸkilendirerek, ikisinin aynÄ± yÃ¶nde olup olmadÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±n.
* Adversarial doÄŸrulama kullanarak test daÄŸÄ±lÄ±mÄ±nÄ±n eÄŸitim verisiyle benzer olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.
* Ã–zellikle kÃ¼Ã§Ã¼k veri setleriyle Ã§alÄ±ÅŸÄ±yorsanÄ±z, Ã§Ã¶zÃ¼mlerinizi toplama (ensembling) yÃ¶ntemleriyle daha dayanÄ±klÄ± hale getirin.

Sonraki bÃ¶lÃ¼mlerde, bu fikirlerin her birini (toplama dÄ±ÅŸÄ±ndaki, Ã§Ã¼nkÃ¼ bu baÅŸka bir bÃ¶lÃ¼mÃ¼n konusu) daha ayrÄ±ntÄ±lÄ± olarak inceleyeceÄŸiz ve Ã¶zel test verisi Ã¼zerinde en iyi sonuÃ§larÄ± elde etmek iÃ§in size en iyi araÃ§larÄ± ve stratejileri saÄŸlayacaÄŸÄ±z.

### The importance of validation in competitions *(YarÄ±ÅŸmalarda doÄŸrulamanÄ±n Ã¶nemi)*

Bir yarÄ±ÅŸmayÄ± dikkatlice dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼zde, onu bÃ¼yÃ¼k bir deney sistemine benzetebilirsiniz. Kim en sistematik ve verimli ÅŸekilde bu deneyleri yapabilirse, o kazanÄ±r.

GerÃ§ekten de, tÃ¼m teorik bilginize raÄŸmen, aynÄ± becerilere sahip olan yÃ¼zlerce ya da binlerce veri profesyoneliyle rekabet iÃ§inde olacaksÄ±nÄ±z. Ãœstelik, onlar da sizinle aynÄ± veriyi kullanacaklar ve veriden Ã¶ÄŸrenmek iÃ§in bÃ¼yÃ¼k Ã¶lÃ§Ã¼de aynÄ± araÃ§larÄ± kullanacaklar (TensorFlow, PyTorch, Scikit-learn vb.). BazÄ±larÄ±nÄ±n kesinlikle daha iyi hesaplama kaynaklarÄ±na eriÅŸimi olacak, ancak Kaggle Notebooksâ€™un ve genel olarak dÃ¼ÅŸen bulut biliÅŸim fiyatlarÄ±nÄ±n sayesinde bu fark artÄ±k o kadar geniÅŸ deÄŸil. DolayÄ±sÄ±yla, bilgi, veri, modeller ve kullanÄ±labilir bilgisayarlar arasÄ±ndaki farklara baktÄ±ÄŸÄ±nÄ±zda, diÄŸer rakiplerle aranÄ±zdaki bÃ¼yÃ¼k performans farklÄ±lÄ±klarÄ±nÄ± aÃ§Ä±klayacak belirgin bir faktÃ¶r bulamayabilirsiniz. Ancak, bazÄ± katÄ±lÄ±mcÄ±lar sÃ¼rekli olarak diÄŸerlerinden daha iyi performans sergiliyor, bu da arka planda bazÄ± baÅŸarÄ± faktÃ¶rlerinin olduÄŸunu ima eder.

RÃ¶portajlarda ve buluÅŸmalarda, bazÄ± Kaggle katÄ±lÄ±mcÄ±larÄ± bu baÅŸarÄ± faktÃ¶rÃ¼nÃ¼ â€œazimâ€ olarak tanÄ±mlarken, bazÄ±larÄ± â€œher ÅŸeyi denemekâ€ diyor, bazÄ±larÄ± ise â€œyarÄ±ÅŸmaya sahip olduÄŸunuz her ÅŸeyi koyma isteÄŸiâ€ olarak ifade ediyor. Bunlar biraz belirsiz ve sihirli gibi gelebilir. Biz ise buna **sistematik deney yapma** diyoruz. Bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼ze gÃ¶re, baÅŸarÄ±lÄ± bir katÄ±lÄ±mÄ±n anahtarÄ±, gerÃ§ekleÅŸtirdiÄŸiniz deneylerin sayÄ±sÄ± ve bu deneyleri nasÄ±l yÃ¶nettiÄŸinizde yatmaktadÄ±r. Ne kadar fazla deney yaparsanÄ±z, diÄŸer katÄ±lÄ±mcÄ±lardan daha iyi bir Ã§Ã¶zÃ¼m bulma ÅŸansÄ±nÄ±z o kadar artar. Bu sayÄ±, elbette bazÄ± faktÃ¶rlere baÄŸlÄ±dÄ±r, Ã¶rneÄŸin sahip olduÄŸunuz zaman, hesaplama kaynaklarÄ±nÄ±z (ne kadar hÄ±zlÄ± olursa o kadar iyi, ancak daha Ã¶nce belirttiÄŸimiz gibi bu, baÅŸlÄ± baÅŸÄ±na gÃ¼Ã§lÃ¼ bir ayÄ±rÄ±cÄ± deÄŸildir), ekip bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼z ve ekip Ã¼yelerinin gÃ¶revdeki katÄ±lÄ±mÄ± gibi. Bu, genellikle baÅŸarÄ± iÃ§in anahtarlar olarak bildirilen azim ve katÄ±lÄ±m ile uyumludur.

Ancak, bunlar sonucu etkileyen tek faktÃ¶rler deÄŸildir. Deneylerinizi nasÄ±l yÃ¼rÃ¼ttÃ¼ÄŸÃ¼nÃ¼zÃ¼n de bir etkisi vardÄ±r. **HÄ±zlÄ±ca baÅŸarÄ±sÄ±z olup ondan Ã¶ÄŸrenmek**, bir yarÄ±ÅŸmadaki Ã¶nemli faktÃ¶rlerden biridir. Tabii ki, hem baÅŸarÄ±sÄ±z olduÄŸunuzda hem de baÅŸarÄ±lÄ± olduÄŸunuzda, deneyimlerinizden bir ÅŸeyler Ã¶ÄŸrenmek iÃ§in dikkatlice dÃ¼ÅŸÃ¼nmeniz gerekir; yoksa yarÄ±ÅŸmanÄ±z sadece doÄŸru Ã§Ã¶zÃ¼mÃ¼ bulma umuduyla rastgele bir deneme dizisine dÃ¶nÃ¼ÅŸÃ¼r.

Bu nedenle, **her ÅŸey eÅŸit olduÄŸunda**, doÄŸru bir doÄŸrulama stratejisine sahip olmak, baÅŸarÄ±lÄ± Kaggle katÄ±lÄ±mcÄ±larÄ± ile sadece liderlik tablosunu aÅŸÄ±rÄ± uyum saÄŸlayan ve yarÄ±ÅŸma sonrasÄ± beklenenden daha dÃ¼ÅŸÃ¼k sÄ±ralamalarda kalanlar arasÄ±ndaki bÃ¼yÃ¼k farkÄ± yaratÄ±r.

> DoÄŸrulama, modelinizin Ã¼rettiÄŸi hatalarÄ± doÄŸru bir ÅŸekilde deÄŸerlendirmeniz ve denemelerinizin sonucunda modelinizin performansÄ±nÄ±n nasÄ±l iyileÅŸtiÄŸini ya da kÃ¶tÃ¼leÅŸtiÄŸini Ã¶lÃ§meniz iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemdir.

Genel olarak, doÄŸru doÄŸrulama seÃ§menin etkisi, genellikle daha nicel faktÃ¶rler, Ã¶rneÄŸin en son, en gÃ¼Ã§lÃ¼ GPU'ya sahip olmak ya da daha bÃ¼yÃ¼k bir ekibin gÃ¶nderim yapmasÄ± gibi faktÃ¶rler lehine gÃ¶z ardÄ± edilir. Ancak, sadece denemelerin gÃ¼cÃ¼ne ve liderlik tablosundaki sonuÃ§larÄ±na gÃ¼venmek, â€œduvara Ã§amur atmak ve bir ÅŸeyin tutmasÄ±nÄ± ummakâ€ gibi bir ÅŸey olur (buna ÅŸu baÄŸlantÄ±dan bakabilirsiniz: [Kaggle Psychopathy Postmortem](http://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/)). Bazen bÃ¶yle bir strateji iÅŸe yarayabilir, ancak Ã§oÄŸu zaman iÅŸe yaramaz Ã§Ã¼nkÃ¼ doÄŸru yÃ¶nde deneme yapma fÄ±rsatlarÄ±nÄ± kaÃ§Ä±rÄ±rsÄ±nÄ±z ve o Ã§amurun iÃ§inde parlayan mÃ¼cevheri bile gÃ¶rmeniz mÃ¼mkÃ¼n olmaz. Ã–rneÄŸin, halka aÃ§Ä±k liderlik tablosunda ÅŸansÄ±nÄ±zÄ± denemek iÃ§in rastgele ve sistematik olmayan bir stratejiye fazla odaklanÄ±rsanÄ±z, harika Ã§Ã¶zÃ¼mler Ã¼retmiÅŸ olsanÄ±z bile, nihai gÃ¶nderiminizi doÄŸru seÃ§emeyebilir ve en iyi skoru elde eden Ã§Ã¶zÃ¼mÃ¼ Ã¶zel test setinde kaÃ§Ä±rabilirsiniz.

DoÄŸru bir doÄŸrulama stratejisi, hangi modellerinizin Ã¶zel test setinde sÄ±ralama yapmak iÃ§in gÃ¶nderileceÄŸine karar vermenize yardÄ±mcÄ± olabilir. Halka aÃ§Ä±k liderlik tablosunda en iyi modellerinizi gÃ¶ndermeye yÃ¶nelik bÃ¼yÃ¼k bir Ã§ekicilik olsa da, her zaman kendi doÄŸrulama puanlarÄ±nÄ±zÄ± dikkate alÄ±n. Nihai gÃ¶nderimleriniz iÃ§in, duruma gÃ¶re ve liderlik tablosuna gÃ¼venip gÃ¼venmediÄŸinize gÃ¶re, en iyi modelinizi liderlik tablosuna gÃ¶re ve en iyi modelinizi yerel doÄŸrulama sonuÃ§larÄ±nÄ±za gÃ¶re seÃ§in. EÄŸer liderlik tablosuna gÃ¼venmiyorsanÄ±z (Ã¶zellikle eÄŸitim Ã¶rnekleriniz kÃ¼Ã§Ã¼kse ya da Ã¶rnekler i.i.d. deÄŸilse), en iyi iki doÄŸrulama puanÄ±na sahip modelleri gÃ¶nderin ve Ã§ok farklÄ± iki model ya da toplama (ensemble) seÃ§in. Bu ÅŸekilde, Ã¶zel test setinde performans gÃ¶stermeyen Ã§Ã¶zÃ¼mleri seÃ§me riskini azaltmÄ±ÅŸ olursunuz.

**DoÄŸrulama Deneylerinin Pratik YÃ¶nleri**

Bir deney sistemini kurmanÄ±n Ã¶nemini belirttikten sonra, geriye kalan her ÅŸey, doÄŸrulamanÄ±n pratik yÃ¶nlerine dayanÄ±r. GerÃ§ekten de, bir Ã§Ã¶zÃ¼m modellediÄŸinizde bir dizi karÅŸÄ±lÄ±klÄ± kararÄ± verirsiniz:

1. **Verinizi nasÄ±l iÅŸleyeceksiniz?**
2. **Hangi modeli uygulayacaksÄ±nÄ±z?**
3. **Modelin mimarisini nasÄ±l deÄŸiÅŸtireceksiniz? (Ã¶zellikle derin Ã¶ÄŸrenme modelleri iÃ§in Ã¶nemlidir)**
4. **Modelin hiperparametrelerini nasÄ±l ayarlayacaksÄ±nÄ±z?**
5. **Tahminleri nasÄ±l post-process (sonraki iÅŸleme) edeceksiniz?**

Halka aÃ§Ä±k liderlik tablosu Ã¶zel tabloyla mÃ¼kemmel bir ÅŸekilde iliÅŸkili olsa bile, gÃ¼nlÃ¼k gÃ¶nderim sÄ±nÄ±rÄ± (tÃ¼m yarÄ±ÅŸmalarda bulunan bir sÄ±nÄ±rlama) size yukarÄ±da belirtilen alanlarÄ±n her birinde yapabileceÄŸiniz olasÄ± testlerin yÃ¼zeyine bile dokunmanÄ±zÄ± engeller. DoÄŸru bir doÄŸrulama sistemi, yaptÄ±ÄŸÄ±nÄ±z ÅŸeyin liderlik tablosunda iÅŸe yarayÄ±p yaramayacaÄŸÄ±nÄ± Ã¶nceden size sÃ¶yler.

> **Dmitry Larko**
> 
> 
> 
> [https://www.kaggle.com/dmitrylarko](https://www.kaggle.com/dmitrylarko)
> 
> 
> 
> Dmitry Larko, Kaggle YarÄ±ÅŸmasÄ± BÃ¼yÃ¼k UstasÄ± ve H2O.ai'da baÅŸ veri bilimcisidir. Makine Ã¶ÄŸrenimi ve veri bilimi alanÄ±nda on yÄ±lÄ± aÅŸkÄ±n bir deneyime sahiptir. Kaggle ile 2012 AralÄ±k ayÄ±nda tanÄ±ÅŸmÄ±ÅŸ ve birkaÃ§ ay sonra ilk yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸtÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda doÄŸrulama konusunda gÃ¼Ã§lÃ¼ bir savunucudur, bunu rÃ¶portajÄ±nda da vurgulamÄ±ÅŸtÄ±r.
> 
> 
> 
> ---
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggle'da uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> 
> 
> Ã‡oÄŸunlukla tabular veri kÃ¼meleri iÃ§in yarÄ±ÅŸmalara katÄ±ldÄ±m ama bilgisayarla gÃ¶rme (computer vision) yarÄ±ÅŸmalarÄ±nÄ± da seviyorum.
> 
> 
> 
> ---
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rsÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±dÄ±r?**
> 
> 
> 
> Her zaman basit baÅŸlayÄ±p kÃ¼Ã§Ã¼k ve daha basit modeller iÃ§in bir gÃ¶nderi hattÄ± (submission pipeline) kurmayÄ± hedeflerim. Buradaki Ã¶nemli bir adÄ±m, fikirlerinizi saÄŸlam bir ÅŸekilde doÄŸrulamak iÃ§in doÄŸru bir doÄŸrulama (validation) ÅŸemasÄ± oluÅŸturmak. AyrÄ±ca, veri Ã¼zerinde olabildiÄŸince Ã§ok zaman geÃ§irip analiz yapmanÄ±z her zaman iyi bir fikirdir.
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸimde, bir AutoML platformu geliÅŸtiriyorum, bu yÃ¼zden Kaggleâ€™da denediÄŸim Ã§oÄŸu ÅŸey, bu platformun bir parÃ§asÄ± olarak uygulanÄ±yor.
> 
> 
> 
> ---
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸma hakkÄ±nda bize bir ÅŸeyler anlatÄ±r mÄ±sÄ±nÄ±z ve gÃ¶revi ele almak iÃ§in hangi iÃ§gÃ¶rÃ¼leri kullandÄ±nÄ±z?**
> 
> 
> 
> AklÄ±ma herhangi bir ÅŸey gelmiyor ve aslÄ±nda bunun Ã§ok Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nmÃ¼yorum, Ã§Ã¼nkÃ¼ teknik olarak zorlayÄ±cÄ± olan bir ÅŸey, baÅŸkasÄ± iÃ§in Ã§ok kolay olabilir. Teknik zorluklar Ã§ok Ã¶nemli deÄŸil; Ã¶nemli olan, bir yarÄ±ÅŸmanÄ±n bir maraton gibi olduÄŸunu unutmamaktÄ±r, bir sprint deÄŸil. Ya da isterseniz bunu bir dizi sprintten oluÅŸan bir maraton olarak gÃ¶rebilirsiniz. Bu yÃ¼zden tÃ¼kenmemek Ã§ok Ã¶nemli; iyi uyumak, egzersiz yapmak ve parkta yÃ¼rÃ¼yÃ¼ÅŸe Ã§Ä±kmak, beyninizi yeni fikirlerle tazelemek iÃ§in faydalÄ±dÄ±r. Bir Kaggle yarÄ±ÅŸmasÄ±nÄ± kazanmak iÃ§in, yaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±z, uzmanlÄ±ÄŸÄ±nÄ±z ve bazen de biraz ÅŸans gerekir.
> 
> 
> 
> ---
> 
> 
> 
> **Kaggle, kariyerinize yardÄ±mcÄ± oldu mu? Olduysa, nasÄ±l?**
> 
> 
> 
> Åu anki iÅŸimi, bir Kaggle YarÄ±ÅŸmasÄ± BÃ¼yÃ¼k UstasÄ± olmam sayesinde buldum. Mevcut iÅŸverenim iÃ§in bu durum, alandaki uzmanlÄ±ÄŸÄ±mÄ±n yeterli bir kanÄ±tÄ±ydÄ±.
> 
> 
> 
> ---
> 
> 
> 
> **TecrÃ¼besine gÃ¶re, deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? Ä°lk baÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz ÅŸimdi neyi farklÄ± yapardÄ±nÄ±z?**
> 
> 
> 
> Genellikle doÄŸru doÄŸrulama ÅŸemasÄ±nÄ± gÃ¶zden kaÃ§Ä±rÄ±yorlar ve halk liderlik tablosundaki (public leaderboard) geri bildirimleri takip ediyorlar. Bu, Ã§oÄŸu durumda kÃ¶tÃ¼ sonuÃ§lanÄ±r ve â€œshake-upâ€ (sÄ±ralama Ã§alkalanmasÄ±) olarak bilinen duruma yol aÃ§ar.
> 
> 
> 
> AyrÄ±ca, keÅŸifsel veri analizi (exploratory data analysis) yapmayÄ± aceleyle geÃ§ip doÄŸrudan model kurmaya baÅŸlÄ±yorlar, bu da basit Ã§Ã¶zÃ¼mlere ve ortalama liderlik tablosu skorlarÄ±na yol aÃ§ar.
> 
> 
> 
> ---
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdir?**
> 
> 
> 
> YaptÄ±ÄŸÄ±m ana hata, aslÄ±nda deneyimsiz bir kiÅŸinin yapacaÄŸÄ± aynÄ± hatadÄ±r â€“ liderlik tablosundaki skoru takip etmek ve iÃ§ doÄŸrulama (internal validation) yerine ona odaklanmak. Her seferinde bunu yaptÄ±ÄŸÄ±mda, birkaÃ§ sÄ±ralama kaybettim.
> 
> 
> 
> ---
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶zellikle Ã¶nerdiÄŸiniz araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> 
> 
> Bunlar genellikle bilinen araÃ§lardÄ±r. Tabular veri iÃ§in: LightGBM, XGBoost, CatBoost; derin Ã¶ÄŸrenme iÃ§in: PyTorch, PyTorch-Lightning, timm; ve herkes iÃ§in Scikit-learn.
> 
> 
> 
> ---
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken dikkat edilmesi gereken en Ã¶nemli ÅŸey nedir?**
> 
> 
> 
> Basit baÅŸlayÄ±n, her zaman doÄŸrulama yapÄ±n; doÄŸrulama skorunuza gÃ¼venin, liderlik tablosu skoruna deÄŸil.

#### Bias and variance *(Ã–nyargÄ± ve varyans)*

**Ä°yi bir doÄŸrulama sistemi**, eÄŸitim setinizden aldÄ±ÄŸÄ±nÄ±z hata Ã¶lÃ§Ã¼mlerinden daha gÃ¼venilir metriklerle size yardÄ±mcÄ± olur. AslÄ±nda, eÄŸitim seti Ã¼zerinde elde edilen metrikler, her modelin kapasitesinden ve karmaÅŸÄ±klÄ±ÄŸÄ±ndan etkilenir. Bir modelin kapasitesini, verilerden Ã¶ÄŸrenmek iÃ§in kullanabileceÄŸi belleÄŸi olarak dÃ¼ÅŸÃ¼nebilirsiniz.

Her modelin, verilerden alÄ±nan desenleri kaydetmesine yardÄ±mcÄ± olan bir iÃ§ parametre seti vardÄ±r. Her modelin desenleri alma yeteneÄŸi farklÄ±dÄ±r ve bazÄ± modeller belirli kurallarÄ± veya iliÅŸkileri tespit ederken, diÄŸerleri farklÄ± kurallarÄ± bulabilir. Bir model, verilerden desenleri Ã§Ä±kardÄ±kÃ§a, bunlarÄ± "belleÄŸine" kaydeder.

AyrÄ±ca, bir modelin kapasitesinden veya ifade gÃ¼cÃ¼nden bahsederken, bu durum genellikle sapma (bias) ve varyans (variance) ile ilgilidir. Bu durumda, bir modelin sapma ve varyansÄ±, tahminlerle ilgilidir, ancak temel prensip doÄŸrudan modelin ifade gÃ¼cÃ¼yle iliÅŸkilidir. Modeller, bir girdi (gÃ¶zlemlenen veriler) ile bir sonuÃ§ (tahminler) arasÄ±nda bir baÄŸlantÄ± kuran matematiksel fonksiyonlara indirgenebilir. BazÄ± matematiksel fonksiyonlar, sahip olduklarÄ± iÃ§ parametre sayÄ±sÄ± ve bu parametreleri nasÄ±l kullandÄ±klarÄ± aÃ§Ä±sÄ±ndan diÄŸerlerinden daha karmaÅŸÄ±ktÄ±r:

* EÄŸer bir modelin matematiksel fonksiyonu, Ã§Ã¶zmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z problemin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yakalamak iÃ§in yeterince karmaÅŸÄ±k veya ifade gÃ¼cÃ¼ yÃ¼ksek deÄŸilse, bundan **sapma (bias)** olarak bahsederiz, Ã§Ã¼nkÃ¼ tahminleriniz modelin sÄ±nÄ±rlarÄ±yla sÄ±nÄ±rlÄ± ("biased") olacaktÄ±r.

* EÄŸer bir modelin temel matematiksel fonksiyonu, ele aldÄ±ÄŸÄ±nÄ±z problem iÃ§in Ã§ok karmaÅŸÄ±ksa, o zaman **varyans (variance)** problemi vardÄ±r, Ã§Ã¼nkÃ¼ model, eÄŸitim verilerindeki gereksiz detaylarÄ± ve gÃ¼rÃ¼ltÃ¼yÃ¼ fazla kaydedecek ve tahminleri bu bilgilerden derinden etkilenecek, bu da tahminlerin dÃ¼zensiz olmasÄ±na yol aÃ§acaktÄ±r.

GÃ¼nÃ¼mÃ¼zde, makine Ã¶ÄŸrenimi alanÄ±ndaki ilerlemeler ve mevcut hesaplama kaynaklarÄ± gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, problem genellikle varyans kaynaklÄ±dÄ±r. Ã‡Ã¼nkÃ¼ derin sinir aÄŸlarÄ± ve gradyan artÄ±rma (gradient boosting) gibi en yaygÄ±n kullanÄ±lan Ã§Ã¶zÃ¼mler, Ã§oÄŸu zaman karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z problemlerin Ã§Ã¶zÃ¼lmesi iÃ§in gerekenin Ã§ok Ã¶tesinde matematiksel bir ifade gÃ¼cÃ¼ne sahiptir.

Bir model, Ã§Ä±karabileceÄŸi tÃ¼m yararlÄ± desenleri elde ettikten sonra, eÄŸer kapasitesini tÃ¼ketmemiÅŸse, veriyle ilgili olmayan (genellikle gÃ¼rÃ¼ltÃ¼ olarak adlandÄ±rÄ±lÄ±r) Ã¶zellikleri ve sinyalleri Ã¶ÄŸrenmeye baÅŸlar. Ä°lk baÅŸta Ã§Ä±karÄ±lan desenler, modelin test verisi Ã¼zerinde genelleme yapmasÄ±na ve daha doÄŸru tahminlerde bulunmasÄ±na yardÄ±mcÄ± olsa da, yalnÄ±zca eÄŸitim seti hakkÄ±nda Ã¶ÄŸrendiklerinin her biri yardÄ±mcÄ± olmayacak; bunun yerine modelin performansÄ±nÄ± zarar verebilir. EÄŸitim setinin, genelleme deÄŸeri taÅŸÄ±mayan unsurlarÄ±nÄ± Ã¶ÄŸrenme sÃ¼reci **aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting)** olarak adlandÄ±rÄ±lÄ±r.

DoÄŸrulamanÄ±n temel amacÄ±, bu deÄŸerin genelleÅŸtirilebilir kÄ±smÄ±nÄ±, eÄŸitim seti Ã¶zelliklerine aÅŸÄ±rÄ± uyum saÄŸlamanÄ±n neden olduÄŸu kÄ±smÄ±ndan ayÄ±ran bir puan veya kayÄ±p deÄŸeri tanÄ±mlamaktÄ±r.

---

**Ä°yi DoÄŸrulama TasarÄ±mÄ±**

Bu, doÄŸrulama kaybÄ±dÄ±r (validation loss). Ã–ÄŸrenme eÄŸrilerinin gÃ¶rselleÅŸtirildiÄŸi ÅŸu ÅŸekilde bir durumu gÃ¶rebilirsiniz:

![](im/1051.png)

**EÄŸer kayÄ±p Ã¶lÃ§Ã¼mÃ¼nÃ¼ (loss measure) y-yakasÄ± Ã¼zerine ve modelin Ã¶ÄŸrenme Ã§abasÄ±nÄ± (bu, sinir aÄŸlarÄ± iÃ§in epoklar veya gradyan artÄ±rma iÃ§in turlar olabilir) x-yakasÄ± Ã¼zerine grafiÄŸe dÃ¶kerseniz, Ã¶ÄŸrenmenin her zaman eÄŸitim veri setinde gerÃ§ekleÅŸtiÄŸini fark edeceksiniz, ancak bu her zaman diÄŸer verilerde geÃ§erli deÄŸildir.**

AynÄ± ÅŸey, hiperparametreleri deÄŸiÅŸtirdiÄŸinizde, veriyi iÅŸlediÄŸinizde veya tamamen farklÄ± bir model seÃ§tiÄŸinizde de olur. EÄŸri ÅŸekli deÄŸiÅŸebilir, ancak her zaman aÅŸÄ±rÄ± Ã¶ÄŸrenmenin (overfitting) baÅŸladÄ±ÄŸÄ± bir tatlÄ± nokta olacaktÄ±r. Bu nokta, modeller arasÄ±nda ve modelleme sÃ¼recinizde yaptÄ±ÄŸÄ±nÄ±z Ã§eÅŸitli seÃ§imlere gÃ¶re farklÄ±lÄ±k gÃ¶sterebilir. EÄŸer aÅŸÄ±rÄ± Ã¶ÄŸrenmenin baÅŸladÄ±ÄŸÄ± noktayÄ± doÄŸru bir doÄŸrulama stratejisi ile doÄŸru ÅŸekilde hesapladÄ±ysanÄ±z, modelinizin performansÄ± kesinlikle liderlik tablosu sonuÃ§larÄ±yla (hem halka aÃ§Ä±k hem de Ã¶zel) korele olacaktÄ±r ve doÄŸrulama metrikleriniz, herhangi bir gÃ¶nderi yapmadan Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± deÄŸerlendirmeniz iÃ§in bir proxy (temsilci) saÄŸlayacaktÄ±r.

**AÅŸÄ±rÄ± Ã¶ÄŸrenme (Overfitting) farklÄ± seviyelerde karÅŸÄ±nÄ±za Ã§Ä±kabilir:**

* EÄŸitim verisi seviyesinde, eÄŸer probleme Ã§ok karmaÅŸÄ±k bir model kullanÄ±yorsanÄ±z
* DoÄŸrulama seti seviyesinde, modelinizi belirli bir doÄŸrulama setine Ã§ok fazla gÃ¶re ayarladÄ±ÄŸÄ±nÄ±zda
* Halka aÃ§Ä±k liderlik tablosu seviyesinde, eÄŸer sonuÃ§larÄ±nÄ±z eÄŸitimle beklediÄŸinizden Ã§ok uzaksa
* Ã–zel liderlik tablosu seviyesinde, halka aÃ§Ä±k liderlik tablosunda iyi sonuÃ§lar elde etmenize raÄŸmen, Ã¶zel sonuÃ§larÄ±nÄ±z hayal kÄ±rÄ±klÄ±ÄŸÄ± yaratÄ±yorsa

Anlam aÃ§Ä±sÄ±ndan biraz farklÄ± olsalar da, hepsi de modelinizin genellenebilir olmadÄ±ÄŸÄ±nÄ± gÃ¶sterir, tÄ±pkÄ± bu bÃ¶lÃ¼mde tarif ettiÄŸimiz gibi.

### Trying different splitting strategies *(FarklÄ± veri bÃ¶lme stratejilerini denemek)*

Daha Ã¶nce tartÄ±ÅŸÄ±ldÄ±ÄŸÄ± gibi, doÄŸrulama kaybÄ±, eÄŸitim setinin parÃ§asÄ± olmayan bir veri Ã¶rneÄŸine dayanmaktadÄ±r. Bu, modelinizin tahmin etme konusundaki ne kadar iyi olduÄŸunu belirten ampirik bir Ã¶lÃ§Ã¼dÃ¼r ve eÄŸitim verilerinin desenlerini ne kadar ezberlediÄŸini belirten eÄŸitimde elde edilen sonuÃ§lardan daha doÄŸru bir Ã¶lÃ§Ã¼dÃ¼r. DoÄŸrulama iÃ§in kullanÄ±lan veri Ã¶rneÄŸini doÄŸru bir ÅŸekilde seÃ§mek, doÄŸrulama stratejinizin temelini oluÅŸturur.

Modelinizi doÄŸrulamak ve performansÄ±nÄ± doÄŸru ÅŸekilde Ã¶lÃ§mek iÃ§in birkaÃ§ seÃ§eneÄŸiniz vardÄ±r:

* Ä°lk seÃ§enek, bir holdout (ayÄ±rma) sistemi kullanmaktÄ±r. Ancak, bu, verilerinizi temsil eden bir Ã¶rneklem seÃ§me riskini taÅŸÄ±r veya doÄŸrulama holdout'unuza aÅŸÄ±rÄ± uyum saÄŸlama riski iÃ§erir.

* Ä°kinci seÃ§enek, olasÄ±lÄ±ksal bir yaklaÅŸÄ±m kullanmak ve sonuÃ§lara varmak iÃ§in bir dizi Ã¶rneklem kullanmaktÄ±r. OlasÄ±lÄ±ksal yaklaÅŸÄ±mlar arasÄ±nda Ã§apraz doÄŸrulama, birer bir bÄ±rakma (LOO) ve bootstrap bulunmaktadÄ±r. Ã‡apraz doÄŸrulama stratejileri arasÄ±nda, verinizin Ã¶zelliÄŸine baÄŸlÄ± olarak Ã§eÅŸitli numaralar vardÄ±r (basit rastgele Ã¶rnekleme, katmanlÄ± Ã¶rnekleme, gruplar halinde Ã¶rnekleme, zamanlÄ± Ã¶rnekleme).

TÃ¼m bu stratejilerin ortak noktasÄ±, Ã¶rnekleme stratejileridir. Bu stratejiler, kÃ¼Ã§Ã¼k bir veri parÃ§asÄ±na dayalÄ± olarak genel bir Ã¶lÃ§Ã¼m Ã§Ä±karÄ±lmasÄ±na yardÄ±mcÄ± olur (modelinizin performansÄ± gibi). Ã–rnekleme, istatistiÄŸin temelidir ve kesin bir prosedÃ¼r deÄŸildir, Ã§Ã¼nkÃ¼ Ã¶rnekleme yÃ¶nteminiz, mevcut veriniz ve Ã¶rnekleme sÃ¼recindeki rastlantÄ±sallÄ±k nedeniyle belirli durumlarÄ±n Ã¶rnekleme dahil edilmesi, belirli bir hata payÄ±na yol aÃ§abilir.

**Ä°yi Bir DoÄŸrulama TasarÄ±mÄ±**

Ã–rneÄŸin, eÄŸer taraflÄ± bir Ã¶rneklem kullanÄ±rsanÄ±z, doÄŸrulama metriÄŸiniz yanlÄ±ÅŸ bir ÅŸekilde (aÅŸÄ±rÄ± veya eksik) tahmin edilebilir. Ancak, doÄŸru bir ÅŸekilde tasarlanÄ±p uygulanÄ±rsa, Ã¶rnekleme stratejileri genel Ã¶lÃ§Ã¼mÃ¼nÃ¼zÃ¼n iyi bir tahminini saÄŸlar.

Bu stratejilerin ortak bir diÄŸer Ã¶zelliÄŸi de bunlarÄ±n bÃ¶lÃ¼mler olmasÄ±dÄ±r, yani her bir vaka, eÄŸitim veya doÄŸrulama olarak birbirinden dÄ±ÅŸlanmÄ±ÅŸ ÅŸekilde ayrÄ±lÄ±r. GerÃ§ekten de, Ã§oÄŸu modelin belirli bir ezberleme yeteneÄŸi olduÄŸundan, aynÄ± vakalarÄ±n hem eÄŸitim hem de doÄŸrulama iÃ§in kullanÄ±lmasÄ±, modelin ezberleme yeteneklerini sergilemesine izin verdiÄŸi iÃ§in ÅŸiÅŸirilmiÅŸ tahminlere yol aÃ§ar; bunun yerine, modelin hiÃ§ gÃ¶rÃ¼lmemiÅŸ Ã¶rneklerde Ã§alÄ±ÅŸacak desenler ve fonksiyonlar tÃ¼retme yeteneÄŸi Ã¼zerinde deÄŸerlendirilmesini istiyoruz.

#### The basic train-test split *(Temel eÄŸitim-test bÃ¶lÃ¼nmesi)*

Ä°lk analiz edeceÄŸimiz strateji, eÄŸitim-test bÃ¶lme (train-test split) stratejisidir. Bu stratejide, eÄŸitim setinizin bir kÄ±smÄ±nÄ± (aynÄ± zamanda holdout olarak da bilinir) Ã¶rnek alÄ±r ve bu kÄ±smÄ±, geri kalan verilerle eÄŸittiÄŸiniz tÃ¼m modeller iÃ§in test seti olarak kullanÄ±rsÄ±nÄ±z.

Bu stratejinin bÃ¼yÃ¼k avantajÄ±, Ã§ok basit olmasÄ±dÄ±r: Verinizin bir kÄ±smÄ±nÄ± seÃ§er ve bu kÄ±smÄ± kullanarak modelinizin baÅŸarÄ±sÄ±nÄ± test edersiniz. Genellikle veriler %80/%20 oranÄ±nda, eÄŸitim seti lehine bÃ¶lÃ¼nÃ¼r. Scikit-learn'de, bu yÃ¶ntem train_test_split fonksiyonu ile uygulanÄ±r. Bu yÃ¶ntemi birkaÃ§ aÃ§Ä±dan ele alalÄ±m:

* BÃ¼yÃ¼k veri setleriniz olduÄŸunda, Ã§Ä±kardÄ±ÄŸÄ±nÄ±z test verisinin orijinal veri setinin daÄŸÄ±lÄ±mÄ±na benzer (temsil edici) olmasÄ±nÄ± bekleyebilirsiniz. Ancak, Ã§Ä±kartma iÅŸlemi rastlantÄ±sal bir ÅŸekilde yapÄ±ldÄ±ÄŸÄ± iÃ§in her zaman temsili olmayan bir Ã¶rnekleme Ã§Ä±karma ÅŸansÄ±nÄ±z vardÄ±r. Ã–zellikle, baÅŸladÄ±ÄŸÄ±nÄ±z eÄŸitim Ã¶rneÄŸiniz kÃ¼Ã§Ã¼kse bu ÅŸans artar. Ã‡Ä±karÄ±lan holdout bÃ¶lÃ¼mÃ¼nÃ¼, adversarial validasyon (bunun hakkÄ±nda birkaÃ§ bÃ¶lÃ¼m sonra daha fazla bilgi verilecektir) kullanarak karÅŸÄ±laÅŸtÄ±rmak, Ã§abalarÄ±nÄ±zÄ± doÄŸru bir ÅŸekilde deÄŸerlendirdiÄŸinizden emin olmanÄ±za yardÄ±mcÄ± olabilir.

* AyrÄ±ca, test Ã¶rneklemenizin temsil edici olmasÄ±nÄ± saÄŸlamak iÃ§in, Ã¶zellikle eÄŸitim verilerinizin hedef deÄŸiÅŸkenle nasÄ±l iliÅŸkilendiÄŸi konusunda, stratifikasyonu (katmanlÄ± Ã¶rnekleme) kullanabilirsiniz. Bu, belirli Ã¶zelliklerin oranlarÄ±nÄ±n Ã¶rneklenen veride korunmasÄ±nÄ± saÄŸlar. Bunu yapmak iÃ§in train_test_split fonksiyonundaki **stratify** parametresini kullanabilir ve korumak istediÄŸiniz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± iÃ§eren bir dizi verebilirsiniz.

Bir temsilci holdout'a sahip olsanÄ±z bile, bazen basit bir train-test bÃ¶lmesi, yarÄ±ÅŸmalarda Ã§abalarÄ±nÄ±zÄ± doÄŸru bir ÅŸekilde takip etmek iÃ§in yeterli olmayabilir.

AslÄ±nda, bu test setinde sÃ¼rekli deÄŸerlendirme yaparken, seÃ§imlerinizi bir tÃ¼r adaptasyon aÅŸÄ±rÄ± uyumuna (diÄŸer bir deyiÅŸle, eÄŸitim setinin gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ yanlÄ±ÅŸ bir ÅŸekilde sinyal olarak almak) yol aÃ§acak ÅŸekilde yÃ¶nlendirebilirsiniz. Bu, Ã¶zellikle sÄ±k sÄ±k halk liderliÄŸi tablosunda deÄŸerlendirme yapÄ±ldÄ±ÄŸÄ±nda meydana gelir. Bu nedenle, olasÄ±lÄ±ksal bir deÄŸerlendirme, daha fazla hesaplama gerektirse de, bir yarÄ±ÅŸma iÃ§in daha uygun bir yaklaÅŸÄ±mdÄ±r.

#### Probabilistic evaluation methods *(OlasÄ±lÄ±ksal deÄŸerlendirme yÃ¶ntemleri)*

Makine Ã¶ÄŸrenimi modelinin performansÄ±nÄ±n olasÄ±lÄ±ksal deÄŸerlendirilmesi, bir daÄŸÄ±lÄ±mdan alÄ±nan Ã¶rneÄŸin istatistiksel Ã¶zelliklerine dayanÄ±r. Ã–rnekleme yaparak, orijinal verinizin daha kÃ¼Ã§Ã¼k bir kÃ¼mesini oluÅŸturmuÅŸ olursunuz ve bu kÃ¼menin, orijinal verinin aynÄ± Ã¶zelliklere sahip olmasÄ± beklenir. AyrÄ±ca, Ã¶rneklemeye dokunulmayan kÄ±sÄ±m da bir Ã¶rneklem oluÅŸturur ve bu kÄ±sÄ±m da orijinal verinin Ã¶zelliklerine sahip olmalÄ±dÄ±r. Modelinizi bu Ã¶rneklenmiÅŸ veriler Ã¼zerinde eÄŸitip test ederek ve bu iÅŸlemi birÃ§ok kez tekrarlayarak, temelde modelinizin performansÄ±nÄ± Ã¶lÃ§en bir istatistiksel tahminci yaratÄ±yorsunuz. Her Ã¶rneklemin iÃ§inde bir "hata" olabilir; yani, orijinal verinin gerÃ§ek daÄŸÄ±lÄ±mÄ±nÄ± tam olarak temsil etmeyebilir. Ancak daha fazla Ã¶rnekleme yaptÄ±kÃ§a, bu birden fazla Ã¶rneklemdeki tahmincilerinizin ortalamasÄ±, tahmin etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z Ã¶lÃ§Ã¼tÃ¼n gerÃ§ek ortalamasÄ±na yakÄ±nsama gÃ¶sterir (bu, olasÄ±lÄ±k teorisinde BÃ¼yÃ¼k SayÄ±lar Kanunu adÄ± verilen bir teoremle aÃ§Ä±klanan gÃ¶zlemlenen bir sonuÃ§tur).

OlasÄ±lÄ±ksal tahminciler, basit bir train-test bÃ¶lmesine gÃ¶re doÄŸal olarak daha fazla hesaplama gerektirir, ancak doÄŸru Ã¶lÃ§Ã¼tÃ¼, yani modelinizin genel performansÄ±nÄ± doÄŸru bir ÅŸekilde tahmin ettiÄŸinizden daha fazla emin olmanÄ±zÄ± saÄŸlar.

##### k-fold cross-validation *(k-katlÄ± Ã§apraz doÄŸrulama)*

En yaygÄ±n kullanÄ±lan olasÄ±lÄ±ksal doÄŸrulama yÃ¶ntemi, k-katlÄ± Ã§apraz doÄŸrulama (k-fold cross-validation) olup, modelinizin daha Ã¶nce gÃ¶rmediÄŸi, aynÄ± daÄŸÄ±lÄ±mdan Ã§ekilmiÅŸ test verileri Ã¼zerindeki performansÄ±nÄ± doÄŸru bir ÅŸekilde tahmin etme yeteneÄŸiyle tanÄ±nÄ±r.

> Bu konu, Bates, S., Hastie, T., ve Tibshirani, R.'nin **Cross-validation: what does it estimate and how well does it do it?** baÅŸlÄ±klÄ± makalesinde aÃ§Ä±kÃ§a aÃ§Ä±klanmÄ±ÅŸtÄ±r (arXiv preprint arXiv:2104.00673, 2021, [makale baÄŸlantÄ±sÄ±](https://arxiv.org/pdf/2104.00673.pdf)).

k-katlÄ± Ã§apraz doÄŸrulama, hem tahminsel modelleri karÅŸÄ±laÅŸtÄ±rmak hem de test seti Ã¼zerinde en iyi performansÄ± gÃ¶sterecek olan modelin hiperparametrelerini seÃ§mek iÃ§in baÅŸarÄ±yla kullanÄ±labilir.

k-katlÄ± Ã§apraz doÄŸrulamanÄ±n pek Ã§ok farklÄ± Ã§eÅŸidi olsa da, en basiti, Scikit-learn'deki **KFold** fonksiyonunda uygulanan versiyonudur. Bu yÃ¶ntemde, mevcut eÄŸitim veriniz k parÃ§aya ayrÄ±lÄ±r. ArdÄ±ndan, k iterasyon iÃ§in bu parÃ§alardan birisi test seti olarak alÄ±nÄ±r, diÄŸer k-1 parÃ§a ise modelin eÄŸitimi iÃ§in kullanÄ±lÄ±r.

k doÄŸrulama skoru daha sonra ortalanÄ±r ve bu ortalama skor deÄŸeri, k-katlÄ± doÄŸrulama skoru olur; bu skor, modelinizin herhangi bir gÃ¶rÃ¼lmemiÅŸ veri Ã¼zerindeki tahmin edilen ortalama performansÄ±nÄ± gÃ¶sterir. SkorlarÄ±n standart sapmasÄ± ise, tahminin ne kadar belirsiz olduÄŸunu size bildirir. Åekil 6.2, 5-katlÄ± Ã§apraz doÄŸrulamanÄ±n nasÄ±l yapÄ±landÄ±rÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir.

![](im/1052.png)

K-katlamalÄ± Ã§apraz doÄŸrulama skorunun Ã¶nemli bir yÃ¶nÃ¼, modelinizin k-1 katÄ±ndan aynÄ± miktarda veri ile eÄŸitilmiÅŸ olarak ortalama skorunu tahmin etmesidir. Ancak sonrasÄ±nda modelinizi tÃ¼m verinizle eÄŸittiÄŸinizde, Ã¶nceki doÄŸrulama tahmini geÃ§erliliÄŸini yitirir. K, Ã¶rnek sayÄ±sÄ± n'ye yaklaÅŸtÄ±kÃ§a, modelinizin tÃ¼m eÄŸitim seti Ã¼zerinde eÄŸitilmiÅŸ haline iliÅŸkin giderek daha doÄŸru bir tahmin elde edersiniz; ancak her katÄ±n tahminleri arasÄ±ndaki artan korelasyon nedeniyle, doÄŸrulamanÄ±n tÃ¼m olasÄ±lÄ±k tahminlerini kaybedersiniz. Bu durumda, elde ettiÄŸiniz sayÄ±, modelinizin eÄŸitim verisi Ã¼zerindeki performansÄ±nÄ± gÃ¶sterir (ki bu hala karÅŸÄ±laÅŸtÄ±rma amaÃ§larÄ± iÃ§in yararlÄ± bir tahmin olabilir, ancak modelinizin genelleme gÃ¼cÃ¼nÃ¼ doÄŸru ÅŸekilde tahmin etmenize yardÄ±mcÄ± olmaz).

K = n'ye ulaÅŸtÄ±ÄŸÄ±nÄ±zda, bunun LOO (Leave-One-Out) doÄŸrulama yÃ¶ntemi olduÄŸunu gÃ¶rÃ¼rsÃ¼nÃ¼z, bu yÃ¶ntem birkaÃ§ Ã¶rneÄŸiniz olduÄŸunda yararlÄ±dÄ±r. Bu yÃ¶ntem Ã§oÄŸunlukla tarafsÄ±z bir uyum Ã¶lÃ§Ã¼tÃ¼dÃ¼r, Ã§Ã¼nkÃ¼ mevcut verilerin neredeyse tamamÄ±nÄ± eÄŸitmek iÃ§in kullanÄ±r ve sadece bir Ã¶rneÄŸi test iÃ§in ayÄ±rÄ±r. Ancak, bu, gÃ¶rÃ¼nmeyen verilerdeki beklenen performansÄ±n iyi bir tahmini deÄŸildir. Verisetindeki her bir testin tekrar edilmesi, birbirleriyle yÃ¼ksek oranda korelasyonlu olur ve ortaya Ã§Ä±kan LOO metriÄŸi, modelin veri seti Ã¼zerindeki performansÄ±nÄ± daha Ã§ok temsil eder, bilinmeyen verilerdeki performansÄ±ndan ziyade.

DoÄŸru k sayÄ±sÄ±, sahip olduÄŸunuz veriye iliÅŸkin birkaÃ§ aÃ§Ä±ya baÄŸlÄ± olarak belirlenir:

* K kÃ¼Ã§Ã¼kse (minimum 2'dir), her kat daha kÃ¼Ã§Ã¼k olacak ve bu nedenle k-1 katÄ±nda eÄŸitilen bir model iÃ§in Ã¶ÄŸrenmede daha fazla bias (sapma) olacaktÄ±r: daha kÃ¼Ã§Ã¼k bir k ile doÄŸrulanan model, daha bÃ¼yÃ¼k bir k ile eÄŸitilen bir modele gÃ¶re daha dÃ¼ÅŸÃ¼k performans gÃ¶sterir.
* K daha bÃ¼yÃ¼kse, daha fazla veri olacaktÄ±r, ancak doÄŸrulama tahminleriniz daha fazla korelasyon gÃ¶sterir: K-katlamalÄ± Ã§apraz doÄŸrulamanÄ±n, gÃ¶rÃ¼nmeyen verilere olan performansÄ± tahmin etme Ã¶zelliklerini kaybedersiniz.

Genellikle, k 5, 7 veya 10 olarak belirlenir, nadiren 20 katlama kullanÄ±lÄ±r. K = 5 veya k = 10 genellikle bir yarÄ±ÅŸma iÃ§in iyi bir seÃ§enek olarak kabul edilir, Ã§Ã¼nkÃ¼ 10 katlama daha fazla veriyi her eÄŸitimde kullanÄ±r (mevcut verilerin %90'Ä±) ve bu nedenle modelinizin tÃ¼m veri kÃ¼mesiyle yeniden eÄŸitildiÄŸinde beklenen performansÄ±nÄ± anlamada daha uygundur.

Bir yarÄ±ÅŸmadaki belirli bir veri seti iÃ§in hangi k'nÄ±n seÃ§ileceÄŸini karar verirken, iki perspektifi gÃ¶z Ã¶nÃ¼nde bulundurmak faydalÄ±dÄ±r.

Ä°lk olarak, katlamalÄ± sayÄ±nÄ±n seÃ§imi hedeflerinize gÃ¶re olmalÄ±dÄ±r:

* AmacÄ±nÄ±z performans tahmini yapmaksa, dÃ¼ÅŸÃ¼k biaslÄ± (yanlÄ±lÄ±ksÄ±z) modeller gerekir (yani tahminlerde sistematik bir distorsiyon olmamalÄ±dÄ±r). Bunu baÅŸarmak iÃ§in daha yÃ¼ksek sayÄ±da katlama kullanmanÄ±z gerekir, genellikle 10 ila 20 arasÄ±nda.
* AmacÄ±nÄ±z parametre ayarlamasÄ± yapmaksa, bias ve varyans karÄ±ÅŸÄ±mÄ±na ihtiyacÄ±nÄ±z vardÄ±r, bu nedenle orta sayÄ±da katlama kullanmak uygundur, genellikle 5 ila 7 arasÄ±nda.
* Son olarak, amacÄ±nÄ±z sadece deÄŸiÅŸken seÃ§imi yapmak ve veri setinizi basitleÅŸtirmekse, dÃ¼ÅŸÃ¼k varyanslÄ± tahminler (ya da anlaÅŸmazlÄ±k yaÅŸamamak) gerekir. Bu nedenle daha dÃ¼ÅŸÃ¼k sayÄ±da katlama yeterlidir, genellikle 3 ila 5 arasÄ±nda.

Mevcut verilerin boyutu oldukÃ§a bÃ¼yÃ¼kse, Ã¶nerilen bantlarÄ±n alt tarafÄ±nda kalmak gÃ¼venlidir.

Ä°kinci olarak, sadece performans tahmini yapmayÄ± amaÃ§lÄ±yorsanÄ±z, kullandÄ±ÄŸÄ±nÄ±z daha fazla katlamanÄ±n, doÄŸrulama setinizde daha az Ã¶rnek olacaÄŸÄ± anlamÄ±na geldiÄŸini ve bu nedenle her katÄ±n tahminlerinin daha fazla korelasyon gÃ¶stereceÄŸini unutmayÄ±n. Belirli bir noktadan sonra, k'yÄ± artÄ±rmak, Ã§apraz doÄŸrulama tahminlerinizi gÃ¶rÃ¼nmeyen test setlerine dair daha az Ã¶ngÃ¶rÃ¼cÃ¼ hale getirir ve modelinizin eÄŸitim setindeki performansÄ±nÄ±n tahmini olarak daha Ã§ok temsil eder. Bu, daha fazla katlama ile, sizin iÃ§in doÄŸru bir "out-of-fold" tahmini almanÄ±zÄ± saÄŸladÄ±ÄŸÄ±ndan, model birleÅŸtirme ve yÄ±ÄŸÄ±lma (stacking) gibi teknikler iÃ§in daha faydalÄ± olabilir.

> Kaggle yarÄ±ÅŸmalarÄ±nda, k-katlamalÄ± Ã§apraz doÄŸrulama genellikle sadece Ã§Ã¶zÃ¼m yaklaÅŸÄ±mÄ±nÄ±zÄ± doÄŸrulamak ve modelinizin performansÄ±nÄ± anlamak iÃ§in deÄŸil, aynÄ± zamanda tahmininizi Ã¼retmek iÃ§in de uygulanÄ±r. Ã‡apraz doÄŸrulama yaparken, alt Ã¶rnekleme yapÄ±yorsunuz ve verinin alt Ã¶rneklerine dayalÄ± olarak birden Ã§ok modelin sonuÃ§larÄ±nÄ± ortalamak, genellikle tÃ¼m mevcut verilerle eÄŸitim yapmaktan daha etkili bir stratejidir. Bu, genellikle varyansla mÃ¼cadele etmek iÃ§in daha etkili bir yol olur (bunu daha detaylÄ± olarak 9. BÃ¶lÃ¼m'de, "Blending ve Stacking Ã‡Ã¶zÃ¼mleriyle BirleÅŸtirme" baÅŸlÄ±ÄŸÄ±nda tartÄ±ÅŸacaÄŸÄ±z). Bu nedenle birÃ§ok Kaggle katÄ±lÄ±mcÄ±sÄ±, Ã§apraz doÄŸrulama sÄ±rasÄ±nda oluÅŸturulan modelleri kullanarak test setinde bir dizi tahmin saÄŸlar ve bunlarÄ± ortaladÄ±ÄŸÄ±nda en iyi Ã§Ã¶zÃ¼mÃ¼ elde eder.

**K-KatlamalÄ± Ã‡apraz DoÄŸrulama VaryasyonlarÄ±**

K-katlamalÄ± Ã§apraz doÄŸrulama, rastgele Ã¶rneklemeye dayandÄ±ÄŸÄ± iÃ§in bazÄ± durumlarda uygun olmayan bÃ¶lmeler verebilir:

* **KÃ¼Ã§Ã¼k sÄ±nÄ±flarÄ±n oranÄ±nÄ± korumanÄ±z gerektiÄŸinde**, hem hedef seviyesinde hem de Ã¶zellikler seviyesinde. Bu durum, hedef deÄŸiÅŸkeninizin oldukÃ§a dengesiz olduÄŸu durumlarda yaygÄ±ndÄ±r. Tipik Ã¶rnekler arasÄ±nda spam veri setleri (Ã§Ã¼nkÃ¼ spam, normal e-posta hacminin kÃ¼Ã§Ã¼k bir kÄ±smÄ±dÄ±r) veya bir kredi riski veri seti (dÃ¼ÅŸÃ¼k ihtimalle gerÃ§ekleÅŸen bir kredi temerrÃ¼dÃ¼ olayÄ±nÄ± tahmin etmek) bulunur.

* **Bir sayÄ±sal deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±nÄ± korumanÄ±z gerektiÄŸinde**, hem hedef seviyesinde hem de Ã¶zellikler seviyesinde. Bu durum, daÄŸÄ±lÄ±mÄ±n oldukÃ§a Ã§arpÄ±k olduÄŸu veya uzun kuyruklar iÃ§erdiÄŸi regresyon problemlerinde yaygÄ±ndÄ±r. YaygÄ±n bir Ã¶rnek, ev fiyatÄ± tahmini olabilir, Ã§Ã¼nkÃ¼ satÄ±ÅŸa Ã§Ä±kan bazÄ± evler, ortalama evden Ã§ok daha yÃ¼ksek fiyatlarla satÄ±lmaktadÄ±r.

* **Verileriniz baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda (i.i.d.) deÄŸilse**, Ã¶zellikle zaman serisi tahmini yapÄ±yorsanÄ±z.

Ä°lk iki senaryoda Ã§Ã¶zÃ¼m, **stratifiye k-katlamalÄ± doÄŸrulama** (stratified k-fold) olacaktÄ±r. Bu yÃ¶ntemde, Ã¶rnekleme kontrol edilmiÅŸ bir ÅŸekilde yapÄ±lÄ±r ve korumak istediÄŸiniz daÄŸÄ±lÄ±mÄ± korur. EÄŸer tek bir sÄ±nÄ±fÄ±n daÄŸÄ±lÄ±mÄ±nÄ± korumanÄ±z gerekiyorsa, Scikit-learn'deki `StratifiedKFold` fonksiyonunu kullanabilirsiniz. Bu fonksiyon, genellikle hedef deÄŸiÅŸkeniniz olan, ancak aynÄ± zamanda daÄŸÄ±lÄ±mÄ±nÄ± korumanÄ±z gereken baÅŸka bir Ã¶zellik ile stratifikasyon deÄŸiÅŸkeni kullanarak, verilerinizi doÄŸru bir ÅŸekilde bÃ¶lmenize yardÄ±mcÄ± olacak indeksler Ã¼retir. AynÄ± sonuca, sayÄ±sal bir deÄŸiÅŸken ile, onu Ã¶nce diskretize ettikten sonra `pandas.cut` veya Scikit-learnâ€™Ã¼n `KBinsDiscretizer` fonksiyonlarÄ± ile de ulaÅŸabilirsiniz.

Birden fazla deÄŸiÅŸken veya Ã¶rtÃ¼ÅŸen etiketler (Ã¶rneÄŸin, Ã§ok etiketli sÄ±nÄ±flandÄ±rma) ile stratifikasyon yapmanÄ±z gerektiÄŸinde durum biraz daha karmaÅŸÄ±k hale gelir.

Bu durumu, **Scikit-multilearn** paketinde bulabilirsiniz ([http://scikit.ml/](http://scikit.ml/)), Ã¶zellikle birden fazla deÄŸiÅŸkenin birleÅŸik oranlarÄ±nÄ± korumak istediÄŸiniz sÄ±rayÄ± kontrol etmenizi saÄŸlayan **IterativeStratification** komutuyla ([http://scikit.ml/api/skmultilearn.model_selection.iterative_stratification.html](http://scikit.ml/api/skmultilearn.model_selection.iterative_stratification.html)). Bu, aÅŸaÄŸÄ±daki makalelerde aÃ§Ä±klanan algoritmayÄ± uygular:

* Sechidis, K., Tsoumakas, G., ve Vlahavas, I. (2011). *On the stratification of multi-label data*. Machine Learning and Knowledge Discovery in Databases, 145-158. [Makale Linki](http://lpis.csd.auth.gr/publications/sechidis-ecmlpkdd-2011.pdf)
* SzymaÅ„ski, P. ve Kajdanowicz, T.; *Proceedings of the First International Workshop on Learning with Imbalanced Domains: Theory and Applications*, PMLR 74:22-35, 2017. [Makale Linki](http://proceedings.mlr.press/v74/szyma%C5%84ski17a.html)

Stratifikasyonu, bir sÄ±nÄ±flandÄ±rma problemi deÄŸil de bir regresyon problemi ile uÄŸraÅŸÄ±yorsanÄ±z da oldukÃ§a faydalÄ± bir ÅŸekilde kullanabilirsiniz. Regresyon problemlerinde stratifikasyon kullanmak, regressor'Ã¼nÃ¼zÃ¼n Ã§apraz doÄŸrulama sÄ±rasÄ±nda hedef (veya prediktÃ¶rler) deÄŸiÅŸkeninin, tÃ¼m Ã¶rneklemdeki daÄŸÄ±lÄ±ma benzer bir daÄŸÄ±lÄ±mda eÄŸitim yapmasÄ±nÄ± saÄŸlar. Bu durumda, `StratifiedKFold`'un dÃ¼zgÃ¼n Ã§alÄ±ÅŸmasÄ± iÃ§in sÃ¼rekli hedefiniz yerine hedefinizin diskretize edilmiÅŸ bir proxyâ€™sini kullanmanÄ±z gerekir.

Bunu baÅŸarmanÄ±n ilk ve en basit yolu, pandas `cut` fonksiyonunu kullanarak hedefinizi 10 veya 20 gibi yeterince bÃ¼yÃ¼k bir bin sayÄ±sÄ±na bÃ¶lmektir:

```python
import pandas as pd
y_proxy = pd.cut(y_train, bins=10, labels=False)
```

KullanÄ±lacak bin sayÄ±sÄ±nÄ± belirlemek iÃ§in, Abhishek Thakur, mevcut Ã¶rnek sayÄ±sÄ±na dayalÄ± olarak **Sturges kuralÄ±nÄ±** kullanmayÄ± tercih eder ve bu sayÄ±yÄ± pandas `cut` fonksiyonuna saÄŸlar (bkz. [https://www.kaggle.com/abhishek/step-1-create-folds](https://www.kaggle.com/abhishek/step-1-create-folds)):

```python
import numpy as np
bins = int(np.floor(1 + np.log2(len(X_train))))
```

Alternatif bir yaklaÅŸÄ±m, eÄŸitim setindeki Ã¶zelliklerin daÄŸÄ±lÄ±mlarÄ±na odaklanmak ve bunlarÄ± yeniden Ã¼retmeye Ã§alÄ±ÅŸmaktÄ±r. Bu, eÄŸitim setinin yalnÄ±zca hedef deÄŸiÅŸkeni ve herhangi bir tanÄ±mlayÄ±cÄ±yÄ± hariÃ§ tutarak, Ã¶zellikler Ã¼zerinde kÃ¼me analizi (denetimsiz bir yaklaÅŸÄ±m) yapÄ±lmasÄ±nÄ± gerektirir. SonrasÄ±nda, tahmin edilen kÃ¼meler strata olarak kullanÄ±labilir. Bunun bir Ã¶rneÄŸini bu Not Defteriâ€™nde gÃ¶rebilirsiniz ([https://www.kaggle.com/lucamassaron/are-you-doing-cross-validation-the-best-way](https://www.kaggle.com/lucamassaron/are-you-doing-cross-validation-the-best-way)), burada ilk olarak **PCA** (temel bileÅŸen analizi) yapÄ±lÄ±r, korelasyonlar kaldÄ±rÄ±lÄ±r ve ardÄ±ndan **k-means** kÃ¼me analizi yapÄ±lÄ±r. KullanÄ±lacak kÃ¼me sayÄ±sÄ±nÄ±, deneysel testler yaparak belirleyebilirsiniz.

---

**Uygunsuz BÃ¶lmeler Ä°Ã§in Ã‡Ã¶zÃ¼mler**

K-katlamalÄ± doÄŸrulamanÄ±n uygun olmayan bÃ¶lmeler verebileceÄŸi durumu tartÄ±ÅŸmaya devam edersek, iÅŸlerin karmaÅŸÄ±klaÅŸtÄ±ÄŸÄ± Ã¼Ã§Ã¼ncÃ¼ senaryo, **baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmayan (non-i.i.d.) verilerle** karÅŸÄ±laÅŸÄ±ldÄ±ÄŸÄ±nda yaÅŸanÄ±r. Bu durum, Ã¶rnekler arasÄ±nda bir gruplaÅŸma olduÄŸunda meydana gelir. BaÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmayan Ã¶rneklerin sorunu, Ã¶zellikler ve hedef deÄŸiÅŸkenin Ã¶rnekler arasÄ±nda birbirleriyle korelasyonlu olmasÄ±dÄ±r (yani, sadece bir Ã¶rneÄŸi biliyorsanÄ±z, tÃ¼m Ã¶rnekleri tahmin etmek daha kolay olur). GerÃ§ekten de, eÄŸer aynÄ± grup eÄŸitim ve test setlerine bÃ¶lÃ¼nÃ¼rse, modeliniz gruplarÄ± ayÄ±rt etmeyi Ã¶ÄŸrenebilir, ancak hedefi Ã¶ÄŸrenmeyebilir ve bu da iyi bir doÄŸrulama skoru elde etmenize ancak liderlik tablosunda Ã§ok kÃ¶tÃ¼ sonuÃ§lar almanÄ±za neden olabilir. Buradaki Ã§Ã¶zÃ¼m, **GroupKFold** kullanmaktÄ±r: bir gruplama deÄŸiÅŸkeni saÄŸlayarak, her grubun ya eÄŸitim setinde ya da doÄŸrulama setinde yer almasÄ±nÄ±, ancak asla her iki set arasÄ±nda bÃ¶lÃ¼nmemesini saÄŸlarsÄ±nÄ±z.

Verilerinizdeki gruplamalarÄ± keÅŸfetmek, verinizin baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmamasÄ±nÄ± saÄŸlayan zor bir gÃ¶rev olabilir. YarÄ±ÅŸma probleminiz tarafÄ±ndan belirtilmedikÃ§e, veriyi araÅŸtÄ±rma (denetimsiz Ã¶ÄŸrenme teknikleri, Ã¶rneÄŸin kÃ¼me analizi kullanarak) ve problemin domainini anlamanÄ±zÄ± gerektirir. Ã–rneÄŸin, veriniz mobil telefon kullanÄ±mÄ±yla ilgiliyse, bazÄ± Ã¶rneklerin aynÄ± kullanÄ±cÄ±ya ait olduÄŸunu, Ã¶zelliklerdeki benzer deÄŸer sÄ±ralamalarÄ±na bakarak fark edebilirsiniz.

Zaman serisi analizi de aynÄ± sorunu sunar; veriler baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmadÄ±ÄŸÄ± iÃ§in, rastgele Ã¶rneklemeyle doÄŸrulama yapamazsÄ±nÄ±z Ã§Ã¼nkÃ¼ farklÄ± zaman dilimlerini karÄ±ÅŸtÄ±rmÄ±ÅŸ olursunuz ve sonraki zaman dilimleri Ã¶nceki zaman dilimlerinin izlerini taÅŸÄ±yabilir (bu, istatistikte *otokorelasyon* olarak adlandÄ±rÄ±lan bir Ã¶zelliktir). Zaman serisi doÄŸrulamasÄ±nÄ±n en temel yaklaÅŸÄ±mÄ±nda, zamanÄ± temel alarak eÄŸitim ve doÄŸrulama setlerini ayÄ±rabilirsiniz, bu, Åekil 6.3'te gÃ¶sterildiÄŸi gibi:

![](im/1053.png)

"DoÄŸrulama yetenekleriniz sÄ±nÄ±rlÄ± olacaktÄ±r, Ã§Ã¼nkÃ¼ doÄŸrulamanÄ±z belirli bir zamana dayanacaktÄ±r. Daha karmaÅŸÄ±k bir yaklaÅŸÄ±m iÃ§in, Scikit-learn paketi (sklearn.model_selection.TimeSeriesSplit) tarafÄ±ndan saÄŸlanan zaman dilimi doÄŸrulamasÄ±nÄ±, TimeSeriesSplit'i kullanabilirsiniz. TimeSeriesSplit, zaman serisinin eÄŸitim ve test kÄ±sÄ±mlarÄ±nÄ±n zaman dilimini ayarlamanÄ±za yardÄ±mcÄ± olabilir.


EÄŸitim zaman dilimi durumunda, TimeSeriesSplit fonksiyonu, eÄŸitim verilerinizi test zaman diliminden Ã¶nceki tÃ¼m geÃ§miÅŸ verileri iÃ§erecek ÅŸekilde ayarlamanÄ±za yardÄ±mcÄ± olabilir veya sabit bir dÃ¶nem geriye bakma sÃ¼resiyle (Ã¶rneÄŸin, her zaman test zaman diliminden Ã¶nceki Ã¼Ã§ ayÄ± eÄŸitim iÃ§in kullanmak gibi) sÄ±nÄ±rlayabilirsiniz.

Åekil 6.4'te, bÃ¼yÃ¼yen bir eÄŸitim seti ve hareketli bir doÄŸrulama seti iÃ§eren zaman tabanlÄ± doÄŸrulama stratejisinin yapÄ±sÄ±nÄ± gÃ¶rebilirsiniz."

![](im/1054.png)

Åekil 6.5'te, eÄŸitim setinin sabit bir geriye bakma sÃ¼resi olduÄŸu durumda stratejinin nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶rebilirsiniz.

![](im/1055.png)

Deneyimlerimize gÃ¶re, sabit bir bakÄ±ÅŸ aralÄ±ÄŸÄ± kullanmak, zaman serisi modellerinin deÄŸerlendirilmesinde daha adil bir sonuÃ§ saÄŸlar Ã§Ã¼nkÃ¼ her zaman aynÄ± eÄŸitim veri seti boyutuna gÃ¼venirsiniz.

Bunun yerine zamanla bÃ¼yÃ¼yen bir eÄŸitim seti boyutu kullanmak, model performansÄ±nÄ±n zaman dilimlerine gÃ¶re etkilerini, modeldeki azalan yanlÄ±lÄ±k ile karÄ±ÅŸtÄ±rmanÄ±za neden olur (Ã§Ã¼nkÃ¼ daha fazla Ã¶rnek, daha az yanlÄ±lÄ±k anlamÄ±na gelir).

Son olarak, TimeSeriesSplit'in, eÄŸitim ve test zamanlarÄ± arasÄ±nda Ã¶nceden tanÄ±mlanmÄ±ÅŸ bir boÅŸluk bÄ±rakacak ÅŸekilde ayarlanabileceÄŸini unutmayÄ±n. Bu, test setinizin belirli bir sÃ¼re sonra (Ã¶rneÄŸin, eÄŸitim verisinden bir ay sonra) olduÄŸunu biliyorsanÄ±z ve modelinizin gelecekte bu kadar ileriye tahmin yapÄ±p yapamayacaÄŸÄ±nÄ± test etmek istiyorsanÄ±z son derece kullanÄ±ÅŸlÄ±dÄ±r.

**Ä°Ã§ Ä°Ã§e Ã‡apraz DoÄŸrulama**

Bu noktada, iÃ§ iÃ§e Ã§apraz doÄŸrulamanÄ±n tanÄ±tÄ±lmasÄ± Ã¶nemlidir. Åimdiye kadar yalnÄ±zca modelleri son performanslarÄ±na gÃ¶re test etmeyi tartÄ±ÅŸtÄ±k, ancak Ã§oÄŸu zaman hiperparametrelerini ayarlarken ara performanslarÄ±nÄ± da test etmeniz gerekir. GerÃ§ekten de, test setinizde model parametrelerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test edemezsiniz ve ardÄ±ndan aynÄ± veriyi nihai performansÄ± deÄŸerlendirmek iÃ§in kullanamazsÄ±nÄ±z. Ã‡Ã¼nkÃ¼ test setinde en iyi Ã§alÄ±ÅŸan parametreleri belirlemiÅŸsinizdir ve aynÄ± test setindeki deÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼nÃ¼z Ã§ok iyimser olacaktÄ±r; farklÄ± bir test setinde, muhtemelen aynÄ± sonucu elde edemezsiniz. Bu durumda, Ã§eÅŸitli modellerin ve hiperparametrelerin performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lan **doÄŸrulama seti** ile nihai model performansÄ±nÄ± tahmin etmek iÃ§in kullanÄ±lan **test seti** arasÄ±ndaki farkÄ± ayÄ±rt etmeniz gerekir.

EÄŸer test-eÄŸitim ayrÄ±mÄ± kullanÄ±yorsanÄ±z, bu, test kÄ±smÄ±nÄ± iki yeni parÃ§aya ayÄ±rarak yapÄ±lÄ±r. YaygÄ±n olarak kullanÄ±lan ayrÄ±m 70/20/10'dur: eÄŸitim, doÄŸrulama ve test, sÄ±rasÄ±yla (ancak farklÄ± bir oran seÃ§ebilirsiniz). EÄŸer Ã§apraz doÄŸrulama kullanÄ±yorsanÄ±z, iÃ§ iÃ§e Ã§apraz doÄŸrulama yapmanÄ±z gerekir; yani baÅŸka bir Ã§apraz doÄŸrulamanÄ±n bÃ¶lÃ¼nmesine dayalÄ± olarak Ã§apraz doÄŸrulama yaparsÄ±nÄ±z. Temelde, her zamanki Ã§apraz doÄŸrulamanÄ±zÄ± Ã§alÄ±ÅŸtÄ±rÄ±rsÄ±nÄ±z, ancak farklÄ± modelleri veya parametreleri deÄŸerlendirmek zorunda olduÄŸunuzda, deÄŸerlendirme ve optimizasyon yapmak iÃ§in eÄŸitim verileriyle birlikte Ã§apraz doÄŸrulama yaparsÄ±nÄ±z.

Åekil 6.6'daki Ã¶rnek, bu iÃ§sel ve dÄ±ÅŸsal Ã§apraz doÄŸrulama yapÄ±sÄ±nÄ± gÃ¶sterir. DÄ±ÅŸsal kÄ±sÄ±mda, deÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼nÃ¼zÃ¼ test etmek iÃ§in kullanÄ±lan veri kÄ±smÄ±nÄ± belirlersiniz. Ä°Ã§sel kÄ±sÄ±mda ise, dÄ±ÅŸsal kÄ±sÄ±mdan gelen eÄŸitim verileriyle, model seÃ§imlerini optimize etmek ve hangi model veya hiperparametre deÄŸerlerinin seÃ§ileceÄŸini belirlemek amacÄ±yla eÄŸitim/doÄŸrulama bÃ¶lÃ¼nmeleri dÃ¼zenlersiniz.

![](im/1056.png)

**Bu yaklaÅŸÄ±mÄ±n avantajÄ±, test ve parametre aramanÄ±zÄ± tamamen gÃ¼venilir hale getirmesidir, ancak bunu yaparken birkaÃ§ problemle karÅŸÄ±laÅŸÄ±rsÄ±nÄ±z:**

* Ã‡apraz doÄŸrulama ile ilk bÃ¶lmeyi yaptÄ±ktan sonra, bir kez daha bÃ¶lme yapmanÄ±z gerektiÄŸi iÃ§in eÄŸitim setiniz azalÄ±r.
* Daha Ã¶nemlisi, Ã§ok sayÄ±da model oluÅŸturmanÄ±z gerekir: EÄŸer iki iÃ§ iÃ§e geÃ§miÅŸ 10 katlÄ± Ã§apraz doÄŸrulama yaparsanÄ±z, 100 model Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekir.

Ã–zellikle son sebepten dolayÄ± bazÄ± Kaggle yarÄ±ÅŸmacÄ±larÄ±, iÃ§ iÃ§e Ã§apraz doÄŸrulamayÄ± gÃ¶z ardÄ± eder ve model/parametre arama ile performans deÄŸerlendirmesi iÃ§in aynÄ± Ã§apraz doÄŸrulamayÄ± kullanmayÄ± ya da nihai deÄŸerlendirme iÃ§in sabit bir test Ã¶rneÄŸi kullanmayÄ± tercih ederler. Deneyimlerimize gÃ¶re bu yaklaÅŸÄ±m da iÅŸe yarayabilir, ancak model performansÄ±nÄ±n aÅŸÄ±rÄ± tahmin edilmesine ve aÅŸÄ±rÄ± uyum (overfitting) durumlarÄ±na yol aÃ§abilir. Bu durum, modelleme sÃ¼recinde kullanÄ±lan katman dÄ±ÅŸÄ± (out-of-fold) tahminler oluÅŸturuyorsanÄ±z daha belirgin hale gelebilir (ki bu konuyu bir sonraki bÃ¶lÃ¼mde ele alacaÄŸÄ±z). Biz her zaman, modellerinizi test etmek iÃ§in en uygun metodolojiyi denemenizi Ã¶neriyoruz. EÄŸer amacÄ±nÄ±z modelinizin performansÄ±nÄ± doÄŸru bir ÅŸekilde tahmin etmek ve tahminlerini baÅŸka modellerde yeniden kullanmaksa, iÃ§ iÃ§e Ã§apraz doÄŸrulama kullanmak, mÃ¼mkÃ¼n olduÄŸunda size daha az aÅŸÄ±rÄ± uyumlu bir Ã§Ã¶zÃ¼m sunabilir ve bazÄ± yarÄ±ÅŸmalarda fark yaratabilir.

**Katman DÄ±ÅŸÄ± Tahminler (OOF) Ãœretme**

Ã‡apraz doÄŸrulamanÄ±n ilginÃ§ bir uygulamasÄ±, deÄŸerlendirme metriÄŸinizin performansÄ±nÄ± tahmin etmenin yanÄ± sÄ±ra test tahminleri ve katman dÄ±ÅŸÄ± tahminler (OOF) Ã¼retmektir. GerÃ§ekten de, eÄŸitim verinizin bazÄ± bÃ¶lÃ¼mleri Ã¼zerinde eÄŸitim yaparken ve geri kalanlar Ã¼zerinde tahminler yaparken ÅŸunlarÄ± yapabilirsiniz:

* **Test seti Ã¼zerinde tahmin yapmak**: TÃ¼m tahminlerin ortalamasÄ±, genellikle tÃ¼m veriler Ã¼zerinde aynÄ± modeli tekrar eÄŸitmekten daha etkili olabilir. Bu, blending ile iliÅŸkili bir topluluk (ensemble) tekniÄŸidir ve 9. BÃ¶lÃ¼m olan *Ensemble: Blending ve Stacking Ã‡Ã¶zÃ¼mleri*'nde ele alÄ±nacaktÄ±r.

* **DoÄŸrulama seti Ã¼zerinde tahmin yapmak**: Sonunda, tÃ¼m eÄŸitim seti iÃ§in tahminleriniz olacak ve bunlarÄ±, orijinal eÄŸitim verileriyle aynÄ± sÄ±rada yeniden sÄ±ralayabilirsiniz. Bu tahminlere genellikle "katman dÄ±ÅŸÄ± (OOF) tahminleri" denir ve oldukÃ§a faydalÄ± olabilirler.

OOF tahminlerinin ilk kullanÄ±mÄ±, performansÄ±nÄ±zÄ± tahmin etmektir Ã§Ã¼nkÃ¼ deÄŸerlendirme metriÄŸinizi doÄŸrudan OOF tahminleri Ã¼zerinde hesaplayabilirsiniz. Elde edilen performans, Ã§apraz doÄŸrulama tahminlerinden (Ã¶rneklemeye dayalÄ±) farklÄ±dÄ±r; aynÄ± olasÄ±lÄ±k Ã¶zelliklerine sahip deÄŸildir, bu yÃ¼zden genelleme performansÄ±nÄ± Ã¶lÃ§mek iÃ§in geÃ§erli bir yol deÄŸildir, ancak modelinizin eÄŸitildiÄŸiniz belirli set Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸi hakkÄ±nda size bilgi verebilir.

Ä°kinci bir kullanÄ±m, tahminleri zemin gerÃ§ek deÄŸerleriyle veya farklÄ± modellerden elde edilen diÄŸer tahminlerle karÅŸÄ±laÅŸtÄ±rarak gÃ¶rselleÅŸtirmek ve bir grafik oluÅŸturmak olabilir. Bu, her bir modelin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve tahminlerinin birbiriyle ne kadar korelasyonlu olduÄŸunu anlamanÄ±za yardÄ±mcÄ± olacaktÄ±r.

Son kullanÄ±m ise meta Ã¶zellikler veya meta tahminciler (meta-predictors) yaratmaktÄ±r. Bu konu, 9. BÃ¶lÃ¼m'de tam olarak ele alÄ±nacaktÄ±r, ancak burada ÅŸunu belirtmek Ã¶nemlidir ki, OOF tahminleri Ã§apraz doÄŸrulamanÄ±n bir yan Ã¼rÃ¼nÃ¼ olup, Ã§alÄ±ÅŸtÄ±klarÄ± iÃ§in kullanÄ±lÄ±r; Ã§Ã¼nkÃ¼ Ã§apraz doÄŸrulama sÄ±rasÄ±nda, modeliniz her zaman eÄŸitim sÄ±rasÄ±nda gÃ¶rmediÄŸi Ã¶rnekler Ã¼zerinde tahmin yapar.

Her OOF tahmininin farklÄ± bir veri seti Ã¼zerinde eÄŸitilmiÅŸ bir model tarafÄ±ndan Ã¼retildiÄŸinden, bu tahminler yanlÄ±lÄ±k iÃ§ermez ve bunlarÄ± aÅŸÄ±rÄ± uyum (overfitting) riskinden korkmadan kullanabilirsiniz (bununla ilgili bazÄ± uyarÄ±lar bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸÄ±lacaktÄ±r).

OOF tahminlerini Ã¼retmenin iki yolu vardÄ±r:

* **Bir prosedÃ¼r kodlayarak** doÄŸrulama tahminlerini bir tahmin vektÃ¶rÃ¼ne kaydetmek ve bunlarÄ± eÄŸitim verilerindeki Ã¶rneklerle aynÄ± indeks konumuna yerleÅŸtirmek.
* **Scikit-learn fonksiyonu olan `cross_val_predict`'i kullanarak**, OOF tahminlerini otomatik olarak Ã¼retmek.

Bu ikinci tekniÄŸi, bu bÃ¶lÃ¼mÃ¼n ilerleyen kÄ±sÄ±mlarÄ±nda *adversarial validation*'Ä± incelediÄŸimizde gÃ¶receÄŸiz.

##### Subsampling *(Alt Ã¶rnekleme)*

**k-katlÄ± Ã§apraz doÄŸrulama dÄ±ÅŸÄ±nda baÅŸka doÄŸrulama stratejileri de vardÄ±r, ancak bunlar aynÄ± genelleme Ã¶zelliklerine sahip deÄŸildir.**

Zaten LOO'yu (Leave-One-Out) tartÄ±ÅŸtÄ±k, bu durum k = n olduÄŸunda (burada n, Ã¶rneklerin sayÄ±sÄ±dÄ±r). DiÄŸer bir seÃ§enek ise **alt Ã¶rnekleme**dir. Alt Ã¶rnekleme, k-katlÄ±ya benzer, ancak sabit katlarÄ±nÄ±z yoktur; ihtiyacÄ±nÄ±z olduÄŸuna dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z kadarÄ±nÄ± kullanÄ±rsÄ±nÄ±z (baÅŸka bir deyiÅŸle, eÄŸitilmiÅŸ bir tahminde bulunursunuz). Verinizi tekrar tekrar alt Ã¶rneklerken, her seferinde Ã¶rneklediÄŸiniz veriyi eÄŸitim verisi olarak kullanÄ±r, geri kalan veriyi ise doÄŸrulama iÃ§in bÄ±rakÄ±rsÄ±nÄ±z. TÃ¼m alt Ã¶rneklerin deÄŸerlendirme metriklerinin ortalamasÄ±nÄ± alarak, modelinizin performanslarÄ± iÃ§in bir doÄŸrulama tahmini elde edersiniz.

k-katlÄ± doÄŸrulama gibi, tÃ¼m Ã¶rneklerinizi sistematik olarak test ettiÄŸiniz iÃ§in, bunlarÄ±n hepsini test etme ÅŸansÄ±nÄ±zÄ±n iyi olabilmesi iÃ§in oldukÃ§a fazla deneme yapmanÄ±z gerekir. AynÄ± sebeple, yeterli sayÄ±da alt Ã¶rnekleme uygulamazsanÄ±z, bazÄ± Ã¶rnekler diÄŸerlerinden daha fazla test edilebilir. Bu tÃ¼r bir doÄŸrulamayÄ±, Scikit-learn'deki **ShuffleSplit** kullanarak yapabilirsiniz.

##### The bootstrap *(Bootstrap yÃ¶ntemi)*

Son olarak, hata daÄŸÄ±lÄ±mÄ±nÄ± sonuÃ§landÄ±rmak iÃ§in istatistiklerde geliÅŸtirilen bootstrap yÃ¶ntemini kullanmayÄ± deneyebilirsiniz; aynÄ± nedenlerden Ã¶tÃ¼rÃ¼, bu yÃ¶ntem performans tahmini iÃ§in de kullanÄ±labilir. Bootstrap, verilerinizi Ã¶rnekleme yaparak, yani yerine koyarak, aynÄ± boyutta bir Ã¶rneklem oluÅŸturmanÄ±zÄ± gerektirir.

Bu noktada bootstrap'Ä± iki farklÄ± ÅŸekilde kullanabilirsiniz:

* Ä°statistiklerde olduÄŸu gibi, bootstrap'Ä± birden Ã§ok kez uygulayarak modelinizi Ã¶rnekler Ã¼zerinde eÄŸitebilir ve eÄŸitim verisi Ã¼zerinde deÄŸerlendirme metriÄŸinizi hesaplayabilirsiniz. Bootstrap'larÄ±n ortalamasÄ±, nihai deÄŸerlendirmenizi saÄŸlar.
* Alternatif olarak, alt Ã¶rnekleme (subsampling) gibi, bootstrap edilmiÅŸ Ã¶rneklemi eÄŸitim iÃ§in kullanabilir ve Ã¶rnekleme yapÄ±lmayan veri kÄ±smÄ±nÄ± test setiniz olarak bÄ±rakabilirsiniz.

Deneyimlerimize gÃ¶re, bootstrap ile eÄŸitim verisi Ã¼zerinde deÄŸerlendirme metriÄŸi hesaplamak, doÄŸrusal modeller iÃ§in modelin katsayÄ±larÄ±nÄ± ve hata daÄŸÄ±lÄ±mlarÄ±nÄ± tahmin etmek amacÄ±yla istatistiklerde sÄ±klÄ±kla kullanÄ±lan bir yÃ¶ntem olmasÄ±na raÄŸmen, makine Ã¶ÄŸreniminde pek faydalÄ± deÄŸildir. Ã‡Ã¼nkÃ¼ birÃ§ok makine Ã¶ÄŸrenimi algoritmasÄ± eÄŸitim verilerine aÅŸÄ±rÄ± uyum saÄŸlama eÄŸilimindedir, bu nedenle eÄŸitim verisi Ã¼zerinde geÃ§erli bir metrik deÄŸerlendirmesi elde edilemez. Bu sebeple, Efron ve Tibshirani (bkz: Efron, B. ve Tibshirani, R. "Cross-validation'da iyileÅŸtirmeler: 632+ bootstrap yÃ¶ntemi". *Journal of the American Statistical Association* 92.438 (1997): 548-560.) final doÄŸrulama metriÄŸi olarak 632+ estimator'Ä±nÄ± Ã¶nermiÅŸlerdir.

BaÅŸlangÄ±Ã§ta, basit bir versiyon olan 632 bootstrapâ€™Ä± Ã¶nermiÅŸlerdir:

$$
Err_{632} = 0.368 * err_{fit} + 0.632 * err_{bootstrap}
$$

Bu formÃ¼lde, deÄŸerlendirme metriÄŸiniz err, errfit eÄŸitim verisi Ã¼zerinde hesapladÄ±ÄŸÄ±nÄ±z metrik ve errbootstrap ise bootstrap edilmiÅŸ veriler Ã¼zerinde hesapladÄ±ÄŸÄ±nÄ±z metriktir. Ancak, aÅŸÄ±rÄ± uyum saÄŸlamÄ±ÅŸ bir eÄŸitim modelinde, errfit sÄ±fÄ±ra yaklaÅŸacak ve bu durumda estimator pek faydalÄ± olmayacaktÄ±r. Bu yÃ¼zden, 632+ bootstrapâ€™Ä±n ikinci versiyonunu geliÅŸtirmiÅŸlerdir:

$$
Err_{.632} + (1 - w) * err_{fit} + w * err_{bootstrap}
$$

Burada w, ÅŸu ÅŸekilde tanÄ±mlanÄ±r:

$$
w = \frac{0.632}{1 - 0.632R}
$$
$$
R = \frac{err_{bootstrap} - err_{fit}}{\gamma - err_{fit}}
$$

Yeni bir parametre olan (\gamma) burada "no-information error rate" (bilgi iÃ§ermeyen hata oranÄ±) olarak tanÄ±mlanÄ±r ve hedefler ile prediktÃ¶rlerin tÃ¼m olasÄ± kombinasyonlarÄ± Ã¼zerinde tahmin modelini deÄŸerlendirerek tahmin edilir. Ancak, (\gamma)â€™yÄ± hesaplamak pratikte imkansÄ±zdÄ±r, bu konuda Scikit-learn geliÅŸtiricilerinin ([https://github.com/scikit-learn/scikit-learn/issues/9153](https://github.com/scikit-learn/scikit-learn/issues/9153)) de tartÄ±ÅŸtÄ±ÄŸÄ± gibi.

Statistiklerdeki klasik bootstrap kullanÄ±mÄ±nÄ±n makine Ã¶ÄŸrenimine uygulanmasÄ±ndaki sÄ±nÄ±rlamalar ve iÅŸlem zorluklarÄ± gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, bunun yerine bootstrap'Ä±n ikinci yÃ¶ntemini kullanmak daha uygundur; bootstrap Ã¶rnekleme yapÄ±lmamÄ±ÅŸ verileri test verisi olarak kullanarak deÄŸerlendirme yapmaktÄ±r.

Bu ÅŸekilde bootstrap, Ã§apraz doÄŸrulamaya (cross-validation) bir alternatif olabilir. Ancak, subsampling gibi, Ã§apraz doÄŸrulama yÃ¶ntemine gÃ¶re daha fazla model inÅŸa edilmesi ve test edilmesi gerekmektedir. Ancak, Ã§apraz doÄŸrulama metrik deÄŸerlendirmesinde yÃ¼ksek varyans gÃ¶steren durumlar ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda, bootstrapâ€™Ä± bu tÃ¼r durumlar iÃ§in daha yoÄŸun test ve yeniden test yaparak model doÄŸrulamanÄ±zda kullanmanÄ±z faydalÄ± olacaktÄ±r.

Daha Ã¶nce bu yÃ¶ntem Scikit-learn'de uygulanmÄ±ÅŸtÄ± ([https://github.com/scikit-learn/scikit-learn/blob/0.16.X/sklearn/cross_validation.py#L613](https://github.com/scikit-learn/scikit-learn/blob/0.16.X/sklearn/cross_validation.py#L613)), ancak sonrasÄ±nda kaldÄ±rÄ±ldÄ±. Ã‡Ã¼nkÃ¼ Scikit-learn'deki bootstrap hem test verilerini hem de eÄŸitim verilerini bootstrap'lamaktaydÄ±. Åimdi bootstrap'Ä± bulamayacaÄŸÄ±nÄ±z iÃ§in, kendi uygulamamÄ±zÄ± kullanabilirsiniz. Ä°ÅŸte Ã¶rnek:

```python
import random
def Bootstrap(n, n_iter=3, random_state=None):
    """
    Yerine koyarak rastgele Ã¶rnekleme yapan Ã§apraz doÄŸrulama jeneratÃ¶rÃ¼.
    Her iterasyonda, [0, n) aralÄ±ÄŸÄ±ndaki indekslerden bir bootstrap Ã¶rneÄŸi oluÅŸturulur
    ve fonksiyon elde edilen Ã¶rneklem ve dÄ±ÅŸarÄ±da kalan tÃ¼m indekslerin listesini dÃ¶ndÃ¼rÃ¼r.
    """
    if random_state:
        random.seed(random_state)
    for j in range(n_iter):
        bs = [random.randint(0, n-1) for i in range(n)]
        out_bs = list({i for i in range(n)} - set(bs))
        yield bs, out_bs
```

SonuÃ§ olarak, bootstrap, Ã§apraz doÄŸrulamaya bir alternatif olarak deÄŸerlendirilebilir. Ä°statistik ve finans alanlarÄ±nda daha yaygÄ±n kullanÄ±lsa da, makine Ã¶ÄŸreniminde altÄ±n kural genellikle k-kat Ã§apraz doÄŸrulama yaklaÅŸÄ±mÄ±nÄ± kullanmaktÄ±r. Ancak, Ã§apraz doÄŸrulama metriÄŸinizde Ã§ok yÃ¼ksek bir varyans varsa ve daha yoÄŸun test ve yeniden test yapmanÄ±z gerekiyorsa, bootstrap'Ä± unutmayÄ±n. Bu tÃ¼r durumlarda bootstrap, modellerinizi doÄŸrulamak iÃ§in Ã§ok daha faydalÄ± olacaktÄ±r.

> **Ryan Chesler**
> 
> [https://www.kaggle.com/ryches](https://www.kaggle.com/ryches)
> 
> 
> 
> BÃ¶lÃ¼mÃ¼n ikinci rÃ¶portajÄ± Ryan Chesler ile yapÄ±lmÄ±ÅŸtÄ±r. Kendisi bir *Discussions Grandmaster* ve *Notebooks ve Competitions Master* unvanlarÄ±na sahiptir. H2O.aiâ€™de veri bilimcisidir ve aynÄ± zamanda Meetup'ta San Diego Makine Ã–ÄŸrenimi grubunun organizatÃ¶rlerinden birisidir ([https://www.meetup.com/San-Diego-Machine-Learning/](https://www.meetup.com/San-Diego-Machine-Learning/)). YanÄ±tlarÄ±nÄ±n birkaÃ§Ä±nda doÄŸrulamanÄ±n Ã¶nemi vurgulanmÄ±ÅŸtÄ±r.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggle'da hangi tekniklerde ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ±nda uzmanlaÅŸtÄ±nÄ±z?**
> 
> Ben genellikle her tÃ¼r yarÄ±ÅŸmaya katÄ±lmaya Ã§alÄ±ÅŸÄ±rÄ±m. Belirli bir alanda uzmanlaÅŸmak yerine farklÄ± problemlerin Ã§Ã¶zÃ¼mÃ¼nÃ¼ denemek daha ilgi Ã§ekici. En ilginÃ§ bulduÄŸum yarÄ±ÅŸmalar, verilerden ve tahmin hatalarÄ±ndan derinlemesine Ã§Ä±karÄ±mlar yapabileceÄŸimiz yarÄ±ÅŸmalardÄ±r. Benim iÃ§in hata analizi en aydÄ±nlatÄ±cÄ± sÃ¼reÃ§lerden birisidir; modelin nerelerde baÅŸarÄ±sÄ±z olduÄŸunu anlamak ve modelin ya da girdi verisi temsilinin zayÄ±f yÃ¶nlerini dÃ¼zeltmek iÃ§in bir yol aramak Ã§ok Ã¶nemlidir.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±dÄ±r?**
> 
> YaklaÅŸÄ±mÄ±m her iki durumda da benzer. BirÃ§ok kiÅŸi, herhangi bir modelleme Ã§abasÄ±na baÅŸlamadan Ã¶nce keÅŸifsel veri analizini tercih eder, ancak ben veriyi modelleme iÃ§in hazÄ±rlama sÃ¼recinin genellikle yeterli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Tipik yaklaÅŸÄ±mÄ±m, veriyi manuel olarak gÃ¶zden geÃ§irmek ve veriyi nasÄ±l en iyi ÅŸekilde modelleyeceÄŸim ve keÅŸfedebileceÄŸim farklÄ± seÃ§enekler hakkÄ±nda bazÄ± Ã¶n kararlar almak. SonrasÄ±nda modelimi kurarÄ±m, performansÄ±nÄ± deÄŸerlendiririm, ardÄ±ndan hatalarÄ± analiz etmeye odaklanÄ±rÄ±m ve modelin nerelerde hata yaptÄ±ÄŸÄ±na dayanarak bir sonraki modelleme adÄ±mlarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼rÃ¼m.
> 
> 
> 
> **Kaggle kariyerinizde size yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?**
> 
> Evet, ÅŸu anki iÅŸimi bu sayede buldum. H2Oâ€™da Ã§alÄ±ÅŸÄ±yorum ve Kaggle baÅŸarÄ±larÄ±na Ã§ok deÄŸer veriyorlar. Ã–nceki iÅŸim de yarÄ±ÅŸmalarda iyi performans sergilememi beÄŸeniyordu.
> 
> 
> 
> **AynÄ± zamanda San Diego'da 2000'den fazla katÄ±lÄ±mcÄ±sÄ± olan bir meet-upâ€™Ä±n organizatÃ¶rÃ¼sÃ¼nÃ¼z. Bu, Kaggle deneyiminizle ilgili mi?**
> 
> Evet, kesinlikle ilgili. Ã‡ok az bilgiyle baÅŸladÄ±m ve ilk baÅŸta pek baÅŸarÄ±lÄ± olamadÄ±ÄŸÄ±m bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ±m. Bir yerel meet-up'a katÄ±ldÄ±m ve burada birlikte Ã§alÄ±ÅŸacak ve Ã¶ÄŸrenecek insanlarla tanÄ±ÅŸtÄ±m. O zamanlar, benden Ã§ok daha yÃ¼ksek beceri seviyesine sahip insanlarla Ã§alÄ±ÅŸtÄ±m ve bir yarÄ±ÅŸmada gerÃ§ekten iyi bir performans gÃ¶sterdik, 4500+ takÄ±m arasÄ±nda 3. olduk.
> 
> Bundan sonra grup eskisi kadar dÃ¼zenli olmadÄ± ve topluluÄŸu devam ettirmek istedim, bu yÃ¼zden kendi grubumu oluÅŸturdum ve kendi etkinliklerimi dÃ¼zenlemeye baÅŸladÄ±m. Bunu yaklaÅŸÄ±k 4 yÄ±ldÄ±r yapÄ±yorum ve ÅŸimdi insanlarÄ±n Ã¶ÄŸretildiÄŸi ve onlara makine Ã¶ÄŸrenimine baÅŸlama konusunda yardÄ±mcÄ± olduÄŸum tarafÄ±nda yer alÄ±yorum. BaÅŸlangÄ±Ã§ta sadece Kaggle yarÄ±ÅŸmalarÄ±na odaklandÄ±k ve takÄ±mlar kurmaya Ã§alÄ±ÅŸtÄ±k, ancak zamanla kitap kulÃ¼pleri ve Ã§eÅŸitli ilgi alanlarÄ±na yÃ¶nelik dersler yapmaya baÅŸladÄ±k. BaÅŸarÄ±larÄ±mdan birÃ§oÄŸunu bu haftalÄ±k zamanÄ± makine Ã¶ÄŸrenimini Ã§alÄ±ÅŸmak ve dÃ¼ÅŸÃ¼nmek iÃ§in ayÄ±rmaya borÃ§luyum.
> 
> 
> 
> **Deneyiminize gÃ¶re, deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle hangi noktalarÄ± gÃ¶zden kaÃ§Ä±rÄ±yor? Ä°lk baÅŸladÄ±ÄŸÄ±nÄ±zda ÅŸimdi bildiÄŸiniz ÅŸeyleri bilseydiniz, neyi daha iyi yapardÄ±nÄ±z?**
> 
> Deneyimlerime gÃ¶re, birÃ§ok kiÅŸi bias-variance (yanlÄ±lÄ±k-Ã§eÅŸitlilik) ticaretini ve aÅŸÄ±rÄ± uyum saÄŸlamayÄ± (overfitting) Ã§ok fazla Ã¶nemseme eÄŸiliminde. Bu, insanlarÄ±n sÃ¼rekli olarak Ã§ok fazla endiÅŸe duyduÄŸu bir ÅŸeydir. Odak noktasÄ±, eÄŸitim ve doÄŸrulama performansÄ±nÄ± yakÄ±nlaÅŸtÄ±rmak deÄŸil, doÄŸrulama performansÄ±nÄ± mÃ¼mkÃ¼n olduÄŸunca iyi hale getirmektir.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda hangi hatalarÄ± yaptÄ±nÄ±z?**
> 
> SÃ¼rekli yaptÄ±ÄŸÄ±m hata yeterince keÅŸif yapmamaktÄ±r. Bazen Ã§ok erken bir ÅŸekilde fikirlerimi gÃ¶z ardÄ± ederim, ancak sonradan bu fikirlerin performansÄ± iyileÅŸtirmek iÃ§in Ã¶nemli olduÄŸunu gÃ¶rÃ¼rÃ¼m. Genellikle ilk denememde rekabetÃ§i bir performansa yakÄ±n bir sonuÃ§ alabiliyorum ama iterasyon yaparak ve yeni ÅŸeyler deneyerek devam etmek farklÄ± bir beceri gerektiriyor ve bunun Ã¼zerinde hala Ã§alÄ±ÅŸÄ±yorum.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in kullanmanÄ±zÄ± Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Ã‡oÄŸunlukla standart araÃ§larÄ± kullanÄ±rÄ±m: XGBoost, LightGBM, Pytorch, TensorFlow, Scikit-learn. Belirli bir araca ya da kÃ¼tÃ¼phaneye Ã¶zel bir baÄŸlÄ±lÄ±ÄŸÄ±m yoktur, sadece probleme uygun olan ne varsa onu kullanÄ±rÄ±m.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken birinin aklÄ±nda tutmasÄ± veya yapmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Bence en Ã¶nemli ÅŸey, iyi bir doÄŸrulama yapmaktÄ±r. Ã‡oÄŸu zaman insanlarÄ±n performanslarÄ±nÄ±n iyileÅŸtiÄŸini dÃ¼ÅŸÃ¼nerek kendilerini kandÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yorum, ancak sonra liderlik panosuna gÃ¶nderdiklerinde bekledikleri gibi gitmediÄŸini fark ediyorlar. Yeni gÃ¶rÃ¼lmemiÅŸ verilerle varsayÄ±mlarÄ± eÅŸleÅŸtirmeyi ve yeni koÅŸullara dayanÄ±klÄ± bir model inÅŸa etmeyi Ã¶ÄŸrenmek Ã¶nemli bir beceridir.

### Tuning your model validation system *(Model doÄŸrulama sistemini ayarlamak)*

Bu noktada, tÃ¼m olasÄ± doÄŸrulama stratejilerinin tam bir genel bakÄ±ÅŸÄ±nÄ± elde etmiÅŸ olmalÄ±sÄ±nÄ±z. Bir yarÄ±ÅŸmaya yaklaÅŸtÄ±ÄŸÄ±nÄ±zda, doÄŸrulama stratejinizi belirler ve uygularsÄ±nÄ±z. ArdÄ±ndan, seÃ§tiÄŸiniz stratejinin doÄŸru olup olmadÄ±ÄŸÄ±nÄ± test edersiniz.
AltÄ±n kural olarak, doÄŸrulama stratejinizi belirlerken, yarÄ±ÅŸmanÄ±n organizatÃ¶rlerinin veriyi eÄŸitim, Ã¶zel ve genel test setlerine ayÄ±rma yaklaÅŸÄ±mÄ±nÄ± taklit etmeye Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z. Kendinize ÅŸu sorularÄ± sorun: Organizatorler veriyi nasÄ±l ayÄ±rmÄ±ÅŸ? Rastgele bir Ã¶rneklem mi almÄ±ÅŸlar? Verinin belirli bir daÄŸÄ±lÄ±mÄ±nÄ± mÄ± korumaya Ã§alÄ±ÅŸmÄ±ÅŸlar? Test setleri gerÃ§ekten eÄŸitim verisi ile aynÄ± daÄŸÄ±lÄ±mdan mÄ± seÃ§ilmiÅŸ?
Bunlar, gerÃ§ek dÃ¼nya projelerinde kendinize sormayacaÄŸÄ±nÄ±z sorulardÄ±r. GerÃ§ek dÃ¼nya projelerinde amacÄ±nÄ±z her koÅŸulda genelleme yapabilmektir, ancak bir yarÄ±ÅŸma Ã§ok daha dar bir odakla, modelin verilen test setinde (Ã¶zellikle Ã¶zel test seti) nasÄ±l performans gÃ¶sterdiÄŸi Ã¼zerine yoÄŸunlaÅŸÄ±r. BaÅŸlangÄ±Ã§tan itibaren bu dÃ¼ÅŸÃ¼nceye odaklanÄ±rsanÄ±z, en iyi doÄŸrulama stratejisini bulma ÅŸansÄ±nÄ±z daha yÃ¼ksek olur ve bu da sizi yarÄ±ÅŸmada daha yÃ¼ksek sÄ±ralara taÅŸÄ±yabilir.
Bu sÃ¼reÃ§ deneme-yanÄ±lma yÃ¶ntemidir, bu yÃ¼zden yarÄ±ÅŸma iÃ§in en iyi doÄŸrulama stratejisini bulmaya Ã§alÄ±ÅŸÄ±rken, doÄŸru yolda olup olmadÄ±ÄŸÄ±nÄ±zÄ± anlamak iÃ§in aÅŸaÄŸÄ±daki iki tutarlÄ±lÄ±k kontrolÃ¼nÃ¼ sistematik olarak uygulayabilirsiniz:

1. **Yerel testlerinizin tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol etmelisiniz**. Yani, tek bir Ã§apraz doÄŸrulama katmanÄ±ndaki hata oranlarÄ±nÄ±n birbirinden Ã§ok farklÄ± olmadÄ±ÄŸÄ±ndan emin olmalÄ±sÄ±nÄ±z veya basit bir eÄŸitim-test bÃ¶lmesi kullandÄ±ÄŸÄ±nÄ±zda, aynÄ± sonuÃ§larÄ±n farklÄ± eÄŸitim-test bÃ¶lmeleri kullanÄ±larak tekrarlanabilir olup olmadÄ±ÄŸÄ±nÄ± kontrol etmelisiniz.
2. **Yerel doÄŸrulama hatanÄ±zÄ±n, genel liderlik panosundaki sonuÃ§larla tutarlÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol etmelisiniz**.
   EÄŸer ilk kontrolÃ¼ geÃ§emediyseniz, sorunun ÅŸu olasÄ±lÄ±klardan biri olabileceÄŸini gÃ¶z Ã¶nÃ¼nde bulundurabilirsiniz:

* EÄŸitim veriniz Ã§ok az
* Veriniz Ã§ok Ã§eÅŸitli ve her bir eÄŸitim parÃ§asÄ± diÄŸerlerinden Ã§ok farklÄ± (Ã¶rneÄŸin, Ã§ok yÃ¼ksek kardinaliteye sahip Ã¶zellikleriniz varsa, yani Ã§ok fazla seviyeye sahip Ã¶zellikler â€“ zip kodlarÄ± gibi â€“ ya da Ã§ok deÄŸiÅŸken dÄ±ÅŸ deÄŸerleriniz varsa).
  Her iki durumda da, modelinizin eÄŸitimi iÃ§in veriniz yetersizdir.
  Veri Ã§ok Ã§eÅŸitli gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ durumlarda bile, Ã¶ÄŸrenme eÄŸrilerini Ã§izmek, modelinizin daha fazla veriye ihtiyaÃ§ duyduÄŸunu size gÃ¶sterecektir.
  Bu durumda, daha basit bir algoritmaya geÃ§menin deÄŸerlendirme metriÄŸi Ã¼zerinde iÅŸe yaradÄ±ÄŸÄ±nÄ± keÅŸfetmediÄŸiniz sÃ¼rece (bu durumda varyansÄ± bias ile takas yaparak modelinizin performansÄ±nÄ± kÃ¶tÃ¼leÅŸtirebilirsiniz, ancak her zaman bÃ¶yle olmayabilir), en iyi seÃ§eneÄŸiniz kapsamlÄ± bir doÄŸrulama yaklaÅŸÄ±mÄ± kullanmak olacaktÄ±r. Bunu ÅŸu ÅŸekilde uygulayabilirsiniz:
* Daha bÃ¼yÃ¼k k deÄŸerleri kullanmak (bu, k = n olduÄŸunda LOO'ya yaklaÅŸÄ±r). DoÄŸrulama sonuÃ§larÄ±nÄ±z artÄ±k modelinizin gÃ¶rÃ¼lmemiÅŸ veriler Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸinden Ã§ok, daha bÃ¼yÃ¼k eÄŸitim parÃ§alarÄ± kullanarak daha kararlÄ± deÄŸerlendirmeler yapmanÄ±z konusunda olacaktÄ±r.
* FarklÄ± rastgele tohum baÅŸlangÄ±Ã§larÄ±yla seÃ§ilen farklÄ± veri bÃ¶lmeleri temelinde, birden fazla k-katlamalÄ± doÄŸrulamanÄ±n sonuÃ§larÄ±nÄ± ortalamak.
* TekrarlÄ± bootstrap kullanmak.
  UnutmayÄ±n ki, yerel doÄŸrulama sonuÃ§larÄ±nÄ±zÄ±n kararsÄ±z olmasÄ± durumunda, yalnÄ±zca siz bu sorunu yaÅŸamÄ±yorsunuzdur. Genellikle, bu sorun verinin kaynaÄŸÄ± ve Ã¶zelliklerinden dolayÄ± yaygÄ±n bir problemdir. TartÄ±ÅŸma forumlarÄ±na kulak vererek olasÄ± Ã§Ã¶zÃ¼mler hakkÄ±nda ipuÃ§larÄ± alabilirsiniz. Ã–rneÄŸin, yÃ¼ksek kardinaliteli Ã¶zellikler iÃ§in hedef kodlama (target encoding) iyi bir Ã§Ã¶zÃ¼m olabilir; aykÄ±rÄ± deÄŸerlerle baÅŸa Ã§Ä±kmak iÃ§in ise stratifikasyon yardÄ±mcÄ± olabilir; ve benzeri.
  Ä°lk kontrolÃ¼ geÃ§ip ikinciyi geÃ§emediyseniz, yerel Ã§apraz doÄŸrulamanÄ±z tutarlÄ± ancak liderlik panosundaki sonuÃ§larla tutarsÄ±zsa, bu problemi fark edebilmeniz iÃ§in tÃ¼m deneylerinizi, doÄŸrulama test tÃ¼rlerini, kullanÄ±lan rastgele tohumlarÄ± ve gÃ¶nderilen tahminlerin liderlik panosundaki sonuÃ§larÄ±nÄ± dikkatlice not etmeniz gerekir. Bu ÅŸekilde, basit bir daÄŸÄ±lÄ±m grafiÄŸi Ã§izebilir ve doÄŸrusal regresyon uyumlamayÄ± ya da daha basit olarak, yerel sonuÃ§larÄ±nÄ±z ile iliÅŸkili genel liderlik panosu skorlarÄ± arasÄ±nda bir korelasyon hesaplayabilirsiniz.
  TÃ¼m bunlarÄ± not almak ve analiz etmek zaman ve sabÄ±r gerektirir, ancak yarÄ±ÅŸmadaki performanslarÄ±nÄ±zÄ±n en Ã¶nemli meta-analizini yapmak, sizi baÅŸarÄ±ya taÅŸÄ±yacak en Ã¶nemli adÄ±mdÄ±r.
  EÄŸer uyuÅŸmazlÄ±k, doÄŸrulama skorunuzun sistematik olarak liderlik panosu skorlarÄ±ndan daha dÃ¼ÅŸÃ¼k ya da daha yÃ¼ksek olmasÄ± nedeniyle ortaya Ã§Ä±kÄ±yorsa, doÄŸrulama stratejinizde eksik bir ÅŸeyler olduÄŸuna dair gÃ¼Ã§lÃ¼ bir sinyal alÄ±yorsunuz demektir. Ancak bu sorun, modelinizi geliÅŸtirmenizi engellemez. Modeliniz Ã¼zerinde Ã§alÄ±ÅŸmaya devam edebilir ve ilerlemelerinizi liderlik panosunda gÃ¶rmek bekleyebilirsiniz, ancak bu her zaman orantÄ±lÄ± olmayacaktÄ±r. Ancak sistematik farklar her zaman bir kÄ±rmÄ±zÄ± bayrak anlamÄ±na gelir, bu da sizin yaptÄ±ÄŸÄ±nÄ±zla organizatÃ¶rlerin modelinizi test etme yaklaÅŸÄ±mÄ± arasÄ±nda bir fark olduÄŸunu gÃ¶sterir.

Ã‡ok daha kÃ¶tÃ¼ bir senaryo, yerel Ã§apraz doÄŸrulama skorlarÄ±nÄ±zÄ±n, liderlik panosundaki geri bildirimle hiÃ§biriyle korelasyon gÃ¶stermediÄŸi durumdur. Bu gerÃ§ekten bir kÄ±rmÄ±zÄ± bayraktÄ±r. BÃ¶yle bir durumla karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zÄ± fark ettiÄŸinizde, derhal bir dizi test ve araÅŸtÄ±rma yaparak bunun nedenini anlamaya Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z, Ã§Ã¼nkÃ¼ bu durum, final sÄ±ralamanÄ±z iÃ§in ciddi bir tehdit oluÅŸturur. BÃ¶yle bir senaryoda birkaÃ§ olasÄ±lÄ±k vardÄ±r:

* Test setinin eÄŸitim setinden farklÄ± bir daÄŸÄ±lÄ±mdan seÃ§ildiÄŸini fark edebilirsiniz. Bu durumda, "adversarial validation" testi (bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸacaÄŸÄ±z) size bu konuda aydÄ±nlatÄ±cÄ± olabilir.
* Veriler baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mdan (i.i.d.) deÄŸil, ancak bu durum aÃ§Ä±kÃ§a belirtilmemiÅŸtir. Ã–rneÄŸin, The Nature Conservancy Fisheries Monitoring yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring)), eÄŸitim setindeki gÃ¶rÃ¼ntÃ¼ler benzer durumlardan (balÄ±kÃ§Ä± tekneleri) alÄ±nmÄ±ÅŸtÄ±. Modelin, gÃ¶rÃ¼ntÃ¼lerin baÄŸlamÄ±nÄ± Ã¶ÄŸrenmek yerine hedefi tanÄ±mamayÄ± engellemek iÃ§in bu gÃ¶rÃ¼ntÃ¼leri nasÄ±l dÃ¼zenlemeniz gerektiÄŸini kendiniz keÅŸfetmeniz gerekiyordu (Ã¶rneÄŸin, Anokas'Ä±n bu Ã§alÄ±ÅŸmasÄ±na bakabilirsiniz: [https://www.kaggle.com/anokas/finding-boatids](https://www.kaggle.com/anokas/finding-boatids)).
* Ã–zelliklerin Ã§ok deÄŸiÅŸkenli daÄŸÄ±lÄ±mÄ± aynÄ± olabilir, ancak bazÄ± gruplar test setinde farklÄ± ÅŸekilde daÄŸÄ±labilir. FarklÄ±lÄ±klarÄ± keÅŸfedebilirseniz, eÄŸitim setinizi ve doÄŸrulamanÄ±zÄ± buna gÃ¶re ayarlayarak avantaj saÄŸlayabilirsiniz. Bunun Ã¼zerinde Ã§alÄ±ÅŸabilmek iÃ§in, genel liderlik panosuna bakmanÄ±z gerekecek.
* Test verisi kaymÄ±ÅŸ veya trendlenmiÅŸ olabilir; bu, genellikle zaman serisi tahminlerinde gÃ¶rÃ¼len bir durumdur. Yine, liderlik panosuna bakarak bazÄ± olasÄ± post-processing iÅŸlemleri hakkÄ±nda fikir sahibi olabilirsiniz. Ã–rneÄŸin, tahminlerinize bir Ã§arpan uygulamak, test verisindeki azalan veya artan bir trendi taklit edebilir.

Daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, liderlik panosunu incelemek, Ã¶zellikle kamu test setinin bileÅŸimi hakkÄ±nda ipuÃ§larÄ± elde etmek amacÄ±yla Ã¶zel olarak tasarlanmÄ±ÅŸ gÃ¶nderimler yapma eylemidir. Bu, Ã¶zel test seti kamu test setine benziyorsa Ã¶zellikle iyi Ã§alÄ±ÅŸÄ±r. Ä°nceleme iÃ§in genel bir yÃ¶ntem yoktur, bu yÃ¼zden her yarÄ±ÅŸma ve problem tÃ¼rÃ¼ne gÃ¶re bir inceleme metodolojisi geliÅŸtirmeniz gerekir.

Ã–rneÄŸin, *Climbing the Kaggle Leaderboard by Exploiting the Log-Loss Oracle* ([https://export.arxiv.org/pdf/1707.01825](https://export.arxiv.org/pdf/1707.01825)) adlÄ± makalede, Jacob, eÄŸitim verisini bile indirmeden bir yarÄ±ÅŸmada nasÄ±l dÃ¶rdÃ¼ncÃ¼ sÄ±raya Ã§Ä±kÄ±labileceÄŸini aÃ§Ä±klar.

Regresyon problemleriyle ilgili olarak, Kaggle tarafÄ±ndan dÃ¼zenlenen *30 Days of ML* etkinliÄŸinde, Hung Khoi, liderlik panosunu incelemenin, eÄŸitim seti ile kamu test verisi arasÄ±ndaki hedef sÃ¼tununun ortalama ve standart sapma farklarÄ±nÄ± anlamasÄ±na nasÄ±l yardÄ±mcÄ± olduÄŸunu aÃ§Ä±klamÄ±ÅŸtÄ±r (bkz: [https://www.kaggle.com/c/30-days-of-ml/discussion/269541](https://www.kaggle.com/c/30-days-of-ml/discussion/269541)).

AÅŸaÄŸÄ±daki denklemi kullandÄ±:

$$
RMSE^2 = MSE = variance + (mean - guessed\_value)^2
$$

Esasen, test hedefinin ortalamasÄ±nÄ± ve varyansÄ±nÄ± Ã§Ã¶zmek iÃ§in yalnÄ±zca iki sunum gereklidir, Ã§Ã¼nkÃ¼ iki bilinmeyen terim vardÄ±r â€“ varyans ve ortalama.

AyrÄ±ca, liderlik panosundan bilgi sorgulama hakkÄ±nda bazÄ± diÄŸer fikirleri Chris Deotte'den ([https://www.kaggle.com/cdeotte](https://www.kaggle.com/cdeotte)) ÅŸu gÃ¶nderisinde bulabilirsiniz: [https://www.kaggle.com/cdeotte/lb-probing-strategies-0-890-2nd-place](https://www.kaggle.com/cdeotte/lb-probing-strategies-0-890-2nd-place), bu gÃ¶nderi "Don't Overfit II" yarÄ±ÅŸmasÄ±yla ilgilidir ([https://www.kaggle.com/c/dont-overfit-ii](https://www.kaggle.com/c/dont-overfit-ii)).

> Liderlik panosundan bilgi sorgulamanÄ±n Ã§ift taraflÄ± bir kÄ±lÄ±Ã§ olduÄŸunu hissetmek isterseniz, Zahar Chikishevâ€™in LANL Deprem Tahmin YarÄ±ÅŸmasÄ±â€™ndan nasÄ±l bilgi sorguladÄ±ÄŸÄ±nÄ± okuyabilirsiniz, sonuÃ§ olarak halkada birinci olduÄŸu halde Ã¶zel liderlik panosunda 87. sÄ±rada yer aldÄ±: [https://towardsdatascience.com/how-to-lb-probe-on-kaggle-c0aa21458bfe](https://towardsdatascience.com/how-to-lb-probe-on-kaggle-c0aa21458bfe)

### Using adversarial validation *(ZÄ±t doÄŸrulama yÃ¶ntemini kullanmak)*

Ã‡apraz doÄŸrulama, modelinizin, eÄŸitim verisinden aynÄ± daÄŸÄ±lÄ±mdan gelen, gÃ¶rÃ¼lmemiÅŸ veri setlerine ne kadar iyi genelleme yapabileceÄŸini test etmenize olanak tanÄ±r. UmarÄ±m, bir Kaggle yarÄ±ÅŸmasÄ±nda, modelinizin hem kamu (public) hem de Ã¶zel (private) veri setlerinde tahmin yapmasÄ± istendiÄŸi iÃ§in, bu test verisinin eÄŸitim verisiyle aynÄ± daÄŸÄ±lÄ±mdan geldiÄŸini varsayabilirsiniz. GerÃ§ek hayatta, bu her zaman bÃ¶yle deÄŸildir.

EÄŸer test verisine aÅŸÄ±rÄ± uyum saÄŸlamazsanÄ±z, Ã§Ã¼nkÃ¼ kararÄ±nÄ±zÄ± yalnÄ±zca liderlik panosu sonuÃ§larÄ±na dayandÄ±rmak yerine Ã§apraz doÄŸrulamanÄ±zÄ± da gÃ¶z Ã¶nÃ¼nde bulundurduysanÄ±z, yine de sonuÃ§lardan ÅŸaÅŸÄ±rabilirsiniz. Bu, test seti eÄŸitim setinden biraz farklÄ± olduÄŸunda gerÃ§ekleÅŸebilir. AslÄ±nda, hedef olasÄ±lÄ±ÄŸÄ± ve bunun daÄŸÄ±lÄ±mÄ± ile Ã¶ngÃ¶rÃ¼cÃ¼ deÄŸiÅŸkenlerin buna nasÄ±l baÄŸlandÄ±ÄŸÄ±, modelinizi eÄŸitim sÄ±rasÄ±nda, test verisi farklÄ± olduÄŸunda yerine getiremeyeceÄŸi belirli beklentiler hakkÄ±nda bilgilendirir.

Bu nedenle, yalnÄ±zca liderlik panosuna aÅŸÄ±rÄ± uyum saÄŸlamaktan kaÃ§Ä±nmak yeterli deÄŸildir, ilk baÅŸta test verinizin eÄŸitim verisiyle karÅŸÄ±laÅŸtÄ±rÄ±labilir olup olmadÄ±ÄŸÄ±nÄ± araÅŸtÄ±rmak da Ã¶nemlidir. EÄŸer farklÄ±larsa, bu daÄŸÄ±lÄ±m farklarÄ±nÄ± test verisi Ã¼zerinde hafifletme ÅŸansÄ±nÄ±z olup olmadÄ±ÄŸÄ±nÄ± bulmanÄ±z ve bu test seti Ã¼zerinde iyi performans gÃ¶steren bir model inÅŸa etmeniz gerekecektir.

Adversarial doÄŸrulama, eÄŸitim ve test verisi arasÄ±ndaki farkÄ± tahmin etmek amacÄ±yla geliÅŸtirilmiÅŸ bir tekniktir. Bu teknik, Kaggle katÄ±lÄ±mcÄ±larÄ± arasÄ±nda uzun zamandÄ±r sÃ¶ylenti olarak dolaÅŸÄ±yor ve takÄ±m takÄ±m aktarÄ±lmaya Ã§alÄ±ÅŸÄ±lmÄ±ÅŸtÄ±, ta ki Zygmunt ZajÄ…c'Ä±n FastML blogunda ([https://www.kaggle.com/zygmunt](https://www.kaggle.com/zygmunt)) paylaÅŸtÄ±ÄŸÄ± bir yazÄ± sayesinde halka aÃ§Ä±k hale gelene kadar.

Fikir basittir: EÄŸitim verinizi alÄ±n, hedefi (target) Ã§Ä±karÄ±n, eÄŸitim verinizi ve test verinizi birleÅŸtirin ve yeni bir ikili sÄ±nÄ±flandÄ±rma hedefi oluÅŸturun. Burada pozitif etiket test verisine atanÄ±r. Bu noktada, bir makine Ã¶ÄŸrenmesi sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve ROC-AUC deÄŸerlendirme metriÄŸiyle deÄŸerlendirin (bu metriÄŸi Ã¶nceki "YarÄ±ÅŸma GÃ¶revleri ve Metreleri DetaylandÄ±rma" bÃ¶lÃ¼mÃ¼nde ele almÄ±ÅŸtÄ±k).

EÄŸer ROC-AUC deÄŸeri 0.5 civarÄ±ndaysa, bu, eÄŸitim ve test verisinin kolayca ayÄ±rt edilemediÄŸi ve muhtemelen aynÄ± daÄŸÄ±lÄ±mdan geldiÄŸi anlamÄ±na gelir. ROC-AUC deÄŸerleri 0.5'ten yÃ¼ksek ve 1.0'a yakÄ±nsa, algoritmanÄ±n eÄŸitim setinden neyin olduÄŸunu ve test setinden neyin olduÄŸunu anlamasÄ±nÄ±n Ã§ok kolay olduÄŸunu gÃ¶sterir; bÃ¶yle bir durumda, test setine kolayca genelleme yapmayÄ± beklemeyin Ã§Ã¼nkÃ¼ bu aÃ§Ä±kÃ§a farklÄ± bir daÄŸÄ±lÄ±mdan gelmektedir.

> Sberbank Rus Konut PiyasasÄ± yarÄ±ÅŸmasÄ± iÃ§in yazÄ±lmÄ±ÅŸ bir Ã¶rnek Notebook'u burada bulabilirsiniz: [Adversarial DoÄŸrulama ve DiÄŸer Korkutucu Terimler](https://www.kaggle.com/konradb/adversarial-validation-and-other-scary-terms), bu, adversarial doÄŸrulama ve yarÄ±ÅŸmalarda nasÄ±l kullanÄ±ldÄ±ÄŸÄ± hakkÄ±nda pratik bir Ã¶rnek sunmaktadÄ±r.

Verileriniz farklÄ± tÃ¼rlerde olabilir (sayÄ±sal veya metin etiketleri gibi) ve eksik veriler olabilir, bu nedenle sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce bazÄ± veri iÅŸleme adÄ±mlarÄ±na ihtiyacÄ±nÄ±z olacak. Ã–nerimiz, rastgele orman sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± kullanmanÄ±zdÄ±r Ã§Ã¼nkÃ¼:

* GerÃ§ek olasÄ±lÄ±klarÄ± vermez, ancak sonuÃ§larÄ± sadece sÄ±ralÄ± olarak sunar, bu da ROC-AUC skoru iÃ§in mÃ¼kemmel bir uyum saÄŸlar.
* Rastgele orman, karar aÄŸaÃ§larÄ±na dayalÄ± esnek bir algoritmadÄ±r ve Ã¶zellik seÃ§imini kendisi yapabilir, farklÄ± tÃ¼rdeki Ã¶zelliklerle Ã§alÄ±ÅŸabilir ve tÃ¼m verileri sayÄ±sal hale getirebilir. AyrÄ±ca, aÅŸÄ±rÄ± uyuma karÅŸÄ± oldukÃ§a dayanÄ±klÄ±dÄ±r ve hiperparametreleri Ã§ok fazla dÃ¼ÅŸÃ¼nmek zorunda kalmazsÄ±nÄ±z.
* Verinin Ã§oÄŸu zaman iÅŸlenmesine gerek yoktur, Ã§Ã¼nkÃ¼ aÄŸaÃ§ tabanlÄ±dÄ±r. Eksik veriler iÃ§in, deÄŸerleri -999 gibi olasÄ±lÄ±ÄŸÄ± dÃ¼ÅŸÃ¼k bir negatif deÄŸerle deÄŸiÅŸtirebilirsiniz ve metin deÄŸiÅŸkenlerini sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rebilirsiniz (Ã¶rneÄŸin, Scikit-learn etiket kodlayÄ±cÄ±sÄ±, `sklearn.preprocessing.LabelEncoder` kullanarak). Bu Ã§Ã¶zÃ¼m, one-hot encoding'den daha dÃ¼ÅŸÃ¼k performans gÃ¶sterebilir ancak Ã§ok hÄ±zlÄ±dÄ±r ve problem iÃ§in yeterince iyi Ã§alÄ±ÅŸacaktÄ±r.

SÄ±nÄ±flandÄ±rÄ±cÄ± kullanmak, test setinizi adversary doÄŸrulama yoluyla deÄŸerlendirmek iÃ§in en doÄŸrudan yol olsa da, baÅŸka yaklaÅŸÄ±mlar da kullanabilirsiniz. Bir yaklaÅŸÄ±m, hem eÄŸitim hem de test verilerini daha dÃ¼ÅŸÃ¼k boyutlu bir alana yerleÅŸtirmektir. Bu, NanoMathias tarafÄ±ndan yazÄ±lmÄ±ÅŸ ÅŸu yazÄ±da ([https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data](https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data)) ele alÄ±nmaktadÄ±r. Daha fazla ayar yapmayÄ± gerektirse de, t-SNE ve PCA'ya dayalÄ± bir yaklaÅŸÄ±m, veriyi grafiksel olarak temsil etmenin yanÄ± sÄ±ra anlaÅŸÄ±lmasÄ± kolay ve cazip bir ÅŸekilde sunulabilir. Ã‡Ã¼nkÃ¼ beyinlerimiz sayÄ±sal verilere kÄ±yasla gÃ¶rsel temsil edilen desenleri fark etmekte daha beceriklidir (gÃ¶rsel yeteneklerimiz Ã¼zerine detaylÄ± bir tartÄ±ÅŸma iÃ§in ÅŸu makaleye bakabilirsiniz: [https://onlinelibrary.wiley.com/doi/full/10.1002/qua.24480](https://onlinelibrary.wiley.com/doi/full/10.1002/qua.24480)).

> PCA ve t-SNE, verinizin boyutunu dÃ¼ÅŸÃ¼rmek ve gÃ¶rselleÅŸtirmek iÃ§in kullanÄ±labilecek tek araÃ§lar deÄŸildir. UMAP ([https://github.com/lmcinnes/umap](https://github.com/lmcinnes/umap)), genellikle daha hÄ±zlÄ± bir dÃ¼ÅŸÃ¼k boyutlu Ã§Ã¶zÃ¼m sunar ve net ve ayrÄ±lmÄ±ÅŸ veri kÃ¼meleri saÄŸlar. Varyasyonel oto-encoders (VAE), doÄŸrusal olmayan boyut indirgeme iÅŸlemi yapabilir ve PCA'dan daha faydalÄ± bir temsil sunabilir; ancak daha karmaÅŸÄ±k bir kurulum ve ayar gerektirir.

#### Example implementation *(Uygulama Ã¶rneÄŸi)*

Zygmunt'un orijinal makalesinde ve baÄŸlantÄ± verdiÄŸimiz Not Defteri'nde, adversarial doÄŸrulama (adversarial validation) Ã¶rneklerine rastlayabilirsiniz. Ancak sizin iÃ§in, Playground yarÄ±ÅŸmasÄ± olan **Tabular Playground Series â€“ Jan 2021** ([https://www.kaggle.com/c/tabular-playground-series-jan-2021](https://www.kaggle.com/c/tabular-playground-series-jan-2021)) verisi Ã¼zerinden yeni bir Ã¶rnek oluÅŸturduk.

BaÅŸlamak iÃ§in bazÄ± Python paketlerini iÃ§eri aktararak ve yarÄ±ÅŸmanÄ±n eÄŸitim ve test verilerini alarak iÅŸlemlere baÅŸlÄ±yoruz:

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import roc_auc_score

train = pd.read_csv("../input/tabular-playground-series-jan-2021/train.csv")
test = pd.read_csv("../input/tabular-playground-series-jan-2021/test.csv")
```

Veri hazÄ±rlÄ±ÄŸÄ± oldukÃ§a kÄ±sa ve net. TÃ¼m Ã¶zellikler sayÄ±sal olduÄŸundan, etiketleme yapmanÄ±za gerek yok, ancak eksik deÄŸerleri (-1 genellikle uygun olur) doldurmanÄ±z gerekiyor. AyrÄ±ca, hedef sÃ¼tununu ve kimlik sÃ¼tunlarÄ±nÄ± (id) dÃ¼ÅŸÃ¼rmeniz gerekli. Kimlik sÃ¼tunu ardÄ±ÅŸÄ±k bir sayÄ±ya sahipse, adversarial doÄŸrulama sonucu yÃ¼ksek bir ROC-AUC skoru elde edebilirsiniz:

```python
train = train.fillna(-1).drop(["id", "target"], axis=1)
test = test.fillna(-1).drop(["id"], axis=1)

X = train.append(test)
y = [0] * len(train) + [1] * len(test)
```

Bu noktada, sadece verilerinizi kullanarak RandomForestClassifier ile tahminler Ã¼retmeniz gerekiyor. Bunun iÃ§in **cross_val_predict** fonksiyonunu kullanÄ±yoruz. Bu fonksiyon otomatik olarak bir Ã§apraz doÄŸrulama ÅŸemasÄ± oluÅŸturur ve tahminleri doÄŸrulama katmanÄ±nda depolar:

```python
model = RandomForestClassifier()
cv_preds = cross_val_predict(model, X, y, cv=5, n_jobs=-1, method='predict_proba')
```

SonuÃ§ olarak, doÄŸrulama setinde modelin Ã¼zerinde overfitting yapmadÄ±ÄŸÄ± (Ã§Ã¼nkÃ¼ eÄŸitilen veriye gÃ¶re tahmin yapÄ±lmamÄ±ÅŸtÄ±r) ve hata tahmini iÃ§in kullanÄ±labilen, tarafsÄ±z tahminler elde edersiniz. **cross_val_predict**, modelinizi fit etmediÄŸi iÃ§in, modelinize ait herhangi bir bilgi (Ã¶rneÄŸin, hangi Ã¶zelliklerin Ã¶nemli olduÄŸu gibi) almazsÄ±nÄ±z. BÃ¶yle bir bilgiye ihtiyacÄ±nÄ±z varsa, Ã¶nce modelinizi fit etmeniz gerekir:

```python
model.fit(X, y)
```

Son olarak, tahminler iÃ§in ROC-AUC skorunu sorgulayabilirsiniz:

```python
print(roc_auc_score(y_true=y, y_score=cv_preds[:, 1]))
```

YaklaÅŸÄ±k 0.49-0.50 arasÄ±nda bir deÄŸer elde etmeniz gerekir (cross_val_predict deterministik deÄŸildir, ancak sabit bir random_seed kullanÄ±rsanÄ±z sabit sonuÃ§lar alabilirsiniz). Bu, eÄŸitim verisi ile test verisinin kolayca ayÄ±rt edilemediÄŸi anlamÄ±na gelir. DolayÄ±sÄ±yla, her iki veri de aynÄ± daÄŸÄ±lÄ±mdan gelmektedir.

#### Handling different distributions of training and test data *(EÄŸitim ve test verilerindeki farklÄ± daÄŸÄ±lÄ±mlarla baÅŸa Ã§Ä±kma)*

ROC-AUC skoru 0.8 veya daha fazla olan bir test seti, eÄŸitim verilerinizden Ã§ok farklÄ± ve ayÄ±rt edilebilir olduÄŸunu gÃ¶sterir. Bu tÃ¼r bir durumda, birkaÃ§ strateji uygulayarak bu farkÄ± yÃ¶netebilirsiniz:

**BaskÄ±lama (Suppression):**

Bu yÃ¶ntemle, test setindeki en Ã¶nemli deÄŸiÅŸkenleri Ã§Ä±kararak eÄŸitim verisi ile test verisinin daÄŸÄ±lÄ±mlarÄ±nÄ± eÅŸitlemeyi amaÃ§larsÄ±nÄ±z. Bunu yapmak iÃ§in, modelinizi tÃ¼m verilerle eÄŸitir ve ardÄ±ndan **feature_importances_** gibi araÃ§lar ile deÄŸiÅŸkenlerin Ã¶nem derecelerini Ã¶lÃ§ersiniz. Daha sonra, modelinizi tekrar eÄŸitirken, en Ã¶nemli deÄŸiÅŸkeni veriden Ã§Ä±karÄ±rsÄ±nÄ±z. Bu iÅŸlemi, ROC-AUC skorunuz yaklaÅŸÄ±k 0.5'lere dÃ¼ÅŸene kadar tekrarlarsÄ±nÄ±z.

Ancak bu yÃ¶ntemle karÅŸÄ±laÅŸÄ±lan ana sorun, Ã¶nemli deÄŸiÅŸkenlerin Ã§oÄŸunu veriden Ã§Ä±karmak zorunda kalmanÄ±zdÄ±r. Bu durumda, modelinizin tahmin performansÄ± Ã¶nemli Ã¶lÃ§Ã¼de dÃ¼ÅŸer Ã§Ã¼nkÃ¼ model, bilgilendirici Ã¶zelliklerden yoksun olacaktÄ±r.

**Test Setine En Benzer Ã–rneklerle EÄŸitim Yapmak:**

Bu yÃ¶ntemde, odak noktanÄ±z deÄŸiÅŸkenlerde deÄŸil, **eÄŸitim Ã¶rnekleriniz** Ã¼zerindedir. EÄŸitim setinden yalnÄ±zca, test daÄŸÄ±lÄ±mÄ±na en yakÄ±n olan Ã¶rnekleri seÃ§ersiniz. Bu ÅŸekilde, eÄŸitilen modeliniz yalnÄ±zca test setiyle uyumlu olur (ancak baÅŸka bir test verisi Ã¼zerinde genellenemez). Ancak bu yaklaÅŸÄ±mda dikkat edilmesi gereken bir sÄ±nÄ±rlama vardÄ±r: EÄŸitim setindeki Ã¶rneklerin sayÄ±sÄ±nÄ± azaltÄ±rsÄ±nÄ±z ve test daÄŸÄ±lÄ±mÄ±na benzer olan Ã¶rnek sayÄ±sÄ± dÃ¼ÅŸÃ¼kse, modeliniz Ã§ok daha dar bir veri kÃ¼mesiyle eÄŸitilmiÅŸ olur. Bu da, eÄŸitim Ã¶rneklerinin yetersizliÄŸi nedeniyle modelin oldukÃ§a **Ã¶nyargÄ±lÄ±** olmasÄ±na neden olabilir.

Ã–rneÄŸin, eÄŸitim verilerinde yalnÄ±zca test setindeki adverser (anormal) tahminlerin **0.5'ten bÃ¼yÃ¼k** olanlarÄ±nÄ± seÃ§erseniz, eÄŸitim verinizin boyutu oldukÃ§a kÃ¼Ã§Ã¼lÃ¼r. Bu durumda, modelinizin genelleme yeteneÄŸi azalÄ±r.

**Test Setini Taklit Ederek DoÄŸrulama Yapmak:**

Bu stratejide, tÃ¼m verilerle modelinizi eÄŸitirken, doÄŸrulama amacÄ±yla yalnÄ±zca **adverser tahminlerin 0.5'ten bÃ¼yÃ¼k** olduÄŸu Ã¶rnekleri seÃ§ersiniz. Bu doÄŸrulama seti, modelin performansÄ±nÄ± **test seti Ã¼zerinde optimize etmek** iÃ§in kullanÄ±lÄ±r.

Bu strateji, Ã¶zellikle modelin **hyperparametrelerinin ve seÃ§imlerinin** test setine gÃ¶re en iyi ÅŸekilde ayarlanmasÄ±na yardÄ±mcÄ± olur. Ancak dikkat edilmesi gereken bir diÄŸer ÅŸey, test setini tam anlamÄ±yla taklit etmeye Ã§alÄ±ÅŸmanÄ±n, modelin baÅŸka durumlar iÃ§in genellenebilirliÄŸini kaybettirebilmesidir.

**Adversarial DoÄŸrulama (Adversarial Validation) ile Ä°lgili Ek Notlar:**

* Adversarial doÄŸrulama, genellikle **yarÄ±ÅŸmalarda** performansÄ±nÄ±zÄ± artÄ±rmaya yardÄ±mcÄ± olur. Ancak her zaman iÅŸe yaramayabilir. Ã–rneÄŸin, Kaggle gibi platformlarda, **test setine tam eriÅŸiminiz olmadÄ±ÄŸÄ± iÃ§in adversarial doÄŸrulama** kullanmak mÃ¼mkÃ¼n deÄŸildir.

* Adversarial doÄŸrulama, test setinin **genel yapÄ±sÄ±nÄ±** anlamanÄ±zÄ± saÄŸlar, ancak **private** ve **public** test verisi arasÄ±ndaki farkÄ± anlamanÄ±za yardÄ±mcÄ± olamaz. Bu, genellikle **public leaderboard overfitting** sorununu ve takip eden sÄ±ralama deÄŸiÅŸikliklerini oluÅŸturur.

* GerÃ§ek dÃ¼nyada, adversarial doÄŸrulama birÃ§ok **pratik kullanÄ±m** sunar. Ã–rneÄŸin, test setinizi yanlÄ±ÅŸ seÃ§meniz durumunda, bu yÃ¶ntem size doÄŸru test verilerini kullanÄ±p kullanmadÄ±ÄŸÄ±nÄ±zÄ± anlamanÄ±zÄ± saÄŸlar. AyrÄ±ca, **modelin Ã¼retim ortamÄ±nda** zamanla bozulabileceÄŸini ve **concept drift** yaÅŸandÄ±ÄŸÄ±nÄ± fark edebilirsiniz. Bu durumda, modelinizi yeniden eÄŸitmeniz gerekebilir.

SonuÃ§ olarak, adversarial doÄŸrulama, doÄŸru test verisini seÃ§mek ve test setinizin eÄŸitim verisinden farklÄ±lÄ±klarÄ±nÄ± anlamak iÃ§in gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r. AyrÄ±ca, zaman iÃ§inde verinizde meydana gelen deÄŸiÅŸikliklerin modelinizin tahmin gÃ¼cÃ¼nÃ¼ nasÄ±l etkileyebileceÄŸi konusunda size bilgi verir.


> Giuliano Janson
> 
> https://www.kaggle.com/adjgiulio
> 
> 
> 
> > Giuliano Janson, Kaggle'da *Competitions Grandmaster* unvanÄ±na sahip ve ÅŸu anda Zillow Group'ta makine Ã¶ÄŸrenimi ve doÄŸal dil iÅŸleme (NLP) alanÄ±nda kÄ±demli bir uygulamalÄ± bilim insanÄ± olarak gÃ¶rev yapÄ±yor. Onunla yapÄ±lan bir rÃ¶portajda, Kaggleâ€™daki yarÄ±ÅŸmalar, veri sÄ±zÄ±ntÄ±larÄ±, Ã§apraz doÄŸrulama ve yaratÄ±cÄ± Ã¶zellik mÃ¼hendisliÄŸi gibi konularda deÄŸerli bilgiler paylaÅŸÄ±yor. Ä°ÅŸte Ã¶nemli bazÄ± noktalar:
> 
> 
> 
> **Favori YarÄ±ÅŸma TÃ¼rÃ¼**
> 
> 
> 
> Giuliano'nun en sevdiÄŸi yarÄ±ÅŸma tipi, Ã§Ã¶zmek iÃ§in ilginÃ§ bir problem sunan, hafÄ±zaya sÄ±ÄŸacak bÃ¼yÃ¼klÃ¼kte fakat aÅŸÄ±rÄ± kÃ¼Ã§Ã¼k olmayacak, yaratÄ±cÄ± Ã¶zellik mÃ¼hendisliÄŸi iÃ§in fÄ±rsatlar tanÄ±yan yarÄ±ÅŸmalardÄ±r. Bu tÃ¼r yarÄ±ÅŸmalar, ona hem dikkatli bir analiz hem de yaratÄ±cÄ± bir yaklaÅŸÄ±m sergileyebilme imkÃ¢nÄ± tanÄ±r.
> 
> 
> 
> **Kaggle YarÄ±ÅŸmalarÄ±na YaklaÅŸÄ±m**
> 
> 
> 
> Bir Kaggle yarÄ±ÅŸmasÄ±nÄ± bir maraton gibi gÃ¶rÃ¼r. Ä°lk birkaÃ§ gÃ¼n iÃ§inde en iyi puanlarÄ±nÄ±n %90-95'ini alabilirken, kalan %5 iÃ§in yoÄŸun bir ÅŸekilde Ã§alÄ±ÅŸmak gerekir. GÃ¼nlÃ¼k iÅŸ yaÅŸamÄ± ise farklÄ±dÄ±r. Burada model performansÄ± sadece bir faktÃ¶rdÃ¼r. Zaman yÃ¶netimi, Ã¶lÃ§eklenebilirlik, sÃ¼rdÃ¼rÃ¼lebilirlik gibi faktÃ¶rler de Ã¶nemli olup, projenin zamanÄ±nda hayata geÃ§mesi iÃ§in sÃ¼rekli Ã¶nceliklendirme yapÄ±lÄ±r.
> 
> 
> 
> **Zorlu Bir YarÄ±ÅŸma Deneyimi**
> 
> 
> 
> Genentech Kanser YarÄ±ÅŸmasÄ±, Giuliano'nun kazandÄ±ÄŸÄ± iki yarÄ±ÅŸmadan biridir. Bu yarÄ±ÅŸma, tÄ±bbi verilerle ilgili ham veriler sundu ve burada veriyi doÄŸru ÅŸekilde iÅŸlemek bÃ¼yÃ¼k bir zorluktu. Ã–zellik mÃ¼hendisliÄŸinde, veri sÄ±zÄ±ntÄ±larÄ±nÄ± tespit etme ve bunlarÄ± kullanarak modelin performansÄ±nÄ± artÄ±rma konusunda Ã¶nemli bir baÅŸarÄ± elde etti. Veri sÄ±zÄ±ntÄ±sÄ±, modelin yanlÄ±ÅŸ sonuÃ§lar Ã¼retmesine neden olabileceÄŸinden Ã§ok dikkat edilmesi gereken bir konu.
> 
> 
> 
> **Kaggle'Ä±n Kariyerine Etkisi**
> 
> 
> 
> Kaggle, Giuliano'ya iki ana aÃ§Ä±dan fayda saÄŸlamÄ±ÅŸtÄ±r: Modern makine Ã¶ÄŸrenimi tekniklerine eriÅŸim ve gÃ¼Ã§lÃ¼ bir model doÄŸrulama anlayÄ±ÅŸÄ± geliÅŸtirme. AyrÄ±ca Kaggle'da diÄŸer yetenekli katÄ±lÄ±mcÄ±larla iÅŸbirliÄŸi yaparak pek Ã§ok Ã¶nemli ders almÄ±ÅŸ ve bu deneyimlerini iÅŸ yerindeki diÄŸer insanlarla da paylaÅŸmaktadÄ±r.
> 
> 
> 
> **Yeni BaÅŸlayanlarÄ±n SÄ±klÄ±kla GÃ¶zden KaÃ§Ä±rdÄ±ÄŸÄ± Noktalar**
> 
> 
> 
> Yeni baÅŸlayanlarÄ±n en Ã§ok gÃ¶z ardÄ± ettiÄŸi konu doÄŸru Ã§apraz doÄŸrulamanÄ±n Ã¶nemi. Ä°yi bir Ã§apraz doÄŸrulama Ã§erÃ§evesi, modelin iyileÅŸtirilmesini doÄŸru ve objektif bir ÅŸekilde Ã¶lÃ§menizi saÄŸlar. YarÄ±ÅŸmalar uzun sÃ¼reli olduÄŸu iÃ§in, baÅŸarÄ±lÄ± olmak yalnÄ±zca iyi bir ilk fikre sahip olmakla deÄŸil, veriden gelen geribildirimle iterasyon yapabilme yeteneÄŸiyle de ilgilidir.
> 
> 
> 
> **Hangi AraÃ§larÄ± ve KÃ¼tÃ¼phaneleri Tavsiye Ediyor?**
> 
> 
> 
> Giuliano'nun tercih ettiÄŸi araÃ§lar arasÄ±nda **Pandas** ve **Scikit-learn** yer alÄ±yor. Pandas, veri manipÃ¼lasyonu ve keÅŸfi iÃ§in harika bir araÃ§ken, Scikit-learn ile hÄ±zlÄ±ca prototipler geliÅŸtirebilir. Nihai modelleri ise genellikle **XGBoost** ile kuruyor. Derin Ã¶ÄŸrenme iÃ§inse **Keras** kullanmayÄ± tercih ediyor.
> 
> 
> 
> Bu gibi deneyimler, Kaggleâ€™da baÅŸarÄ±lÄ± olmak iÃ§in gereken derin bilgi ve pratik deneyimi pekiÅŸtiriyor.

### Handling leakage *(Veri sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nleme)*

Kaggle yarÄ±ÅŸmalarÄ±nda sonucu etkileyebilecek yaygÄ±n bir sorun **veri sÄ±zÄ±ntÄ±sÄ±**dÄ±r. Genellikle basitÃ§e **sÄ±zÄ±ntÄ±** (leakage) olarak veya baÅŸka sÃ¼slÃ¼ isimlerle (Ã¶rneÄŸin, **golden features - altÄ±n Ã¶zellikler**) anÄ±lan veri sÄ±zÄ±ntÄ±sÄ±, eÄŸitim aÅŸamasÄ±nda mevcut olan ancak **tahmin anÄ±nda kullanÄ±lamayacak** bilgileri iÃ§erir. BÃ¶yle bir bilginin (sÄ±zÄ±ntÄ±nÄ±n) varlÄ±ÄŸÄ±, modelinizin eÄŸitimde ve testte aÅŸÄ±rÄ± performans gÃ¶stermesine izin vererek sizi yarÄ±ÅŸmada Ã¼st sÄ±ralara taÅŸÄ±yacak, ancak sponsÃ¶rÃ¼n bakÄ±ÅŸ aÃ§Ä±sÄ±ndan bu bilgiye dayalÄ± herhangi bir Ã§Ã¶zÃ¼mÃ¼ **kullanÄ±lmaz** veya en iyi ihtimalle **en iyi olmayan** hale getirecektir.

> Michael Kim'in ([https://www.kaggle.com/mikeskim](https://www.kaggle.com/mikeskim)) 2019'da Kaggle Days San Francisco'daki sunumunda belirttiÄŸi gibi, sÄ±zÄ±ntÄ±yÄ± "**gerÃ§ek hakkÄ±nda bilgi, yapay ve kasÄ±tsÄ±z olarak eÄŸitim Ã¶zellik verilerine veya eÄŸitim meta verilerine dahil edildiÄŸinde**" ÅŸeklinde tanÄ±mlayabiliriz.

Sponsor ve Kaggle ekibinin dikkatli kontrolÃ¼ne raÄŸmen, sÄ±zÄ±ntÄ±nÄ±n beklenmedik bir ÅŸekilde ortaya Ã§Ä±kabilen **ince ve sinsi doÄŸasÄ±** nedeniyle, Kaggle yarÄ±ÅŸmalarÄ±nda sÄ±zÄ±ntÄ± sÄ±kÃ§a bulunur. Bu durum, her zaman bir yarÄ±ÅŸmada daha iyi puan almanÄ±n yollarÄ±nÄ± arayan Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n yÃ¼rÃ¼ttÃ¼ÄŸÃ¼ yoÄŸun arama faaliyetinden kaynaklanmaktadÄ±r.

> **Veri sÄ±zÄ±ntÄ±sÄ±nÄ±, sÄ±zÄ±ntÄ±lÄ± bir doÄŸrulama stratejisiyle karÄ±ÅŸtÄ±rmayÄ±n.** SÄ±zÄ±ntÄ±lÄ± bir doÄŸrulama stratejisinde, sorun, bazÄ± bilgilerin eÄŸitim verilerinden sÄ±zmasÄ± nedeniyle doÄŸrulama stratejinizi daha iyi doÄŸrulama puanlarÄ±nÄ± destekleyecek ÅŸekilde dÃ¼zenlemiÅŸ olmanÄ±zdÄ±r. Bu, yarÄ±ÅŸmanÄ±n kendisiyle ilgili deÄŸildir, ancak doÄŸrulamanÄ±zÄ± nasÄ±l ele aldÄ±ÄŸÄ±nÄ±zla ilgilidir. Bu, verilerinizi (normalleÅŸtirme, boyutluluk azaltma, eksik deÄŸer doldurma) eÄŸitim ve doÄŸrulama veya test verilerini ayÄ±rmadan **Ã¶nce** deÄŸiÅŸtiren herhangi bir Ã¶n iÅŸleme uygulamanÄ±z durumunda ortaya Ã§Ä±kar.
> SÄ±zÄ±ntÄ±lÄ± doÄŸrulamayÄ± Ã¶nlemek iÃ§in, verilerinizi manipÃ¼le etmek ve iÅŸlemek iÃ§in **Scikit-learn** kullanÄ±yorsanÄ±z, doÄŸrulama verilerinizi kesinlikle herhangi bir **uyumlandÄ±rma (fitting) iÅŸleminden** hariÃ§ tutmalÄ±sÄ±nÄ±z. Uyumlama iÅŸlemleri, doÄŸrulama iÃ§in kullandÄ±ÄŸÄ±nÄ±z herhangi bir veriye uygulanÄ±rsa sÄ±zÄ±ntÄ± oluÅŸturma eÄŸilimindedir. Bunu Ã¶nlemenin en iyi yolu, hem veri iÅŸleme hem de modeli bir araya getirecek olan Scikit-learn **pipelines** ([https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)) kullanmaktÄ±r, bÃ¶ylece verilerinize yanlÄ±ÅŸlÄ±kla herhangi bir sÄ±zÄ±ntÄ± oluÅŸturan dÃ¶nÃ¼ÅŸÃ¼m uygulama riskini ortadan kaldÄ±rÄ±rsÄ±nÄ±z.
> Buna karÅŸÄ±lÄ±k, veri sÄ±zÄ±ntÄ±sÄ±, doÄŸrulama iÅŸlemlerinden kesinlikle kaynaklanmaz, ancak onlarÄ± derinden etkiler. Bu bÃ¶lÃ¼m esas olarak doÄŸrulama stratejilerine ayrÄ±lmÄ±ÅŸ olsa da, modellerinizi ve genelleme yeteneklerini derinden etkileyebileceÄŸi iÃ§in veri sÄ±zÄ±ntÄ±sÄ±nÄ± tartÄ±ÅŸmayÄ± gerekli gÃ¶rÃ¼yoruz.

Genel olarak konuÅŸursak, sÄ±zÄ±ntÄ± **Ã¶zellik (feature)** veya **Ã¶rnek (example)** dÃ¼zeyinde ortaya Ã§Ä±kabilir. **Ã–zellik sÄ±zÄ±ntÄ±sÄ±** aÃ§Ä±k ara en yaygÄ±n olanÄ±dÄ±r. Hedefin bir vekilinin (proxy) varlÄ±ÄŸÄ±ndan veya hedefin kendisine **sonradan gelen** bir Ã¶zellikten kaynaklanabilir. Bir hedef vekili, etiketin kendisinin iÅŸlenmesinden veya test ayÄ±rma sÃ¼recinden tÃ¼retilmiÅŸ herhangi bir ÅŸey olabilir; Ã¶rneÄŸin, tanÄ±mlayÄ±cÄ±lar belirlenirken, belirli tanÄ±mlayÄ±cÄ±lar (bir numaralandÄ±rma yayÄ± gibi) belirli hedef yanÄ±tlarÄ±yla iliÅŸkilendirilebilir, bu da doÄŸru ÅŸekilde iÅŸlenen bilgiyle beslenirse modelin tahmin etmesini kolaylaÅŸtÄ±rÄ±r. Veri iÅŸlemenin sÄ±zÄ±ntÄ±ya neden olabileceÄŸi daha incelikli bir yol, yarÄ±ÅŸma organizatÃ¶rlerinin eÄŸitim ve test setlerini **ayÄ±rmadan Ã¶nce birlikte iÅŸlemesidir**. Tarihsel olarak, Kaggle yarÄ±ÅŸmalarÄ±ndaki sÄ±zÄ±ntÄ±lar ÅŸunlarda bulunmuÅŸtur:

1.  Organizasyon ekibinin **yanlÄ±ÅŸ ele alÄ±nmÄ±ÅŸ veri hazÄ±rlÄ±ÄŸÄ±**, Ã¶zellikle eÄŸitim ve test verilerinin birleÅŸimi Ã¼zerinde Ã§alÄ±ÅŸtÄ±klarÄ±nda (Ã¶rneÄŸin, Loan Default Prediction'da, organizatÃ¶rler baÅŸlangÄ±Ã§ta **gelecekteki bilgileri sÄ±zdÄ±ran** toplu geÃ§miÅŸ verilere sahip Ã¶zellikler kullandÄ±lar).
2.  **SatÄ±r sÄ±rasÄ±nÄ±n** bir zaman endeksi veya belirli veri gruplarÄ±yla baÄŸlantÄ±lÄ± olmasÄ± (Ã¶rneÄŸin, Telstra Network Disruptions'da, bir Ã¶zellikteki kayÄ±tlarÄ±n sÄ±rasÄ±, veride bulunmayan ve Ã§ok tahmine dayalÄ± olan bir vekil bilgiye, **konuma**, iÅŸaret ediyordu).
3.  **SÃ¼tun sÄ±rasÄ±nÄ±n** bir zaman endeksiyle baÄŸlantÄ±lÄ± olmasÄ± (sÃ¼tunlarÄ± satÄ±r olarak kullanarak ipuÃ§larÄ± elde edebilirsiniz).
4.  **ArdÄ±ÅŸÄ±k satÄ±rlardaki Ã¶zellik tekrarÄ±**, korelasyonlu yanÄ±tlara sahip Ã¶rneklere iÅŸaret edebileceÄŸi iÃ§in (Bosch Production Line Performance'da olduÄŸu gibi).
5.  **GÃ¶rÃ¼ntÃ¼ meta verileri** (Two Sigma Connect: Rental Listing Inquiries'da olduÄŸu gibi).
6.  **Hash'ler** veya kodlamalarÄ±n ve tanÄ±mlayÄ±cÄ±larÄ±n diÄŸer kolayca kÄ±rÄ±labilir anonimleÅŸtirme uygulamalarÄ±.

**Sonradan gelen bilgiyle** ilgili sorun, zamanÄ±n etkilerini ve zaman boyunca uzanan neden-sonuÃ§ dizisini dikkate almadÄ±ÄŸÄ±mÄ±zda bilgiyle baÅŸa Ã§Ä±kma ÅŸeklimizden kaynaklanÄ±r. GeÃ§miÅŸe baktÄ±ÄŸÄ±mÄ±z iÃ§in, ÅŸimdiki anda anlam ifade eden bazÄ± deÄŸiÅŸkenlerin geÃ§miÅŸte bir deÄŸeri olmadÄ±ÄŸÄ±nÄ± sÄ±k sÄ±k unuturuz. Ã–rneÄŸin, yeni bir ÅŸirkete kredi iÃ§in kredi puanÄ± hesaplamanÄ±z gerekiyorsa, Ã¶dÃ¼nÃ§ alÄ±nan paranÄ±n Ã¶demelerinin sÄ±klÄ±kla geÃ§ olduÄŸunu bilmek, borÃ§lunun daha dÃ¼ÅŸÃ¼k gÃ¼venilirliÄŸinin ve temsil ettiÄŸi daha yÃ¼ksek riskin harika bir gÃ¶stergesidir, ancak bunu parayÄ± Ã¶dÃ¼nÃ§ vermeden **Ã¶nce** bilemezsiniz. Bu, projelerinizde ÅŸirket veritabanlarÄ±nÄ± analiz ederken de sÄ±kÃ§a karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z bir sorundur: sorguladÄ±ÄŸÄ±nÄ±z veriler geÃ§miÅŸ durumlarÄ± deÄŸil, **ÅŸimdiki durumlarÄ±** temsil edecektir. GeÃ§miÅŸ bilgileri yeniden oluÅŸturmak, yalnÄ±zca belirli bir zamanda mevcut olan bilgileri almak istediÄŸinizi belirtemezseniz de zor bir gÃ¶rev olabilir. Bu nedenle, herhangi bir model oluÅŸturmadan Ã¶nce bu sÄ±zÄ±ntÄ± yapan Ã¶zellikleri bulmaya ve hariÃ§ tutmaya veya ayarlamaya bÃ¼yÃ¼k Ã§aba harcanmalÄ±dÄ±r.

Benzer sorunlar, aynÄ± tÃ¼r verilere (Ã¶rneÄŸin, bankacÄ±lÄ±k veya sigorta) dayalÄ± Kaggle yarÄ±ÅŸmalarÄ±nda da yaygÄ±ndÄ±r, ancak verilerin yarÄ±ÅŸma iÃ§in hazÄ±rlanmasÄ±na Ã§ok dikkat edildiÄŸinden, daha incelikli yollarla ve biÃ§imlerde ortaya Ã§Ä±karlar. Genel olarak, bu sÄ±zÄ±ntÄ± yapan Ã¶zellikleri tespit etmek kolaydÄ±r, Ã§Ã¼nkÃ¼ hedefle gÃ¼Ã§lÃ¼ bir ÅŸekilde iliÅŸkilidirler ve bir alan uzmanÄ± nedenini Ã§Ã¶zebilir (Ã¶rneÄŸin, verilerin veritabanlarÄ±nda hangi aÅŸamada kaydedildiÄŸini bilmek). Bu nedenle, yarÄ±ÅŸmalarda asla bu kadar bariz Ã¶zellikler bulamazsÄ±nÄ±z, ancak sponsorun kontrolÃ¼nden kaÃ§an, genellikle dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veya iÅŸlenmiÅŸ, bunlarÄ±n tÃ¼revlerini bulursunuz. Ã–zellikler, sponsorun iÅŸini korumak iÃ§in genellikle anonimleÅŸtirildiÄŸinden, diÄŸerlerinin arasÄ±nda gizlenmiÅŸ olarak kalÄ±rlar. Bu, **altÄ±n/sihirli Ã¶zellikler** iÃ§in bir dizi avÄ±n doÄŸmasÄ±na neden olmuÅŸtur, yani sÄ±zÄ±ntÄ±nÄ±n ortaya Ã§Ä±kmasÄ± iÃ§in veri kÃ¼mesindeki mevcut Ã¶zellikleri birleÅŸtirme arayÄ±ÅŸÄ±.

> Corey Levison'Ä±n aydÄ±nlatÄ±cÄ± bir yazÄ±sÄ±nÄ± buradan okuyabilirsiniz: [https://www.linkedin.com/pulse/winning-13th-place-kaggles-magic-competition-coreylevinson/](https://www.google.com/search?q=https://www.linkedin.com/pulse/winning-13th-place-kaggles-magic-competition-coreylevinson/). Bu, Santander Customer Transaction Prediction yarÄ±ÅŸmasÄ±nÄ±n ekibi iÃ§in nasÄ±l sihirli Ã¶zellikler avÄ±na dÃ¶nÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼n hikayesini anlatÄ±yor.
> 
> 
> 
> BaÅŸka bir iyi Ã¶rnek dune\_dweller tarafÄ±ndan burada sunulmuÅŸtur: [https://www.kaggle.com/c/telstra-recruiting-network/discussion/19239\#109766](https://www.google.com/search?q=https://www.kaggle.com/c/telstra-recruiting-network/discussion/19239%23109766). dune\_dweller, verilerin nasÄ±l sÄ±ralandÄ±ÄŸÄ±na bakarak, verilerin bÃ¼yÃ¼k olasÄ±lÄ±kla zaman sÄ±rasÄ±na gÃ¶re olduÄŸunu buldu. Bu bilgiyi yeni bir Ã¶zelliÄŸe koymak puanÄ± artÄ±rdÄ±.

SÄ±zÄ±ntÄ±nÄ±n diÄŸer ortaya Ã§Ä±kma yolu ise **eÄŸitim Ã¶rneÄŸi sÄ±zÄ±ntÄ±sÄ±dÄ±r**. Bu, Ã¶zellikle **i.i.d olmayan (baÄŸÄ±msÄ±z ve Ã¶zdeÅŸ daÄŸÄ±lÄ±mlÄ± olmayan)** verilerde olur. Bu, bazÄ± vakalarÄ±n aynÄ± dÃ¶nemden (veya ardÄ±ÅŸÄ±k olanlardan) veya aynÄ± gruptan olmalarÄ± nedeniyle kendi aralarÄ±nda korelasyonlu olduÄŸu anlamÄ±na gelir. Bu tÃ¼r vakalarÄ±n hepsi eÄŸitim veya test verilerinde bir arada deÄŸil, aralarÄ±nda ayrÄ±lmÄ±ÅŸlarsa, makine Ã¶ÄŸrenimi algoritmasÄ±nÄ±n genel kurallar kullanmak yerine vakalarÄ± nasÄ±l tespit edeceÄŸini (ve tahminleri nasÄ±l tÃ¼reteceÄŸini) Ã¶ÄŸrenme ÅŸansÄ± yÃ¼ksektir. BÃ¶yle bir durumun sÄ±kÃ§a bahsedilen bir Ã¶rneÄŸi, Prof. Andrew Ng'nin ekibini iÃ§erir (bkz. [https://twitter.com/nizkroberts/status/931121395748270080](https://twitter.com/nizkroberts/status/931121395748270080)). 2017'de, 30.000 hastadan alÄ±nan 100.000 rÃ¶ntgen gÃ¶rÃ¼ntÃ¼sÃ¼nden oluÅŸan bir veri kÃ¼mesi kullanarak bir makale yazdÄ±lar. EÄŸitim ve test verilerini ayÄ±rmak iÃ§in rastgele bir bÃ¶lme kullandÄ±lar, ancak aynÄ± hastanÄ±n rÃ¶ntgenlerinin kÄ±smen eÄŸitim setinde ve kÄ±smen test setinde olabileceÄŸini fark etmediler. Nick Roberts gibi uygulayÄ±cÄ±lar bu gerÃ§eÄŸi fark ederek, modelin performanslarÄ±nÄ± ÅŸiÅŸirebilecek olasÄ± bir sÄ±zÄ±ntÄ±ya dikkat Ã§ekti ve bu da makalenin Ã¶nemli Ã¶lÃ§Ã¼de revize edilmesine yol aÃ§tÄ±.

Kaggle yarÄ±ÅŸmasÄ±nda veri sÄ±zÄ±ntÄ±sÄ± olduÄŸunda ne olur? Kaggle'Ä±n bu konuda net politikalarÄ± vardÄ±r ve ya:

  * YarÄ±ÅŸmanÄ±n olduÄŸu gibi devam etmesine izin verir (Ã¶zellikle sÄ±zÄ±ntÄ±nÄ±n yalnÄ±zca kÃ¼Ã§Ã¼k bir etkisi varsa)
  * SÄ±zÄ±ntÄ±yÄ± setten kaldÄ±rÄ±r ve yarÄ±ÅŸmayÄ± yeniden baÅŸlatÄ±r
  * SÄ±zÄ±ntÄ±nÄ±n bulunmadÄ±ÄŸÄ± yeni bir test seti oluÅŸturur

Ã–zellikle, Kaggle bulunan herhangi bir sÄ±zÄ±ntÄ±yÄ± **kamuya aÃ§Ä±klamayÄ±** tavsiye eder, ancak bu zorunlu deÄŸildir veya yapÄ±lmazsa yaptÄ±rÄ±m uygulanmaz. Ancak, deneyimlerimize gÃ¶re, bir yarÄ±ÅŸmada herhangi bir sÄ±zÄ±ntÄ± varsa, yakÄ±nda Ã§ok belirgin hale gelecek ve tartÄ±ÅŸma forumlarÄ± sihirli ÅŸeyler ve benzerleri hakkÄ±nda bir tartÄ±ÅŸmayla aydÄ±nlanmaya baÅŸlayacaktÄ±r. Forumlarda sÃ¶ylenenlere dikkat ederseniz ve farklÄ± Kaggle katÄ±lÄ±mcÄ±larÄ± tarafÄ±ndan saÄŸlanan tÃ¼m ipuÃ§larÄ±nÄ± bir araya getirebilirseniz, kÄ±sa sÃ¼rede bileceksiniz.

Ancak, bazÄ± oyuncularÄ±n diÄŸer yarÄ±ÅŸmacÄ±larÄ± ciddi modellemeden uzaklaÅŸtÄ±rmak iÃ§in sihirli Ã¶zellikler hakkÄ±ndaki tartÄ±ÅŸmalarÄ± bile kullanabileceÄŸine lÃ¼tfen dikkat edin. Ã–rneÄŸin, Santander Customer Transaction Prediction'da, bazÄ± Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n diÄŸer katÄ±lÄ±mcÄ±larÄ± aslÄ±nda o kadar da sihirli olmayan sihirli Ã¶zelliklere ilgi duymaya teÅŸvik ettiÄŸi, Ã§abalarÄ±nÄ± yanlÄ±ÅŸ yÃ¶ne yÃ¶nlendirdiÄŸi Ã¼nlÃ¼ bir durum vardÄ± (tartÄ±ÅŸmaya buradan bakÄ±n: [https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/87057\#502362](https://www.google.com/search?q=https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/87057%23502362)).

Ã–nerimiz, yarÄ±ÅŸma forumunda ortaya Ã§Ä±kan sÄ±zÄ±ntÄ± ve sihirli Ã¶zellikler hakkÄ±ndaki tartÄ±ÅŸmalarÄ± dikkatlice okumanÄ±z ve yarÄ±ÅŸmaya katÄ±lma ilgi ve motivasyonlarÄ±nÄ±za dayanarak araÅŸtÄ±rmayÄ± sÃ¼rdÃ¼rÃ¼p sÃ¼rdÃ¼rmemeye ve bulunan herhangi bir sÄ±zÄ±ntÄ±yÄ± kullanÄ±p kullanmamaya karar vermenizdir.

Herhangi bir sÄ±zÄ±ntÄ±yÄ± kullanmamak, nihai sÄ±ralamanÄ±za gerÃ§ekten zarar verebilir, ancak Ã¶ÄŸrenme deneyiminizi kesinlikle bozacaktÄ±r (Ã§Ã¼nkÃ¼ sÄ±zÄ±ntÄ± bir Ã§arpÄ±tmadÄ±r ve onu kullanan modeller hakkÄ±nda herhangi bir iddiada bulunamazsÄ±nÄ±z). Bir itibar kazanmak veya daha sonra bir iÅŸe alÄ±nma fÄ±rsatÄ± iÃ§in sponsora yaklaÅŸmak amacÄ±yla bir yarÄ±ÅŸmaya katÄ±lmÄ±yorsanÄ±z, karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z herhangi bir sÄ±zÄ±ntÄ±yÄ± kullanmanÄ±z tamamen normaldir. Aksi takdirde, onu gÃ¶rmezden gelin ve modelleriniz Ã¼zerinde sÄ±kÄ± Ã§alÄ±ÅŸmaya devam edin (kim bilir; belki Kaggle sonunda yarÄ±ÅŸmayÄ± sÄ±fÄ±rlar veya dÃ¼zeltir, sÄ±zÄ±ntÄ±yÄ± kullanan birÃ§ok kiÅŸinin bÃ¼yÃ¼k hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸramasÄ±na neden olur).

> SÄ±zÄ±ntÄ±lar, yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã§ok farklÄ±dÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda gerÃ§ekleÅŸen birkaÃ§ gerÃ§ek sÄ±zÄ±ntÄ± hakkÄ±nda fikir edinmek isterseniz, bu Ã¼Ã§ unutulmaz Ã¶rneÄŸe bakabilirsiniz:
> 
> 
> 
> * [https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/22807](https://www.google.com/search?q=https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/22807) Predicting Red Hat Business Value'dan, sorunun yarÄ±ÅŸmanÄ±n kusurlu bir eÄŸitim/test bÃ¶lme metodolojisinden kaynaklandÄ±ÄŸÄ± yer.
> 
> * [https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23403](https://www.google.com/search?q=https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23403) TalkingData Mobile User Demographics'ten, bir dizi sorun ve i.i.d olmayan vakalarÄ±n yarÄ±ÅŸmanÄ±n doÄŸru eÄŸitim/test bÃ¶lmesini etkilediÄŸi yer.
> 
> * [https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870](https://www.google.com/search?q=https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870) Two Sigma Connect: Rental Listing Inquiries'dan, meta verilerin (her klasÃ¶rÃ¼n oluÅŸturulma zamanÄ±) iÅŸe yaradÄ±ÄŸÄ± yer.


### Summary *(Ã–zet)*

BÃ¶lÃ¼mÃ¼n sonuna gelmiÅŸ bulunuyoruz, bu nedenle doÄŸrulama (validation) stratejinizi dÃ¼zenleyebilmeniz ve bir yarÄ±ÅŸmanÄ±n sonuna gÃ¶ndereceÄŸiniz birkaÃ§ uygun modelle ulaÅŸabilmeniz iÃ§in yolda tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z tavsiyeleri Ã¶zetleyeceÄŸiz.

Bu bÃ¶lÃ¼mde, Ã¶ncelikle **halka aÃ§Ä±k liderlik tablosunun (public leaderboard) dinamiklerini** analiz ettik, uyarlanabilir aÅŸÄ±rÄ± Ã¶ÄŸrenme (adaptive overfitting) ve bÃ¼yÃ¼k deÄŸiÅŸiklikler (shake-ups) gibi sorunlarÄ± araÅŸtÄ±rdÄ±k. ArdÄ±ndan, bir veri bilimi yarÄ±ÅŸmasÄ±nda doÄŸrulamanÄ±n Ã¶nemini, **gÃ¼venilir bir sistem oluÅŸturmayÄ±**, bunu liderlik tablosuna gÃ¶re ayarlamayÄ± ve ardÄ±ndan Ã§abalarÄ±nÄ±zÄ±n kaydÄ±nÄ± tutmayÄ± tartÄ±ÅŸtÄ±k.

Ã‡eÅŸitli doÄŸrulama stratejilerini tartÄ±ÅŸtÄ±k ve **hiperparametrelerinizi ayarlamanÄ±n** ve test verilerinizi veya doÄŸrulama bÃ¶lÃ¼mlerinizi **dÃ¼ÅŸmanca doÄŸrulama (adversarial validation)** kullanarak kontrol etmenin en iyi yolunu da gÃ¶rdÃ¼k.

Son olarak, **Kaggle yarÄ±ÅŸmalarÄ±nda karÅŸÄ±laÅŸÄ±lan bazÄ± veri sÄ±zÄ±ntÄ±larÄ±nÄ± (leakages)** tartÄ±ÅŸtÄ±k ve bunlarla nasÄ±l baÅŸa Ã§Ä±kÄ±lacaÄŸÄ±na dair tavsiyeler sunduk.

Ä°ÅŸte kapanÄ±ÅŸ Ã¶nerilerimiz:

* Daima yarÄ±ÅŸmanÄ±n ilk kÄ±smÄ±nÄ±, **gÃ¼venilir bir doÄŸrulama ÅŸemasÄ± oluÅŸturmaya** ayÄ±rÄ±n. OlasÄ±lÄ±ksal doÄŸasÄ± ve daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ verilere genelleme yeteneÄŸi gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, bir **eÄŸitim-test bÃ¶lmesinden (train-test split) ziyade k-katlÄ± Ã§apraz doÄŸrulama (k-fold)** yÃ¶ntemini tercih edin.
* DoÄŸrulama ÅŸemanÄ±z **kararsÄ±zsa**, daha fazla kat (fold) kullanÄ±n veya farklÄ± veri bÃ¶lmeleriyle **birden Ã§ok kez Ã§alÄ±ÅŸtÄ±rÄ±n**. Test setinizi daima dÃ¼ÅŸmanca doÄŸrulama kullanarak kontrol edin.
* Hem doÄŸrulama ÅŸemanÄ±za hem de liderlik tablosuna dayalÄ± olarak **sonuÃ§larÄ±n kaydÄ±nÄ± tutun**. OlasÄ± optimizasyonlar ve Ã§Ä±ÄŸÄ±r aÃ§Ä±cÄ± buluÅŸlar (sihirli Ã¶zellikler veya sÄ±zÄ±ntÄ±lar gibi) iÃ§in **doÄŸrulama puanÄ±nÄ±za daha Ã§ok gÃ¼venin**.
* BÃ¶lÃ¼mÃ¼n baÅŸÄ±nda aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z gibi, yarÄ±ÅŸmaya yapacaÄŸÄ±nÄ±z **nihai gÃ¶nderimlerinize karar verirken doÄŸrulama puanlarÄ±nÄ±zÄ± kullanÄ±n**. Nihai gÃ¶nderimleriniz iÃ§in, duruma ve liderlik tablosuna gÃ¼venip gÃ¼venmediÄŸinize baÄŸlÄ± olarak, **en iyi yerel Ã§apraz doÄŸrulama yapÄ±lmÄ±ÅŸ modelleriniz** ve liderlik tablosunda iyi puan alan gÃ¶nderimleriniz arasÄ±ndan seÃ§im yapÄ±n, **birinciyi ikinciye tercih edin**.

---

Bu yolculuÄŸumuzun bu noktasÄ±nda, satÄ±rlarÄ±n Ã¶rnekleri (examples) ve sÃ¼tunlarÄ±n Ã¶zellikleri (features) temsil ettiÄŸi matrisler halinde dÃ¼zenlenmiÅŸ sayÄ±sal veya kategorik veriler olan **tablosal verilerle** yarÄ±ÅŸmalara nasÄ±l yaklaÅŸacaÄŸÄ±mÄ±zÄ± tartÄ±ÅŸmaya hazÄ±rÄ±z. Bir sonraki bÃ¶lÃ¼mde, Kaggle tarafÄ±ndan tablosal veriler kullanÄ±larak dÃ¼zenlenen aylÄ±k bir yarÄ±ÅŸma olan **Tabular Playground Series**'i (Inversion tarafÄ±ndan organize edilmiÅŸtir: [https://www.kaggle.com/inversion](https://www.kaggle.com/inversion)) tartÄ±ÅŸacaÄŸÄ±z.

AyrÄ±ca, bu yarÄ±ÅŸmalarda Ã¶ne Ã§Ä±kmanÄ±za yardÄ±mcÄ± olacak **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering), hedef kodlama (target encoding), gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±lar (denoising autoencoders)** ve tablosal veri sorunlarÄ±nda kabul gÃ¶rmÃ¼ÅŸ son teknoloji Ã¶ÄŸrenme algoritmalarÄ±na (XGBoost, LightGBM veya CatBoost gibi gradyan artÄ±rma algoritmalarÄ±) bir alternatif olarak **tablosal veriler iÃ§in bazÄ± sinir aÄŸlarÄ±** gibi bazÄ± Ã¶zel teknikleri tanÄ±tacaÄŸÄ±z.

---

## Chapter 7: Modeling for Tabular Competitions *(BÃ¶lÃ¼m 7: Tablo Verisi YarÄ±ÅŸmalarÄ± Ä°Ã§in Modellemede YaklaÅŸÄ±mlar)*

2017 yÄ±lÄ±na kadar, yarÄ±ÅŸma tÃ¼rleri arasÄ±nda Ã§ok fazla ayrÄ±m yapmaya gerek yoktu ve yarÄ±ÅŸmalarÄ±n bÃ¼yÃ¼k Ã§oÄŸunluÄŸu **tablosal verilere** dayandÄ±ÄŸÄ± iÃ§in Kaggle forumlarÄ±nda "tablosal yarÄ±ÅŸmalar" diye bir ifade bile bulamazdÄ±nÄ±z. Aniden bir ÅŸeyler deÄŸiÅŸti. GÃ¶rece bir yarÄ±ÅŸma kÄ±tlÄ±ÄŸÄ±nÄ±n ardÄ±ndan (bkz. [https://www.kaggle.com/general/49904](https://www.kaggle.com/general/49904)), **derin Ã¶ÄŸrenme** (deep learning) yarÄ±ÅŸmalarÄ± Ã¼stÃ¼nlÃ¼k saÄŸladÄ± ve tablosal yarÄ±ÅŸmalar nadir hale gelerek pek Ã§ok kiÅŸiyi hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸrattÄ±. O kadar nadir hale geldiler ki, Kaggle kÄ±sa sÃ¼re Ã¶nce sentetik verilere dayalÄ± bir dizi tablosal yarÄ±ÅŸma baÅŸlatmak zorunda kaldÄ±. Ne oldu?

2017-2018'e gelindiÄŸinde, veri bilimi tam olgunluÄŸa eriÅŸmiÅŸti ve birÃ§ok ÅŸirket kendi veri yolculuklarÄ±na baÅŸlamÄ±ÅŸtÄ±. Veri bilimi hala sÄ±cak bir konuydu, ancak artÄ±k o kadar da sÄ±ra dÄ±ÅŸÄ± deÄŸildi. O zamanlar Kaggle'Ä± yÄ±llardÄ±r dolduran sorunlara benzer sorunlarÄ±n Ã§Ã¶zÃ¼mleri, birÃ§ok ÅŸirkette **standart bir uygulama** haline gelmiÅŸti. Bu koÅŸullar altÄ±nda, sponsorlar artÄ±k dÄ±ÅŸarÄ±dan tablosal yarÄ±ÅŸmalar dÃ¼zenlemeye daha az motive oldular, Ã§Ã¼nkÃ¼ zaten aynÄ± sorunlarla **iÃ§eride** baÅŸ ediyorlardÄ±. Buna karÅŸÄ±lÄ±k, derin Ã¶ÄŸrenme hala bÃ¼yÃ¼k Ã¶lÃ§Ã¼de keÅŸfedilmemiÅŸ bir alandÄ±r ve uzun bir sÃ¼re daha Ã¶yle kalmaya devam edecektir, bu nedenle en son teknolojiyi zorlamak ve yeni bir ÅŸeyin ortaya Ã§Ä±kÄ±p Ã§Ä±kmadÄ±ÄŸÄ±nÄ± gÃ¶rmek iÃ§in yarÄ±ÅŸmalar baÅŸlatmak mantÄ±klÄ±dÄ±r.

Bu bÃ¶lÃ¼mde **tablosal yarÄ±ÅŸmalarÄ±** ele alacaÄŸÄ±z. BazÄ± Ã¼nlÃ¼ tarihi yarÄ±ÅŸmalara deÄŸinecek ve ayrÄ±ca **Tabular Playground Series**'in daha yeni gerÃ§ekliÄŸine odaklanacaÄŸÄ±z, Ã§Ã¼nkÃ¼ tablosal problemler Ã§oÄŸu veri bilimci iÃ§in standart uygulamadÄ±r ve Kaggle'dan gerÃ§ekten Ã¶ÄŸrenilecek Ã§ok ÅŸey vardÄ±r. **KeÅŸifÃ§i Veri Analizi (EDA)** ve **Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)**, bu yarÄ±ÅŸmalardaki iki yaygÄ±n aktiviteyi tartÄ±ÅŸarak baÅŸlayacaÄŸÄ±z.

Ã–zellik mÃ¼hendisliÄŸi iÃ§in temel stratejileri sunduktan sonra, **kategorik kodlama, Ã¶zellik seÃ§imi, hedef dÃ¶nÃ¼ÅŸÃ¼mleri ve sÃ¶zde etiketleme (pseudo-labeling)** gibi birÃ§ok ilgili konuya geniÅŸleyeceÄŸiz. Tablosal veriler iÃ§in derin Ã¶ÄŸrenme metodolojilerine deÄŸinerek, **TabNet** gibi birkaÃ§ uzmanlaÅŸmÄ±ÅŸ derin sinir aÄŸÄ±nÄ± tanÄ±tacak ve bir **gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±yÄ± (denoising autoencoder)** gÃ¶stereceÄŸiz. Otomatik kodlayÄ±cÄ±larÄ±n, gerÃ§ek dÃ¼nya uygulamalarÄ±nda hala marjinal olmasÄ±na raÄŸmen, son Kaggle yarÄ±ÅŸmalarÄ± iÃ§in neden bu kadar alakalÄ± hale geldiÄŸini aÃ§Ä±klayacaÄŸÄ±z.

Ä°ÅŸleyeceÄŸimiz konular:
* **Tabular Playground Series**
* Tekrarlanabilirlik iÃ§in **rastgele durum (random state) ayarlama**
* **EDA'nÄ±n Ã¶nemi**
* Verilerinizin **boyutunu kÃ¼Ã§Ã¼ltme**
* **Ã–zellik mÃ¼hendisliÄŸi** uygulama
* **SÃ¶zde etiketleme (Pseudo-labeling)**
* **Otomatik kodlayÄ±cÄ±lar** ile gÃ¼rÃ¼ltÃ¼ giderme
* Tablosal yarÄ±ÅŸmalar iÃ§in **sinir aÄŸlarÄ±**

Bu bÃ¶lÃ¼m, tablosal yarÄ±ÅŸmalarla ilgili her konuyu kapsamayacaktÄ±r, ancak veri biliminin Ã¶zÃ¼nÃ¼ oluÅŸturduklarÄ± iÃ§in bunlarÄ± diÄŸer birÃ§ok kitapta kolayca bulabilirsiniz. Bu bÃ¶lÃ¼mÃ¼n yapacaÄŸÄ± ÅŸey, Kaggle'daki tablosal yarÄ±ÅŸmalarÄ± karakterize eden ve Kaggle forumlarÄ± dÄ±ÅŸÄ±nda baÅŸka bir yerde kolay kolay bulamayacaÄŸÄ±nÄ±z bir dizi Ã¶zel teknik ve yaklaÅŸÄ±m sunmaktÄ±r.

### The Tabular Playground Series *(Tabular Playground Serisi)*

Tablosal problemlere yÃ¶nelik bÃ¼yÃ¼k talep nedeniyle, Kaggle Ã§alÄ±ÅŸanlarÄ± 2021'de bir deney baÅŸlattÄ± ve **Tabular Playground Series** adÄ±nÄ± verdikleri aylÄ±k bir yarÄ±ÅŸma dÃ¼zenledi. YarÄ±ÅŸmalar, halka aÃ§Ä±k verileri veya Ã¶nceki yarÄ±ÅŸmalardan elde edilen verileri kopyalayan **sentetik veri setlerine** dayanÄ±yordu. Sentetik veriler, **CTGAN** adlÄ± derin Ã¶ÄŸrenme Ã¼retken aÄŸÄ± sayesinde oluÅŸturuldu.

> **CTGAN** kodunu [https://github.com/sdv-dev/CTGAN](https://github.com/sdv-dev/CTGAN) adresinde bulabilirsiniz. AyrÄ±ca, tablosal verilerdeki satÄ±rlarÄ±n olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± modelleyerek ve ardÄ±ndan gerÃ§ekÃ§i sentetik veriler Ã¼reterek nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± aÃ§Ä±klayan ilgili bir makale de mevcuttur (bkz. [https://arxiv.org/pdf/1907.00503v2.pdf](https://www.google.com/search?q=https://arxiv.org/pdf/1907.00503v2.pdf)).


> MIT giriÅŸimi olan **Synthetic Data Vault (SDV)** ([https://sdv.dev/](https://sdv.dev/)), CTGAN'Ä±n arkasÄ±ndaki teknolojiyi ve etrafÄ±ndaki oldukÃ§a fazla sayÄ±da aracÄ± yarattÄ±. SonuÃ§, iÅŸletmelerin gerÃ§ek verileri taklit eden sentetik veriler Ã¼retmesine yardÄ±mcÄ± olmak iÃ§in oluÅŸturulmuÅŸ bir dizi aÃ§Ä±k kaynaklÄ± yazÄ±lÄ±m sistemidir; veri bilimcilerinin gerÃ§ek verilere dayalÄ± anonim veri setleri oluÅŸturmasÄ±na ve ayrÄ±ca modelleme amaÃ§larÄ± iÃ§in mevcut olanlarÄ± artÄ±rmasÄ±na yardÄ±mcÄ± olabilir.

Kaggle, 2021'de puan, madalya veya Ã¶dÃ¼l (yalnÄ±zca bazÄ± promosyon Ã¼rÃ¼nleri) sunmamasÄ±na raÄŸmen birÃ§ok Kaggle kullanÄ±cÄ±sÄ±nÄ±n ilgisini Ã§eken 13 oldukÃ§a baÅŸarÄ±lÄ± yarÄ±ÅŸma baÅŸlattÄ±. Ä°ÅŸte 2021 listesi; belirli problemleri tÃ¼re veya metriÄŸe gÃ¶re bulmak ve ilgili kaynaklarÄ± (odaklanmÄ±ÅŸ tartÄ±ÅŸmalar veya Notebook'lar gibi) aramak iÃ§in kullanabilirsiniz:

| Ay | Problem | DeÄŸiÅŸkenler | Metrik | Eksik Veri |
| :--- | :--- | :--- | :--- | :--- |
| Ocak 2021 | BelirtilmemiÅŸ bir problem Ã¼zerine Regresyon | SayÄ±sal | RMSE | HayÄ±r |
| Åubat 2021 | Bir sigorta talebinin deÄŸerini tahmin eden Regresyon | SayÄ±sal ve Kategorik | RMSE | HayÄ±r |
| Mart 2021 | Bir sigorta talebini tahmin eden Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | AUC | HayÄ±r |
| Nisan 2021 | Orijinal **Titanic** veri setine Ã§ok benzeyen bir kopyasÄ± Ã¼zerine Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | DoÄŸruluk (Accuracy) | Evet |
| MayÄ±s 2021 | Listeleme ile ilgili Ã§eÅŸitli nitelikler verildiÄŸinde bir e-ticaret Ã¼rÃ¼nÃ¼ndeki kategoriyi tahmin eden Ã‡oklu SÄ±nÄ±flandÄ±rma | Kategorik | Ã‡oklu SÄ±nÄ±f LogLoss | HayÄ±r |
| Haziran 2021 | Listeleme ile ilgili Ã§eÅŸitli nitelikler verildiÄŸinde bir e-ticaret Ã¼rÃ¼nÃ¼ndeki kategoriyi tahmin eden Ã‡oklu SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | Ã‡oklu SÄ±nÄ±f LogLoss | HayÄ±r |
| Temmuz 2021 | Ã‡eÅŸitli girdi sensÃ¶r deÄŸerleri (Ã¶rneÄŸin, bir zaman serisi) aracÄ±lÄ±ÄŸÄ±yla bir ÅŸehirdeki hava kirliliÄŸini tahmin eden Ã‡oklu Regresyon | SayÄ±sal, Zaman | RMSLE | Evet |
| AÄŸustos 2021 | Bir kredi temerrÃ¼dÃ¼ (loan default) ile iliÅŸkili kaybÄ± hesaplayan Regresyon | SayÄ±sal | RMSE | HayÄ±r |
| 30 GÃ¼n ML | Bir sigorta talebinin deÄŸeri Ã¼zerine Regresyon | SayÄ±sal ve Kategorik | RMSE | HayÄ±r |
| EylÃ¼l 2021 | Bir sigorta poliÃ§esi iÃ§in talepte bulunulup bulunulmayacaÄŸÄ±nÄ± tahmin eden Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal | AUC | Evet |
| Ekim 2021 | Ã‡eÅŸitli kimyasal Ã¶zellikler verildiÄŸinde molekÃ¼llerin biyolojik tepkisini tahmin eden Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | AUC | HayÄ±r |
| KasÄ±m 2021 | E-postadan Ã§Ä±karÄ±lan Ã§eÅŸitli Ã¶zellikler aracÄ±lÄ±ÄŸÄ±yla spam e-postalarÄ± tanÄ±mlayan Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal | AUC | HayÄ±r |
| AralÄ±k 2021 | Orijinal Forest Cover Type Prediction yarÄ±ÅŸmasÄ±na dayanan Ã‡oklu SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | Ã‡oklu SÄ±nÄ±flandÄ±rma DoÄŸruluÄŸu | HayÄ±r |

Tabular Playground yarÄ±ÅŸmalarÄ±, daha sofistike ve zorlu problemlerle 2022'de de devam etti:

| Ay | Problem | DeÄŸiÅŸkenler | Metrik | Eksik Veri |
| :--- | :--- | :--- | :--- | :--- |
| Ocak 2022 | Ä°ki kurgusal baÄŸÄ±msÄ±z maÄŸaza zincirinden Kaggle Ã¼rÃ¼nlerinin satÄ±ÅŸlarÄ±nÄ± tahmin etme | Tarihler ve Kategorik | Simetrik Ortalama Mutlak YÃ¼zde HatasÄ± (SMAPE) | HayÄ±r |
| Åubat 2022 | Veri sÄ±kÄ±ÅŸtÄ±rma ve veri kaybÄ± iÃ§eren bir genomik analiz tekniÄŸinden elde edilen verileri kullanarak 10 farklÄ± bakteri tÃ¼rÃ¼nÃ¼ sÄ±nÄ±flandÄ±rma | SayÄ±sal | Kategorizasyon DoÄŸruluÄŸu | HayÄ±r |

Bu bÃ¶lÃ¼mÃ¼n bÃ¼yÃ¼k bir kÄ±smÄ±, geÃ§miÅŸteki daha gÃ¶rkemli yarÄ±ÅŸmalarÄ± analiz etmek yerine, bu yarÄ±ÅŸmalarda ortaya Ã§Ä±kan kod ve tartÄ±ÅŸmalar gÃ¶zlemlenerek yazÄ±lmÄ±ÅŸtÄ±r. BelirttiÄŸimiz gibi, deÄŸiÅŸen profesyonel ortam gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, tablosal yarÄ±ÅŸmalarÄ±n gerÃ§ekten ortadan kalktÄ±ÄŸÄ±na ve geÃ§miÅŸten ziyade **ÅŸimdiki zamana iliÅŸkin Ã¶neri ve ipuÃ§larÄ±nÄ±** okumanÄ±n sizin iÃ§in daha yararlÄ± olacaÄŸÄ±na inanÄ±yoruz.

Kaggle puanlarÄ± ve madalyalarÄ± iÃ§eren diÄŸer tam teÅŸekkÃ¼llÃ¼ yarÄ±ÅŸmalarda olduÄŸu gibi, tablosal yarÄ±ÅŸmalarda da kitabÄ±n baÅŸka bir yerinde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z basit ama Ã§ok etkili bir sÃ¼reÃ§ (pipeline) izlemenizi Ã¶neririz:

  * **KeÅŸifÃ§i Veri Analizi (EDA)**
  * **Veri HazÄ±rlama**
  * **Modelleme** (model doÄŸrulamasÄ± iÃ§in bir Ã§apraz doÄŸrulama stratejisi kullanarak)
  * **Ä°ÅŸlem SonrasÄ± (Post-processing)**
  * **GÃ¶nderim (Submission)**

Kural olarak, ayrÄ±ca **tekrarlanabilirliÄŸi** saÄŸlamaya ve tÃ¼m modelleri (her bir katmandan/fold'dan), kullanÄ±lan parametrelerin listesini, tÃ¼m katman tahminlerini, katman dÄ±ÅŸÄ± (out-of-fold) tahminlerin tÃ¼mÃ¼nÃ¼ ve tÃ¼m veriler Ã¼zerinde eÄŸitilmiÅŸ modellerden gelen tÃ¼m tahminleri kaydetmeye Ã¶zen gÃ¶stermelisiniz.

TÃ¼m bu bilgileri, Ã¶rneÄŸin uygun etiketleme kullanarak, **MD5 karma deÄŸerlerini** takip ederek (ayrÄ±ntÄ±lar iÃ§in bu Stack Overflow yanÄ±tÄ±na bakabilirsiniz: [https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python](https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python)) ve her deneyden elde edilen **CV puanlarÄ±nÄ± ve liderlik tablosu sonuÃ§larÄ±nÄ±** izleyerek, kurtarÄ±lmasÄ± ve yeniden yapÄ±landÄ±rÄ±lmasÄ± kolay olacak ÅŸekilde kaydetmelisiniz. Kaggle kullanÄ±cÄ±larÄ±nÄ±n Ã§oÄŸu bunu .txt dosyalarÄ± veya Excel elektronik tablolarÄ± gibi basit araÃ§larla yapar, ancak aÅŸaÄŸÄ±dakiler gibi daha sofistike yollar da mevcuttur:

  * DVC ([https://dvc.org/](https://dvc.org/))
  * Weights and Biases ([https://wandb.ai/site](https://wandb.ai/site))
  * MLflow ([https://mlflow.org/](https://mlflow.org/))
  * Neptune ([https://neptune.ai/experiment-tracking](https://neptune.ai/experiment-tracking))

SonuÃ§ta, Ã¶nemli olan kullandÄ±ÄŸÄ±nÄ±z araÃ§ deÄŸil, **sonuÃ§lardÄ±r**, bu yÃ¼zden bir yarÄ±ÅŸmanÄ±n heyecanÄ± iÃ§inde bile deneylerinizde ve modellerinizde dÃ¼zeni saÄŸlamak iÃ§in elinizden geleni yapÄ±n.

Devam etmeden Ã¶nce, Kaggle'Ä±n bu yarÄ±ÅŸmalar iÃ§in verileri oluÅŸturmak iÃ§in kullandÄ±ÄŸÄ± teknolojiyi de dÃ¼ÅŸÃ¼nÃ¼n; **verilerin nasÄ±l oluÅŸturulduÄŸunu doÄŸru bir ÅŸekilde anlayabilirseniz**, Ã¶nemli bir avantaj elde edersiniz. Buna ek olarak, sentetik verilerin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamak, gerÃ§ek dÃ¼nyada veri bilimi yapma ÅŸekliniz Ã¼zerinde gerÃ§ekten bir etki yaratabilir, Ã§Ã¼nkÃ¼ size eÄŸitim iÃ§in daha Ã§eÅŸitli verileri kolayca elde etme yolu sunar.

> Ã–rneÄŸin, **Google Brain â€“ Ventilator Pressure Prediction** yarÄ±ÅŸmasÄ±nÄ± ([https://www.kaggle.com/c/ventilator-pressure-prediction](https://www.kaggle.com/c/ventilator-pressure-prediction)) ele alalÄ±m. Bu yarÄ±ÅŸmada, mekanik ventilasyon kontrolÃ¼ iÃ§in makine Ã¶ÄŸrenimi geliÅŸtirmeniz gerekiyordu.
>
> SaÄŸlanan verileri derin Ã¶ÄŸrenme ile modelleyerek iyi sonuÃ§lar elde edebilmenize raÄŸmen, verilerin sentetik kÃ¶keni gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, **Ã¼retici sÃ¼recini tersine mÃ¼hendislikle Ã§Ã¶zebilir** ve Jun Koda'nÄ±n ([https://www.kaggle.com/junkoda](https://www.kaggle.com/junkoda)) yaptÄ±ÄŸÄ± ve gÃ¶nderisinde aÃ§Ä±kladÄ±ÄŸÄ± gibi liderlik tablosunda en Ã¼st sÄ±ralarda yer alan bir sonuÃ§ elde edebilirdiniz: [https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285278](https://www.google.com/search?q=https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285278).

Yapay verileri kendi baÅŸÄ±nÄ±za Ã¼retmek ve sentetik verileri anlamak hiÃ§ bu kadar kolay olmamÄ±ÅŸtÄ±; Dariush Bahrami ([https://www.kaggle.com/dariushbahrami](https://www.kaggle.com/dariushbahrami)) tarafÄ±ndan orijinal olarak kodlanmÄ±ÅŸ ve test edilmiÅŸ bir Notebook'tan tÃ¼retilen bu Notebook'tan ([https://www.kaggle.com/lucamassaron/how-to-use-ctgan-to-generate-more-data](https://www.kaggle.com/lucamassaron/how-to-use-ctgan-to-generate-more-data)) doÄŸrulayabilirsiniz.

### Setting a random state for reproducibility *(Tekrarlanabilirlik iÃ§in rastgele durum belirleme)*

Tablosal bir yarÄ±ÅŸmada kullanabileceÄŸiniz adÄ±mlarÄ± ve modelleri tartÄ±ÅŸmaya baÅŸlamadan Ã¶nce, yukarÄ±da bahsettiÄŸimiz **tekrarlanabilirlik** temasÄ±na geri dÃ¶nmek faydalÄ± olacaktÄ±r.

Kaggle Notebook'larÄ±nda gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z Ã§oÄŸu komutta, **rastgele durum (random state)** olarak bir sayÄ±, yani bir **Ã§ekirdek (seed)** bildiren bir parametre bulacaksÄ±nÄ±z. Bu ayar, sonuÃ§larÄ±nÄ±zÄ±n **tekrarlanabilirliÄŸi** iÃ§in Ã¶nemlidir. BirÃ§ok algoritma deterministik (belirlenimci) deÄŸil, rastgeleliÄŸe dayandÄ±ÄŸÄ± iÃ§in, bir Ã§ekirdek ayarlayarak rastgele Ã¼reticinin davranÄ±ÅŸÄ±nÄ± etkiler, bÃ¶ylece rastgeleliÄŸini **Ã¶ngÃ¶rÃ¼lebilir** hale getirirsiniz: aynÄ± rastgele Ã§ekirdek, aynÄ± rastgele sayÄ± dizisine karÅŸÄ±lÄ±k gelir. BaÅŸka bir deyiÅŸle, aynÄ± kodun her Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±ndan sonra aynÄ± sonuÃ§larÄ± almanÄ±zÄ± saÄŸlar.

Bu nedenle, Scikit-learn'deki tÃ¼m makine Ã¶ÄŸrenimi algoritmalarÄ±nda ve Scikit-learn uyumlu tÃ¼m modellerde (en popÃ¼ler olanlardan bahsetmek gerekirse, Ã¶rneÄŸin **XGBoost, LightGBM** ve **CatBoost**) bir rastgele Ã§ekirdek ayarlama parametresi bulursunuz.

SonuÃ§larÄ±n tekrarlanabilirliÄŸi, gerÃ§ek dÃ¼nya projelerinde olduÄŸu kadar Kaggle yarÄ±ÅŸmalarÄ±nda da Ã¶nemlidir. GerÃ§ek dÃ¼nyada, tekrarlanabilir bir modele sahip olmak, model geliÅŸtirmenin daha iyi izlenmesine ve tutarlÄ±lÄ±ÄŸa olanak tanÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda, tekrarlanabilirlik, modellerinizdeki herhangi bir varyasyon kaynaÄŸÄ±nÄ± kontrol ettiÄŸiniz iÃ§in **hipotezleri daha iyi test etmenize** yardÄ±mcÄ± olur. Ã–rneÄŸin, yeni bir Ã¶zellik oluÅŸturduysanÄ±z, bunu tekrarlanabilir bir sÃ¼rece (pipeline) dahil etmek, Ã¶zelliÄŸin avantajlÄ± olup olmadÄ±ÄŸÄ±nÄ± anlamanÄ±za yardÄ±mcÄ± olacaktÄ±r. Modeldeki herhangi bir iyileÅŸmenin veya kÃ¶tÃ¼leÅŸmenin yalnÄ±zca Ã¶zelliÄŸe atfedilebileceÄŸinden ve modeli en son Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan beri deÄŸiÅŸen bazÄ± rastgele sÃ¼reÃ§lerin etkilerine atfedilemeyeceÄŸinden emin olursunuz.

Yine, tekrarlanabilirlik **halka aÃ§Ä±k Notebook'larla** uÄŸraÅŸÄ±rken sizin avantajÄ±nÄ±za kullanÄ±labilir. Ã‡oÄŸu zaman, bu Notebook'lar **0, 1 veya 42** gibi sabit bir Ã§ekirdeÄŸe sahip olacaktÄ±r. **42** deÄŸeri oldukÃ§a popÃ¼lerdir Ã§Ã¼nkÃ¼ Douglas Adam'Ä±n *OtostopÃ§unun Galaksi Rehberi*'ne bir gÃ¶ndermedir; kitapta, 7,5 milyon yÄ±llÄ±k bir sÃ¼re boyunca Deep Thought adlÄ± devasa bir sÃ¼per bilgisayar tarafÄ±ndan hesaplanan "HayatÄ±n, Evrenin ve Her Åeyin Nihai Sorununa Cevap"tÄ±r. Åimdi, bir yarÄ±ÅŸmadaki herkes aynÄ± rastgele Ã§ekirdeÄŸi kullanÄ±yorsa, bunun Ã§ifte bir etkisi olabilir:

* Rastgele Ã§ekirdek, halka aÃ§Ä±k liderlik tablosuyla **Ã§ok iyi Ã§alÄ±ÅŸÄ±yor olabilir**, bu da **aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting)** anlamÄ±na gelir.
* BirÃ§ok Kaggle kullanÄ±cÄ±sÄ± benzer sonuÃ§lar Ã¼retecek ve bu da onlarÄ±n Ã¶zel liderlik tablosundaki sÄ±ralamalarÄ±nÄ± aynÄ± ÅŸekilde etkileyecektir.

Rastgele Ã§ekirdeÄŸi deÄŸiÅŸtirerek, aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemiÅŸ ve aynÄ± zamanda **sÄ±ralamayÄ± bozmuÅŸ** olursunuz; baÅŸka bir deyiÅŸle, herkesten farklÄ± sonuÃ§lar alÄ±rsÄ±nÄ±z, bu da sonuÃ§ta size bir avantaj saÄŸlayabilir. Ek olarak, bir Kaggle yarÄ±ÅŸmasÄ±nÄ± kazanÄ±rsanÄ±z, modellerinizin kazanan gÃ¶nderimi nasÄ±l Ã¼rettiÄŸini gÃ¶stermeniz gerekir, bu nedenle Ã¶dÃ¼lÃ¼nÃ¼zÃ¼ hÄ±zlÄ± bir ÅŸekilde almak istiyorsanÄ±z her ÅŸeyin tamamen **tekrarlanabilir** olmasÄ± Ã§ok Ã¶nemlidir.

**TensorFlow** ve **PyTorch** modelleri aÃ§Ä±kÃ§a bir rastgele Ã§ekirdek parametresi kullanmaz, bu nedenle bunlarÄ±n tam tekrarlanabilirliÄŸini saÄŸlamak daha zordur. AÅŸaÄŸÄ±daki kod parÃ§acÄ±ÄŸÄ±, Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda TensorFlow ve PyTorch modelleri iÃ§in aynÄ± rastgele Ã§ekirdeÄŸi ayarlar:

```python
def seed_everything(seed,
                    tensorflow_init=True,
                    pytorch_init=True):
    """
    SonuÃ§larÄ±n tekrarlanabilirliÄŸi iÃ§in temel parametreleri Ã§ekirdekler.
    """
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    if tensorflow_init is True:
        tf.random.set_seed(seed)
    if pytorch_init is True:
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
```

Scikit-learn'e gelince, bunun yerine, izin verildiÄŸi durumlarda, **`random_state`** parametresini kullanarak rastgele Ã§ekirdeÄŸi doÄŸrudan sÄ±nÄ±fta veya fonksiyonda ayarlamak tavsiye edilir.

### The importance of EDA *(KeÅŸifsel veri analizinin Ã¶nemi)*

**EDA** terimi, modern istatistiksel metodolojinin en Ã¶nde gelen temsilcilerinden biri olan **John W. Tukey**'in Ã§alÄ±ÅŸmalarÄ±ndan gelmektedir. Tukey, 1977 tarihli *Exploratory Data Analysis* (dolayÄ±sÄ±yla EDA kÄ±saltmasÄ±) adlÄ± kitabÄ±nda, EDA'yÄ± veriyi keÅŸfetme, kanÄ±tlarÄ± ortaya Ã§Ä±karma ve daha sonra istatistiksel testlerle doÄŸrulanabilecek **hipotezler geliÅŸtirme** yolu olarak dÃ¼ÅŸÃ¼nÃ¼r.

Onun fikri, istatistiksel hipotezleri nasÄ±l tanÄ±mladÄ±ÄŸÄ±mÄ±zÄ±n, yalnÄ±zca matematiksel hesaplamalara dayalÄ± sÄ±ralÄ± testlerden ziyade **gÃ¶zlem ve muhakemeye** daha fazla dayanabileceÄŸiydi. Bu fikir, makine Ã¶ÄŸrenimi dÃ¼nyasÄ±na iyi bir ÅŸekilde tercÃ¼me edilir, Ã§Ã¼nkÃ¼ bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸacaÄŸÄ±mÄ±z gibi, Ã¶ÄŸrenme algoritmalarÄ±nÄ±n daha iyi ve daha verimli Ã§alÄ±ÅŸabilmesi iÃ§in veriler iyileÅŸtirilebilir ve Ã¶nceden sindirilebilir.

Bir Kaggle yarÄ±ÅŸmasÄ± iÃ§in yapÄ±lan EDA'da ÅŸunlarÄ± arayacaksÄ±nÄ±z:

  * **Eksik deÄŸerler** ve en Ã¶nemlisi, hedef (target) ile iliÅŸkili eksik deÄŸer **Ã¶rÃ¼ntÃ¼leri**.
  * **Ã‡arpÄ±k (skewed) sayÄ±sal deÄŸiÅŸkenler** ve bunlarÄ±n olasÄ± dÃ¶nÃ¼ÅŸÃ¼mleri.
  * **Birlikte gruplandÄ±rÄ±labilecek** kategorik deÄŸiÅŸkenlerdeki **nadir kategoriler**.
  * Hem tek deÄŸiÅŸkenli (univariate) hem de Ã§ok deÄŸiÅŸkenli (multivariate) **potansiyel aykÄ±rÄ± deÄŸerler** (outliers).
  * **YÃ¼ksek dÃ¼zeyde korelasyonlu** (hatta yinelenen) **Ã¶zellikler**. Kategorik deÄŸiÅŸkenler iÃ§in, **Ã¶rtÃ¼ÅŸen kategorilere** odaklanÄ±n.
  * Problem iÃ§in **en Ã§ok tahmin edici** olan Ã¶zellikler.

Bunu, Ã§eÅŸitli tanÄ±mlayÄ±cÄ± analizler, grafikler ve Ã§izelgeler aracÄ±lÄ±ÄŸÄ±yla baÅŸarÄ±rsÄ±nÄ±z; Ã¶nce her bir ayrÄ± Ã¶zelliÄŸi (istatistiksel terimlerle **tek deÄŸiÅŸkenli analiz**), ardÄ±ndan birkaÃ§ deÄŸiÅŸkeni eÅŸleÅŸtirerek (**iki deÄŸiÅŸkenli analiz**, Ã¶rneÄŸin bir daÄŸÄ±lÄ±m grafiÄŸinde) ve son olarak daha fazla Ã¶zelliÄŸi aynÄ± anda birlikte ele alarak (**Ã§ok deÄŸiÅŸkenli yaklaÅŸÄ±m**) incelersiniz.

-----

**ğŸš€ Otomatik EDA AraÃ§larÄ±**

Tembel hissediyorsanÄ±z veya nasÄ±l ve nereden baÅŸlayacaÄŸÄ±nÄ±zdan emin deÄŸilseniz, baÅŸlangÄ±Ã§ta **otomatik stratejilere** gÃ¼venmek size yardÄ±mcÄ± olabilir. Ã–rneÄŸin, popÃ¼ler bir hÄ±zlÄ± EDA Ã¼cretsiz yazÄ±lÄ±m aracÄ± olan **AutoViz** ([https://github.com/AutoViML/AutoViz](https://github.com/AutoViML/AutoViz)) size Ã§ok zaman kazandÄ±rabilir. AÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rarak onu Notebook'unuza kurabilirsiniz:

```bash
pip install git+git://github.com/AutoViML/AutoViz.git 
```

> AutoViz'in sizin iÃ§in neler yapabileceÄŸine dair daha net bir anlayÄ±ÅŸ elde etmek iÃ§in Dan Roth'un bu Medium makalesini ([https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad](https://www.google.com/search?q=https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad)) okuyabilir veya Georgii Vyshnia'nÄ±n ([https://www.kaggle.com/gvyshnya](https://www.kaggle.com/gvyshnya)) [https://www.kaggle.com/gvyshnya/automating-eda-and-feature-importance-detection](https://www.google.com/search?q=https://www.kaggle.com/gvyshnya/automating-eda-and-feature-importance-detection) gibi birkaÃ§ ilginÃ§ genel Notebook'a gÃ¶z atabilirsiniz.
>
> Ä°kinci baÄŸlantÄ±da, baÅŸka bir araÃ§ olan **Sweetviz**'e ([https://github.com/fbdesignpro/sweetviz](https://github.com/fbdesignpro/sweetviz)) de referanslar bulacaksÄ±nÄ±z. Sweetviz'in Titanic veri setine dayalÄ± bir genel bakÄ±ÅŸ makalesi ve eÄŸitim iÃ§eriÄŸi vardÄ±r: [https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34](https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34). KullanÄ±ÅŸlÄ± bulabileceÄŸiniz bir diÄŸer popÃ¼ler araÃ§ ise, bu makalede aÃ§Ä±klandÄ±ÄŸÄ± gibi, klasik istatistiksel tanÄ±mlayÄ±cÄ± istatistiklere ve gÃ¶rselleÅŸtirmeye daha fazla dayanan **Pandas Profiling**'dir ([https://github.com/pandas-profiling/pandas-profiling](https://github.com/pandas-profiling/pandas-profiling)): [https://medium.com/analytics-vidhya/pandas-profiling-5ecd0b977ecd](https://medium.com/analytics-vidhya/pandas-profiling-5ecd0b977ecd).

**ğŸ’¡ En Ã–nemli Ä°pucu: Ã–zelleÅŸtirme**

DiÄŸer Kaggle kullanÄ±cÄ±larÄ±nÄ±n ilginÃ§ EDA Notebook'larÄ± yayÄ±nlamasÄ±nÄ± beklemek de bir Ã§Ã¶zÃ¼m olabilir, bu yÃ¼zden her zaman Notebook bÃ¶lÃ¼mlerini takip edin; bazen deÄŸerli ipuÃ§larÄ± ortaya Ã§Ä±kabilir. Bu, modelleme aÅŸamanÄ±zÄ± baÅŸlatmalÄ± ve yarÄ±ÅŸmanÄ±n temel yapÄ±lmasÄ± ve yapÄ±lmamasÄ± gerekenlerini anlamanÄ±za yardÄ±mcÄ± olmalÄ±dÄ±r.

Ancak, unutmayÄ±n ki EDA, eldeki **probleme yÃ¼ksek oranda Ã¶zgÃ¼ olduÄŸunda** bir metadan Ã§Ä±kÄ±p yarÄ±ÅŸma iÃ§in bir **varlÄ±k (asset)** haline gelir; bu, otomatik Ã§Ã¶zÃ¼mlerde asla bulamayacaÄŸÄ±nÄ±z ve genel Notebook'larda nadiren karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z bir ÅŸeydir. **Kendi EDA'nÄ±zÄ± yapmalÄ±** ve kilit, kazandÄ±ran iÃ§gÃ¶rÃ¼leri toplamalÄ±sÄ±nÄ±z.

TÃ¼m bunlar gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, Ã¶nerimiz, Ã¶ÄŸrenilmesi ve Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± gerÃ§ekten kolay olduklarÄ± iÃ§in **otomatik araÃ§lara** biraz bakmanÄ±zdÄ±r. Bu, size, onun yerine grafiklere bakarak ve olasÄ± iÃ§gÃ¶rÃ¼ler hakkÄ±nda akÄ±l yÃ¼rÃ¼terek geÃ§irebileceÄŸiniz bolca zaman kazandÄ±racaktÄ±r ve bu da rekabet performansÄ±nÄ±za kesinlikle yardÄ±mcÄ± olacaktÄ±r.

Ancak, bunu yaptÄ±ktan sonra, **Matplotlib** ve **Seaborn**'u almalÄ± ve saÄŸlanan veri tÃ¼rÃ¼ne ve probleme baÄŸlÄ± olan standart dÄ±ÅŸÄ± Ã§izimler Ã¼zerinde kendiniz bir ÅŸeyler denemelisiniz.

> Ã–rneÄŸin, zaman iÃ§inde gerÃ§ekleÅŸtirilen bir dizi Ã¶lÃ§Ã¼m size verilirse, daha iyi tahminler iÃ§in aÃ§Ä±ÄŸa Ã§Ä±karÄ±cÄ± iÃ§gÃ¶rÃ¼lere iÅŸaret edebilecek bir olgu olan, bir gÃ¶zlem ile diÄŸeri arasÄ±ndaki farklÄ± gecikmeleri gÃ¶stererek, **tek kaydedilen zaman noktalarÄ±nÄ± Ã§izmek** kadar **zamana dayalÄ± sÃ¼rekli fonksiyonu Ã§izmek** de faydalÄ±dÄ±r.

### Dimensionality reduction with t-SNE and UMAP *(t-SNE ve UMAP ile boyut indirgeme)*

EDA yaparken oluÅŸturabileceÄŸiniz pek Ã§ok olasÄ± grafik vardÄ±r ve amacÄ±mÄ±z bunlarÄ±n hepsini burada listelemek deÄŸildir, ancak Ã§ok spesifik ve verilere Ã¶zel Ã§izelgeler kadar bilgi saÄŸlayabilecek, Ã¼zerinde birkaÃ§ sÃ¶z harcamaya deÄŸer birkaÃ§ **boyut indirgeme grafiÄŸi** bulunmaktadÄ±r. Bunlar **t-SNE** ([https://lvdmaaten.github.io/tsne/](https://lvdmaaten.github.io/tsne/)) ve **UMAP** ([https://github.com/lmcinnes/umap)'tÄ±r](https://github.com/lmcinnes/umap)'tÄ±r).

t-SNE ve UMAP, veri bilimcileri tarafÄ±ndan sÄ±klÄ±kla kullanÄ±lan ve Ã§ok deÄŸiÅŸkenli verileri **daha dÃ¼ÅŸÃ¼k boyutlara yansÄ±tmanÄ±za** olanak tanÄ±yan iki tekniktir. Genellikle karmaÅŸÄ±k veri setlerini iki boyutta temsil etmek iÃ§in kullanÄ±lÄ±rlar. 2 boyutlu UMAP ve t-SNE grafikleri, veri probleminiz iÃ§in **aykÄ±rÄ± deÄŸerlerin (outliers)** ve **ilgili kÃ¼melerin (clusters)** varlÄ±ÄŸÄ±nÄ± ortaya Ã§Ä±karabilir.

> Zaman iÃ§inde gerÃ§ekleÅŸtirilen bir dizi Ã¶lÃ§Ã¼m size verilirse, daha iyi tahminler iÃ§in aÃ§Ä±ÄŸa Ã§Ä±karÄ±cÄ± iÃ§gÃ¶rÃ¼lere iÅŸaret edebilecek bir olgu olan, bir gÃ¶zlem ile diÄŸeri arasÄ±ndaki farklÄ± gecikmeleri gÃ¶stererek, tek kaydedilen zaman noktalarÄ±nÄ± Ã§izmek kadar zamana dayalÄ± sÃ¼rekli fonksiyonu Ã§izmek de faydalÄ±dÄ±r.

AslÄ±nda, ortaya Ã§Ä±kan **2 boyutlu yansÄ±tmanÄ±n daÄŸÄ±lÄ±m grafiÄŸini Ã§izebilir** ve onu hedef deÄŸere gÃ¶re renklendirebilirseniz, grafik size **alt gruplarla baÅŸa Ã§Ä±kmak iÃ§in olasÄ± stratejiler** hakkÄ±nda ipuÃ§larÄ± verebilir.

Bir gÃ¶rÃ¼ntÃ¼ yarÄ±ÅŸmasÄ±yla ilgili olmasÄ±na raÄŸmen, UMAP ve t-SNE'nin verilerinizi daha iyi anlamanÄ±za nasÄ±l yardÄ±mcÄ± olabileceÄŸinin iyi bir Ã¶rneÄŸi, Chris Deotte'nin SIIM-ISIC Melanoma SÄ±nÄ±flandÄ±rma yarÄ±ÅŸmasÄ± iÃ§in yaptÄ±ÄŸÄ± analizdir (bkz. [https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/168028](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/168028)). Bu Ã¶rnekte, Chris eÄŸitim ve test verilerini aynÄ± dÃ¼ÅŸÃ¼k boyutlu yansÄ±tmalarda iliÅŸkilendirmiÅŸ, yalnÄ±zca test Ã¶rneklerinin bulunduÄŸu kÄ±sÄ±mlarÄ± vurgulamÄ±ÅŸtÄ±r.

> UMAP ve t-SNE, verilerde bulunmasÄ± zor olan Ã¶rÃ¼ntÃ¼leri keÅŸfetmede paha biÃ§ilmez bir yardÄ±m sunsa da, onlarÄ± modelleme Ã§abalarÄ±nÄ±zda **Ã¶zellikler** olarak da kullanabilirsiniz. Bu kullanÄ±mÄ±n ilginÃ§ bir Ã¶rneÄŸi, Mike Kim'in t-SNE yansÄ±tÄ±mlarÄ±nÄ± yarÄ±ÅŸma iÃ§in eÄŸitim Ã¶zellikleri olarak kullandÄ±ÄŸÄ± Otto Group ÃœrÃ¼n SÄ±nÄ±flandÄ±rma YarÄ±ÅŸmasÄ±'nda gÃ¶sterilmiÅŸtir ([https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295](https://www.google.com/search?q=https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295)).

-----

**âš ï¸ Dikkat Edilmesi Gerekenler ve Ä°yileÅŸtirmeler**

*How to t-SNE Effectively* ([https://distill.pub/2016/misread-tsne/](https://distill.pub/2016/misread-tsne/)) makalesinde belirtildiÄŸi gibi, bu teknikleri doÄŸru bir ÅŸekilde kullanmanÄ±z gerekir, Ã§Ã¼nkÃ¼ **olmayan yerlerde kÃ¼meler ve Ã¶rÃ¼ntÃ¼ler gÃ¶rmek kolaydÄ±r**. AynÄ± uyarÄ± UMAP iÃ§in de geÃ§erlidir, Ã§Ã¼nkÃ¼ yanlÄ±ÅŸ okunabilecek grafikler de Ã¼retebilir. [https://pair-code.github.io/understanding-umap/](https://pair-code.github.io/understanding-umap/) gibi kÄ±lavuzlar, hem UMAP hem de t-SNE'nin gerÃ§ek dÃ¼nya verileri Ã¼zerindeki performansÄ± hakkÄ±nda saÄŸlam tavsiyeler sunarak Ã¶neriler ve uyarÄ±lar saÄŸlar.

Bu tehlikelere raÄŸmen, deneyimlerimize gÃ¶re, bu yaklaÅŸÄ±mlar PCA veya SVD gibi **doÄŸrusal kombinasyonla varyans yeniden yapÄ±landÄ±rmasÄ±na dayanan klasik yÃ¶ntemlerden kesinlikle daha aÃ§Ä±klayÄ±cÄ±dÄ±r**. Bu yaklaÅŸÄ±mlarla karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, UMAP ve t-SNE, verilerin topografyasÄ±nÄ± korurken sonuÃ§larÄ±n gÃ¶rsel olarak Ã§izilmesine izin vererek, boyutu aÅŸÄ±rÄ± derecede azaltmayÄ± baÅŸarÄ±r. Yan etki olarak, uydurulmalarÄ± (fit) Ã§ok daha yavaÅŸtÄ±r. Ancak, NVIDIA, bir GPU destekli Notebook veya betik kullanarak hem UMAP hem de t-SNE sonuÃ§larÄ±nÄ± Ã§ok makul bir zaman diliminde geri dÃ¶ndÃ¼ren ve etkili bir EDA aracÄ± olarak kullanÄ±mlarÄ±na izin veren CUDA tabanlÄ± **RAPIDS** paketini ([https://developer.nvidia.com/rapids](https://developer.nvidia.com/rapids)) yayÄ±nladÄ±.

> Hem UMAP hem de t-SNE'yi bir RAPIDS uygulamasÄ± ve GPU ile veri keÅŸif amaÃ§lÄ± uygulamanÄ±n yararlÄ± bir Ã¶rneÄŸini 30 GÃ¼n ML yarÄ±ÅŸmasÄ± iÃ§in aÅŸaÄŸÄ±daki baÄŸlantÄ±da bulabilirsiniz: [https://www.kaggle.com/lucamassaron/interesting-eda-tsne-umap/](https://www.google.com/search?q=https://www.kaggle.com/lucamassaron/interesting-eda-tsne-umap/).

YukarÄ±daki Ã¶rnek Notebook'un Ã§Ä±ktÄ±sÄ± olan ÅŸekilde, veri kÃ¼mesini birden Ã§ok kÃ¼menin nasÄ±l doldurduÄŸunu gÃ¶rebilirsiniz, ancak bunlarÄ±n hiÃ§biri hedefle belirli bir iliÅŸkiyi ortaya Ã§Ä±karacak ÅŸekilde kabul edilemez:

![](im/1057.png)

BaÅŸka bir Notebook'ta ([https://www.kaggle.com/lucamassaron/really-not-missing-at-random](https://www.google.com/search?q=https://www.kaggle.com/lucamassaron/really-not-missing-at-random)), aynÄ± teknikler bunun yerine **eksik Ã¶rneklere ait ikili gÃ¶stergelere** uygulanmÄ±ÅŸ ve belirli bir yanÄ±t tÃ¼rÃ¼nÃ¼n hakim olduÄŸu spesifik ve ayrÄ± alanlara iÅŸaret eden dÃ¼ÅŸÃ¼ndÃ¼rÃ¼cÃ¼ figÃ¼rler ortaya Ã§Ä±karmÄ±ÅŸtÄ±r. GerÃ§ekten de, o Ã¶rnekte, eksik Ã¶rnekler rastgele oluÅŸmamÄ±ÅŸ ve oldukÃ§a tahmin edici olmuÅŸtur:

![](im/1058.png)

### Reducing the size of your data *(Veri boyutunu kÃ¼Ã§Ã¼ltme)*

**ğŸ’¾ Verilerinizin Boyutunu KÃ¼Ã§Ã¼ltme (Bellek KullanÄ±mÄ±nÄ± Azaltma)**

Kaggle Notebook'larÄ±nda doÄŸrudan Ã§alÄ±ÅŸÄ±yorsanÄ±z, bunlarÄ±n sÄ±nÄ±rlamalarÄ± oldukÃ§a can sÄ±kÄ±cÄ± gelebilir ve bunlarla uÄŸraÅŸmak zaman kaybÄ±na neden olabilir. Bu sÄ±nÄ±rlamalardan biri, yÃ¼rÃ¼tmeyi durduracak ve betiÄŸi baÅŸtan baÅŸlatmaya zorlayacak olan **bellek yetersizliÄŸi (out-of-memory)** hatalarÄ±dÄ±r. Bu, birÃ§ok yarÄ±ÅŸmada oldukÃ§a yaygÄ±ndÄ±r. Ancak, verileri kÃ¼Ã§Ã¼k yÄ±ÄŸÄ±nlar halinde diskten alÄ±p iÅŸleyebileceÄŸiniz metin veya gÃ¶rÃ¼ntÃ¼lere dayalÄ± derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ±nÄ±n aksine, tablosal verilerle Ã§alÄ±ÅŸan algoritmalarÄ±n Ã§oÄŸu, **tÃ¼m verilerin bellekte iÅŸlenmesini** gerektirir.

En yaygÄ±n durum, Pandas'Ä±n `read_csv` iÅŸlevi kullanÄ±larak bir CSV dosyasÄ±ndan verileri yÃ¼klediÄŸinizde, ancak **DataFrame'in Ã¶zellik mÃ¼hendisliÄŸi ve makine Ã¶ÄŸrenimi iÃ§in Kaggle Notebook'unda iÅŸlenemeyecek kadar bÃ¼yÃ¼k** olmasÄ±dÄ±r. Ã‡Ã¶zÃ¼m, kullandÄ±ÄŸÄ±nÄ±z Pandas DataFrame'in boyutunu **hiÃ§bir bilgi kaybetmeden (kayÄ±psÄ±z sÄ±kÄ±ÅŸtÄ±rma)** sÄ±kÄ±ÅŸtÄ±rmaktÄ±r. Bu, Guillaume Martin'in Ã§alÄ±ÅŸmasÄ±ndan tÃ¼retilen aÅŸaÄŸÄ±daki betik kullanÄ±larak kolayca baÅŸarÄ±labilir (orijinal Notebook'u burada bulabilirsiniz: [https://www.kaggle.com/gemartin/load-data-reduce-memory-usage](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)).

```python
def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else: # float types
                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024**2
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))
    return df
```

> Guillaume Martin, Kaggle'da bÃ¶yle bir fikri Ã¶neren ilk kiÅŸi deÄŸildi. Pandas DataFrame'i sÄ±kÄ±ÅŸtÄ±rma fikrine sahip ilk Kaggle kullanÄ±cÄ±sÄ±, Zillow yarÄ±ÅŸmasÄ± sÄ±rasÄ±nda bir kÃ¼Ã§Ã¼ltme iÅŸlevi yazan Arjan Groen'di ([https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65](https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65)).

-----

**ğŸ¤” Bu YaklaÅŸÄ±m NasÄ±l Ã‡alÄ±ÅŸÄ±r?**

Bu betik, bir veri setindeki tÃ¼m **sayÄ±sal Ã¶zelliklerin** belirli bir deÄŸer aralÄ±ÄŸÄ±nda bulunmasÄ± gerÃ§eÄŸinden yararlanÄ±r. Python'da bellekte kapladÄ±klarÄ± bayt sayÄ±sÄ±na gÃ¶re farklÄ± tÃ¼rde tam sayÄ± ve kayan noktalÄ± sayÄ±sal deÄŸiÅŸkenler bulunduÄŸundan, betik her Ã¶zellikte bulunan deÄŸer aralÄ±ÄŸÄ±nÄ±, her bir sayÄ±sal tipin kabul edebileceÄŸi maksimum ve minimum deÄŸerle karÅŸÄ±laÅŸtÄ±rÄ±r. Bu, Ã¶zelliÄŸi, kendi deÄŸer aralÄ±ÄŸÄ±yla Ã§alÄ±ÅŸan ve **en az bellek gerektiren sayÄ±sal tipe** ayarlamak iÃ§in yapÄ±lÄ±r.

Bu yaklaÅŸÄ±m, Kaggle Notebook'larÄ±nda sorunsuz Ã§alÄ±ÅŸÄ±r, ancak bazÄ± uyarÄ±larla birlikte. SÄ±kÄ±ÅŸtÄ±rma yoluyla her Ã¶zellik iÃ§in en uygun sayÄ±sal tipi ayarladÄ±ktan sonra, ayarlanan sayÄ±sal tiplerin kapasitesini aÅŸan deÄŸerlerle sonuÃ§lanabilecek herhangi bir **Ã¶zellik mÃ¼hendisliÄŸi** uygulayamazsÄ±nÄ±z, Ã§Ã¼nkÃ¼ bÃ¶yle bir iÅŸlem **hatalÄ± sonuÃ§lar** Ã¼retecektir. Ã–nerimiz, bunu Ã¶zellik mÃ¼hendisliÄŸinden **sonra** veya mevcut verilerinizi yeniden Ã¶lÃ§eklendirmeyen bÃ¼yÃ¼k dÃ¶nÃ¼ÅŸÃ¼mlerden **Ã¶nce** uygulamanÄ±zdÄ±r. Bunu **Ã§Ã¶p toplama (garbage collection)** kitaplÄ±ÄŸÄ± `gc` ve `gc.collect()` metodu ile birleÅŸtirmek, Kaggle Notebook'unuzun bellek durumunu iyileÅŸtirecektir.

Verilerinizin boyutunu azaltmanÄ±n (diÄŸer ÅŸeylerin yanÄ± sÄ±ra) baÅŸka bir yolu da Ã¶zellik mÃ¼hendisliÄŸini (Ã¶zellikle **Ã¶zellik seÃ§imi** ve **veri sÄ±kÄ±ÅŸtÄ±rma**) kullanmaktÄ±r.

### Applying feature engineering *(Ã–zellik mÃ¼hendisliÄŸi uygulama)*

GerÃ§ek dÃ¼nyadaki projelerde, baÅŸarÄ±lÄ± bir makine Ã¶ÄŸrenimi modeliyle vasat bir model arasÄ±ndaki farkÄ± yaratan ÅŸey Ã§oÄŸu zaman **modelin kendisi deÄŸil, veridir**.
Veriden bahsederken, kÃ¶tÃ¼, iyi ve mÃ¼kemmel veri arasÄ±ndaki fark yalnÄ±zca **eksik deÄŸerlerin bulunmamasÄ±** veya **deÄŸerlerin gÃ¼venilirliÄŸi** (yani verinin â€œkalitesiâ€) ya da **mevcut Ã¶rnek sayÄ±sÄ±** (yani verinin â€œmiktarÄ±â€) deÄŸildir. Deneyimlerimize gÃ¶re, asÄ±l farkÄ± yaratan unsur, verinin iÃ§eriÄŸinin **bilgi deÄŸeri**dir ve bu deÄŸer **Ã¶zelliklerin (features)** tÃ¼rÃ¼yle temsil edilir.

**Ã–zellikler**, veri bilimi projelerinin ÅŸekil verilen gerÃ§ek â€œham maddesidirâ€, Ã§Ã¼nkÃ¼ modellerin sÄ±nÄ±flarÄ± ayÄ±rmak veya deÄŸerleri tahmin etmek iÃ§in kullandÄ±klarÄ± bilgi onlarda bulunur. Her modelin bir ifade gÃ¼cÃ¼ ve Ã¶zellikleri tahminlere dÃ¶nÃ¼ÅŸtÃ¼rme yeteneÄŸi vardÄ±r. Ancak eÄŸer Ã¶zellikler aÃ§Ä±sÄ±ndan yetersizseniz, hiÃ§bir model sizi kurtaramaz ve daha iyi tahminler sunamaz. Modeller yalnÄ±zca verideki deÄŸeri gÃ¶rÃ¼nÃ¼r hale getirir â€” kendileri baÅŸlÄ± baÅŸÄ±na sihirli deÄŸildir.

**Kaggle** Ã¼zerinde, nadir yarÄ±ÅŸmalar dÄ±ÅŸÄ±nda tÃ¼m katÄ±lÄ±mcÄ±lar baÅŸlangÄ±Ã§ta aynÄ± veriye sahiptir. Bu noktada farkÄ± yaratan, **veriyi nasÄ±l iÅŸlediÄŸinizdir**. Elinizdeki veriyi iyileÅŸtirebileceÄŸinizi gÃ¶z ardÄ± etmek, birÃ§ok Kaggle katÄ±lÄ±mcÄ±sÄ±nÄ±n yaptÄ±ÄŸÄ± yaygÄ±n bir hatadÄ±r. **Ã–zellik mÃ¼hendisliÄŸi (feature engineering)**, veriyi modeller iÃ§in daha yararlÄ± bilgilere dÃ¶nÃ¼ÅŸtÃ¼rmeye yÃ¶nelik teknikler bÃ¼tÃ¼nÃ¼dÃ¼r ve yarÄ±ÅŸmalarda daha iyi performans elde etmenin deÄŸiÅŸmez anahtarÄ±dÄ±r. En gÃ¼Ã§lÃ¼ modeller bile, verinin daha anlaÅŸÄ±lÄ±r bir biÃ§imde iÅŸlenmesini gerektirir.

Ã–zellik mÃ¼hendisliÄŸi aynÄ± zamanda, genellikle konuya Ã¶zel uzmanlÄ±k bilgisi olan **Ã¶n bilgileri** veriye dahil etmenin bir yoludur. Mevcut Ã¶zellikleri toplamak, Ã§Ä±karmak veya bÃ¶lmek gibi iÅŸlemlerle, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z problemi daha iyi aÃ§Ä±klayan gÃ¶stergeler veya tahminler elde edebilirsiniz.

Ã–zellik mÃ¼hendisliÄŸinin, Kaggle yarÄ±ÅŸmalarÄ±nda o kadar Ã¶nemli olmasa da, **gerÃ§ek dÃ¼nya projelerinde deÄŸerli olabilecek baÅŸka amaÃ§larÄ±** da vardÄ±r.
Birincisi, eÄŸitim verisinin boyutunu azaltmaktÄ±r (bu, Ã¶zellikle bellek sÄ±nÄ±rlamalarÄ± olan Kaggle Notebook ortamlarÄ±nda da faydalÄ± olabilir).
Ä°kincisi ise, sonuÃ§ modelinin **yorumlanabilirliÄŸini artÄ±rmaktÄ±r** â€” yani insanlar tarafÄ±ndan daha kolay anlaÅŸÄ±labilen Ã¶zellikler kullanmak.

Her alan, uzmanlarÄ± tarafÄ±ndan bilinen fakat kendiliÄŸinden fark edilmeyen belirli **deÄŸiÅŸken dÃ¶nÃ¼ÅŸÃ¼mlerine** sahip olabilir. Ã–rneÄŸin, finans alanÄ±nda, piyasa ve ÅŸirket verilerini temsil eden farklÄ± Ã¶zellik kÃ¼melerinde sinyali gÃ¼rÃ¼ltÃ¼den ayÄ±rmak iÃ§in **Kalman filtreleri** veya **dalgacÄ±k dÃ¶nÃ¼ÅŸÃ¼mleri (wavelet transformations)** gibi Ã¶zel dÃ¶nÃ¼ÅŸÃ¼mler uygulanÄ±r.

Ã‡ok sayÄ±da alan ve karmaÅŸÄ±k Ã¶zellik mÃ¼hendisliÄŸi yÃ¶ntemleri bulunduÄŸundan, bu bÃ¶lÃ¼mde belirli alanlara Ã¶zgÃ¼ tekniklere girmeyeceÄŸiz. Bunun yerine, **her tÃ¼rlÃ¼ tablo (tabular) verisi yarÄ±ÅŸmasÄ±nda uygulanabilecek en yaygÄ±n ve genel teknikleri** sunacaÄŸÄ±z.

#### Easily derived features *(Kolay tÃ¼retilen Ã¶zellikler)*

DÃ¶nÃ¼ÅŸÃ¼mler yoluyla Ã¶zellikler tÃ¼retmek, **en basit ama genellikle en etkili** yaklaÅŸÄ±mdÄ±r.
Ã–rneÄŸin, **Ã¶zellik oranlarÄ±nÄ±** (bir Ã¶zelliÄŸi diÄŸerine bÃ¶lmek) hesaplamak oldukÃ§a etkili olabilir, Ã§Ã¼nkÃ¼ birÃ§ok algoritma (Ã¶rneÄŸin *gradient boosting*) bu tÃ¼r bÃ¶lme iÅŸlemlerini doÄŸrudan taklit edemez veya (Ã¶rneÄŸin derin sinir aÄŸlarÄ± gibi) bunu yapmakta zorlanabilir.
Denemeye deÄŸer en yaygÄ±n dÃ¶nÃ¼ÅŸÃ¼mler aÅŸaÄŸÄ±da listelenmiÅŸtir:

---

* **Zaman Ã–zelliklerinin Ä°ÅŸlenmesi (Time Feature Processing):**

Bir tarihi bileÅŸenlerine (yÄ±l, ay, gÃ¼n) ayÄ±rmak; yÄ±lÄ± haftalara veya haftanÄ±n gÃ¼nlerine dÃ¶nÃ¼ÅŸtÃ¼rmek; tarihler arasÄ±ndaki farklarÄ± hesaplamak; Ã¶nemli olaylarla (Ã¶rneÄŸin tatillerle) olan farklarÄ± hesaplamak.

Tarihler iÃ§in baÅŸka bir yaygÄ±n dÃ¶nÃ¼ÅŸÃ¼m, bir tarih veya saatten zamanla ilgili bileÅŸenleri Ã§Ä±karmaktÄ±r.
ZamanÄ±n sÃ¼rekliliÄŸini temsil etmek ve **periyodik Ã¶zellikler** oluÅŸturmak iÃ§in **sinÃ¼s (sine)** ve **kosinÃ¼s (cosine)** tabanlÄ± dÃ¶ngÃ¼sel sÃ¼rekli dÃ¶nÃ¼ÅŸÃ¼mler de oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r:

```python
cycle = 7
df['weekday_sin'] = np.sin(2 * np.pi * df['col1'].dt.dayofweek / cycle)
df['weekday_cos'] = np.cos(2 * np.pi * df['col1'].dt.dayofweek / cycle)
```

---

* **SayÄ±sal Ã–zellik DÃ¶nÃ¼ÅŸÃ¼mleri (Numeric Feature Transformations):**

Ã–zelliklerin Ã¶lÃ§eklenmesi (scaling), normalizasyon, logaritmik veya Ã¼stel dÃ¶nÃ¼ÅŸÃ¼mler; tam sayÄ± ve ondalÄ±k kÄ±sÄ±mlarÄ±n ayrÄ±lmasÄ±; iki sayÄ±sal Ã¶zelliÄŸin toplanmasÄ±, Ã§Ä±karÄ±lmasÄ±, Ã§arpÄ±lmasÄ± veya bÃ¶lÃ¼nmesi gibi iÅŸlemler yapÄ±labilir.

SayÄ±sal Ã¶zelliklerin **standartlaÅŸtÄ±rma (z-score)** veya **normalizasyon (min-max scaling)** yoluyla Ã¶lÃ§eklenmesi, Ã¶zellikle **Ã¶lÃ§ek duyarlÄ± algoritmalar** (Ã¶rneÄŸin sinir aÄŸlarÄ±) kullanÄ±ldÄ±ÄŸÄ±nda mantÄ±klÄ± bir seÃ§imdir.

---

* **SayÄ±sal Ã–zelliklerin GruplandÄ±rÄ±lmasÄ± (Binning):**

Bu yÃ¶ntem, sÃ¼rekli deÄŸiÅŸkenleri belirli aralÄ±klara (bin) ayÄ±rarak **ayrÄ±k** hale getirmek iÃ§in kullanÄ±lÄ±r.
Binning, verideki gÃ¼rÃ¼ltÃ¼ ve hatalarÄ± azaltmaya yardÄ±mcÄ± olur ve **binned** Ã¶zellikler ile hedef deÄŸiÅŸken arasÄ±nda doÄŸrusal olmayan iliÅŸkilerin kolayca modellenmesini saÄŸlar. Ã–zellikle one-hot encoding ile birlikte kullanÄ±ldÄ±ÄŸÄ±nda etkilidir.
Ã–rnek olarak ÅŸu Scikit-learn uygulamasÄ±na bakÄ±labilir:
[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html)

---

* **Kategorik Ã–zellik Kodlama (Categorical Feature Encoding):**

One-hot encoding, iki veya Ã¼Ã§ kategorik Ã¶zelliÄŸin birleÅŸtirilmesi gibi iÅŸlemler ya da daha geliÅŸmiÅŸ **target encoding** yÃ¶ntemleri (ilerleyen bÃ¶lÃ¼mlerde anlatÄ±lacaktÄ±r) kullanÄ±labilir.

---

* **Kategorik Ã–zelliklerin AyrÄ±ÅŸtÄ±rÄ±lmasÄ± ve BirleÅŸtirilmesi:**

Ã–rneÄŸin, [Titanic yarÄ±ÅŸmasÄ±nda](https://www.kaggle.com/c/titanic), isimleri ve soyisimleri ayÄ±rmak veya baÅŸ harflerini (Ã¶rneÄŸin unvanlarÄ±) Ã§Ä±karmak yeni Ã¶zellikler oluÅŸturmak iÃ§in kullanÄ±labilir.

---

* **Polinomial Ã–zellikler (Polynomial Features):**

Mevcut Ã¶zelliklerin Ã¼sse yÃ¼kseltilmesiyle oluÅŸturulan yeni Ã¶zelliklerdir.
Ã–rneÄŸin Scikit-learnâ€™de ÅŸu fonksiyon kullanÄ±labilir:
[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)

---

* **Eksik Veriler ve AykÄ±rÄ± DeÄŸerlerin Ä°ÅŸlenmesi (Missing Data & Outlier Treatment):**

Bu iÅŸlemler teknik olarak doÄŸrudan Ã¶zellik mÃ¼hendisliÄŸi olmasa da, verideki sinyalleri daha gÃ¶rÃ¼nÃ¼r hale getirdikleri iÃ§in Ã¶zellikleri dÃ¶nÃ¼ÅŸtÃ¼rmenin bir parÃ§asÄ± sayÄ±labilir.

* **Eksik DeÄŸerlerin Ele AlÄ±nmasÄ±:**

Eksik deÄŸerleri belirten **ikili (binary) Ã¶zellikler** oluÅŸturmak yararlÄ±dÄ±r; Ã§Ã¼nkÃ¼ eksikliÄŸin kendisi rastgele olmayabilir ve Ã¶nemli bir nedeni olabilir.
Eksik veri, Ã§oÄŸu zaman verinin nasÄ±l toplandÄ±ÄŸÄ± hakkÄ±nda bilgi verir ve baÅŸka bir deÄŸiÅŸkenin **dolaylÄ± bir gÃ¶stergesi (proxy)** gibi davranabilir.

Ã–rneÄŸin, nÃ¼fus sayÄ±mÄ± anketlerinde bir kiÅŸi gelirini bildirmiyorsa, bu genellikle ya Ã§ok dÃ¼ÅŸÃ¼k ya da Ã§ok yÃ¼ksek gelire sahip olduÄŸunu ima eder.

Modelinizin gerektirmesi durumunda, eksik deÄŸerleri **ortalama (mean)**, **medyan (median)** veya **mod (mode)** ile doldurabilirsiniz.
Daha karmaÅŸÄ±k yÃ¶ntemlere genellikle gerek yoktur.

> Parul Pandey tarafÄ±ndan yazÄ±lmÄ±ÅŸ olan bu kapsamlÄ± rehbere baÅŸvurabilirsiniz ([https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey)):
ğŸ‘‰ [Eksik DeÄŸerlerle BaÅŸ Etme Rehberi â€“ Pythonâ€™da Eksik Verilerin Ä°ÅŸlenmesi](https://www.kaggle.com/parulpandey/a-guide-to-handling-missing-values-in-python).

UnutmayÄ±n ki bazÄ± modeller, **eksik deÄŸerleri kendi baÅŸlarÄ±na iÅŸleyebilir** ve bunu birÃ§ok standart yaklaÅŸÄ±mdan daha iyi yaparlar. Bunun nedeni, eksik deÄŸerlerin iÅŸlenmesinin bu modellerin **optimizasyon sÃ¼recinin bir parÃ§asÄ±** olmasÄ±dÄ±r.

Eksik deÄŸerleri kendi iÃ§inde ele alabilen modellerin tamamÄ± **gradient boosting** algoritmalarÄ±dÄ±r:

* **XGBoost:** [https://xgboost.readthedocs.io/en/latest/faq.html](https://xgboost.readthedocs.io/en/latest/faq.html)
* **LightGBM:** [https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html)
* **CatBoost:** [https://catboost.ai/docs/concepts/algorithm-missing-valuesprocessing.html](https://catboost.ai/docs/concepts/algorithm-missing-valuesprocessing.html)

---

* **AykÄ±rÄ± DeÄŸerlerin SÄ±nÄ±rlandÄ±rÄ±lmasÄ± veya KaldÄ±rÄ±lmasÄ± (Outlier Capping or Removal)**

AykÄ±rÄ± deÄŸerleri (outlier) veriden tamamen Ã§Ä±karmak, belirli bir **maksimum veya minimum deÄŸere sÄ±nÄ±rlandÄ±rmak**, ya da doÄŸrudan **deÄŸerlerini deÄŸiÅŸtirmek** mÃ¼mkÃ¼ndÃ¼r.
Bunu yapmak iÃ§in, **Scikit-learn** kÃ¼tÃ¼phanesinde yer alan Ã§ok deÄŸiÅŸkenli (multivariate) aykÄ±rÄ± deÄŸer tespit modelleri gibi geliÅŸmiÅŸ yÃ¶ntemleri kullanabilirsiniz:
ğŸ”— [https://scikit-learn.org/stable/modules/outlier_detection.html](https://scikit-learn.org/stable/modules/outlier_detection.html)

Daha basit bir yÃ¶ntem olarak, **tek deÄŸiÅŸkenli (univariate)** yaklaÅŸÄ±mlarla da aykÄ±rÄ± deÄŸerleri bulabilirsiniz.
Bunun iÃ§in, deÄŸerlerin ortalamadan **kaÃ§ standart sapma** uzakta olduÄŸuna veya **Ã§eyrekler arasÄ± aralÄ±k (IQR)** sÄ±nÄ±rlarÄ±ndan ne kadar uzak olduÄŸuna bakÄ±lÄ±r.

Bu durumda ÅŸu kurallar uygulanabilir:

* **Ãœst aykÄ±rÄ± deÄŸerler (upper outliers):** Q3 + 1.5 Ã— IQR deÄŸerinden bÃ¼yÃ¼k olan noktalar,
* **Alt aykÄ±rÄ± deÄŸerler (lower outliers):** Q1 â€“ 1.5 Ã— IQR deÄŸerinden kÃ¼Ã§Ã¼k olan noktalar.

AykÄ±rÄ± deÄŸerleri belirledikten sonra, bu gÃ¶zlemleri belirtmek iÃ§in **ikili (binary) bir deÄŸiÅŸken** de oluÅŸturabilirsiniz.

---

TÃ¼m bu veri dÃ¶nÃ¼ÅŸÃ¼mleri, modellerinizin **tahmin performansÄ±nÄ± artÄ±rabilir**, ancak yarÄ±ÅŸmalarda **tek baÅŸÄ±na belirleyici** olmazlar.
Bu iÅŸlemler gerekli olsa da, yalnÄ±zca temel Ã¶zellik mÃ¼hendisliÄŸine gÃ¼venemezsiniz.
Bir sonraki bÃ¶lÃ¼mlerde, verinizden **daha fazla deÄŸer Ã§Ä±karmak iÃ§in** daha karmaÅŸÄ±k yÃ¶ntemler ele alÄ±nacaktÄ±r.

#### Meta-features based on rows and columns *(SatÄ±r ve sÃ¼tunlara dayalÄ± meta-Ã¶zellikler)*

RekabetÃ§i bir performans elde edebilmek iÃ§in, **daha karmaÅŸÄ±k Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** tekniklerine ihtiyacÄ±nÄ±z vardÄ±r. BaÅŸlamak iÃ§in iyi bir nokta, **her satÄ±rÄ±n (Ã¶rneÄŸin her Ã¶rneÄŸin) kendi baÅŸÄ±na incelendiÄŸi Ã¶zellikleri** ele almaktÄ±r:

* SayÄ±sal deÄŸerlerin (veya bunlarÄ±n bir alt kÃ¼mesinin) **ortalamasÄ±nÄ±, medyanÄ±nÄ±, toplamÄ±nÄ±, standart sapmasÄ±nÄ±, minimum veya maksimumunu** hesaplayÄ±n.
* **Eksik deÄŸerlerin sayÄ±sÄ±nÄ±** belirleyin.
* SatÄ±rlarda bulunan yaygÄ±n deÄŸerlerin **frekanslarÄ±nÄ±** hesaplayÄ±n (Ã¶rneÄŸin ikili (binary) Ã¶zelliklerde pozitif deÄŸerlerin sayÄ±sÄ±nÄ±).
* Her satÄ±rÄ±, **k-means** gibi bir kÃ¼meleme (clustering) analizinden elde edilen bir kÃ¼meye atayÄ±n.

Bu tÃ¼rden Ã¶zelliklere **meta-Ã¶zellikler (meta-features)** denir; Ã§Ã¼nkÃ¼ bunlar, birden fazla Ã¶zelliÄŸi temsil eden Ã¶zet niteliklerdir. Meta-Ã¶zellikler, algoritmanÄ±zÄ±n veri kÃ¼menizdeki farklÄ± Ã¶rnek tÃ¼rlerini daha kolay ayÄ±rt etmesini saÄŸlar; Ã§Ã¼nkÃ¼ belirli Ã¶rnek gruplarÄ±nÄ± vurgular.

---

Meta-Ã¶zellikler yalnÄ±zca satÄ±rlara deÄŸil, **sÃ¼tunlara dayalÄ± olarak** da oluÅŸturulabilir.
Tek bir Ã¶zelliÄŸin Ã¼zerinde yapÄ±lan **toplama (aggregation)** ve **Ã¶zetleme (summarization)** iÅŸlemleri, sayÄ±sal veya kategorik deÄŸiÅŸkenlerin deÄŸeri hakkÄ±nda ek bilgi saÄŸlamayÄ± amaÃ§lar.
Yani, â€œbu Ã¶zellik deÄŸeri yaygÄ±n mÄ±, yoksa nadir mi?â€ gibi sorulara yanÄ±t verir.
Bu tÃ¼r bilgileri modeller doÄŸrudan Ã§Ä±karamaz; Ã§Ã¼nkÃ¼ bir kategorik deÄŸiÅŸkende deÄŸerlerin kaÃ§ kez tekrarlandÄ±ÄŸÄ±nÄ± â€œsaymaâ€ yeteneÄŸine sahip deÄŸildir.

---

Meta-Ã¶zellikler olarak, sÃ¼tunlara iliÅŸkin herhangi bir istatistiksel Ã¶lÃ§Ã¼yÃ¼ kullanabilirsiniz.
Bunlara Ã¶rnek olarak: **mod, ortalama, medyan, toplam, standart sapma, minimum, maksimum, Ã§arpÄ±klÄ±k (skewness)** ve **basÄ±klÄ±k (kurtosis)** sayÄ±labilir.

SÃ¼tun bazlÄ± meta-Ã¶zellikleri oluÅŸturmak iÃ§in birkaÃ§ farklÄ± yÃ¶ntem uygulanabilir:

---

* **Frekans Kodlama (Frequency Encoding):**

Bir kategorik Ã¶zelliÄŸin deÄŸerlerinin veri setinde kaÃ§ kez tekrarlandÄ±ÄŸÄ±nÄ± sayÄ±n ve bu frekansla orijinal deÄŸeri deÄŸiÅŸtirerek yeni bir Ã¶zellik oluÅŸturun.
AyrÄ±ca, belirli sayÄ±sal deÄŸerlerin sÄ±klÄ±kla tekrarlandÄ±ÄŸÄ± durumlarda **sayÄ±sal Ã¶zelliklere** de frekans kodlama uygulanabilir.

---

* **Gruplara GÃ¶re Frekans ve SÃ¼tun Ä°statistikleri:**

Bu yÃ¶ntemde, verideki farklÄ± **gruplar** dikkate alÄ±narak yeni Ã¶zellikler oluÅŸturulur.
Gruplar, kÃ¼meleme analiziyle (Ã¶rneÄŸin k-means) oluÅŸturulabilir veya doÄŸrudan bir Ã¶zellik Ã¼zerinden tanÄ±mlanabilir (Ã¶rneÄŸin yaÅŸa gÃ¶re yaÅŸ gruplarÄ±, konuma gÃ¶re bÃ¶lgeler vb.).

Her grubun tanÄ±mlayÄ±cÄ± meta-Ã¶zellikleri, o gruba ait Ã¶rneklere atanÄ±r.
Bunu yapmak iÃ§in **Pandas `groupby`** fonksiyonu kullanÄ±labilir:
Bu fonksiyonla grup bazlÄ± istatistikler hesaplanÄ±r ve daha sonra **gruplama deÄŸiÅŸkenine gÃ¶re** orijinal veriye eklenir.

Bu yÃ¶ntemdeki en zor kÄ±sÄ±m, veride **anlamlÄ± gruplar** bulmaktÄ±r.

---

* **GruplarÄ±n BirleÅŸtirilmesiyle Ek Frekans ve Ä°statistikler:**

Birden fazla grubu birleÅŸtirerek ek sÃ¼tun istatistikleri veya frekanslar tÃ¼retmek mÃ¼mkÃ¼ndÃ¼r.

---

Bu liste elbette tÃ¼m yÃ¶ntemleri kapsamÄ±yor; ancak size, **Ã¶zellik dÃ¼zeyinde** ve **satÄ±r dÃ¼zeyinde** frekanslar ve istatistikler kullanarak yeni Ã¶zellikler tÃ¼retmenin yollarÄ± hakkÄ±nda bir fikir verir.

---

* **Basit Bir Uygulama Ã–rneÄŸi: Amazon Employee Access Challenge**

AÅŸaÄŸÄ±da, **ROLE_TITLE** Ã¶zelliÄŸine frekans kodlamasÄ± uygulanan bir Ã¶rnek verilmiÅŸtir:

```python
import pandas as pd
train = pd.read_csv("../input/amazon-employee-access-challenge/train.csv")

# Bir Ã¶zelliÄŸin frekans sayÄ±mÄ±
feature_counts = train.groupby('ROLE_TITLE').size()
print(train['ROLE_TITLE'].apply(lambda x: feature_counts[x]))
```

Bu iÅŸlemin sonucunda, **ROLE_TITLE** deÄŸiÅŸkenindeki sÄ±nÄ±flar, veri setinde gÃ¶rÃ¼lme sÄ±klÄ±klarÄ±yla (frekanslarÄ±yla) deÄŸiÅŸtirilmiÅŸ olur.

Åimdi ise, **ROLE_TITLE** Ã¶zelliÄŸini **ROLE_DEPTNAME** (departman adÄ±) deÄŸiÅŸkeniyle gruplayarak kodlayacaÄŸÄ±z; Ã§Ã¼nkÃ¼ farklÄ± unvanlarÄ±n bazÄ± departmanlarda daha yaygÄ±n, bazÄ±larÄ±nda ise daha nadir olabileceÄŸini varsayÄ±yoruz.

SonuÃ§ olarak, her iki Ã¶zelliÄŸi (departman ve unvan) birleÅŸtirerek yeni bir Ã¶zellik oluÅŸturuyoruz ve bu birleÅŸik deÄŸerin frekansÄ±nÄ± hesaplÄ±yoruz:

```python
feature_counts = train.groupby(['ROLE_DEPTNAME', 'ROLE_TITLE']).size()
print(train[['ROLE_DEPTNAME', 'ROLE_TITLE']].apply(lambda x: feature_counts[x[0]][x[1]], axis=1))
```

Bu ÅŸekilde, verideki gruplarÄ±n ve kategorilerin birbiriyle iliÅŸkisini yansÄ±tan **daha bilgilendirici yeni Ã¶zellikler** elde edilmiÅŸ olur.

TÃ¼m Ã§alÄ±ÅŸan kodlarÄ± ve sonuÃ§larÄ± bu Kaggle Notebookâ€™ta bulabilirsiniz:
ğŸ‘‰ [https://www.kaggle.com/lucamassaron/meta-features-and-target-encoding/](https://www.kaggle.com/lucamassaron/meta-features-and-target-encoding/)

#### Target encoding *(Hedef kodlama)*

Kategorik Ã¶zelliklerle Ã§alÄ±ÅŸmak genellikle zorlayÄ±cÄ± deÄŸildir, Ã§Ã¼nkÃ¼ Scikit-learn tarafÄ±ndan sunulan bazÄ± basit fonksiyonlar bu iÅŸlemi kolaylaÅŸtÄ±rÄ±r:

* **LabelEncoder**
* **OneHotEncoder**
* **OrdinalEncoder**

Bu fonksiyonlar, kategorileri sayÄ±sal Ã¶zelliklere ve ardÄ±ndan ikili (binary) Ã¶zelliklere dÃ¶nÃ¼ÅŸtÃ¼rerek makine Ã¶ÄŸrenimi algoritmalarÄ±nÄ±n bunlarÄ± kolayca iÅŸlemesini saÄŸlar.
Ancak, eÄŸer kategorilerin sayÄ±sÄ± Ã§ok fazlaysa, **one-hot encoding** stratejisiyle oluÅŸturulan veri kÃ¼mesi seyrek (sparse) hale gelir (yani Ã§oÄŸu deÄŸer sÄ±fÄ±r olur) ve bu durum bilgisayarÄ±nÄ±zÄ±n veya Notebookâ€™un belleÄŸi ve iÅŸlemcisi aÃ§Ä±sÄ±ndan yÃ¶netilmesi zor bir hale gelir.
Bu tÃ¼r durumlarda, **yÃ¼ksek kardinaliteli Ã¶zellik (high-cardinality feature)** olarak adlandÄ±rÄ±lan bir Ã¶zellikten bahsederiz ve bu tÃ¼r veriler Ã¶zel bir ÅŸekilde ele alÄ±nmalÄ±dÄ±r.

Kaggle yarÄ±ÅŸmalarÄ±nÄ±n erken dÃ¶nemlerinden beri, yÃ¼ksek kardinaliteli deÄŸiÅŸkenler genellikle **Micci-Barreca (2001)** tarafÄ±ndan Ã¶nerilen bir kodlama yÃ¶ntemi kullanÄ±larak iÅŸlenmiÅŸtir:

> Micci-Barreca, D. *A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems.*
> *ACM SIGKDD Explorations Newsletter 3.1 (2001): 27â€“32.*

Bu yaklaÅŸÄ±mÄ±n temel fikri, kategorik bir Ã¶zelliÄŸin sahip olduÄŸu birÃ§ok kategoriyi, o kategoriye karÅŸÄ±lÄ±k gelen beklenen hedef (target) deÄŸeriyle dÃ¶nÃ¼ÅŸtÃ¼rmektir.

* Regresyon durumunda, bu kategoriye ait **ortalama beklenen deÄŸer**,
* Ä°kili sÄ±nÄ±flandÄ±rmada (binary classification), **koÅŸullu olasÄ±lÄ±k (conditional probability)**,
* Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmada (multiclass classification) ise **her olasÄ± sonuÃ§ iÃ§in koÅŸullu olasÄ±lÄ±k** kullanÄ±lÄ±r.

Ã–rneÄŸin, **Titanic GettingStarted** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/competitions/titanic](https://www.kaggle.com/competitions/titanic)), her yolcunun hayatta kalma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin etmeniz gerekir.
Bu durumda, **gender (cinsiyet)** gibi bir kategorik Ã¶zelliÄŸe hedef kodlama (target encoding) uygulamak, cinsiyet deÄŸerini o cinsiyetin ortalama hayatta kalma olasÄ±lÄ±ÄŸÄ±yla deÄŸiÅŸtirmek anlamÄ±na gelir.

Bu yÃ¶ntemle, kategorik Ã¶zellik, veriyi bÃ¼yÃ¼tmeden veya seyrekleÅŸtirmeden sayÄ±sal bir Ã¶zelliÄŸe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ olur.
KÄ±saca, **hedef kodlama (target encoding)** budur â€” ve birÃ§ok durumda oldukÃ§a etkilidir, Ã§Ã¼nkÃ¼ yÃ¼ksek kardinaliteli Ã¶zelliklere dayalÄ± bir â€œtahminâ€ mantÄ±ÄŸÄ±na benzer ÅŸekilde Ã§alÄ±ÅŸÄ±r.

Ancak, **stacked prediction** (yani baÅŸka bir modelin tahminini bir Ã¶zellik olarak kullanma) yaklaÅŸÄ±mÄ±na benzer ÅŸekilde, hedef kodlama da **aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting)** riski taÅŸÄ±r.
BazÄ± kategoriler Ã§ok nadirse, hedef kodlama neredeyse hedef etiketin doÄŸrudan verilmesiyle eÅŸdeÄŸer hale gelir.
Bu riski Ã¶nlemenin yollarÄ± vardÄ±r.

UygulamanÄ±za doÄŸrudan dahil edebileceÄŸiniz implementasyonu gÃ¶rmeden Ã¶nce, **hedef kodlama (target encoding)** iÃ§in kullanÄ±lan gerÃ§ek bir Ã¶rneÄŸe bakalÄ±m.
AÅŸaÄŸÄ±daki kod, **PetFinder.my Adoption Prediction** yarÄ±ÅŸmasÄ±nda en yÃ¼ksek puanlÄ± gÃ¶nderimlerden birinde kullanÄ±lmÄ±ÅŸtÄ±r:

```python
import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin

class TargetEncode(BaseEstimator, TransformerMixin):
    
    def __init__(self, categories='auto', k=1, f=1, noise_level=0, random_state=None):
        if type(categories) == str and categories != 'auto':
            self.categories = [categories]
        else:
            self.categories = categories
        self.k = k
        self.f = f
        self.noise_level = noise_level
        self.encodings = dict()
        self.prior = None
        self.random_state = random_state
        
    def add_noise(self, series, noise_level):
        return series * (1 + noise_level * np.random.randn(len(series)))
```

Fonksiyonun **girdi parametreleri** ÅŸunlardÄ±r:

* **categories:** Hedef kodlama (target encoding) uygulamak istediÄŸiniz sÃ¼tun adlarÄ±. `'auto'` olarak bÄ±rakÄ±lÄ±rsa, sÄ±nÄ±f otomatik olarak string tipindeki sÃ¼tunlarÄ± seÃ§er.
* **k (int):** Bir kategorinin ortalamasÄ±nÄ±n dikkate alÄ±nabilmesi iÃ§in gereken minimum Ã¶rnek sayÄ±sÄ±.
* **f (int):** Kategori ortalamasÄ± ile genel ortalama (prior probability) arasÄ±ndaki **dengelenme (smoothing)** miktarÄ±nÄ± belirler.
* **noise_level:** AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in hedef kodlamaya eklenecek **gÃ¼rÃ¼ltÃ¼ (noise)** miktarÄ±. KÃ¼Ã§Ã¼k deÄŸerlerle baÅŸlamak gerekir.
* **random_state:** GÃ¼rÃ¼ltÃ¼ seviyesi sÄ±fÄ±rdan bÃ¼yÃ¼k olduÄŸunda aynÄ± kodlamayÄ± yeniden Ã¼retebilmek iÃ§in rastgelelik tohumu (seed).

Burada dikkat edilmesi gereken, **k** ve **f** parametrelerinin varlÄ±ÄŸÄ±dÄ±r.
Bir kategorik Ã¶zelliÄŸin bir seviyesi iÃ§in (Ã¶rneÄŸin bir ÅŸehir, bir Ã¼rÃ¼n tÃ¼rÃ¼ vb.), hedefi tahmin etmede yardÄ±mcÄ± olabilecek yaklaÅŸÄ±k bir deÄŸer arÄ±yoruz.
Bu seviyeyi doÄŸrudan gÃ¶zlenen koÅŸullu olasÄ±lÄ±kla deÄŸiÅŸtirmek bir Ã§Ã¶zÃ¼m olabilir, ancak az gÃ¶zlemli seviyelerde iyi Ã§alÄ±ÅŸmaz.

Ã‡Ã¶zÃ¼m, **empirik Bayes yaklaÅŸÄ±mÄ± (empirical Bayesian approach)** kullanmaktÄ±r â€” yani, o seviyedeki gÃ¶zlenen koÅŸullu olasÄ±lÄ±ÄŸÄ± (posterior) tÃ¼m Ã¶rnekler Ã¼zerindeki genel olasÄ±lÄ±kla (prior) birleÅŸtiririz.
Bu karÄ±ÅŸÄ±mÄ± belirleyen faktÃ¶r **lambda**â€™dÄ±r.

Pratikte, her kategori seviyesi iÃ§in ÅŸu soruya cevap veririz:

> â€œKoÅŸullu hedef deÄŸerini mi, genel ortalamayÄ± mÄ±, yoksa ikisinin karÄ±ÅŸÄ±mÄ±nÄ± mÄ± kullanmalÄ±yÄ±z?â€

Bu dengeyi belirleyen ÅŸey **f parametresidir**, ve **k parametresi** (genellikle 1 veya 2 gibi kÃ¼Ã§Ã¼k deÄŸerler) minimum gÃ¶zlem sayÄ±sÄ±nÄ± ifade eder.

![](im/1059.png)

Grafikte gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi, x ekseni belirli bir kategorik seviyedeki Ã¶rnek sayÄ±sÄ±nÄ±, y ekseni ise koÅŸullu hedef deÄŸerinin aÄŸÄ±rlÄ±ÄŸÄ±nÄ± temsil etmektedir. KÃ¼Ã§Ã¼k **f** deÄŸerleri, ortalama hedef deÄŸerini kullanmaktan koÅŸullu deÄŸeri kullanmaya ani bir ÅŸekilde geÃ§meye eÄŸilimlidir. Daha yÃ¼ksek **f** deÄŸerleri ise, Ã¶rnek sayÄ±sÄ± bÃ¼yÃ¼k olmayan seviyeler dÄ±ÅŸÄ±nda, koÅŸullu deÄŸeri ortalama ile harmanlamaya meyillidir.

DolayÄ±sÄ±yla, sabit bir **k** iÃ§in, yÃ¼ksek **f** deÄŸerleri gÃ¶zlenen empirik frekansa daha az gÃ¼venmeyi ve tÃ¼m hÃ¼creler iÃ§in empirik olasÄ±lÄ±ÄŸa daha fazla dayanmayÄ± ifade eder. **f** iÃ§in doÄŸru deÄŸer genellikle deneme-yanÄ±lma yoluyla (cross-validation ile desteklenmiÅŸ) bulunur, Ã§Ã¼nkÃ¼ **f** parametresi kendi baÅŸÄ±na bir hiperparametre olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.

TÃ¼m bu aÃ§Ä±klamalardan sonra, sÄ±nÄ±fÄ±n kullanÄ±mÄ± aslÄ±nda oldukÃ§a basittir. Target encoding uygulamak istediÄŸiniz Ã¶zelliklerin adlarÄ±nÄ± ve denemek istediÄŸiniz parametreleri belirterek sÄ±nÄ±fÄ± baÅŸlatabilir ve eÄŸitim verisine fit edebilirsiniz. ArdÄ±ndan, yalnÄ±zca fit edilen Ã¶zellikleri target encoding uygulayarak baÅŸka herhangi bir veri Ã¼zerinde dÃ¶nÃ¼ÅŸÃ¼m yapabilirsiniz:

```python
te = TargetEncode(categories='ROLE_TITLE')
te.fit(train, train['ACTION'])
te.transform(train[['ROLE_TITLE']])
```

Bu Ã¶rnek, daha Ã¶nce kullandÄ±ÄŸÄ±mÄ±z **Amazon Employee Access Challenge** verisi Ã¼zerinde Ã§alÄ±ÅŸÄ±r ve yalnÄ±zca **ROLE_TITLE** Ã¶zelliÄŸini hedef kodlar.

> Kendi kodunuzu yazmak yerine, [scikit-learn-contrib/category_encoders](https://github.com/scikit-learn-contrib/category_encoders) paketindeki **TargetEncoder**â€™Ä± da kullanabilirsiniz ([TargetEncoder dokÃ¼mantasyonu](http://contrib.scikit-learn.org/category_encoders/targetencoder.html)). Bu paket, bu bÃ¶lÃ¼mdeki kodla aynÄ± ÅŸekilde Ã§alÄ±ÅŸÄ±r ve kutudan Ã§Ä±ktÄ±ÄŸÄ± haliyle kullanÄ±labilir.

### Using feature importance to evaluate your work *(Ã–zellik Ã¶nemini kullanarak Ã§alÄ±ÅŸmanÄ± deÄŸerlendirme)*

AÅŸÄ±rÄ± Ã¶zellik mÃ¼hendisliÄŸi uygulamanÄ±n yan etkileri olabilir. EÄŸer Ã§ok fazla korelasyonlu Ã¶zellik veya problem iÃ§in Ã¶nemsiz Ã¶zellikler oluÅŸturursanÄ±z, modellerin eÄŸitimi Ã§ok uzun sÃ¼rebilir ve sonuÃ§larÄ±nÄ±z kÃ¶tÃ¼leÅŸebilir. Bu, paradoks gibi gÃ¶rÃ¼nse de, her deÄŸiÅŸkenin Ã¶lÃ§Ã¼m veya kayÄ±t hatalarÄ±ndan kaynaklanan bazÄ± rastgele bileÅŸenler (gÃ¼rÃ¼ltÃ¼) taÅŸÄ±masÄ±yla aÃ§Ä±klanÄ±r. Model, yanlÄ±ÅŸlÄ±kla bu gÃ¼rÃ¼ltÃ¼yÃ¼ sinyal olarak algÄ±layabilir: kullandÄ±ÄŸÄ±nÄ±z deÄŸiÅŸken sayÄ±sÄ± arttÄ±kÃ§a, modelin gÃ¼rÃ¼ltÃ¼yÃ¼ sinyal yerine yakalama olasÄ±lÄ±ÄŸÄ± da artar. Bu nedenle, yalnÄ±zca eÄŸitim iÃ§in kullandÄ±ÄŸÄ±nÄ±z veri setinde ilgili Ã¶zellikleri tutmaya Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z; Ã¶zellik seÃ§imini, Ã¶zellik mÃ¼hendisliÄŸi sÃ¼recinizin bir parÃ§asÄ± olarak dÃ¼ÅŸÃ¼nÃ¼n (budama aÅŸamasÄ±).

Hangi Ã¶zellikleri tutmanÄ±z gerektiÄŸini belirlemek zor bir problemdir Ã§Ã¼nkÃ¼ mevcut Ã¶zellik sayÄ±sÄ± arttÄ±kÃ§a, olasÄ± kombinasyonlarÄ±n sayÄ±sÄ± da artar. Ã–zellik seÃ§menin Ã§eÅŸitli yollarÄ± vardÄ±r, ancak Ã¶ncelikle seÃ§im iÅŸleminin veri hazÄ±rlama hattÄ±nÄ±zÄ±n hangi aÅŸamasÄ±nda yapÄ±lmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼nmek Ã¶nemlidir.

Deneyimlerimize dayanarak, Ã¶zellik seÃ§imini veri hazÄ±rlama hattÄ±nÄ±zÄ±n sonunda yapmanÄ±zÄ± Ã¶neririz. Ã–zellikler, varyanslarÄ±nÄ±n bir kÄ±smÄ±nÄ± diÄŸer Ã¶zelliklerle paylaÅŸÄ±r, bu nedenle bunlarÄ±n etkinliÄŸini tek tek test ederek deÄŸerlendiremezsiniz; doÄŸru bir ÅŸekilde hangi Ã¶zellikleri kullanmanÄ±z gerektiÄŸini belirlemek iÃ§in hepsini birlikte deÄŸerlendirmelisiniz.

AyrÄ±ca, seÃ§tiÄŸiniz Ã¶zelliklerin etkinliÄŸini Ã§apraz doÄŸrulama (cross-validation) ile test etmelisiniz. Bu nedenle, tÃ¼m Ã¶zellikleri hazÄ±rladÄ±ktan ve tutarlÄ± bir pipeline ile Ã§alÄ±ÅŸan bir modeliniz (tam optimize edilmiÅŸ olmasÄ± gerekmez, ancak dÃ¼zgÃ¼n Ã§alÄ±ÅŸmalÄ± ve yarÄ±ÅŸma iÃ§in kabul edilebilir sonuÃ§lar vermelidir) olduktan sonra, hangi Ã¶zelliklerin tutulacaÄŸÄ±nÄ± ve hangi Ã¶zelliklerin Ã§Ä±karÄ±labileceÄŸini test etmeye hazÄ±rsÄ±nÄ±z. Bu noktada, Ã¶zellik seÃ§imi iÃ§in Ã§eÅŸitli yollar vardÄ±r:

* Ä°statistikte kullanÄ±lan klasik yaklaÅŸÄ±mlar, her bir Ã¶zelliÄŸi tahmin edici setine ekleyerek veya Ã§Ä±kararak test eden ileri ekleme (forward addition) veya geri eleme (backward elimination) yÃ¶ntemlerine baÅŸvurur. Bu yaklaÅŸÄ±m oldukÃ§a zaman alÄ±cÄ± olabilir Ã§Ã¼nkÃ¼ her adÄ±mda her Ã¶zellik iÃ§in deÄŸiÅŸkenlerin iÃ§ Ã¶nemini veya modelin performansÄ±na olan etkisini belirlemek iÃ§in bir Ã¶lÃ§Ã¼m yeniden hesaplanmak zorundadÄ±r.
* Regresyon modelleri iÃ§in, lasso seÃ§imi kullanmak, tÃ¼m Ã¶nemli ve yinelemeli (korelasyonlu) Ã¶zellikler hakkÄ±nda ipucu verebilir (bu yÃ¶ntem aslÄ±nda yÃ¼ksek korelasyonlu Ã¶zellikleri bile tutabilir) ve stabilite seÃ§imi (stability selection) prosedÃ¼rÃ¼nÃ¼ kullanÄ±r. Stabilite seÃ§iminde, hangi Ã¶zelliklerin tutulmasÄ± gerektiÄŸini birden fazla kez test edersiniz (bagging prosedÃ¼rÃ¼ kullanarak) â€“ her testte katsayÄ±larÄ± sÄ±fÄ±r olmayan Ã¶zellikleri dikkate alÄ±rsÄ±nÄ±z â€“ ve ardÄ±ndan en sÄ±k sÄ±fÄ±r olmayan katsayÄ±ya sahip olanlarÄ± tutmak iÃ§in bir oylama sistemi uygularsÄ±nÄ±z.

> Ä°ÅŸlemle ilgili daha fazla detayÄ± bu depoda bulabilirsiniz: [https://github.com/scikit-learn-contrib/stability-selection](https://github.com/scikit-learn-contrib/stability-selection).

* AÄŸaÃ§ tabanlÄ± modeller iÃ§in, Ã¶rneÄŸin rastgele ormanlar (random forests) veya gradient boosting gibi modellerde, Ã¶zellikleri sÄ±ralamanÄ±n yaygÄ±n yollarÄ±, bÃ¶lÃ¼nmelere dayalÄ± saflÄ±k azalmasÄ± veya hedef metriÄŸindeki kazanÃ§tÄ±r. Bir eÅŸik deÄŸeri en az Ã¶nemli Ã¶zellikleri elemek iÃ§in kullanÄ±labilir.
* Yine aÄŸaÃ§ tabanlÄ± modeller iÃ§in, ancak diÄŸer modellere kolayca genellenebilir ÅŸekilde, test tabanlÄ± Ã¶zellik rastgeleleÅŸtirmesi (veya basitÃ§e rastgele Ã¶zelliklerle karÅŸÄ±laÅŸtÄ±rmalar) modelin doÄŸru tahmin yapmasÄ±na gerÃ§ekten yardÄ±mcÄ± olan Ã¶zellikleri, yalnÄ±zca gÃ¼rÃ¼ltÃ¼ veya gereksiz olanlardan ayÄ±rmaya yardÄ±mcÄ± olur.

Ã–zellikleri rastgeleleÅŸtirmenin Ã¶nemli Ã¶zellikleri seÃ§mede nasÄ±l yardÄ±mcÄ± olduÄŸunu gÃ¶steren bir Ã¶rnek, Chris Deotte tarafÄ±ndan Ventilator Pressure Prediction yarÄ±ÅŸmasÄ±nda sunulmuÅŸtur: [https://www.kaggle.com/cdeotte/lstm-feature-importance](https://www.kaggle.com/cdeotte/lstm-feature-importance). Bu Notebook, LSTM tabanlÄ± bir sinir aÄŸÄ±nda Ã¶zelliklerin rolÃ¼nÃ¼ test eder. Ä°lk olarak, model oluÅŸturulur ve temel performans kaydedilir. Daha sonra, Ã¶zellikler tek tek karÄ±ÅŸtÄ±rÄ±lÄ±r ve model tekrar tahmin yapmak zorunda bÄ±rakÄ±lÄ±r. EÄŸer tahmin performansÄ± kÃ¶tÃ¼leÅŸirse, bu, Ã¶nemli bir Ã¶zelliÄŸi karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±z ve dokunulmamasÄ± gerektiÄŸini gÃ¶sterir. EÄŸer performans aynÄ± kalÄ±r veya artarsa, karÄ±ÅŸtÄ±rÄ±lan Ã¶zellik model iÃ§in etkili deÄŸildir veya hatta zararlÄ± olabilir.

> Ã–zellik Ã¶neminin deÄŸerlendirilmesinde â€œNo Free Lunchâ€ prensibi geÃ§erlidir. KarÄ±ÅŸtÄ±rma iÅŸlemi yeniden eÄŸitim gerektirmez; bu, yeni bir modelin eÄŸitiminin zaman aldÄ±ÄŸÄ± durumlarda bÃ¼yÃ¼k bir avantajdÄ±r. Ancak bazÄ± durumlarda baÅŸarÄ±sÄ±z olabilir. KarÄ±ÅŸtÄ±rma, bazen deÄŸerlendirilmesi mantÄ±ksÄ±z olan gerÃ§ekÃ§i olmayan giriÅŸ kombinasyonlarÄ± oluÅŸturabilir. DiÄŸer durumlarda, yÃ¼ksek korelasyonlu Ã¶zelliklerin varlÄ±ÄŸÄ± tarafÄ±ndan yanÄ±ltÄ±labilir (birinin Ã¶nemli, diÄŸerinin Ã¶nemsiz olduÄŸunu yanlÄ±ÅŸ deÄŸerlendirebilir). Bu durumda, Ã¶zelliÄŸi karÄ±ÅŸtÄ±rmak yerine kaldÄ±rmak, modeli yeniden eÄŸitmek ve performansÄ±nÄ± temel deÄŸerle karÅŸÄ±laÅŸtÄ±rmak en iyi Ã§Ã¶zÃ¼mdÃ¼r.

KarÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ Ã¶zelliklere dayanan baÅŸka bir yaklaÅŸÄ±ma Boruta Ã¶rnek verilebilir ([https://github.com/scikit-learn-contrib/boruta_py](https://github.com/scikit-learn-contrib/boruta_py)). Boruta, modelin geÃ§erliliÄŸini yinelemeli olarak test etmek iÃ§in rastgele Ã¶zellikler kullanÄ±r. Boruta seÃ§me prosedÃ¼rÃ¼nÃ¼n alternatif bir versiyonu olan BorutaShap ([https://github.com/Ekeany/Boruta-Shap](https://github.com/Ekeany/Boruta-Shap)), SHAP deÄŸerlerini kullanarak hem Ã¶zellik seÃ§imi hem de aÃ§Ä±klanabilirlik saÄŸlar. Elde edilen seÃ§im genellikle basit kaldÄ±rma veya rastgeleleÅŸtirme turlarÄ±ndan daha gÃ¼venilirdir, Ã§Ã¼nkÃ¼ Ã¶zellikler, Ã¶nemlerini istatistiksel olarak kanÄ±tlayana kadar rastgele Ã¶zelliklere karÅŸÄ± birden fazla kez test edilir. Boruta veya BorutaShap 100 iterasyona kadar sÃ¼rebilir ve yalnÄ±zca aÄŸaÃ§ tabanlÄ± makine Ã¶ÄŸrenimi algoritmalarÄ±yla gerÃ§ekleÅŸtirilebilir.

DoÄŸrusal model iÃ§in Ã¶zellik seÃ§iyorsanÄ±z, Boruta aslÄ±nda aÅŸÄ±rÄ±ya kaÃ§abilir. Ã‡Ã¼nkÃ¼ hem ana etkiler hem de diÄŸer Ã¶zelliklerle olan etkileÅŸimler aÃ§Ä±sÄ±ndan Ã¶zellikleri Ã¶nemli kabul eder (doÄŸrusal modelde yalnÄ±zca ana etkiler ve seÃ§ilmiÅŸ bir alt kÃ¼me etkileÅŸimler Ã¶nemlidir). Yine de Borutaâ€™yÄ± doÄŸrusal model seÃ§imi iÃ§in etkili ÅŸekilde kullanabilirsiniz; bunun iÃ§in maksimum derinliÄŸi bir aÄŸaÃ§ olarak ayarlanmÄ±ÅŸ bir gradient boosting kullanarak yalnÄ±zca Ã¶zelliklerin ana etkilerini dikkate alÄ±rsÄ±nÄ±z, etkileÅŸimlerini deÄŸil.

BorutaShap ile Ã¶zellik seÃ§iminin ne kadar basit ve hÄ±zlÄ± kurulduÄŸunu gÃ¶rmek iÃ§in, 30 Days of ML yarÄ±ÅŸmasÄ±nda sunulan bu tutorial Notebookâ€™a gÃ¶z atabilirsiniz: [https://www.kaggle.com/lucamassaron/tutorial-feature-selection-with-boruta-shap](https://www.kaggle.com/lucamassaron/tutorial-feature-selection-with-boruta-shap).

> Bojan Tunguz
> 
> [https://www.kaggle.com/tunguz](https://www.kaggle.com/tunguz)
> 
> 
> 
> Bojan Tunguz, kesinlikle Ã¶zellik mÃ¼hendisliÄŸinin Ã¶nemini iyi anlayan bir Kaggle yarÄ±ÅŸmacÄ±sÄ±dÄ±r (ve ayrÄ±ca XGBoostâ€™un bÃ¼yÃ¼k bir hayranÄ±dÄ±r). NVIDIAâ€™da Makine Ã–ÄŸrenimi Modelleyicisi olarak edindiÄŸi deneyimlerini ve etkileyici ÅŸekilde Kaggleâ€™da DÃ¶rt Kat Grandmaster unvanÄ±nÄ± konuÅŸmak iÃ§in kendisiyle sohbet etmek istedik.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknik ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Her tÃ¼rlÃ¼ kodsuz yarÄ±ÅŸmayÄ± seviyorum. Bu yÄ±llar iÃ§inde Ã§ok deÄŸiÅŸti. Eskiden gÃ¶rÃ¼ntÃ¼ yarÄ±ÅŸmalarÄ±na Ã§ok ilgiliydim, ancak bu yarÄ±ÅŸmalarda rekabetÃ§i olabilmek iÃ§in gereken mÃ¼hendislik yÄ±ÄŸÄ±nÄ± yÄ±llar iÃ§inde inanÄ±lmaz derecede karmaÅŸÄ±k hale geldi. Bir sÃ¼re NLP yarÄ±ÅŸmalarÄ±na da ilgim vardÄ±, ama bunlar Kaggleâ€™da her zaman nadir olmuÅŸtur. Ancak yÄ±llar boyunca deÄŸiÅŸmeyen tek ÅŸey, tablo (tabular) veri problemlerine olan ilgim oldu. Bu problemler eskiden tipik Kaggle yarÄ±ÅŸma problemleriydi ama ne yazÄ±k ki artÄ±k neredeyse yok oldular. HÃ¢lÃ¢ bu alanla Ã§ok ilgileniyorum ve bu alanda bazÄ± temel araÅŸtÄ±rmalar yapmaya baÅŸladÄ±m. ML/DLâ€™nin diÄŸer alanlarÄ±na kÄ±yasla tablo verilerinde makine Ã¶ÄŸrenimini geliÅŸtirme konusunda Ã§ok az ilerleme kaydedildi ve burada bÃ¼yÃ¼k fÄ±rsatlar olduÄŸuna inanÄ±yorum.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±?**
> 
> Kaggleâ€™Ä±n oyun yÃ¶nÃ¼nÃ¼ her zaman ciddiye aldÄ±m. Bu benim iÃ§in, yeni Kaggle yarÄ±ÅŸmalarÄ±na genellikle Ã§ok eÄŸlenceli bir ÅŸekilde baÅŸlamam anlamÄ±na geliyor â€“ basit Ã§Ã¶zÃ¼mler, esprili Ã§Ã¶zÃ¼mler, diÄŸer oyunculardan modifiye edilmiÅŸ Ã§Ã¶zÃ¼mler, karÄ±ÅŸÄ±mlar vb. Bu yÃ¶ntemler, problemi anlamama, hangi tÃ¼r Ã§Ã¶zÃ¼mlerin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶rmeme ve birkaÃ§ basit hile ile ne kadar ilerleyebileceÄŸimi test etmeme yardÄ±mcÄ± oluyor. Bunun bir kÄ±smÄ± gÃ¼nlÃ¼k modelleme Ã§alÄ±ÅŸmalarÄ±mda da geÃ§erli, ama orada eksik olan Ã¶nemli bir unsur var â€“ o da topluluktan ve lider tablodan gelen destek ve geri bildirim. Kendi baÅŸÄ±nÄ±za veya kÃ¼Ã§Ã¼k bir ekiple Ã§alÄ±ÅŸÄ±rken, oluÅŸturduÄŸunuz Ã§Ã¶zÃ¼mÃ¼n en iyi olup olmadÄ±ÄŸÄ±nÄ± veya daha iyi bir Ã§Ã¶zÃ¼mÃ¼n mÃ¼mkÃ¼n olup olmadÄ±ÄŸÄ±nÄ± asla bilemezsiniz.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu gÃ¶revi nasÄ±l Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼zden bahseder misiniz?**
> 
> Kaggle kariyerimdeki en zor ve en Ã¶nemli yarÄ±ÅŸma, Home Credit Default Risk yarÄ±ÅŸmasÄ±ydÄ±. TÃ¼m zamanlarÄ±n ikinci en bÃ¼yÃ¼k Kaggle yarÄ±ÅŸmasÄ±ydÄ± ve hayatÄ±mda Ã¶zellikle zor bir dÃ¶nemde gerÃ§ekleÅŸti.
> 
> 
> 
> Kredi deÄŸerliliÄŸi (credit underwriting) Ã§ok zor bir veri bilimi problemidir ve Ã§ok zeki bir Ã¶zellik mÃ¼hendisliÄŸi ile gÃ¼venilir bir doÄŸrulama ÅŸemasÄ± gerektirir. Benim kiÅŸisel iÃ§gÃ¶rÃ¼m, Ã¶zellik seÃ§imi iÃ§in basit lineer modellemeyi kullanmaktÄ± ve bu genel modelimize yardÄ±mcÄ± oldu. Ekibimiz bu yarÄ±ÅŸmayÄ± kazandÄ± ve bugÃ¼n hÃ¢lÃ¢ bu zaferi Kaggle kariyerimin en Ã¶nemli noktasÄ± olarak gÃ¶rÃ¼yorum.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? NasÄ±l?**
> 
> Kaggle, ML kariyerimin en bÃ¼yÃ¼k hÄ±zlandÄ±rÄ±cÄ±sÄ± oldu. Sahip olduÄŸum dÃ¶rt ML iÅŸinden Ã¼Ã§Ã¼nÃ¼n doÄŸrudan Kaggle baÅŸarÄ±mÄ±n bir sonucu olduÄŸunu sÃ¶yleyebilirim. Kaggle baÅŸarÄ±sÄ±nÄ±n bir kariyer iÃ§in ne kadar Ã¶nemli olabileceÄŸini abartmak imkÃ¢nsÄ±zdÄ±r.
> 
> 
> 
> **Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neleri gÃ¶z ardÄ± ediyor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilmenizi istediÄŸiniz ÅŸeyler nelerdi?**
> 
> TÃ¼m ML problemlerinin, Ã¶zellikle Kaggle yarÄ±ÅŸmalarÄ±nÄ±n, uzun sÃ¼re ya az deÄŸer verdiÄŸim ya da yeterince Ã¶nemsemediÄŸim iki yÃ¶nÃ¼ vardÄ±r: Ã¶zellik mÃ¼hendisliÄŸi ve saÄŸlam bir doÄŸrulama stratejisi. ML kÃ¼tÃ¼phanelerini ve algoritmalarÄ±nÄ± Ã§ok seviyorum ve genellikle mÃ¼mkÃ¼n olan en kÄ±sa sÃ¼rede ML algoritmasÄ±nÄ± kurmaya baÅŸlÄ±yorum. Ama model performansÄ±na en bÃ¼yÃ¼k etkiyi Ã§ok iyi Ã¶zellikler saÄŸlar. Ne yazÄ±k ki, Ã¶zellik mÃ¼hendisliÄŸi daha Ã§ok bir sanat ve daha az bir bilimdir ve genellikle modele ve veri setine baÄŸlÄ±dÄ±r. Daha ilginÃ§ Ã¶zellik mÃ¼hendisliÄŸi hilelerinin ve uygulamalarÄ±nÄ±n Ã§oÄŸu standart ML kurslarÄ±nda veya kaynaklarÄ±nda nadiren Ã¶ÄŸretilir. BirÃ§oÄŸu Ã¶ÄŸretilmez ve Ã¶zel problem bazlÄ± iÃ§gÃ¶rÃ¼lere baÄŸÄ±mlÄ±dÄ±r. Ama Ã¶zellik mÃ¼hendisliÄŸine varsayÄ±lan olarak odaklanma zihniyeti geliÅŸtirilebilir ve genellikle iyi hale gelmek yÄ±llar alÄ±r.
> 
> 
> 
> **Kaggle iÃ§in kullanmanÄ±zÄ± Ã¶nereceÄŸiniz araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> XGBoost her ÅŸey iÃ§in yeter!
> 
> 

### Pseudo-labeling *(Sahte etiketleme)*

EÄŸitim iÃ§in kullanÄ±lan Ã¶rnek sayÄ±sÄ±nÄ±n fark yaratabileceÄŸi yarÄ±ÅŸmalarda, **sahte etiketleme (pseudo-labeling)**, test setinden alÄ±nan ek Ã¶rnekler sayesinde skorlarÄ±nÄ±zÄ± artÄ±rabilir. Fikir, tahminlerinden emin olduÄŸunuz test seti Ã¶rneklerini eÄŸitim setinize eklemektir.

Kredi deÄŸerliliÄŸi (credit underwriting) Ã§ok zor bir veri bilimi problemidir ve Ã§ok akÄ±llÄ±ca Ã¶zellik mÃ¼hendisliÄŸi ve gÃ¼venilir bir doÄŸrulama ÅŸemasÄ± gerektirir. Benim kiÅŸisel iÃ§gÃ¶rÃ¼m, Ã¶zellik seÃ§imi iÃ§in basit lineer modellemeyi kullanmaktÄ± ve bu genel modelimize yardÄ±mcÄ± oldu. Ekibimiz bu yarÄ±ÅŸmayÄ± kazandÄ± ve bugÃ¼n hÃ¢lÃ¢ bu zaferi Kaggle kariyerimin en Ã¶nemli noktasÄ± olarak gÃ¶rÃ¼yorum.

Kaggle kariyerinize yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?
Kaggle, ML kariyerimin en bÃ¼yÃ¼k hÄ±zlandÄ±rÄ±cÄ±sÄ± oldu. Sahip olduÄŸum dÃ¶rt ML iÅŸinden Ã¼Ã§Ã¼nÃ¼n doÄŸrudan Kaggle baÅŸarÄ±mÄ±n bir sonucu olduÄŸunu sÃ¶yleyebilirim. Kaggle baÅŸarÄ±sÄ±nÄ±n bir kariyer iÃ§in ne kadar Ã¶nemli olabileceÄŸini abartmak imkÃ¢nsÄ±zdÄ±r.

Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neleri gÃ¶z ardÄ± ediyor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilmenizi istediÄŸiniz ÅŸeyler nelerdi?
TÃ¼m ML problemlerinin, Ã¶zellikle Kaggle yarÄ±ÅŸmalarÄ±nÄ±n, uzun sÃ¼re ya az deÄŸer verdiÄŸim ya da yeterince Ã¶nemsemediÄŸim iki yÃ¶nÃ¼ vardÄ±r: **Ã¶zellik mÃ¼hendisliÄŸi** ve **saÄŸlam bir doÄŸrulama stratejisi**. ML kÃ¼tÃ¼phanelerini ve algoritmalarÄ±nÄ± Ã§ok seviyorum ve genellikle mÃ¼mkÃ¼n olan en kÄ±sa sÃ¼rede ML algoritmasÄ±nÄ± kurmaya baÅŸlÄ±yorum. Ama model performansÄ±na en bÃ¼yÃ¼k etkiyi Ã§ok iyi Ã¶zellikler saÄŸlar. Ne yazÄ±k ki, Ã¶zellik mÃ¼hendisliÄŸi daha Ã§ok bir sanat ve daha az bir bilimdir ve genellikle modele ve veri setine baÄŸlÄ±dÄ±r. Daha ilginÃ§ Ã¶zellik mÃ¼hendisliÄŸi hilelerinin ve uygulamalarÄ±nÄ±n Ã§oÄŸu standart ML kurslarÄ±nda veya kaynaklarÄ±nda nadiren Ã¶ÄŸretilir. BirÃ§oÄŸu Ã¶ÄŸretilmez ve Ã¶zel problem bazlÄ± iÃ§gÃ¶rÃ¼lere baÄŸÄ±mlÄ±dÄ±r. Ama Ã¶zellik mÃ¼hendisliÄŸine varsayÄ±lan olarak odaklanma zihniyeti geliÅŸtirilebilir ve genellikle iyi hale gelmek yÄ±llar alÄ±r.

Kaggle iÃ§in kullanmanÄ±zÄ± Ã¶nereceÄŸiniz araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?
**XGBoost her ÅŸey iÃ§in yeter!**

---

Sahte etiketleme ilk olarak **Santander Customer Transaction Prediction** yarÄ±ÅŸmasÄ±nda team Wizardry tarafÄ±ndan tanÄ±tÄ±ldÄ± (detaylar: [https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003](https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003)). Sahte etiketleme, modele daha fazla veri saÄŸladÄ±ÄŸÄ± iÃ§in katsayÄ±larÄ±nÄ± geliÅŸtirmesine yardÄ±mcÄ± olur, ancak her zaman iÅŸe yaramayabilir. Ã–ncelikle bazÄ± yarÄ±ÅŸmalarda buna gerek yoktur; sahte etiketler eklemek sonucu deÄŸiÅŸtirmeyebilir ve eklenen gÃ¼rÃ¼ltÃ¼ varsa sonucu kÃ¶tÃ¼leÅŸtirebilir.

> Ne yazÄ±k ki, sahte etiketlemenin bir yarÄ±ÅŸmada iÅŸe yarayÄ±p yaramayacaÄŸÄ±nÄ± Ã¶nceden kesin olarak bilmek mÃ¼mkÃ¼n deÄŸildir (bunu deneysel olarak test etmeniz gerekir). Ã–ÄŸrenme eÄŸrilerini Ã§izmek, daha fazla verinin faydalÄ± olup olmayacaÄŸÄ±na dair ipucu verebilir (Ã¶rnek: [https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)).

Ä°kinci olarak, test seti tahminlerinin hangi kÄ±sÄ±mlarÄ±nÄ± ekleyeceÄŸinize veya tÃ¼m prosedÃ¼rÃ¼ en iyi sonuÃ§ iÃ§in nasÄ±l ayarlayacaÄŸÄ±nÄ±za karar vermek kolay deÄŸildir. Genel prosedÃ¼r ÅŸudur:

1. Modelinizi eÄŸitin
2. Test setinde tahmin yapÄ±n
3. GÃ¼ven Ã¶lÃ§Ã¼sÃ¼ belirleyin
4. Eklenecek test seti Ã¶rneklerini seÃ§in
5. BirleÅŸtirilmiÅŸ veri ile yeni bir model oluÅŸturun
6. Bu modelle tahmin yapÄ±n ve gÃ¶nderin

Ã–rnek bir sahte etiketleme prosedÃ¼rÃ¼ Chris Deotte tarafÄ±ndan **Instant Gratification** yarÄ±ÅŸmasÄ±nda sunulmuÅŸtur: [https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969)

Sahte etiketleme uygularken dikkate almanÄ±z gereken birkaÃ§ nokta:

* EÄŸitilebilir ve iyi tahminler Ã¼reten bir modeliniz olmalÄ±; aksi takdirde sadece gÃ¼rÃ¼ltÃ¼ eklemiÅŸ olursunuz.
* Test setinde mÃ¼kemmel tahminler mÃ¼mkÃ¼n olmadÄ±ÄŸÄ±ndan, iyi olanlarÄ± kÃ¶tÃ¼ olanlardan ayÄ±rmanÄ±z gerekir. CV katlarÄ±yla tahmin yapÄ±yorsanÄ±z, tahminlerin standart sapmasÄ±nÄ± kontrol edin ve yalnÄ±zca standart sapmasÄ± en dÃ¼ÅŸÃ¼k olan test Ã¶rneklerini seÃ§in. OlasÄ±lÄ±k tahmini yapÄ±yorsanÄ±z, yalnÄ±zca yÃ¼ksek veya dÃ¼ÅŸÃ¼k uÃ§ tahminleri kullanÄ±n (modelin daha emin olduÄŸu durumlar).
* Ä°kinci aÅŸamada, eÄŸitim Ã¶rneklerini test Ã¶rnekleriyle birleÅŸtirirken, test Ã¶rneklerinin %50â€™den fazla olmamasÄ±na dikkat edin. Ä°deal olarak, %70 orijinal eÄŸitim ve %30 sahte etiketli Ã¶rnek en iyisidir. Ã‡ok fazla sahte etiket eklerseniz, yeni modeliniz orijinal veriden Ã§ok test Ã¶rneklerinden Ã¶ÄŸrenir ve performans dÃ¼ÅŸer.

> Sahte etiketlere tamamen gÃ¼venemeyeceÄŸinizi unutmayÄ±n; test tahminlerini eÄŸitim Ã¶rnekleri olarak kullanmak verilerinizi kÄ±smen bozmak demektir. Bu yÃ¶ntem, saÄŸladÄ±ÄŸÄ± faydalar olumsuz etkilerden fazlaysa iÅŸe yarar.

* EÄŸer doÄŸrulama ile erken durdurma, hiperparametre ayarlama veya model deÄŸerlendirme yapÄ±yorsanÄ±z, sahte etiketleri doÄŸrulamada kullanmayÄ±n. YanÄ±ltÄ±cÄ± olabilir. Her zaman orijinal eÄŸitim verisini kullanÄ±n.
* MÃ¼mkÃ¼nse sahte etiketleri tahmin etmek iÃ§in farklÄ± bir model, final modeli eÄŸitmek iÃ§in ise orijinal ve sahte etiketlerle baÅŸka bir model kullanÄ±n. BÃ¶ylece Ã¶nceki modelden aynÄ± bilgiyi tekrar etmeyip, sahte etiketlerden yeni bilgiler Ã§Ä±karÄ±rsÄ±nÄ±z.

Ã–zetle, sahte etiketleme daha Ã§ok bir sanattÄ±r. BazÄ± yarÄ±ÅŸmalarda fark yaratabilir, ancak iyi uygulanmasÄ± gerekir. Bir kaynak olarak dÃ¼ÅŸÃ¼nÃ¼n ve her zaman en az bir sahte etiket tabanlÄ± gÃ¶nderim deneyin.

### Denoising with autoencoders *(Otoenkoderlerle gÃ¼rÃ¼ltÃ¼ giderme)*

Otomatik kodlayÄ±cÄ±lar (Autoencoders), baÅŸlangÄ±Ã§ta doÄŸrusal olmayan veri sÄ±kÄ±ÅŸtÄ±rma (bir tÃ¼r doÄŸrusal olmayan PCA) ve gÃ¶rÃ¼ntÃ¼ gÃ¼rÃ¼ltÃ¼ giderme iÅŸlemleriyle daha Ã§ok tanÄ±nÄ±rken, Michael Jahrerâ€™in ([https://www.kaggle.com/mjahrer](https://www.kaggle.com/mjahrer)) Porto Seguroâ€™s Safe Driver Prediction yarÄ±ÅŸmasÄ±nÄ± ([https://www.kaggle.com/c/porto-seguro-safe-driver-prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)) kazanmak iÃ§in bunlarÄ± baÅŸarÄ±lÄ± bir ÅŸekilde kullanmasÄ±ndan sonra tabular veri yarÄ±ÅŸmalarÄ±nda ilginÃ§ bir araÃ§ olarak tanÄ±nmaya baÅŸladÄ±. Porto Seguro, Ã¶zellikle gÃ¼rÃ¼ltÃ¼lÃ¼ Ã¶zelliklerle karakterize edilmiÅŸ, popÃ¼ler bir sigorta tabanlÄ± risk analiz yarÄ±ÅŸmasÄ±ydÄ± ve 5.000â€™den fazla katÄ±lÄ±mcÄ±ya sahipti.

Michael Jahrer, sayÄ±sal verilerin sonraki sinir aÄŸÄ± denetimli Ã¶ÄŸrenme iÃ§in daha iyi bir temsilini nasÄ±l bulduÄŸunu, gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±lar (Denoising Autoencoders - DAE) kullanarak aÃ§Ä±klamaktadÄ±r. Bir DAE, aÄŸÄ±n ortasÄ±ndaki gizli katmanlarÄ±n aktivasyonlarÄ±na ve bilgiyi kodlayan orta katman aktivasyonlarÄ±na dayanarak Ã§ok sayÄ±da yeni Ã¶zellik Ã¼reten bir veri seti oluÅŸturabilir.

ÃœnlÃ¼ gÃ¶nderisinde ([https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629)), Michael Jahrer, bir DAEâ€™nin sadece gÃ¼rÃ¼ltÃ¼yÃ¼ kaldÄ±rmakla kalmayÄ±p aynÄ± zamanda otomatik olarak yeni Ã¶zellikler oluÅŸturabileceÄŸini ve bÃ¶ylece Ã¶zelliklerin temsilinin, gÃ¶rÃ¼ntÃ¼ yarÄ±ÅŸmalarÄ±nda olduÄŸu gibi Ã¶ÄŸrenildiÄŸini anlatmaktadÄ±r. GÃ¶nderide, DAE yÃ¶nteminin gizli sÄ±rrÄ±nÄ±n sadece katmanlar deÄŸil, veriyi artÄ±rmak iÃ§in eklenen gÃ¼rÃ¼ltÃ¼ olduÄŸunu belirtmiÅŸtir. AyrÄ±ca bu tekniÄŸin, eÄŸitim ve test verilerinin birleÅŸtirilmesini gerektirdiÄŸini ve dolayÄ±sÄ±yla yÃ¶ntemin Kaggle yarÄ±ÅŸmasÄ±nÄ± kazanmanÄ±n Ã¶tesinde uygulamalarÄ± olmayacaÄŸÄ±nÄ± vurgulamÄ±ÅŸtÄ±r. AslÄ±nda, bu kazanma baÅŸarÄ±sÄ±ndan sonra teknik forumlardan ve Ã§oÄŸu yarÄ±ÅŸmadan kaybolmuÅŸ, ta ki Tabular Playground Series sÄ±rasÄ±nda tekrar ortaya Ã§Ä±kana kadar.

DAEâ€™ler teknik olarak bir kodlayÄ±cÄ± (encoder) ve bir Ã§Ã¶zÃ¼cÃ¼den (decoder) oluÅŸur. KodlayÄ±cÄ± kÄ±smÄ±, eÄŸitim verilerini giriÅŸ olarak alÄ±r ve ardÄ±ndan birkaÃ§ yoÄŸun katman (dense layer) gelir. Ä°deal olarak, tÃ¼m eÄŸitim bilgisini kodlayan bir gizli orta katman bulunur. Bu orta katmandaki dÃ¼ÄŸÃ¼m sayÄ±sÄ± orijinal giriÅŸ boyutundan kÃ¼Ã§Ã¼kse, bir sÄ±kÄ±ÅŸtÄ±rma yapÄ±lmÄ±ÅŸ olur ve istatistiksel olarak giriÅŸ verisinin Ã¼retim sÃ¼recinin arkasÄ±ndaki gizli boyutlarÄ± temsil edersiniz; aksi takdirde, sadece fazlalÄ±klarÄ± ortadan kaldÄ±rÄ±r ve gÃ¼rÃ¼ltÃ¼yÃ¼ sinyalden ayÄ±rÄ±rsÄ±nÄ±z (bu da kÃ¶tÃ¼ bir sonuÃ§ deÄŸildir).

KatmanÄ±n ikinci kÄ±smÄ± olan Ã§Ã¶zÃ¼cÃ¼ (decoder) kÄ±smÄ±nda ise katmanlarÄ± tekrar geniÅŸleterek orijinal giriÅŸ boyutuna kavuÅŸturursunuz. Ã‡Ä±ktÄ±, aÄŸÄ±n geri yayÄ±lÄ±mÄ± (backpropagation) iÃ§in hata kaybÄ±nÄ± (error loss) hesaplamak Ã¼zere giriÅŸle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

Bu Ã§Ã¶zÃ¼mlerden, DAEâ€™lerin iki tÃ¼rde olduÄŸunu Ã§Ä±karabiliriz:
* **Bottleneck DAEâ€™ler**: GÃ¶rÃ¼ntÃ¼ iÅŸleme yÃ¶ntemlerini taklit ederek, kodlayÄ±cÄ± kÄ±smÄ± Ã§Ã¶zÃ¼cÃ¼ kÄ±sÄ±mdan ayÄ±ran orta katmandaki aktivasyonlarÄ± yeni Ã¶zellik olarak alÄ±rsÄ±nÄ±z. Bu mimariler kum saati (hourglass) ÅŸekline sahiptir; Ã¶nce katman katman nÃ¶ron sayÄ±sÄ±nÄ± orta bottleneck katmanÄ±na kadar azaltÄ±r, ardÄ±ndan ikinci kÄ±sÄ±mda tekrar geniÅŸletirsiniz. Gizli katman sayÄ±sÄ± her zaman tek sayÄ±dÄ±r.

![](im/1060.png)

* **Derin yÄ±ÄŸÄ±n (deep stack) DAEâ€™lerde**, kodlayÄ±cÄ±, Ã§Ã¶zÃ¼cÃ¼ veya orta katman ayrÄ±mÄ± yapmadan tÃ¼m gizli katmanlarÄ±n aktivasyonlarÄ± alÄ±nÄ±r. Bu mimarilerde katmanlar aynÄ± boyuttadÄ±r. Gizli katman sayÄ±sÄ± tek veya Ã§ift olabilir.

![](im1061.png)

BahsettiÄŸimiz gibi, sÄ±kÃ§a tartÄ±ÅŸÄ±lan Ã¶nemli bir konu, DAEâ€™nize (Denoising Autoencoder) biraz rastgele gÃ¼rÃ¼ltÃ¼ eklemektir. Her tÃ¼rlÃ¼ DAEâ€™yi eÄŸitmeye yardÄ±mcÄ± olmak iÃ§in, eÄŸitim verilerini artÄ±racak ve aÅŸÄ±rÄ± parametreli sinir aÄŸÄ±nÄ±n sadece girdileri ezberlemesini (baÅŸka bir deyiÅŸle overfittingâ€™i) Ã¶nleyecek gÃ¼rÃ¼ltÃ¼yÃ¼ eklemeniz gerekir. Porto Seguro yarÄ±ÅŸmasÄ±nda Michael Jahrer, swap noise adÄ± verilen bir teknik kullanarak gÃ¼rÃ¼ltÃ¼ eklemiÅŸtir ve bunu ÅŸÃ¶yle aÃ§Ä±klamÄ±ÅŸtÄ±r:

> Burada yukarÄ±daki tabloda â€œinputSwapNoiseâ€ olarak belirtilen belirli bir olasÄ±lÄ±k ile Ã¶zellikten Ã¶rnek alÄ±yorum. 0.15, Ã¶zelliklerin %15â€™inin baÅŸka bir satÄ±rdan alÄ±nan deÄŸerlerle deÄŸiÅŸtirilmesi anlamÄ±na geliyor.

Burada anlatÄ±lan, temel olarak mixup adÄ± verilen bir veri artÄ±rma (augmentation) tekniÄŸidir (bu yÃ¶ntem gÃ¶rÃ¼ntÃ¼ artÄ±rmada da kullanÄ±lÄ±r: [https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412)). Tablo verileri iÃ§in mixup uygularken, karÄ±ÅŸtÄ±rma olasÄ±lÄ±ÄŸÄ±nÄ± belirlersiniz. Bu olasÄ±lÄ±ÄŸa baÄŸlÄ± olarak, bir Ã¶rnekteki bazÄ± orijinal deÄŸerleri, aynÄ± eÄŸitim verisinden daha az veya daha Ã§ok benzer bir Ã¶rnekten alÄ±nan deÄŸerlerle deÄŸiÅŸtirirsiniz.

Danzel, walkthroughâ€™unda ([https://www.kaggle.com/springmanndaniel/1st-place-turn-your-data-into-daeta](https://www.kaggle.com/springmanndaniel/1st-place-turn-your-data-into-daeta)) bunun Ã¼Ã§ yaklaÅŸÄ±mÄ±nÄ± aÃ§Ä±klamaktadÄ±r: sÃ¼tun bazlÄ±, satÄ±r bazlÄ± ve rastgele:

* **SÃ¼tun bazlÄ± gÃ¼rÃ¼ltÃ¼ deÄŸiÅŸimi (column-wise noise swapping)**: Belirli sayÄ±da sÃ¼tundaki deÄŸerleri deÄŸiÅŸtirirsiniz. DeÄŸiÅŸtirilecek sÃ¼tun oranÄ±, mixup olasÄ±lÄ±ÄŸÄ±na gÃ¶re belirlenir.
* **SatÄ±r bazlÄ± gÃ¼rÃ¼ltÃ¼ deÄŸiÅŸimi (row-wise noise swapping)**: Her satÄ±rdaki belirli sayÄ±da deÄŸeri deÄŸiÅŸtirirsiniz. Temelde, her satÄ±r aynÄ± oranda deÄŸiÅŸtirilmiÅŸ deÄŸer iÃ§erir, ancak deÄŸiÅŸtirilen Ã¶zellikler satÄ±rdan satÄ±ra farklÄ±lÄ±k gÃ¶sterir.
* **Rastgele gÃ¼rÃ¼ltÃ¼ deÄŸiÅŸimi (random noise swapping)**: DeÄŸiÅŸtirilecek deÄŸer sayÄ±sÄ±nÄ± mixup olasÄ±lÄ±ÄŸÄ±na gÃ¶re belirler ve tÃ¼m veri setinden rastgele seÃ§ersiniz (etki olarak satÄ±r bazlÄ± deÄŸiÅŸime benzerdir).

TÄ±pkÄ± pseudo-labelingâ€™de olduÄŸu gibi, DAE de bilimden Ã§ok bir sanattÄ±r; yani tamamen deneme-yanÄ±lma yÃ¶ntemine dayanÄ±r. Her zaman iÅŸe yaramayabilir ve bir problemde iÅŸe yarayan detaylar baÅŸka bir problemde faydalÄ± olmayabilir. YarÄ±ÅŸmanÄ±z iÃ§in iyi bir DAE elde etmek istiyorsanÄ±z, test edilmesi ve ayarlanmasÄ± gereken bir dizi unsuru gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±sÄ±nÄ±z:

* DAEâ€™nin mimarisi (derin yÄ±ÄŸÄ±n genellikle daha iyi Ã§alÄ±ÅŸÄ±r, ancak katman baÅŸÄ±na birim sayÄ±sÄ± ve katman sayÄ±sÄ±nÄ± belirlemeniz gerekir)
* Ã–ÄŸrenme oranÄ± ve batch boyutu
* Loss (sayÄ±sal ve kategorik Ã¶zelliklerin lossâ€™larÄ±nÄ± ayÄ±rmak da faydalÄ±dÄ±r)
* Durdurma noktasÄ± (en dÃ¼ÅŸÃ¼k loss her zaman en iyi sonuÃ§ deÄŸildir; mÃ¼mkÃ¼nse validation ve early stopping kullanÄ±n)

Probleme baÄŸlÄ± olarak, doÄŸru mimariyi kurmak ve dÃ¼zgÃ¼n Ã§alÄ±ÅŸacak ÅŸekilde ayarlamakta zorluk yaÅŸayabilirsiniz. Ancak Ã§abalarÄ±nÄ±z, nihai Ã¶zel leaderboardâ€™da yÃ¼ksek bir sonuÃ§la Ã¶dÃ¼llendirilebilir. AslÄ±nda, son tablo yarÄ±ÅŸmalarÄ±nda DAE teknikleri, birÃ§ok kazanan gÃ¶nderinin tarifinin bir parÃ§asÄ± olarak gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r:

* Danzel ([https://www.kaggle.com/springmanndaniel](https://www.kaggle.com/springmanndaniel)), [https://www.kaggle.com/c/tabular-playground-series-jan-2021/discussion/216037](https://www.kaggle.com/c/tabular-playground-series-jan-2021/discussion/216037) adresinde Ã¼Ã§ adet 1,500 nÃ¶ronlu gizli katmanÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± kullanarak, orijinal 14 sÃ¼tunu 4,500 sÃ¼tuna geniÅŸlettiÄŸini bildirmiÅŸtir. Bu yeni iÅŸlenmiÅŸ veri seti, diÄŸer sinir aÄŸlarÄ± ve gradient boosting modelleri iÃ§in girdi olarak kullanÄ±lmÄ±ÅŸtÄ±r.
* Ren Zhang ([https://www.kaggle.com/ryanzhang](https://www.kaggle.com/ryanzhang)), Ã§Ã¶zÃ¼mÃ¼nÃ¼ ([https://www.kaggle.com/c/tabular-playground-series-feb-2021/discussion/222745](https://www.kaggle.com/c/tabular-playground-series-feb-2021/discussion/222745)) paylaÅŸmÄ±ÅŸ ve kodunu ([https://github.com/ryancheunggit/Denoise-Transformer-AutoEncoder](https://github.com/ryancheunggit/Denoise-Transformer-AutoEncoder)) aÃ§Ä±klamÄ±ÅŸtÄ±r. Tipik lineer ve ReLU aktivasyonlu gizli katmanlar yerine stacked transformer encoder kullandÄ±ÄŸÄ±nÄ± ve uygun bir DAEâ€™yi eÄŸitmenin 20 saate kadar sÃ¼rebileceÄŸini belirtmiÅŸtir. Bu yaklaÅŸÄ±mda, veriye rastgele gÃ¼rÃ¼ltÃ¼ eklemeyi (gÃ¼rÃ¼ltÃ¼ maskesi kullanarak) ve lossâ€™u yalnÄ±zca orijinal veriyi yeniden oluÅŸturma hatasÄ±ndan deÄŸil, aynÄ± zamanda gÃ¼rÃ¼ltÃ¼ maskesinden hesaplamayÄ± Ã¶nermiÅŸtir. Bu birleÅŸik loss, aÄŸÄ±n daha iyi yakÄ±nsamasÄ±na yardÄ±mcÄ± olur.
* JianTT ([https://www.kaggle.com/jiangtt](https://www.kaggle.com/jiangtt)), Ã¶zellikle yeni gÃ¶zlemler oluÅŸturmak iÃ§in gÃ¼rÃ¼ltÃ¼ eklemenin, eksiksiz bir DAE oluÅŸturmadan daha iyi algoritmalar eÄŸitmek iÃ§in faydalÄ± olabileceÄŸini fark etmiÅŸtir: [https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/235739](https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/235739).

> Kendi DAEâ€™nizi kurmak iÃ§in Ã§ok fazla zaman harcamak istemiyorsanÄ±z, ama yarÄ±ÅŸmada iÅŸe yarayÄ±p yaramayacaÄŸÄ±nÄ± keÅŸfetmek istiyorsanÄ±z, Ã¶nceden hazÄ±rlanmÄ±ÅŸ birkaÃ§ Ã§Ã¶zÃ¼mÃ¼ deneyebilirsiniz. Ã–ncelikle Hung Khoiâ€™nin PyTorch aÄŸÄ± iÃ§in hazÄ±rladÄ±ÄŸÄ± Notebookâ€™a ([https://www.kaggle.com/hungkhoi/train-denoise-transformer-autoencoder](https://www.kaggle.com/hungkhoi/train-denoise-transformer-autoencoder)) bakabilir ve ihtiyacÄ±nÄ±za gÃ¶re uyarlayabilirsiniz. Ya da Jeong-Yoon Leeâ€™nin Kaggler kÃ¼tÃ¼phanesini ([https://www.kaggle.com/jeongyoonlee](https://www.kaggle.com/jeongyoonlee)) kullanabilirsiniz. Jeong-Yoon Lee Notebookâ€™unda, bunun Tabular Playground yarÄ±ÅŸmalarÄ±ndan birinde nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶stermektedir: [https://www.kaggle.com/jeongyoonlee/dae-with-2-lines-of-code-with-kaggler](https://www.kaggle.com/jeongyoonlee/dae-with-2-lines-of-code-with-kaggler).

### Neural networks for tabular competitions *(Tablo verisi yarÄ±ÅŸmalarÄ± iÃ§in sinir aÄŸlarÄ±)*

DAEâ€™li sinir aÄŸlarÄ±nÄ± tartÄ±ÅŸtÄ±ktan sonra, bu bÃ¶lÃ¼mÃ¼ sinir aÄŸlarÄ±nÄ±n tablo yarÄ±ÅŸmalarÄ±nda daha genel olarak nasÄ±l yardÄ±mcÄ± olabileceÄŸini ele alarak tamamlamamÄ±z gerekiyor. Gradient boosting Ã§Ã¶zÃ¼mleri hÃ¢lÃ¢ tablo yarÄ±ÅŸmalarÄ±nda (ve gerÃ§ek dÃ¼nya projelerinde) aÃ§Ä±k ara Ã¶nde olsa da, bazen sinir aÄŸlarÄ± gradient boosting modellerinin yakalayamadÄ±ÄŸÄ± sinyalleri yakalayabilir ve tek baÅŸÄ±na mÃ¼kemmel modeller veya bir ensemble iÃ§inde Ã¶ne Ã§Ä±kan modeller olabilir.

> GeÃ§miÅŸin ve gÃ¼nÃ¼mÃ¼zÃ¼n birÃ§ok Grandmasterâ€™Ä±nÄ±n sÄ±kÃ§a belirttiÄŸi gibi, farklÄ± modelleri (Ã¶rneÄŸin bir sinir aÄŸÄ± ve bir gradient boosting modeli) bir araya getirmek, tablo verisi problemlerinde tek baÅŸÄ±na kullanÄ±lan modellerden her zaman daha iyi sonuÃ§lar verir. Kaggleâ€™da daha Ã¶nce birinci olan Owen Zhang, sinir aÄŸlarÄ± ve GBMâ€™lerin bir yarÄ±ÅŸmada daha iyi sonuÃ§lar iÃ§in nasÄ±l uyumlu bir ÅŸekilde birleÅŸtirilebileceÄŸini ÅŸu rÃ¶portajda ayrÄ±ntÄ±lÄ± ÅŸekilde tartÄ±ÅŸÄ±yor: [https://www.youtube.com/watch?v=LgLcfZjNF44](https://www.youtube.com/watch?v=LgLcfZjNF44)

Bir tablo yarÄ±ÅŸmasÄ± iÃ§in hÄ±zlÄ±ca bir sinir aÄŸÄ± kurmak artÄ±k gÃ¶z korkutucu bir zorluk deÄŸil. TensorFlow/Keras ve PyTorch gibi kÃ¼tÃ¼phaneler iÅŸleri kolaylaÅŸtÄ±rÄ±yor ve TabNet gibi Ã¶nceden hazÄ±rlanmÄ±ÅŸ aÄŸlarÄ±n kÃ¼tÃ¼phanelerde paketlenmiÅŸ olmasÄ± iÅŸleri daha da kolaylaÅŸtÄ±rÄ±yor.

Kendi aÄŸÄ±nÄ±zÄ± hÄ±zlÄ± bir ÅŸekilde oluÅŸturmaya baÅŸlamak iÃ§in Ã§eÅŸitli kaynaklarÄ± kullanabilirsiniz. Ã–zellikle, yayÄ±nladÄ±ÄŸÄ±mÄ±z **Machine Learning Using TensorFlow Cookbook** kitabÄ±na ([https://www.packtpub.com/product/machine-learning-using-tensorflow-cookbook/9781800208865](https://www.packtpub.com/product/machine-learning-using-tensorflow-cookbook/9781800208865)) baÅŸvurmanÄ±zÄ± ÅŸiddetle Ã¶neririz; Ã§Ã¼nkÃ¼ kitabÄ±n bir bÃ¶lÃ¼mÃ¼, tablo verileri iÃ§in TensorFlow ile DNN (Derin Sinir AÄŸlarÄ±) kurmayÄ± kapsamlÄ± ÅŸekilde ele alÄ±yor (BÃ¶lÃ¼m 7, Predicting with Tabular Data). Kitapta ayrÄ±ca Kaggleâ€™da TensorFlow kullanÄ±mÄ±yla ilgili birÃ§ok Ã¶neri ve tarif de bulabilirsiniz.

Bunun dÄ±ÅŸÄ±nda, konuyu tanÄ±tmak iÃ§in bazÄ± Ã§evrimiÃ§i kaynaklara da baÅŸvurabilirsiniz. 30 Days of ML yarÄ±ÅŸmasÄ±nda Ã¶nerilen kaynaklar ÅŸunlardÄ±r:

* TensorFlowâ€™u tablo verileri iÃ§in nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± anlatan videoyu izleyin: [https://www.youtube.com/watch?v=nQgUt_uADSE](https://www.youtube.com/watch?v=nQgUt_uADSE)
* GitHubâ€™daki eÄŸitim kodunu kullanÄ±n: [https://github.com/lmassaron/deep_learning_for_tabular_data](https://github.com/lmassaron/deep_learning_for_tabular_data)
* En Ã¶nemlisi, yarÄ±ÅŸmada uygulanan eÄŸitim Notebookâ€™una gÃ¶z atÄ±n: [https://www.kaggle.com/lucamassaron/tutorial-tensorflow-2-x-for-tabular-data](https://www.kaggle.com/lucamassaron/tutorial-tensorflow-2-x-for-tabular-data)

Bu Ã§Ã¶zÃ¼mleri kurarken gÃ¶z Ã¶nÃ¼nde bulundurmanÄ±z gereken temel noktalar ÅŸunlardÄ±r:

* ReLU yerine GeLU, SeLU veya Mish gibi aktivasyon fonksiyonlarÄ±nÄ± kullanÄ±n; birÃ§ok Ã§alÄ±ÅŸmada tablo verilerini modellemek iÃ§in daha uygun olduÄŸu belirtilmiÅŸtir ve kendi deneyimlerimiz de genellikle daha iyi performans gÃ¶sterdiklerini doÄŸrulamaktadÄ±r.
* Batch boyutu ile denemeler yapÄ±n.
* Mixup ile veri artÄ±rmayÄ± (augmentation) kullanÄ±n (autoencoder bÃ¶lÃ¼mÃ¼nde tartÄ±ÅŸÄ±lmÄ±ÅŸtÄ±).
* SayÄ±sal Ã¶zelliklerde quantile dÃ¶nÃ¼ÅŸÃ¼mÃ¼ kullanÄ±n ve bunun sonucunda uniform veya Gaussian daÄŸÄ±lÄ±mlarÄ± zorlayÄ±n.
* Embedding katmanlarÄ±ndan faydalanÄ±n, ancak embeddinglerin her ÅŸeyi modellemediÄŸini unutmayÄ±n. AslÄ±nda, embeddingler gÃ¶mÃ¼lÃ¼ Ã¶zelliÄŸin diÄŸer tÃ¼m Ã¶zelliklerle etkileÅŸimlerini kaÃ§Ä±rÄ±r (bu yÃ¼zden bu etkileÅŸimleri doÄŸrudan feature engineering ile aÄŸa dahil etmelisiniz).

Ã–zellikle, embedding katmanlarÄ±nÄ±n yeniden kullanÄ±labilir olduÄŸunu unutmayÄ±n. AslÄ±nda, sadece giriÅŸ (yÃ¼ksek kardinaliteli deÄŸiÅŸkenin seyrek one-hot kodlamasÄ±) ile dÃ¼ÅŸÃ¼k boyutlu yoÄŸun bir vektÃ¶r arasÄ±ndaki matris Ã§arpÄ±mÄ±ndan oluÅŸur. EÄŸitilmiÅŸ bir sinir aÄŸÄ±nÄ±n embeddingini kaydederek, aynÄ± Ã¶zelliÄŸi dÃ¶nÃ¼ÅŸtÃ¼rebilir ve ortaya Ã§Ä±kan embeddingleri gradient boostingâ€™tan lineer modellere kadar birÃ§ok farklÄ± algoritmada kullanabilirsiniz.

24 seviyeli kategorik bir deÄŸiÅŸkeni iÃ§eren sÃ¼reci daha iyi anlamak iÃ§in Åekil 7.6â€™daki diyagrama bakÄ±n. Grafikte, bir kategorik Ã¶zelliÄŸin deÄŸerinin metin veya tamsayÄ±dan, bir sinir aÄŸÄ±nÄ±n iÅŸleyebileceÄŸi bir deÄŸerler vektÃ¶rÃ¼ne nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼ÄŸÃ¼ gÃ¶sterilmektedir.

![](im/1062.png)

Her ÅŸey, Ã¶zelliÄŸin kaÃ§ farklÄ± deÄŸere sahip olduÄŸunu bilmekle baÅŸlar. Bu, sÃ¶zlÃ¼k boyutunu oluÅŸturur ve Ã¶nemli bir bilgidir. Bu Ã¶rnekte, 24 farklÄ± deÄŸere sahip bir Ã¶zellik ele alÄ±nmÄ±ÅŸtÄ±r. Bu bilgi, her olasÄ± Ã¶zellik deÄŸerini temsil eden 24 boyutlu bir one-hot kodlamalÄ± vektÃ¶r oluÅŸturmamÄ±zÄ± saÄŸlar. Elde edilen vektÃ¶r, satÄ±r boyutu one-hot vektÃ¶rÃ¼nÃ¼n boyutuna, sÃ¼tun boyutu ise Ã§Ä±ktÄ± boyutlarÄ±na karÅŸÄ±lÄ±k gelen bir matris ile Ã§arpÄ±lÄ±r. Bu ÅŸekilde, vektÃ¶r-matris Ã§arpÄ±mÄ±yla kategorik deÄŸiÅŸkenin girdisi Ã§ok boyutlu sayÄ±sal bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Ã‡arpmanÄ±n etkinliÄŸi, sinir aÄŸÄ±nÄ±n geri yayÄ±lÄ±m (backpropagation) algoritmasÄ± tarafÄ±ndan saÄŸlanÄ±r; algoritma matrisin her deÄŸerini gÃ¼ncelleyerek Ã§arpÄ±mdan en Ã¶ngÃ¶rÃ¼cÃ¼ sonucu elde eder.

EÄŸer TensorFlow veya PyTorch ile kendi derin sinir aÄŸÄ±nÄ±zÄ± kurmak istemiyorsanÄ±z, birkaÃ§ hazÄ±r mimari Ã§Ã¶zÃ¼mden faydalanabilirsiniz. Bu Ã§Ã¶zÃ¼mlerin tÃ¼mÃ¼ â€œout-of-the-boxâ€ yani kutudan Ã§Ä±ktÄ±ÄŸÄ± gibi kullanÄ±labilir; ya paketlenmiÅŸlerdir ya da diÄŸer Kaggle kullanÄ±cÄ±larÄ± orijinal makalelere dayanarak kodlamÄ±ÅŸlardÄ±r. Tablo yarÄ±ÅŸmalarÄ±ndaki baÅŸarÄ±larÄ±na dayanarak, kendiniz bir tablo yarÄ±ÅŸmasÄ±na girerken deneyebileceÄŸiniz baÅŸlÄ±ca Ã§Ã¶zÃ¼mler ÅŸunlardÄ±r:

* **TabNet**: Google araÅŸtÄ±rmacÄ±larÄ± tarafÄ±ndan geliÅŸtirilmiÅŸ bir aÄŸdÄ±r (ArÄ±k, S. O. ve Pfister, T. TabNet: Attentive interpretable tabular learning. arXiv 2020. [https://www.aaai.org/AAAI21Papers/AAAI-1063.ArikS.pdf](https://www.aaai.org/AAAI21Papers/AAAI-1063.ArikS.pdf)). Ä°lgili Ã¶zellikleri seÃ§ip iÅŸleme ve hem kategorik hem sayÄ±sal Ã¶zelliklerle akÄ±llÄ±ca baÅŸa Ã§Ä±kma sÃ¶zÃ¼ verir. Ayarlanacak Ã§ok hiperparametresi yoktur, ancak sonuÃ§lar ayarlanmamÄ±ÅŸ ve ayarlanmÄ±ÅŸ bir aÄŸ arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±k gÃ¶sterebilir (bu yÃ¼zden en iyi performans iÃ§in biraz zaman harcamak gerekir). Uygulamalar arasÄ±nda mÃ¼kemmel **pytorch-tabnet** paketi ([https://github.com/dreamquark-ai/tabnet](https://github.com/dreamquark-ai/tabnet)) veya Yirun Zhang tarafÄ±ndan kodlanmÄ±ÅŸ uygulamalar ([https://www.kaggle.com/gogo827jz](https://www.kaggle.com/gogo827jz)) yer alÄ±r. Bu uygulamalar Mechanism of Action (MoA) Prediction yarÄ±ÅŸmasÄ± iÃ§in tasarlanmÄ±ÅŸtÄ±r.

* **Neural Oblivious Decision Ensembles (NODE)**: Sinir aÄŸÄ±nda karar aÄŸacÄ±nÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± taklit etmeye Ã§alÄ±ÅŸan bir mimaridir (Popov, S., Morozov, S., ve Babenko, A. Neural oblivious decision ensembles for deep learning on tabular data. arXiv preprint arXiv:1909.06312, 2019. [https://arxiv.org/abs/1909.06312](https://arxiv.org/abs/1909.06312)). TensorFlow iÃ§in Yirun Zhangâ€™Ä±n sunduÄŸu uygulamayÄ± kullanabilirsiniz: [https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras](https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras) veya PyTorch iÃ§in: [https://www.kaggle.com/gogo827jz/moa-public-pytorch-node](https://www.kaggle.com/gogo827jz/moa-public-pytorch-node)

* **DiÄŸer modeller**: Wide & Deep, DeepFM, xDeepFM, AutoInt gibi geniÅŸ bir model yelpazesi mevcuttur; bunlarÄ±n Ã§oÄŸu faktorizasyon makinelerine dayanÄ±r ve genellikle tÄ±klama oranÄ± tahmini iÃ§in tasarlanmÄ±ÅŸtÄ±r. TÃ¼m bu sinir aÄŸlarÄ±nÄ± kendiniz kurmak zorunda deÄŸilsiniz; **DeepCTR** ([https://github.com/shenweichen/DeepCTR](https://github.com/shenweichen/DeepCTR)) veya **DeepTables** ([https://github.com/DataCanvasIO/deeptables](https://github.com/DataCanvasIO/deeptables)) gibi paketlere gÃ¼venebilirsiniz. Bu paketler, Categorical Feature Encoding Challenge II yarÄ±ÅŸmasÄ±nda ikinci ve birinci olan Changhao Lee ([https://www.kaggle.com/leechh](https://www.kaggle.com/leechh)) ve Jian Yang ([https://www.kaggle.com/jackguagua](https://www.kaggle.com/jackguagua)) tarafÄ±ndan Ã¶nerilmiÅŸtir.

SonuÃ§ olarak, kategorik Ã¶zellikler iÃ§in embedding katmanlarÄ± ve sayÄ±sal Ã¶zellikler iÃ§in dense katmanlarÄ± birleÅŸtirerek kendi tablo verisi sinir aÄŸÄ±nÄ±zÄ± oluÅŸturabilirsiniz. Ancak bu iÅŸe yaramazsa, iyi yazÄ±lmÄ±ÅŸ paketlerin saÄŸladÄ±ÄŸÄ± geniÅŸ Ã§Ã¶zÃ¼mlere her zaman gÃ¼venebilirsiniz. Yeni bir paket Ã§Ä±ktÄ±ÄŸÄ±nda gÃ¶zÃ¼nÃ¼z aÃ§Ä±k olsun; hem Kaggle yarÄ±ÅŸmalarÄ±nda hem de gerÃ§ek dÃ¼nya projelerinde performansÄ±nÄ±zÄ± artÄ±rabilir. AyrÄ±ca deneyimlerimize dayanarak bir tavsiye: Bir tablo yarÄ±ÅŸmasÄ±nda sinir aÄŸÄ±nÄ±n en iyi model olmasÄ±nÄ± beklemeyin; bu nadiren olur. Bunun yerine, klasik tablo veri modellerinden (gradient boosting modelleri ve sinir aÄŸlarÄ± gibi) Ã§Ã¶zÃ¼mleri harmanlayÄ±n; Ã§Ã¼nkÃ¼ bu modeller veriden farklÄ± sinyalleri yakalar ve bir ensemble iÃ§inde birleÅŸtirilebilir.

> Jean-FranÃ§ois Puget
> 
> [https://www.kaggle.com/cpmpml](https://www.kaggle.com/cpmpml)
> 
> 
> 
> Jean-FranÃ§ois Puget, namÄ± diÄŸer CPMP ile reproducibility (tekrarlanabilirlik) konusunun Ã¶nemi, veri ile Ã§alÄ±ÅŸma yÃ¶ntemleri, en iyi yarÄ±ÅŸmasÄ± ve daha fazlasÄ± hakkÄ±nda konuÅŸtuk. Kaggleâ€™da Competitions ve Discussions Grandmasterâ€™Ä± ve NVIDIA RAPIDSâ€™te Distinguished Engineer olarak birÃ§ok deÄŸerli gÃ¶rÃ¼ÅŸ paylaÅŸtÄ±. EditÃ¶r Ã¶zellikle onun bilimsel yÃ¶ntemle ilgili sÃ¶ylediklerini Ã§ok beÄŸendi.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Bilimsel bir temele sahip yarÄ±ÅŸmalarÄ± ya da kendimle iliÅŸki kurabileceÄŸim bir temeli olan yarÄ±ÅŸmalarÄ± severim. Anonim veya sentetik verilerden hoÅŸlanmam, ancak veri Ã§ok hassas bir fizik simÃ¼lasyonu ile Ã¼retilmiÅŸse kabul edebilirim. Genel olarak, Ã§ok az bilgi sahibi olduÄŸum alanlardaki Kaggle yarÄ±ÅŸmalarÄ±nÄ± severim; Ã§Ã¼nkÃ¼ en Ã§ok Ã¶ÄŸrenme fÄ±rsatÄ±nÄ± burada buluyorum. Bu, sÄ±ralama puanÄ± kazanmak iÃ§in en etkili yol deÄŸil ama en Ã§ok eÄŸlendiÄŸim yol.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±lÄ±r? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±klarÄ±nÄ±zdan ne kadar farklÄ±?**
> 
> Veriye bakarak ve mÃ¼mkÃ¼n olduÄŸunca iyi anlayarak baÅŸlarÄ±m. Ã–zellikle Ã¶ngÃ¶rÃ¼cÃ¼ desenleri bulmaya Ã§alÄ±ÅŸÄ±rÄ±m. SÄ±klÄ±kla iki Ã¶zelliÄŸi veya tÃ¼retilmiÅŸ Ã¶zellikleri x ve y eksenine, Ã¼Ã§Ã¼ncÃ¼ bir Ã¶zelliÄŸi ise renk kodlamasÄ± iÃ§in kullanarak Ã¶rnekleri Ã§izerim. ÃœÃ§ Ã¶zellikten biri hedef olabilir. GÃ¶rselleÅŸtirme Ã§ok kullanÄ±rÄ±m; Ã§Ã¼nkÃ¼ insan gÃ¶rselliÄŸinin veri analizinde en iyi araÃ§ olduÄŸuna inanÄ±yorum.
> 
> 
> 
> Ä°kinci olarak, model veya pipeline performansÄ±nÄ± deÄŸerlendirmeye zaman ayÄ±rÄ±rÄ±m. Model performansÄ±nÄ± olabildiÄŸince doÄŸru bir ÅŸekilde deÄŸerlendirebilmek son derece Ã¶nemlidir. DeÄŸerlendirme genellikle k-fold cross-validationâ€™Ä±n bir Ã§eÅŸididir, ancak fold tanÄ±mÄ± yarÄ±ÅŸma tÃ¼rÃ¼ne gÃ¶re uyarlanabilir (Ã¶rneÄŸin tahmin yarÄ±ÅŸmalarÄ±nda zaman bazlÄ± foldâ€™lar, Ã¶rnekler bir ÅŸekilde baÄŸlantÄ±lÄ±ysa group k-fold, Ã¶r. aynÄ± kullanÄ±cÄ± IDâ€™sine sahip aksiyonlar).
> 
> 
> 
> ArdÄ±ndan, veri giriÅŸinden submissionâ€™a kadar giden bir baseline pipeline oluÅŸturur ve test ederim. Kod yarÄ±ÅŸmalarÄ±nda, pipelineâ€™Ä±n doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test etmek kritik Ã¶nemdedir.
> 
> 
> 
> Daha sonra daha karmaÅŸÄ±k modelleri (derin Ã¶ÄŸrenme kullanÄ±yorsam) veya daha fazla Ã¶zelliÄŸi (XGBoost veya RAPIDS/sklearn modelleri kullanÄ±yorsam) denerim. BunlarÄ± submit ederek lokal deÄŸerlendirme skorum ile public test skorunun korelasyonunu gÃ¶zlemlerim. Korelasyon iyiyse submit sayÄ±sÄ±nÄ± azaltÄ±rÄ±m.
> 
> 
> 
> BirkaÃ§ hafta sonra hiperparametre ayarlamasÄ± yaparÄ±m, ama bunu yalnÄ±zca bir kez ya da belki yarÄ±ÅŸma sonuna yakÄ±n ikinci kez yaparÄ±m. Ã‡Ã¼nkÃ¼ hiperparametre ayarlamasÄ± overfittingâ€™e neden olabilecek en kolay yollardan biridir ve overfitting konusunda Ã§ok dikkatliyim.
> 
> 
> 
> **GirdiÄŸiniz Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemlerden bahseder misiniz?**
> 
> En gurur duyduÄŸum yarÄ±ÅŸmalardan biri, TalkingData AdTracking Fraud Detection Challengeâ€™dir. Ã‡ok bÃ¼yÃ¼k bir tÄ±klama geÃ§miÅŸi vardÄ± ve hangi tÄ±klamalarÄ±n uygulama indirmelerine yol aÃ§tÄ±ÄŸÄ±nÄ± tahmin etmemiz gerekiyordu. Ã–zellikler Ã§ok az, satÄ±r sayÄ±sÄ± Ã§ok fazlaydÄ± (yaklaÅŸÄ±k yarÄ±m milyar). O zamanlar yalnÄ±zca 64 GB makinam vardÄ± ve yeni Ã¶zellikler oluÅŸturup deÄŸerlendirmek iÃ§in Ã§ok verimli bir yÃ¶ntem uygulamak zorundaydÄ±m.
> 
> 
> 
> BazÄ± Ã§Ä±karÄ±mlarÄ±m oldu:
> 
> 
> 
> 1. Uygulama indirmeye yol aÃ§an tÄ±klama, kullanÄ±cÄ±nÄ±n uygulama indirme sayfasÄ±ndaki son tÄ±klamaydÄ±. Bu nedenle â€œaynÄ± kullanÄ±cÄ± ve uygulama iÃ§in bir sonraki tÄ±klamaya kadar geÃ§en sÃ¼reâ€ en Ã¶nemli Ã¶zellikti.
> 
> 2. AynÄ± kullanÄ±cÄ± ve uygulamadan aynÄ± zaman damgasÄ±na sahip birÃ§ok tÄ±klama vardÄ±; indirme olan varsa, bunun son tÄ±klama olduÄŸunu varsaydÄ±m.
> 
> 3. Ã–zellik deÄŸerlerinin eÅŸzamanlÄ±lÄ±klarÄ±nÄ± tahmin etmek iÃ§in matris faktorizasyonu kullandÄ±m. O zaman Kerasâ€™ta bir libFM modeli uyguladÄ±m ve latent vektÃ¶rleri Ã¶zellik olarak eklemek faydalÄ± oldu.
> 
> 
> 
> Bunu uygulayan tek diÄŸer ekip, yarÄ±ÅŸmayÄ± kazanan ekipti. Bununla, Grandmaster olmayan birisi olarak ekipler arasÄ±nda 6. oldum.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? EÄŸer evet ise, nasÄ±l?**
> 
> Kaggle bana iki kez yardÄ±mcÄ± oldu:
> 
> 
> 
> 1. IBMâ€™de Kaggle, SOTA makine Ã¶ÄŸrenimi uygulamalarÄ± hakkÄ±nda bÃ¼yÃ¼k bir bilgi kaynaÄŸÄ±ydÄ±. Bu bilgiyi IBMâ€™in makine Ã¶ÄŸrenimi araÃ§larÄ±nÄ± (Watson Studio ve Watson Machine Learning) geliÅŸtirmek iÃ§in kullandÄ±m. Ã–rneÄŸin, 2016â€™da IBMâ€™in Python paketlerini desteklemesini saÄŸladÄ±m; o dÃ¶nemde IBM tamamen Java/Scala aÄŸÄ±rlÄ±klÄ±ydÄ±. Ben olmasaydÄ±m, IBM Spark ve Scalaâ€™ya yatÄ±rÄ±m yapacak ve Python dalgasÄ±nÄ± tamamen kaÃ§Ä±racaktÄ±. AyrÄ±ca IBMâ€™in yalnÄ±zca Spark ML veya TensorFlowâ€™u desteklemek istediÄŸi dÃ¶nemde XGBoostâ€™u erken desteklemeleri iÃ§in zorladÄ±m.
> 
> 2. Ä°kinci olarak, ÅŸu anki iÅŸimi elde etmemde Kaggle yardÄ±mcÄ± oldu. NVIDIA, Kaggle yarÄ±ÅŸma Grandmasterâ€™larÄ±nÄ± sosyal varlÄ±klarÄ± gÃ¼Ã§lÃ¼ olan kiÅŸileri arÄ±yordu ve bu kiÅŸiler NVIDIA stackâ€™ini ve RAPIDS GPU hÄ±zlandÄ±rmalÄ± ML paketini tanÄ±tmak iÃ§in Ã§alÄ±ÅŸÄ±yordu.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilmek istediÄŸiniz bir ÅŸey var mÄ±ydÄ±?**
> 
> Kagglers ile diÄŸer veri bilimciler arasÄ±ndaki fark, model performansÄ±nÄ± deÄŸerlendirme konusudur. EÄŸer bunu bilmezlerse, public leaderboardâ€™da iyi gÃ¶rÃ¼nen ancak private leaderboardâ€™da kÃ¶tÃ¼ performans gÃ¶steren submissionâ€™lar seÃ§erler. Private leaderboardâ€™da iyi performans gÃ¶steren modelleri kurmayÄ± bilen bir Kaggler, yeni veride de iyi performans gÃ¶steren, yani overfit olmayan modelleri kurmayÄ± Ã¶ÄŸrenir.
> 
> 
> 
> Deneyimsiz Kagglers sÄ±k sÄ±k â€œX yÃ¶ntemi/bu model bu yarÄ±ÅŸmada iÅŸe yarar mÄ±?â€ diye sorar. Benim cevabÄ±m her zaman: â€œDeneyin ve iÅŸe yarayÄ±p yaramadÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼n.â€ Makine Ã¶ÄŸrenimin deneysel bir bilim olduÄŸunu Ã§oÄŸu kiÅŸi kaÃ§Ä±rÄ±yor. Ä°yi modeller kurmak iÃ§in bilimsel yÃ¶ntem izlenmelidir:
> 
> 
> 
> * Hipotez oluÅŸturun (Ã¶rn. bu Ã¶zellik veya bu NN katmanÄ± pipeline performansÄ±nÄ± artÄ±racak)
> 
> * Hipotezi test etmek iÃ§in bir deney yÃ¼rÃ¼tÃ¼n (deÄŸiÅŸtirilen pipelineâ€™Ä± eÄŸitin)
> 
> * Deney sonuÃ§larÄ±nÄ± analiz edin (CV skoru Ã¶ncekinden daha iyi mi? Nerede daha iyi? Nerede kÃ¶tÃ¼?)
> 
> 
> 
> Her deney, bir hipotezi doÄŸrulamak veya reddetmek iÃ§in yapÄ±lmalÄ±dÄ±r ve her deney yalnÄ±zca bir deÄŸiÅŸkeni deÄŸiÅŸtirmelidir. Deneyimsiz kiÅŸiler genellikle birÃ§ok ÅŸeyi aynÄ± anda deÄŸiÅŸtirir ve neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± Ã§Ä±karamaz.
> 
> 
> 
> **Veri analizi ve makine Ã¶ÄŸrenimi iÃ§in Ã¶nereceÄŸiniz araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> 
> 
> * Veri keÅŸfi iÃ§in Ã§oÄŸunlukla **Matplotlib** kullanÄ±rÄ±m.
> 
> * KÃ¼Ã§Ã¼k veri setlerinde **Pandas**, bÃ¼yÃ¼k veri setlerinde **cuDF (RAPIDS)** ile veri iÅŸleme yaparÄ±m.
> 
> * Makine Ã¶ÄŸrenimi iÃ§in **cuML (RAPIDS)**, GPU hÄ±zlandÄ±rmalÄ± **XGBoost** ve **PyTorch** kullanÄ±rÄ±m.
> 
> * MÃ¼mkÃ¼nse Ã¶nceden eÄŸitilmiÅŸ modelleri kullanÄ±rÄ±m; Ã¶rneÄŸin Hugging Faceâ€™den NLP modelleri veya **timm** paketinden gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma modelleri.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken en Ã¶nemli ÅŸey nedir?**
> 
> YarÄ±ÅŸmaya yeterince zaman ayÄ±rabileceÄŸinizden emin olun.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggleâ€™daki tabular (tablo tabanlÄ±) yarÄ±ÅŸmalarÄ± ele aldÄ±k. Tablo tabanlÄ± bir yarÄ±ÅŸmada uygulanabilecek bilgilerin Ã§oÄŸu standart veri bilimi bilgi ve uygulamalarÄ±yla Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ iÃ§in, dikkatimiz daha Ã§ok Kaggleâ€™a Ã¶zgÃ¼ tekniklere odaklandÄ±.

Yeni tanÄ±tÄ±lan **Tabular Playground Series**â€™den baÅŸlayarak, reproducibility (tekrarlanabilirlik), EDA (Exploratory Data Analysis â€“ KeÅŸifsel Veri Analizi), feature engineering (Ã¶zellik mÃ¼hendisliÄŸi), feature selection (Ã¶zellik seÃ§imi), target encoding (hedef kodlama), pseudo-labeling (sahte etiketleme) ve tablo veri setlerine uygulanan neural network (sinir aÄŸÄ±) konularÄ±na deÄŸindik.

**EDA**, bir yarÄ±ÅŸmayÄ± kazanmak iÃ§in iÃ§gÃ¶rÃ¼ elde etmek istiyorsanÄ±z kritik bir aÅŸamadÄ±r. Ancak oldukÃ§a yapÄ±sÄ±zdÄ±r ve sahip olduÄŸunuz veri tÃ¼rÃ¼ne gÃ¼Ã§lÃ¼ ÅŸekilde baÄŸlÄ±dÄ±r. Genel EDA Ã¶nerilerinin yanÄ± sÄ±ra, tÃ¼m veri setinizi bir bakÄ±ÅŸta Ã¶zetleyebilecek **t-SNE** ve **UMAP** gibi tekniklere de dikkatinizi Ã§ektik.

Bir sonraki aÅŸama olan **feature engineering**, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z veri tÃ¼rÃ¼ne gÃ¼Ã§lÃ¼ bir ÅŸekilde baÄŸlÄ±dÄ±r. Bu nedenle, belirli durumunuza uygulayabileceÄŸiniz bir dizi olasÄ± Ã¶zellik mÃ¼hendisliÄŸi fikri sunduk.

**Feature selection** konusunda kÄ±sa bir genel bakÄ±ÅŸÄ±n ardÄ±ndan, hemen hemen her makine Ã¶ÄŸrenimi algoritmasÄ±na uygulanabilecek **Ã¶zellik Ã¶nemi** ve **rastgeleleÅŸtirme** temelli tekniklere dikkatinizi Ã§ektik.

Otomatik olarak iÅŸlenemeyeceÄŸini vurgulamak istediÄŸimiz **target encoding**â€™i aÃ§Ä±kladÄ±ktan sonra, muhtemelen gerÃ§ek dÃ¼nya projelerinizde uygulamayacaÄŸÄ±nÄ±z ama Kaggle yarÄ±ÅŸmalarÄ±nda Ã§ok iyi Ã§alÄ±ÅŸabilecek Ã¶zel tekniklere geÃ§tik: **pseudo-labeling** ve tablo yarÄ±ÅŸmalarÄ± iÃ§in **denoising autoencoder**.

Son olarak, kategorik Ã¶zelliklerin sinir aÄŸlarÄ±nda embedding katmanlarÄ± kullanÄ±larak nasÄ±l iÅŸlenebileceÄŸini tartÄ±ÅŸtÄ±ktan sonra, tablo verileri iÃ§in kullanÄ±labilecek hazÄ±r sinir aÄŸÄ± mimarilerinin kÄ±sa bir Ã¶zetini verdik.

Bir sonraki bÃ¶lÃ¼mde, tabular yarÄ±ÅŸmalara katÄ±lÄ±rken bilmeniz gereken tÃ¼m tekniklerin incelemesini **hyperparameter optimizasyonu** konusunu tartÄ±ÅŸarak tamamlayacaÄŸÄ±z.

---

## Chapter 8: Hyperparameter Optimization *(BÃ¶lÃ¼m 8: Hiperparametre Optimizasyonu)*

Bir Kaggle Ã§Ã¶zÃ¼mÃ¼nÃ¼n performansÄ±, yalnÄ±zca seÃ§tiÄŸiniz Ã¶ÄŸrenme algoritmasÄ±nÄ±n tÃ¼rÃ¼ ile belirlenmez. Verilerin ve kullandÄ±ÄŸÄ±nÄ±z Ã¶zelliklerin yanÄ± sÄ±ra, algoritmanÄ±n **hyperparameter**â€™larÄ± (eÄŸitim Ã¶ncesinde sabitlenmesi gereken ve eÄŸitim sÄ±rasÄ±nda Ã¶ÄŸrenilemeyen algoritma parametreleri) da performansÄ± gÃ¼Ã§lÃ¼ bir ÅŸekilde etkiler. Tablo veri yarÄ±ÅŸmalarÄ±nda doÄŸru deÄŸiÅŸkenleri/verileri/Ã¶zellikleri seÃ§mek en etkili yÃ¶ntemdir; ancak hyperparameter optimizasyonu, tÃ¼rÃ¼ ne olursa olsun tÃ¼m yarÄ±ÅŸmalarda etkilidir. AslÄ±nda, veri ve algoritma sabit olduÄŸunda, hyperparameter optimizasyonu algoritmanÄ±n tahmin performansÄ±nÄ± artÄ±rmanÄ±n ve leaderboardâ€™da yÃ¼kselmenin tek gÃ¼venilir yoludur. AyrÄ±ca, hyperparameter optimizasyonu **ensemble** yÃ¶ntemlerinde de faydalÄ±dÄ±r; Ã§Ã¼nkÃ¼ optimize edilmiÅŸ modellerin birleÅŸiminden oluÅŸan bir ensemble, optimize edilmemiÅŸ modellerin birleÅŸiminden her zaman daha iyi performans gÃ¶sterir.

Hyperparameterâ€™larÄ± manuel olarak ayarlamanÄ±n mÃ¼mkÃ¼n olduÄŸunu duyabilirsiniz; Ã¶zellikle seÃ§imlerinizin algoritma Ã¼zerindeki etkilerini biliyor ve anlÄ±yorsanÄ±z. BirÃ§ok Kaggle Grandmaster ve Master, yarÄ±ÅŸmalarda modellerini doÄŸrudan ayarlamaya sÄ±klÄ±kla gÃ¼vendiklerini belirtmiÅŸtir. Bu kiÅŸiler, en Ã¶nemli hyperparameterâ€™lar Ã¼zerinde **bisection (ikiye bÃ¶lme) yÃ¶ntemi** tarzÄ±nda Ã§alÄ±ÅŸÄ±r, bir parametrenin deÄŸer aralÄ±ÄŸÄ±nÄ± gittikÃ§e daraltarak en iyi sonucu Ã¼reten deÄŸeri bulurlar. ArdÄ±ndan diÄŸer parametreye geÃ§erler. Bu yÃ¶ntem, her parametre iÃ§in tek bir minimum varsa ve parametreler birbirinden baÄŸÄ±msÄ±zsa oldukÃ§a iyi Ã§alÄ±ÅŸÄ±r. Bu durumda arama, Ã§oÄŸunlukla deneyim ve Ã¶ÄŸrenme algoritmalarÄ±na dair bilgi ile yÃ¶nlendirilir.

Ancak deneyimlerimize gÃ¶re, Kaggleâ€™da karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z Ã§oÄŸu gÃ¶revde durum bÃ¶yle deÄŸildir. Problemlerin ve kullanÄ±lan algoritmalarÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±, yalnÄ±zca bir arama algoritmasÄ±nÄ±n saÄŸlayabileceÄŸi sistematik bir yaklaÅŸÄ±m gerektirir. Bu nedenle, bu bÃ¶lÃ¼mÃ¼ yazmaya karar verdik.

Bu bÃ¶lÃ¼mde, **cross-validation** yaklaÅŸÄ±mÄ±nÄ±zÄ± test setine genellenebilecek en iyi hyperparameterâ€™larÄ± bulacak ÅŸekilde nasÄ±l geniÅŸletebileceÄŸinizi inceleyeceÄŸiz. AmaÃ§, yarÄ±ÅŸmalarda karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z zaman ve kaynak kÄ±sÄ±tlamalarÄ±nÄ± yÃ¶netmektir. Bu nedenle, sahip olduÄŸunuz kaynaklara gÃ¶re karmaÅŸÄ±k modeller ve veri problemleri iÃ§in optimize edilmiÅŸ **Bayesian optimizasyon** yÃ¶ntemlerine odaklanacaÄŸÄ±z. YalnÄ±zca Ã¶nceden tanÄ±mlanmÄ±ÅŸ hyperparameterâ€™lar iÃ§in en iyi deÄŸerleri aramakla sÄ±nÄ±rlÄ± kalmayacak, aynÄ± zamanda **sinir aÄŸÄ± mimarisi** sorununa da deÄŸineceÄŸiz.

Ele alacaÄŸÄ±mÄ±z konular ÅŸunlardÄ±r:

* Temel optimizasyon teknikleri
* Ana parametreler ve nasÄ±l kullanÄ±lacaÄŸÄ±
* Bayesian optimizasyon

Hadi baÅŸlayalÄ±m!

### Basic optimization techniques *(Temel optimizasyon teknikleri)*

Hyperparameter optimizasyonunun temel algoritmalarÄ±, Scikit-learn paketinde bulunan **grid search** ve **random search**â€™tir. Son zamanlarda, Scikit-learn katkÄ±cÄ±larÄ±, hem grid search hem de random search stratejilerinin performansÄ±nÄ± artÄ±rmak iÃ§in **halving algoritmasÄ±nÄ±** da eklemiÅŸlerdir.

Bu bÃ¶lÃ¼mde, bu temel tekniklerin hepsini ele alacaÄŸÄ±z. BunlarÄ± Ã¶ÄŸrenerek, yalnÄ±zca bazÄ± Ã¶zel problemler iÃ§in etkili optimizasyon araÃ§larÄ±na sahip olmakla kalmayacak (Ã¶rneÄŸin, SVMâ€™ler genellikle grid search ile optimize edilir), aynÄ± zamanda hyperparameter optimizasyonunun temel mantÄ±ÄŸÄ±nÄ± da kavrayacaksÄ±nÄ±z.

BaÅŸlamak iÃ§in, gerekli bileÅŸenlerin neler olduÄŸunu belirlemek Ã§ok Ã¶nemlidir:

* Hyperparameterâ€™larÄ± optimize edilmesi gereken bir model
* Her hyperparameter iÃ§in aranacak deÄŸerlerin sÄ±nÄ±rlarÄ±nÄ± iÃ§eren bir **arama alanÄ±**
* Bir **cross-validation** ÅŸemasÄ±
* Bir **deÄŸerlendirme metriÄŸi** ve buna ait skor fonksiyonu

TÃ¼m bu Ã¶ÄŸeler, aradÄ±ÄŸÄ±nÄ±z Ã§Ã¶zÃ¼mÃ¼ belirlemek iÃ§in **arama yÃ¶ntemi** iÃ§inde bir araya gelir. Hadi nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± inceleyelim.

#### Grid search *(Izgara aramasÄ±)*

**Grid search**, hyperparameterâ€™larÄ± eksiksiz bir ÅŸekilde tarayan bir yÃ¶ntemdir ve yÃ¼ksek boyutlu uzaylarda uygulanabilirliÄŸi sÄ±nÄ±rlÄ±dÄ±r. Her parametre iÃ§in test etmek istediÄŸiniz bir deÄŸer kÃ¼mesi seÃ§ersiniz ve ardÄ±ndan bu kÃ¼medeki tÃ¼m olasÄ± kombinasyonlarÄ± denersiniz. Bu nedenle â€œeksiksizâ€ (exhaustive) olarak adlandÄ±rÄ±lÄ±r: her ÅŸeyi denersiniz. OldukÃ§a basit bir algoritmadÄ±r ve boyutsallÄ±k lanetine (curse of dimensionality) maruz kalÄ±r, ancak olumlu tarafÄ±, **embarrassingly parallel** olmasÄ±dÄ±r (bu bilgisayar bilimi teriminin tanÄ±mÄ± iÃ§in bkz. [link](https://www.cs.iusb.edu/~danav/teach/b424/b424_23_embpar.html)). Bu, yeterli sayÄ±da iÅŸlemciniz varsa, optimal ayarlamayÄ± Ã§ok hÄ±zlÄ± bir ÅŸekilde elde edebileceÄŸiniz anlamÄ±na gelir.

Ã–rnek olarak, bir sÄ±nÄ±flandÄ±rma problemi ve **support-vector machine (SVM)** sÄ±nÄ±flandÄ±rmasÄ±nÄ± ele alalÄ±m. SVMâ€™ler, hem sÄ±nÄ±flandÄ±rma hem de regresyon problemleri iÃ§in, grid searchâ€™Ã¼n en Ã§ok kullanÄ±lacaÄŸÄ± makine Ã¶ÄŸrenmesi algoritmalarÄ±ndan biridir. Scikit-learnâ€™Ã¼n **make_classification** fonksiyonunu kullanarak hÄ±zlÄ±ca bir sÄ±nÄ±flandÄ±rma veri seti oluÅŸturabiliriz:

```python
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

X, y = make_classification(n_samples=300, n_features=50,
                           n_informative=10,
                           n_redundant=25, n_repeated=15,
                           n_clusters_per_class=5,
                           flip_y=0.05, class_sep=0.5,
                           random_state=0)
```

Sonraki adÄ±m olarak, temel bir SVC algoritmasÄ± tanÄ±mlar ve arama alanÄ±nÄ± belirleriz. SVCâ€™nin kernel fonksiyonu (SVMâ€™de girdi verilerini dÃ¶nÃ¼ÅŸtÃ¼ren iÃ§ fonksiyon) farklÄ± hyperparameterâ€™larÄ± belirlediÄŸi iÃ§in, kernel tipine baÄŸlÄ± olarak kullanÄ±lacak parametrelerin iki farklÄ± sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ iÃ§eren bir liste saÄŸlarÄ±z. AyrÄ±ca deÄŸerlendirme metriÄŸini de belirleriz (bu Ã¶rnekte hedef dengeli olduÄŸundan **accuracy** kullanÄ±yoruz):

```python
from sklearn import svm
svc = svm.SVC(probability=True, random_state=1)

from sklearn import model_selection
search_grid = [
    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}
]

scorer = 'accuracy'
```

Ã–rneÄŸimizde, lineer kernel gamma parametresinin ayarlanmasÄ±nÄ± gerektirmez, ancak radial basis function (RBF) kernel iÃ§in bu parametre Ã§ok Ã¶nemlidir. Bu nedenle iki sÃ¶zlÃ¼k saÄŸlÄ±yoruz: ilki lineer kernel iÃ§in, ikincisi RBF kernel iÃ§in. Her sÃ¶zlÃ¼k yalnÄ±zca ilgili kernel ve bu kernel iÃ§in geÃ§erli parametre aralÄ±klarÄ±nÄ± iÃ§erir.

DeÄŸerlendirme metriÄŸinin, algoritmanÄ±n optimize ettiÄŸi **maliyet fonksiyonundan** farklÄ± olabileceÄŸini unutmamak Ã¶nemlidir. BÃ¶lÃ¼m 5â€™te tartÄ±ÅŸÄ±ldÄ±ÄŸÄ± gibi, bazÄ± yarÄ±ÅŸmalarda deÄŸerlendirme metriÄŸi farklÄ± olabilir, ancak algoritmanÄ±n maliyet fonksiyonu deÄŸiÅŸtirilemez. Bu durumlarda, hyperparameterâ€™larÄ± deÄŸerlendirme metriÄŸine gÃ¶re ayarlamak, iyi performans gÃ¶steren bir model elde etmeye yardÄ±mcÄ± olabilir. Optimal hyperparameter seti, bu kÄ±sÄ±tlar altÄ±nda en iyi deÄŸerlendirme metriÄŸini dÃ¶ndÃ¼recektir. Teorik olarak en iyi sonuÃ§ olmayabilir, ama genellikle ona yakÄ±n olur.

TÃ¼m bu bileÅŸenler (model, arama alanÄ±, deÄŸerlendirme metriÄŸi, cross-validation ÅŸemasÄ±) **GridSearchCV** Ã¶rneÄŸinde birleÅŸtirilir ve model veriye uyarlanÄ±r:

```python
search_func = model_selection.GridSearchCV(estimator=svc, 
                                           param_grid=search_grid,
                                           scoring=scorer, 
                                           n_jobs=-1,
                                           cv=5)

search_func.fit(X, y)
print(search_func.best_params_)
print(search_func.best_score_)
```

Bir sÃ¼re sonra, kullandÄ±ÄŸÄ±nÄ±z makineye baÄŸlÄ± olarak, **cross-validated** sonuÃ§lara gÃ¶re en iyi kombinasyonu elde edeceksiniz.

Ã–zetle, grid search Ã§ok basit bir optimizasyon algoritmasÄ±dÄ±r ve Ã§ok Ã§ekirdekli bilgisayarlarÄ±n avantajÄ±nÄ± kullanabilir. Ã‡ok az ayarlama gerektiren algoritmalarla (SVM, ridge veya lasso regresyonlarÄ± gibi) iyi Ã§alÄ±ÅŸabilir, ancak diÄŸer durumlarda uygulanabilirliÄŸi sÄ±nÄ±rlÄ±dÄ±r. Ã–ncelikle, yalnÄ±zca **diskret seÃ§imler** ile hyperparameter optimizasyonunu sÄ±nÄ±rlÄ±dÄ±r (yani sÄ±nÄ±rlÄ± bir deÄŸer kÃ¼mesi gerekir). AyrÄ±ca, birden fazla hyperparameterâ€™Ä±n ayarlanmasÄ± gereken algoritmalarda etkili olmasÄ±nÄ± bekleyemezsiniz. Bunun nedeni, arama alanÄ±nÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n hÄ±zla artmasÄ± ve Ã§oÄŸu parametre deÄŸerinin soruna uygun olmadan **kÃ¶r bir ÅŸekilde** denenmesinden kaynaklanan hesaplama verimsizliÄŸidir.

#### Random search *(Rastgele arama)*

**Random search**, arama alanÄ±nÄ± rastgele Ã¶rnekleyen bir yÃ¶ntemdir ve yÃ¼ksek boyutlu uzaylarda uygulanabilirliÄŸi vardÄ±r; bu nedenle pratikte yaygÄ±n olarak kullanÄ±lÄ±r. Ancak random searchâ€™Ã¼n dezavantajÄ±, bir Ã¶nceki denemelerden elde edilen bilgiyi bir sonraki ayarÄ± seÃ§mek iÃ§in kullanmamasÄ±dÄ±r (bu sorun, grid search iÃ§in de geÃ§erlidir). AyrÄ±ca, en iyi Ã§Ã¶zÃ¼mÃ¼ mÃ¼mkÃ¼n olan en hÄ±zlÄ± ÅŸekilde bulmak iÃ§in yapabileceÄŸiniz tek ÅŸey, doÄŸru hyperparameterâ€™larÄ± yakalayabilmeyi ummaktÄ±r.

Random search inanÄ±lmaz derecede iyi Ã§alÄ±ÅŸÄ±r ve anlaÅŸÄ±lmasÄ± oldukÃ§a basittir. RastgeleliÄŸe dayanmasÄ±na raÄŸmen, yalnÄ±zca ÅŸansa baÄŸlÄ± deÄŸildir; baÅŸlangÄ±Ã§ta Ã¶yle gÃ¶rÃ¼nse de istatistikteki rastgele Ã¶rnekleme gibi Ã§alÄ±ÅŸÄ±r. Teknikteki ana nokta ÅŸudur: yeterince rastgele test yaparsanÄ±z, benzer performans gÃ¶steren kombinasyonlarÄ±n hafifÃ§e farklÄ± varyasyonlarÄ±nÄ± denemekle enerji harcamadan doÄŸru parametreleri bulma olasÄ±lÄ±ÄŸÄ±nÄ±z yÃ¼ksektir.

BirÃ§ok AutoML sistemi, ayarlanacak Ã§ok fazla parametre olduÄŸunda random searchâ€™e dayanÄ±r (bkz. Golovin, D. ve ark., *Google Vizier: A Service for Black-Box Optimization*, 2017). Genel bir kural olarak, hyperparameter optimizasyon probleminizin boyutu yeterince yÃ¼ksekse (Ã¶rneÄŸin 16â€™nÄ±n Ã¼zerinde), random searchâ€™e bakmayÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

AÅŸaÄŸÄ±da, Ã¶nceki Ã¶rneÄŸi random search kullanarak Ã§alÄ±ÅŸtÄ±rÄ±yoruz:

```python
import scipy.stats as stats
from sklearn.utils.fixes import loguniform

search_dict = {
    'kernel': ['linear', 'rbf'], 
    'C': loguniform(1, 1000),
    'gamma': loguniform(0.0001, 0.1)
}

scorer = 'accuracy'

search_func = model_selection.RandomizedSearchCV(
    estimator=svc,
    param_distributions=search_dict,
    n_iter=6,
    scoring=scorer,
    n_jobs=-1,
    cv=5
)

search_func.fit(X, y)
print(search_func.best_params_)
print(search_func.best_score_)
```

Dikkat edin, artÄ±k farklÄ± kernelâ€™ler iÃ§in ayrÄ± arama alanlarÄ±nda Ã§alÄ±ÅŸtÄ±rmaya gerek yok. Grid searchâ€™Ã¼n aksine, burada her parametre, etkisiz olanlar dahil, sistematik olarak test edilmez; bu da hesaplama sÃ¼resi gerektirir. Burada aramanÄ±n verimliliÄŸi, test edilen hyperparameter kÃ¼mesinden etkilenmez. Arama, ilgisiz parametrelere baÄŸlÄ± deÄŸildir; ÅŸansa dayalÄ±dÄ±r. SeÃ§ilen kernel iÃ§in birÃ§ok parametre arasÄ±ndan yalnÄ±zca bir geÃ§erli parametreyi test etseniz bile her deneme faydalÄ±dÄ±r.

#### Halving search *(YarÄ±ya indirme aramasÄ±)*

DediÄŸimiz gibi, hem grid search hem de random search bilgiye dayalÄ± olmayan bir ÅŸekilde Ã§alÄ±ÅŸÄ±r: bazÄ± testler belirli hyperparameterâ€™larÄ±n sonucu etkilemediÄŸini veya belirli deÄŸer aralÄ±klarÄ±nÄ±n etkisiz olduÄŸunu ortaya Ã§Ä±karsa bile, bu bilgi sonraki aramalara aktarÄ±lmaz.

Bu nedenle, Scikit-learn yakÄ±n zamanda **HalvingGridSearchCV** ve **HalvingRandomSearchCV** tahmin edicilerini tanÄ±ttÄ±. Bunlar, grid search ve random search stratejilerini ardÄ±ÅŸÄ±k yarÄ±ya indirme (successive halving) yÃ¶ntemiyle parametre arama iÃ§in kullanÄ±labilir.

**Halving** yÃ¶nteminde, baÅŸlangÄ±Ã§ turunda Ã§ok sayÄ±da hyperparameter kombinasyonu deÄŸerlendirilir, ancak kÃ¼Ã§Ã¼k miktarda hesaplama kaynaÄŸÄ± kullanÄ±lÄ±r. Bu, testleri eÄŸitim verinizden seÃ§ilen kÃ¼Ã§Ã¼k bir alt Ã¶rnek Ã¼zerinde Ã§alÄ±ÅŸtÄ±rarak gerÃ§ekleÅŸtirilir. Daha kÃ¼Ã§Ã¼k bir eÄŸitim seti, test edilmesi iÃ§in daha az hesaplama gerektirir; bÃ¶ylece daha az kaynak (Ã¶zellikle zaman) kullanÄ±lÄ±r, ancak performans tahminleri daha az hassas olur. Bu baÅŸlangÄ±Ã§ turu, problem Ã¼zerinde daha iyi performans gÃ¶steren bir hyperparameter alt kÃ¼mesinin seÃ§ilmesini saÄŸlar ve ikinci turda eÄŸitim seti boyutu artÄ±rÄ±lÄ±r.

Sonraki turlar benzer ÅŸekilde ilerler: test edilen deÄŸer aralÄ±ÄŸÄ± daraltÄ±ldÄ±kÃ§a, aranan eÄŸitim seti alt kÃ¼meleri giderek bÃ¼yÃ¼tÃ¼lÃ¼r (bu, testin Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± iÃ§in daha fazla zaman gerektirir, ancak daha hassas performans tahmini saÄŸlar) ve aday sayÄ±sÄ± yarÄ±ya indirilmeye devam eder.

Ã–nceki probleme uygulanan bir Ã¶rnek ÅŸÃ¶yle:

```python
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingRandomSearchCV

search_func = HalvingRandomSearchCV(
    estimator=svc,
    param_distributions=search_dict,
    resource='n_samples',
    max_resources=100,
    aggressive_elimination=True,
    scoring=scorer,
    n_jobs=-1,
    cv=5,
    random_state=0
)

search_func.fit(X, y)
print(search_func.best_params_)
print(search_func.best_score_)
```

Bu ÅŸekilde, halving yÃ¶ntemi adaylarÄ±n seÃ§imi yoluyla ardÄ±ÅŸÄ±k optimizasyon adÄ±mlarÄ±na bilgi saÄŸlar. Sonraki bÃ¶lÃ¼mlerde, hyperparameter uzayÄ±nda daha hassas ve verimli bir arama yapmak iÃ§in daha akÄ±llÄ± yÃ¶ntemleri tartÄ±ÅŸacaÄŸÄ±z.

> Kazuki Onodera
> 
> [https://www.kaggle.com/onodera](https://www.kaggle.com/onodera)
> 
> 
> 
> BaÅŸka bir Kaggler ile kÄ±sa bir rÃ¶portaj yapalÄ±m. Kazuki Onodera, **Competitions Grandmaster** ve **Discussions Master** unvanlarÄ±na sahip, yaklaÅŸÄ±k 7 yÄ±llÄ±k yarÄ±ÅŸma deneyimi olan bir Kaggle kullanÄ±cÄ±sÄ±dÄ±r. AyrÄ±ca NVIDIAâ€™da KÄ±demli Derin Ã–ÄŸrenme Veri Bilimcisi olarak Ã§alÄ±ÅŸmakta ve NVIDIA KGMON (Kaggle Grandmasters of NVIDIA) ekibinin bir Ã¼yesidir.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™daki uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Instacart Market Basket Analysis. Bu yarÄ±ÅŸma, Kaggle topluluÄŸu iÃ§in oldukÃ§a zorluydu Ã§Ã¼nkÃ¼ kullanÄ±cÄ±larÄ±n Ã¶nceki sipariÅŸlerine dayanarak bir sonraki sipariÅŸlerinde hangi Ã¼rÃ¼nlerin olacaÄŸÄ±nÄ± tahmin etmek iÃ§in anonimleÅŸtirilmiÅŸ veriler kullanÄ±lÄ±yordu. Bu yarÄ±ÅŸmayÄ± sevme sebebim, Ã¶zellik mÃ¼hendisliÄŸini Ã§ok seviyor olmam ve diÄŸerlerinin aklÄ±na gelmeyen ilginÃ§ ve iyi Ã¶zellikler geliÅŸtirebilmem. Bu sayede yarÄ±ÅŸmada ikinci olabildim.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±klarÄ±nÄ±zdan ne kadar farklÄ±?**
> 
> Bir modelin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± hayal etmeye Ã§alÄ±ÅŸÄ±yorum ve yanlÄ±ÅŸ negatifler ile yanlÄ±ÅŸ pozitiflere derinlemesine bakÄ±yorum. GÃ¼nlÃ¼k iÅŸimde yaptÄ±klarÄ±mla aynÄ±.
> 
> 
> 
> **GirdiÄŸiniz Ã¶zellikle zorlu bir yarÄ±ÅŸmadan bahseder misiniz ve gÃ¶revi Ã§Ã¶zmek iÃ§in hangi iÃ§gÃ¶rÃ¼leri kullandÄ±nÄ±z?**
> 
> Human Protein Atlas - Single Cell Classification. Bu yarÄ±ÅŸma aslÄ±nda bir tÃ¼r instance segmentation yarÄ±ÅŸmasÄ±ydÄ±, fakat maskeler saÄŸlanmamÄ±ÅŸtÄ±. Bu yÃ¼zden zayÄ±f denetimli Ã§ok etiketli bir sÄ±nÄ±flandÄ±rma problemine dÃ¶nÃ¼ÅŸtÃ¼. Etiket gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ temizlemek iÃ§in iki aÅŸamalÄ± bir pipeline oluÅŸturdum.
> 
> 
> 
> **Kaggle kariyerinize katkÄ±da bulundu mu? EÄŸer Ã¶yleyse, nasÄ±l?**
> 
> Evet. Åu anda NVIDIA KGMON ekibinde Ã§alÄ±ÅŸÄ±yorum. Kaggle, tablo verisi, gÃ¶rsel, doÄŸal dil ve sinyal verisi gibi farklÄ± veri tÃ¼rlerinde, ayrÄ±ca sektÃ¶r ve alan aÃ§Ä±sÄ±ndan farklÄ± yarÄ±ÅŸmalar (sanayi, finans, astronomi, patoloji, spor, perakende vb.) dÃ¼zenliyor. Bu tÃ¼r verilere eriÅŸim ve deneyim edinmek iÃ§in en uygun yer kesinlikle Kaggle.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz iyi olurdu dediÄŸiniz ÅŸey nedir?**
> 
> Hedef analizi. AyrÄ±ca seed averaging de oldukÃ§a gÃ¶z ardÄ± ediliyor: her zaman basit ama gÃ¼Ã§lÃ¼.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> Hedef analizi. En iyi takÄ±mlar her zaman hedefi diÄŸerlerinden daha iyi analiz eder, bu yÃ¼zden bir yarÄ±ÅŸmada daha iyi bir yerde olamÄ±yorsam, en iyi Ã§Ã¶zÃ¼mleri okuyorum; Ã§Ã¼nkÃ¼ bu Ã§Ã¶zÃ¼mler bana yarÄ±ÅŸma sÄ±rasÄ±nda kaÃ§Ä±rdÄ±ÄŸÄ±m veri bilgilerini aÃ§Ä±klÄ±yor.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Sadece Python ve Jupyter Notebook.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken insanlarÄ±n akÄ±lda tutmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Bir yenilgiden Ã¶ÄŸrenebiliyorsanÄ±z, aslÄ±nda kaybetmemiÅŸsiniz demektir.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ±nÄ± kullanÄ±yor musunuz? Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±lÄ±rlar?**
> 
> KDD Cup ve RecSys. Her ikisi de ilginÃ§ ve zorlu olma aÃ§Ä±sÄ±ndan minimum gereksinimleri karÅŸÄ±lÄ±yor.
> 
> 

### Key parameters and how to use them *(Temel parametreler ve nasÄ±l kullanÄ±lacaklarÄ±)*

Bir sonraki sorun, kullandÄ±ÄŸÄ±nÄ±z her model tÃ¼rÃ¼ iÃ§in doÄŸru hiperparametre setini kullanmaktÄ±r. Ã–zellikle optimizasyonunuzu verimli yapmak iÃ§in, her farklÄ± algoritma iÃ§in hangi hiperparametre deÄŸerlerini test etmenin gerÃ§ekten anlamlÄ± olduÄŸunu bilmeniz gerekir.

Bu bÃ¶lÃ¼mde, Kaggle yarÄ±ÅŸmalarÄ±nda, Ã¶zellikle tablo verisi yarÄ±ÅŸmalarÄ±nda, en yaygÄ±n olarak kullanÄ±lan modelleri inceleyecek ve en iyi sonuÃ§larÄ± elde etmek iÃ§in ayarlamanÄ±z gereken hiperparametreleri tartÄ±ÅŸacaÄŸÄ±z. Genel tablo verisi problemleri iÃ§in klasik makine Ã¶ÄŸrenimi modelleri ile (parametre alanÄ± aÃ§Ä±sÄ±ndan Ã§ok daha talepkar olan) gradient boosting modelleri arasÄ±nda ayrÄ±m yapacaÄŸÄ±z.

Sinir aÄŸlarÄ±na gelince, standart modelleri tanÄ±tÄ±rken ayarlanmasÄ± gereken bazÄ± Ã¶zel parametreler hakkÄ±nda fikir verebiliriz (Ã¶rneÄŸin, TabNet sinir modeli dÃ¼zgÃ¼n Ã§alÄ±ÅŸmasÄ± iÃ§in bazÄ± Ã¶zel parametrelere ihtiyaÃ§ duyar). Ancak, Kaggle yarÄ±ÅŸmalarÄ±nda derin sinir aÄŸlarÄ± optimizasyonunun Ã§oÄŸu standart modeller Ã¼zerinde deÄŸil, Ã¶zel olarak geliÅŸtirilmiÅŸ modeller Ã¼zerinde yapÄ±lmaktadÄ±r. DolayÄ±sÄ±yla, Ã¶ÄŸrenme oranÄ± ve batch boyutu gibi temel Ã¶ÄŸrenme parametreleri dÄ±ÅŸÄ±nda, sinir aÄŸlarÄ±nda optimizasyon modelinizin sinir mimarisinin Ã¶zel Ã¶zelliklerine dayanmaktadÄ±r. Bu problemi ad hoc (duruma Ã¶zel) bir ÅŸekilde ele almanÄ±z gerekir. BÃ¶lÃ¼mÃ¼n sonunda, KerasTuner kullanarak bir sinir mimarisi arama (NAS) Ã¶rneÄŸini tartÄ±ÅŸacaÄŸÄ±z ([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)).

#### Linear models *(DoÄŸrusal modeller)*

AyarlanmasÄ± gereken lineer modeller genellikle dÃ¼zenlemeli (regularized) lineer regresyon veya lojistik regresyon modelleridir:

* **C**: AramanÄ±z gereken deÄŸer aralÄ±ÄŸÄ± `np.logspace(-4, 4, 10)`â€™dur; daha kÃ¼Ã§Ã¼k deÄŸerler daha gÃ¼Ã§lÃ¼ regularizasyon uygular.
* **alpha**: AramanÄ±z gereken deÄŸer aralÄ±ÄŸÄ± `np.logspace(-2, 2, 10)`â€™dur; daha kÃ¼Ã§Ã¼k deÄŸerler daha gÃ¼Ã§lÃ¼ regularizasyon uygular, daha bÃ¼yÃ¼k deÄŸerler ise daha gÃ¼Ã§lÃ¼ regularizasyon uygular. AyrÄ±ca, Lasso kullanÄ±rken daha yÃ¼ksek deÄŸerlerin iÅŸlenmesinin daha fazla zaman aldÄ±ÄŸÄ±nÄ± unutmayÄ±n.
* **l1_ratio**: SeÃ§ebileceÄŸiniz deÄŸerler `[.1, .5, .7, .9, .95, .99, 1]` listesindendir; yalnÄ±zca Elastic Net iÃ§in geÃ§erlidir.

Scikit-learnâ€™de, algoritmaya baÄŸlÄ± olarak, ya hiperparametre **C** (lojistik regresyon iÃ§in) ya da **alpha** (Lasso, Ridge, Elastic Net iÃ§in) bulunur.

#### Support-vector machines *(Destek vektÃ¶r makineleri)*

SVMâ€™ler, sÄ±nÄ±flandÄ±rma ve regresyon iÃ§in gÃ¼Ã§lÃ¼ ve ileri dÃ¼zey gÃ¶zetimli Ã¶ÄŸrenme teknikleri ailesidir ve hem lineer hem de lineer olmayan modelleri otomatik olarak uyarlayabilir. Scikit-learn, SVM sÄ±nÄ±flandÄ±rma ve regresyon uygulamalarÄ±nÄ±n eksiksiz bir kÃ¼tÃ¼phanesi olan **LIBSVM** ve Ã¶zellikle bÃ¼yÃ¼k veri kÃ¼meleri, Ã¶zellikle seyrek metin tabanlÄ± veri kÃ¼meleri iÃ§in uygun, Ã¶lÃ§eklenebilir bir lineer sÄ±nÄ±flandÄ±rma kÃ¼tÃ¼phanesi olan **LIBLINEAR**â€™a dayalÄ± bir uygulama sunar. SVM optimizasyonunda, sÄ±nÄ±flandÄ±rma problemlerinde hedef sÄ±nÄ±flarÄ± ayÄ±rmak iÃ§in sÄ±nÄ±flar arasÄ±ndaki mÃ¼mkÃ¼n olan en geniÅŸ marj ile karakterize edilen bir karar sÄ±nÄ±rÄ± kullanÄ±lÄ±r.

VarsayÄ±lan parametrelerle SVMâ€™ler iyi Ã§alÄ±ÅŸsa da Ã§oÄŸu zaman optimal deÄŸildir ve en iyi deÄŸerleri bulmak iÃ§in Ã§eÅŸitli deÄŸer kombinasyonlarÄ±nÄ± Ã§apraz doÄŸrulama ile test etmeniz gerekir. Ã–ncelik sÄ±rasÄ±na gÃ¶re ayarlanmasÄ± gereken parametreler ÅŸunlardÄ±r:

* **C**: Ceza deÄŸeri. AzaltÄ±lmasÄ± sÄ±nÄ±flar arasÄ±ndaki marjÄ± bÃ¼yÃ¼tÃ¼r, bÃ¶ylece daha fazla gÃ¼rÃ¼ltÃ¼yÃ¼ gÃ¶rmezden gelir ancak modelin genellenebilirliÄŸini artÄ±rÄ±r. Genellikle en iyi deÄŸer aralÄ±ÄŸÄ± `np.logspace(-3, 3, 7)`â€™dir.
* **kernel**: SVMâ€™de doÄŸrusal olmayan yapÄ±nÄ±n nasÄ±l uygulanacaÄŸÄ±nÄ± belirler ve `'linear'`, `'poly'`, `'rbf'`, `'sigmoid'` veya Ã¶zel bir kernel olarak ayarlanabilir. En yaygÄ±n kullanÄ±lan deÄŸer kesinlikle `'rbf'`â€™dir.
* **degree**: `kernel='poly'` ile Ã§alÄ±ÅŸÄ±r ve polinom geniÅŸlemesinin boyutunu belirtir. DiÄŸer kernelâ€™ler tarafÄ±ndan gÃ¶z ardÄ± edilir. Genellikle 2 ile 5 arasÄ± deÄŸerler en iyi sonucu verir.
* **gamma**: `'rbf'`, `'poly'` ve `'sigmoid'` iÃ§in bir katsayÄ±dÄ±r. YÃ¼ksek deÄŸerler veriye daha iyi uyum saÄŸlar, ancak aÅŸÄ±rÄ± Ã¶ÄŸrenmeye (overfitting) yol aÃ§abilir. Gammaâ€™yÄ±, tek bir Ã¶rneÄŸin model Ã¼zerindeki etkisi olarak dÃ¼ÅŸÃ¼nebiliriz. DÃ¼ÅŸÃ¼k deÄŸerler, her bir Ã¶rneÄŸin etkisinin daha geniÅŸ alana yayÄ±lmasÄ±nÄ± saÄŸlar; bu da SVM eÄŸri Ã§izgisinin lokal noktalardan daha az etkilenmesine ve daha dÃ¼zgÃ¼n bir karar sÄ±nÄ±rÄ± elde edilmesine yol aÃ§ar. YÃ¼ksek gamma deÄŸerleri ise eÄŸrinin lokal noktalarÄ±n dÃ¼zenini daha Ã§ok dikkate almasÄ±na sebep olur ve daha dÃ¼zensiz, kÄ±vrÄ±mlÄ± bir karar eÄŸrisi ortaya Ã§Ä±kar. Ã–nerilen grid search aralÄ±ÄŸÄ± `np.logspace(-3, 3, 7)`â€™dir.
* **nu**: `nuSVR` ve `nuSVC` ile regresyon ve sÄ±nÄ±flandÄ±rmada, marja yakÄ±n ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ eÄŸitim noktalarÄ± iÃ§in tolerans belirler. YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ noktalarÄ± gÃ¶z ardÄ± etmeye yardÄ±mcÄ± olur ve karar eÄŸrisinin daha dÃ¼zgÃ¼n olmasÄ±nÄ± saÄŸlar. [0,1] aralÄ±ÄŸÄ±nda olmalÄ±dÄ±r Ã§Ã¼nkÃ¼ eÄŸitim setine gÃ¶re oransaldÄ±r. Temel olarak **C** gibi davranÄ±r; yÃ¼ksek oranlar marjÄ± bÃ¼yÃ¼tÃ¼r.
* **epsilon**: SVRâ€™nin kabul edeceÄŸi hata miktarÄ±nÄ± belirler; algoritmanÄ±n eÄŸitiminde bir Ã¶rneÄŸin yanlÄ±ÅŸ tahmini iÃ§in ceza uygulanmayan geniÅŸ bir epsilon aralÄ±ÄŸÄ± tanÄ±mlar. Ã–nerilen aralÄ±k `np.logspace(-4, 2, 7)`â€™dir.
* **penalty, loss ve dual**: `LinearSVC` iÃ§in bu parametreler `('l1', 'squared_hinge', False)`, `('l2', 'hinge', True)`, `('l2', 'squared_hinge', True)` ve `('l2', 'squared_hinge', False)` kombinasyonlarÄ±nÄ± alabilir. `('l2', 'hinge', True)` kombinasyonu, `SVC(kernel='linear')` ile eÅŸdeÄŸerdir.

SVMâ€™nin ayarlanacak Ã§ok fazla hiperparametresi var gibi gÃ¶rÃ¼nebilir, ancak birÃ§ok ayar yalnÄ±zca belirli implementasyonlara veya kernelâ€™lere Ã¶zgÃ¼dÃ¼r; bu nedenle yalnÄ±zca ilgili parametreleri seÃ§meniz yeterlidir.

#### Random forests and extremely randomized trees *(Rastgele ormanlar ve aÅŸÄ±rÄ± rastgele aÄŸaÃ§lar)*

Leo Breiman ve Adele Cutler, rastgele orman (random forest) algoritmasÄ±nÄ±n temel fikrini ilk olarak geliÅŸtirmiÅŸlerdir ve algoritmanÄ±n adÄ± bugÃ¼n hÃ¢lÃ¢ onlarÄ±n tescilli markasÄ±dÄ±r (algoritma aÃ§Ä±k kaynak olmasÄ±na raÄŸmen). Scikit-learnâ€™de rastgele ormanlar **RandomForestClassifier** veya **RandomForestRegressor** sÄ±nÄ±flarÄ± ile uygulanÄ±r.

Rastgele orman, Leo Breiman tarafÄ±ndan geliÅŸtirilen bagging yÃ¶ntemine benzer ÅŸekilde Ã§alÄ±ÅŸÄ±r, ancak yalnÄ±zca ikili bÃ¶lÃ¼nme karar aÄŸaÃ§larÄ±nÄ± kullanÄ±r ve bu aÄŸaÃ§lar uÃ§larÄ±na kadar bÃ¼yÃ¼tÃ¼lÃ¼r. AyrÄ±ca her modelde kullanÄ±lacak Ã¶rnekleri **bootstrap** yÃ¶ntemiyle seÃ§er. AÄŸaÃ§ bÃ¼yÃ¼tÃ¼lÃ¼rken, her dalÄ±n bÃ¶lÃ¼nmesinde, bÃ¶lÃ¼nmede dikkate alÄ±nacak deÄŸiÅŸkenler de rastgele seÃ§ilir.

Ä°ÅŸte algoritmanÄ±n kalbindeki sÄ±r budur: FarklÄ± Ã¶rnekler ve farklÄ± deÄŸiÅŸkenler nedeniyle birbirinden Ã§ok farklÄ± aÄŸaÃ§larÄ± bir araya getirir. Bu aÄŸaÃ§lar farklÄ± olduklarÄ± iÃ§in aynÄ± zamanda **korelasyonsuzdur**. Bu faydalÄ±dÄ±r Ã§Ã¼nkÃ¼ sonuÃ§lar birleÅŸtirildiÄŸinde, daÄŸÄ±lÄ±mÄ±n uÃ§ deÄŸerleri birbirini dengeler ve varyans azalÄ±r. BaÅŸka bir deyiÅŸle, bagging algoritmalarÄ± tahminlerde belirli bir Ã§eÅŸitlilik dÃ¼zeyi saÄŸlar ve tek bir Ã¶ÄŸrenicinin (Ã¶rneÄŸin bir karar aÄŸacÄ±nÄ±n) keÅŸfetmeyeceÄŸi kurallarÄ± geliÅŸtirmelerine olanak tanÄ±r. Bu Ã§eÅŸitlilik, bireysel aÄŸaÃ§larÄ±n ortalamasÄ±nÄ±n tahmin performansÄ±nÄ± artÄ±ran bir daÄŸÄ±lÄ±m oluÅŸturulmasÄ±na yardÄ±mcÄ± olur.

**Extra Trees** (aÅŸÄ±rÄ± rastgeleleÅŸtirilmiÅŸ aÄŸaÃ§lar), Scikit-learnâ€™de **ExtraTreesClassifier/ExtraTreesRegressor** sÄ±nÄ±flarÄ±yla temsil edilir ve daha rastgele bir rastgele orman tÃ¼rÃ¼dÃ¼r. Tahminlerde daha dÃ¼ÅŸÃ¼k varyans Ã¼retirken, estimatÃ¶rlerde daha yÃ¼ksek bias (sapma) ortaya Ã§Ä±kar. Ancak CPU verimliliÄŸi aÃ§Ä±sÄ±ndan Extra Trees, rastgele ormanlara kÄ±yasla Ã¶nemli bir hÄ±z kazanÄ±mÄ± saÄŸlayabilir; bu nedenle hem Ã¶rnek sayÄ±sÄ± hem de Ã¶zellik sayÄ±sÄ± aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k veri kÃ¼meleriyle Ã§alÄ±ÅŸÄ±rken ideal olabilir. Bu daha yÃ¼ksek bias ama daha hÄ±zlÄ± performansÄ±n nedeni, Extra Treeâ€™da bÃ¶lÃ¼nmelerin rastgele oluÅŸturulmasÄ±dÄ±r. Rastgele ormanlarda, bir dalÄ± bÃ¶lmek iÃ§in rastgele seÃ§ilen Ã¶zellikler arasÄ±nda en iyi deÄŸerleri bulmak iÃ§in dikkatli bir arama yapÄ±lÄ±r. Buna karÅŸÄ±lÄ±k, Extra Treesâ€™da hem bÃ¶lÃ¼nmede kullanÄ±lacak Ã¶zellikler hem de bÃ¶lÃ¼nme deÄŸeri tamamen rastgele seÃ§ilir. Bu nedenle hesaplama maliyeti dÃ¼ÅŸÃ¼ktÃ¼r, ancak seÃ§ilen rastgele bÃ¶lÃ¼nme her zaman en etkili olan olmayabilir (iÅŸte bias burada ortaya Ã§Ä±kar).

Her iki algoritma iÃ§in de ayarlanmasÄ± gereken temel hiperparametreler ÅŸunlardÄ±r:

* **max_features**: Her bÃ¶lÃ¼nmede kullanÄ±lacak Ã¶rneklenmiÅŸ Ã¶zellik sayÄ±sÄ±dÄ±r ve algoritmanÄ±n performansÄ±nÄ± belirleyebilir. DÃ¼ÅŸÃ¼k deÄŸer daha hÄ±zlÄ± Ã§alÄ±ÅŸmayÄ± saÄŸlar, ancak bias artar.
* **min_samples_leaf**: AÄŸaÃ§larÄ±n derinliÄŸini belirler. BÃ¼yÃ¼k deÄŸerler varyansÄ± azaltÄ±r ve biasâ€™Ä± artÄ±rÄ±r.
* **bootstrap**: Bootstrapping uygulanÄ±p uygulanmayacaÄŸÄ±nÄ± belirten Boolean parametredir.
* **n_estimators**: AÄŸaÃ§ sayÄ±sÄ±dÄ±r. Daha fazla aÄŸaÃ§ genellikle daha iyidir, ancak veri problemine baÄŸlÄ± olarak belli bir noktadan sonra getiriler azalÄ±r. AyrÄ±ca hesaplama maliyeti artar; bu, mevcut kaynaklarÄ±nÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurmayÄ± gerektirir.

Extra Trees, Ã¶zellikle verileriniz oldukÃ§a gÃ¼rÃ¼ltÃ¼lÃ¼ olduÄŸunda rastgele ormanlara iyi bir alternatiftir. BÃ¶lÃ¼nmelerin rastgele seÃ§imi nedeniyle bazÄ± varyans azalÄ±mÄ± karÅŸÄ±lÄ±ÄŸÄ±nda daha yÃ¼ksek bias verirler ve bu sayede rastgele ormanda baskÄ±n olabilecek Ã¶nemli ancak gÃ¼rÃ¼ltÃ¼lÃ¼ Ã¶zelliklerde daha az aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) eÄŸilimi gÃ¶sterirler.

#### Gradient tree boosting *(Gradyan aÄŸaÃ§ gÃ¼Ã§lendirmesi)*

Gradyan aÄŸaÃ§ gÃ¼Ã§lendirme (Gradient Tree Boosting) veya gradyan artÄ±rmalÄ± karar aÄŸaÃ§larÄ± (GBDT), **boosting** yÃ¶nteminin geliÅŸtirilmiÅŸ bir versiyonudur (boosting, zayÄ±f Ã¶ÄŸreniciler dizisini verilerin yeniden aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ versiyonlarÄ±na uygulayarak Ã§alÄ±ÅŸÄ±r). AdaBoost gibi, GBDT de bir **gradyan iniÅŸ fonksiyonuna** dayanÄ±r. Algoritma, topluluk (ensemble) tabanlÄ± modeller ailesinin en yetkinlerinden biri olduÄŸunu kanÄ±tlamÄ±ÅŸtÄ±r; ancak **tahminlerde artan varyans**, **verideki gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± daha yÃ¼ksek hassasiyet** (her iki sorun da alt Ã¶rnekleme, subsampling, ile hafifletilebilir) ve **paralel olmayan iÅŸlemler nedeniyle yÃ¼ksek hesaplama maliyetleri** ile karakterizedir.

Derin Ã¶ÄŸrenme dÄ±ÅŸÄ±nda, gradyan gÃ¼Ã§lendirme en geliÅŸmiÅŸ makine Ã¶ÄŸrenimi algoritmalarÄ±ndan biridir. Jerome Friedman tarafÄ±ndan geliÅŸtirilen AdaBoost ve ilk gradyan gÃ¼Ã§lendirme uygulamasÄ±ndan bu yana, algoritmanÄ±n Ã§eÅŸitli baÅŸka sÃ¼rÃ¼mleri ortaya Ã§Ä±kmÄ±ÅŸtÄ±r; en gÃ¼ncel olanlar **XGBoost**, **LightGBM** ve **CatBoost**â€™tur.

#### LightGBM *(LightGBM algoritmasÄ±)*

YÃ¼ksek performanslÄ± **LightGBM** algoritmasÄ± ([https://github.com/Microsoft/LightGBM](https://github.com/Microsoft/LightGBM)), birden fazla bilgisayarda daÄŸÄ±tÄ±k olarak Ã§alÄ±ÅŸabilir ve bÃ¼yÃ¼k veri setlerini hÄ±zlÄ± bir ÅŸekilde iÅŸleyebilir. Microsoftâ€™taki bir ekip tarafÄ±ndan GitHubâ€™da aÃ§Ä±k kaynak proje olarak geliÅŸtirilmiÅŸtir (ayrÄ±ca akademik bir makale de mevcuttur: [https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html](https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html)).

LightGBM, XGBoost gibi karar aÄŸaÃ§larÄ±na dayanÄ±r, ancak farklÄ± bir strateji izler. XGBoost, bir deÄŸiÅŸkene gÃ¶re dallanma yapar ve o deÄŸiÅŸkende farklÄ± aÄŸaÃ§ dallanmalarÄ±nÄ± keÅŸfeder (**seviye-odaklÄ± aÄŸaÃ§ bÃ¼yÃ¼me stratejisi**), LightGBM ise tek bir dallanmaya odaklanÄ±r ve oradan dallanmayÄ± sÃ¼rdÃ¼rerek daha iyi bir uyum saÄŸlar (**yaprak-odaklÄ± aÄŸaÃ§ bÃ¼yÃ¼me stratejisi**). Bu sayede LightGBM, veriye hÄ±zlÄ±ca iyi bir uyum saÄŸlar ve XGBoostâ€™a kÄ±yasla alternatif Ã§Ã¶zÃ¼mler Ã¼retebilir (bu, tahminlerin varyansÄ±nÄ± azaltmak iÃ§in iki Ã§Ã¶zÃ¼mÃ¼ birleÅŸtirmeyi planlÄ±yorsanÄ±z avantajlÄ±dÄ±r). Algoritmik olarak dÃ¼ÅŸÃ¼nÃ¼rsek, bir karar aÄŸacÄ±nÄ±n dallanma yapÄ±sÄ±nÄ± bir grafik olarak hayal edersek, **XGBoost geniÅŸlik Ã¶ncelikli arama (BFS)**, **LightGBM derinlik Ã¶ncelikli arama (DFS)** uygular.

LightGBMâ€™i ayarlamak baÅŸlangÄ±Ã§ta gÃ¶z korkutucu gÃ¶rÃ¼nebilir; ayarlanabilecek **yÃ¼zden fazla parametre** vardÄ±r. Bu parametreleri buradan inceleyebilirsiniz:

* GitHub: [https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst)
* DokÃ¼mantasyon: [https://lightgbm.readthedocs.io/en/latest/Parameters.html](https://lightgbm.readthedocs.io/en/latest/Parameters.html)

Genel olarak, sonuÃ§larÄ± en Ã§ok etkileyen ve odaklanmanÄ±z gereken baÅŸlÄ±ca hiperparametreler ÅŸunlardÄ±r:

* **n_estimators**: 10â€“10.000 arasÄ±nda bir tamsayÄ±; yineleme sayÄ±sÄ±nÄ± belirler.
* **learning_rate**: 0.01â€“1.0 arasÄ±nda bir gerÃ§ek sayÄ±, genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir. AlgoritmanÄ±n tÃ¼m iterasyonlarÄ±nÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± hesaplayan gradyan iniÅŸ adÄ±m boyutunu temsil eder.
* **max_depth**: 1â€“16 arasÄ±nda bir tamsayÄ±; Ã¶zelliklerdeki maksimum dallanma sayÄ±sÄ±nÄ± belirler. 0â€™dan kÃ¼Ã§Ã¼k deÄŸer verilirse maksimum olasÄ± dallanma saÄŸlanÄ±r, bu genellikle aÅŸÄ±rÄ± uyum (overfitting) riskini artÄ±rÄ±r.
* **num_leaves**: 2â€“2^max_depth arasÄ±nda bir tamsayÄ±; her aÄŸacÄ±n alacaÄŸÄ± maksimum yaprak sayÄ±sÄ±nÄ± belirler.
* **min_data_in_leaf**: 0â€“300 arasÄ±nda bir tamsayÄ±; bir yapraktaki minimum veri sayÄ±sÄ±nÄ± belirler.
* **min_gain_to_split**: 0â€“15 arasÄ±nda bir float; aÄŸacÄ±n dallanma yapmasÄ± iÃ§in gereken minimum kazancÄ± ayarlar. Gereksiz dallanmalarÄ± Ã¶nleyerek overfittingâ€™i azaltÄ±r (XGBoostâ€™ta gamma parametresine karÅŸÄ±lÄ±k gelir).
* **max_bin**: 32â€“512 arasÄ±nda bir tamsayÄ±; Ã¶zellik deÄŸerlerinin kaÃ§ binde gruplanacaÄŸÄ±nÄ± belirler. 255â€™in Ã¼stÃ¼nde deÄŸerler overfitting riskini artÄ±rÄ±r.
* **subsample**: 0.01â€“1.0 arasÄ±nda bir gerÃ§ek sayÄ±; eÄŸitimde kullanÄ±lacak Ã¶rnek oranÄ±nÄ± temsil eder.
* **subsample_freq**: 0â€“10 arasÄ±nda bir tamsayÄ±; algoritmanÄ±n Ã¶rnekleri kaÃ§ iterasyonda bir alt Ã¶rnekleyeceÄŸini belirler. 0 ise subsample parametresi gÃ¶z ardÄ± edilir (varsayÄ±lan 0â€™dÄ±r).
* **feature_fraction**: 0.1â€“1.0 arasÄ±nda bir gerÃ§ek sayÄ±; alt Ã¶rnekleme ile kullanÄ±lacak Ã¶zelliklerin oranÄ±nÄ± belirler. Bu, eÄŸitimde rastgeleliÄŸi artÄ±rarak gÃ¼rÃ¼ltÃ¼ ve multicollinearity ile mÃ¼cadele eder.
* **subsample_for_bin**: 30â€™dan Ã¶rnek sayÄ±sÄ±na kadar bir tamsayÄ±; histogram binleri iÃ§in Ã¶rnek alÄ±nacak veri sayÄ±sÄ±nÄ± belirler.
* **reg_lambda**: 0â€“100 arasÄ±nda bir gerÃ§ek sayÄ±; L2 dÃ¼zenlileÅŸtirmeyi belirler. Parametre Ã¶lÃ§eÄŸe duyarlÄ±dÄ±r, genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir.
* **reg_alpha**: 0â€“100 arasÄ±nda bir gerÃ§ek sayÄ±; L1 dÃ¼zenlileÅŸtirmeyi belirler, genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir.
* **scale_pos_weight**: 1e-6â€“500 arasÄ±nda bir gerÃ§ek sayÄ±; pozitif Ã¶rnekleri aÄŸÄ±rlÄ±klandÄ±rÄ±r (dolayÄ±sÄ±yla etkili olarak upsampling veya downsampling yapar), negatif Ã¶rnekler 1 deÄŸeri ile tutulur.

LightGBMâ€™de Ã§ok sayÄ±da hiperparametre bulunmasÄ±na raÄŸmen, aslÄ±nda yalnÄ±zca birkaÃ§ tanesi bÃ¼yÃ¼k etkiye sahiptir. Sabit iterasyon ve Ã¶ÄŸrenme hÄ±zÄ± iÃ§in en etkili olanlar: **feature_fraction, num_leaves, subsample, reg_lambda, reg_alpha, min_data_in_leaf**. Bu konu hakkÄ±nda Kaggle Grandmaster **Kohei Ozaki** tarafÄ±ndan yazÄ±lmÄ±ÅŸ blog yazÄ±sÄ±: [https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258). Ozaki, Optuna iÃ§in hÄ±zlÄ± bir hiperparametre ayarlama prosedÃ¼rÃ¼ oluÅŸtururken bu bilgiden faydalanÄ±r.

#### XGBoost *(XGBoost algoritmasÄ±)*

**XGBoost** ([https://github.com/dmlc/XGBoost](https://github.com/dmlc/XGBoost)), eXtreme Gradient Boostingâ€™in kÄ±saltmasÄ±dÄ±r. AÃ§Ä±k kaynaklÄ± bir projedir ve Scikit-learnâ€™Ã¼n bir parÃ§asÄ± deÄŸildir; ancak son zamanlarda bir Scikit-learn sarmalayÄ±cÄ± (wrapper) arayÃ¼zÃ¼ eklenmiÅŸtir, bu sayede XGBoostâ€™u Scikit-learn tarzÄ± veri pipelineâ€™larÄ±na entegre etmek kolaylaÅŸmÄ±ÅŸtÄ±r.

XGBoost algoritmasÄ±, 2015 yÄ±lÄ±nda Kaggle ve KDD Cup 2015 gibi veri bilimi yarÄ±ÅŸmalarÄ±nda popÃ¼lerlik kazanmÄ±ÅŸtÄ±r. AlgoritmanÄ±n yaratÄ±cÄ±sÄ± Tianqi Chen, Tong He ve Carlos Guestrinâ€™in makalelerinde belirttiÄŸi gibi, 2015â€™te Kaggleâ€™da dÃ¼zenlenen 29 yarÄ±ÅŸmadan 17â€™sinin kazanan Ã§Ã¶zÃ¼mÃ¼ XGBoostâ€™u ya tek baÅŸÄ±na ya da birden fazla modelden oluÅŸan bir ensemble iÃ§inde kullanmÄ±ÅŸtÄ±r. O tarihten sonra algoritma veri bilimi topluluÄŸu arasÄ±nda popÃ¼laritesini korumuÅŸ, ancak LightGBM ve CatBoost gibi diÄŸer GBM uygulamalarÄ±nÄ±n getirdiÄŸi yeniliklerle yarÄ±ÅŸmakta zaman zaman zorlanmÄ±ÅŸtÄ±r.

XGBoost, hem doÄŸruluk hem de hesaplama verimliliÄŸi aÃ§Ä±sÄ±ndan iyi performans gÃ¶stermesinin yanÄ± sÄ±ra, Ã§ok Ã§ekirdekli iÅŸlemciler ve daÄŸÄ±tÄ±k makineler kullanarak Ã¶lÃ§eklenebilir bir Ã§Ã¶zÃ¼mdÃ¼r.

XGBoost, ilk tree-boost GBM algoritmasÄ±na yapÄ±lan Ã¶nemli iyileÅŸtirmeler sayesinde GBM algoritmalarÄ±nÄ±n yeni neslini temsil eder:

* **Sparsity-awareness (seyreklik farkÄ±ndalÄ±ÄŸÄ±)**: Seyrek matrislerden faydalanabilir, bÃ¶ylece hem bellek tasarrufu saÄŸlar (yoÄŸun matris gerekmez) hem de iÅŸlem sÃ¼resini kÄ±saltÄ±r (sÄ±fÄ±r deÄŸerler Ã¶zel olarak iÅŸlenir).
* **YaklaÅŸÄ±k aÄŸaÃ§ Ã¶ÄŸrenimi (weighted quantile sketch)**: Klasik dallanma kesitlerinin tÃ¼m olasÄ± kombinasyonlarÄ±nÄ± araÅŸtÄ±rmaya gÃ¶re benzer sonuÃ§larÄ± Ã§ok daha kÄ±sa sÃ¼rede Ã¼retir.
* **Tek makinada paralel hesaplama**: En iyi bÃ¶lÃ¼nmeyi ararken Ã§oklu iÅŸ parÃ§acÄ±ÄŸÄ± kullanÄ±r; benzer ÅŸekilde, birden fazla makinede daÄŸÄ±tÄ±k hesaplamalar yapÄ±labilir.
* **Out-of-core hesaplama**: Tek bir makinede, sÃ¼tun bloklarÄ± olarak adlandÄ±rÄ±lan veri depolama Ã§Ã¶zÃ¼mÃ¼ kullanÄ±r. Bu yÃ¶ntem, veriyi diskte sÃ¼tunlar halinde dÃ¼zenleyerek optimizasyon algoritmasÄ±nÄ±n (sÃ¼tun vektÃ¶rleri Ã¼zerinde Ã§alÄ±ÅŸÄ±r) beklediÄŸi ÅŸekilde hÄ±zlÄ± veri Ã§ekimi saÄŸlar.

XGBoost ayrÄ±ca eksik verilerle etkili bir ÅŸekilde baÅŸa Ã§Ä±kabilir. Standart karar aÄŸaÃ§larÄ±na dayalÄ± diÄŸer aÄŸaÃ§ ensembleâ€™larÄ±, eksik verileri iÅŸlemden Ã¶nce Ã¶rneÄŸin negatif bir deÄŸer gibi Ã¶zel bir deÄŸerle doldurmak zorundadÄ±r; XGBoost bunu gereksiz kÄ±larak uygun dallanmayÄ± doÄŸrudan oluÅŸturabilir.

XGBoost parametreleri ([https://xgboost.readthedocs.io/en/latest/parameter.html](https://xgboost.readthedocs.io/en/latest/parameter.html)) arasÄ±nda, yarÄ±ÅŸmalarda ve projelerde sÄ±kÃ§a kullanÄ±lan baÅŸlÄ±ca parametreler ÅŸunlardÄ±r:

* **n_estimators**: Genellikle 10â€“5.000 arasÄ± bir tamsayÄ±.
* **learning_rate**: 0.01â€“1.0 arasÄ± bir gerÃ§ek sayÄ±, log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.
* **min_child_weight**: Genellikle 1â€“10 arasÄ± bir tamsayÄ±.
* **max_depth**: Genellikle 1â€“50 arasÄ± bir tamsayÄ±.
* **max_delta_step**: Genellikle 0â€“20 arasÄ± bir tamsayÄ±; her yaprak Ã§Ä±ktÄ±sÄ± iÃ§in izin verilen maksimum delta adÄ±mÄ±nÄ± temsil eder.
* **subsample**: 0.1â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; Ã¶rneklerin alt Ã¶rneklenme oranÄ±nÄ± belirtir.
* **colsample_bytree**: 0.1â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; aÄŸaÃ§ baÅŸÄ±na sÃ¼tun alt Ã¶rnekleme oranÄ±nÄ± belirtir.
* **colsample_bylevel**: 0.1â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; aÄŸaÃ§taki her seviyede sÃ¼tun alt Ã¶rnekleme oranÄ±nÄ± belirtir.
* **reg_lambda**: 1e-9â€“100 arasÄ± bir gerÃ§ek sayÄ±, L2 dÃ¼zenlileÅŸtirmeyi kontrol eder; log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi tercih edilir.
* **reg_alpha**: 1e-9â€“100 arasÄ± bir gerÃ§ek sayÄ±, L1 dÃ¼zenlileÅŸtirmeyi kontrol eder; log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi tercih edilir.
* **gamma**: AÄŸacÄ±n dallanmasÄ± iÃ§in gereken minimum kayÄ±p azaltÄ±mÄ±nÄ± belirtir; 1e-9â€“0.5 arasÄ± bir gerÃ§ek sayÄ± olmalÄ±, log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.
* **scale_pos_weight**: 1e-6â€“500 arasÄ± bir gerÃ§ek sayÄ±; pozitif sÄ±nÄ±f iÃ§in aÄŸÄ±rlÄ±ÄŸÄ± temsil eder, log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.

LightGBMâ€™de olduÄŸu gibi, XGBoostâ€™un da ayarlanmasÄ± gereken birÃ§ok benzer hiperparametresi vardÄ±r. DolayÄ±sÄ±yla LightGBM iÃ§in yapÄ±lan tÃ¼m deÄŸerlendirmeler XGBoost iÃ§in de geÃ§erlidir.

#### CatBoost *(CatBoost algoritmasÄ±)*

2017 Temmuzâ€™unda, Rus arama motoru Yandex, baÅŸka bir ilginÃ§ GBM algoritmasÄ±nÄ± kamuya aÃ§tÄ±: **CatBoost** ([https://catboost.ai/](https://catboost.ai/)). AdÄ±, â€œCategoryâ€ ve â€œBoostingâ€ kelimelerinin birleÅŸtirilmesinden gelir. AslÄ±nda gÃ¼Ã§lÃ¼ yÃ¶nÃ¼, Ã§oÄŸu iliÅŸkisel veritabanÄ±nda yer alan bilgilerin bÃ¼yÃ¼k kÄ±smÄ±nÄ± oluÅŸturan kategorik deÄŸiÅŸkenleri iÅŸleyebilme yeteneÄŸidir. Bunu, **one-hot encoding** ve **target encoding** yÃ¶ntemlerini harmanlayarak gerÃ§ekleÅŸtirir. Target encoding, kategorik seviyeleri, Ã¼zerinde Ã§alÄ±ÅŸÄ±lan probleme uygun sayÄ±sal bir deÄŸer atayarak ifade etme yÃ¶ntemidir; bunun detaylarÄ± **BÃ¶lÃ¼m 7, Tabular Competitions iÃ§in Modelleme** kÄ±smÄ±nda bulunabilir.

CatBoostâ€™un kategorik deÄŸiÅŸkenleri kodlamak iÃ§in kullandÄ±ÄŸÄ± fikir yeni deÄŸildir; aslÄ±nda bu, daha Ã¶nce Ã¶zellikle veri bilimi yarÄ±ÅŸmalarÄ±nda kullanÄ±lan bir tÃ¼r **feature engineering** (Ã¶zellik mÃ¼hendisliÄŸi) yÃ¶ntemidir. **Target encoding**, aynÄ± zamanda **likelihood encoding**, **impact coding** veya **mean encoding** olarak da bilinir ve temel olarak etiketlerinizi hedef deÄŸiÅŸkenle olan iliÅŸkilerine gÃ¶re sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rmenin bir yoludur. EÄŸer regresyon problemi varsa, etiketler tipik hedef deÄŸerinin ortalamasÄ±na gÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lebilir; sÄ±nÄ±flandÄ±rmada ise, bir etiket iÃ§in hedef sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ±dÄ±r (her kategori deÄŸeri iÃ§in hedefin koÅŸullu olasÄ±lÄ±ÄŸÄ±). Basit ve akÄ±llÄ±ca bir Ã¶zellik mÃ¼hendisliÄŸi hilesi gibi gÃ¶rÃ¼nse de, Ã§oÄŸunlukla **overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme)** riski taÅŸÄ±r Ã§Ã¼nkÃ¼ hedeften alÄ±nan bilgi tahminleyicilere dahil edilir.

CatBoostâ€™un oldukÃ§a fazla parametresi vardÄ±r ([https://catboost.ai/en/docs/references/training-parameters/](https://catboost.ai/en/docs/references/training-parameters/)). Biz tartÄ±ÅŸmamÄ±zÄ± en Ã¶nemli sekiz parametre ile sÄ±nÄ±rladÄ±k:

* **iterations**: Genellikle 10â€“1.000 arasÄ± bir tamsayÄ±; problem durumuna gÃ¶re artabilir.
* **depth**: 1â€“8 arasÄ± bir tamsayÄ±; genellikle daha yÃ¼ksek deÄŸerler daha uzun eÄŸitim sÃ¼resi gerektirir ve daha iyi sonuÃ§lar Ã¼retmez.
* **learning_rate**: 0.01â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.
* **random_strength**: 1e-9â€“10.0 arasÄ± log-lineer Ã¶rneklenen bir gerÃ§ek sayÄ±; dallanma puanlamasÄ±nda rastgelelik seviyesini belirtir.
* **bagging_temperature**: 0.0â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; Bayesian bootstrapâ€™u ayarlar.
* **border_count**: 1â€“255 arasÄ± bir tamsayÄ±; sayÄ±sal Ã¶zellikler iÃ§in bÃ¶lÃ¼nmeleri belirtir.
* **l2_leaf_reg**: 2â€“30 arasÄ± bir tamsayÄ±; L2 dÃ¼zenlileÅŸtirme iÃ§in deÄŸeri belirtir.
* **scale_pos_weight**: 0.01â€“10.0 arasÄ± bir gerÃ§ek sayÄ±; pozitif sÄ±nÄ±fÄ±n aÄŸÄ±rlÄ±ÄŸÄ±nÄ± temsil eder.

CatBoost, sadece baÅŸka bir GBM uygulamasÄ± gibi gÃ¶rÃ¼nse de, kullanÄ±lan farklÄ± parametrelerle de gÃ¶rÃ¼lebileceÄŸi Ã¼zere, yarÄ±ÅŸmalarda hem **tek model Ã§Ã¶zÃ¼mÃ¼** hem de **daha bÃ¼yÃ¼k bir ensemble iÃ§inde** bÃ¼yÃ¼k avantaj saÄŸlayabilecek birÃ§ok farklÄ±lÄ±ÄŸa sahiptir.

#### HistGradientBoosting *(Histogram tabanlÄ± gradyan gÃ¼Ã§lendirme)*

Son zamanlarda, Scikit-learn, LightGBMâ€™in **binned data** ve histogramlarÄ±ndan esinlenerek yeni bir gradient boosting sÃ¼rÃ¼mÃ¼ tanÄ±ttÄ± (EuroPythonâ€™daki Olivier Grisel sunumuna bakabilirsiniz: [https://www.youtube.com/watch?v=urVUlKbQfQ4](https://www.youtube.com/watch?v=urVUlKbQfQ4)). Bu algoritma, sÄ±nÄ±flandÄ±rÄ±cÄ± (**HistGradientBoostingClassifier**) veya regresÃ¶r (**HistGradientBoostingRegressor**) olarak kullanÄ±labilir. FarklÄ± modellerle ensemble oluÅŸturmak iÃ§in uygundur ve ayarlanmasÄ± gereken hiperparametreler Ã§ok daha kÄ±sa ve temel bir aralÄ±kta sunulmuÅŸtur:

* **learning_rate**: 0.01â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir.
* **max_iter**: 10â€“10.000 arasÄ± bir tamsayÄ±.
* **max_leaf_nodes**: 2â€“500 arasÄ± bir tamsayÄ±; **max_depth** ile etkileÅŸimlidir. Tavsiye edilen, iki parametreden yalnÄ±zca birini ayarlamak ve diÄŸerini **None** bÄ±rakmaktÄ±r.
* **max_depth**: 2â€“12 arasÄ± bir tamsayÄ±.
* **min_samples_leaf**: 2â€“300 arasÄ± bir tamsayÄ±.
* **l2_regularization**: 0.0â€“100.0 arasÄ± bir gerÃ§ek sayÄ±.
* **max_bins**: 32â€“512 arasÄ± bir tamsayÄ±.

Scikit-learnâ€™Ã¼n **HistGradientBoosting** algoritmasÄ±, LightGBM veya XGBoostâ€™tan Ã§ok farklÄ± olmasa da, bir yarÄ±ÅŸmada GBMâ€™leri uygulamak iÃ§in farklÄ± bir yol sunar. HistGradientBoosting ile oluÅŸturulan modeller, **blending** ve **stacking** gibi birden fazla tahminin ensemble edilmesinde katkÄ± saÄŸlayabilir.

Bu bÃ¶lÃ¼mÃ¼n sonunda, en yaygÄ±n makine Ã¶ÄŸrenimi algoritmalarÄ±na (sadece derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mleri hariÃ§) ve ayarlanmasÄ± gereken en Ã¶nemli hiperparametrelere daha aÅŸina olmalÄ±sÄ±nÄ±z. Bu bilgiler, Kaggle yarÄ±ÅŸmalarÄ±nda etkileyici Ã§Ã¶zÃ¼mler oluÅŸturmanÄ±zda yardÄ±mcÄ± olacaktÄ±r. Temel optimizasyon stratejilerini, kullanÄ±labilir algoritmalarÄ± ve bunlarÄ±n anahtar hiperparametrelerini bilmek yalnÄ±zca bir baÅŸlangÄ±Ã§tÄ±r. Bir sonraki bÃ¶lÃ¼mde, **Bayesian optimizasyon** kullanarak hiperparametreleri daha optimal ÅŸekilde ayarlamayÄ± derinlemesine ele alacaÄŸÄ±z.

> Alberto Danese
> 
> [https://www.kaggle.com/albedan](https://www.kaggle.com/albedan)
> 
> 
> 
> Bu bÃ¶lÃ¼mÃ¼n ikinci rÃ¶portajÄ±, Ä°talyan kredi kartÄ± ve dijital Ã¶deme ÅŸirketi Nexiâ€™de Veri Bilimi MÃ¼dÃ¼rÃ¼ olan Alberto Danese ile. 2015 yÄ±lÄ±nda Kaggleâ€™a katÄ±lmÄ±ÅŸ bir **Competitions Grandmaster** olan Danese, Ã§oÄŸu altÄ±n madalyasÄ±nÄ± bireysel olarak kazanmÄ±ÅŸtÄ±r.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z hangisi ve neden? Kaggleâ€™da teknik ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Finans sektÃ¶rÃ¼nde Ã§alÄ±ÅŸtÄ±m ve Ã§oÄŸunlukla yapÄ±landÄ±rÄ±lmÄ±ÅŸ verilerle ilgilendim, bu nedenle bu kategoriye ait yarÄ±ÅŸmalarÄ± tercih ediyorum. Verinin ne hakkÄ±nda olduÄŸunu pratik olarak anlamak ve veriden her bir bilgiyi Ã§Ä±karmak iÃ§in akÄ±llÄ±ca Ã¶zellik mÃ¼hendisliÄŸi yapmaktan keyif alÄ±yorum.
> 
> Teknik aÃ§Ä±dan, klasik ML kÃ¼tÃ¼phaneleri ve Ã¶zellikle **Gradient Boosting Decision Trees** konusunda deneyimim var: en yaygÄ±n kÃ¼tÃ¼phaneler (**XGBoost, LightGBM, CatBoost**) her zaman ilk tercihimdir.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±klarÄ±nÄ±zdan ne kadar farklÄ±?**
> 
> Veriyi keÅŸfetmeye ve sponsorun makine Ã¶ÄŸrenimi ile gerÃ§ekten Ã§Ã¶zmek istediÄŸi problemi anlamaya Ã§ok zaman harcarÄ±m. Yeni baÅŸlayanlarÄ±n dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼n aksine, ML algoritmasÄ±nÄ±n spesifik â€œayarlamalarÄ±â€na fazla zaman harcamam â€“ ve gÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re bu yaklaÅŸÄ±m iÅŸe yarÄ±yor!
> 
> GÃ¼nlÃ¼k iÅŸimde veri anlayÄ±ÅŸÄ± da Ã§ok Ã¶nemli, ancak Kaggle yarÄ±ÅŸmalarÄ±nda tamamen eksik olan bazÄ± ek aÅŸamalar var:
> 
> 
> 
> * ML ile Ã§Ã¶zÃ¼lmesi gereken bir iÅŸ problemi tanÄ±mlamak (iÅŸ birimindeki meslektaÅŸlarla birlikte)
> 
> * Veriyi bulmak, bazen harici veri saÄŸlayÄ±cÄ±lardan da
> 
> * ML kÄ±smÄ± tamamlandÄ±ÄŸÄ±nda, bunu Ã¼retime almak ve geliÅŸimlerini yÃ¶netmek
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zor bir yarÄ±ÅŸmayÄ± ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼leri anlatÄ±r mÄ±sÄ±nÄ±z?**
> 
> Grandmaster olduÄŸum **TalkingData AdTracking Fraud Detection Challenge** yarÄ±ÅŸmasÄ±nÄ± Ã§ok sevdim. Konu oldukÃ§a ilginÃ§ti (click-farm dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ±yla mÃ¼cadele) ve bÃ¼yÃ¼k hacimler (100Mâ€™den fazla etiketli satÄ±r) nedeniyle verimli Ã¶zellik mÃ¼hendisliÄŸi yapmamÄ± zorunlu kÄ±ldÄ±. AyrÄ±ca, farklÄ± yaklaÅŸÄ±mlarÄ± test etmek iÃ§in hesaplama sÃ¼relerini azaltmak ve lag/lead Ã¶zellikleri ile diÄŸer pencere fonksiyonlarÄ±nÄ± en iyi ÅŸekilde kullanarak klasik bir ML problemine zaman serisi benzeri bir yapÄ± kazandÄ±rmak zorundaydÄ±m.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? NasÄ±l?**
> 
> Kesinlikle! BÃ¼yÃ¼k ve doÄŸrulanabilir sonuÃ§lar elde edebilmek, Ã¶zgeÃ§miÅŸte Ã¶ne Ã§Ä±kmanÄ±zÄ± saÄŸlar. 2016â€™da Cerved (bir pazarlama istihbarat ÅŸirketi) tarafÄ±ndan iÅŸe alÄ±ndÄ±ÄŸÄ±mda, iÅŸe alÄ±m yÃ¶neticisi Kaggleâ€™Ä±n ne olduÄŸunu Ã§ok iyi biliyordu â€“ ve gÃ¶rÃ¼ÅŸmede gerÃ§ek dÃ¼nya projelerinden bahsedebilmek Ã§ok deÄŸerliydi. Kesinlikle Kaggle, kariyerimin geliÅŸiminde Ã¶nemli bir rol oynadÄ±.
> 
> 
> 
> **Deneyiminize gÃ¶re, acemi Kagglers genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? Ä°lk baÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz iyi olurdu dediÄŸiniz ÅŸey nedir?**
> 
> Herkesin genellikle kodlamaya baÅŸladÄ±ÄŸÄ±nÄ±, bir public kernelâ€™i forkladÄ±ÄŸÄ±nÄ± ve birkaÃ§ satÄ±r veya parametre deÄŸiÅŸtirdiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. BaÅŸlangÄ±Ã§ta bu tamamen normal! Ancak kodlamadan Ã¶nce veriyi incelemeye ve problemi anlamaya ciddi zaman ayÄ±rmak gerekir.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdir?**
> 
> Belki hata sayÄ±lmaz ama genellikle solo yarÄ±ÅŸmayÄ± tercih ettim: bir yandan her yÃ¶nÃ¼yle ilgilenmek zorunda olduÄŸunuz iÃ§in iyi, zamanÄ±nÄ±zÄ± istediÄŸiniz gibi yÃ¶netebilirsiniz. Ancak birkaÃ§ yarÄ±ÅŸmada takÄ±m arkadaÅŸlarÄ±yla Ã§alÄ±ÅŸmak da Ã§ok keyifliydi; muhtemelen daha sÄ±k takÄ±m kurmayÄ± dÃ¼ÅŸÃ¼nmeliyim, Ã§Ã¼nkÃ¼ iÅŸ birliÄŸi Ã§ok ÅŸey Ã¶ÄŸretiyor.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> AlÄ±ÅŸÄ±lmÄ±ÅŸlarÄ±n dÄ±ÅŸÄ±nda, her zaman **data.table** (R versiyonundan itibaren) hayranÄ± oldum: yeterince takdir edilmiyor bence! BÃ¼yÃ¼k veriyle yerel bir makinede Ã§alÄ±ÅŸmak iÃ§in gerÃ§ekten harika bir paket.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Ã–nce problemi ve veriyi anlayÄ±n: hemen kodlamaya baÅŸlamayÄ±n!

### Bayesian optimization *(Bayesyen optimizasyon)*

Grid searchâ€™Ã¼ geride bÄ±raktÄ±ÄŸÄ±mÄ±zda (ki bu yalnÄ±zca deney alanÄ± sÄ±nÄ±rlÄ± olduÄŸunda uygulanabilir), uygulayÄ±cÄ±larÄ±n genellikle tercih ettiÄŸi yÃ¶ntem **random search optimizasyonu** uygulamak veya daha karmaÅŸÄ±k bir kurulum gerektiren **Bayesian optimizasyon (BO)** tekniÄŸini denemektir.

Bayesian optimizasyon kavramÄ±, Snoek, J., Larochelle, H. ve Adams, R. P. tarafÄ±ndan **â€œPractical Bayesian Optimization of Machine Learning Algorithmsâ€** ([http://export.arxiv.org/pdf/1206.2944](http://export.arxiv.org/pdf/1206.2944)) adlÄ± makalede tanÄ±tÄ±lmÄ±ÅŸtÄ±r. Temel fikir ÅŸudur: **GerÃ§ek amaÃ§ fonksiyonu yerine bir vekil fonksiyon (surrogate function) optimize edilir**. Grid search ve random search ise doÄŸrudan gerÃ§ek amaÃ§ fonksiyonunu optimize eder. Bu yaklaÅŸÄ±m, gradyanlar yoksa, gerÃ§ek amaÃ§ fonksiyonunu test etmek maliyetliyse (aksi takdirde random search tercih edilir) veya arama alanÄ± karmaÅŸÄ±k ve gÃ¼rÃ¼ltÃ¼lÃ¼ ise kullanÄ±lÄ±r.

Bayesian arama, **keÅŸif (exploration)** ile **sÃ¶mÃ¼rÃ¼ (exploitation)** arasÄ±nda bir denge kurar. BaÅŸlangÄ±Ã§ta rastgele keÅŸif yaparak vekil fonksiyonu eÄŸitir. Bu vekil fonksiyon temel alÄ±narak, arama, tahminleyicinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair ilk yaklaÅŸÄ±k bilgiyi kullanarak daha faydalÄ± Ã¶rnekler seÃ§er ve maliyet fonksiyonunu minimize eder. Bayesian yaklaÅŸÄ±mÄ± adÄ±nda belirtildiÄŸi gibi, optimizasyon sÄ±rasÄ±nda daha akÄ±llÄ±ca kararlar almak iÃ§in **Ã¶ncÃ¼l bilgiler (priors)** kullanÄ±lÄ±r. BÃ¶ylece, gerekli deÄŸerlendirme sayÄ±sÄ±nÄ± sÄ±nÄ±rlayarak minimizasyon daha hÄ±zlÄ± gerÃ§ekleÅŸtirilir.

Bayesian optimizasyon, bir gÃ¶zlemin ne kadar faydalÄ± olacaÄŸÄ±nÄ± belirlemek iÃ§in bir **acquisition function (edinim fonksiyonu)** kullanÄ±r. KeÅŸif ve sÃ¶mÃ¼rÃ¼ arasÄ±ndaki dengeyi yÃ¶netmek iÃ§in algoritma, herhangi bir noktanÄ±n denenmesinin ne kadar faydalÄ± olacaÄŸÄ±nÄ± tek bir Ã¶lÃ§Ã¼ ile saÄŸlar.

Genellikle Bayesian optimizasyon **Gaussian sÃ¼reÃ§leri (Gaussian processes)** ile desteklenir. Gaussian sÃ¼reÃ§leri, arama alanÄ± dÃ¼zgÃ¼n ve tahmin edilebilir bir yanÄ±t verdiÄŸinde daha iyi performans gÃ¶sterir. Arama alanÄ± daha karmaÅŸÄ±ksa, alternatif olarak **aÄŸaÃ§ algoritmalarÄ±** (Ã¶r. random forests) veya tamamen farklÄ± bir yaklaÅŸÄ±m olan **Tree Parzen Estimators (TPE)** / **Tree-structured Parzen Estimators** kullanÄ±labilir.

TPEâ€™ler, parametrelerin baÅŸarÄ±sÄ±nÄ± tahmin eden bir model kurmak yerine, deneylerden elde edilen ardÄ±ÅŸÄ±k yaklaÅŸÄ±mlara dayanarak **en iyi performans gÃ¶steren parametrelerin Ã§ok deÄŸiÅŸkenli daÄŸÄ±lÄ±mÄ±nÄ± tahmin eder**. BÃ¶ylece TPEâ€™ler, parametreleri doÄŸrudan bir ML modeli Ã¼zerinden (Gaussian sÃ¼reÃ§leri gibi) almak yerine, olasÄ±lÄ±ksal bir daÄŸÄ±lÄ±mdan Ã¶rnekleyerek en iyi parametre setini elde eder.

Bu yaklaÅŸÄ±mlarÄ± inceleyeceÄŸiz: Ã¶nce **Gaussian sÃ¼reÃ§lerine dayalÄ±** Scikit-optimize ve KerasTuner (Scikit-optimize ayrÄ±ca random forests, KerasTuner ise multi-armed bandits kullanabilir), ardÄ±ndan esas olarak **TPE tabanlÄ± Optuna** (farklÄ± stratejiler de sunar: [https://optuna.readthedocs.io/en/stable/reference/samplers.html](https://optuna.readthedocs.io/en/stable/reference/samplers.html)) ele alÄ±nacak.

> Bayesian optimizasyon, hiperparametre ayarlamada **en geliÅŸmiÅŸ yÃ¶ntem** olarak kabul edilse de, daha karmaÅŸÄ±k parametre alanlarÄ±nda zaman ve hesaplama aÃ§Ä±sÄ±ndan **random search ile bulunan bir Ã§Ã¶zÃ¼me gÃ¶re avantaj saÄŸlamayabileceÄŸini** unutmamak gerekir. Ã–rneÄŸin Google Cloud Machine Learning Engine hizmetlerinde Bayesian optimizasyon, en fazla 16 parametreli problemlerle sÄ±nÄ±rlÄ±dÄ±r; daha fazla parametre olduÄŸunda **random sampling** kullanÄ±lÄ±r.

#### Using Scikit-optimize *(Scikit-optimize kullanÄ±mÄ±)*

Scikit-optimize (skopt), **Scikit-learn ile aynÄ± API kullanÄ±larak geliÅŸtirilmiÅŸ** ve **NumPy ile SciPy fonksiyonlarÄ±ndan yoÄŸun ÅŸekilde yararlanÄ±lmÄ±ÅŸtÄ±r**. AyrÄ±ca, Scikit-learn projesine katkÄ±da bulunan bazÄ± kiÅŸiler (Ã¶r. Gilles Louppe) tarafÄ±ndan oluÅŸturulmuÅŸtur.

Gaussian sÃ¼reÃ§ algoritmalarÄ±na dayalÄ± bu paket, iyi bir ÅŸekilde bakÄ±m yapÄ±lmaktadÄ±r; ancak bazen Scikit-learn, NumPy veya SciPy tarafÄ±ndaki gÃ¼ncellemeleri yakalamak iÃ§in geri kalmasÄ± gerekebilir. Ã–rneÄŸin yazÄ±m sÄ±rasÄ±nda, Kaggle Notebooks Ã¼zerinde dÃ¼zgÃ¼n Ã§alÄ±ÅŸtÄ±rmak iÃ§in bu paketlerin eski sÃ¼rÃ¼mlerine dÃ¶nmek gerekebilir (detaylar GitHubâ€™da: [https://github.com/scikit-optimize/scikit-optimize/issues/981](https://github.com/scikit-optimize/scikit-optimize/issues/981)).

Paket **sezgisel bir APIâ€™ye sahiptir** ve iÅŸlevlerini kendi optimizasyon stratejilerinizde kullanmak oldukÃ§a kolaydÄ±r. Skopt ayrÄ±ca **grafiksel gÃ¶rselleÅŸtirmeleriyle** de tanÄ±nÄ±r. Ã–rneÄŸin, optimizasyon sÃ¼recinin sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirerek (`plot_objective` fonksiyonu ile) arama alanÄ±nÄ± yeniden tanÄ±mlayÄ±p, optimizasyonun problem iÃ§in nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± aÃ§Ä±klayabilirsiniz.

Ã–rnekler iÃ§in baÅŸvurulan Kaggle Notebooks:

* [https://www.kaggle.com/lucamassaron/tutorial-bayesian-optimization-with-lightgbm](https://www.kaggle.com/lucamassaron/tutorial-bayesian-optimization-with-lightgbm)
* [https://www.kaggle.com/lucamassaron/scikit-optimize-for-lightgbm](https://www.kaggle.com/lucamassaron/scikit-optimize-for-lightgbm)

Bu Ã¶rnekte, **30 Days of ML** yarÄ±ÅŸmasÄ± Ã¼zerinden bir optimizasyon problemini nasÄ±l hÄ±zlÄ±ca Ã§Ã¶zebileceÄŸimizi gÃ¶stereceÄŸiz. Bu yarÄ±ÅŸma, katÄ±lÄ±mcÄ±lara yeni beceriler kazandÄ±rmayÄ± ve 30 gÃ¼n sÃ¼ren bir yarÄ±ÅŸmada uygulamayÄ± amaÃ§lamaktadÄ±r. YarÄ±ÅŸma, bir sigorta talebinin deÄŸerini tahmin etmeyi hedeflediÄŸi iÃ§in **regresyon problemi** olarak sÄ±nÄ±flandÄ±rÄ±lÄ±r. Daha fazla bilgi ve veri indirmek iÃ§in: [https://www.kaggle.com/thirty-days-of-ml](https://www.kaggle.com/thirty-days-of-ml)

---

* AdÄ±m 1: KÃ¼tÃ¼phaneleri yÃ¼klemek

```python
# Temel kÃ¼tÃ¼phaneler
import numpy as np
import pandas as pd
from time import time
import pprint
import joblib
from functools import partial

# UyarÄ±larÄ± gizlemek
import warnings
warnings.filterwarnings("ignore")

# SÄ±nÄ±flandÄ±rÄ±cÄ±lar
import lightgbm as lgb

# Model seÃ§imi
from sklearn.model_selection import KFold

# Metrikler
from sklearn.metrics import mean_squared_error, make_scorer

# Skopt fonksiyonlarÄ±
from skopt import BayesSearchCV
from skopt.callbacks import DeadlineStopper, DeltaYStopper
from skopt.space import Real, Categorical, Integer
```

* AdÄ±m 2: Veriyi yÃ¼klemek ve hazÄ±rlamak

```python
# Veriyi yÃ¼kleme
X = pd.read_csv("../input/30-days-of-ml/train.csv")
X_test = pd.read_csv("../input/30-days-of-ml/test.csv")

# Hedef ve indeks ayarlama
y = X.target
X = X.set_index('id').drop('target', axis='columns')
X_test = X_test.set_index('id')

# Kategorik verileri sayÄ±sal hale getirme
categoricals = [item for item in X.columns if 'cat' in item]
cat_values = np.unique(X[categoricals].values)
cat_dict = dict(zip(cat_values, range(len(cat_values))))
X[categoricals] = X[categoricals].replace(cat_dict).astype('category')
X_test[categoricals] = X_test[categoricals].replace(cat_dict).astype('category')
```

* AdÄ±m 3: Raporlama fonksiyonunu tanÄ±mlamak

```python
def report_perf(optimizer, X, y, title="model", callbacks=None):
    """
    Optimizer performansÄ±nÄ± ve sÃ¼reyi raporlamak iÃ§in bir wrapper
    """
    start = time()
    if callbacks is not None:
        optimizer.fit(X, y, callback=callbacks)
    else:
        optimizer.fit(X, y)
    
    d = pd.DataFrame(optimizer.cv_results_)
    best_score = optimizer.best_score_
    best_score_std = d.iloc[optimizer.best_index_].std_test_score
    best_params = optimizer.best_params_
    
    print((title + " took %.2f seconds, candidates checked: %d, best CV score: %.3f Â± %.3f") %
          (time() - start, len(optimizer.cv_results_['params']), best_score, best_score_std))
    print('Best parameters:')
    pprint.pprint(best_params)
    print()
    
    return best_params
```

* AdÄ±m 4: DeÄŸerlendirme metriÄŸi, doÄŸrulama stratejisi ve model

```python
scoring = make_scorer(partial(mean_squared_error, squared=False), greater_is_better=False)
kf = KFold(n_splits=5, shuffle=True, random_state=0)

reg = lgb.LGBMRegressor(
    boosting_type='gbdt',
    metric='rmse',
    objective='regression',
    n_jobs=1,
    verbose=-1,
    random_state=0
)
```

* AdÄ±m 5: Hiperparametre arama alanÄ±nÄ± tanÄ±mlamak

```python
search_spaces = {
    'learning_rate': Real(0.01, 1.0, 'log-uniform'),
    'n_estimators': Integer(30, 5000),
    'num_leaves': Integer(2, 512),
    'max_depth': Integer(-1, 256),
    'min_child_samples': Integer(1, 256),
    'max_bin': Integer(100, 1000),
    'subsample': Real(0.01, 1.0, 'uniform'),
    'subsample_freq': Integer(0, 10),
    'colsample_bytree': Real(0.01, 1.0, 'uniform'),
    'min_child_weight': Real(0.01, 10.0, 'uniform'),
    'reg_lambda': Real(1e-9, 100.0, 'log-uniform'),
    'reg_alpha': Real(1e-9, 100.0, 'log-uniform'),
}
```

* AdÄ±m 6: Bayesian optimizasyonunu baÅŸlatmak

```python
opt = BayesSearchCV(
    estimator=reg,
    search_spaces=search_spaces,
    scoring=scoring,
    cv=kf,
    n_iter=60,           # Maksimum deneme sayÄ±sÄ±
    n_jobs=-1,           # Ä°ÅŸlem sayÄ±sÄ±
    iid=False,           # CV skoruna gÃ¶re optimize et
    return_train_score=False,
    refit=False,
    optimizer_kwargs={'base_estimator': 'GP'},  # Gaussian Processes
    random_state=0
)

# Kontroller
overdone_control = DeltaYStopper(delta=0.0001)   # KazanÃ§ Ã§ok az ise dur
time_limit_control = DeadlineStopper(total_time=60*60*6)  # 6 saat limit

best_params = report_perf(opt, X, y, 'LightGBM_regression',
                          callbacks=[overdone_control, time_limit_control])
```

Bu Ã¶rnekte, **Bayesian optimizasyon** keÅŸif ve sÃ¶mÃ¼rÃ¼ stratejilerini birleÅŸtirdiÄŸi iÃ§in, herhangi bir zamanda durdurulsa bile o ana kadar bulunan **en iyi Ã§Ã¶zÃ¼mÃ¼** dÃ¶ndÃ¼rÃ¼r. Ancak bu, mutlaka **en iyi teorik Ã§Ã¶zÃ¼m** olduÄŸu anlamÄ±na gelmez; Ã§Ã¼nkÃ¼ acquisition function, vekil fonksiyon ve belirsizlik aralÄ±klarÄ±na gÃ¶re **en umut verici bÃ¶lgeleri Ã¶nceliklendirir**.

#### Customizing a Bayesian optimization search *(Bayesyen aramayÄ± Ã¶zelleÅŸtirme)*

Scikit-optimize tarafÄ±ndan sunulan **BayesSearchCV** fonksiyonu kesinlikle kullanÄ±ÅŸlÄ±dÄ±r; Ã§Ã¼nkÃ¼ bir hiperparametre aramasÄ±nÄ±n tÃ¼m Ã¶ÄŸelerini kendi baÅŸÄ±na sarar ve dÃ¼zenler. Ancak, bazÄ± sÄ±nÄ±rlamalarÄ± da vardÄ±r. Ã–rneÄŸin, bir yarÄ±ÅŸmada ÅŸu durumlarda faydalÄ± olabilir:

* Her arama iterasyonu Ã¼zerinde daha fazla kontrol sahibi olmak (Ã¶rneÄŸin, rastgele arama ile Bayesian aramayÄ± karÄ±ÅŸtÄ±rmak)
* Algoritmalarda erken durdurmayÄ± uygulayabilmek
* DoÄŸrulama stratejinizi daha fazla Ã¶zelleÅŸtirmek
* Ã‡alÄ±ÅŸmayan deneyleri erken durdurmak (Ã¶rneÄŸin, tÃ¼m katlarÄ±n ortalamasÄ±nÄ± beklemek yerine, tek bir Ã§apraz doÄŸrulama katÄ±nÄ±n performansÄ±nÄ± hemen deÄŸerlendirmek)
* Benzer performans gÃ¶steren hiperparametre setlerinden kÃ¼meler oluÅŸturmak (Ã¶rneÄŸin, yalnÄ±zca kullanÄ±lan hiperparametreler farklÄ± olan birden fazla model oluÅŸturmak ve bunlarÄ± bir *blending ensemble* iÃ§in kullanmak)

Bu gÃ¶revlerin her biri, BayesSearchCVâ€™nin dahili prosedÃ¼rÃ¼nÃ¼ deÄŸiÅŸtirebilseydiniz Ã§ok karmaÅŸÄ±k olmazdÄ±. Neyse ki, Scikit-optimize bunu yapmanÄ±za izin veriyor. AslÄ±nda, BayesSearchCVâ€™nin ve paketteki diÄŸer sarÄ±cÄ±larÄ±n arkasÄ±nda, kendi arama fonksiyonunuzun baÄŸÄ±msÄ±z bir parÃ§asÄ± olarak kullanabileceÄŸiniz belirli minimize fonksiyonlarÄ± vardÄ±r:

* **gp_minimize**: Gauss sÃ¼reÃ§leri kullanarak Bayesian optimizasyonu
* **forest_minimize**: Rastgele ormanlar veya aÅŸÄ±rÄ± rastgeleleÅŸtirilmiÅŸ aÄŸaÃ§lar kullanarak Bayesian optimizasyonu
* **gbrt_minimize**: Gradient boosting kullanarak Bayesian optimizasyonu
* **dummy_minimize**: Sadece rastgele arama

AÅŸaÄŸÄ±daki Ã¶rnekte, Ã¶nceki aramayÄ± kendi Ã¶zel arama fonksiyonumuzu kullanarak deÄŸiÅŸtireceÄŸiz. Yeni Ã¶zel fonksiyon, eÄŸitim sÄ±rasÄ±nda erken durdurmayÄ± kabul edecek ve kat doÄŸrulama sonuÃ§larÄ±ndan biri iyi performans gÃ¶stermiyorsa deneyleri budayacaktÄ±r.

> Ã–rneÄŸin Ã§alÄ±ÅŸÄ±r hÃ¢li, Kaggle Notebookâ€™ta bulunabilir: [Hacking Bayesian Optimization](https://www.kaggle.com/lucamassaron/hacking-bayesian-optimization).

Ã–nceki Ã¶rnekte olduÄŸu gibi, gerekli paketleri import ederek baÅŸlÄ±yoruz:

```python
# Temel kÃ¼tÃ¼phaneler
import numpy as np
import pandas as pd
from time import time
import pprint
import joblib
from functools import partial
import warnings
warnings.filterwarnings("ignore")  # skopt verbosity nedeniyle uyarÄ±larÄ± kapatma

# SÄ±nÄ±flandÄ±rÄ±cÄ±/RegresÃ¶r
from xgboost import XGBRegressor

# Model seÃ§imi
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split

# Ã–lÃ§Ã¼tler
from sklearn.metrics import mean_squared_error, make_scorer

# Skopt fonksiyonlarÄ±
from skopt import BayesSearchCV
from skopt.callbacks import DeadlineStopper, DeltaYStopper
from skopt.space import Real, Categorical, Integer
from skopt import gp_minimize, forest_minimize, gbrt_minimize, dummy_minimize
from skopt.utils import use_named_args  # Parametre listesini isimlendirilmiÅŸ argÃ¼manlara Ã§eviren decorator

# Veri iÅŸleme
from sklearn.preprocessing import OrdinalEncoder
```

Verileri, **30 Days of ML** yarÄ±ÅŸmasÄ±ndan yÃ¼kleyelim:

```python
X_train = pd.read_csv("../input/30-days-of-ml/train.csv")
X_test = pd.read_csv("../input/30-days-of-ml/test.csv")

y_train = X_train.target
X_train = X_train.set_index('id').drop('target', axis='columns')
X_test = X_test.set_index('id')

# Kategorik deÄŸiÅŸkenleri belirleme
categoricals = [item for item in X_train.columns if 'cat' in item]

# Kategorik verileri OrdinalEncoder ile iÅŸleme
ordinal_encoder = OrdinalEncoder()
X_train[categoricals] = ordinal_encoder.fit_transform(X_train[categoricals])
X_test[categoricals] = ordinal_encoder.transform(X_test[categoricals])
```

Åimdi hiperparametre aramasÄ± iÃ§in gerekli tÃ¼m Ã¶ÄŸeleri ayarlÄ±yoruz: scoring fonksiyonu, doÄŸrulama stratejisi, arama alanÄ± ve optimize edilecek makine Ã¶ÄŸrenimi modeli. Scoring fonksiyonu ve doÄŸrulama stratejisi, daha sonra Bayesian optimizasyonunun minimize etmeye Ã§alÄ±ÅŸacaÄŸÄ± **objective function**â€™Ä±n temel Ã¶ÄŸeleri olacak:

```python
# Scoring fonksiyonu
scoring = partial(mean_squared_error, squared=False)

# CV stratejisi
kf = KFold(n_splits=5, shuffle=True, random_state=0)

# Arama alanÄ±
space = [
    Real(0.01, 1.0, 'uniform', name='learning_rate'),
    Integer(1, 8, name='max_depth'),
    Real(0.1, 1.0, 'uniform', name='subsample'),
    Real(0.1, 1.0, 'uniform', name='colsample_bytree'),  
    Real(0, 100., 'uniform', name='reg_lambda'),
    Real(0, 100., 'uniform', name='reg_alpha'),
    Real(1, 30, 'uniform', name='min_child_weight')
]

model = XGBRegressor(n_estimators=10_000, booster='gbtree', random_state=0)
```

Bu sefer **n_estimators** parametresini arama alanÄ±na dahil etmedik; bunun yerine model Ã¶rneÄŸi oluÅŸtururken yÃ¼ksek bir deÄŸer verdik, Ã§Ã¼nkÃ¼ modelin erken durdurulmasÄ±nÄ± doÄŸrulama setine gÃ¶re yapmayÄ± planlÄ±yoruz.

---

DevamÄ±nda, objective functionâ€™Ä± tanÄ±mlayacaÄŸÄ±z. Bu fonksiyon, optimize edilecek parametreleri alacak ve skoru dÃ¶ndÃ¼recek. Ancak aynÄ± zamanda hazÄ±rladÄ±ÄŸÄ±nÄ±z arama Ã¶ÄŸelerini de kabul etmelidir. Ä°yi bir uygulama olarak, bu Ã¶ÄŸeleri fonksiyonun iÃ§ine almak daha avantajlÄ±dÄ±r; bÃ¶ylece Ã¶ÄŸeler deÄŸiÅŸmez olur ve fonksiyonla birlikte taÅŸÄ±nabilir.

```python
# Minimize edilecek objective function
def make_objective(model, X, y, space, cv, scoring, validation=0.2):
    @use_named_args(space)
    def objective(**params):
        model.set_params(**params)
        print("\nTesting: ", params)
        validation_scores = list()
        for k, (train_index, test_index) in enumerate(kf.split(X, y)):
            val_index = list()
            train_examples = int(train_examples * (1 - validation))
            train_index, val_index = (train_index[:train_examples], train_index[train_examples:])
            start_time = time()
            model.fit(
                X.iloc[train_index,:], y[train_index],
                early_stopping_rounds=50,
                eval_set=[(X.iloc[val_index,:], y[val_index])], 
                verbose=0
            )
            end_time = time()
            
            rounds = model.best_iteration
            test_preds = model.predict(X.iloc[test_index,:])
            test_score = scoring(y[test_index], test_preds)
            print(f"CV Fold {k+1} rmse:{test_score:0.5f}-{rounds} rounds - it took {end_time-start_time:0.0f} secs")
            validation_scores.append(test_score)

            # Erken durdurma kontrolÃ¼
            if len(history[k]) >= 10:
                threshold = np.percentile(history[k], q=25)
                if test_score > threshold:
                    print(f"Early stopping for under-performing fold: threshold is {threshold:0.5f}")
                    return np.mean(validation_scores)
            history[k].append(test_score)
        return np.mean(validation_scores)
    return objective
```

Bu fonksiyon, veri ve modeli kullanarak Ã§apraz doÄŸrulama yapar ve erken durdurma uygular. Daha sonra tÃ¼m bu Ã¶ÄŸeleri **make_objective** ile birleÅŸtirip yalnÄ±zca parametreleri alan bir fonksiyon elde ediyoruz:

```python
objective = make_objective(model, X_train, y_train, space=space, cv=kf, scoring=scoring)
```

AyrÄ±ca her iterasyonu kaydedecek bir callback fonksiyonu hazÄ±rlÄ±yoruz:

```python
def onstep(res):
    global counter
    x0 = res.x_iters   
    y0 = res.func_vals
    print('Last eval: ', x0[-1], ' - Score ', y0[-1])
    print('Current iter: ', counter, ' - Best Score ', res.fun, ' - Best Args: ', res.x)
    joblib.dump((x0, y0), 'checkpoint.pkl') 
    counter += 1
```

BaÅŸlangÄ±Ã§ iÃ§in rastgele arama ile birkaÃ§ deney oluÅŸturuyoruz:

```python
counter = 0
history = {i:list() for i in range(5)}
used_time = 0

gp_round = dummy_minimize(func=objective,
                          dimensions=space,
                          n_calls=30,
                          callback=[onstep],
                          random_state=0)
```

Kaydedilen deneyleri geri Ã§aÄŸÄ±rabilir ve Bayes optimizasyonunu devam ettirebiliriz:

```python
x0, y0 = joblib.load('checkpoint.pkl')
gp_round = gp_minimize(func=objective,
                       x0=x0,
                       y0=y0,
                       dimensions=space,
                       acq_func='gp_hedge',
                       n_calls=30,
                       n_initial_points=0,
                       callback=[onstep],
                       random_state=0)
```

Son olarak, en iyi skoru ve hiperparametre setini yazdÄ±rabiliriz:

```python
x0, y0 = joblib.load('checkpoint.pkl')
print(f"Best score: {gp_round.fun:0.5f}")
print("Best hyperparameters:")
for sp, x in zip(gp_round.space, gp_round.x):
    print(f"{sp.name:25} : {x}")
```

Bu parametreler ile modelimizi yeniden eÄŸitip yarÄ±ÅŸmada kullanabiliriz. AyrÄ±ca sonuÃ§larÄ± analiz edip benzer performans gÃ¶steren ancak farklÄ± parametre setlerine sahip modelleri gruplayabiliriz; bu da **blending** iÃ§in idealdir ve daha Ã§eÅŸitli bir model seti oluÅŸturur.

#### Extending Bayesian optimization to neural architecture search *(Bayesyen optimizasyonu sinir aÄŸÄ± mimarisi aramasÄ±na geniÅŸletme)*

#### Creating lighter and faster models with KerasTuner *(KerasTuner ile daha hafif ve hÄ±zlÄ± modeller oluÅŸturma)*

#### The TPE approach in Optuna *(Optunaâ€™daki TPE yaklaÅŸÄ±mÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 9: Ensembling with Blending and Stacking Solutions *(BÃ¶lÃ¼m 9: KarÄ±ÅŸtÄ±rma ve YÄ±ÄŸÄ±nlama (Ensemble) Ã‡Ã¶zÃ¼mleri)*

### A brief introduction to ensemble algorithms *(Topluluk (ensemble) algoritmalarÄ±na kÄ±sa bir giriÅŸ)*

### Averaging models into an ensemble *(Modelleri ortalama alarak birleÅŸtirme)*

#### Majority voting *(Ã‡oÄŸunluk oylamasÄ±)*

#### Averaging of model predictions *(Model tahminlerinin ortalamasÄ±)*

#### Weighted averages *(AÄŸÄ±rlÄ±klÄ± ortalamalar)*

#### Averaging in your cross-validation strategy *(Ã‡apraz doÄŸrulama stratejinde ortalama alma)*

#### Correcting averaging for ROC-AUC evaluations *(ROC-AUC deÄŸerlendirmeleri iÃ§in ortalamayÄ± dÃ¼zeltme)*

### Blending models using a meta-model *(Meta-model kullanarak modelleri karÄ±ÅŸtÄ±rma)*

#### Best practices for blending *(KarÄ±ÅŸtÄ±rma iÃ§in en iyi uygulamalar)*

### Stacking models together *(Modelleri yÄ±ÄŸÄ±nlama)*

#### Stacking variations *(YÄ±ÄŸÄ±nlama varyasyonlarÄ±)*

### Creating complex stacking and blending solutions *(KarmaÅŸÄ±k karÄ±ÅŸtÄ±rma ve yÄ±ÄŸÄ±nlama Ã§Ã¶zÃ¼mleri oluÅŸturma)*

### Summary *(Ã–zet)*

---

## Chapter 10: Modeling for Computer Vision *(BÃ¶lÃ¼m 10: BilgisayarlÄ± GÃ¶rÃ¼ (Computer Vision) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Augmentation strategies *(Veri artÄ±rma stratejileri)*

#### Keras built-in augmentations *(Kerasâ€™Ä±n yerleÅŸik artÄ±rmalarÄ±)*

#### ImageDataGenerator approach *(ImageDataGenerator yaklaÅŸÄ±mÄ±)*

#### Preprocessing layers *(Ã–n iÅŸleme katmanlarÄ±)*

#### albumentations *(Albumentations kÃ¼tÃ¼phanesi)*

### Classification *(SÄ±nÄ±flandÄ±rma)*

### Object detection *(Nesne tespiti)*

### Semantic segmentation *(Anlamsal segmentasyon)*

### Summary *(Ã–zet)*

---

## Chapter 11: Modeling for NLP *(BÃ¶lÃ¼m 11: DoÄŸal Dil Ä°ÅŸleme (NLP) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Sentiment analysis *(Duygu analizi)*

### Open domain Q&A *(AÃ§Ä±k alan soru-cevap)*

### Text augmentation strategies *(Metin artÄ±rma stratejileri)*

#### Basic techniques *(Temel teknikler)*

#### nlpaug *(nlpaug kÃ¼tÃ¼phanesi)*

### Summary *(Ã–zet)*

---

## Chapter 12: Simulation and Optimization Competitions *(BÃ¶lÃ¼m 12: SimÃ¼lasyon ve Optimizasyon YarÄ±ÅŸmalarÄ±)*

### Connect X *(Connect X oyunu)*

### Rock-paper-scissors *(TaÅŸ-kaÄŸÄ±t-makas)*

### Santa competition 2020 *(Santa yarÄ±ÅŸmasÄ± 2020)*

### The name of the game *(Oyunun Ã¶zÃ¼)*

### Summary *(Ã–zet)*

---

# Part III: Leveraging Competitions for Your Career *(BÃ¶lÃ¼m III: YarÄ±ÅŸmalarÄ± Kariyerinde Avantaja DÃ¶nÃ¼ÅŸtÃ¼rme)*

## Chapter 13: Creating Your Portfolio of Projects and Ideas *(BÃ¶lÃ¼m 13: Proje ve Fikir PortfÃ¶yÃ¼ OluÅŸturma)*

### Building your portfolio with Kaggle *(Kaggle ile portfÃ¶y oluÅŸturma)*

### Leveraging Notebooks and discussions *(Defterler ve tartÄ±ÅŸmalardan yararlanma)*

### Leveraging Datasets *(Veri setlerinden yararlanma)*

### Arranging your online presence beyond Kaggle *(Kaggle dÄ±ÅŸÄ±nda Ã§evrimiÃ§i varlÄ±ÄŸÄ±nÄ± dÃ¼zenleme)*

#### Blogs and publications *(Bloglar ve yayÄ±nlar)*

#### GitHub *(GitHub)*

### Monitoring competition updates and newsletters *(YarÄ±ÅŸma gÃ¼ncellemelerini ve bÃ¼ltenleri takip etme)*

### Summary *(Ã–zet)*

---

## Chapter 14: Finding New Professional Opportunities *(BÃ¶lÃ¼m 14: Yeni Profesyonel FÄ±rsatlar Bulmak)*

### Building connections with other competition data scientists *(DiÄŸer yarÄ±ÅŸmacÄ± veri bilimcilerle baÄŸlantÄ± kurma)*

### Participating in Kaggle Days and other Kaggle meetups *(Kaggle Days ve diÄŸer Kaggle buluÅŸmalarÄ±na katÄ±lma)*

### Getting spotted and other job opportunities *(Fark edilmek ve diÄŸer iÅŸ fÄ±rsatlarÄ±)*

#### The STAR approach *(STAR yaklaÅŸÄ±mÄ±)*

### Summary (and some parting words) *(Ã–zet ve kapanÄ±ÅŸ notlarÄ±)*

---

## Other Books You May Enjoy *(HoÅŸunuza Gidebilecek DiÄŸer Kitaplar)*

## Index *(Dizin)*
