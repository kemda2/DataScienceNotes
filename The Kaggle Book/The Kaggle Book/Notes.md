# Part I: Introduction to Competitions *(BÃ¶lÃ¼m I: YarÄ±ÅŸmalara GiriÅŸ)*

## Chapter 1: Introducing Kaggle and Other Data Science Competitions *(BÃ¶lÃ¼m 1: Kaggle ve DiÄŸer Veri Bilimi YarÄ±ÅŸmalarÄ±na GiriÅŸ)*

Veri bilimi yarÄ±ÅŸmalarÄ± uzun zamandÄ±r var ve zaman iÃ§inde giderek artan bir baÅŸarÄ± elde ettiler. Tutkulu bir yarÄ±ÅŸmacÄ± topluluÄŸundan doÄŸan bu yarÄ±ÅŸmalar, giderek daha fazla ilgi Ã§ekmeye ve milyonlarca veri bilimciden oluÅŸan Ã§ok daha geniÅŸ bir kitleye ulaÅŸmaya baÅŸladÄ±. En popÃ¼ler veri bilimi yarÄ±ÅŸma platformu olan **Kaggle**â€™da uzun yÄ±llardÄ±r yarÄ±ÅŸmacÄ± olarak yer aldÄ±ÄŸÄ±mÄ±z iÃ§in, bu deÄŸiÅŸimlerin tÃ¼mÃ¼ne yÄ±llar boyunca doÄŸrudan tanÄ±klÄ±k ettik ve bizzat deneyimledik.

BugÃ¼n, Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ± hakkÄ±nda bilgi ararsanÄ±z, Ã§ok sayÄ±da **buluÅŸma (meetup)**, **tartÄ±ÅŸma paneli**, **podcast**, **rÃ¶portaj** ve hatta bu tÃ¼r yarÄ±ÅŸmalarda nasÄ±l kazanÄ±lacaÄŸÄ±nÄ± anlatan **Ã§evrimiÃ§i kurslar** bulabilirsiniz. (Genellikle bu kurslar size azim, hesaplama kaynaklarÄ± ve harcanan zamanÄ±n doÄŸru karÄ±ÅŸÄ±mÄ±nÄ± kullanmanÄ±zÄ± tavsiye eder.) Ancak, ÅŸu anda okumakta olduÄŸunuz kitap dÄ±ÅŸÄ±nda, bu kadar Ã§ok veri bilimi yarÄ±ÅŸmasÄ±nÄ± nasÄ±l yÃ¶neteceÄŸinizi ve onlardan nasÄ±l en iyi ÅŸekilde yararlanabileceÄŸinizi â€” yalnÄ±zca puan veya sÄ±ralama aÃ§Ä±sÄ±ndan deÄŸil, **profesyonel deneyim** bakÄ±mÄ±ndan da â€” sistematik bir ÅŸekilde anlatan bir rehber bulmanÄ±z oldukÃ§a zordur.

Bu kitapta amacÄ±mÄ±z, Kaggle veya diÄŸer veri bilimi yarÄ±ÅŸmalarÄ±nda nasÄ±l yÃ¼ksek puan alacaÄŸÄ±nÄ±zÄ± anlatan birkaÃ§ ipucu vermek deÄŸil. Bunun yerine, **Kaggleâ€™da daha etkili yarÄ±ÅŸmanÄ±z** ve yarÄ±ÅŸma deneyimlerinizden â€” Ã¶zellikle de profesyonel hayatÄ±nÄ±z aÃ§Ä±sÄ±ndan â€” **en fazla faydayÄ± elde etmeniz** iÃ§in kapsamlÄ± bir rehber sunmak istiyoruz. Kitap iÃ§eriÄŸine, **Kaggle Master** ve **Grandmaster**â€™larla yapÄ±lan rÃ¶portajlar da eÅŸlik ediyor. Bu rÃ¶portajlarÄ±n size Kaggleâ€™da yarÄ±ÅŸmanÄ±n belirli yÃ¶nleri hakkÄ±nda farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve iÃ§gÃ¶rÃ¼ler sunacaÄŸÄ±nÄ± ve rekabetÃ§i veri bilimi yaparken kendinizi sÄ±nama ve Ã¶ÄŸrenme biÃ§iminize ilham vereceÄŸini umuyoruz.

Bu kitabÄ±n sonunda, **kendi deneyimlerimizden**, **yarÄ±ÅŸmalardan edindiÄŸimiz bilgilerden** ve **kaynaklardan** doÄŸrudan derlediÄŸimiz bilgileri iÃ§selleÅŸtirmiÅŸ olacaksÄ±nÄ±z. BÃ¶ylece yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã¶ÄŸrenmenizi ve geliÅŸmenizi saÄŸlayacak bir yol haritasÄ±na sahip olacaksÄ±nÄ±z.

BaÅŸlangÄ±Ã§ noktasÄ± olarak, bu bÃ¶lÃ¼mde ÅŸunlarÄ± inceleyeceÄŸiz:

* RekabetÃ§i programlamanÄ±n nasÄ±l veri bilimi yarÄ±ÅŸmalarÄ±na evrildiÄŸini,
* Neden Kaggle platformunun bu tÃ¼r yarÄ±ÅŸmalar iÃ§in en popÃ¼ler site olduÄŸunu,
* Ve bu platformun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±.

Bu bÃ¶lÃ¼mde aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

* Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi
* **Common Task Framework** (Ortak GÃ¶rev Ã‡erÃ§evesi) paradigmasÄ±
* Kaggle platformu ve bazÄ± alternatifleri
* Bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸi: aÅŸamalarÄ±, yarÄ±ÅŸma tÃ¼rleri, gÃ¶nderim ve liderlik tablosu dinamikleri, hesaplama kaynaklarÄ±, aÄŸ oluÅŸturma ve daha fazlasÄ±

### The rise of data science competition platforms *(Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi)*

RekabetÃ§i programlamanÄ±n kÃ¶klÃ¼ bir geÃ§miÅŸi vardÄ±r; 1970â€™lerde dÃ¼zenlenen ilk **ICPC (International Collegiate Programming Contest â€“ UluslararasÄ± ÃœniversitelerarasÄ± Programlama YarÄ±ÅŸmasÄ±)** ile baÅŸlamÄ±ÅŸtÄ±r. Ä°lk ICPCâ€™de, Ã¼niversitelerden ve ÅŸirketlerden gelen kÃ¼Ã§Ã¼k takÄ±mlar, bir dizi problemi bilgisayar programÄ± kullanarak Ã§Ã¶zmeleri gereken bir yarÄ±ÅŸmaya katÄ±lÄ±yordu (baÅŸlangÄ±Ã§ta katÄ±lÄ±mcÄ±lar **FORTRAN** dilinde kodlama yapÄ±yordu). Ä°yi bir final sÄ±ralamasÄ± elde etmek iÃ§in takÄ±mlarÄ±n gÃ¼Ã§lÃ¼ **takÄ±m Ã§alÄ±ÅŸmasÄ±**, **problem Ã§Ã¶zme** ve **programlama** becerileri sergilemeleri gerekiyordu.

Bu tÃ¼r bir yarÄ±ÅŸmanÄ±n yoÄŸun atmosferinde yer almak ve iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§ekme fÄ±rsatÄ±, Ã¶ÄŸrencilere bÃ¼yÃ¼k bir motivasyon saÄŸladÄ± ve yarÄ±ÅŸmanÄ±n yÄ±llar boyunca popÃ¼ler kalmasÄ±na neden oldu. ICPC finalistleri arasÄ±nda, gÃ¼nÃ¼mÃ¼zde oldukÃ§a tanÄ±nmÄ±ÅŸ isimler vardÄ±r: **Adam Dâ€™Angelo** (Facebookâ€™un eski CTOâ€™su ve Quoraâ€™nÄ±n kurucusu), **Nikolai Durov** (Telegram Messengerâ€™Ä±n kurucu ortaÄŸÄ±) ve **Matei Zaharia** (Apache Sparkâ€™Ä±n yaratÄ±cÄ±sÄ±). Bu isimlerin yanÄ± sÄ±ra birÃ§ok profesyonel aynÄ± ortak deneyimi paylaÅŸÄ±r: bir ICPC yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸlardÄ±r.

ICPCâ€™nin ardÄ±ndan, Ã¶zellikle 2000 yÄ±lÄ±ndan sonra uzaktan katÄ±lÄ±mÄ±n kolaylaÅŸmasÄ±yla programlama yarÄ±ÅŸmalarÄ± bÃ¼yÃ¼k bir geliÅŸme gÃ¶sterdi. Bu sayede uluslararasÄ± yarÄ±ÅŸmalarÄ±n dÃ¼zenlenmesi hem daha kolay hem de daha dÃ¼ÅŸÃ¼k maliyetli hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸunun formatÄ± benzerdir: bir dizi problem verilir ve katÄ±lÄ±mcÄ±larÄ±n bunlarÄ± Ã§Ã¶zmek iÃ§in kod yazmasÄ± gerekir. Kazananlar sadece Ã¶dÃ¼l kazanmakla kalmaz, aynÄ± zamanda iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§eker veya kendi alanlarÄ±nda tanÄ±nÄ±r hale gelirler.

RekabetÃ§i programlamadaki problemler genellikle **kombinatorik**, **sayÄ± teorisi**, **graf teorisi**, **algoritmik oyun teorisi**, **hesaplamalÄ± geometri**, **dizgi analizi** ve **veri yapÄ±larÄ±** gibi konulardan oluÅŸur. Son yÄ±llarda ise **yapay zekÃ¢** ile ilgili problemler de bu yarÄ±ÅŸmalarda yer almaya baÅŸlamÄ±ÅŸtÄ±r. Ã–zellikle **KDD Cup**â€™Ä±n (Knowledge Discovery and Data Mining Cup â€“ Bilgi KeÅŸfi ve Veri MadenciliÄŸi YarÄ±ÅŸmasÄ±) baÅŸlatÄ±lmasÄ±ndan sonra bu tÃ¼r problemler oldukÃ§a popÃ¼ler hale gelmiÅŸtir. Bu yarÄ±ÅŸma, her yÄ±l **Association for Computing Machinery (ACM)** tarafÄ±ndan dÃ¼zenlenen konferans kapsamÄ±nda **Ã–zel Ä°lgi Grubu (SIG)** tarafÄ±ndan yÃ¼rÃ¼tÃ¼lmektedir. (Kaynak: [https://kdd.org/conferences](https://kdd.org/conferences))

Ä°lk **KDD Cup**, 1997 yÄ±lÄ±nda dÃ¼zenlenmiÅŸ ve **doÄŸrudan pazarlamada lift eÄŸrisi optimizasyonu** konusundaki bir problemi iÃ§ermiÅŸtir. Bu yarÄ±ÅŸma, gÃ¼nÃ¼mÃ¼zde hÃ¢lÃ¢ devam eden uzun bir yarÄ±ÅŸma serisinin baÅŸlangÄ±cÄ±nÄ± oluÅŸturmuÅŸtur. Veri kÃ¼meleri, yÃ¶nergeler ve kazananlar dÃ¢hil olmak Ã¼zere tÃ¼m arÅŸivlere ÅŸu adresten ulaÅŸabilirsiniz: [https://www.kdd.org/kdd-cup](https://www.kdd.org/kdd-cup). YazÄ±m sÄ±rasÄ±nda en son mevcut olan yarÄ±ÅŸma ise [https://ogb.stanford.edu/kddcup2021/](https://ogb.stanford.edu/kddcup2021/).
KDD Cup yarÄ±ÅŸmalarÄ±, en iyi uygulamalarÄ± belirlemede oldukÃ§a etkili olmuÅŸtur. BirÃ§ok makalede yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri, teknikler ve veri kÃ¼meleri paylaÅŸÄ±lmÄ±ÅŸ, bu da araÅŸtÄ±rmacÄ±lar ve uygulayÄ±cÄ±lar iÃ§in **deney**, **eÄŸitim** ve **karÅŸÄ±laÅŸtÄ±rma (benchmarking)** aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k fayda saÄŸlamÄ±ÅŸtÄ±r.

Hem rekabetÃ§i programlama etkinliklerinin hem de KDD Cupâ€™Ä±n baÅŸarÄ±sÄ±, ÅŸirketleri (Ã¶rneÄŸin **Netflix**) ve giriÅŸimcileri (Ã¶rneÄŸin Kaggleâ€™Ä±n kurucusu **Anthony Goldbloom**) **veri bilimi yarÄ±ÅŸma platformlarÄ±** kurmaya teÅŸvik etti. Bu platformlar, ÅŸirketlerin Ã§Ã¶zÃ¼lmesi zor veri bilimi problemlerini kitle kaynaklÄ± Ã§Ã¶zÃ¼mlerle Ã§Ã¶zebilmesine olanak tanÄ±dÄ±. GerÃ§ekten de veri bilimi alanÄ±nda her problem iÃ§in iÅŸe yarayan tek bir â€œaltÄ±nâ€ yÃ¶ntem yoktur; Ã§oÄŸu zaman, **â€œdeneyebileceÄŸin her ÅŸeyi deneâ€** yaklaÅŸÄ±mÄ± gerekir.

AslÄ±nda, uzun vadede hiÃ§bir algoritma tÃ¼m problemler iÃ§in diÄŸerlerini alt edemez. Bu durum, **David Wolpert** ve **William Macready** tarafÄ±ndan ortaya konan **No Free Lunch Teoremi (Bedava Ã–ÄŸle YemeÄŸi Yok Teoremi)** ile aÃ§Ä±klanÄ±r. Bu teoreme gÃ¶re, her makine Ã¶ÄŸrenimi algoritmasÄ± yalnÄ±zca Ã§Ã¶zÃ¼mÃ¼ iÃ§eren bir hipotez uzayÄ±na sahipse baÅŸarÄ±lÄ± olur. DolayÄ±sÄ±yla, bir algoritmanÄ±n belirli bir problemi en iyi ÅŸekilde Ã§Ã¶zebileceÄŸini Ã¶nceden bilemezsiniz; bunu Ã¶ÄŸrenmenin tek yolu, algoritmayÄ± doÄŸrudan o problem Ã¼zerinde test etmektir.
Makine Ã¶ÄŸreniminde herhangi bir â€œkutsal kÃ¢seâ€ veya teorik kestirme yoktur â€” yalnÄ±zca **ampirik deneyler** size neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶sterebilir.

Bu konuda daha fazla bilgi edinmek iÃ§in **No Free Lunch Teoremi** Ã¼zerine kuramsal aÃ§Ä±klamalarÄ± inceleyebilirsiniz. AÅŸaÄŸÄ±da bu konuyu detaylÄ± anlatan bir makaleye baÄŸlantÄ± verilmiÅŸtir:
ğŸ‘‰ [Analytics India Magazine â€“ What are the No Free Lunch Theorems in Data Science?](https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/)

Bu tÃ¼r durumlarda **crowdsourcing (kitle kaynak kullanÄ±mÄ±)** mÃ¼kemmel bir yÃ¶ntemdir; Ã§Ã¼nkÃ¼ algoritmalarÄ± ve veri dÃ¶nÃ¼ÅŸÃ¼mlerini kapsamlÄ± bir ÅŸekilde test etmeniz gerekir, ancak bunu yapacak insan gÃ¼cÃ¼ ve iÅŸlem gÃ¼cÃ¼nÃ¼z yoktur. Bu nedenle, hÃ¼kÃ¼metler ve ÅŸirketler belirli alanlarda ilerleme kaydetmek iÃ§in yarÄ±ÅŸmalara baÅŸvurur:

* **Kamu tarafÄ±nda:** ABDâ€™nin **DARPA** kuruluÅŸu tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalarda; **otonom araÃ§lar**, **robotik operasyonlar**, **makine Ã§evirisi**, **konuÅŸmacÄ± tanÄ±ma**, **parmak izi tanÄ±ma**, **bilgi eriÅŸimi**, **OCR (Optik Karakter TanÄ±ma)**, **otomatik hedef tanÄ±ma** gibi birÃ§ok alanda yarÄ±ÅŸmalar dÃ¼zenlenmiÅŸtir.
* **Åirket tarafÄ±nda:** Ã–rneÄŸin **Netflix**, kullanÄ±cÄ±larÄ±n film tercihlerinin tahmin edilmesini iyileÅŸtirmek amacÄ±yla dÃ¼zenlenen bir yarÄ±ÅŸmanÄ±n sonucuna gÃ¶re algoritmasÄ±nÄ± geliÅŸtirmiÅŸtir.

**Netflix YarÄ±ÅŸmasÄ± (Netflix Prize)**, mevcut **Ã¶neri sistemini** (collaborative filtering) geliÅŸtirmeyi amaÃ§lÄ±yordu. YarÄ±ÅŸmanÄ±n hedefi, bir kullanÄ±cÄ±nÄ±n bir filme vereceÄŸi puanÄ±, yalnÄ±zca daha Ã¶nce puanladÄ±ÄŸÄ± filmlerden yola Ã§Ä±karak tahmin etmekti â€” yani kullanÄ±cÄ± kimliÄŸi veya film aÃ§Ä±klamalarÄ± hakkÄ±nda hiÃ§bir bilgi yoktu (bunlarÄ±n tÃ¼mÃ¼ kimlik kodlarÄ±yla deÄŸiÅŸtirilmiÅŸti). KatÄ±lÄ±mcÄ±lardan, mevcut puan geÃ§miÅŸini akÄ±llÄ±ca kullanarak tahmin yapan modeller geliÅŸtirmeleri istendi.
**1.000.000 ABD DolarÄ±** tutarÄ±ndaki bÃ¼yÃ¼k Ã¶dÃ¼l, yalnÄ±zca geliÅŸtirilen modelin Netflixâ€™in mevcut algoritmasÄ± **Cinematch**â€™i belirli bir eÅŸiÄŸin Ã¼zerinde iyileÅŸtirmesi durumunda verilecekti.

YarÄ±ÅŸma 2006â€™dan 2009â€™a kadar sÃ¼rdÃ¼ ve kazanan takÄ±m, Ã¶nceki yarÄ±ÅŸmalardan birÃ§ok takÄ±mÄ±n birleÅŸmesiyle oluÅŸtu: **Commendo Research & Consulting GmbH**â€™den **Andreas TÃ¶scher** ve **Michael Jahrer** (aynÄ± zamanda Kaggleâ€™da da tanÄ±nan yarÄ±ÅŸmacÄ±lar), **AT&T Labs**â€™tan iki araÅŸtÄ±rmacÄ± ve **Yahoo!**â€™dan iki araÅŸtÄ±rmacÄ±.
YarÄ±ÅŸmayÄ± kazanmak, o kadar bÃ¼yÃ¼k bir hesaplama gÃ¼cÃ¼ ve farklÄ± Ã§Ã¶zÃ¼mlerin birleÅŸtirilmesini (ensemble) gerektirdi ki, takÄ±mlar rekabeti sÃ¼rdÃ¼rebilmek iÃ§in birleÅŸmek zorunda kaldÄ±lar. SonuÃ§ta, **Netflix** bu Ã§Ã¶zÃ¼mÃ¼ doÄŸrudan uygulamak yerine, yarÄ±ÅŸmadan elde edilen en deÄŸerli iÃ§gÃ¶rÃ¼leri alÄ±p mevcut **Cinematch algoritmasÄ±nÄ±** geliÅŸtirmede kullandÄ±.
Bu konuda daha fazla bilgi iÃ§in ÅŸu **Wired** makalesini okuyabilirsiniz:
ğŸ‘‰ [https://www.wired.com/2012/04/netflix-prize-costs/](https://www.wired.com/2012/04/netflix-prize-costs/)

Netflix yarÄ±ÅŸmasÄ±nÄ±n sonunda Ã¶nemli olan ÅŸey, Ã§Ã¶zÃ¼mÃ¼n kendisi deÄŸil, **Netflixâ€™in iÅŸ modelinin DVD kiralamadan Ã§evrimiÃ§i yayÄ±n platformuna geÃ§mesiyle** birlikte elde edilen **bilgi ve deneyimdi**. YarÄ±ÅŸmadan hem katÄ±lÄ±mcÄ±lar (Ã¶neri sistemleri alanÄ±nda bÃ¼yÃ¼k bir Ã¼n kazandÄ±lar) hem de Netflix (geliÅŸtirilmiÅŸ Ã¶neri sistemi bilgisini yeni iÅŸ modeline aktardÄ±) bÃ¼yÃ¼k fayda saÄŸladÄ±.

### The Kaggle competition platform *(Kaggle yarÄ±ÅŸma platformu)*

**Netflix dÄ±ÅŸÄ±ndaki birÃ§ok ÅŸirket de veri bilimi yarÄ±ÅŸmalarÄ±ndan fayda saÄŸlamÄ±ÅŸtÄ±r.** Liste oldukÃ§a uzundur, ancak yarÄ±ÅŸmayÄ± dÃ¼zenleyen ÅŸirketlerin aÃ§Ä±k bir ÅŸekilde fayda elde ettiÄŸini bildirdiÄŸi birkaÃ§ Ã¶rneÄŸi verebiliriz. Ã–rneÄŸin:

* **Allstate** adlÄ± sigorta ÅŸirketi, yÃ¼zlerce veri bilimcinin katÄ±ldÄ±ÄŸÄ± bir yarÄ±ÅŸma sayesinde ([https://www.kaggle.com/c/ClaimPredictionChallenge](https://www.kaggle.com/c/ClaimPredictionChallenge)), kendi uzmanlarÄ± tarafÄ±ndan geliÅŸtirilen aktÃ¼eryal modellerini Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirebilmiÅŸtir.
* BaÅŸka iyi belgelenmiÅŸ bir Ã¶rnek olarak, **General Electric**, havayolu uÃ§uÅŸlarÄ±nÄ±n varÄ±ÅŸ zamanlarÄ±nÄ± tahmin etmede kullanÄ±lan sektÃ¶r standardÄ± performans Ã¶lÃ§Ã¼tÃ¼ne gÃ¶re (kÃ¶k ortalama kare hatasÄ± â€“ *root mean squared error* metriÄŸiyle Ã¶lÃ§Ã¼lÃ¼r) %40â€™lÄ±k bir geliÅŸme saÄŸlamÄ±ÅŸtÄ±r. Bu baÅŸarÄ±, benzer bir yarÄ±ÅŸma sayesinde elde edilmiÅŸtir ([https://www.kaggle.com/c/flight](https://www.kaggle.com/c/flight)).

**Kaggle yarÄ±ÅŸma platformu** bugÃ¼ne kadar yÃ¼zlerce yarÄ±ÅŸma dÃ¼zenlemiÅŸtir ve bu iki Ã¶rnek, platformu baÅŸarÄ±yla kullanan ÅŸirketlerden yalnÄ±zca birkaÃ§Ä±dÄ±r.
Åimdi, belirli yarÄ±ÅŸmalarÄ±n Ã¶tesine geÃ§ip bu kitabÄ±n da merkezinde yer alan **Kaggle ÅŸirketi** hakkÄ±nda konuÅŸalÄ±m.

### A history of Kaggle *(Kaggleâ€™Ä±n tarihÃ§esi)*

**Kaggle**, ilk adÄ±mlarÄ±nÄ± **Åubat 2010â€™da**, ekonomist ve ekonometrikÃ§i olarak eÄŸitim almÄ±ÅŸ AvustralyalÄ± **Anthony Goldbloom** sayesinde attÄ±. Goldbloom, Avustralya Hazine BakanlÄ±ÄŸÄ±â€™nda (*Department of the Treasury*) ve Avustralya Merkez BankasÄ±â€™nÄ±n (*Reserve Bank of Australia*) AraÅŸtÄ±rma DepartmanÄ±â€™nda Ã§alÄ±ÅŸtÄ±ktan sonra, Londraâ€™da haftalÄ±k uluslararasÄ± dergi **The Economist**â€™te staj yaptÄ±.

The Economistâ€™te Ã§alÄ±ÅŸtÄ±ÄŸÄ± dÃ¶nemde â€œ**bÃ¼yÃ¼k veri (big data)**â€ Ã¼zerine bir makale yazma fÄ±rsatÄ± buldu. Bu makale, onun aklÄ±na **ilginÃ§ makine Ã¶ÄŸrenimi problemlerini Ã§Ã¶zmek iÃ§in en iyi analitik uzmanlarÄ± kitlesel katÄ±lÄ±mla (crowdsourcing) bir araya getirecek bir yarÄ±ÅŸma platformu kurma fikrini** getirdi ([kaynak](https://www.smh.com.au/technology/from-bondi-to-the-big-bucks-the-28yearold-whos-making-datascience-a-sport-20111104-1myq1.html)).

Bu platformun iÅŸ fikrinde â€œcrowdsourcingâ€ dinamiklerinin Ã¶nemli bir rol oynamasÄ±ndan dolayÄ±, Goldbloom platformun adÄ±nÄ± **Kaggle** koydu. Bu isim, Ä°ngilizce â€œ**gaggle**â€ (kaz sÃ¼rÃ¼sÃ¼) kelimesine bir gÃ¶nderme yapÄ±yor; kaz figÃ¼rÃ¼ de zaten Kaggle platformunun sembolÃ¼dÃ¼r.

Goldbloom, daha sonra **ABDâ€™nin Silikon Vadisiâ€™ne taÅŸÄ±ndÄ±** ve Kaggle giriÅŸimi, iki tanÄ±nmÄ±ÅŸ risk sermayesi ÅŸirketi olan **Khosla Ventures** ve **Index Ventures** tarafÄ±ndan yÃ¶netilen bir yatÄ±rÄ±m turunda **11,25 milyon dolar** tutarÄ±nda **A Serisi yatÄ±rÄ±m** aldÄ±. Ä°lk yarÄ±ÅŸmalar baÅŸlatÄ±ldÄ±, topluluk hÄ±zla bÃ¼yÃ¼dÃ¼ ve bazÄ± erken dÃ¶nem yarÄ±ÅŸmacÄ±lar dikkat Ã§ekici baÅŸarÄ±lara ulaÅŸtÄ±. Bunlardan biri olan **Jeremy Howard**, AvustralyalÄ± bir veri bilimci ve giriÅŸimciydi. Kaggleâ€™da birkaÃ§ yarÄ±ÅŸma kazandÄ±ktan sonra ÅŸirketin **BaÅŸkanÄ± (President)** ve **BaÅŸ Bilimcisi (Chief Scientist)** oldu.

Jeremy Howard, **AralÄ±k 2013â€™te** gÃ¶revinden ayrÄ±ldÄ± ve daha sonra **fast.ai** ([www.fast.ai](http://www.fast.ai)) adlÄ± yeni bir giriÅŸim kurdu. Bu giriÅŸim, **makine Ã¶ÄŸrenimi kurslarÄ±** ve **geliÅŸtiriciler iÃ§in derin Ã¶ÄŸrenme (deep learning) kÃ¼tÃ¼phanesi** sunmaktadÄ±r.

O dÃ¶nemde Ã¶ne Ã§Ä±kan diÄŸer bazÄ± **Kaggle yarÄ±ÅŸmacÄ±larÄ± (Kagglers)** arasÄ±nda **Jeremy Achin** ve **Thomas de Godoy** da bulunuyordu. Platformda **ilk 20 kÃ¼resel sÄ±ralama** arasÄ±na girdikten sonra emekli olmaya karar verdiler ve **DataRobot** adlÄ± kendi ÅŸirketlerini kurdular. KÄ±sa sÃ¼re sonra, geliÅŸtirdikleri yazÄ±lÄ±ma en iyi makine Ã¶ÄŸrenimi bilgilerini ve uygulamalarÄ±nÄ± kazandÄ±rmak amacÄ±yla **Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmuÅŸ katÄ±lÄ±mcÄ±larÄ± iÅŸe almaya** baÅŸladÄ±lar. BugÃ¼n **DataRobot**, **AutoML (otomatik makine Ã¶ÄŸrenimi)** Ã§Ã¶zÃ¼mleri geliÅŸtiren Ã¶nde gelen ÅŸirketlerden biridir.

Kaggle yarÄ±ÅŸmalarÄ±, giderek artan bir ilgiyle bÃ¼yÃ¼meye devam etti. **Derin Ã¶ÄŸrenmenin â€œbabasÄ±â€ Geoffrey Hinton**, 2012â€™de **Merck** tarafÄ±ndan dÃ¼zenlenen bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ± ve kazandÄ± ([kaynak](https://www.kaggle.com/c/MerckActivity/overview/winners)).

AyrÄ±ca Kaggle, **FranÃ§ois Chollet**â€™nin derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi **Keras**â€™Ä± tanÄ±ttÄ±ÄŸÄ± **Otto Group Product Classification Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13632)) yarÄ±ÅŸmasÄ±nÄ±n ve **Tianqi Chen**â€™in **XGBoost** adlÄ± daha hÄ±zlÄ± ve daha doÄŸru bir **gradient boosting** algoritmasÄ±nÄ± tanÄ±ttÄ±ÄŸÄ± **Higgs Boson Machine Learning Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/higgs-boson/discussion/10335)) yarÄ±ÅŸmasÄ±nÄ±n da dÃ¼zenlendiÄŸi platformdur.

FranÃ§ois Chollet ayrÄ±ca **Quora** sitesinde â€œKaggle yarÄ±ÅŸmalarÄ±nda neden Keras bu kadar baÅŸarÄ±lÄ± oldu?â€ sorusuna verdiÄŸi cevapta, Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmanÄ±n Ã¶zÃ¼nÃ¼ mÃ¼kemmel bir ÅŸekilde aÃ§Ä±klamÄ±ÅŸtÄ±r ([kaynak](https://www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions)).
Ona gÃ¶re, **Ã§ok sayÄ±da denemeyi hÄ±zlÄ± ÅŸekilde yapmak ve teoriden ziyade ampirik kanÄ±tlarla yÃ¶nlenmek**, Kaggleâ€™da baÅŸarÄ±lÄ± olmanÄ±n temelidir. Biz de onun belirttiÄŸi noktalarÄ±n dÄ±ÅŸÄ±nda baÅŸka bir â€œgizli sÄ±râ€ olduÄŸuna inanmÄ±yoruz.

FranÃ§ois Chollet ayrÄ±ca Kaggleâ€™da kendi yarÄ±ÅŸmasÄ±nÄ± da dÃ¼zenlemiÅŸtir ([Abstraction and Reasoning Challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge/)) â€” bu yarÄ±ÅŸma, **dÃ¼nyanÄ±n ilk genel yapay zekÃ¢ (general AI) yarÄ±ÅŸmasÄ±** olarak kabul edilir.

YarÄ±ÅŸma Ã¼stÃ¼ne yarÄ±ÅŸma geldikÃ§e, Kaggle etrafÄ±ndaki topluluk bÃ¼yÃ¼meye devam etti ve **2017 yÄ±lÄ±nda 1 milyon kullanÄ±cÄ±ya** ulaÅŸtÄ±. AynÄ± yÄ±l, **Google BaÅŸ Bilimcisi Fei-Fei Li**, **Google Next** etkinliÄŸinde yaptÄ±ÄŸÄ± aÃ§Ä±lÄ±ÅŸ konuÅŸmasÄ±nda **Googleâ€™Ä±n Kaggleâ€™Ä± satÄ±n alacaÄŸÄ±nÄ±** duyurdu.
O tarihten bu yana **Kaggle, Google Ã§atÄ±sÄ± altÄ±nda** faaliyet gÃ¶stermektedir.

BugÃ¼n, **Kaggle topluluÄŸu hÃ¢lÃ¢ aktif ve bÃ¼yÃ¼meye devam ediyor.**
Anthony Goldbloomâ€™un bir tweetâ€™inde ([kaynak](https://twitter.com/antgoldbloom/status/1400119591246852096)) belirttiÄŸi Ã¼zere, kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k bir kÄ±smÄ± sadece yarÄ±ÅŸmalara katÄ±lmakla kalmÄ±yor; aynÄ± zamanda **Kaggleâ€™Ä±n herkese aÃ§Ä±k veri setlerini indiriyor** (Kaggle artÄ±k Ã¶nemli bir **veri merkezi** haline gelmiÅŸtir), **Python veya R ile herkese aÃ§Ä±k Notebooks oluÅŸturuyor** ya da **platformun sunduÄŸu kurslardan yeni bir ÅŸeyler Ã¶ÄŸreniyor.**

![](./im/1001.png)

YÄ±llar boyunca Kaggle, katÄ±lÄ±mcÄ±larÄ±na aÅŸaÄŸÄ±daki gibi **daha pek Ã§ok fÄ±rsat** sunmuÅŸtur:

* **Kendi ÅŸirketlerini kurmak**
* **Makine Ã¶ÄŸrenimi yazÄ±lÄ±mlarÄ± ve paketleri baÅŸlatmak**
* **Dergilerde rÃ¶portajlar yapmak** ([kaynak](https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/))
* **Makine Ã¶ÄŸrenimi kitaplarÄ± yazmak** ([kaynak](https://twitter.com/antgoldbloom/status/745662719588589568))
* **Hayallerindeki iÅŸi bulmak**

Ve en Ã¶nemlisi, **veri bilimi ile ilgili beceriler ve teknik detaylar hakkÄ±nda daha fazla bilgi edinmek**.

### Other competition platforms *(DiÄŸer yarÄ±ÅŸma platformlarÄ±)*

### Introducing Kaggle *(Kaggleâ€™a giriÅŸ)*

### Stages of a competition *(Bir yarÄ±ÅŸmanÄ±n aÅŸamalarÄ±)*

### Types of competitions and examples *(YarÄ±ÅŸma tÃ¼rleri ve Ã¶rnekleri)*

### Submission and leaderboard dynamics *(GÃ¶nderim ve liderlik tablosu dinamikleri)*

### Explaining the Common Task Framework paradigm *(Ortak GÃ¶rev Ã‡erÃ§evesi paradigmasÄ±nÄ±n aÃ§Ä±klanmasÄ±)*

### Understanding what can go wrong in a competition *(Bir yarÄ±ÅŸmada nelerin ters gidebileceÄŸini anlamak)*

### Computational resources *(Hesaplama kaynaklarÄ±)*

### Kaggle Notebooks *(Kaggle Defterleri)*

### Teaming and networking *(TakÄ±m kurma ve aÄŸ oluÅŸturma)*

### Performance tiers and rankings *(Performans seviyeleri ve sÄ±ralamalar)*

### Criticism and opportunities *(EleÅŸtiriler ve fÄ±rsatlar)*

### Summary *(Ã–zet)*

---

## Chapter 2: Organizing Data with Datasets *(BÃ¶lÃ¼m 2: Veri Setleriyle Veriyi DÃ¼zenleme)*

### Setting up a dataset *(Bir veri seti oluÅŸturma)*

### Gathering the data *(Veri toplama)*

### Working with datasets *(Veri setleriyle Ã§alÄ±ÅŸma)*

### Using Kaggle Datasets in Google Colab *(Google Colabâ€™da Kaggle veri setlerini kullanma)*

### Legal caveats *(Yasal uyarÄ±lar)*

### Summary *(Ã–zet)*

---

## Chapter 3: Working and Learning with Kaggle Notebooks *(BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek)*

### Setting up a Notebook *(Bir defter oluÅŸturma)*

### Running your Notebook *(Defterinizi Ã§alÄ±ÅŸtÄ±rma)*

### Saving Notebooks to GitHub *(Defterleri GitHubâ€™a kaydetme)*

### Getting the most out of Notebooks *(Defterlerden en iyi ÅŸekilde yararlanma)*

### Upgrading to Google Cloud Platform (GCP) *(Google Cloud Platformâ€™a (GCP) yÃ¼kseltme)*

### One step beyond *(Bir adÄ±m Ã¶teye geÃ§mek)*

### Kaggle Learn courses *(Kaggle Learn kurslarÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 4: Leveraging Discussion Forums *(BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±nÄ± Etkin Kullanma)*

### How forums work *(Forumlar nasÄ±l Ã§alÄ±ÅŸÄ±r)*

### Example discussion approaches *(TartÄ±ÅŸma Ã¶rnekleri ve yaklaÅŸÄ±mlar)*

### Netiquette *(Ä°nternet gÃ¶rgÃ¼ kurallarÄ±)*

### Summary *(Ã–zet)*

---

# Part II: Sharpening Your Skills for Competitions *(BÃ¶lÃ¼m II: YarÄ±ÅŸmalar Ä°Ã§in Becerilerini GeliÅŸtirme)*

## Chapter 5: Competition Tasks and Metrics *(BÃ¶lÃ¼m 5: YarÄ±ÅŸma GÃ¶revleri ve Ã–lÃ§Ã¼tleri)*

### Evaluation metrics and objective functions *(DeÄŸerlendirme metrikleri ve hedef fonksiyonlar)*

### Basic types of tasks *(Temel gÃ¶rev tÃ¼rleri)*

#### Regression *(Regresyon)*

#### Classification *(SÄ±nÄ±flandÄ±rma)*

#### Ordinal *(SÄ±ralÄ± veriler)*

### The Meta Kaggle dataset *(Meta Kaggle veri seti)*

### Handling never-before-seen metrics *(Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerle baÅŸa Ã§Ä±kma)*

### Metrics for regression (standard and ordinal) *(Regresyon iÃ§in metrikler - standart ve sÄ±ralÄ±)*

#### Mean squared error (MSE) and RÂ² *(Ortalama kare hata (MSE) ve RÂ²)*

#### Root mean squared error (RMSE) *(KÃ¶k ortalama kare hata (RMSE))*

#### Root mean squared log error (RMSLE) *(KÃ¶k ortalama log kare hata (RMSLE))*

#### Mean absolute error (MAE) *(Ortalama mutlak hata (MAE))*

### Metrics for classification (label prediction and probability) *(SÄ±nÄ±flandÄ±rma metrikleri - etiket tahmini ve olasÄ±lÄ±k)*

#### Accuracy *(DoÄŸruluk)*

#### Precision and recall *(Kesinlik ve duyarlÄ±lÄ±k)*

#### The F1 score *(F1 skoru)*

#### Log loss and ROC-AUC *(Log kaybÄ± ve ROC-AUC)*

#### Matthews correlation coefficient (MCC) *(Matthews korelasyon katsayÄ±sÄ±)*

### Metrics for multi-class classification *(Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri)*

### Metrics for object detection problems *(Nesne tespiti problemleri iÃ§in metrikler)*

#### Intersection over union (IoU) *(KesiÅŸim/BirleÅŸim oranÄ±)*

#### Dice *(Dice katsayÄ±sÄ±)*

### Metrics for multi-label classification and recommendation problems *(Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri problemleri iÃ§in metrikler)*

#### MAP@K *(MAP@K metriÄŸi)*

### Optimizing evaluation metrics *(DeÄŸerlendirme metriklerini optimize etme)*

### Custom metrics and custom objective functions *(Ã–zel metrikler ve Ã¶zel hedef fonksiyonlarÄ±)*

### Post-processing your predictions *(Tahminleri sonradan iÅŸleme)*

### Predicted probability and its adjustment *(Tahmin edilen olasÄ±lÄ±ÄŸÄ±n ayarlanmasÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 6: Designing Good Validation *(BÃ¶lÃ¼m 6: Ä°yi Bir DoÄŸrulama Sistemi Tasarlama)*

### Snooping on the leaderboard *(Liderlik tablosunu gÃ¶zetlemek)*

### The importance of validation in competitions *(YarÄ±ÅŸmalarda doÄŸrulamanÄ±n Ã¶nemi)*

### Bias and variance *(Ã–nyargÄ± ve varyans)*

### Trying different splitting strategies *(FarklÄ± veri bÃ¶lme stratejilerini denemek)*

#### The basic train-test split *(Temel eÄŸitim-test bÃ¶lÃ¼nmesi)*

#### Probabilistic evaluation methods *(OlasÄ±lÄ±ksal deÄŸerlendirme yÃ¶ntemleri)*

#### k-fold cross-validation *(k-katlÄ± Ã§apraz doÄŸrulama)*

#### Subsampling *(Alt Ã¶rnekleme)*

#### The bootstrap *(Bootstrap yÃ¶ntemi)*

### Tuning your model validation system *(Model doÄŸrulama sistemini ayarlamak)*

### Using adversarial validation *(ZÄ±t doÄŸrulama yÃ¶ntemini kullanmak)*

#### Example implementation *(Uygulama Ã¶rneÄŸi)*

### Handling different distributions of training and test data *(EÄŸitim ve test verilerindeki farklÄ± daÄŸÄ±lÄ±mlarla baÅŸa Ã§Ä±kma)*

### Handling leakage *(Veri sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nleme)*

### Summary *(Ã–zet)*

---

## Chapter 7: Modeling for Tabular Competitions *(BÃ¶lÃ¼m 7: Tablo Verisi YarÄ±ÅŸmalarÄ± Ä°Ã§in Modellemede YaklaÅŸÄ±mlar)*

### The Tabular Playground Series *(Tabular Playground Serisi)*

### Setting a random state for reproducibility *(Tekrarlanabilirlik iÃ§in rastgele durum belirleme)*

### The importance of EDA *(KeÅŸifsel veri analizinin Ã¶nemi)*

### Dimensionality reduction with t-SNE and UMAP *(t-SNE ve UMAP ile boyut indirgeme)*

### Reducing the size of your data *(Veri boyutunu kÃ¼Ã§Ã¼ltme)*

### Applying feature engineering *(Ã–zellik mÃ¼hendisliÄŸi uygulama)*

#### Easily derived features *(Kolay tÃ¼retilen Ã¶zellikler)*

#### Meta-features based on rows and columns *(SatÄ±r ve sÃ¼tunlara dayalÄ± meta-Ã¶zellikler)*

#### Target encoding *(Hedef kodlama)*

### Using feature importance to evaluate your work *(Ã–zellik Ã¶nemini kullanarak Ã§alÄ±ÅŸmanÄ± deÄŸerlendirme)*

### Pseudo-labeling *(Sahte etiketleme)*

### Denoising with autoencoders *(Otoenkoderlerle gÃ¼rÃ¼ltÃ¼ giderme)*

### Neural networks for tabular competitions *(Tablo verisi yarÄ±ÅŸmalarÄ± iÃ§in sinir aÄŸlarÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 8: Hyperparameter Optimization *(BÃ¶lÃ¼m 8: Hiperparametre Optimizasyonu)*

### Basic optimization techniques *(Temel optimizasyon teknikleri)*

#### Grid search *(Izgara aramasÄ±)*

#### Random search *(Rastgele arama)*

#### Halving search *(YarÄ±ya indirme aramasÄ±)*

### Key parameters and how to use them *(Temel parametreler ve nasÄ±l kullanÄ±lacaklarÄ±)*

#### Linear models *(DoÄŸrusal modeller)*

#### Support-vector machines *(Destek vektÃ¶r makineleri)*

#### Random forests and extremely randomized trees *(Rastgele ormanlar ve aÅŸÄ±rÄ± rastgele aÄŸaÃ§lar)*

#### Gradient tree boosting *(Gradyan aÄŸaÃ§ gÃ¼Ã§lendirmesi)*

#### LightGBM *(LightGBM algoritmasÄ±)*

#### XGBoost *(XGBoost algoritmasÄ±)*

#### CatBoost *(CatBoost algoritmasÄ±)*

#### HistGradientBoosting *(Histogram tabanlÄ± gradyan gÃ¼Ã§lendirme)*

### Bayesian optimization *(Bayesyen optimizasyon)*

#### Using Scikit-optimize *(Scikit-optimize kullanÄ±mÄ±)*

#### Customizing a Bayesian optimization search *(Bayesyen aramayÄ± Ã¶zelleÅŸtirme)*

#### Extending Bayesian optimization to neural architecture search *(Bayesyen optimizasyonu sinir aÄŸÄ± mimarisi aramasÄ±na geniÅŸletme)*

#### Creating lighter and faster models with KerasTuner *(KerasTuner ile daha hafif ve hÄ±zlÄ± modeller oluÅŸturma)*

#### The TPE approach in Optuna *(Optunaâ€™daki TPE yaklaÅŸÄ±mÄ±)*

### Summary *(Ã–zet)*

---

## Chapter 9: Ensembling with Blending and Stacking Solutions *(BÃ¶lÃ¼m 9: KarÄ±ÅŸtÄ±rma ve YÄ±ÄŸÄ±nlama (Ensemble) Ã‡Ã¶zÃ¼mleri)*

### A brief introduction to ensemble algorithms *(Topluluk (ensemble) algoritmalarÄ±na kÄ±sa bir giriÅŸ)*

### Averaging models into an ensemble *(Modelleri ortalama alarak birleÅŸtirme)*

#### Majority voting *(Ã‡oÄŸunluk oylamasÄ±)*

#### Averaging of model predictions *(Model tahminlerinin ortalamasÄ±)*

#### Weighted averages *(AÄŸÄ±rlÄ±klÄ± ortalamalar)*

#### Averaging in your cross-validation strategy *(Ã‡apraz doÄŸrulama stratejinde ortalama alma)*

#### Correcting averaging for ROC-AUC evaluations *(ROC-AUC deÄŸerlendirmeleri iÃ§in ortalamayÄ± dÃ¼zeltme)*

### Blending models using a meta-model *(Meta-model kullanarak modelleri karÄ±ÅŸtÄ±rma)*

#### Best practices for blending *(KarÄ±ÅŸtÄ±rma iÃ§in en iyi uygulamalar)*

### Stacking models together *(Modelleri yÄ±ÄŸÄ±nlama)*

#### Stacking variations *(YÄ±ÄŸÄ±nlama varyasyonlarÄ±)*

### Creating complex stacking and blending solutions *(KarmaÅŸÄ±k karÄ±ÅŸtÄ±rma ve yÄ±ÄŸÄ±nlama Ã§Ã¶zÃ¼mleri oluÅŸturma)*

### Summary *(Ã–zet)*

---

## Chapter 10: Modeling for Computer Vision *(BÃ¶lÃ¼m 10: BilgisayarlÄ± GÃ¶rÃ¼ (Computer Vision) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Augmentation strategies *(Veri artÄ±rma stratejileri)*

#### Keras built-in augmentations *(Kerasâ€™Ä±n yerleÅŸik artÄ±rmalarÄ±)*

#### ImageDataGenerator approach *(ImageDataGenerator yaklaÅŸÄ±mÄ±)*

#### Preprocessing layers *(Ã–n iÅŸleme katmanlarÄ±)*

#### albumentations *(Albumentations kÃ¼tÃ¼phanesi)*

### Classification *(SÄ±nÄ±flandÄ±rma)*

### Object detection *(Nesne tespiti)*

### Semantic segmentation *(Anlamsal segmentasyon)*

### Summary *(Ã–zet)*

---

## Chapter 11: Modeling for NLP *(BÃ¶lÃ¼m 11: DoÄŸal Dil Ä°ÅŸleme (NLP) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

### Sentiment analysis *(Duygu analizi)*

### Open domain Q&A *(AÃ§Ä±k alan soru-cevap)*

### Text augmentation strategies *(Metin artÄ±rma stratejileri)*

#### Basic techniques *(Temel teknikler)*

#### nlpaug *(nlpaug kÃ¼tÃ¼phanesi)*

### Summary *(Ã–zet)*

---

## Chapter 12: Simulation and Optimization Competitions *(BÃ¶lÃ¼m 12: SimÃ¼lasyon ve Optimizasyon YarÄ±ÅŸmalarÄ±)*

### Connect X *(Connect X oyunu)*

### Rock-paper-scissors *(TaÅŸ-kaÄŸÄ±t-makas)*

### Santa competition 2020 *(Santa yarÄ±ÅŸmasÄ± 2020)*

### The name of the game *(Oyunun Ã¶zÃ¼)*

### Summary *(Ã–zet)*

---

# Part III: Leveraging Competitions for Your Career *(BÃ¶lÃ¼m III: YarÄ±ÅŸmalarÄ± Kariyerinde Avantaja DÃ¶nÃ¼ÅŸtÃ¼rme)*

## Chapter 13: Creating Your Portfolio of Projects and Ideas *(BÃ¶lÃ¼m 13: Proje ve Fikir PortfÃ¶yÃ¼ OluÅŸturma)*

### Building your portfolio with Kaggle *(Kaggle ile portfÃ¶y oluÅŸturma)*

### Leveraging Notebooks and discussions *(Defterler ve tartÄ±ÅŸmalardan yararlanma)*

### Leveraging Datasets *(Veri setlerinden yararlanma)*

### Arranging your online presence beyond Kaggle *(Kaggle dÄ±ÅŸÄ±nda Ã§evrimiÃ§i varlÄ±ÄŸÄ±nÄ± dÃ¼zenleme)*

#### Blogs and publications *(Bloglar ve yayÄ±nlar)*

#### GitHub *(GitHub)*

### Monitoring competition updates and newsletters *(YarÄ±ÅŸma gÃ¼ncellemelerini ve bÃ¼ltenleri takip etme)*

### Summary *(Ã–zet)*

---

## Chapter 14: Finding New Professional Opportunities *(BÃ¶lÃ¼m 14: Yeni Profesyonel FÄ±rsatlar Bulmak)*

### Building connections with other competition data scientists *(DiÄŸer yarÄ±ÅŸmacÄ± veri bilimcilerle baÄŸlantÄ± kurma)*

### Participating in Kaggle Days and other Kaggle meetups *(Kaggle Days ve diÄŸer Kaggle buluÅŸmalarÄ±na katÄ±lma)*

### Getting spotted and other job opportunities *(Fark edilmek ve diÄŸer iÅŸ fÄ±rsatlarÄ±)*

#### The STAR approach *(STAR yaklaÅŸÄ±mÄ±)*

### Summary (and some parting words) *(Ã–zet ve kapanÄ±ÅŸ notlarÄ±)*

---

## Other Books You May Enjoy *(HoÅŸunuza Gidebilecek DiÄŸer Kitaplar)*

## Index *(Dizin)*
