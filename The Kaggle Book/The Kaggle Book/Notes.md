# Part I: Introduction to Competitions *(BÃ¶lÃ¼m I: YarÄ±ÅŸmalara GiriÅŸ)*

## Chapter 1: Introducing Kaggle and Other Data Science Competitions *(BÃ¶lÃ¼m 1: Kaggle ve DiÄŸer Veri Bilimi YarÄ±ÅŸmalarÄ±na GiriÅŸ)*

Veri bilimi yarÄ±ÅŸmalarÄ± uzun zamandÄ±r var ve zaman iÃ§inde giderek artan bir baÅŸarÄ± elde ettiler. Tutkulu bir yarÄ±ÅŸmacÄ± topluluÄŸundan doÄŸan bu yarÄ±ÅŸmalar, giderek daha fazla ilgi Ã§ekmeye ve milyonlarca veri bilimciden oluÅŸan Ã§ok daha geniÅŸ bir kitleye ulaÅŸmaya baÅŸladÄ±. En popÃ¼ler veri bilimi yarÄ±ÅŸma platformu olan **Kaggle**â€™da uzun yÄ±llardÄ±r yarÄ±ÅŸmacÄ± olarak yer aldÄ±ÄŸÄ±mÄ±z iÃ§in, bu deÄŸiÅŸimlerin tÃ¼mÃ¼ne yÄ±llar boyunca doÄŸrudan tanÄ±klÄ±k ettik ve bizzat deneyimledik.

BugÃ¼n, Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ± hakkÄ±nda bilgi ararsanÄ±z, Ã§ok sayÄ±da **buluÅŸma (meetup)**, **tartÄ±ÅŸma paneli**, **podcast**, **rÃ¶portaj** ve hatta bu tÃ¼r yarÄ±ÅŸmalarda nasÄ±l kazanÄ±lacaÄŸÄ±nÄ± anlatan **Ã§evrimiÃ§i kurslar** bulabilirsiniz. (Genellikle bu kurslar size azim, hesaplama kaynaklarÄ± ve harcanan zamanÄ±n doÄŸru karÄ±ÅŸÄ±mÄ±nÄ± kullanmanÄ±zÄ± tavsiye eder.) Ancak, ÅŸu anda okumakta olduÄŸunuz kitap dÄ±ÅŸÄ±nda, bu kadar Ã§ok veri bilimi yarÄ±ÅŸmasÄ±nÄ± nasÄ±l yÃ¶neteceÄŸinizi ve onlardan nasÄ±l en iyi ÅŸekilde yararlanabileceÄŸinizi â€” yalnÄ±zca puan veya sÄ±ralama aÃ§Ä±sÄ±ndan deÄŸil, **profesyonel deneyim** bakÄ±mÄ±ndan da â€” sistematik bir ÅŸekilde anlatan bir rehber bulmanÄ±z oldukÃ§a zordur.

Bu kitapta amacÄ±mÄ±z, Kaggle veya diÄŸer veri bilimi yarÄ±ÅŸmalarÄ±nda nasÄ±l yÃ¼ksek puan alacaÄŸÄ±nÄ±zÄ± anlatan birkaÃ§ ipucu vermek deÄŸil. Bunun yerine, **Kaggleâ€™da daha etkili yarÄ±ÅŸmanÄ±z** ve yarÄ±ÅŸma deneyimlerinizden â€” Ã¶zellikle de profesyonel hayatÄ±nÄ±z aÃ§Ä±sÄ±ndan â€” **en fazla faydayÄ± elde etmeniz** iÃ§in kapsamlÄ± bir rehber sunmak istiyoruz. Kitap iÃ§eriÄŸine, **Kaggle Master** ve **Grandmaster**â€™larla yapÄ±lan rÃ¶portajlar da eÅŸlik ediyor. Bu rÃ¶portajlarÄ±n size Kaggleâ€™da yarÄ±ÅŸmanÄ±n belirli yÃ¶nleri hakkÄ±nda farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve iÃ§gÃ¶rÃ¼ler sunacaÄŸÄ±nÄ± ve rekabetÃ§i veri bilimi yaparken kendinizi sÄ±nama ve Ã¶ÄŸrenme biÃ§iminize ilham vereceÄŸini umuyoruz.

Bu kitabÄ±n sonunda, **kendi deneyimlerimizden**, **yarÄ±ÅŸmalardan edindiÄŸimiz bilgilerden** ve **kaynaklardan** doÄŸrudan derlediÄŸimiz bilgileri iÃ§selleÅŸtirmiÅŸ olacaksÄ±nÄ±z. BÃ¶ylece yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã¶ÄŸrenmenizi ve geliÅŸmenizi saÄŸlayacak bir yol haritasÄ±na sahip olacaksÄ±nÄ±z.

BaÅŸlangÄ±Ã§ noktasÄ± olarak, bu bÃ¶lÃ¼mde ÅŸunlarÄ± inceleyeceÄŸiz:

* RekabetÃ§i programlamanÄ±n nasÄ±l veri bilimi yarÄ±ÅŸmalarÄ±na evrildiÄŸini,
* Neden Kaggle platformunun bu tÃ¼r yarÄ±ÅŸmalar iÃ§in en popÃ¼ler site olduÄŸunu,
* Ve bu platformun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±.

Bu bÃ¶lÃ¼mde aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

* Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi
* **Common Task Framework** (Ortak GÃ¶rev Ã‡erÃ§evesi) paradigmasÄ±
* Kaggle platformu ve bazÄ± alternatifleri
* Bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸi: aÅŸamalarÄ±, yarÄ±ÅŸma tÃ¼rleri, gÃ¶nderim ve liderlik tablosu dinamikleri, hesaplama kaynaklarÄ±, aÄŸ oluÅŸturma ve daha fazlasÄ±

### The rise of data science competition platforms *(Veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n yÃ¼kseliÅŸi)*

RekabetÃ§i programlamanÄ±n kÃ¶klÃ¼ bir geÃ§miÅŸi vardÄ±r; 1970â€™lerde dÃ¼zenlenen ilk **ICPC (International Collegiate Programming Contest â€“ UluslararasÄ± ÃœniversitelerarasÄ± Programlama YarÄ±ÅŸmasÄ±)** ile baÅŸlamÄ±ÅŸtÄ±r. Ä°lk ICPCâ€™de, Ã¼niversitelerden ve ÅŸirketlerden gelen kÃ¼Ã§Ã¼k takÄ±mlar, bir dizi problemi bilgisayar programÄ± kullanarak Ã§Ã¶zmeleri gereken bir yarÄ±ÅŸmaya katÄ±lÄ±yordu (baÅŸlangÄ±Ã§ta katÄ±lÄ±mcÄ±lar **FORTRAN** dilinde kodlama yapÄ±yordu). Ä°yi bir final sÄ±ralamasÄ± elde etmek iÃ§in takÄ±mlarÄ±n gÃ¼Ã§lÃ¼ **takÄ±m Ã§alÄ±ÅŸmasÄ±**, **problem Ã§Ã¶zme** ve **programlama** becerileri sergilemeleri gerekiyordu.

Bu tÃ¼r bir yarÄ±ÅŸmanÄ±n yoÄŸun atmosferinde yer almak ve iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§ekme fÄ±rsatÄ±, Ã¶ÄŸrencilere bÃ¼yÃ¼k bir motivasyon saÄŸladÄ± ve yarÄ±ÅŸmanÄ±n yÄ±llar boyunca popÃ¼ler kalmasÄ±na neden oldu. ICPC finalistleri arasÄ±nda, gÃ¼nÃ¼mÃ¼zde oldukÃ§a tanÄ±nmÄ±ÅŸ isimler vardÄ±r: **Adam Dâ€™Angelo** (Facebookâ€™un eski CTOâ€™su ve Quoraâ€™nÄ±n kurucusu), **Nikolai Durov** (Telegram Messengerâ€™Ä±n kurucu ortaÄŸÄ±) ve **Matei Zaharia** (Apache Sparkâ€™Ä±n yaratÄ±cÄ±sÄ±). Bu isimlerin yanÄ± sÄ±ra birÃ§ok profesyonel aynÄ± ortak deneyimi paylaÅŸÄ±r: bir ICPC yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸlardÄ±r.

ICPCâ€™nin ardÄ±ndan, Ã¶zellikle 2000 yÄ±lÄ±ndan sonra uzaktan katÄ±lÄ±mÄ±n kolaylaÅŸmasÄ±yla programlama yarÄ±ÅŸmalarÄ± bÃ¼yÃ¼k bir geliÅŸme gÃ¶sterdi. Bu sayede uluslararasÄ± yarÄ±ÅŸmalarÄ±n dÃ¼zenlenmesi hem daha kolay hem de daha dÃ¼ÅŸÃ¼k maliyetli hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸunun formatÄ± benzerdir: bir dizi problem verilir ve katÄ±lÄ±mcÄ±larÄ±n bunlarÄ± Ã§Ã¶zmek iÃ§in kod yazmasÄ± gerekir. Kazananlar sadece Ã¶dÃ¼l kazanmakla kalmaz, aynÄ± zamanda iÅŸe alÄ±m yapan ÅŸirketlerin dikkatini Ã§eker veya kendi alanlarÄ±nda tanÄ±nÄ±r hale gelirler.

RekabetÃ§i programlamadaki problemler genellikle **kombinatorik**, **sayÄ± teorisi**, **graf teorisi**, **algoritmik oyun teorisi**, **hesaplamalÄ± geometri**, **dizgi analizi** ve **veri yapÄ±larÄ±** gibi konulardan oluÅŸur. Son yÄ±llarda ise **yapay zekÃ¢** ile ilgili problemler de bu yarÄ±ÅŸmalarda yer almaya baÅŸlamÄ±ÅŸtÄ±r. Ã–zellikle **KDD Cup**â€™Ä±n (Knowledge Discovery and Data Mining Cup â€“ Bilgi KeÅŸfi ve Veri MadenciliÄŸi YarÄ±ÅŸmasÄ±) baÅŸlatÄ±lmasÄ±ndan sonra bu tÃ¼r problemler oldukÃ§a popÃ¼ler hale gelmiÅŸtir. Bu yarÄ±ÅŸma, her yÄ±l **Association for Computing Machinery (ACM)** tarafÄ±ndan dÃ¼zenlenen konferans kapsamÄ±nda **Ã–zel Ä°lgi Grubu (SIG)** tarafÄ±ndan yÃ¼rÃ¼tÃ¼lmektedir. (Kaynak: [https://kdd.org/conferences](https://kdd.org/conferences))

Ä°lk **KDD Cup**, 1997 yÄ±lÄ±nda dÃ¼zenlenmiÅŸ ve **doÄŸrudan pazarlamada lift eÄŸrisi optimizasyonu** konusundaki bir problemi iÃ§ermiÅŸtir. Bu yarÄ±ÅŸma, gÃ¼nÃ¼mÃ¼zde hÃ¢lÃ¢ devam eden uzun bir yarÄ±ÅŸma serisinin baÅŸlangÄ±cÄ±nÄ± oluÅŸturmuÅŸtur. Veri kÃ¼meleri, yÃ¶nergeler ve kazananlar dÃ¢hil olmak Ã¼zere tÃ¼m arÅŸivlere ÅŸu adresten ulaÅŸabilirsiniz: [https://www.kdd.org/kdd-cup](https://www.kdd.org/kdd-cup). YazÄ±m sÄ±rasÄ±nda en son mevcut olan yarÄ±ÅŸma ise [https://ogb.stanford.edu/kddcup2021/](https://ogb.stanford.edu/kddcup2021/).
KDD Cup yarÄ±ÅŸmalarÄ±, en iyi uygulamalarÄ± belirlemede oldukÃ§a etkili olmuÅŸtur. BirÃ§ok makalede yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri, teknikler ve veri kÃ¼meleri paylaÅŸÄ±lmÄ±ÅŸ, bu da araÅŸtÄ±rmacÄ±lar ve uygulayÄ±cÄ±lar iÃ§in **deney**, **eÄŸitim** ve **karÅŸÄ±laÅŸtÄ±rma (benchmarking)** aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k fayda saÄŸlamÄ±ÅŸtÄ±r.

Hem rekabetÃ§i programlama etkinliklerinin hem de KDD Cupâ€™Ä±n baÅŸarÄ±sÄ±, ÅŸirketleri (Ã¶rneÄŸin **Netflix**) ve giriÅŸimcileri (Ã¶rneÄŸin Kaggleâ€™Ä±n kurucusu **Anthony Goldbloom**) **veri bilimi yarÄ±ÅŸma platformlarÄ±** kurmaya teÅŸvik etti. Bu platformlar, ÅŸirketlerin Ã§Ã¶zÃ¼lmesi zor veri bilimi problemlerini kitle kaynaklÄ± Ã§Ã¶zÃ¼mlerle Ã§Ã¶zebilmesine olanak tanÄ±dÄ±. GerÃ§ekten de veri bilimi alanÄ±nda her problem iÃ§in iÅŸe yarayan tek bir â€œaltÄ±nâ€ yÃ¶ntem yoktur; Ã§oÄŸu zaman, **â€œdeneyebileceÄŸin her ÅŸeyi deneâ€** yaklaÅŸÄ±mÄ± gerekir.

AslÄ±nda, uzun vadede hiÃ§bir algoritma tÃ¼m problemler iÃ§in diÄŸerlerini alt edemez. Bu durum, **David Wolpert** ve **William Macready** tarafÄ±ndan ortaya konan **No Free Lunch Teoremi (Bedava Ã–ÄŸle YemeÄŸi Yok Teoremi)** ile aÃ§Ä±klanÄ±r. Bu teoreme gÃ¶re, her makine Ã¶ÄŸrenimi algoritmasÄ± yalnÄ±zca Ã§Ã¶zÃ¼mÃ¼ iÃ§eren bir hipotez uzayÄ±na sahipse baÅŸarÄ±lÄ± olur. DolayÄ±sÄ±yla, bir algoritmanÄ±n belirli bir problemi en iyi ÅŸekilde Ã§Ã¶zebileceÄŸini Ã¶nceden bilemezsiniz; bunu Ã¶ÄŸrenmenin tek yolu, algoritmayÄ± doÄŸrudan o problem Ã¼zerinde test etmektir.
Makine Ã¶ÄŸreniminde herhangi bir â€œkutsal kÃ¢seâ€ veya teorik kestirme yoktur â€” yalnÄ±zca **ampirik deneyler** size neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶sterebilir.

Bu konuda daha fazla bilgi edinmek iÃ§in **No Free Lunch Teoremi** Ã¼zerine kuramsal aÃ§Ä±klamalarÄ± inceleyebilirsiniz. AÅŸaÄŸÄ±da bu konuyu detaylÄ± anlatan bir makaleye baÄŸlantÄ± verilmiÅŸtir:
ğŸ‘‰ [Analytics India Magazine â€“ What are the No Free Lunch Theorems in Data Science?](https://analyticsindiamag.com/what-are-the-no-free-lunch-theorems-in-data-science/)

Bu tÃ¼r durumlarda **crowdsourcing (kitle kaynak kullanÄ±mÄ±)** mÃ¼kemmel bir yÃ¶ntemdir; Ã§Ã¼nkÃ¼ algoritmalarÄ± ve veri dÃ¶nÃ¼ÅŸÃ¼mlerini kapsamlÄ± bir ÅŸekilde test etmeniz gerekir, ancak bunu yapacak insan gÃ¼cÃ¼ ve iÅŸlem gÃ¼cÃ¼nÃ¼z yoktur. Bu nedenle, hÃ¼kÃ¼metler ve ÅŸirketler belirli alanlarda ilerleme kaydetmek iÃ§in yarÄ±ÅŸmalara baÅŸvurur:

* **Kamu tarafÄ±nda:** ABDâ€™nin **DARPA** kuruluÅŸu tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalarda; **otonom araÃ§lar**, **robotik operasyonlar**, **makine Ã§evirisi**, **konuÅŸmacÄ± tanÄ±ma**, **parmak izi tanÄ±ma**, **bilgi eriÅŸimi**, **OCR (Optik Karakter TanÄ±ma)**, **otomatik hedef tanÄ±ma** gibi birÃ§ok alanda yarÄ±ÅŸmalar dÃ¼zenlenmiÅŸtir.
* **Åirket tarafÄ±nda:** Ã–rneÄŸin **Netflix**, kullanÄ±cÄ±larÄ±n film tercihlerinin tahmin edilmesini iyileÅŸtirmek amacÄ±yla dÃ¼zenlenen bir yarÄ±ÅŸmanÄ±n sonucuna gÃ¶re algoritmasÄ±nÄ± geliÅŸtirmiÅŸtir.

**Netflix YarÄ±ÅŸmasÄ± (Netflix Prize)**, mevcut **Ã¶neri sistemini** (collaborative filtering) geliÅŸtirmeyi amaÃ§lÄ±yordu. YarÄ±ÅŸmanÄ±n hedefi, bir kullanÄ±cÄ±nÄ±n bir filme vereceÄŸi puanÄ±, yalnÄ±zca daha Ã¶nce puanladÄ±ÄŸÄ± filmlerden yola Ã§Ä±karak tahmin etmekti â€” yani kullanÄ±cÄ± kimliÄŸi veya film aÃ§Ä±klamalarÄ± hakkÄ±nda hiÃ§bir bilgi yoktu (bunlarÄ±n tÃ¼mÃ¼ kimlik kodlarÄ±yla deÄŸiÅŸtirilmiÅŸti). KatÄ±lÄ±mcÄ±lardan, mevcut puan geÃ§miÅŸini akÄ±llÄ±ca kullanarak tahmin yapan modeller geliÅŸtirmeleri istendi.
**1.000.000 ABD DolarÄ±** tutarÄ±ndaki bÃ¼yÃ¼k Ã¶dÃ¼l, yalnÄ±zca geliÅŸtirilen modelin Netflixâ€™in mevcut algoritmasÄ± **Cinematch**â€™i belirli bir eÅŸiÄŸin Ã¼zerinde iyileÅŸtirmesi durumunda verilecekti.

YarÄ±ÅŸma 2006â€™dan 2009â€™a kadar sÃ¼rdÃ¼ ve kazanan takÄ±m, Ã¶nceki yarÄ±ÅŸmalardan birÃ§ok takÄ±mÄ±n birleÅŸmesiyle oluÅŸtu: **Commendo Research & Consulting GmbH**â€™den **Andreas TÃ¶scher** ve **Michael Jahrer** (aynÄ± zamanda Kaggleâ€™da da tanÄ±nan yarÄ±ÅŸmacÄ±lar), **AT&T Labs**â€™tan iki araÅŸtÄ±rmacÄ± ve **Yahoo!**â€™dan iki araÅŸtÄ±rmacÄ±.
YarÄ±ÅŸmayÄ± kazanmak, o kadar bÃ¼yÃ¼k bir hesaplama gÃ¼cÃ¼ ve farklÄ± Ã§Ã¶zÃ¼mlerin birleÅŸtirilmesini (ensemble) gerektirdi ki, takÄ±mlar rekabeti sÃ¼rdÃ¼rebilmek iÃ§in birleÅŸmek zorunda kaldÄ±lar. SonuÃ§ta, **Netflix** bu Ã§Ã¶zÃ¼mÃ¼ doÄŸrudan uygulamak yerine, yarÄ±ÅŸmadan elde edilen en deÄŸerli iÃ§gÃ¶rÃ¼leri alÄ±p mevcut **Cinematch algoritmasÄ±nÄ±** geliÅŸtirmede kullandÄ±.
Bu konuda daha fazla bilgi iÃ§in ÅŸu **Wired** makalesini okuyabilirsiniz:
ğŸ‘‰ [https://www.wired.com/2012/04/netflix-prize-costs/](https://www.wired.com/2012/04/netflix-prize-costs/)

Netflix yarÄ±ÅŸmasÄ±nÄ±n sonunda Ã¶nemli olan ÅŸey, Ã§Ã¶zÃ¼mÃ¼n kendisi deÄŸil, **Netflixâ€™in iÅŸ modelinin DVD kiralamadan Ã§evrimiÃ§i yayÄ±n platformuna geÃ§mesiyle** birlikte elde edilen **bilgi ve deneyimdi**. YarÄ±ÅŸmadan hem katÄ±lÄ±mcÄ±lar (Ã¶neri sistemleri alanÄ±nda bÃ¼yÃ¼k bir Ã¼n kazandÄ±lar) hem de Netflix (geliÅŸtirilmiÅŸ Ã¶neri sistemi bilgisini yeni iÅŸ modeline aktardÄ±) bÃ¼yÃ¼k fayda saÄŸladÄ±.

#### The Kaggle competition platform *(Kaggle yarÄ±ÅŸma platformu)*

**Netflix dÄ±ÅŸÄ±ndaki birÃ§ok ÅŸirket de veri bilimi yarÄ±ÅŸmalarÄ±ndan fayda saÄŸlamÄ±ÅŸtÄ±r.** Liste oldukÃ§a uzundur, ancak yarÄ±ÅŸmayÄ± dÃ¼zenleyen ÅŸirketlerin aÃ§Ä±k bir ÅŸekilde fayda elde ettiÄŸini bildirdiÄŸi birkaÃ§ Ã¶rneÄŸi verebiliriz. Ã–rneÄŸin:

* **Allstate** adlÄ± sigorta ÅŸirketi, yÃ¼zlerce veri bilimcinin katÄ±ldÄ±ÄŸÄ± bir yarÄ±ÅŸma sayesinde ([https://www.kaggle.com/c/ClaimPredictionChallenge](https://www.kaggle.com/c/ClaimPredictionChallenge)), kendi uzmanlarÄ± tarafÄ±ndan geliÅŸtirilen aktÃ¼eryal modellerini Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸtirebilmiÅŸtir.
* BaÅŸka iyi belgelenmiÅŸ bir Ã¶rnek olarak, **General Electric**, havayolu uÃ§uÅŸlarÄ±nÄ±n varÄ±ÅŸ zamanlarÄ±nÄ± tahmin etmede kullanÄ±lan sektÃ¶r standardÄ± performans Ã¶lÃ§Ã¼tÃ¼ne gÃ¶re (kÃ¶k ortalama kare hatasÄ± â€“ *root mean squared error* metriÄŸiyle Ã¶lÃ§Ã¼lÃ¼r) %40â€™lÄ±k bir geliÅŸme saÄŸlamÄ±ÅŸtÄ±r. Bu baÅŸarÄ±, benzer bir yarÄ±ÅŸma sayesinde elde edilmiÅŸtir ([https://www.kaggle.com/c/flight](https://www.kaggle.com/c/flight)).

**Kaggle yarÄ±ÅŸma platformu** bugÃ¼ne kadar yÃ¼zlerce yarÄ±ÅŸma dÃ¼zenlemiÅŸtir ve bu iki Ã¶rnek, platformu baÅŸarÄ±yla kullanan ÅŸirketlerden yalnÄ±zca birkaÃ§Ä±dÄ±r.
Åimdi, belirli yarÄ±ÅŸmalarÄ±n Ã¶tesine geÃ§ip bu kitabÄ±n da merkezinde yer alan **Kaggle ÅŸirketi** hakkÄ±nda konuÅŸalÄ±m.

##### A history of Kaggle *(Kaggleâ€™Ä±n tarihÃ§esi)*

**Kaggle**, ilk adÄ±mlarÄ±nÄ± **Åubat 2010â€™da**, ekonomist ve ekonometrikÃ§i olarak eÄŸitim almÄ±ÅŸ AvustralyalÄ± **Anthony Goldbloom** sayesinde attÄ±. Goldbloom, Avustralya Hazine BakanlÄ±ÄŸÄ±â€™nda (*Department of the Treasury*) ve Avustralya Merkez BankasÄ±â€™nÄ±n (*Reserve Bank of Australia*) AraÅŸtÄ±rma DepartmanÄ±â€™nda Ã§alÄ±ÅŸtÄ±ktan sonra, Londraâ€™da haftalÄ±k uluslararasÄ± dergi **The Economist**â€™te staj yaptÄ±.

The Economistâ€™te Ã§alÄ±ÅŸtÄ±ÄŸÄ± dÃ¶nemde â€œ**bÃ¼yÃ¼k veri (big data)**â€ Ã¼zerine bir makale yazma fÄ±rsatÄ± buldu. Bu makale, onun aklÄ±na **ilginÃ§ makine Ã¶ÄŸrenimi problemlerini Ã§Ã¶zmek iÃ§in en iyi analitik uzmanlarÄ± kitlesel katÄ±lÄ±mla (crowdsourcing) bir araya getirecek bir yarÄ±ÅŸma platformu kurma fikrini** getirdi ([kaynak](https://www.smh.com.au/technology/from-bondi-to-the-big-bucks-the-28yearold-whos-making-datascience-a-sport-20111104-1myq1.html)).

Bu platformun iÅŸ fikrinde â€œcrowdsourcingâ€ dinamiklerinin Ã¶nemli bir rol oynamasÄ±ndan dolayÄ±, Goldbloom platformun adÄ±nÄ± **Kaggle** koydu. Bu isim, Ä°ngilizce â€œ**gaggle**â€ (kaz sÃ¼rÃ¼sÃ¼) kelimesine bir gÃ¶nderme yapÄ±yor; kaz figÃ¼rÃ¼ de zaten Kaggle platformunun sembolÃ¼dÃ¼r.

Goldbloom, daha sonra **ABDâ€™nin Silikon Vadisiâ€™ne taÅŸÄ±ndÄ±** ve Kaggle giriÅŸimi, iki tanÄ±nmÄ±ÅŸ risk sermayesi ÅŸirketi olan **Khosla Ventures** ve **Index Ventures** tarafÄ±ndan yÃ¶netilen bir yatÄ±rÄ±m turunda **11,25 milyon dolar** tutarÄ±nda **A Serisi yatÄ±rÄ±m** aldÄ±. Ä°lk yarÄ±ÅŸmalar baÅŸlatÄ±ldÄ±, topluluk hÄ±zla bÃ¼yÃ¼dÃ¼ ve bazÄ± erken dÃ¶nem yarÄ±ÅŸmacÄ±lar dikkat Ã§ekici baÅŸarÄ±lara ulaÅŸtÄ±. Bunlardan biri olan **Jeremy Howard**, AvustralyalÄ± bir veri bilimci ve giriÅŸimciydi. Kaggleâ€™da birkaÃ§ yarÄ±ÅŸma kazandÄ±ktan sonra ÅŸirketin **BaÅŸkanÄ± (President)** ve **BaÅŸ Bilimcisi (Chief Scientist)** oldu.

Jeremy Howard, **AralÄ±k 2013â€™te** gÃ¶revinden ayrÄ±ldÄ± ve daha sonra **fast.ai** ([www.fast.ai](http://www.fast.ai)) adlÄ± yeni bir giriÅŸim kurdu. Bu giriÅŸim, **makine Ã¶ÄŸrenimi kurslarÄ±** ve **geliÅŸtiriciler iÃ§in derin Ã¶ÄŸrenme (deep learning) kÃ¼tÃ¼phanesi** sunmaktadÄ±r.

O dÃ¶nemde Ã¶ne Ã§Ä±kan diÄŸer bazÄ± **Kaggle yarÄ±ÅŸmacÄ±larÄ± (Kagglers)** arasÄ±nda **Jeremy Achin** ve **Thomas de Godoy** da bulunuyordu. Platformda **ilk 20 kÃ¼resel sÄ±ralama** arasÄ±na girdikten sonra emekli olmaya karar verdiler ve **DataRobot** adlÄ± kendi ÅŸirketlerini kurdular. KÄ±sa sÃ¼re sonra, geliÅŸtirdikleri yazÄ±lÄ±ma en iyi makine Ã¶ÄŸrenimi bilgilerini ve uygulamalarÄ±nÄ± kazandÄ±rmak amacÄ±yla **Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmuÅŸ katÄ±lÄ±mcÄ±larÄ± iÅŸe almaya** baÅŸladÄ±lar. BugÃ¼n **DataRobot**, **AutoML (otomatik makine Ã¶ÄŸrenimi)** Ã§Ã¶zÃ¼mleri geliÅŸtiren Ã¶nde gelen ÅŸirketlerden biridir.

Kaggle yarÄ±ÅŸmalarÄ±, giderek artan bir ilgiyle bÃ¼yÃ¼meye devam etti. **Derin Ã¶ÄŸrenmenin â€œbabasÄ±â€ Geoffrey Hinton**, 2012â€™de **Merck** tarafÄ±ndan dÃ¼zenlenen bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ± ve kazandÄ± ([kaynak](https://www.kaggle.com/c/MerckActivity/overview/winners)).

AyrÄ±ca Kaggle, **FranÃ§ois Chollet**â€™nin derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesi **Keras**â€™Ä± tanÄ±ttÄ±ÄŸÄ± **Otto Group Product Classification Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13632)) yarÄ±ÅŸmasÄ±nÄ±n ve **Tianqi Chen**â€™in **XGBoost** adlÄ± daha hÄ±zlÄ± ve daha doÄŸru bir **gradient boosting** algoritmasÄ±nÄ± tanÄ±ttÄ±ÄŸÄ± **Higgs Boson Machine Learning Challenge** ([baÄŸlantÄ±](https://www.kaggle.com/c/higgs-boson/discussion/10335)) yarÄ±ÅŸmasÄ±nÄ±n da dÃ¼zenlendiÄŸi platformdur.

FranÃ§ois Chollet ayrÄ±ca **Quora** sitesinde â€œKaggle yarÄ±ÅŸmalarÄ±nda neden Keras bu kadar baÅŸarÄ±lÄ± oldu?â€ sorusuna verdiÄŸi cevapta, Kaggle yarÄ±ÅŸmalarÄ±nda baÅŸarÄ±lÄ± olmanÄ±n Ã¶zÃ¼nÃ¼ mÃ¼kemmel bir ÅŸekilde aÃ§Ä±klamÄ±ÅŸtÄ±r ([kaynak](https://www.quora.com/Why-has-Keras-been-so-successful-lately-at-Kaggle-competitions)).
Ona gÃ¶re, **Ã§ok sayÄ±da denemeyi hÄ±zlÄ± ÅŸekilde yapmak ve teoriden ziyade ampirik kanÄ±tlarla yÃ¶nlenmek**, Kaggleâ€™da baÅŸarÄ±lÄ± olmanÄ±n temelidir. Biz de onun belirttiÄŸi noktalarÄ±n dÄ±ÅŸÄ±nda baÅŸka bir â€œgizli sÄ±râ€ olduÄŸuna inanmÄ±yoruz.

FranÃ§ois Chollet ayrÄ±ca Kaggleâ€™da kendi yarÄ±ÅŸmasÄ±nÄ± da dÃ¼zenlemiÅŸtir ([Abstraction and Reasoning Challenge](https://www.kaggle.com/c/abstraction-and-reasoning-challenge/)) â€” bu yarÄ±ÅŸma, **dÃ¼nyanÄ±n ilk genel yapay zekÃ¢ (general AI) yarÄ±ÅŸmasÄ±** olarak kabul edilir.

YarÄ±ÅŸma Ã¼stÃ¼ne yarÄ±ÅŸma geldikÃ§e, Kaggle etrafÄ±ndaki topluluk bÃ¼yÃ¼meye devam etti ve **2017 yÄ±lÄ±nda 1 milyon kullanÄ±cÄ±ya** ulaÅŸtÄ±. AynÄ± yÄ±l, **Google BaÅŸ Bilimcisi Fei-Fei Li**, **Google Next** etkinliÄŸinde yaptÄ±ÄŸÄ± aÃ§Ä±lÄ±ÅŸ konuÅŸmasÄ±nda **Googleâ€™Ä±n Kaggleâ€™Ä± satÄ±n alacaÄŸÄ±nÄ±** duyurdu.
O tarihten bu yana **Kaggle, Google Ã§atÄ±sÄ± altÄ±nda** faaliyet gÃ¶stermektedir.

BugÃ¼n, **Kaggle topluluÄŸu hÃ¢lÃ¢ aktif ve bÃ¼yÃ¼meye devam ediyor.**
Anthony Goldbloomâ€™un bir tweetâ€™inde ([kaynak](https://twitter.com/antgoldbloom/status/1400119591246852096)) belirttiÄŸi Ã¼zere, kullanÄ±cÄ±larÄ±n bÃ¼yÃ¼k bir kÄ±smÄ± sadece yarÄ±ÅŸmalara katÄ±lmakla kalmÄ±yor; aynÄ± zamanda **Kaggleâ€™Ä±n herkese aÃ§Ä±k veri setlerini indiriyor** (Kaggle artÄ±k Ã¶nemli bir **veri merkezi** haline gelmiÅŸtir), **Python veya R ile herkese aÃ§Ä±k Notebooks oluÅŸturuyor** ya da **platformun sunduÄŸu kurslardan yeni bir ÅŸeyler Ã¶ÄŸreniyor.**

![](im/1001.png)

YÄ±llar boyunca Kaggle, katÄ±lÄ±mcÄ±larÄ±na aÅŸaÄŸÄ±daki gibi **daha pek Ã§ok fÄ±rsat** sunmuÅŸtur:

* **Kendi ÅŸirketlerini kurmak**
* **Makine Ã¶ÄŸrenimi yazÄ±lÄ±mlarÄ± ve paketleri baÅŸlatmak**
* **Dergilerde rÃ¶portajlar yapmak** ([kaynak](https://www.wired.com/story/solve-these-tough-data-problems-and-watch-job-offers-roll-in/))
* **Makine Ã¶ÄŸrenimi kitaplarÄ± yazmak** ([kaynak](https://twitter.com/antgoldbloom/status/745662719588589568))
* **Hayallerindeki iÅŸi bulmak**

Ve en Ã¶nemlisi, **veri bilimi ile ilgili beceriler ve teknik detaylar hakkÄ±nda daha fazla bilgi edinmek**.

#### Other competition platforms *(DiÄŸer yarÄ±ÅŸma platformlarÄ±)*

Bu kitap Kaggleâ€™daki yarÄ±ÅŸmalara odaklansa da, birÃ§ok veri yarÄ±ÅŸmasÄ±nÄ±n Ã¶zel platformlarda veya diÄŸer yarÄ±ÅŸma platformlarÄ±nda dÃ¼zenlendiÄŸini unutmamak gerekir. AslÄ±nda, bu kitapta bulacaÄŸÄ±nÄ±z bilgilerin Ã§oÄŸu diÄŸer yarÄ±ÅŸmalar iÃ§in de geÃ§erlidir; Ã§Ã¼nkÃ¼ temelde hepsi benzer prensiplerle Ã§alÄ±ÅŸÄ±r ve katÄ±lÄ±mcÄ±lara saÄŸladÄ±klarÄ± faydalar da aÅŸaÄŸÄ± yukarÄ± aynÄ±dÄ±r.

BirÃ§ok diÄŸer platform belirli Ã¼lkelere odaklanmÄ±ÅŸ ya da yalnÄ±zca belirli tÃ¼rde yarÄ±ÅŸmalarda uzmanlaÅŸmÄ±ÅŸtÄ±r. Yine de, tamlÄ±k aÃ§Ä±sÄ±ndan, en azÄ±ndan deneyim ve bilgimizin bulunduÄŸu bazÄ±larÄ±nÄ± kÄ±saca tanÄ±tmakta fayda var:

* **DrivenData** ([https://www.drivendata.org/competitions/](https://www.drivendata.org/competitions/)) sosyal problemlere yÃ¶nelik yarÄ±ÅŸmalar dÃ¼zenleyen bir kitle kaynaklÄ± (crowdsourcing) yarÄ±ÅŸma platformudur (bkz. [https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/](https://www.drivendata.co/blog/intro-to-machine-learning-social-impact/)). Åirketin kendisi, dÃ¼nyanÄ±n en bÃ¼yÃ¼k sorunlarÄ±yla mÃ¼cadele eden kuruluÅŸlara veri bilimi Ã§Ã¶zÃ¼mleri sunmayÄ± amaÃ§layan bir sosyal giriÅŸimdir. Veri bilimciler, sosyal fayda iÃ§in algoritmalar geliÅŸtirir. Ã–rneÄŸin, [https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html](https://www.engadget.com/facebook-ai-hate-speechcovid-19-160037191.html) adresindeki makalede okuyabileceÄŸiniz gibi, Facebook nefret sÃ¶ylemi ve yanlÄ±ÅŸ bilgiyle mÃ¼cadele iÃ§in dÃ¼zenlediÄŸi yarÄ±ÅŸmada DrivenDataâ€™yÄ± seÃ§miÅŸtir.

* **Numerai** ([https://numer.ai/](https://numer.ai/)) San Francisco merkezli, yapay zekÃ¢ destekli bir kitle kaynaklÄ± hedge fonudur. KatÄ±lÄ±mcÄ±lar her hafta fonun anonimleÅŸtirilmiÅŸ verileri Ã¼zerinde tahmin modelleri gÃ¶nderir ve ÅŸirketin kendi kripto para birimi olan *Numeraire* ile Ã¶dÃ¼ller kazanÄ±rlar.

* **CrowdANALYTIX** ([https://www.crowdanalytix.com/community](https://www.crowdanalytix.com/community)) artÄ±k eskisi kadar aktif olmasa da, bir sÃ¼re Ã¶nce birÃ§ok zorlu yarÄ±ÅŸmaya ev sahipliÄŸi yapmÄ±ÅŸtÄ±r (bkz. [https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1](https://towardsdatascience.com/how-i-won-topfive-in-a-deep-learning-competition-753c788cade1)). AyrÄ±ca topluluk blogu, bu platformda ne tÃ¼r zorluklarla karÅŸÄ±laÅŸabileceÄŸinize dair fikir edinmek iÃ§in oldukÃ§a ilginÃ§tir: [https://www.crowdanalytix.com/jq/communityBlog/listBlog.html](https://www.crowdanalytix.com/jq/communityBlog/listBlog.html).

* **Signate** ([https://signate.jp/competitions](https://signate.jp/competitions)) Japonya merkezli bir veri bilimi yarÄ±ÅŸma platformudur. BirÃ§ok yarÄ±ÅŸmaya ev sahipliÄŸi yapar ve Kaggleâ€™a benzer bir sÄ±ralama sistemi sunar ([https://signate.jp/users/rankings](https://signate.jp/users/rankings)).

* **Zindi** ([https://zindi.africa/competitions](https://zindi.africa/competitions)) Afrika merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Afrikaâ€™nÄ±n en acil sosyal, ekonomik ve Ã§evresel sorunlarÄ±nÄ± Ã§Ã¶zmeye odaklÄ± yarÄ±ÅŸmalar dÃ¼zenler.

* **Alibaba Cloud** ([https://www.alibabacloud.com/campaign/tianchi-competitions](https://www.alibabacloud.com/campaign/tianchi-competitions)) Ã‡in merkezli bir bulut biliÅŸim ve yapay zekÃ¢ saÄŸlayÄ±cÄ±sÄ±dÄ±r. SIGKDD, IJCAI-PRICAI ve CVPR gibi akademik konferanslarla ortaklaÅŸa dÃ¼zenlenen *Tianchi Academic* yarÄ±ÅŸmalarÄ±nÄ± baÅŸlatmÄ±ÅŸtÄ±r. GÃ¶rsel tabanlÄ± 3D ÅŸekil tanÄ±ma, 3D nesne yeniden oluÅŸturma ve Ã¶rnek segmentasyonu gibi zorluklar iÃ§eren yarÄ±ÅŸmalar dÃ¼zenler.

* **Analytics Vidhya** ([https://datahack.analyticsvidhya.com/](https://datahack.analyticsvidhya.com/)) Hindistanâ€™Ä±n en bÃ¼yÃ¼k veri bilimi topluluÄŸudur ve veri bilimi hackathonâ€™larÄ± iÃ§in bir platform sunar.

* **CodaLab** ([https://codalab.lri.fr/](https://codalab.lri.fr/)) 2013 yÄ±lÄ±nda Microsoft ve Stanford Ãœniversitesiâ€™nin ortak giriÅŸimiyle kurulmuÅŸ, Fransa merkezli bir veri bilimi yarÄ±ÅŸma platformudur. Bilgi paylaÅŸÄ±mÄ± ve yeniden Ã¼retilebilir modelleme iÃ§in **Worksheets** ([https://worksheets.codalab.org/](https://worksheets.codalab.org/)) adlÄ± Ã¼cretsiz bulut tabanlÄ± bir defter sunar.

DiÄŸer daha kÃ¼Ã§Ã¼k platformlar arasÄ±nda Ä°sviÃ§reâ€™deki Ã‰cole Polytechnique FÃ©dÃ©rale de Lausanne tarafÄ±ndan geliÅŸtirilen **CrowdAI** ([https://www.crowdai.org/](https://www.crowdai.org/)), **InnoCentive** ([https://www.innocentive.com/](https://www.innocentive.com/)), biyomedikal gÃ¶rÃ¼ntÃ¼leme iÃ§in **Grand-Challenge** ([https://grand-challenge.org/](https://grand-challenge.org/)), **DataFountain** ([https://www.datafountain.cn/business?lang=en-US](https://www.datafountain.cn/business?lang=en-US)), **OpenML** ([https://www.openml.org/](https://www.openml.org/)) gibi platformlar yer alÄ±r. AyrÄ±ca, Rus topluluÄŸu **Open Data Science** ([https://ods.ai/competitions](https://ods.ai/competitions)) sitesinde devam eden bÃ¼yÃ¼k yarÄ±ÅŸmalarÄ±n kapsamlÄ± bir listesini bulabilir ve zaman zaman yeni yarÄ±ÅŸma platformlarÄ±nÄ± keÅŸfedebilirsiniz.

Kaggle, hÃ¢lÃ¢ en ilginÃ§ yarÄ±ÅŸmalarÄ± bulabileceÄŸiniz ve yarÄ±ÅŸma Ã§abalarÄ±nÄ±zla en geniÅŸ tanÄ±nÄ±rlÄ±ÄŸÄ± elde edebileceÄŸiniz en iyi platformdur. Ancak, Kaggle dÄ±ÅŸÄ±ndaki bir yarÄ±ÅŸmayÄ± seÃ§mek de anlamlÄ± olabilir; Ã¶zellikle kiÅŸisel veya profesyonel ilgi alanlarÄ±nÄ±za uyan bir yarÄ±ÅŸma bulduÄŸunuzda. GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, Kaggle dÄ±ÅŸÄ±nda da oldukÃ§a fazla alternatif ve fÄ±rsat mevcut. Bu da, Kaggle ile birlikte diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± da dikkate alarak, ilginizi Ã§ekebilecek Ã¶zel veri veya temalÄ± bir yarÄ±ÅŸma bulma olasÄ±lÄ±ÄŸÄ±nÄ±zÄ± artÄ±rÄ±r.

AyrÄ±ca, bu tÃ¼r platformlarda rekabetin genellikle daha az olduÄŸunu (dolayÄ±sÄ±yla daha iyi bir sÄ±ralama veya Ã¶dÃ¼l kazanma ÅŸansÄ±nÄ±zÄ±n daha yÃ¼ksek olabileceÄŸini) bekleyebilirsiniz; ancak katÄ±lÄ±mcÄ±lar arasÄ±nda bilgi paylaÅŸÄ±mÄ±nÄ±n Kaggleâ€™daki kadar zengin olmadÄ±ÄŸÄ±nÄ± da unutmamalÄ±sÄ±nÄ±z.

### Introducing Kaggle *(Kaggleâ€™a giriÅŸ)*

Bu noktada, Ã¶zellikle **Kaggle**â€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha derinlemesine incelememiz gerekiyor.
AÅŸaÄŸÄ±daki paragraflarda, Kaggle platformunun ve yarÄ±ÅŸmalarÄ±nÄ±n Ã§eÅŸitli yÃ¶nlerini ele alacaÄŸÄ±z ve Kaggleâ€™daki bir yarÄ±ÅŸmada yer almanÄ±n ne anlama geldiÄŸine dair bir fikir edineceksiniz.
Daha sonra, kitabÄ±n geri kalan bÃ¶lÃ¼mlerinde bu konularÄ±n Ã§oÄŸuna Ã§ok daha ayrÄ±ntÄ±lÄ± biÃ§imde geri dÃ¶nerek, ek Ã¶neriler ve stratejilerle birlikte tartÄ±ÅŸacaÄŸÄ±z.

#### Stages of a competition *(Bir yarÄ±ÅŸmanÄ±n aÅŸamalarÄ±)*

Kaggleâ€™daki bir yarÄ±ÅŸma, farklÄ± adÄ±mlardan oluÅŸacak ÅŸekilde dÃ¼zenlenir.
Bu adÄ±mlarÄ±n her birine gÃ¶z atarak, bir veri bilimi yarÄ±ÅŸmasÄ±nÄ±n nasÄ±l iÅŸlediÄŸini ve sizden neler beklenebileceÄŸini daha iyi anlayabilirsiniz.

Bir yarÄ±ÅŸma baÅŸlatÄ±ldÄ±ÄŸÄ±nda, genellikle sosyal medyada â€” Ã¶rneÄŸin Kaggleâ€™Ä±n Twitter hesabÄ±nda ([https://twitter.com/kaggle](https://twitter.com/kaggle)) â€” yarÄ±ÅŸmayÄ± duyuran paylaÅŸÄ±mlar yapÄ±lÄ±r. AyrÄ±ca, **Competitions** sayfasÄ±nda ([https://www.kaggle.com/competitions](https://www.kaggle.com/competitions)) **Active Competitions** (aktif yarÄ±ÅŸmalar) bÃ¶lÃ¼mÃ¼nde yeni bir sekme gÃ¶rÃ¼nÃ¼r.

Belirli bir yarÄ±ÅŸmanÄ±n sekmesine tÄ±kladÄ±ÄŸÄ±nÄ±zda, o yarÄ±ÅŸmanÄ±n sayfasÄ±na yÃ¶nlendirilirsiniz. Ä°lk bakÄ±ÅŸta, yarÄ±ÅŸmanÄ±n Ã¶dÃ¼l verip vermediÄŸini (ve yarÄ±ÅŸmaya katÄ±lmanÄ±n bir sonucu olarak puan ve madalya kazandÄ±rÄ±p kazandÄ±rmadÄ±ÄŸÄ±nÄ±), ÅŸu anda kaÃ§ takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ±nÄ± ve Ã§Ã¶zÃ¼mÃ¼nÃ¼z Ã¼zerinde Ã§alÄ±ÅŸmak iÃ§in ne kadar sÃ¼reniz kaldÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz.

![](im/1002.png)

Orada, Ã¶ncelikle **Overview (Genel BakÄ±ÅŸ)** menÃ¼sÃ¼nÃ¼ inceleyebilirsiniz. Bu menÃ¼ size ÅŸu konularda bilgi verir:

* YarÄ±ÅŸmanÄ±n konusu
* DeÄŸerlendirme metriÄŸi (modellerinizin deÄŸerlendirileceÄŸi Ã¶lÃ§Ã¼t)
* YarÄ±ÅŸmanÄ±n zaman Ã§izelgesi
* Ã–dÃ¼ller
* Yasal veya yarÄ±ÅŸma gereklilikleri

Genellikle zaman Ã§izelgesi Ã§ok dikkat edilmeyen bir kÄ±sÄ±mdÄ±r, ancak kontrol etmeniz gereken ilk ÅŸeylerden biri olmalÄ±dÄ±r; Ã§Ã¼nkÃ¼ yalnÄ±zca yarÄ±ÅŸmanÄ±n ne zaman baÅŸlayÄ±p biteceÄŸini deÄŸil, aynÄ± zamanda **kural kabul etme son tarihini** de gÃ¶sterir. Bu tarih genellikle yarÄ±ÅŸma kapanmadan **7 ila 14 gÃ¼n Ã¶nce** olur ve yarÄ±ÅŸmaya katÄ±labileceÄŸiniz (kurallarÄ± kabul edebileceÄŸiniz) son gÃ¼nÃ¼ belirtir.

AyrÄ±ca bir **takÄ±m birleÅŸtirme son tarihi (team merger deadline)** de bulunur: Bu tarihten Ã¶nce istediÄŸiniz herhangi bir zamanda ekibinizi baÅŸka bir yarÄ±ÅŸmacÄ±nÄ±n ekibiyle birleÅŸtirebilirsiniz; ancak bu tarihten sonra artÄ±k mÃ¼mkÃ¼n deÄŸildir.

**Rules (Kurallar)** menÃ¼sÃ¼ de sÄ±klÄ±kla gÃ¶z ardÄ± edilir (Ã§oÄŸu kiÅŸi doÄŸrudan **Data** kÄ±smÄ±na geÃ§er), ancak kontrol edilmesi Ã¶nemlidir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n gereklilikleri hakkÄ±nda bilgi verir. Kurallar kÄ±smÄ±ndan edinebileceÄŸiniz Ã¶nemli bilgiler arasÄ±nda ÅŸunlar yer alÄ±r:

* Ã–dÃ¼l almaya uygun olup olmadÄ±ÄŸÄ±nÄ±z
* PuanÄ±nÄ±zÄ± artÄ±rmak iÃ§in harici veri kullanÄ±p kullanamayacaÄŸÄ±nÄ±z
* GÃ¼nde kaÃ§ tane gÃ¶nderim (Ã§Ã¶zÃ¼m testi) yapabileceÄŸiniz
* KaÃ§ tane nihai Ã§Ã¶zÃ¼m seÃ§ebileceÄŸiniz

KurallarÄ± kabul ettikten sonra, **Data** menÃ¼sÃ¼nden verileri indirebilir veya doÄŸrudan **Code** menÃ¼sÃ¼nden Kaggle Notebooks (Ã§evrimiÃ§i, bulut tabanlÄ± defterler) Ã¼zerinde Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz. Burada diÄŸerlerinin paylaÅŸtÄ±ÄŸÄ± kodlarÄ± yeniden kullanabilir veya sÄ±fÄ±rdan kendi kodunuzu oluÅŸturabilirsiniz.

EÄŸer verileri indirmeye karar verirseniz, **Kaggle API**â€™sini de kullanabileceÄŸinizi unutmayÄ±n. Bu API, indirme ve gÃ¶nderim iÅŸlemlerini neredeyse otomatik hale getirmenize yardÄ±mcÄ± olur. Yerel bilgisayarÄ±nÄ±zda veya bulut sunucunuzda modellerinizi Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z, bu araÃ§ oldukÃ§a faydalÄ±dÄ±r. API hakkÄ±nda daha fazla bilgiyi ÅŸu adreste bulabilirsiniz:
ğŸ‘‰ [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)
Kaynak koduna ise GitHub Ã¼zerinden ulaÅŸabilirsiniz:
ğŸ‘‰ [https://github.com/Kaggle/kaggle-api](https://github.com/Kaggle/kaggle-api)

Kaggleâ€™Ä±n GitHub deposunu daha yakÄ±ndan incelerseniz, **Kaggle Notebooks** (Ã§evrimiÃ§i defterler) iÃ§in kullanÄ±lan tÃ¼m **Docker imajlarÄ±nÄ±** da bulabilirsiniz.

![](im/1003.png)

Bu noktada, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirirken **tek baÅŸÄ±nÄ±za devam etmemenizi**, diÄŸer yarÄ±ÅŸmacÄ±larla **Discussion (TartÄ±ÅŸma)** forumu Ã¼zerinden iletiÅŸime geÃ§menizi iÃ§tenlikle tavsiye ederiz. Bu forumda yarÄ±ÅŸmaya Ã¶zgÃ¼ sorular sorabilir ve diÄŸer katÄ±lÄ±mcÄ±larÄ±n sorularÄ±nÄ± yanÄ±tlayabilirsiniz.
Ã‡oÄŸu zaman burada, veriyle ilgili belirli problemlere dair faydalÄ± ipuÃ§larÄ± veya kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirmeye yardÄ±mcÄ± olabilecek fikirler bulabilirsiniz.
BirÃ§ok baÅŸarÄ±lÄ± Kaggle kullanÄ±cÄ±sÄ± (*Kaggler*), forumlarda edindikleri fikirlerin kendilerine daha iyi performans saÄŸladÄ±ÄŸÄ±nÄ± ve daha da Ã¶nemlisi, veri bilimi modelleme konusunda Ã§ok ÅŸey Ã¶ÄŸrenmelerine yardÄ±mcÄ± olduÄŸunu belirtmiÅŸtir.

Ã‡Ã¶zÃ¼mÃ¼nÃ¼z hazÄ±r olduÄŸunda, yarÄ±ÅŸmanÄ±n yÃ¶nergelerine uygun ÅŸekilde **Kaggle deÄŸerlendirme sistemine** gÃ¶nderebilirsiniz.
BazÄ± yarÄ±ÅŸmalar Ã§Ã¶zÃ¼mleri **CSV dosyasÄ±** olarak kabul ederken, bazÄ±larÄ± **Kaggle Notebook** Ã¼zerinde kod yazmanÄ±zÄ± ve sonuÃ§larÄ± orada Ã¼retmenizi ister.
YarÄ±ÅŸma sÃ¼resince Ã§Ã¶zÃ¼m gÃ¶ndermeye devam edebilirsiniz.

Her gÃ¶nderim yaptÄ±ÄŸÄ±nÄ±zda, kÄ±sa bir sÃ¼re sonra **liderlik tablosu (leaderboard)** size bir puan ve yarÄ±ÅŸmacÄ±lar arasÄ±ndaki konumunuzu gÃ¶sterecektir (bekleme sÃ¼resi, puan hesaplamasÄ± iÃ§in gereken iÅŸlem sÃ¼resine baÄŸlÄ± olarak deÄŸiÅŸir).
Ancak bu sÄ±ralama yalnÄ±zca yaklaÅŸÄ±k bir gÃ¶stergedir; Ã§Ã¼nkÃ¼ modelinizin performansÄ±nÄ±, test verisinin yalnÄ±zca bir kÄ±smÄ± olan **public test set (genel test kÃ¼mesi)** Ã¼zerinde yansÄ±tÄ±r. Bu kÃ¼medeki sonuÃ§lar yarÄ±ÅŸma boyunca herkesin gÃ¶rebileceÄŸi ÅŸekilde paylaÅŸÄ±lÄ±r.

YarÄ±ÅŸma kapanmadan Ã¶nce, her yarÄ±ÅŸmacÄ± **nihai deÄŸerlendirme** iÃ§in kendi Ã§Ã¶zÃ¼mleri arasÄ±ndan belirli bir sayÄ±da (genellikle iki) Ã§Ã¶zÃ¼m seÃ§ebilir.

![](im/1004.png)

YarÄ±ÅŸma ancak kapandÄ±ktan sonra, yarÄ±ÅŸmacÄ±larÄ±n deÄŸerlendirilmesini istedikleri modeller temel alÄ±narak, **test veri setinin baÅŸka bir kÄ±smÄ±** olan **private test set (Ã¶zel test kÃ¼mesi)** Ã¼zerindeki puanlarÄ± aÃ§Ä±klanÄ±r.
Bu yeni sÄ±ralama tablosu **private leaderboard (Ã¶zel liderlik tablosu)** olarak adlandÄ±rÄ±lÄ±r ve yarÄ±ÅŸmanÄ±n **nihai, gerÃ§ek puanlarÄ±nÄ±** gÃ¶sterir; ancak bu sÄ±ralama henÃ¼z **resmÃ® ve kesin** deÄŸildir.

GerÃ§ekte, Kaggle ekibi her ÅŸeyin doÄŸru olduÄŸunu ve tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n yarÄ±ÅŸma kurallarÄ±na uyduÄŸunu kontrol etmek iÃ§in bir sÃ¼re ayÄ±rÄ±r.
Bir sÃ¼re sonra (ve bazen bazÄ± yarÄ±ÅŸmacÄ±larÄ±n diskalifiye edilmesine baÄŸlÄ± olarak sÄ±ralamalarda deÄŸiÅŸiklikler olduktan sonra), **private leaderboard** resmÃ® ve kesin hale gelir.
Kazananlar aÃ§Ä±klanÄ±r ve birÃ§ok katÄ±lÄ±mcÄ±, yarÄ±ÅŸma tartÄ±ÅŸma forumunda kendi stratejilerini, Ã§Ã¶zÃ¼mlerini ve kodlarÄ±nÄ± paylaÅŸÄ±r.

Bu noktada, diÄŸer katÄ±lÄ±mcÄ±larÄ±n Ã§Ã¶zÃ¼mlerini incelemek ve kendi yaklaÅŸÄ±mÄ±nÄ±zÄ± geliÅŸtirmeye Ã§alÄ±ÅŸmak tamamen size kalmÄ±ÅŸtÄ±r.
Bunu yapmanÄ±zÄ± **ÅŸiddetle tavsiye ederiz**, Ã§Ã¼nkÃ¼ bu sÃ¼reÃ§ Kaggleâ€™daki en Ã¶nemli Ã¶ÄŸrenme kaynaklarÄ±ndan bir diÄŸeridir.

#### Types of competitions and examples *(YarÄ±ÅŸma tÃ¼rleri ve Ã¶rnekleri)*

Kaggle yarÄ±ÅŸmalarÄ±, **yarÄ±ÅŸma kategorilerine** gÃ¶re sÄ±nÄ±flandÄ±rÄ±lÄ±r ve her kategori, yarÄ±ÅŸma biÃ§imi ve beklentiler aÃ§Ä±sÄ±ndan farklÄ±lÄ±k gÃ¶sterir.
Veri tÃ¼rÃ¼, problem zorluÄŸu, verilen Ã¶dÃ¼ller ve yarÄ±ÅŸma dinamikleri bu kategoriler iÃ§inde oldukÃ§a Ã§eÅŸitlidir; bu nedenle her kategorinin ne anlama geldiÄŸini Ã¶nceden anlamak Ã¶nemlidir.

Kaggleâ€™daki yarÄ±ÅŸmalarÄ± filtrelemek iÃ§in kullanabileceÄŸiniz **resmÃ® kategoriler** ÅŸunlardÄ±r:

* **Featured**
* **Masters**
* **Annuals**
* **Research**
* **Recruitment**
* **Getting Started**
* **Playground**
* **Analytics**
* **Community**

---

> ğŸ† Featured (Ã–ne Ã‡Ä±kan) YarÄ±ÅŸmalar

Bunlar en yaygÄ±n yarÄ±ÅŸma tÃ¼rÃ¼dÃ¼r. Genellikle sponsor bir ÅŸirketin iÅŸ ile ilgili bir problemini iÃ§erir ve en iyi performans gÃ¶sterenlere Ã¶dÃ¼l verilir.
Kazananlar, Ã§Ã¶zÃ¼mlerinin **lisanssÄ±z (non-exclusive)** kullanÄ±m hakkÄ±nÄ± sponsor ÅŸirkete verirler; ayrÄ±ca ayrÄ±ntÄ±lÄ± bir rapor hazÄ±rlamalarÄ± ve bazen sponsor ÅŸirketle toplantÄ±lara katÄ±lmalarÄ± gerekebilir.

Kaggleâ€™da neredeyse her zaman Featured yarÄ±ÅŸmalara rastlayabilirsiniz. GÃ¼nÃ¼mÃ¼zde Ã§oÄŸu, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veriler** (metin, gÃ¶rÃ¼ntÃ¼, video, ses gibi) Ã¼zerinde derin Ã¶ÄŸrenme yÃ¶ntemlerinin uygulanmasÄ±na yÃ¶neliktir.
GeÃ§miÅŸte ise daha Ã§ok **tablo biÃ§iminde veriler (tabular data)** Ã¼zerine kurulu yarÄ±ÅŸmalar yapÄ±lÄ±rdÄ± â€” yani veritabanlarÄ±nda bulunan yapÄ±landÄ±rÄ±lmÄ±ÅŸ veriler Ã¼zerinde Ã§alÄ±ÅŸan problemlerdi.
Ä°lk zamanlarda rastgele ormanlar (random forests), daha sonra ise akÄ±llÄ± Ã¶zellik mÃ¼hendisliÄŸiyle birlikte **gradient boosting** yÃ¶ntemleri Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar vermiÅŸtir.
Ancak gÃ¼nÃ¼mÃ¼zde, geliÅŸmiÅŸ yazÄ±lÄ±mlar ve **AutoML** araÃ§larÄ± sayesinde bu tÃ¼r problemlerde yarÄ±ÅŸmalardan elde edilen geliÅŸmeler genellikle marjinaldir.
Buna karÅŸÄ±lÄ±k, **yapÄ±landÄ±rÄ±lmamÄ±ÅŸ veri** dÃ¼nyasÄ±nda iyi bir derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mÃ¼ hÃ¢lÃ¢ bÃ¼yÃ¼k fark yaratabilir.
Ã–rneÄŸin, **BERT** gibi Ã¶nceden eÄŸitilmiÅŸ aÄŸlar, birÃ§ok NLP gÃ¶revinde Ã¶nceki standartlara gÃ¶re Ã§ift haneli performans artÄ±ÅŸlarÄ± saÄŸlamÄ±ÅŸtÄ±r.

---

> ğŸ§  Masters (Ustalar) YarÄ±ÅŸmalarÄ±

ArtÄ±k daha az dÃ¼zenlenmektedir, ancak bunlar **Ã¶zel (invite-only)** yarÄ±ÅŸmalardÄ±r.
AmaÃ§, yalnÄ±zca uzmanlar (genellikle Kaggle sÄ±ralamasÄ±nda **Master** veya **Grandmaster** unvanÄ±na sahip yarÄ±ÅŸmacÄ±lar) iÃ§in yarÄ±ÅŸmalar dÃ¼zenlemektir.

---

> ğŸ“… Annuals (YÄ±llÄ±k) YarÄ±ÅŸmalar

Her yÄ±l belirli dÃ¶nemlerde dÃ¼zenlenen yarÄ±ÅŸmalardÄ±r.
Bunlar arasÄ±nda:

* **Santa Claus Competitions** (genellikle algoritmik optimizasyon problemleri Ã¼zerine),
* **March Machine Learning Mania** (2014â€™ten beri her yÄ±l ABD Kolej Basketbol TurnuvalarÄ± sÄ±rasÄ±nda dÃ¼zenlenir) bulunur.

---

> ğŸ”¬ Research (AraÅŸtÄ±rma) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarÄ±n amacÄ± ticari deÄŸil, **bilimsel veya araÅŸtÄ±rma odaklÄ±dÄ±r**, bazen de kamu yararÄ±na hizmet eder.
Bu nedenle genellikle para Ã¶dÃ¼lÃ¼ sunmazlar.
AyrÄ±ca kazananlardan Ã§Ã¶zÃ¼mlerini **aÃ§Ä±k kaynak (open-source)** olarak paylaÅŸmalarÄ± istenebilir.

Ã–rneÄŸin, **Google Landmark Recognition 2020** ([https://www.kaggle.com/c/landmark-recognition-2020](https://www.kaggle.com/c/landmark-recognition-2020)) yarÄ±ÅŸmasÄ±nda, Ã¼nlÃ¼ (veya pek tanÄ±nmamÄ±ÅŸ) yapÄ±tlarÄ±n fotoÄŸraflarÄ±nÄ± tanÄ±mlamak hedeflenmiÅŸtir.

---

> ğŸ’¼ Recruitment (Ä°ÅŸe AlÄ±m) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar, sponsor ÅŸirketlerin **potansiyel iÅŸ adaylarÄ±nÄ±n yeteneklerini test etmek** iÃ§in dÃ¼zenlenir.
Genellikle tek kiÅŸilik takÄ±mlarla sÄ±nÄ±rlÄ±dÄ±r ve en iyi performans gÃ¶steren yarÄ±ÅŸmacÄ±lara **iÅŸ gÃ¶rÃ¼ÅŸmesi** Ã¶dÃ¼lÃ¼ sunulur.
YarÄ±ÅŸma sonunda, deÄŸerlendirilmek isteyen yarÄ±ÅŸmacÄ±larÄ±n **Ã¶zgeÃ§miÅŸlerini (CV)** yÃ¼klemeleri gerekir.

Ã–rnekler:

* **Facebook Recruiting Competition** ([https://www.kaggle.com/c/FacebookRecruiting](https://www.kaggle.com/c/FacebookRecruiting))
* **Yelp Recruiting Competition** ([https://www.kaggle.com/c/yelp-recruiting](https://www.kaggle.com/c/yelp-recruiting))

---

> ğŸš€ Getting Started (BaÅŸlangÄ±Ã§) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar Ã¶dÃ¼l sunmaz, ancak **yeni baÅŸlayanlarÄ±n** Kaggle prensiplerine ve dinamiklerine alÄ±ÅŸmalarÄ± iÃ§in **kolay ve Ã¶ÄŸretici problemler** iÃ§erir.
Genellikle **yarÄ± kalÄ±cÄ±dÄ±rlar** ve liderlik tablolarÄ± zaman zaman yenilenir.
Makine Ã¶ÄŸrenmesine giriÅŸ yapmak istiyorsanÄ±z, bu yarÄ±ÅŸmalar mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r; Ã§Ã¼nkÃ¼ oldukÃ§a **iÅŸbirlikÃ§i bir ortam** sunarlar ve veri iÅŸleme ile model oluÅŸturma adÄ±mlarÄ±nÄ± gÃ¶steren birÃ§ok **Kaggle Notebook** mevcuttur.

BazÄ± Ã¼nlÃ¼ Getting Started yarÄ±ÅŸmalarÄ±:

* [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer)
* [Titanic â€” Machine Learning from Disaster](https://www.kaggle.com/c/titanic)
* [House Prices â€” Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

---

> ğŸ® Playground (Oyun AlanÄ±) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalar **Getting Started** yarÄ±ÅŸmalarÄ±ndan biraz daha zordur, ancak hÃ¢lÃ¢ Ã¶ÄŸrenme ve pratik yapma odaklÄ±dÄ±r.
Tam Ã¶lÃ§ekli Featured yarÄ±ÅŸmalar kadar baskÄ± oluÅŸturmazlar, fakat bazen rekabet oldukÃ§a kÄ±zÄ±ÅŸabilir.
Ã–dÃ¼ller genellikle **Kaggle logolu hediyelikler (swag: kupa, tiÅŸÃ¶rt, Ã§orap vb.)** veya kÃ¼Ã§Ã¼k miktarlarda paradÄ±r.

ÃœnlÃ¼ bir Playground yarÄ±ÅŸmasÄ± Ã¶rneÄŸi:

* [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats) â€” kÃ¶pekleri ve kedileri ayÄ±rt eden bir algoritma geliÅŸtirme gÃ¶revi.

---

> ğŸ“Š Analytics (Analiz) YarÄ±ÅŸmalarÄ±

Bu yarÄ±ÅŸmalarda deÄŸerlendirme **niteliksel (qualitative)** olup, katÄ±lÄ±mcÄ±lardan fikirler, Ã§Ã¶zÃ¼m taslaklarÄ±, PowerPoint sunumlarÄ±, grafikler vb. hazÄ±rlamalarÄ± beklenir.

---

> ğŸ‘¥ Community (Topluluk) YarÄ±ÅŸmalarÄ±

Eskiden **InClass** olarak bilinen bu yarÄ±ÅŸmalar, **akademik kurumlar** veya bireysel **Kagglerâ€™lar** tarafÄ±ndan dÃ¼zenlenir.
Topluluk yarÄ±ÅŸmalarÄ±nÄ±n duyurusu iÃ§in:
ğŸ”— [https://www.kaggle.com/product-feedback/294337](https://www.kaggle.com/product-feedback/294337)
Kendi yarÄ±ÅŸmanÄ±zÄ± dÃ¼zenleme rehberleri iÃ§in:
ğŸ”— [https://www.kaggle.com/c/about/host](https://www.kaggle.com/c/about/host)
ğŸ”— [https://www.kaggle.com/community-competitions-setup-guide](https://www.kaggle.com/community-competitions-setup-guide)


> **Parul Pandey**
> 
> [https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey)
> 
> 
> 
> Kaggle Notebooks Grandmasterâ€™Ä±, Datasets Masterâ€™Ä± ve H2O.aiâ€™de veri bilimci olan **Parul Pandey** ile analitik yarÄ±ÅŸmalar ve deneyimleri hakkÄ±nda konuÅŸtuk.
> 
> ---
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±n nedir?**
> 
> Veri analizi yapmanÄ±zÄ± ve sonunda kapsamlÄ± bir analiz raporu sunmanÄ±zÄ± gerektiren **Veri AnalitiÄŸi yarÄ±ÅŸmalarÄ±nÄ±** gerÃ§ekten Ã§ok seviyorum. Bunlara *Data Science for Good* (DS4G) yarÄ±ÅŸmalarÄ±, spor analitiÄŸi yarÄ±ÅŸmalarÄ± (Ã¶rneÄŸin NFL) ve genel anket temelli yarÄ±ÅŸmalar dÃ¢hildir. Geleneksel yarÄ±ÅŸmalardan farklÄ± olarak, bu tÃ¼r yarÄ±ÅŸmalarda performansÄ±nÄ±zÄ± baÅŸkalarÄ±yla kÄ±yaslayabileceÄŸiniz bir **liderlik tablosu (leaderboard)** bulunmaz; ayrÄ±ca madalya veya puan da kazanmazsÄ±nÄ±z.
> 
> Ã–te yandan bu yarÄ±ÅŸmalar, veri biliminin Ã§ok yÃ¶nlÃ¼ alanlarÄ±na â€“ veri temizleme, veri madenciliÄŸi, gÃ¶rselleÅŸtirme ve iÃ§gÃ¶rÃ¼ iletimi gibi â€“ dokunan uÃ§tan uca Ã§Ã¶zÃ¼mler gerektirir. Bu tÃ¼r problemler, gerÃ§ek hayattaki senaryolarÄ± taklit etmenizi ve kendi iÃ§gÃ¶rÃ¼nÃ¼zÃ¼, bakÄ±ÅŸ aÃ§Ä±nÄ±zÄ± sunmanÄ±zÄ± saÄŸlar. Tek bir â€œen iyiâ€ Ã§Ã¶zÃ¼m olmayabilir, ancak bu size Ã§eÅŸitli yaklaÅŸÄ±mlarÄ± tartÄ±p deÄŸerlendirerek kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼ze entegre etme fÄ±rsatÄ± verir.
> 
> ---
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinden ne kadar farklÄ±?**
> 
> Ä°lk adÄ±mÄ±m her zaman **EDA (keÅŸifsel veri analizi)** yapmaktÄ±r. Bu, iÅŸ rutinimin de bir parÃ§asÄ±dÄ±r. Genellikle verideki tutarsÄ±zlÄ±klarÄ±, eksik deÄŸerleri, aykÄ±rÄ± noktalarÄ± vb. belirlemek iÃ§in veriyi incelerim; Ã§Ã¼nkÃ¼ bunlar ileride sorun yaratabilir. Sonra **iyi ve gÃ¼venilir bir Ã§apraz doÄŸrulama stratejisi** oluÅŸtururum. ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±nÄ± okur ve diÄŸer kullanÄ±cÄ±larÄ±n paylaÅŸtÄ±ÄŸÄ± Notebookâ€™lara gÃ¶z atarÄ±m. Bu genelde iyi bir baÅŸlangÄ±Ã§ noktasÄ± olur; sonra Ã¶nceki deneyimlerimden edindiÄŸim ÅŸeyleri bu sÃ¼rece eklerim. AyrÄ±ca **model performansÄ±nÄ± izlemek** de Ã§ok Ã¶nemlidir.
> 
> Analitik yarÄ±ÅŸmalar sÃ¶z konusu olduÄŸunda ise problemi genellikle birkaÃ§ adÄ±ma ayÄ±rmayÄ± severim. Ã–rneÄŸin, ilk kÄ±sÄ±m problemi anlamakla ilgilidir ve bu birkaÃ§ gÃ¼n sÃ¼rebilir. SonrasÄ±nda veriyi keÅŸfederim, ardÄ±ndan temel bir baÅŸlangÄ±Ã§ Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururum. Daha sonra bu Ã§Ã¶zÃ¼mÃ¼, her seferinde bir parÃ§a ekleyerek geliÅŸtiririm. Bu, Lego parÃ§alarÄ±nÄ± tek tek ekleyerek son eseri oluÅŸturmak gibidir.
> 
> ---
> 
> **KatÄ±ldÄ±ÄŸÄ±n zorlu bir yarÄ±ÅŸmadan ve bu gÃ¶revi nasÄ±l ele aldÄ±ÄŸÄ±ndan bahseder misin?**
> 
> Daha Ã¶nce de belirttiÄŸim gibi genellikle Analitik yarÄ±ÅŸmalara katÄ±lmayÄ± tercih ediyorum, ama bazen klasik yarÄ±ÅŸmalarda da ÅŸansÄ±mÄ± deniyorum. Ã–zellikle **Environmental Insights Explorer** adlÄ± *Data Science for Good* yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/ds4g-environmental-insightsexplorer](https://www.kaggle.com/c/ds4g-environmental-insightsexplorer)) Ã§ok ilgimi Ã§ekmiÅŸti. GÃ¶rev, mevcut metodolojilerdeki emisyon katsayÄ±larÄ±nÄ± hesaplamak yerine, **uzaktan algÄ±lama (remote sensing)** tekniklerini kullanarak Ã§evresel emisyonlarÄ± anlamaktÄ±.
> 
> Beni en Ã§ok etkileyen ÅŸey, bu yarÄ±ÅŸmanÄ±n ele aldÄ±ÄŸÄ± konuydu. Gezegenimiz iklim deÄŸiÅŸikliÄŸiyle mÃ¼cadele ediyor ve bu yarÄ±ÅŸma tam da bu konuya odaklanmÄ±ÅŸtÄ±. YarÄ±ÅŸma iÃ§in araÅŸtÄ±rma yaparken, **uydu gÃ¶rÃ¼ntÃ¼leme teknolojilerindeki ilerlemeyi** gÃ¶rÃ¼nce hayran kaldÄ±m. Bu sayede bu konuyu daha derinlemesine anlama fÄ±rsatÄ± buldum. Landsat, Modis ve Sentinel gibi uydularÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve bu verilerin nasÄ±l eriÅŸilebilir hale getirildiÄŸini Ã¶ÄŸrendim. Bu yarÄ±ÅŸma, Ã¶nceden Ã§ok az bilgim olan bir alan hakkÄ±nda bilgi edinmemi saÄŸlayan harika bir deneyimdi.
> 
> ---
> 
> **YarÄ±ÅŸma biÃ§imleri Ã¼zerine**
> 
> Kaggle yarÄ±ÅŸmalarÄ±nÄ±n kendi iÃ§inde farklÄ± biÃ§imleri de vardÄ±r. En yaygÄ±n olanÄ±, katÄ±lÄ±mcÄ±nÄ±n Ã§Ã¶zÃ¼mÃ¼nÃ¼ sunup deÄŸerlendirildiÄŸi **â€œbasit formatâ€tÄ±r.** Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸmalarda**, yarÄ±ÅŸma ikiye ayrÄ±lÄ±r: Ä°lk kÄ±sÄ±m tamamlandÄ±ktan sonra ikinci kÄ±sma Ã¶zel bir veri seti yalnÄ±zca ilk kÄ±sÄ±m katÄ±lÄ±mcÄ±larÄ±na verilir. Bu format, yarÄ±ÅŸmacÄ±larÄ±n hile yapma ihtimalini azaltmak iÃ§in tasarlanmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼reliÄŸine eriÅŸilebilen, daha Ã¶nce hiÃ§ gÃ¶rÃ¼lmemiÅŸ bir test setinde yapÄ±lÄ±r. Bu nedenle katÄ±lÄ±mcÄ±larÄ±n deneme sayÄ±sÄ± ve zamanÄ± daha sÄ±nÄ±rlÄ±dÄ±r.
> 
> ---
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nda bilmek isteyeceÄŸin ÅŸey ne olurdu?**
> 
> Kaggleâ€™daki ilk yÄ±llarÄ±mda yaptÄ±ÄŸÄ±m bazÄ± hatalardan bahsedebilirim.
> 
> Ã–ncelikle, Ã§oÄŸu yeni baÅŸlayan **Kaggleâ€™Ä± sadece yarÄ±ÅŸma platformu** olarak gÃ¶rÃ¼r. EÄŸer yarÄ±ÅŸmalarÄ± seviyorsanÄ±z, burada fazlasÄ±yla var; ama Kaggle aynÄ± zamanda baÅŸka alanlarda da katkÄ± yapabileceÄŸiniz bir platformdur. Kod yazabilir, baÅŸkalarÄ±yla paylaÅŸabilir, saÄŸlÄ±klÄ± tartÄ±ÅŸmalara katÄ±labilir ve aÄŸÄ±nÄ±zÄ± geniÅŸletebilirsiniz. Toplulukla kaliteli veri setleri oluÅŸturup paylaÅŸabilirsiniz. BaÅŸlangÄ±Ã§ta Kaggleâ€™Ä± yalnÄ±zca veri seti indirmek iÃ§in kullanÄ±yordum; ancak birkaÃ§ yÄ±l Ã¶nce aktif oldum. Geriye dÃ¶nÃ¼p baktÄ±ÄŸÄ±mda, daha Ã¶nce ne kadar yanÄ±ldÄ±ÄŸÄ±mÄ± gÃ¶rÃ¼yorum.
> 
> BirÃ§ok kiÅŸi yarÄ±ÅŸmalardan Ã§ekiniyor. Ã–nce platforma alÄ±ÅŸÄ±p, sonra yavaÅŸ yavaÅŸ yarÄ±ÅŸmalara katÄ±labilirsiniz.
> 
> AyrÄ±ca birÃ§ok kiÅŸi **tek baÅŸÄ±na Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in motivasyonunu kaybedip bÄ±rakÄ±yor.** Kaggleâ€™da takÄ±m kurmanÄ±n birÃ§ok gÃ¶rÃ¼nmeyen avantajÄ± var. TakÄ±m Ã§alÄ±ÅŸmasÄ± Ã¶ÄŸrenmenizi, deneyim paylaÅŸmanÄ±zÄ± ve sÄ±nÄ±rlÄ± bir zaman diliminde ortak bir hedefe ulaÅŸmayÄ± Ã¶ÄŸretir.
> 
> ---
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± da kullanÄ±yor musun? Bunlar Kaggle ile nasÄ±l kÄ±yaslanÄ±r?**
> 
> Åu anda zamanÄ±mÄ±n Ã§oÄŸunu Kaggleâ€™a ayÄ±rÄ±yorum, ancak geÃ§miÅŸte **Zindi** adlÄ± platformu da kullandÄ±m. Zindi, Afrika odaklÄ± veri bilimi yarÄ±ÅŸmalarÄ±na yoÄŸunlaÅŸan bir platform. Afrikaâ€™ya Ã¶zel veri setlerine eriÅŸmek iÃ§in harika bir yer.
> 
> Kaggle Ã§ok yÃ¶nlÃ¼ bir platform olsa da, dÃ¼nyanÄ±n farklÄ± bÃ¶lgelerinden gelen problem ifadeleri konusunda eksiklikler var. Son zamanlarda bu Ã§eÅŸitlilik artmaya baÅŸladÄ±; Ã¶rneÄŸin **chaii yarÄ±ÅŸmasÄ±** â€“ Hint dillerine odaklanan bir NLP yarÄ±ÅŸmasÄ± â€“ buna iyi bir Ã¶rnektir. Benzer ÅŸekilde, farklÄ± Ã¼lkelere odaklanan yarÄ±ÅŸmalarÄ±n da hem araÅŸtÄ±rma hem de genel veri bilimi topluluÄŸu iÃ§in faydalÄ± olacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼yorum.

Kaggle yarÄ±ÅŸmalarÄ±nÄ±n bu sÄ±nÄ±flandÄ±rmasÄ±nÄ±n Ã¶tesinde, yarÄ±ÅŸmalarÄ±n farklÄ± **formatlarda** dÃ¼zenlenebileceÄŸini de dikkate almak gerekir.
En yaygÄ±n format, daha Ã¶nce aÃ§Ä±klandÄ±ÄŸÄ± gibi, bir Ã§Ã¶zÃ¼m sunduÄŸunuz ve bu Ã§Ã¶zÃ¼mÃ¼n deÄŸerlendirildiÄŸi **â€œbasit (simple)â€ formattÄ±r.**
Daha geliÅŸmiÅŸ olan **iki aÅŸamalÄ± yarÄ±ÅŸma (two-stage competition)** formatÄ±nda ise yarÄ±ÅŸma iki bÃ¶lÃ¼me ayrÄ±lÄ±r. Son veri seti yalnÄ±zca ilk bÃ¶lÃ¼m tamamlandÄ±ktan sonra ve sadece bu ilk bÃ¶lÃ¼me katÄ±lan yarÄ±ÅŸmacÄ±lara sunulur.
Bu iki aÅŸamalÄ± yarÄ±ÅŸma formatÄ±, bazÄ± yarÄ±ÅŸmacÄ±larÄ±n **hile yapma veya kurallarÄ± ihlal etme olasÄ±lÄ±ÄŸÄ±nÄ± azaltmak** amacÄ±yla ortaya Ã§Ä±kmÄ±ÅŸtÄ±r; Ã§Ã¼nkÃ¼ deÄŸerlendirme, yalnÄ±zca kÄ±sa bir sÃ¼re iÃ§in eriÅŸilebilen ve daha Ã¶nce hiÃ§ test edilmemiÅŸ bir test seti Ã¼zerinde yapÄ±lÄ±r.
Orijinal Kaggle yarÄ±ÅŸma formatÄ±nÄ±n aksine, bu durumda yarÄ±ÅŸmacÄ±larÄ±n **Ã§ok daha az zamanÄ±** ve test setindeki Ã¶rÃ¼ntÃ¼leri (pattern) keÅŸfetmek iÃ§in **Ã§ok daha az sayÄ±da gÃ¶nderim hakkÄ±** vardÄ±r.

AynÄ± nedenle, son zamanlarda **Code yarÄ±ÅŸmalarÄ±** da ortaya Ã§Ä±kmÄ±ÅŸtÄ±r.
Bu yarÄ±ÅŸmalarda tÃ¼m gÃ¶nderimler doÄŸrudan bir **Kaggle Notebook** Ã¼zerinden yapÄ±lÄ±r ve herhangi bir dÄ±ÅŸ dosya yÃ¼kleme seÃ§eneÄŸi devre dÄ±ÅŸÄ± bÄ±rakÄ±lmÄ±ÅŸtÄ±r.

Kaggle yarÄ±ÅŸma kariyerlerinin farklÄ± aÅŸamalarÄ±nda olan kullanÄ±cÄ±larÄ±n her tÃ¼r yarÄ±ÅŸmaya katÄ±lmasÄ±nda hiÃ§bir kÄ±sÄ±tlama yoktur.
Ancak, **veri bilimi konusundaki deneyim dÃ¼zeyinize** ve **hesaplama kaynaklarÄ±nÄ±za** baÄŸlÄ± olarak, belirli yarÄ±ÅŸma tÃ¼rleri veya formatlarÄ± lehine veya aleyhine bazÄ± Ã¶nerilerimiz vardÄ±r:

* **Tamamen yeni baÅŸlayanlar** iÃ§in, *Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± iyi bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r.
  Bu yarÄ±ÅŸmalar, yÃ¼ksek rekabet baskÄ±sÄ± olmadan Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmenizi saÄŸlar.
  Bununla birlikte, birÃ§ok yeni baÅŸlayan da *Featured* veya *Research* yarÄ±ÅŸmalarÄ±ndan baÅŸlamÄ±ÅŸ ve rekabet baskÄ±sÄ±nÄ±n altÄ±nda daha hÄ±zlÄ± Ã¶ÄŸrendiklerini fark etmiÅŸtir.
  Bu nedenle Ã¶nerimiz, **Ã¶ÄŸrenme tarzÄ±nÄ±za gÃ¶re karar vermenizdir:**

  * BazÄ± Kaggle kullanÄ±cÄ±larÄ± keÅŸfederek ve iÅŸ birliÄŸi yaparak Ã¶ÄŸrenir (*Getting Started* veya *Playground* yarÄ±ÅŸmalarÄ± bu kiÅŸiler iÃ§in idealdir).
  * DiÄŸerleri ise hÄ±zlÄ± tempolu bir yarÄ±ÅŸmanÄ±n rekabet ortamÄ±nda motive olur.

* *Featured* ve *Research* yarÄ±ÅŸmalarÄ±nda ise ÅŸunu da gÃ¶z Ã¶nÃ¼nde bulundurmak gerekir:
  Bu yarÄ±ÅŸmalar genellikle yapay zekÃ¢ ve makine Ã¶ÄŸrenmesinin **uÃ§ (deneysel) uygulamalarÄ±yla** ilgilidir.
  DolayÄ±sÄ±yla bu yarÄ±ÅŸmalarda baÅŸarÄ±lÄ± olabilmek iÃ§in ya bu alanda **saÄŸlam bir altyapÄ±ya sahip olmanÄ±z** ya da yarÄ±ÅŸmanÄ±n uygulama alanÄ±yla ilgili araÅŸtÄ±rmalarÄ± Ã¶ÄŸrenmeye istekli olmanÄ±z gerekir.

Son olarak, Ã§oÄŸu yarÄ±ÅŸmanÄ±n, birÃ§ok veri bilimcisinin iÅŸ yerinde eriÅŸemediÄŸi **hesaplama kaynaklarÄ±na** ihtiyaÃ§ duyduÄŸunu unutmayÄ±n.
Kaggle dÄ±ÅŸÄ±ndaki bulut platformlarÄ±nÄ± kullanÄ±rsanÄ±z bu, **artan maliyetlere** yol aÃ§abilir.
Bu nedenle, **Code yarÄ±ÅŸmalarÄ±** veya **zaman ve kaynak sÄ±nÄ±rlamalarÄ± olan yarÄ±ÅŸmalar**, tÃ¼m katÄ±lÄ±mcÄ±larÄ± aynÄ± kaynak dÃ¼zeyine getirmeyi amaÃ§ladÄ±klarÄ± iÃ§in Ã§abalarÄ±nÄ±zÄ± yoÄŸunlaÅŸtÄ±rmak aÃ§Ä±sÄ±ndan ideal bir seÃ§enek olabilir.

#### Submission and leaderboard dynamics *(GÃ¶nderim ve liderlik tablosu dinamikleri)*

Kaggleâ€™Ä±n Ã§alÄ±ÅŸma biÃ§imi basit gÃ¶rÃ¼nebilir: Test seti katÄ±lÄ±mcÄ±lardan gizlenir; modelinizi eÄŸitirsiniz; eÄŸer modeliniz test setindeki sonuÃ§larÄ± en iyi ÅŸekilde tahmin ederse yÃ¼ksek puan alÄ±r ve muhtemelen kazanÄ±rsÄ±nÄ±z.
Ne yazÄ±k ki, bu tanÄ±m Kaggle yarÄ±ÅŸmalarÄ±nÄ±n iÃ§ iÅŸleyiÅŸini **fazla basitleÅŸtirilmiÅŸ** bir ÅŸekilde aÃ§Ä±klar.
Bu aÃ§Ä±klama, yarÄ±ÅŸmacÄ±larÄ±n doÄŸrudan ve dolaylÄ± etkileÅŸimleriyle ilgili dinamikleri ya da karÅŸÄ± karÅŸÄ±ya olduÄŸunuz problemin, eÄŸitim ve test setinin **ince ayrÄ±ntÄ±larÄ±nÄ± (nÃ¼anslarÄ±nÄ±)** dikkate almaz.

##### Explaining the Common Task Framework paradigm *(Ortak GÃ¶rev Ã‡erÃ§evesi paradigmasÄ±nÄ±n aÃ§Ä±klanmasÄ±)*

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair daha kapsamlÄ± bir aÃ§Ä±klama, **Stanford Ãœniversitesi Ä°statistik ProfesÃ¶rÃ¼ David Donoho** tarafÄ±ndan *50 Years of Data Science* (Veri Biliminin 50 YÄ±lÄ±) adlÄ± makalesinde verilmiÅŸtir.
Bu makale ilk olarak *Journal of Computational and Graphical Statistics* dergisinde yayÄ±mlanmÄ±ÅŸ, ardÄ±ndan MIT Bilgisayar Bilimi ve Yapay ZekÃ¢ LaboratuvarÄ± sitesinde paylaÅŸÄ±lmÄ±ÅŸtÄ±r (bkz. [http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf](http://courses.csail.mit.edu/18.337/2015/docs/50YearsDataScience.pdf)).

ProfesÃ¶r Donoho doÄŸrudan Kaggleâ€™dan deÄŸil, genel olarak **veri bilimi yarÄ±ÅŸma platformlarÄ±ndan** bahseder.
BilgisayarlÄ± dilbilimci **Mark Liberman**â€™dan alÄ±ntÄ± yaparak, veri bilimi yarÄ±ÅŸmalarÄ±nÄ± ve platformlarÄ±nÄ± **â€œCommon Task Framework (CTF)â€ â€” Ortak GÃ¶rev Ã‡erÃ§evesi** paradigmasÄ±nÄ±n bir parÃ§asÄ± olarak tanÄ±mlar.
Bu paradigma, son on yÄ±llarda birÃ§ok alanda veri biliminin sessiz ama istikrarlÄ± bir ÅŸekilde ilerlemesini saÄŸlamÄ±ÅŸtÄ±r.

Donoho, CTFâ€™nin veri bilimi problemlerine **ampirik (deneysel)** aÃ§Ä±dan Ã§Ã¶zÃ¼m getirmede son derece etkili olduÄŸunu sÃ¶yler ve bunu desteklemek iÃ§in **Netflix yarÄ±ÅŸmasÄ±** ile Ã§eÅŸitli **DARPA yarÄ±ÅŸmalarÄ±nÄ±** baÅŸarÄ±lÄ± Ã¶rnekler olarak gÃ¶sterir.
CTF paradigmasÄ±, birÃ§ok alanda en iyi Ã§Ã¶zÃ¼mleri yeniden ÅŸekillendirmeye katkÄ±da bulunmuÅŸtur.

---

**CTFâ€™nin bileÅŸenleri ve â€œgizli sosuâ€**

Bir CTF, bazÄ± bileÅŸenlerden ve â€œgizli bir sostanâ€ oluÅŸur.
BileÅŸenler ÅŸunlardÄ±r:

1. Herkese aÃ§Ä±k bir veri seti ve bununla iliÅŸkili bir tahmin gÃ¶revi,
2. Bu gÃ¶reve en iyi tahmini Ã¼retmek iÃ§in ortak bir amaÃ§la Ã§alÄ±ÅŸan yarÄ±ÅŸmacÄ±lar,
3. KatÄ±lÄ±mcÄ±larÄ±n tahminlerini adil ve objektif biÃ§imde puanlayan, ancak Ã§Ã¶zÃ¼me dair fazla ipucu vermeyen (ya da en azÄ±ndan bunu sÄ±nÄ±rlayan) bir deÄŸerlendirme sistemi.

Bu sistem, gÃ¶rev aÃ§Ä±k ÅŸekilde tanÄ±mlandÄ±ÄŸÄ±nda ve veri kaliteli olduÄŸunda en iyi ÅŸekilde Ã§alÄ±ÅŸÄ±r.
Zaman iÃ§inde Ã§Ã¶zÃ¼mlerin performansÄ± kÃ¼Ã§Ã¼k artÄ±ÅŸlarla geliÅŸir ve sonunda bir **asimptota (doyum noktasÄ±na)** ulaÅŸÄ±r.
Bu sÃ¼reÃ§, katÄ±lÄ±mcÄ±lar arasÄ±nda belli bir dÃ¼zeyde paylaÅŸÄ±mÄ±n teÅŸvik edilmesiyle hÄ±zlanabilir.
Kaggleâ€™da bu paylaÅŸÄ±m; **tartÄ±ÅŸmalar, paylaÅŸÄ±lan Kaggle Notebookâ€™larÄ±** ve **Datasets** bÃ¶lÃ¼mÃ¼ndeki ek veriler aracÄ±lÄ±ÄŸÄ±yla gerÃ§ekleÅŸir.

CTF paradigmasÄ±na gÃ¶re, bir yarÄ±ÅŸmadaki **rekabet baskÄ±sÄ±**, Ã§Ã¶zÃ¼mlerin sÃ¼rekli olarak geliÅŸmesi iÃ§in tek baÅŸÄ±na yeterlidir.
Bu rekabet baskÄ±sÄ±, katÄ±lÄ±mcÄ±lar arasÄ±nda belli Ã¶lÃ§Ã¼de **bilgi paylaÅŸÄ±mÄ±yla** birleÅŸtiÄŸinde, geliÅŸme Ã§ok daha hÄ±zlÄ± gerÃ§ekleÅŸir.
Ä°ÅŸte bu nedenle Kaggle, paylaÅŸÄ±mÄ± teÅŸvik eden birÃ§ok Ã¶dÃ¼l ve mekanizma getirmiÅŸtir.

---

**CTFâ€™nin gizli sosu: rekabetin kendisi**

CTF paradigmasÄ±ndaki â€œgizli sosâ€, **bizzat yarÄ±ÅŸmanÄ±n kendisidir**.
Bu yapÄ±, ampirik performansÄ±n artÄ±rÄ±lmasÄ±nÄ±n hedeflendiÄŸi pratik bir problem Ã§erÃ§evesinde, her zaman yeni **Ã¶lÃ§Ã¼tlerin (benchmark)**, **veri ve modelleme Ã§Ã¶zÃ¼mlerinin**, ve genel anlamda **makine Ã¶ÄŸrenmesinin daha iyi uygulanma biÃ§imlerinin** ortaya Ã§Ä±kmasÄ±nÄ± saÄŸlar.

Bir yarÄ±ÅŸma, dolayÄ±sÄ±yla bir tahmin problemini Ã§Ã¶zmenin yeni yollarÄ±nÄ±, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** iÃ§in yeni yÃ¶ntemleri ve yeni **algoritmik veya modelleme Ã§Ã¶zÃ¼mlerini** sunabilir.
Ã–rneÄŸin, **derin Ã¶ÄŸrenme (deep learning)** yalnÄ±zca akademik araÅŸtÄ±rmalardan doÄŸmamÄ±ÅŸtÄ±r; tersine, etkinliÄŸini kanÄ±tlayan baÅŸarÄ±lÄ± yarÄ±ÅŸmalar sayesinde bÃ¼yÃ¼k bir ivme kazanmÄ±ÅŸtÄ±r.
(Ã–rneÄŸin, Geoffrey Hinton ekibinin kazandÄ±ÄŸÄ± **Merck yarÄ±ÅŸmasÄ±nÄ±** hatÄ±rlayalÄ±m: [https://www.kaggle.com/c/MerckActivity/overview/winners](https://www.kaggle.com/c/MerckActivity/overview/winners)).

---

**CTF ve aÃ§Ä±k yazÄ±lÄ±m hareketi**

**AÃ§Ä±k kaynak yazÄ±lÄ±m hareketi** ile birleÅŸtiÄŸinde (Ã¶rneÄŸin Scikit-learn, TensorFlow veya PyTorch gibi gÃ¼Ã§lÃ¼ analitik araÃ§lara herkesin eriÅŸebilmesi), CTF paradigmasÄ± Ã§ok daha iyi sonuÃ§lar Ã¼retir.
Bunun nedeni, tÃ¼m yarÄ±ÅŸmacÄ±larÄ±n baÅŸlangÄ±Ã§ta **aynÄ± dÃ¼zeyde olanaklara sahip** olmasÄ±dÄ±r.

Ancak, bir yarÄ±ÅŸmadaki Ã§Ã¶zÃ¼mÃ¼n **Ã¶zel donanÄ±m veya yÃ¼ksek iÅŸlem gÃ¼cÃ¼ne** dayanmasÄ±, elde edilebilecek sonuÃ§larÄ± sÄ±nÄ±rlayabilir.
Ã‡Ã¼nkÃ¼ bu durum, bu tÃ¼r kaynaklara eriÅŸimi olmayan yarÄ±ÅŸmacÄ±larÄ±n doÄŸru ÅŸekilde katÄ±lÄ±m gÃ¶stermesini ya da diÄŸer katÄ±lÄ±mcÄ±lar Ã¼zerinde **rekabet baskÄ±sÄ±** oluÅŸturarak dolaylÄ± katkÄ± saÄŸlamasÄ±nÄ± engelleyebilir.

Ä°ÅŸte bu nedenle Kaggle, yarÄ±ÅŸmalara katÄ±lanlar iÃ§in **Ã¼cretsiz bulut hizmetleri** (Ã¶rneÄŸin **Kaggle Notebooks**) sunmaya baÅŸlamÄ±ÅŸtÄ±r.
Bu uygulama, Ã¶zellikle donanÄ±m yoÄŸun yarÄ±ÅŸmalarda (Ã¶rneÄŸin derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ± gibi) bazÄ± farklarÄ± azaltabilir ve genel anlamda rekabeti artÄ±rabilir.

##### Understanding what can go wrong in a competition *(Bir yarÄ±ÅŸmada nelerin ters gidebileceÄŸini anlamak)*

**CTF ParadigmasÄ± ve YarÄ±ÅŸma BaÅŸarÄ±sÄ±zlÄ±klarÄ±nÄ±n Nedenleri**

CTF paradigmasÄ±na dair Ã¶nceki aÃ§Ä±klamamÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurursak, bir yarÄ±ÅŸmanÄ±n tek ihtiyacÄ± uygun bir platformda dÃ¼zenlenmekmiÅŸ gibi gÃ¶rÃ¼nebilir. BÃ¶yle olursa, katÄ±lÄ±mcÄ±lar iÃ§in olumlu bir katÄ±lÄ±m ve sponsor ÅŸirket iÃ§in olaÄŸanÃ¼stÃ¼ modeller gibi iyi sonuÃ§larÄ±n kendiliÄŸinden ortaya Ã§Ä±kacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

Ancak, hem katÄ±lÄ±mcÄ±lar hem de yarÄ±ÅŸmayÄ± dÃ¼zenleyen kurum aÃ§Ä±sÄ±ndan **hayal kÄ±rÄ±klÄ±ÄŸÄ±na yol aÃ§abilecek** bazÄ± durumlar da meydana gelebilir:

* Veri sÄ±zÄ±ntÄ±sÄ± (data leakage)
* Liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼m denemesi (probing)
* AÅŸÄ±rÄ± uyum (overfitting) ve buna baÄŸlÄ± liderlik tablosu deÄŸiÅŸimleri
* Ã–zel paylaÅŸÄ±m (private sharing)

---

**Veri SÄ±zÄ±ntÄ±sÄ± (Data Leakage)**

**Veri sÄ±zÄ±ntÄ±sÄ±**, Ã§Ã¶zÃ¼mÃ¼n bir kÄ±smÄ±nÄ±n bizzat verinin kendisinden geri izlenebilmesi durumudur.
Ã–rneÄŸin, bazÄ± deÄŸiÅŸkenler hedef deÄŸiÅŸkenden (target variable) sonra oluÅŸmuÅŸ olabilir ve bu da hedef hakkÄ±nda bilgi sÄ±zdÄ±rÄ±r.

Bu durum, Ã¶rneÄŸin dolandÄ±rÄ±cÄ±lÄ±k tespitinde, dolandÄ±rÄ±cÄ±lÄ±k gerÃ§ekleÅŸtikten sonra gÃ¼ncellenen deÄŸiÅŸkenleri kullandÄ±ÄŸÄ±nÄ±zda; veya satÄ±ÅŸ tahmini yaparken, bir Ã¼rÃ¼nÃ¼n **gerÃ§ek daÄŸÄ±tÄ±m bilgilerini** iÅŸlediÄŸinizde (daha fazla daÄŸÄ±tÄ±m â†’ daha fazla talep â†’ daha fazla satÄ±ÅŸ) ortaya Ã§Ä±kar.

BaÅŸka bir Ã¶rnek de, **eÄŸitim ve test Ã¶rneklerinin tahmin edilebilir bir sÄ±rada dÃ¼zenlenmiÅŸ olmasÄ±** ya da Ã¶rnek kimliklerinin (identifier) deÄŸerlerinin Ã§Ã¶zÃ¼me dair ipuÃ§larÄ± iÃ§ermesidir.
Ã–rneÄŸin, kimlik numarasÄ± hedef deÄŸiÅŸkenin sÄ±rasÄ±na gÃ¶re belirlenmiÅŸse ya da kimlik deÄŸeri zamanla iliÅŸkiliyse ve zaman hedef deÄŸiÅŸkenin olasÄ±lÄ±ÄŸÄ±nÄ± etkiliyorsa bu da bir sÄ±zÄ±ntÄ±dÄ±r.

Bu tÃ¼r veri sÄ±zÄ±ntÄ±larÄ±na, bazÄ± yarÄ±ÅŸmacÄ±lar tarafÄ±ndan **â€œaltÄ±n Ã¶zellikler (golden features)â€** adÄ± verilir â€” Ã§Ã¼nkÃ¼ verideki bu tÃ¼r kÃ¼Ã§Ã¼k ipuÃ§larÄ±nÄ± fark etmek, katÄ±lÄ±mcÄ±lar iÃ§in adeta altÄ±n deÄŸerinde Ã¶dÃ¼ller kazandÄ±rabilir.
Ancak bu durum genellikle **yeniden kullanÄ±labilir olmayan Ã§Ã¶zÃ¼mler** Ã¼retir.
Bu da sponsor iÃ§in **optimal olmayan sonuÃ§lar** anlamÄ±na gelir, ancak en azÄ±ndan sponsor hangi deÄŸiÅŸkenlerin sÄ±zÄ±ntÄ±ya yol aÃ§abileceÄŸini Ã¶ÄŸrenmiÅŸ olur.

---

**Liderlik Tablosu Ãœzerinden Ã‡Ã¶zÃ¼m Denemesi (Leaderboard Probing)**

Bir diÄŸer problem, **liderlik tablosu Ã¼zerinden Ã§Ã¶zÃ¼mÃ¼ test etmek veya â€œdeÅŸifre etmekâ€** olasÄ±lÄ±ÄŸÄ±dÄ±r.
Bu durumda, yarÄ±ÅŸmacÄ±lar deÄŸerlendirme metriklerinden yararlanarak sÃ¼rekli denemeler yapabilir ve bu yolla Ã§Ã¶zÃ¼m hakkÄ±nda bilgi elde edebilir.
Yine bu tÃ¼r Ã§Ã¶zÃ¼mler, farklÄ± koÅŸullarda tamamen **kullanÄ±lamaz** hale gelir.

Bunun aÃ§Ä±k bir Ã¶rneÄŸi **â€œDonâ€™t Overfit IIâ€** yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r.
Kazanan katÄ±lÄ±mcÄ± **Zachary Mayers**, her bir deÄŸiÅŸkeni tek tek gÃ¶ndererek her birinin model Ã¼zerindeki etkisini analiz etmiÅŸ ve bu yolla modelinin katsayÄ±larÄ±nÄ± doÄŸru tahmin edebilmiÅŸtir.
(Zachâ€™Ä±n detaylÄ± Ã§Ã¶zÃ¼mÃ¼nÃ¼ burada okuyabilirsiniz: [https://www.kaggle.com/c/dont-overfit-ii/discussion/91766](https://www.kaggle.com/c/dont-overfit-ii/discussion/91766))

Genellikle **zaman serisi problemleri** veya test verisinde sistematik deÄŸiÅŸimler olan diÄŸer problemler, bu tÃ¼r probingâ€™den ciddi ÅŸekilde etkilenebilir.
Ã‡Ã¼nkÃ¼ bu durum, yarÄ±ÅŸmacÄ±larÄ±n tahminlerini Ã¶rneÄŸin sabit bir sayÄ± ile Ã§arpmak gibi bir **son iÅŸleme (post-processing)** adÄ±mÄ±yla puanlarÄ±nÄ± artÄ±rmalarÄ±na olanak tanÄ±yabilir.

---

**Liderlik Tablosuna AÅŸÄ±rÄ± GÃ¼venme ve AÅŸÄ±rÄ± Uyum (Overfitting)**

Liderlik tablosuna aÅŸÄ±rÄ± gÃ¼venmek, bir baÅŸka tÃ¼r **aÅŸÄ±rÄ± uyum (overfitting)** Ã¶rneÄŸidir.
KatÄ±lÄ±mcÄ±lar kendi doÄŸrulama testlerinden Ã§ok liderlik tablosundaki geri bildirimlere gÃ¶re hareket ettiklerinde bu durum ortaya Ã§Ä±kar.

Bazen bu durum yarÄ±ÅŸmanÄ±n **tamamen baÅŸarÄ±sÄ±z olmasÄ±na**, yani nihai liderlik tablosunda **beklenmedik ve rastlantÄ±sal sÄ±ralama deÄŸiÅŸikliklerine (shake-up)** yol aÃ§abilir.
BÃ¶yle bir durumda kazanan Ã§Ã¶zÃ¼mler, aslÄ±nda probleme uygun olmayan veya tamamen tesadÃ¼fi Ã§Ã¶zÃ¼mler olabilir.

Bu tÃ¼r olaylar, **eÄŸitim seti ile test seti arasÄ±ndaki farklarÄ± analiz eden** bazÄ± tekniklerin geliÅŸtirilmesine yol aÃ§mÄ±ÅŸtÄ±r.
Bu tÃ¼r analizlere **adversarial testing** denir ve liderlik tablosuna ne kadar gÃ¼venileceÄŸi veya eÄŸitim ve test setleri arasÄ±nda tamamen kaÃ§Ä±nÄ±lmasÄ± gereken Ã¶zellikler olup olmadÄ±ÄŸÄ± konusunda fikir verir.
Ã–rnek olarak, **Bojan Tunguz**â€™un ÅŸu Notebookâ€™una gÃ¶z atabilirsiniz:
[https://www.kaggle.com/tunguz/adversarial-ieee](https://www.kaggle.com/tunguz/adversarial-ieee).

---

**Overfittingâ€™e KarÅŸÄ± Savunma Stratejileri**

Liderlik tablosuna aÅŸÄ±rÄ± uyumu Ã¶nlemenin bir baÅŸka yolu, **gÃ¼venli stratejiler** kullanmaktÄ±r.
Ã–rneÄŸin, genellikle her katÄ±lÄ±mcÄ±nÄ±n **final deÄŸerlendirmesi iÃ§in iki Ã§Ã¶zÃ¼m** gÃ¶ndermesine izin verilir.
Bu durumda iyi bir strateji, birini liderlik tablosuna gÃ¶re en baÅŸarÄ±lÄ± olan Ã§Ã¶zÃ¼m olarak, diÄŸerini ise **kendi Ã§apraz doÄŸrulama testlerinde** en iyi performans gÃ¶steren Ã§Ã¶zÃ¼m olarak gÃ¶ndermektir.

Liderlik tablosu probingâ€™i ve overfittingâ€™i Ã¶nlemek iÃ§in Kaggle, daha Ã¶nce de bahsettiÄŸimiz gibi, **iki aÅŸamalÄ± deÄŸerlendirme sistemi** iÃ§eren **Code yarÄ±ÅŸmalarÄ±na** yÃ¶nelik Ã§eÅŸitli yenilikler getirmiÅŸtir.
Bu yarÄ±ÅŸmalarda katÄ±lÄ±mcÄ±lar test verisini hiÃ§ gÃ¶rmedikleri iÃ§in, kendi **yerel doÄŸrulama testlerine** daha fazla Ã¶nem vermek zorunda kalÄ±rlar.

---

**Ã–zel PaylaÅŸÄ±m (Private Sharing) ve Etik DÄ±ÅŸÄ± DavranÄ±ÅŸlar**

Bir yarÄ±ÅŸmayÄ± bozabilecek bir diÄŸer unsur, **Ã¶zel paylaÅŸÄ±m (private sharing)** yani fikir ve Ã§Ã¶zÃ¼mlerin yalnÄ±zca kapalÄ± bir grup arasÄ±nda paylaÅŸÄ±lmasÄ±dÄ±r.
Buna ek olarak, **birden fazla hesapla yarÄ±ÅŸmak**, **birden fazla takÄ±ma katÄ±lÄ±p fikir Ã§almak** gibi etik dÄ±ÅŸÄ± davranÄ±ÅŸlar da olabilir.

Bu tÃ¼r durumlar, bazÄ± katÄ±lÄ±mcÄ±lar iÃ§in avantaj yaratÄ±rken Ã§oÄŸunluk iÃ§in dezavantaj doÄŸurur â€” yani **bilgi asimetrisi** oluÅŸur.
BÃ¶ylece, yarÄ±ÅŸma boyunca paylaÅŸÄ±m eksik kalÄ±r ve az sayÄ±da takÄ±m tam rekabet baskÄ±sÄ± yaratabilir.

AyrÄ±ca, bu tÃ¼r durumlar katÄ±lÄ±mcÄ±larÄ±n farkÄ±na vardÄ±ÄŸÄ±nda (Ã¶rneÄŸin ÅŸu tartÄ±ÅŸmaya bakÄ±labilir: [https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503](https://www.kaggle.com/c/ashrae-energy-prediction/discussion/122503)), yarÄ±ÅŸmaya ve sonraki yarÄ±ÅŸmalara olan gÃ¼ven ve katÄ±lÄ±m da azalabilir.

#### Computational resources *(Hesaplama kaynaklarÄ±)*

BazÄ± yarÄ±ÅŸmalar, **Ã¼retim ortamÄ±nda uygulanabilir Ã§Ã¶zÃ¼mler** elde edebilmek iÃ§in belirli sÄ±nÄ±rlamalar getirir.
Ã–rneÄŸin, **Bosch Production Line Performance** yarÄ±ÅŸmasÄ± ([https://www.kaggle.com/c/bosch-production-line-performance](https://www.kaggle.com/c/bosch-production-line-performance)) Ã§Ã¶zÃ¼m modelleri iÃ§in **Ã§alÄ±ÅŸma sÃ¼resi**, **Ã§Ä±ktÄ± dosyasÄ± boyutu** ve **bellek kullanÄ±mÄ±** aÃ§Ä±sÄ±ndan katÄ± sÄ±nÄ±rlamalara sahipti.

**Notebook tabanlÄ± yarÄ±ÅŸmalar** (Ã¶nceden *Kernel-Only* yarÄ±ÅŸmalarÄ± olarak biliniyordu), hem eÄŸitimin hem de Ã§Ä±karÄ±mÄ±n (inference) **Kaggle Notebooks** Ã¼zerinde gerÃ§ekleÅŸtirilmesini zorunlu kÄ±lar.
Bu durumda, kullanmanÄ±z gereken kaynaklarla ilgili bir sorun oluÅŸmaz; Ã§Ã¼nkÃ¼ **Kaggle size tÃ¼m gerekli donanÄ±m kaynaklarÄ±nÄ± saÄŸlar**.
Bu yaklaÅŸÄ±m aynÄ± zamanda, **tÃ¼m katÄ±lÄ±mcÄ±larÄ±n aynÄ± baÅŸlangÄ±Ã§ noktasÄ±nda yarÄ±ÅŸmasÄ±nÄ±** saÄŸlamak amacÄ±yla da tasarlanmÄ±ÅŸtÄ±r.

Sorunlar, yalnÄ±zca **Ã§Ä±karÄ±m (inference)** aÅŸamasÄ±nda Notebook kullanÄ±mÄ±nÄ± zorunlu kÄ±lan yarÄ±ÅŸmalarda ortaya Ã§Ä±kar.
Bu tÃ¼r yarÄ±ÅŸmalarda modellerinizi kendi bilgisayarÄ±nÄ±zda eÄŸitebilir, ancak **test aÅŸamasÄ±nda** model sayÄ±sÄ± ve karmaÅŸÄ±klÄ±ÄŸÄ± aÃ§Ä±sÄ±ndan sÄ±nÄ±rlamalara tabi olursunuz.

GÃ¼nÃ¼mÃ¼zde yarÄ±ÅŸmalarÄ±n Ã§oÄŸu **derin Ã¶ÄŸrenme (deep learning)** Ã§Ã¶zÃ¼mleri gerektirdiÄŸinden, **rekabetÃ§i sonuÃ§lar elde edebilmek iÃ§in GPU gibi Ã¶zel donanÄ±mlara** ihtiyaÃ§ duyacaÄŸÄ±nÄ±zÄ± bilmelisiniz.

GÃ¼nÃ¼mÃ¼zde nadirleÅŸmiÅŸ olsa da, bazÄ± **tabular veri yarÄ±ÅŸmalarÄ±nda** bile, **Ã§ok Ã§ekirdekli iÅŸlemcilere** ve **yÃ¼ksek belleÄŸe** sahip gÃ¼Ã§lÃ¼ bir makineye ihtiyacÄ±nÄ±z olduÄŸunu fark edeceksiniz.
Bu kaynaklar, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** uygulamak, **deneyler yÃ¼rÃ¼tmek** ve **modelleri hÄ±zlÄ± bir ÅŸekilde inÅŸa etmek** iÃ§in gereklidir.

Standartlar hÄ±zla deÄŸiÅŸtiÄŸi iÃ§in, tÃ¼m katÄ±lÄ±mcÄ±larla aynÄ± seviyede rekabet edebilmek adÄ±na **net bir donanÄ±m standardÄ± tanÄ±mlamak zordur**.
Ancak, diÄŸer yarÄ±ÅŸmacÄ±larÄ±n hangi makineleri kullandÄ±ÄŸÄ±na bakarak gÃ¼ncel standartlar hakkÄ±nda fikir edinebilirsiniz â€” ister kendi bilgisayarlarÄ± olsun, ister bulut tabanlÄ± makineler.

Ã–rneÄŸin, **HP**, marka gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼ karÅŸÄ±lÄ±ÄŸÄ±nda bazÄ± seÃ§ilmiÅŸ Kaggle yarÄ±ÅŸmacÄ±larÄ±na **HP Z4 veya Z8** makineleri hediye ettiÄŸi bir program baÅŸlatmÄ±ÅŸtÄ±r.
Bir **Z8 makinesi**,

* 72 Ã§ekirdeÄŸe kadar CPU,
* 3 TB bellek,
* 48 TB depolama (Ã§oÄŸunluÄŸu SSD),
* ve genellikle **Ã§ift NVIDIA RTX GPU** barÄ±ndÄ±rÄ±r.

Bu dÃ¼zeyde bir sistemin birÃ§ok kiÅŸi iÃ§in eriÅŸilemez olduÄŸunu anlamak zor deÄŸildir.
Benzer Ã¶zelliklerde bir makineyi kÄ±sa sÃ¼reliÄŸine bile **Google Cloud (GCP)** veya **Amazon AWS** gibi platformlarda kiralamak bile **yÃ¼ksek maliyetler** doÄŸurabilir.

Bu nedenle, **Kaggleâ€™da Ã¼st sÄ±ralara tÄ±rmanma yolculuÄŸunuza baÅŸlarken**, en iyi yaklaÅŸÄ±m **Kaggleâ€™Ä±n Ã¼cretsiz sunduÄŸu altyapÄ±yÄ±**, yani **Kaggle Notebooksâ€™u (Ã¶nceki adÄ±yla Kaggle Kernels)** kullanmaktÄ±r.

##### Kaggle Notebooks *(Kaggle Defterleri)*

**Kaggle Notebooks**, bulut makinelerinde Ã§alÄ±ÅŸan **Docker konteynerleri** tabanlÄ±, sÃ¼rÃ¼mlenebilir (versioned) hesaplama ortamlarÄ±dÄ±r.
Bu ortamlar, **R** ve **Python** dillerinde hem **script** hem de **notebook** yazÄ±p Ã§alÄ±ÅŸtÄ±rmanÄ±za olanak tanÄ±r.

Kaggle Notebooks:

* **Kaggle ortamÄ±na entegredir:** Bu sayede doÄŸrudan notebookâ€™tan yarÄ±ÅŸmaya gÃ¶nderim (submission) yapabilir ve hangi gÃ¶nderimin hangi notebookâ€™tan geldiÄŸini takip edebilirsiniz.
* **Ã‡oÄŸu veri bilimi paketini Ã¶nceden yÃ¼klÃ¼ olarak iÃ§erir.**
* **KÄ±sÄ±tlÄ± Ã¶zelleÅŸtirme olanaÄŸÄ± sunar:** Dosya indirebilir ve ek Python/R paketleri yÃ¼kleyebilirsiniz.

Temel **Kaggle Notebook**, yalnÄ±zca CPU tabanlÄ±dÄ±r. Ancak, isterseniz:

* **NVIDIA Tesla P100 GPU**,
* veya **TPU v3-8** (Ã¶zellikle derin Ã¶ÄŸrenme gÃ¶revleri iÃ§in optimize edilmiÅŸ donanÄ±m hÄ±zlandÄ±rÄ±cÄ±sÄ±)
  desteÄŸiyle gÃ¼Ã§lendirilmiÅŸ sÃ¼rÃ¼mleri de kullanabilirsiniz.

Her yarÄ±ÅŸmanÄ±n bulut maliyeti, **iÅŸlenecek veri miktarÄ±na**, **kurduÄŸunuz model sayÄ±sÄ±na ve tÃ¼rÃ¼ne** baÄŸlÄ±dÄ±r.
Kaggle yarÄ±ÅŸmalarÄ±nda, **GCP (Google Cloud Platform)** veya **AWS** Ã¼zerinde kullanÄ±lmak Ã¼zere genellikle **200 â€“ 500 ABD DolarÄ±** aralÄ±ÄŸÄ±nda **Ã¼cretsiz bulut kredisi** daÄŸÄ±tÄ±lÄ±r.

Kaggle Notebooks, belirli **kullanÄ±m ve sÃ¼re sÄ±nÄ±rlamalarÄ±** altÄ±nda Ã§alÄ±ÅŸÄ±r; ancak bu sÄ±nÄ±rlar dahilinde yarÄ±ÅŸmalarda **temel modellerinizi geliÅŸtirmek iÃ§in yeterli hesaplama gÃ¼cÃ¼nÃ¼** saÄŸlar.

| Notebook tÃ¼rÃ¼ | CPU Ã§ekirdeÄŸi | Bellek | AynÄ± anda Ã§alÄ±ÅŸtÄ±rÄ±labilen notebook sayÄ±sÄ± | HaftalÄ±k kota |
| ------------- | ------------- | ------ | ------------------------------------------ | ------------- |
| **CPU**       | 4             | 16 GB  | 10                                         | SÄ±nÄ±rsÄ±z      |
| **GPU**       | 2             | 13 GB  | 2                                          | 30 saat       |
| **TPU**       | 4             | 16 GB  | 2                                          | 30 saat       |

* **CPU ve GPU notebookâ€™larÄ±**, **maksimum 12 saat** boyunca kesintisiz Ã§alÄ±ÅŸabilir.
* **TPU notebookâ€™larÄ±** ise **en fazla 9 saat** boyunca Ã§alÄ±ÅŸtÄ±rÄ±labilir.
  Bu sÃ¼reler dolduÄŸunda, diske kaydedilmemiÅŸ hiÃ§bir Ã§Ä±ktÄ± alÄ±namaz.

KullanÄ±cÄ±larÄ±n **20 GB kalÄ±cÄ± disk alanÄ±** bulunur (model ve sonuÃ§larÄ± saklamak iÃ§in).
Buna ek olarak, geÃ§ici dosyalar iÃ§in **20 GBâ€™tan fazla geÃ§ici (scratchpad) alan** kullanÄ±labilir.

BazÄ± durumlarda, Kaggleâ€™Ä±n sunduÄŸu **GPU destekli makineler** yeterli olmayabilir.
Ã–rneÄŸin, **Deepfake Detection Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/deepfake-detection-challenge](https://www.kaggle.com/c/deepfake-detection-challenge)) yaklaÅŸÄ±k **500 GB video verisi** iÅŸlenmesi gerekiyordu.

Bu, iki aÃ§Ä±dan zorluk yaratÄ±yordu:

1. HaftalÄ±k **30 saatlik kullanÄ±m sÃ¼resi** sÄ±nÄ±rlamasÄ±,
2. AynÄ± anda **en fazla iki GPU destekli makine** Ã§alÄ±ÅŸtÄ±rÄ±labilmesi.

Kodunuzu **GPU yerine TPU kullanacak ÅŸekilde optimize ederek** (bunun iÃ§in rehber: [https://www.kaggle.com/docs/tpu](https://www.kaggle.com/docs/tpu)) sÃ¼reyi iki katÄ±na Ã§Ä±karabilirsiniz.
Ancak bu bile, **bÃ¼yÃ¼k veri setlerine sahip yarÄ±ÅŸmalarda** (Ã¶rneÄŸin Deepfake Detection Challenge gibi) **hÄ±zlÄ± denemeler** yapmak iÃ§in yeterli olmayabilir.

Bu nedenle, **BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek** kÄ±smÄ±nda, bu tÃ¼r sÄ±nÄ±rlamalarla nasÄ±l baÅŸa Ã§Ä±kabileceÄŸinize dair **ipuÃ§larÄ±** vereceÄŸiz.
AmaÃ§, **yÃ¼ksek performanslÄ± donanÄ±m satÄ±n almadan** tatmin edici sonuÃ§lar elde etmenize yardÄ±mcÄ± olmaktÄ±r.

AyrÄ±ca, **Kaggle Notebooksâ€™u GCP ile entegre etme** yÃ¶ntemlerini gÃ¶stereceÄŸiz.
Alternatif olarak, **BÃ¶lÃ¼m 2: Datasets ile Verileri Organize Etmek** kÄ±smÄ±nda, tÃ¼m Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± **Google Colab** gibi baÅŸka bir bulut tabanlÄ± ortama nasÄ±l taÅŸÄ±yabileceÄŸinizi anlatacaÄŸÄ±z.

#### Teaming and networking *(TakÄ±m kurma ve aÄŸ oluÅŸturma)*

Hesaplama gÃ¼cÃ¼ (computational power) Ã¶nemli bir rol oynasa da, bir Kaggle yarÄ±ÅŸmasÄ±nda **gerÃ§ek farkÄ± yaratan unsur, insan uzmanlÄ±ÄŸÄ± ve yeteneÄŸidir.**
Bir yarÄ±ÅŸmanÄ±n baÅŸarÄ±lÄ± bir ÅŸekilde yÃ¼rÃ¼tÃ¼lebilmesi bazen bir **takÄ±mÄ±n ortak Ã§alÄ±ÅŸmasÄ±nÄ±** gerektirir.

**Recruitment (Ä°ÅŸe AlÄ±m)** yarÄ±ÅŸmalarÄ± hariÃ§ â€” ki bu yarÄ±ÅŸmalarda sponsor ÅŸirket, katÄ±lÄ±mcÄ±larÄ±n bireysel yeteneklerini daha iyi deÄŸerlendirebilmek iÃ§in yalnÄ±z katÄ±lÄ±m talep edebilir â€” Kaggleâ€™da genellikle **takÄ±m kurmaya dair herhangi bir kÄ±sÄ±tlama yoktur.**
Bir takÄ±m genellikle **en fazla beÅŸ kiÅŸiden** oluÅŸabilir.

TakÄ±m kurmanÄ±n birÃ§ok avantajÄ± vardÄ±r; Ã§Ã¼nkÃ¼ **farklÄ± becerilerin birleÅŸmesi**, daha iyi Ã§Ã¶zÃ¼mler Ã¼retilmesini saÄŸlar.
Bir ekip, **probleme daha fazla zaman ayÄ±rabilir** ve her Ã¼yenin sahip olduÄŸu farklÄ± uzmanlÄ±k alanlarÄ± (Ã¶rneÄŸin modelleme, veri Ã¶n iÅŸleme, gÃ¶rselleÅŸtirme) ortak hedefe katkÄ± saÄŸlar.
Her veri bilimcisi aynÄ± becerilere veya aynÄ± seviyede uzmanlÄ±ÄŸa sahip deÄŸildir; dolayÄ±sÄ±yla ekip iÃ§indeki **beceri Ã§eÅŸitliliÄŸi**, yarÄ±ÅŸma performansÄ±nÄ± artÄ±rÄ±r.

Yine de, takÄ±m Ã§alÄ±ÅŸmasÄ±nÄ±n dezavantajlarÄ± da vardÄ±r.
**FarklÄ± bireyleri ortak bir hedef doÄŸrultusunda koordine etmek her zaman kolay deÄŸildir** ve bazen verimsiz durumlar yaÅŸanabilir.

YaygÄ±n sorunlardan biri, bazÄ± ekip Ã¼yelerinin **aktif katÄ±lÄ±m gÃ¶stermemesi** veya **tamamen pasif kalmasÄ±dÄ±r.**
Ancak en kÃ¶tÃ¼ senaryo, ekip Ã¼yelerinden birinin yarÄ±ÅŸma kurallarÄ±nÄ± ihlal etmesidir; bu durumda **tÃ¼m ekip diskalifiye edilebilir.**
Daha da kÃ¶tÃ¼sÃ¼, bazen bir ekip Ã¼yesi **diÄŸer bir takÄ±ma avantaj saÄŸlamak iÃ§in casusluk** bile yapabilir â€” ki bu durum geÃ§miÅŸte yaÅŸanmÄ±ÅŸtÄ±r.

Olumsuzluklara raÄŸmen, Kaggleâ€™da takÄ±m olmak harika bir fÄ±rsattÄ±r.
DiÄŸer veri bilimcileriyle tanÄ±ÅŸmak, **ortak bir amaÃ§ iÃ§in iÅŸ birliÄŸi yapmak** ve **bireysel olarak elde edilemeyecek sonuÃ§lara ulaÅŸmak** iÃ§in Ã¶nemli bir deneyimdir.

AyrÄ±ca Kaggle, **takÄ±m katÄ±lÄ±mcÄ±larÄ±nÄ± bireysel katÄ±lÄ±mcÄ±lara gÃ¶re Ã¶dÃ¼llendirme aÃ§Ä±sÄ±ndan avantajlÄ±** kÄ±lar.
KÃ¼Ã§Ã¼k takÄ±mlar, Ã¶dÃ¼l havuzundan **eÅŸit paydan daha yÃ¼ksek bir yÃ¼zde** alabilir.

TakÄ±m kurmak, Kaggleâ€™da **aÄŸ kurmanÄ±n (networking)** tek yolu deÄŸildir, ancak katÄ±lÄ±mcÄ±lar iÃ§in kesinlikle **daha faydalÄ± ve etkileÅŸimli** bir yoldur.
Bunun dÄ±ÅŸÄ±nda, **forum tartÄ±ÅŸmalarÄ±**, **dataset paylaÅŸÄ±mÄ±** ve **notebook paylaÅŸÄ±mÄ±** aracÄ±lÄ±ÄŸÄ±yla da diÄŸer katÄ±lÄ±mcÄ±larla baÄŸlantÄ± kurabilirsiniz.
Bu olanaklar, **diÄŸer veri bilimcileriyle tanÄ±ÅŸmanÄ±za** ve **toplulukta tanÄ±nmanÄ±za** yardÄ±mcÄ± olur.

Kaggle platformunun dÄ±ÅŸÄ±nda da Kaggle topluluÄŸuyla iletiÅŸim kurabileceÄŸiniz birÃ§ok ortam bulunmaktadÄ±r.
Ã–ncelikle, **Slack kanallarÄ±** oldukÃ§a faydalÄ±dÄ±r.

Ã–rneÄŸin, **KaggleNoobs** ([https://www.kaggle.com/getting-started/20577](https://www.kaggle.com/getting-started/20577)) adlÄ± kanal 2016 yÄ±lÄ±nda aÃ§Ä±lmÄ±ÅŸtÄ±r ve Kaggle yarÄ±ÅŸmalarÄ± Ã¼zerine birÃ§ok tartÄ±ÅŸmayÄ± barÄ±ndÄ±rÄ±r.
Burada, **kod veya model ile ilgili Ã¶zel bir probleminiz varsa**, size yardÄ±mcÄ± olabilecek destekleyici bir topluluk vardÄ±r.

Bunun dÄ±ÅŸÄ±nda da birÃ§ok Slack kanalÄ±, **Kaggle yarÄ±ÅŸmalarÄ±** ve **veri bilimi konularÄ±nda gÃ¶rÃ¼ÅŸ alÄ±ÅŸveriÅŸi** yapmak iÃ§in kurulmuÅŸtur.
BazÄ±larÄ± **bÃ¶lgesel veya ulusal dÃ¼zeyde** organize edilmiÅŸtir; Ã¶rneÄŸin:

* **Japon topluluÄŸu:** [Kaggler-ja](http://kaggler-ja-wiki.herokuapp.com/)
* **Rus topluluÄŸu:** [Open Data Science Network (ODS)](https://ods.ai/) â€” 2015 yÄ±lÄ±nda kurulmuÅŸ, daha sonra **RusÃ§a bilmeyen katÄ±lÄ±mcÄ±lara da aÃ§Ä±lmÄ±ÅŸtÄ±r.**

**ODS Network**, yalnÄ±zca bir Slack kanalÄ± deÄŸildir; aynÄ± zamanda:

* **YarÄ±ÅŸma kazanma stratejileri Ã¼zerine kurslar**,
* **Etkinlikler**,
* **TÃ¼m veri bilimi platformlarÄ±nda aktif yarÄ±ÅŸmalar hakkÄ±nda raporlar**
  da sunar.
  (Bkz. [https://ods.ai/competitions](https://ods.ai/competitions))

Slack dÄ±ÅŸÄ±nda, **Kaggle temalÄ± yerel buluÅŸmalar (meetup)** da giderek yaygÄ±nlaÅŸmaktadÄ±r.
BazÄ±larÄ± belirli yarÄ±ÅŸmalar etrafÄ±nda, bazÄ±larÄ± ise genel Kaggle topluluÄŸu odaÄŸÄ±nda dÃ¼zenlenir.
BazÄ±larÄ± **geÃ§ici**, bazÄ±larÄ± ise **dÃ¼zenli ve kalÄ±cÄ± etkinlikler** haline gelmiÅŸtir.

Bu buluÅŸmalar genellikle, **deneyimlerini paylaÅŸmak isteyen yarÄ±ÅŸmacÄ±larÄ±n sunumlarÄ±** etrafÄ±nda ÅŸekillenir.
KatÄ±lÄ±mcÄ±lar, bu tÃ¼r etkinliklerde **diÄŸer Kaggle kullanÄ±cÄ±larÄ±yla yÃ¼z yÃ¼ze tanÄ±ÅŸabilir**, **fikir alÄ±ÅŸveriÅŸinde bulunabilir** ve **ortak yarÄ±ÅŸma ekipleri kurabilir.**

Bu alanda Ã¶zellikle **Kaggle Days** ([https://kaggledays.com/](https://kaggledays.com/)) etkinliklerinden bahsetmek gerekir.
Bu etkinlikler, **Maria Parysz** ve **PaweÅ‚ Jankiewicz** tarafÄ±ndan organize edilmiÅŸtir.

**Kaggle Days**, dÃ¼nyanÄ±n dÃ¶rt bir yanÄ±nda dÃ¼zenlenen (bkz. [https://kaggledays.com/about-us/](https://kaggledays.com/about-us/)) konferanslar aracÄ±lÄ±ÄŸÄ±yla **Kaggle uzmanlarÄ±nÄ± bir araya getirmeyi** amaÃ§lar.
AyrÄ±ca, farklÄ± Ã¼lkelerde hÃ¢lÃ¢ aktif olan **yerel Kaggle meetup aÄŸlarÄ±** da oluÅŸturmuÅŸtur (bkz. [https://kaggledays.com/meetups/](https://kaggledays.com/meetups/)).

> PaweÅ‚ Jankiewicz ile RÃ¶portaj
> 
> 
> 
> **Profil:** [PaweÅ‚ Jankiewicz](https://www.kaggle.com/paweljankiewicz)
> 
> PaweÅ‚, **Kaggle Competitions Grandmaster** ve **LogicAIâ€™nin kurucu ortaklarÄ±ndan** biridir. Kaggle deneyimleri hakkÄ±nda kendisiyle konuÅŸma fÄ±rsatÄ± bulduk.
> 
> 
> 
> **Soru:** En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?
> 
> 
> 
> En sevdiÄŸim yarÄ±ÅŸma tÃ¼rÃ¼ **kod yarÄ±ÅŸmalarÄ±dÄ±r**. Ã‡Ã¼nkÃ¼ sÄ±nÄ±rlÄ± bir ortamda Ã§alÄ±ÅŸmak, farklÄ± tÃ¼rde bÃ¼tÃ§eleri dÃ¼ÅŸÃ¼nmeye zorlar: zaman, CPU, bellek. Ã–nceki yarÄ±ÅŸmalarda Ã§oÄŸu zaman **3-4 gÃ¼Ã§lÃ¼ sanal makine** kullanmam gerekiyordu. Bunu sevmiyordum; Ã§Ã¼nkÃ¼ kazanÃ§ iÃ§in bu kadar kaynak kullanmak, yarÄ±ÅŸmayÄ± adaletsiz hale getiriyor.
> 
> 
> 
> **Soru:** Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±?
> 
> 
> 
> Her yarÄ±ÅŸmaya biraz farklÄ± yaklaÅŸÄ±rÄ±m. Her yarÄ±ÅŸma iÃ§in **mÃ¼mkÃ¼n olduÄŸunca Ã§ok deney oluÅŸturmayÄ± saÄŸlayan bir Ã§erÃ§eve (framework) kurarÄ±m.**
> 
> 
> 
> Ã–rneÄŸin, bir yarÄ±ÅŸmada **derin Ã¶ÄŸrenme konvolÃ¼syonel sinir aÄŸÄ± (CNN)** kurmamÄ±z gerekiyordu. Ben, aÄŸlarÄ± **C4-MP4-C3-MP3** formatÄ±nda yapÄ±landÄ±rmayÄ± saÄŸlayan bir yÃ¶ntem geliÅŸtirdim (her harf farklÄ± bir katmanÄ± temsil ediyordu).
> 
> Bu olay yÄ±llar Ã¶nce oldu; artÄ±k muhtemelen sinir aÄŸlarÄ± yapÄ±landÄ±rmasÄ±, **backbone model seÃ§imiyle** yapÄ±lÄ±yor. Ama kural hÃ¢lÃ¢ geÃ§erli: **Pipelineâ€™daki en hassas bÃ¶lÃ¼mleri hÄ±zlÄ±ca deÄŸiÅŸtirebileceÄŸiniz bir Ã§erÃ§eve oluÅŸturmalÄ±sÄ±nÄ±z.**
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ, modelleme yaklaÅŸÄ±mÄ± ve doÄŸru validasyon aÃ§Ä±sÄ±ndan Kaggle yarÄ±ÅŸmalarÄ±yla benzerlik gÃ¶sterir.
> 
> Kaggle yarÄ±ÅŸmalarÄ±ndan Ã¶ÄŸrendiÄŸim en Ã¶nemli ÅŸey: **validasyonun Ã¶nemi ve veri sÄ±zÄ±ntÄ±sÄ±nÄ± (data leakage) Ã¶nlemenin gerekliliÄŸi.**
> 
> Ã–rneÄŸin, veri sÄ±zÄ±ntÄ±larÄ± Ã§ok sayÄ±da yarÄ±ÅŸmada gÃ¶rÃ¼lÃ¼yor; ve bunlarÄ± hazÄ±rlayan kiÅŸiler alanÄ±n en iyileri. Bu durum, Ã¼retimde kullanÄ±lan modellerin **%80â€™den fazlasÄ±nÄ±n doÄŸru ÅŸekilde validasyon edilmediÄŸini** dÃ¼ÅŸÃ¼ndÃ¼rÃ¼yor (kiÅŸisel gÃ¶rÃ¼ÅŸ).
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸ ile farklÄ±lÄ±k: kimse size **modelleme problemini nasÄ±l tanÄ±mlayacaÄŸÄ±nÄ±zÄ±** sÃ¶ylemez.
> 
> Ã–rneÄŸin:
> 
> 
> 
> 1. RaporlayacaÄŸÄ±nÄ±z veya optimize edeceÄŸiniz metrik **RMSE, RMSLE, SMAPE, MAPE** hangisi olmalÄ±?
> 
> 2. Problem zaman bazlÄ±ysa, modeli en gerÃ§ekÃ§i ÅŸekilde deÄŸerlendirmek iÃ§in veriyi nasÄ±l bÃ¶lmelisiniz?
> 
> 
> 
> Bunlar sadece iÅŸ aÃ§Ä±sÄ±ndan Ã¶nemli olan noktalar deÄŸil; ayrÄ±ca **seÃ§imlerinizi aÃ§Ä±klayabilme ve neden yaptÄ±ÄŸÄ±nÄ±zÄ± anlatabilme** becerisine de sahip olmalÄ±sÄ±nÄ±z.
> 
> 
> 
> **Soru:** KatÄ±ldÄ±ÄŸÄ±nÄ±z en zorlu yarÄ±ÅŸma hangisiydi ve problemi Ã§Ã¶zmek iÃ§in hangi yaklaÅŸÄ±mlarÄ± kullandÄ±nÄ±z?
> 
> 
> 
> **PaweÅ‚â€™Ä±n CevabÄ±:**
> 
> En zorlu ve ilginÃ§ yarÄ±ÅŸma, **Mercari Price Prediction Code** yarÄ±ÅŸmasÄ±ydÄ±.
> 
> DiÄŸer yarÄ±ÅŸmalardan farklÄ±ydÄ± Ã§Ã¼nkÃ¼ **sadece 1 saat hesaplama sÃ¼resi ve 4 Ã§ekirdek ile 16 GB bellek** ile sÄ±nÄ±rlÄ±ydÄ±. Bu kÄ±sÄ±tlarÄ± aÅŸmak, yarÄ±ÅŸmanÄ±n en heyecan verici kÄ±smÄ±ydÄ±.
> 
> 
> 
> Bu yarÄ±ÅŸmadan Ã¶ÄŸrendiÄŸim: **tabular veri iÃ§in aÄŸlara daha fazla gÃ¼venmek** gerekir.
> 
> TakÄ±m arkadaÅŸÄ±m **Konstantin Lopukhin** ile birleÅŸmeden Ã¶nce, karmaÅŸÄ±k modellerim vardÄ± (neural networkâ€™ler ve bazÄ± boosting algoritmalarÄ±).
> 
> BirleÅŸtiÄŸimizde, Konstantin sadece **Ã§ok optimize edilmiÅŸ tek bir mimari** kullanÄ±yordu (epoch sayÄ±sÄ±, Ã¶ÄŸrenme hÄ±zÄ± vb.).
> 
> 
> 
> Bu yarÄ±ÅŸmada ayrÄ±ca, **sadece Ã§Ã¶zÃ¼mleri ortalamak yeterli deÄŸildi.**
> 
> Workflowâ€™u yeniden organize edip, **tek bir uyumlu Ã§Ã¶zÃ¼m** Ã¼retmemiz gerekiyordu. Ã‡Ã¶zÃ¼mlerimizi birleÅŸtirmemiz **3 hafta** sÃ¼rdÃ¼.
> 
> 
> 
> **Soru:** TecrÃ¼besiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r?
> 
> 
> 
> **YazÄ±lÄ±m mÃ¼hendisliÄŸi becerileri (software engineering skills)** genellikle fazla Ã¶nemsenmez.
> 
> Her yarÄ±ÅŸma ve problem biraz farklÄ±dÄ±r ve Ã§Ã¶zÃ¼mÃ¼ **dÃ¼zene sokacak bir framework** gerektirir.
> 
> Ã–rnek: [https://github.com/bestfitting/instance_level_recognition](https://github.com/bestfitting/instance_level_recognition)
> 
> Ä°yi kod organizasyonu, **daha hÄ±zlÄ± iterasyon ve daha fazla deneme** yapmanÄ±za olanak saÄŸlar.
> 
> 
> 
> **PaweÅ‚â€™Ä±n Tavsiyesi:**
> 
> En Ã¶nemli ÅŸey **yarÄ±ÅŸmadan keyif almak.**

#### Performance tiers and rankings *(Performans seviyeleri ve sÄ±ralamalar)*

Parasal Ã¶dÃ¼ller ve kupa, tiÅŸÃ¶rt, hoodie veya sticker gibi maddi Ã¶dÃ¼llerin yanÄ± sÄ±ra, Kaggle birÃ§ok **maddi olmayan Ã¶dÃ¼l** de sunar.

Kagglers yarÄ±ÅŸmalar sÄ±rasÄ±nda Ã§ok **zaman ve Ã§aba harcar** (yarÄ±ÅŸmada kullandÄ±klarÄ± beceriler, genel nÃ¼fus arasÄ±nda oldukÃ§a nadirdir). Parasal Ã¶dÃ¼ller genellikle sadece en iyi birkaÃ§ Kaggle katÄ±lÄ±mcÄ±sÄ±nÄ±n Ã§abasÄ±nÄ± karÅŸÄ±lar, Ã§oÄŸu zaman sadece **birinciyi**. DiÄŸer katÄ±lÄ±mcÄ±lar ise saatlerce gÃ¶nÃ¼llÃ¼ Ã§alÄ±ÅŸÄ±r ama karÅŸÄ±lÄ±ÄŸÄ±nda Ã§ok az ÅŸey alÄ±r. Uzun vadede, somut bir Ã¶dÃ¼l olmadan yarÄ±ÅŸmalara katÄ±lmak, **ilgi kaybÄ±na ve motivasyon dÃ¼ÅŸÃ¼ÅŸÃ¼ne** yol aÃ§abilir.

Bu nedenle Kaggle, yarÄ±ÅŸmacÄ±larÄ± **madalya ve puan temelli bir onur sistemiyle** Ã¶dÃ¼llendirmeyi bulmuÅŸtur. AmaÃ§: ne kadar Ã§ok madalya ve puan kazanÄ±rsanÄ±z, becerileriniz o kadar tanÄ±nÄ±r ve iÅŸ arayÄ±ÅŸÄ± veya diÄŸer ilgili aktivitelerde fÄ±rsatlar elde edebilirsiniz.

Kaggleâ€™de bir **genel lider tablosu** vardÄ±r. Bu tablo, tÃ¼m bireysel yarÄ±ÅŸmalarÄ±n lider tablolarÄ±nÄ± birleÅŸtirir: [https://www.kaggle.com/rankings](https://www.kaggle.com/rankings).

* Her yarÄ±ÅŸmadaki pozisyonunuza gÃ¶re puan kazanÄ±rsÄ±nÄ±z.
* Bu puanlar toplandÄ±ÄŸÄ±nda genel lider tablosundaki sÄ±ralamanÄ±zÄ± belirler.

Ä°lk bakÄ±ÅŸta puan hesaplama formÃ¼lÃ¼ karmaÅŸÄ±k gÃ¶rÃ¼nebilir:

[
\left[ \frac{100000}{\sqrt{N_{\text{total}}}} \right] * [RRR - 0.75] * [\log_{10}(1 + \log_{10}(N_{\text{total}}))] * [e^{-t/500}]
]

Ama aslÄ±nda puanlar **temel birkaÃ§ unsur** Ã¼zerine kuruludur:

* YarÄ±ÅŸmadaki sÄ±ralamanÄ±z
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼z
* YarÄ±ÅŸmanÄ±n popÃ¼lerliÄŸi
* YarÄ±ÅŸmanÄ±n yaÅŸÄ±

**Ä°puÃ§larÄ±:**

* PopÃ¼ler yarÄ±ÅŸmalarda yÃ¼ksek sÄ±ralama, daha Ã§ok puan kazandÄ±rÄ±r.
* TakÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ **doÄŸrusal olmayan bir ÅŸekilde** puanlarÄ± etkiler. FormÃ¼ldeki **ters kare kÃ¶k** nedeniyle, takÄ±m bÃ¼yÃ¼dÃ¼kÃ§e kaybedilen puan oranÄ± artar.
* TakÄ±mÄ±nÄ±z **kÃ¼Ã§Ã¼k (2-3 kiÅŸi)** ise iÅŸbirliÄŸi ve hesaplama avantajÄ± aÃ§Ä±sÄ±ndan daha iyidir.
* Puanlar **zamanla azalÄ±r**; lineer olmasa da, bir yÄ±l sonra kazandÄ±ÄŸÄ±nÄ±z puanlarÄ±n Ã§oÄŸu kaybolur.

Yine de, profilinizde **ulaÅŸtÄ±ÄŸÄ±nÄ±z en yÃ¼ksek sÄ±ralamayÄ±** her zaman saklarsÄ±nÄ±z.

Daha kalÄ±cÄ± olan, Kaggleâ€™daki dÃ¶rt alanÄ± kapsayan **madalya sistemidir**:

* **Competitions (YarÄ±ÅŸmalar)**
* **Notebooks (Not Defterleri)**
* **Discussion (Forum KatkÄ±larÄ±)**
* **Datasets (Veri Setleri)**

**Competitions:** Madalyalar, lider tablodaki sÄ±ralamanÄ±za gÃ¶re verilir.
**DiÄŸer Ã¼Ã§ alan:** Madalyalar, diÄŸer katÄ±lÄ±mcÄ±larÄ±n **upvoteâ€™larÄ±** ile verilir. (Upvoteâ€™lar popÃ¼lerliÄŸe baÄŸlÄ± ve daha az objektif olabilir.)

Daha fazla madalya kazandÄ±kÃ§a **Kaggle uzmanlÄ±k sÄ±ralamalarÄ±** yÃ¼kselir:

* **Novice (Acemi)**
* **Contributor (KatÄ±lÄ±mcÄ±)**
* **Expert (Uzman)**
* **Master (Usta)**
* **Grandmaster (BÃ¼yÃ¼k Usta)**

DetaylÄ± bilgi ve gerekli madalya sayÄ±larÄ± iÃ§in: [https://www.kaggle.com/progression](https://www.kaggle.com/progression)

> Not: Bu sÄ±ralamalar **her zaman gÃ¶recelidir** ve zamanla deÄŸiÅŸebilir. BirkaÃ§ yÄ±l Ã¶nce puanlama sistemi ve sÄ±ralamalar oldukÃ§a farklÄ±ydÄ±. Muhtemelen gelecekte de, Ã¼st sÄ±ralar **daha nadir ve deÄŸerli** olacak ÅŸekilde deÄŸiÅŸtirilecektir.

#### Criticism and opportunities *(EleÅŸtiriler ve fÄ±rsatlar)*

Kaggle, baÅŸladÄ±ÄŸÄ± gÃ¼nden bu yana pek Ã§ok eleÅŸtiri aldÄ±. Veri bilimi yarÄ±ÅŸmalarÄ±na katÄ±lmak hÃ¢lÃ¢ tartÄ±ÅŸmalÄ± bir konu olup, bu konuda hem olumlu hem de olumsuz pek Ã§ok farklÄ± gÃ¶rÃ¼ÅŸ bulunmaktadÄ±r.

**Olumsuz eleÅŸtiriler aÃ§Ä±sÄ±ndan:**

* Kaggle, makine Ã¶ÄŸreniminin gerÃ§ekte ne olduÄŸuna dair yanlÄ±ÅŸ bir algÄ± yaratÄ±yor Ã§Ã¼nkÃ¼ sadece liderlik tablosu dinamiklerine odaklanÄ±yor.
* Kaggle, aslÄ±nda sadece biraz daha yÃ¼ksek doÄŸruluk elde etmek iÃ§in birÃ§ok modeli bir araya getirip hiperparametre optimizasyonu yapmak Ã¼zerine kurulu bir oyun gibi (gerÃ§ekte test setine fazla uyum saÄŸlama/overfitting yapÄ±yor).
* Kaggle, puan ve dikkat Ã§ekme umuduyla her ÅŸeyi denemeye hazÄ±r deneyimsiz meraklÄ±larla dolu.
* SonuÃ§ olarak, yarÄ±ÅŸma Ã§Ã¶zÃ¼mleri Ã§ok karmaÅŸÄ±k ve genellikle yalnÄ±zca test setine Ã¶zgÃ¼ olup uygulanmasÄ± zor.

BirÃ§ok kiÅŸi Kaggle ve diÄŸer veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ± gerÃ§ek veri bilimine oldukÃ§a uzak olarak gÃ¶rÃ¼yor. EleÅŸtirmenlerin vurguladÄ±ÄŸÄ± nokta ÅŸudur: Ä°ÅŸ problemleri boÅŸluktan ortaya Ã§Ä±kmaz ve nadiren Ã¶nceden iyi hazÄ±rlanmÄ±ÅŸ bir veri setine sahip olursunuz; Ã§Ã¼nkÃ¼ genellikle bunu, iÅŸ gereksinimlerini ve problem anlayÄ±ÅŸÄ±nÄ± geliÅŸtirerek oluÅŸturursunuz. AyrÄ±ca, birÃ§ok eleÅŸtirmen, kazanan Ã§Ã¶zÃ¼mlerin kaynak sÄ±nÄ±rlamalarÄ± veya teknik borÃ§ gibi kÄ±sÄ±tlamalarla sÄ±nÄ±rlandÄ±rÄ±lamayacaÄŸÄ± iÃ§in Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n Ã¼retim odaklÄ± modeller yaratmada yeterince Ã¶ÄŸrenmediÄŸini vurguluyor (her yarÄ±ÅŸma iÃ§in bu doÄŸru olmasa da).

TÃ¼m bu eleÅŸtiriler, nihayetinde Kaggle sÄ±ralamalarÄ±nÄ±n iÅŸveren gÃ¶zÃ¼nde diÄŸer deneyim tÃ¼rleriyle karÅŸÄ±laÅŸtÄ±rÄ±labilirliÄŸi ile ilgilidir; Ã¶zellikle veri bilimi eÄŸitimi ve iÅŸ deneyimi ile kÄ±yaslandÄ±ÄŸÄ±nda. SÃ¼regelen bir mit, Kaggle yarÄ±ÅŸmalarÄ±nÄ±n size iÅŸ bulmada veya daha iyi bir iÅŸ elde etmede yardÄ±mcÄ± olmayacaÄŸÄ± ve Kaggleâ€™a katÄ±lmayan veri bilimcilerden sizi farklÄ± bir seviyeye taÅŸÄ±yamayacaÄŸÄ±dÄ±r.

Bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼z, Kaggle sÄ±ralamalarÄ±nÄ±n Kaggle topluluÄŸunun Ã¶tesinde otomatik bir deÄŸeri olmadÄ±ÄŸÄ±na dair bu inanÄ±ÅŸÄ±n yanÄ±ltÄ±cÄ± olduÄŸudur. Ã–rneÄŸin, iÅŸ ararken Kaggle size veri ve problem modelleme ile etkili model test etme konusunda Ã§ok faydalÄ± beceriler kazandÄ±rabilir. AyrÄ±ca, sizi mevcut deneyim ve konfor alanÄ±nÄ±zÄ±n Ã¶tesinde birÃ§ok teknik ve farklÄ± veri/iÅŸ problemleriyle tanÄ±ÅŸtÄ±rabilir; ancak bir ÅŸirkette veri bilimci olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken her ÅŸeyi tek baÅŸÄ±na saÄŸlayamaz.

Kaggleâ€™Ä± Ã¶ÄŸrenmek iÃ§in (web sitesinde yalnÄ±zca Ã¶ÄŸrenmeye ayrÄ±lmÄ±ÅŸ â€œCoursesâ€ bÃ¶lÃ¼mÃ¼ de vardÄ±r) ve iÅŸ arayÄ±ÅŸÄ±nda kendinizi diÄŸer adaylardan farklÄ± kÄ±lmak iÃ§in kullanabilirsiniz; fakat bunun nasÄ±l deÄŸerlendirileceÄŸi ÅŸirketten ÅŸirkete oldukÃ§a deÄŸiÅŸir. Yine de, Kaggleâ€™da Ã¶ÄŸrendikleriniz kariyeriniz boyunca kesinlikle faydalÄ± olacaktÄ±r ve veri modelleme ile karmaÅŸÄ±k ve alÄ±ÅŸÄ±lmadÄ±k problemleri Ã§Ã¶zmeniz gerektiÄŸinde size bir avantaj saÄŸlayacaktÄ±r. Kaggle yarÄ±ÅŸmalarÄ±na katÄ±larak modelleme ve doÄŸrulama konusunda gÃ¼Ã§lÃ¼ yetkinlikler kazanÄ±rsÄ±nÄ±z. AyrÄ±ca, diÄŸer veri bilimcilerle aÄŸ kurabilir, bu sayede bir iÅŸ referansÄ± elde etmeniz kolaylaÅŸÄ±r ve kendi becerilerinizin Ã¶tesinde zor problemleri Ã§Ã¶zmek iÃ§in baÅŸkalarÄ±nÄ±n yetkinliklerinden ve gÃ¶rÃ¼ÅŸlerinden faydalanabilirsiniz.

Bu nedenle, bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼ze gÃ¶re Kaggle, veri bilimci olarak kariyerinize dolaylÄ± yollardan pek Ã§ok ÅŸekilde katkÄ± saÄŸlar. Elbette, bazen Kaggle, baÅŸarÄ±larÄ±nÄ±z Ã¼zerinden doÄŸrudan bir iÅŸ teklifi almanÄ±za yardÄ±mcÄ± olabilir; fakat Ã§oÄŸu zaman Kaggle, Ã¶nce bir aday olarak, sonra bir uygulayÄ±cÄ± olarak baÅŸarÄ±lÄ± olmanÄ±z iÃ§in gereken entelektÃ¼el beceri ve deneyimi saÄŸlar.

AslÄ±nda, Kaggleâ€™da bir sÃ¼re veri ve modellerle uÄŸraÅŸtÄ±ktan sonra, farklÄ± veri setleri, problemler ve bunlarla baÅŸa Ã§Ä±kma yÃ¶ntemlerini zaman baskÄ±sÄ± altÄ±nda gÃ¶rmÃ¼ÅŸ olursunuz; bu da benzer problemlerle gerÃ§ek ortamda karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda hÄ±zlÄ± ve etkili Ã§Ã¶zÃ¼mler bulma konusunda sizi yetkin kÄ±lar.

Ä°ÅŸte bu beceri geliÅŸimi fÄ±rsatÄ±, bizi bu kitabÄ± yazmaya motive eden ve kitabÄ±n temel amacÄ±nÄ± oluÅŸturan ÅŸeydir. Burada yalnÄ±zca Kaggle yarÄ±ÅŸmalarÄ±nÄ± kazanma veya yÃ¼ksek puan alma rehberi bulamayacaksÄ±nÄ±z; fakat yarÄ±ÅŸmalarda daha iyi nasÄ±l rekabet edeceÄŸinizi ve yarÄ±ÅŸma deneyimlerinden en iyi ÅŸekilde nasÄ±l faydalanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz.

Kaggle ve diÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± akÄ±llÄ±ca kullanÄ±n. Kaggle bir sihirli anahtar deÄŸildir â€“ bir yarÄ±ÅŸmada birinci olmak, yÃ¼ksek maaÅŸ veya Kaggle topluluÄŸu dÄ±ÅŸÄ±nda ÅŸan getirmez. Ancak, yarÄ±ÅŸmalara dÃ¼zenli olarak katÄ±lmak, veri bilimi iÅŸ arayÄ±ÅŸÄ±nÄ±zda ilgi ve tutkuyu gÃ¶stermek ve bazÄ± Ã¶zel becerileri geliÅŸtirerek sizi diÄŸer veri bilimcilerden farklÄ± kÄ±lmak iÃ§in stratejik bir karttÄ±r; ayrÄ±ca sizi AutoML Ã§Ã¶zÃ¼mlerine karÅŸÄ± modasÄ± geÃ§miÅŸ hÃ¢le getirmez.

EÄŸer kitabÄ±n ilerleyen bÃ¶lÃ¼mlerini takip ederseniz, bunu nasÄ±l yapacaÄŸÄ±nÄ±zÄ± gÃ¶stereceÄŸiz.

### Summary *(Ã–zet)*

Bu baÅŸlangÄ±Ã§ bÃ¶lÃ¼mÃ¼nde, Ã¶ncelikle veri bilimi yarÄ±ÅŸma platformlarÄ±nÄ±n nasÄ±l ortaya Ã§Ä±ktÄ±ÄŸÄ±nÄ± ve hem yarÄ±ÅŸmacÄ±lar hem de bu platformlarÄ± iÅŸleten kurumlar aÃ§Ä±sÄ±ndan nasÄ±l iÅŸlediÄŸini tartÄ±ÅŸtÄ±k; Ã¶zellikle ProfesÃ¶r David Donoho tarafÄ±ndan ele alÄ±nan ikna edici CTF (Capture The Flag) paradigmasÄ±na atÄ±fta bulunduk.

Kaggleâ€™Ä±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± Ã¶rneklerle gÃ¶sterdik, aynÄ± zamanda diÄŸer kayda deÄŸer yarÄ±ÅŸma platformlarÄ±ndan da bahsederek, Kaggle dÄ±ÅŸÄ±ndaki meydan okumalarÄ± da denemenin size nasÄ±l fayda saÄŸlayabileceÄŸini anlattÄ±k. Kaggle ile ilgili olarak, bir yarÄ±ÅŸmanÄ±n farklÄ± aÅŸamalarÄ±nÄ±n nasÄ±l iÅŸlediÄŸini, yarÄ±ÅŸmalarÄ±n birbirinden nasÄ±l farklÄ±laÅŸtÄ±ÄŸÄ±nÄ± ve Kaggle platformunun size sunabileceÄŸi kaynaklarÄ± detaylÄ± ÅŸekilde ele aldÄ±k.

Bir sonraki birkaÃ§ bÃ¶lÃ¼mde, Kaggleâ€™Ä± daha ayrÄ±ntÄ±lÄ± olarak incelemeye baÅŸlayacaÄŸÄ±z; bunun ilk adÄ±mÄ± olarak veri setleri (Datasets) ile nasÄ±l Ã§alÄ±ÅŸÄ±lacaÄŸÄ±nÄ± ele alacaÄŸÄ±z.

---

## Chapter 2: Organizing Data with Datasets *(BÃ¶lÃ¼m 2: Veri Setleriyle Veriyi DÃ¼zenleme)*

Arthur Conan Doyleâ€™un *The Adventure of the Copper Beeches* (BakÄ±r KayÄ±n AÄŸaÃ§larÄ±nÄ±n MacerasÄ±) adlÄ± hikÃ¢yesinde Sherlock Holmes, â€œVeri! Veri! Veri! Kil olmadan tuÄŸla yapamam.â€ diye baÄŸÄ±rÄ±r. EdebiyatÄ±n en Ã¼nlÃ¼ dedektifine bu kadar iyi hizmet eden bu bakÄ±ÅŸ aÃ§Ä±sÄ±, her veri bilimcinin benimsemesi gereken bir yaklaÅŸÄ±m olmalÄ±dÄ±r. Bu nedenle, kitabÄ±n daha teknik bÃ¶lÃ¼mÃ¼ne veri odaklÄ± bir bÃ¶lÃ¼mle baÅŸlÄ±yoruz: Ã¶zellikle Kaggle baÄŸlamÄ±nda, amaÃ§larÄ±mÄ±z doÄŸrultusunda Kaggle Datasets (Veri Setleri) fonksiyonunun gÃ¼cÃ¼nden yararlanmayÄ± ele alacaÄŸÄ±z.

Bu bÃ¶lÃ¼mde ÅŸu konularÄ± ele alacaÄŸÄ±z:

* Bir veri seti oluÅŸturma
* Veriyi toplama
* Veri setleriyle Ã§alÄ±ÅŸma
* Kaggle Datasetsâ€™i Google Colabâ€™de kullanma
* Hukuki uyarÄ±lar

### Setting up a dataset *(Bir veri seti oluÅŸturma)*

Ä°lke olarak, kullanabileceÄŸiniz herhangi bir veriyi Kaggleâ€™a yÃ¼kleyebilirsiniz (sÄ±nÄ±rlamalara tabi; daha sonra â€œHukuki UyarÄ±larâ€ bÃ¶lÃ¼mÃ¼ne bakÄ±nÄ±z). YazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihteki Ã¶zel sÄ±nÄ±rlamalar, her Ã¶zel veri seti iÃ§in 100 GB ve toplam kota olarak 100 GBâ€™dÄ±r. Tek bir veri seti iÃ§in boyut sÄ±nÄ±rÄ±nÄ±n sÄ±kÄ±ÅŸtÄ±rÄ±lmamÄ±ÅŸ hÃ¢liyle hesaplandÄ±ÄŸÄ±nÄ± unutmayÄ±n; sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ versiyonlarÄ± yÃ¼klemek aktarÄ±mÄ± hÄ±zlandÄ±rÄ±r ancak sÄ±nÄ±rlamalara karÅŸÄ± bir avantaj saÄŸlamaz. Veri setleri ile ilgili en gÃ¼ncel dokÃ¼mantasyonu bu baÄŸlantÄ±dan kontrol edebilirsiniz: [Kaggle Datasets Documentation](https://www.kaggle.com/docs/datasets).

Kaggle kendini â€œveri biliminin eviâ€ olarak tanÄ±tÄ±r ve sitede bulunan etkileyici veri seti koleksiyonu bu iddiaya bÃ¼yÃ¼k Ã¶lÃ§Ã¼de gÃ¼venilirlik kazandÄ±rÄ±r. Sadece petrol fiyatlarÄ±ndan anime Ã¶nerilerine kadar Ã§eÅŸitli konularda veri bulmakla kalmazsÄ±nÄ±z; verilerin ne kadar hÄ±zlÄ± bir ÅŸekilde siteye ulaÅŸtÄ±ÄŸÄ± da etkileyicidir. Ã–rneÄŸin, Anthony Fauciâ€™nin e-postalarÄ± 2021 MayÄ±s ayÄ±nda Bilgi Edinme HakkÄ± YasasÄ± kapsamÄ±nda yayÄ±mlandÄ±ÄŸÄ±nda ([link](https://www.washingtonpost.com/politics/interactive/2021/tony-fauci-emails/)), yalnÄ±zca 48 saat iÃ§inde bir Kaggle veri seti olarak yÃ¼klenmiÅŸti.

![](im/1005.png)

Projeniz iÃ§in verileri bir veri setine yÃ¼klemeden Ã¶nce, mevcut iÃ§erikleri kontrol ettiÄŸinizden emin olun.
BazÄ± popÃ¼ler uygulamalar iÃ§in (gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma, NLP, finansal zaman serileri) verilerin zaten orada depolanmÄ±ÅŸ olma ihtimali vardÄ±r.

Bu giriÅŸ iÃ§in, projenizde kullanacaÄŸÄ±nÄ±z veri tÃ¼rÃ¼nÃ¼n henÃ¼z orada bulunmadÄ±ÄŸÄ±nÄ± varsayalÄ±m; bu durumda yeni bir veri seti oluÅŸturmanÄ±z gerekir. Sol taraftaki Ã¼Ã§ Ã§izgili menÃ¼ye gidip â€œDataâ€ (Veri) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, Datasets (Veri Setleri) sayfasÄ±na yÃ¶nlendirileceksiniz:

![](im/1006.png)

â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±kladÄ±ÄŸÄ±nÄ±zda, sizden temel bilgileri girmeniz istenecektir: veriyi yÃ¼klemek ve bir baÅŸlÄ±k vermek.

![](im/1007.png)

Sol taraftaki simgeler, veri setiniz iÃ§in kullanabileceÄŸiniz farklÄ± kaynaklara karÅŸÄ±lÄ±k gelir. BunlarÄ± sayfada gÃ¶sterildikleri sÄ±rayla aÃ§Ä±klÄ±yoruz:

* Yerel bir sÃ¼rÃ¼cÃ¼den dosya yÃ¼kleme (ÅŸekilde gÃ¶sterilmiÅŸtir)
* Uzak bir URLâ€™den oluÅŸturma
* Bir GitHub deposunu iÃ§e aktarma
* Mevcut bir Notebookâ€™tan Ã§Ä±ktÄ± dosyalarÄ±nÄ± kullanma
* Google Cloud Storage dosyasÄ±nÄ± iÃ§e aktarma

GitHub seÃ§eneÄŸi ile ilgili Ã¶nemli bir nokta: Bu Ã¶zellik, Ã¶zellikle deneysel kÃ¼tÃ¼phaneler sÃ¶z konusu olduÄŸunda oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r. HenÃ¼z mevcut olmayan iÅŸlevsellikler sunmalarÄ±na sÄ±kÃ§a raÄŸmen, bu kÃ¼tÃ¼phaneler genellikle Kaggle ortamÄ±na dahil edilmez; bu nedenle, kodunuzda bÃ¶yle bir kÃ¼tÃ¼phaneyi kullanmak istiyorsanÄ±z, aÅŸaÄŸÄ±da gÃ¶sterildiÄŸi gibi veri seti olarak iÃ§e aktarabilirsiniz:

1. Datasets (Veri Setleri) sayfasÄ±na gidin ve â€œ+ New Datasetâ€ (Yeni Veri Seti) seÃ§eneÄŸine tÄ±klayÄ±n.
2. GitHub simgesini seÃ§in.
3. Depo baÄŸlantÄ±sÄ±nÄ± ve veri seti iÃ§in baÅŸlÄ±ÄŸÄ± girin.
4. SaÄŸ alt kÃ¶ÅŸedeki â€œCreateâ€ (OluÅŸtur) butonuna tÄ±klayÄ±n.

![](im/1008.png)

â€œCreateâ€ (OluÅŸtur) butonunun yanÄ±nda bir de â€œPrivateâ€ (Ã–zel) olarak iÅŸaretlenmiÅŸ baÅŸka bir buton vardÄ±r. VarsayÄ±lan olarak oluÅŸturduÄŸunuz herhangi bir veri seti Ã¶zeldir: yalnÄ±zca siz, yani veri setinin yaratÄ±cÄ±sÄ±, onu gÃ¶rÃ¼ntÃ¼leyip dÃ¼zenleyebilirsiniz. Veri seti oluÅŸturma aÅŸamasÄ±nda bu ayarÄ± varsayÄ±lan hÃ¢lde bÄ±rakmak ve yalnÄ±zca daha sonraki bir aÅŸamada veri setini halka aÃ§mak (ya belirli bir katkÄ±da bulunanlar listesi iÃ§in ya da herkes iÃ§in) muhtemelen iyi bir fikirdir.

Kaggleâ€™Ä±n popÃ¼ler bir platform olduÄŸunu ve birÃ§ok kiÅŸinin veri setlerini â€“ Ã¶zel olanlar da dahil â€“ yÃ¼klediÄŸini unutmayÄ±n; bu nedenle, veri setiniz iÃ§in genel olmayan bir baÅŸlÄ±k dÃ¼ÅŸÃ¼nmeye Ã§alÄ±ÅŸÄ±n. Bu, veri setinizin gerÃ§ekten fark edilme ÅŸansÄ±nÄ± artÄ±racaktÄ±r.

TÃ¼m adÄ±mlarÄ± tamamlayÄ±p â€œCreateâ€ (OluÅŸtur) butonuna tÄ±kladÄ±ÄŸÄ±nÄ±zda, voilÃ ! Ä°lk veri setiniz hazÄ±r. ArdÄ±ndan â€œDataâ€ sekmesine gidebilirsiniz:

![](im/1009.png)

YukarÄ±daki ekran gÃ¶rÃ¼ntÃ¼sÃ¼, veri setinizle ilgili saÄŸlayabileceÄŸiniz farklÄ± bilgileri gÃ¶stermektedir; saÄŸladÄ±ÄŸÄ±nÄ±z bilgi ne kadar Ã§ok olursa, kullanÄ±labilirlik indeksi o kadar yÃ¼ksek olur. Bu indeks, veri setinizin ne kadar iyi tanÄ±mlandÄ±ÄŸÄ±nÄ± Ã¶zetleyen sentetik bir Ã¶lÃ§Ã¼dÃ¼r. YÃ¼ksek kullanÄ±labilirlik indeksine sahip veri setleri, arama sonuÃ§larÄ±nda daha Ã¼st sÄ±ralarda gÃ¶rÃ¼nÃ¼r. Her veri seti iÃ§in kullanÄ±labilirlik indeksi, dokÃ¼mantasyon seviyesi, Notebooks gibi ilgili kamuya aÃ§Ä±k iÃ§eriklerin referans olarak bulunabilirliÄŸi, dosya tÃ¼rleri ve temel meta verilerin kapsanmasÄ± gibi Ã§eÅŸitli faktÃ¶rlere dayanÄ±r.

Ä°lke olarak, yukarÄ±daki gÃ¶rselde gÃ¶sterilen tÃ¼m alanlarÄ± doldurmak zorunda deÄŸilsiniz; yeni oluÅŸturduÄŸunuz veri seti bunlar olmadan da tamamen kullanÄ±labilir (ve eÄŸer Ã¶zel bir veri seti ise, muhtemelen Ã¶nemsemezsiniz; sonuÃ§ta iÃ§eriÄŸini siz biliyorsunuz). Ancak, topluluk gÃ¶rgÃ¼ kurallarÄ±, veri setlerinizi halka aÃ§tÄ±ÄŸÄ±nÄ±zda bilgileri doldurmanÄ±zÄ± Ã¶nerir: ne kadar Ã§ok bilgi belirtirseniz, veri baÅŸkalarÄ± iÃ§in o kadar kullanÄ±ÅŸlÄ± olur.

### Gathering the data *(Veri toplama)*

Hukuki boyutlar dÄ±ÅŸÄ±nda, veri setlerinde saklayabileceÄŸiniz iÃ§erik tÃ¼rÃ¼ konusunda gerÃ§ek bir sÄ±nÄ±r yoktur: tablo verileri, gÃ¶rseller, metin; eÄŸer boyut gereksinimlerine uyuyorsa, bunlarÄ± saklayabilirsiniz. Bu, diÄŸer kaynaklardan elde edilen verileri de kapsar; yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± tarihte popÃ¼ler veri setleri arasÄ±nda hashtag veya konuya gÃ¶re toplanmÄ±ÅŸ tweetler yer almaktadÄ±r:

![](im/1010.png)

Sosyal medyadan (Twitter, Reddit ve benzeri) veri toplamak iÃ§in kullanÄ±lan farklÄ± Ã§erÃ§evelerin tartÄ±ÅŸÄ±lmasÄ±, bu kitabÄ±n kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r.

> **Andrew MaranhÃ£o**
> 
> [https://www.kaggle.com/andrewmvd](https://www.kaggle.com/andrewmvd)
> 
> 
> 
> Andrew MaranhÃ£o (diÄŸer adÄ±yla Larxel), Datasets Grandmaster (yazÄ±nÄ±n hazÄ±rlandÄ±ÄŸÄ± sÄ±rada Datasetsâ€™te bir numara) ve SÃ£o Pauloâ€™daki Hospital Albert Einsteinâ€™da KÄ±demli Veri Bilimci, bize Datasets baÅŸarÄ±sÄ±na nasÄ±l ulaÅŸtÄ±ÄŸÄ±nÄ±, veri seti oluÅŸturma ipuÃ§larÄ±nÄ± ve Kaggleâ€™daki genel deneyimlerini anlattÄ±.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Genellikle en sevdiÄŸim alan tÄ±bbi gÃ¶rÃ¼ntÃ¼lemedir. Hem iÅŸimle hem de amacÄ±mla Ã¶rtÃ¼ÅŸÃ¼yor. TÄ±bbi yarÄ±ÅŸmalarda NLP dil ile sÄ±nÄ±rlÄ±dÄ±r, tablo verileri hastaneler arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±k gÃ¶sterir, fakat gÃ¶rÃ¼ntÃ¼leme Ã§oÄŸunlukla aynÄ±dÄ±r; bu nedenle bu baÄŸlamda yapÄ±lan herhangi bir geliÅŸme, dÃ¼nya genelinde birÃ§ok Ã¼lke iÃ§in fayda saÄŸlayabilir ve bu etki potansiyelini seviyorum. AyrÄ±ca NLP ve tablo verilerini de severim, ama sanÄ±rÄ±m bu oldukÃ§a standart bir tercih.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸmayÄ± ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemleri anlatÄ±r mÄ±sÄ±nÄ±z?**
> 
> Bir tÃ¼berkÃ¼loz tespit yarÄ±ÅŸmasÄ±nda, yaklaÅŸÄ±k 1.000 rÃ¶ntgen gÃ¶rÃ¼ntÃ¼sÃ¼ vardÄ±; bu sayÄ±, hastalÄ±ÄŸÄ±n tÃ¼m belirtilerini yakalamak iÃ§in oldukÃ§a kÃ¼Ã§Ã¼ktÃ¼. Bunu telafi etmek iÃ§in iki fikir geliÅŸtirdim:
> 
> 
> 
> 1. DÄ±ÅŸ veri ile pnÃ¶moni tespiti iÃ§in Ã¶n eÄŸitim (~20k gÃ¶rÃ¼ntÃ¼), Ã§Ã¼nkÃ¼ pnÃ¶moni tÃ¼berkÃ¼loz ile karÄ±ÅŸtÄ±rÄ±labilir.
> 
> 2. AkciÄŸer anomalilerinin Ã§ok etiketli sÄ±nÄ±flandÄ±rmasÄ± (~600k gÃ¶rÃ¼ntÃ¼) Ã¼zerinde Ã¶n eÄŸitim ve basit bir SSD ile sÄ±nÄ±flandÄ±rma etiketlerinin bounding box anotasyonlarÄ±nÄ± oluÅŸturmak iÃ§in grad-CAM kullanÄ±mÄ±.
> 
> 
> 
> SonuÃ§ta, bu iki yaklaÅŸÄ±mÄ±n basit bir karÄ±ÅŸÄ±mÄ±, ikinci sÄ±radaki takÄ±mÄ±n sonucuna gÃ¶re %22 daha iyi bir performans saÄŸladÄ±. Bu yarÄ±ÅŸma, yaklaÅŸÄ±k 100 takÄ±mÄ±n katÄ±ldÄ±ÄŸÄ± bir tÄ±bbi kongrede gerÃ§ekleÅŸti.
> 
> 
> 
> **Dataset Grandmaster oldunuz ve Datasetsâ€™te 1 numara oldunuz. Veri setleri iÃ§in konu seÃ§imi, veri bulma, toplama ve yayÄ±mlama sÃ¼reciniz nasÄ±l iÅŸliyor?**
> 
> Bu bÃ¼yÃ¼k bir soru; parÃ§alar hÃ¢linde aÃ§Ä±klamaya Ã§alÄ±ÅŸayÄ±m:
> 
> 
> 
> 1. **Kendinize bir amaÃ§ belirleyin**
> 
>    Konu seÃ§erken aklÄ±mda tuttuÄŸum ilk ÅŸey, bunu yapmamÄ±n temel nedenidir. Derin bir amaÃ§ olduÄŸunda, mÃ¼kemmel veri setleri bir sonuÃ§ olarak ortaya Ã§Ä±kar, hedef olarak deÄŸil.
> 
> 
> 
> 2. **Harika bir veri seti, harika bir sorunun vÃ¼cut bulmuÅŸ hÃ¢lidir**
> 
>    En iyi veri setlerinde ortak temalar:
> 
> 
> 
> * Cesur ve ilgili bir soru, bÃ¼yÃ¼k potansiyele sahip
> 
> * Veriler iyi toplanmÄ±ÅŸ, kalite kontrolÃ¼ yapÄ±lmÄ±ÅŸ ve iyi belgelenmiÅŸ
> 
> * Mevcut donanÄ±m iÃ§in yeterli veri ve Ã§eÅŸitlilik
> 
> * Veriye sÃ¼rekli katkÄ±da bulunan aktif bir topluluk
> 
> 
> 
> 3. **Sadece baÅŸarÄ±ya odaklanmayÄ±n; baÅŸarÄ± iÃ§in sÃ¼reci oluÅŸturun**
> 
>    Kalite, nicelikten Ã§ok daha Ã¶nemlidir. Grandmaster olmak iÃ§in sadece 15 veri setine ihtiyacÄ±nÄ±z vardÄ±r ve Ã¶ne Ã§Ä±kan veri setleri az ve iyi hazÄ±rlanmÄ±ÅŸ olmalÄ±dÄ±r. AyrÄ±ca veri setlerinin bakÄ±m ve sÃ¼rekli geliÅŸtirme gerektirdiÄŸini unutmayÄ±n. Topluluk desteÄŸi de Ã§ok Ã¶nemlidir; veri setinizi analiz edenlerin ihtiyaÃ§larÄ±nÄ± ve seÃ§imlerini anlamak, Ã¶n iÅŸleme adÄ±mlarÄ±nÄ±zÄ± ve belgelerinizi geliÅŸtirebilir.
> 
> 
> 
> **Ã–rnek sÃ¼reÃ§:**
> 
> Sosyal refahÄ± artÄ±rmak istiyorsunuz â†’ hedef: Ä±rksal eÅŸitlik â†’ konular: Black Lives Matter hareketi â†’ soru: Milyonlarca sesin ne dediÄŸini nasÄ±l anlayabilirim? â†’ veri tÃ¼rÃ¼: NLP â†’ veri toplama: haber makaleleri, YouTube yorumlarÄ±, tweetler â†’ Ã¶n iÅŸleme ve anonimleÅŸtirme â†’ yayÄ±nlama â†’ topluluk desteÄŸi ve geliÅŸtirme.
> 
> 
> 
> 4. **Ä°yi iÅŸ yapmak, kontrolÃ¼nÃ¼zde olan tek ÅŸeydir**
> 
>    Grandmaster olmanÄ±zÄ± baÅŸkalarÄ± saÄŸlar; oylar her zaman Ã§abaya veya etkiye dÃ¶nÃ¼ÅŸmez. Ã–nemli olan sizin Ã§abanÄ±z, Ã¶ÄŸrenmeniz ve denemenizdir.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz araÃ§lar/lisanslar nelerdir?**
> 
> LightGBM, CatBoost, Optuna, Streamlit, Gradio, FastAPI, Plotly, PyTorch gibi kÃ¼tÃ¼phaneleri Ã¶neriyor. AyrÄ±ca, kendi Ã§Ã¶zÃ¼mlerinizi uygulamak, derinlemesine bilgi edinmek aÃ§Ä±sÄ±ndan Ã§ok deÄŸerli.
> 
> 
> 
> **Deneyimsiz Kagglers neyi sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rÄ±r?**
> 
> 
> 
> * YarÄ±ÅŸmanÄ±n sonunda bilgiyi tam olarak absorbe etmek
> 
> * BitmiÅŸ yarÄ±ÅŸmalarda kazanan Ã§Ã¶zÃ¼mleri tekrar etmek
> 
> 
> 
> **Kaggle kariyerinize nasÄ±l katkÄ± saÄŸladÄ±?**
> 
> Kaggle bilgi, deneyim ve portfÃ¶y kazandÄ±rdÄ±. Ä°lk veri bilimi iÅŸim bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Kaggle ve DrivenData yarÄ±ÅŸmalarÄ± sayesinde oldu.
> 
> 
> 
> **PortfÃ¶yÃ¼nÃ¼zÃ¼ potansiyel iÅŸverenlere gÃ¶stermek iÃ§in Kaggle deneyimlerinizi kullandÄ±nÄ±z mÄ±?**
> 
> Kesinlikle. Ä°lk iÅŸimi Kaggle portfÃ¶yÃ¼ sayesinde aldÄ±m. PortfÃ¶y, eÄŸitim geÃ§miÅŸinden daha iyi veri bilimi bilgisi ve deneyimi temsil eder.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musunuz? Kaggle ile karÅŸÄ±laÅŸtÄ±rmasÄ± nasÄ±l?**
> 
> DrivenData ve AICrowdâ€™u da kullanÄ±yorum. Kaggle daha bÃ¼yÃ¼k ve aktif bir topluluk sunuyor, donanÄ±m ve veri/Notebook Ã¶zellikleri ile en iyi seÃ§enek. Ancak diÄŸer platformlar da ilginÃ§ ve Ã§eÅŸitli zorluklar sunuyor.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya girerken en Ã¶nemli ÅŸey nedir?**
> 
> GeliÅŸim odaklÄ±ysanÄ±z, ilginizi Ã§eken ve daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z bir konuyu seÃ§in. Derinlik ve Ã§eÅŸitlilik kritik; derinlik, odaklanarak ve en iyinizi vererek; Ã§eÅŸitlilik ise daha Ã¶nce yapmadÄ±ÄŸÄ±nÄ±z veya farklÄ± yaptÄ±ÄŸÄ±nÄ±z ÅŸeyleri deneyerek elde edilir.

### Working with datasets *(Veri setleriyle Ã§alÄ±ÅŸma)*

Bir veri seti oluÅŸturduktan sonra, muhtemelen onu analizlerinizde kullanmak isteyeceksiniz. Bu bÃ¶lÃ¼mde, bunu yapmanÄ±n farklÄ± yÃ¶ntemlerini ele alÄ±yoruz.

Muhtemelen en Ã¶nemli yÃ¶ntem, veri setinizi birincil kaynak olarak kullanacaÄŸÄ±nÄ±z bir Notebook baÅŸlatmaktÄ±r. Bunu yapmak iÃ§in veri seti sayfasÄ±na gidip ardÄ±ndan **New Notebook** Ã¼zerine tÄ±klayabilirsiniz.

![](im/1011.png)

Bunu yaptÄ±ktan sonra, Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![](im/1012.png)

Ä°ÅŸte bununla ilgili birkaÃ§ ipucu:

* AlfasayÄ±sal baÅŸlÄ±k otomatik olarak oluÅŸturulur; Ã¼zerine tÄ±klayarak dÃ¼zenleyebilirsiniz.
* SaÄŸ tarafta, **Data** altÄ±nda Notebookâ€™unuza baÄŸlÄ± veri kaynaklarÄ±nÄ±n listesini gÃ¶rÃ¼rsÃ¼nÃ¼z; seÃ§tiÄŸim veri setine **../input/** veya **/kaggle/input/** Ã¼zerinden eriÅŸilebilir.
* AÃ§Ä±lÄ±ÅŸ bloÄŸu (iÃ§e aktarÄ±lan paketler, aÃ§Ä±klayÄ±cÄ± yorumlar ve mevcut dosyalarÄ±n listesi) yeni bir Python Notebookâ€™a otomatik olarak eklenir.

Bu temel kurulumla, analiziniz iÃ§in bir Notebook yazmaya baÅŸlayabilir ve veri setinizi veri kaynaÄŸÄ± olarak kullanabilirsiniz. Notebookâ€™larÄ± daha ayrÄ±ntÄ±lÄ± olarak **BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±ndan Yararlanmak** kÄ±smÄ±nda ele alacaÄŸÄ±z.

### Using Kaggle Datasets in Google Colab *(Google Colabâ€™da Kaggle veri setlerini kullanma)*

Kaggle Notebookâ€™larÄ± Ã¼cretsizdir, ancak sÄ±nÄ±rsÄ±z deÄŸildir (buna BÃ¶lÃ¼m 4â€™te daha ayrÄ±ntÄ±lÄ± deÄŸineceÄŸiz) ve karÅŸÄ±laÅŸabileceÄŸiniz ilk sÄ±nÄ±rlama muhtemelen **zaman limitidir**. PopÃ¼ler bir alternatif, tamamen bulutta Ã§alÄ±ÅŸan Ã¼cretsiz bir Jupyter Notebook ortamÄ± olan **Google Colab**â€™a geÃ§mektir: [https://colab.research.google.com](https://colab.research.google.com).

HesaplamalarÄ± Colabâ€™a taÅŸÄ±dÄ±ktan sonra bile Kaggle veri setlerine eriÅŸmek isteyebiliriz; bu yÃ¼zden onlarÄ± Colabâ€™a aktarmak oldukÃ§a kullanÄ±ÅŸlÄ± bir Ã¶zelliktir. Bu bÃ¶lÃ¼mÃ¼n geri kalanÄ±nda, Kaggle Datasetsâ€™i Colab Ã¼zerinden kullanmak iÃ§in gerekli adÄ±mlarÄ± ele alacaÄŸÄ±z.

Ä°lk olarak, Kaggleâ€™a zaten kayÄ±tlÄ± olduÄŸumuzu varsayarak, **API token** (giriÅŸ oturumu, kullanÄ±cÄ± kimliÄŸi, yetkiler vb. iÃ§in gÃ¼venlik bilgilerini iÃ§eren eriÅŸim belirteci) oluÅŸturmak iÃ§in hesap sayfasÄ±na gideriz:

1. HesabÄ±nÄ±za gidin: [https://www.kaggle.com/USERNAME/account](https://www.kaggle.com/USERNAME/account)

**Create New API Token** butonuna tÄ±klayÄ±n.

![](im/1013.png)

Bir **kaggle.json** dosyasÄ± oluÅŸturulacak; bu dosya kullanÄ±cÄ± adÄ±nÄ±zÄ± ve API tokenâ€™Ä±nÄ±zÄ± iÃ§erir.

2. Google Driveâ€™Ä±nÄ±zda **Kaggle** adÄ±nda bir klasÃ¶r oluÅŸturun ve **.json** dosyasÄ±nÄ± bu klasÃ¶re yÃ¼kleyin.

![](im/1014.png)

3. Ä°ÅŸlem tamamlandÄ±ktan sonra, yeni bir Colab defteri oluÅŸturmanÄ±z ve Google Driveâ€™Ä±nÄ±zÄ± baÄŸlamanÄ±z gerekir. Bunu yapmak iÃ§in defterde aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rÄ±n:

```python
from google.colab import drive
drive.mount('/content/gdrive')
```

4. URL isteminden yetkilendirme kodunu alÄ±n ve aÃ§Ä±lan boÅŸ kutuya girin, ardÄ±ndan aÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rarak `.json` yapÄ±landÄ±rma dosyasÄ±nÄ±n yolunu belirtin:

```python
import os
# content/gdrive/My Drive/Kaggle is the path where kaggle.json is
# present in the Google Drive
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
# change the working directory
%cd /content/gdrive/My Drive/Kaggle
# check the present working directory using the pwd command
```

5. ArtÄ±k veri setini indirebiliriz. Bunun iÃ§in Kaggleâ€™daki veri seti sayfasÄ±na gidin, **New Notebook** yanÄ±ndaki Ã¼Ã§ noktaya tÄ±klayÄ±n ve **Copy API command** seÃ§eneÄŸini seÃ§in:

![alt text](im/1015.png)

6. Veri setini indirmek iÃ§in API komutunu Ã§alÄ±ÅŸtÄ±rÄ±n (komutlarÄ±n detaylarÄ±yla ilgilenenler resmi dokÃ¼mantasyona bakabilir: [https://www.kaggle.com/docs/api](https://www.kaggle.com/docs/api)):

```python
!kaggle datasets download -d ajaypalsinghlo/world-happinessreport-2021
```
7. Veri seti, Kaggle klasÃ¶rÃ¼ne bir .zip arÅŸivi olarak indirilecektir â€“ arÅŸivi aÃ§Ä±n ve kullanÄ±ma hazÄ±r hale gelmiÅŸ olacaktÄ±r.

YukarÄ±daki listeden de gÃ¶rebileceÄŸiniz gibi, bir Kaggle veri setini Colabâ€™da kullanmak oldukÃ§a basit bir sÃ¼reÃ§tir â€“ tek ihtiyacÄ±nÄ±z olan bir API tokenâ€™Ä±dÄ±r ve bu geÃ§iÅŸ size Kaggleâ€™Ä±n saÄŸladÄ±ÄŸÄ±ndan daha fazla GPU saatini kullanma imkÃ¢nÄ± verir.

### Legal caveats *(Yasal uyarÄ±lar)*

Sadece bazÄ± verileri Kaggleâ€™a yÃ¼kleyebilmeniz, bunu yapmanÄ±z gerektiÄŸi anlamÄ±na gelmez. MÃ¼kemmel bir Ã¶rnek, **People of Tinder** veri setidir. 2017â€™de bir geliÅŸtirici, Tinder APIâ€™sini kullanarak web sitesinden yarÄ±-Ã¶zel profilleri Ã§ekmiÅŸ ve veriyi Kaggleâ€™a yÃ¼klemiÅŸti. Bu durum ortaya Ã§Ä±ktÄ±ktan sonra, Kaggle veri setini kaldÄ±rdÄ±. Tam hikÃ¢yeyi ÅŸuradan okuyabilirsiniz: [Forbes makalesi](https://www.forbes.com/sites/janetwburns/2017/05/02/tinder-profiles-have-been-looted-again-this-time-for-teaching-ai-to-genderize-faces/?sh=1afb86b25454).

Genel olarak, Kaggleâ€™a herhangi bir ÅŸey yÃ¼klemeden Ã¶nce kendinize ÅŸu iki soruyu sorun:

1. **Telif hakkÄ± aÃ§Ä±sÄ±ndan izinli mi?** LisanslarÄ± her zaman kontrol edin. ÅÃ¼phe durumunda [Open Definition Guide](https://opendefinition.org/guide/data/) veya Kaggle ile iletiÅŸime geÃ§ebilirsiniz.
2. **Bu veri setiyle ilgili gizlilik riskleri var mÄ±?** Belirli bilgileri paylaÅŸmak, teknik olarak yasadÄ±ÅŸÄ± olmasa da, baÅŸka bir kiÅŸinin gizliliÄŸine zarar verebilir.

Bu sÄ±nÄ±rlamalar aslÄ±nda saÄŸduyuya dayanmaktadÄ±r, bu yÃ¼zden Kaggleâ€™daki Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± engellemesi pek olasÄ± deÄŸildir.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle platformunda verileri depolamanÄ±n ve kullanmanÄ±n standart yolu olan **Kaggle Datasets**â€™i tanÄ±ttÄ±k. Veri seti oluÅŸturmayÄ±, Kaggle dÄ±ÅŸÄ±ndaki ortamlarda Ã§alÄ±ÅŸma yÃ¶ntemlerini ve en Ã¶nemli iÅŸlevi olan **veri setini Notebookâ€™ta kullanmayÄ±** ele aldÄ±k. Bu, bir sonraki bÃ¶lÃ¼mde odaklanacaÄŸÄ±mÄ±z **Kaggle Notebooks** konusuna geÃ§iÅŸ iÃ§in gÃ¼zel bir kÃ¶prÃ¼ oluÅŸturuyor.

---

## Chapter 3: Working and Learning with Kaggle Notebooks *(BÃ¶lÃ¼m 3: Kaggle Notebooks ile Ã‡alÄ±ÅŸmak ve Ã–ÄŸrenmek)*

Kaggle Notebooks â€” yakÄ±n zamana kadar **Kernels** olarak adlandÄ±rÄ±lÄ±yordu â€” tarayÄ±cÄ± Ã¼zerinden Ã§alÄ±ÅŸan ve Ã¼cretsiz olan **Jupyter Notebook**â€™lardÄ±r. Bu, internet baÄŸlantÄ±sÄ± olan herhangi bir cihazdan deneylerinizi Ã§alÄ±ÅŸtÄ±rabileceÄŸiniz anlamÄ±na gelir; ancak mobil telefondan daha bÃ¼yÃ¼k bir cihaz kullanmak muhtemelen daha iyi olacaktÄ±r. OrtamÄ±n teknik Ã¶zellikleri (yazÄ±m tarihi itibarÄ±yla) Kaggle web sitesinden alÄ±nmÄ±ÅŸtÄ±r; en gÃ¼ncel sÃ¼rÃ¼mÃ¼ **[https://www.kaggle.com/docs/notebooks](https://www.kaggle.com/docs/notebooks)** adresinden doÄŸrulanabilir:

* CPU/GPU iÃ§in 12 saat Ã§alÄ±ÅŸma sÃ¼resi, TPU iÃ§in 9 saat
* 20 GB otomatik kaydedilen disk alanÄ± (/kaggle/working)
* Ek geÃ§ici disk alanÄ± ( /kaggle/working dÄ±ÅŸÄ±nda) â€” bu alan mevcut oturum dÄ±ÅŸÄ±nda kaydedilmez

**CPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

**GPU Ã¶zellikleri:**

* 2 CPU Ã§ekirdeÄŸi
* 13 GB RAM

**TPU Ã¶zellikleri:**

* 4 CPU Ã§ekirdeÄŸi
* 16 GB RAM

Bu bÃ¶lÃ¼mde ele alacaÄŸÄ±mÄ±z konular:

* Notebook kurulumunu yapmak
* Notebookâ€™unuzu Ã§alÄ±ÅŸtÄ±rmak
* Notebookâ€™larÄ± GitHubâ€™a kaydetmek
* Notebookâ€™lardan en iyi ÅŸekilde faydalanmak
* Kaggle Learn kurslarÄ±

Hadi baÅŸlayalÄ±m. Ä°lk yapmamÄ±z gereken, bir Notebookâ€™un nasÄ±l kurulacaÄŸÄ±nÄ± Ã¶ÄŸrenmek.

### Setting up a Notebook *(Bir defter oluÅŸturma)*

Bir Notebook oluÅŸturmanÄ±n iki temel yÃ¶ntemi vardÄ±r: **ana sayfadan** veya **bir Dataset Ã¼zerinden**.

Ä°lk yÃ¶ntemi kullanmak iÃ§in:

1. [https://www.kaggle.com/](https://www.kaggle.com/) adresindeki ana sayfada, sol menÃ¼deki **Code** bÃ¶lÃ¼mÃ¼ne gidin.
2. ArdÄ±ndan **+ New Notebook** butonuna tÄ±klayÄ±n.

Bu yÃ¶ntem, kendi veri setinizi yÃ¼klemeyi iÃ§eren bir deneme planlÄ±yorsanÄ±z tercih edilen yÃ¶ntemdir.

![alt text](im/1016.png)

Alternatif olarak, ilgilendiÄŸiniz Datasetâ€™in sayfasÄ±na gidip oradaki **New Notebook** butonuna tÄ±klayabilirsiniz; bu yÃ¶ntemi bir Ã¶nceki bÃ¶lÃ¼mde gÃ¶rmÃ¼ÅŸtÃ¼k.

![alt text](im/1017.png)

Hangi yÃ¶ntemi seÃ§erseniz seÃ§in, **New Notebook** butonuna tÄ±kladÄ±ktan sonra Notebook sayfanÄ±za yÃ¶nlendirileceksiniz:

![alt text](im/1018.png)

YukarÄ±da gÃ¶sterilen yeni Notebook sayfasÄ±nÄ±n saÄŸ tarafÄ±nda, ayarlanabilecek birkaÃ§ farklÄ± ayar bulunmaktadÄ±r:

![alt text](im/1019.png)

AyarlarÄ± kÄ±saca ele alalÄ±m:

1. **Kodlama Dili (Language)**:
   Kaggle ortamÄ±, yazÄ±ldÄ±ÄŸÄ± tarihte yalnÄ±zca Python ve R dillerini destekliyor. Yeni bir Notebook varsayÄ±lan olarak Python ile aÃ§Ä±lÄ±r. R kullanmak isterseniz aÃ§Ä±lÄ±r menÃ¼den Râ€™yi seÃ§ebilirsiniz.

2. **Ortam (Environment)**:
   Bu seÃ§enek, Notebookâ€™un hangi Docker ortamÄ±nda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirler.

   * **Latest Docker**: En gÃ¼ncel ortamÄ± kullanÄ±r; hÄ±zlÄ± gÃ¼ncellemeler alÄ±rsÄ±nÄ±z ama baÄŸÄ±mlÄ±lÄ±klar bozulabilir (riskli).
   * **Original Kaggle environment**: Kaggle tarafÄ±ndan saÄŸlanan orijinal ortamÄ± kullanÄ±r (gÃ¼venli ve varsayÄ±lan).

3. **HÄ±zlandÄ±rÄ±cÄ± (Accelerator)**:
   Kodun hangi donanÄ±mda Ã§alÄ±ÅŸacaÄŸÄ±nÄ± seÃ§menizi saÄŸlar:

   * **CPU**: HÄ±zlandÄ±rmasÄ±z
   * **GPU**: Derin Ã¶ÄŸrenme uygulamalarÄ± iÃ§in gereklidir
   * **TPU**: TPUâ€™ya taÅŸÄ±mak iÃ§in veri iÅŸleme ve kodda daha kapsamlÄ± deÄŸiÅŸiklik gerekir

   CPU, GPU veya TPU arasÄ±nda geÃ§iÅŸ yapabilirsiniz; fakat geÃ§iÅŸ yaptÄ±ÄŸÄ±nÄ±zda ortam yeniden baÅŸlatÄ±lÄ±r ve tÃ¼m kodu baÅŸtan Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekir.

4. **Ä°nternet (Internet) AÃ§ma/Kapama**:
   Ä°nternete eriÅŸimi aÃ§Ä±p kapatmanÄ±zÄ± saÄŸlar. Ã–rneÄŸin, ek paket yÃ¼klemek gerektiÄŸinde internet aÃ§Ä±k olmalÄ±dÄ±r. BazÄ± yarÄ±ÅŸmalarda, teslim sÄ±rasÄ±nda internetin kapalÄ± olmasÄ± zorunludur.

AyrÄ±ca, mevcut bir Notebookâ€™u (kendinizin veya baÅŸkasÄ±nÄ±n oluÅŸturduÄŸu) **kopyalayÄ±p dÃ¼zenleyebilirsiniz**. Bunun iÃ§in Notebook sayfasÄ±nÄ±n saÄŸ Ã¼stÃ¼ndeki **Copy and Edit** butonuna tÄ±klamanÄ±z yeterlidir. Kaggleâ€™da bu iÅŸlem **forking** olarak adlandÄ±rÄ±lÄ±r.

![alt text](im/1020.png)

> Bir gÃ¶rgÃ¼ notu: EÄŸer daha Ã¶nce bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ±ysanÄ±z, sÄ±ralama tablosunun (leaderboard) iyi puan alan Notebookâ€™larÄ±n kopyalarÄ±yla (forks of forks) dolu olduÄŸunu fark etmiÅŸsinizdir. BaÅŸkasÄ±nÄ±n Ã§alÄ±ÅŸmasÄ± Ã¼zerine inÅŸa etmek yanlÄ±ÅŸ deÄŸildir; ancak bunu yaparken **orijinal yazara oy vermeyi (upvote) ve referans alÄ±nan Ã§alÄ±ÅŸmanÄ±n sahibine aÃ§Ä±kÃ§a kredi vermeyi** unutmayÄ±n.

OluÅŸturduÄŸunuz bir Notebook varsayÄ±lan olarak **Ã¶zel**dir (sadece siz gÃ¶rebilirsiniz). EÄŸer baÅŸkalarÄ±nÄ±n eriÅŸmesini istiyorsanÄ±z iki seÃ§enek vardÄ±r:

1. **Ä°ÅŸbirlikÃ§ileri eklemek (adding collaborators):** Sadece aÃ§Ä±kÃ§a eklenen kullanÄ±cÄ±lar Notebookâ€™u gÃ¶rebilir veya dÃ¼zenleyebilir.
2. **Notebookâ€™u herkese aÃ§Ä±k yapmak (making public):** Bu durumda herkes Notebookâ€™u gÃ¶rebilir.

### Running your Notebook *(Defterinizi Ã§alÄ±ÅŸtÄ±rma)*

TÃ¼m kodlamalar tamamlandÄ±, Notebook sorunsuz Ã§alÄ±ÅŸÄ±yor gibi gÃ¶rÃ¼nÃ¼yor ve Ã§alÄ±ÅŸtÄ±rmaya hazÄ±rsÄ±nÄ±z. Bunu yapmak iÃ§in, Notebook sayfanÄ±zÄ±n **saÄŸ Ã¼st kÃ¶ÅŸesine** gidin ve **Save Version** (SÃ¼rÃ¼mÃ¼ Kaydet) dÃ¼ÄŸmesine tÄ±klayÄ±n.

![](im/1021.png)

**Save & Run All** genellikle tÃ¼m scripti Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r, ancak **Quick Save** seÃ§eneÄŸi de vardÄ±r; bu, script henÃ¼z gÃ¶nderime hazÄ±r olmadan Ã¶nce ara bir sÃ¼rÃ¼mÃ¼ kaydetmek iÃ§in kullanÄ±labilir.

![](im/1022.png)

Scriptinizi baÅŸlattÄ±ktan sonra, sol alt kÃ¶ÅŸeye gidip **Active Events** (Aktif Etkinlikler) butonuna tÄ±klayabilirsiniz. Bu bÃ¶lÃ¼m, Ã§alÄ±ÅŸmakta olan Notebook sÃ¼rÃ¼mlerinizin durumunu ve ilerlemesini izlemenizi saÄŸlar.

![](im/1023.png)

Bu ÅŸekilde, Notebookâ€™larÄ±nÄ±zÄ±n Ã§alÄ±ÅŸma durumunu takip edebilirsiniz. Normal bir yÃ¼rÃ¼tme sÄ±rasÄ±nda **Running** mesajÄ± gÃ¶rÃ¼nÃ¼r; aksi durumda **Failed** olarak gÃ¶rÃ¼ntÃ¼lenir.

EÄŸer herhangi bir nedenle (Ã¶rneÄŸin en gÃ¼ncel veriyi kullanmayÄ± unuttuÄŸunuzu fark ederseniz) Ã§alÄ±ÅŸan bir oturumu sonlandÄ±rmak isterseniz, **Active Events** altÄ±nda script giriÅŸinizin saÄŸ tarafÄ±ndaki Ã¼Ã§ noktaya tÄ±klayabilirsiniz. Bu iÅŸlem size aÅŸaÄŸÄ±daki ÅŸekilde bir aÃ§Ä±lÄ±r pencere (pop-up) gÃ¶sterecektir ve oturumu durdurmanÄ±za olanak tanÄ±r.

![](im/1024.png)

### Saving Notebooks to GitHub *(Defterleri GitHubâ€™a kaydetme)*

YakÄ±n zamanda eklenen bir Ã¶zellik (bkz. [https://www.kaggle.com/product-feedback/295170](https://www.kaggle.com/product-feedback/295170)), kodunuzu veya Notebookâ€™unuzu GitHub sÃ¼rÃ¼m kontrol deposuna ([https://github.com/](https://github.com/)) kaydetmenize olanak tanÄ±r. Ã‡alÄ±ÅŸmanÄ±zÄ± hem **public** hem de **private** depolara kaydedebilirsiniz ve bu iÅŸlem, kodunuzun bir versiyonunu kaydettiÄŸinizde otomatik olarak gerÃ§ekleÅŸir.

Bu Ã¶zellik, hem Kaggle takÄ±m arkadaÅŸlarÄ±nÄ±zla Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± paylaÅŸmak hem de Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± daha geniÅŸ bir kitleye sergilemek iÃ§in oldukÃ§a faydalÄ± olabilir.

Bu Ã¶zelliÄŸi etkinleÅŸtirmek iÃ§in:

1. Notebookâ€™unuzu aÃ§Ä±n.
2. Ãœst menÃ¼den **File** menÃ¼sÃ¼ne gidin.
3. **Link to GitHub** seÃ§eneÄŸini tÄ±klayÄ±n.

![](im/1025.png)

Bu seÃ§eneÄŸi seÃ§tikten sonra, GitHub hesabÄ±nÄ±zÄ± Notebook ile baÄŸlamanÄ±z gerekecek. Ä°lk kez baÄŸlama iÅŸlemi yaptÄ±ÄŸÄ±nÄ±zda, aÃ§Ä±kÃ§a **baÄŸlantÄ± izinleri** sorulacaktÄ±r. Sonraki yeni Notebookâ€™larda ise bu iÅŸlem otomatik olarak gerÃ§ekleÅŸtirilecektir.

![](im/1026.png)

Notebookâ€™unuzu ancak baÄŸladÄ±ktan sonra, kaydettiÄŸinizde Ã§alÄ±ÅŸmanÄ±zÄ± seÃ§tiÄŸiniz bir GitHub deposuyla senkronize etme izniniz olur.

![](im/1027.png)

Bir depo ve dal (branch) seÃ§tikten sonra, Ã§alÄ±ÅŸmanÄ±zÄ±n farklÄ± geliÅŸtirme aÅŸamalarÄ±nÄ± saklamanÄ±za olanak tanÄ±r ve depoya gÃ¶ndereceÄŸiniz dosyanÄ±n adÄ±nÄ± deÄŸiÅŸtirebilir ve commit mesajÄ±nÄ± dÃ¼zenleyebilirsiniz.

ArtÄ±k belirli bir Notebookâ€™u GitHub ile senkronize etmek istemiyorsanÄ±z, tek yapmanÄ±z gereken Dosya menÃ¼sÃ¼nden **Unlink from GitHub** seÃ§eneÄŸini tÄ±klamaktÄ±r.

Son olarak, Kaggleâ€™Ä±n GitHub hesabÄ±nÄ±za baÄŸlanmasÄ±nÄ± tamamen durdurmak isterseniz, hesaplarÄ±nÄ±zÄ± ya Kaggleâ€™daki **My linked accounts** sayfasÄ±ndan ya da GitHubâ€™daki [ayarlar](https://github.com/settings/applications) sayfasÄ±ndan ayÄ±rabilirsiniz.

### Getting the most out of Notebooks *(Defterlerden en iyi ÅŸekilde yararlanma)*

Kaggle, belirli miktarda kaynaklarÄ± Ã¼cretsiz olarak saÄŸlar ve bu kotlar haftalÄ±k olarak sÄ±fÄ±rlanÄ±r. GPU ve TPU kullanÄ±mÄ± iÃ§in belli bir saat hakkÄ±nÄ±z vardÄ±r; TPU iÃ§in bu sÃ¼re 30 saattir, GPU iÃ§in ise haftadan haftaya deÄŸiÅŸen bir kota uygulanÄ±r (resmÃ® aÃ§Ä±klamayÄ± ve â€œfloatingâ€ kotalar politikasÄ±nÄ± [buradan](https://www.kaggle.com/product-feedback/173129) inceleyebilirsiniz).

Kendi kullanÄ±mÄ±nÄ±zÄ± her zaman profilinizden takip edebilirsiniz.

![](im/1028.png)

Ä°lk bakÄ±ÅŸta kaynak miktarlarÄ± bÃ¼yÃ¼k gÃ¶rÃ¼nebilir, ancak bu izlenim yanÄ±ltÄ±cÄ± olabilir; kotanÄ±zÄ± oldukÃ§a hÄ±zlÄ± bir ÅŸekilde tÃ¼ketmek kolaydÄ±r. Kaynak kullanÄ±mÄ±nÄ± kontrol etmenize yardÄ±mcÄ± olacak bazÄ± pratik Ã¶neriler:

* Kota sayacÄ± (GPU veya TPU gibi seÃ§tiÄŸiniz hÄ±zlandÄ±rÄ±cÄ±yÄ± ne kadar sÃ¼re kullandÄ±ÄŸÄ±nÄ±zÄ± Ã¶lÃ§en sayaÃ§) Notebookâ€™u baÅŸlattÄ±ÄŸÄ±nÄ±z anda Ã§alÄ±ÅŸmaya baÅŸlar.
* Bu nedenle, Ã¶ncelikle ayarlardan GPUâ€™nun devre dÄ±ÅŸÄ± olduÄŸundan emin olun (bkz. Åekil 3.6). Ã–nce temel kodu yazÄ±n, sÃ¶zdizimini kontrol edin ve yalnÄ±zca GPU gerektiren kod parÃ§alarÄ±nÄ± eklediÄŸinizde GPUâ€™yu etkinleÅŸtirin. HatÄ±rlatma: HÄ±zlandÄ±rÄ±cÄ±yÄ± deÄŸiÅŸtirdiÄŸinizde Notebook yeniden baÅŸlatÄ±lÄ±r.
* Kodun tamamÄ±nÄ± kÃ¼Ã§Ã¼k bir veri alt kÃ¼mesi Ã¼zerinde Ã§alÄ±ÅŸtÄ±rmak genellikle iyi bir fikirdir; bÃ¶ylece Ã§alÄ±ÅŸtÄ±rma sÃ¼resini tahmin edebilir ve kotayÄ± aÅŸarak kodun Ã§Ã¶kmesi riskini en aza indirirsiniz.

Bazen Kaggleâ€™Ä±n Ã¼cretsiz olarak saÄŸladÄ±ÄŸÄ± kaynaklar, yapÄ±lacak iÅŸ iÃ§in yeterli olmayabilir ve daha gÃ¼Ã§lÃ¼ bir makineye geÃ§meniz gerekir. Ã–rneÄŸin, yakÄ±n zamanda yapÄ±lan bir tÃ¼mÃ¶r sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmasÄ±: [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification/data).

EÄŸer ham veriniz 100GBâ€™dan bÃ¼yÃ¼kse, ya gÃ¶rÃ¼ntÃ¼leri yeniden boyutlandÄ±rmalÄ±/aÅŸaÄŸÄ± Ã¶rneklemeli (bu model performansÄ±nÄ± olumsuz etkileyebilir) ya da yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼leri iÅŸleyebilecek bir ortamda model eÄŸitmelisiniz. BÃ¼tÃ¼n ortamÄ± kendiniz kurabilirsiniz (Ã¶rnek olarak, BÃ¶lÃ¼m 2â€™deki â€œGoogle Colabâ€™da Kaggle Datasets KullanÄ±mÄ±â€ kÄ±smÄ±na bakabilirsiniz) veya Notebooks Ã§erÃ§evesinde kalÄ±p, altyapÄ± makinesini deÄŸiÅŸtirebilirsiniz. Ä°ÅŸte burada Google Cloud AI Notebooks devreye girer.

### Upgrading to Google Cloud Platform (GCP) *(Google Cloud Platformâ€™a (GCP) yÃ¼kseltme)*

GCPâ€™ye (Google Cloud Platform) geÃ§menin bariz avantajÄ±, daha gÃ¼Ã§lÃ¼ donanÄ±ma eriÅŸim saÄŸlamaktÄ±r: Kaggle tarafÄ±ndan saÄŸlanan Tesla P100 GPU birÃ§ok uygulama iÃ§in yeterli olsa da performans aÃ§Ä±sÄ±ndan en Ã¼st seviye deÄŸildir ve 16 GB RAM de Ã¶zellikle bÃ¼yÃ¼k NLP modelleri veya yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼ iÅŸleme gibi kaynak yoÄŸun uygulamalarda sÄ±nÄ±rlayÄ±cÄ± olabilir. Ã‡alÄ±ÅŸtÄ±rma sÃ¼resindeki iyileÅŸme, geliÅŸtirme dÃ¶ngÃ¼sÃ¼nde daha hÄ±zlÄ± iterasyon imkÃ¢nÄ± saÄŸlarken, bunun bir maliyeti vardÄ±r: Ne kadar harcamaya hazÄ±r olduÄŸunuzu belirlemeniz gerekir. GÃ¼Ã§lÃ¼ bir makine ile veri iÅŸlemek sÃ¶z konusu olduÄŸunda zaman, kelimenin tam anlamÄ±yla paradÄ±r.

Notebookâ€™unuzu GCP ortamÄ±na taÅŸÄ±mak iÃ§in, saÄŸ taraftaki yan menÃ¼den **Upgrade to Google Cloud AI Notebooks** seÃ§eneÄŸine tÄ±klayÄ±n.

![](im/1029.png)

Åu ifadeyle karÅŸÄ±lanacaksÄ±nÄ±z:

![](im/1030.png)

â€œDevam Etâ€e tÄ±kladÄ±ÄŸÄ±nÄ±zda, faturalandÄ±rma seÃ§eneklerinizi yapÄ±landÄ±rmanÄ±z gereken Google Cloud Platform konsoluna yÃ¶nlendirileceksiniz. HatÄ±rlatma: GCP Ã¼cretsiz deÄŸildir. Ä°lk kez kullanÄ±yorsanÄ±z, gerekli adÄ±mlar boyunca size rehberlik edecek bir Ã¶ÄŸreticiyi (tutorial) tamamlamanÄ±z gerekecektir.

### One step beyond *(Bir adÄ±m Ã¶teye geÃ§mek)*

Bu bÃ¶lÃ¼mÃ¼n Ã¶nceki kÄ±sÄ±mlarÄ±nda da belirtildiÄŸi gibi, **Kaggle Notebooks** (Kaggle Defterleri) eÄŸitim ve yarÄ±ÅŸmalara katÄ±lÄ±m iÃ§in harika bir araÃ§tÄ±r; ancak aynÄ± zamanda bir baÅŸka son derece faydalÄ± amaca da hizmet eder: **veri bilimi becerilerinizi sergileyebileceÄŸiniz bir portfÃ¶yÃ¼n parÃ§asÄ±** olarak kullanÄ±labilirler.

Bir veri bilimi portfÃ¶yÃ¼ oluÅŸtururken dikkate alÄ±nabilecek birÃ§ok potansiyel kriter vardÄ±r (markalaÅŸma, hedef kitleye ulaÅŸma, potansiyel iÅŸvereninize kendinizi tanÄ±tma vb.); ancak kimse portfÃ¶yÃ¼nÃ¼zÃ¼ bulamazsa, bunlarÄ±n hiÃ§birinin Ã¶nemi kalmaz. Kaggle, Googleâ€™Ä±n bir parÃ§asÄ± olduÄŸu iÃ§in Notebooks (defterler), dÃ¼nyanÄ±n en popÃ¼ler arama motoru tarafÄ±ndan dizine eklenir; dolayÄ±sÄ±yla biri kodunuzla ilgili bir konuyu aradÄ±ÄŸÄ±nda, Ã§alÄ±ÅŸmanÄ±z arama sonuÃ§larÄ±nda gÃ¶rÃ¼nebilir.

AÅŸaÄŸÄ±da kiÅŸisel bir Ã¶rnek gÃ¶steriyorum: birkaÃ§ yÄ±l Ã¶nce bir yarÄ±ÅŸma iÃ§in bir Notebook yazmÄ±ÅŸtÄ±m. Ãœzerinde Ã§alÄ±ÅŸmak istediÄŸim problem, **adversarial validation** (karÅŸÄ±t doÄŸrulama) idi. (Bu konuya aÅŸina olmayanlar iÃ§in kÄ±sa bir aÃ§Ä±klama: eÄŸitim ve test veri kÃ¼melerinizin benzer bir daÄŸÄ±lÄ±ma sahip olup olmadÄ±ÄŸÄ±nÄ± anlamanÄ±n oldukÃ§a kolay bir yolu, onlarÄ± ayÄ±rt etmeyi Ã¶ÄŸrenen ikili bir sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturmaktÄ±r; bu kavram 6. BÃ¶lÃ¼mâ€™de, *Ä°yi Bir DoÄŸrulama Tasarlama* kÄ±smÄ±nda daha ayrÄ±ntÄ±lÄ± olarak ele alÄ±nmÄ±ÅŸtÄ±r.)

Bu bÃ¶lÃ¼mÃ¼ yazarken, o defteri aramayÄ± denedim ve tahmin edin ne oldu â€” arama sonuÃ§larÄ±nda oldukÃ§a Ã¼st sÄ±ralarda gÃ¶rÃ¼ndÃ¼. (Dikkat ederseniz, arama sorguma â€œKaggleâ€ veya adÄ±m gibi kiÅŸisel bilgiler eklemedim.)

![](im/1031.png)

Notebooks kullanarak becerilerinizi sergilemenin diÄŸer avantajlarÄ±na geÃ§elim: **Competitions (YarÄ±ÅŸmalar)**, **Datasets (Veri KÃ¼meleri)** ve **Discussions (TartÄ±ÅŸmalar)** bÃ¶lÃ¼mlerinde olduÄŸu gibi, **Notebooks** da oy (vote) ve madalya (medal) alabilir. Bu sayede Kaggleâ€™daki ilerleme sisteminde ve sÄ±ralamalarda yerinizi alabilirsiniz.

YarÄ±ÅŸmalara hiÃ§ katÄ±lmadan da, yalnÄ±zca topluluk tarafÄ±ndan beÄŸenilen yÃ¼ksek kaliteli kodlara odaklanarak **Expert (Uzman)**, **Master (Usta)** veya **Grandmaster (BÃ¼yÃ¼k Usta)** unvanlarÄ±na ulaÅŸabilirsiniz.

Ä°lerleme gereksinimlerinin en gÃ¼ncel hÃ¢lini [https://www.kaggle.com/progression](https://www.kaggle.com/progression) adresinde bulabilirsiniz; aÅŸaÄŸÄ±da ise **Expert** ve **Master** seviyeleriyle ilgili bir Ã¶zet yer almaktadÄ±r:

![](im/1032.png)

**Notebooks** kategorisinde ilerlemek zorlu bir deneyim olabilir; **Competitions (YarÄ±ÅŸmalar)** bÃ¶lÃ¼mÃ¼ne gÃ¶re biraz daha kolay olsa da, **Discussions (TartÄ±ÅŸmalar)** bÃ¶lÃ¼mÃ¼nden kesinlikle daha zordur. En popÃ¼ler Notebooks genellikle belirli bir yarÄ±ÅŸmayla baÄŸlantÄ±lÄ± olanlardÄ±r: **keÅŸifsel veri analizi (exploratory data analysis)**, **uÃ§tan uca kavramsal kanÄ±t Ã§Ã¶zÃ¼mleri (end-to-end proof of concept)** ve **liderlik tablosu kovalamaca (leaderboard chasing)** gibi konulara odaklanÄ±rlar.

Ne yazÄ±k ki, sÄ±kÃ§a rastlanan bir uygulama da ÅŸudur: bazÄ± kiÅŸiler en yÃ¼ksek puanÄ± alan herkese aÃ§Ä±k bir Notebookâ€™u kopyalar (clone eder), birkaÃ§ parametreyi deÄŸiÅŸtirerek skoru biraz artÄ±rÄ±r ve ardÄ±ndan bunu bÃ¼yÃ¼k beÄŸeniyle (upvoteâ€™lar bir beÄŸeni Ã¶lÃ§Ã¼sÃ¼ olarak kabul edilirse) yayÄ±mlar. Bu durum, okuyucunun Kaggleâ€™da kaliteli Ã§alÄ±ÅŸmalar yayÄ±mlama isteÄŸini kÄ±rmak iÃ§in sÃ¶ylenmemektedir â€” Ã§Ã¼nkÃ¼ Kaggle topluluÄŸunun bÃ¼yÃ¼k bir kÄ±smÄ± yenilikÃ§i Ã§alÄ±ÅŸmalarÄ± gerÃ§ekten takdir eder ve uzun vadede kalite her zaman Ã¶ne Ã§Ä±kar â€” ancak **beklentilerin gerÃ§ekÃ§i bir ÅŸekilde ayarlanmasÄ±** gerekir.

Kaggle profilinizin takipÃ§ileri (followers) olur ve **LinkedIn** veya **GitHub** gibi diÄŸer profesyonel aÄŸlarla baÄŸlantÄ± kurma olanaÄŸÄ± sunar; bÃ¶ylece topluluk iÃ§inde kazandÄ±ÄŸÄ±nÄ±z baÄŸlantÄ±larÄ± **fÄ±rsata dÃ¶nÃ¼ÅŸtÃ¼rebilirsiniz**.

![](im/1033.png)

GÃ¼nÃ¼mÃ¼zde â€œtopluluk oluÅŸturmaâ€ iddialarÄ±na karÅŸÄ± kuÅŸkucu olmak oldukÃ§a kolaydÄ±r, ancak **Kaggle** sÃ¶z konusu olduÄŸunda bu durum gerÃ§ekten doÄŸrudur. Kaggleâ€™Ä±n veri bilimi dÃ¼nyasÄ±ndaki marka bilinirliÄŸi, hem uygulayÄ±cÄ±lar (practitioners) hem de iÅŸini gerÃ§ekten iyi yapan iÅŸe alÄ±m uzmanlarÄ± (recruiters) arasÄ±nda rakipsizdir.

Pratikte bu ÅŸu anlama gelir: **yeterince iyi bir Kaggle profili**, sizi zaten â€œkapÄ±dan iÃ§eri sokabilirâ€ â€” ki hepimizin bildiÄŸi gibi, bu genellikle en zor adÄ±mdÄ±r.

> **Martin Henze**
> 
> [https://www.kaggle.com/headsortails](https://www.kaggle.com/headsortails)
> 
> 
> 
> Martin Henze, yani â€œHeads or Tailsâ€ ile konuÅŸma fÄ±rsatÄ±nÄ± bulduk. Kendisi Notebooks ve Discussion alanlarÄ±nda bir **Kaggle Grandmaster** (bÃ¼yÃ¼k usta) ve **Edison Software**â€™da bir veri bilimci. Martin aynÄ± zamanda, her hafta gÃ¶zden kaÃ§mÄ±ÅŸ en iyi Notebooksâ€™larÄ± bir araya getirdiÄŸi **â€œNotebooks of the Week: Hidden Gemsâ€** adlÄ± koleksiyonun yazarÄ±. Yeni â€œHidden Gemsâ€ paylaÅŸÄ±mlarÄ±ndan haberdar olmak iÃ§in Kaggle profilini veya Twitter ve LinkedIn hesaplarÄ±nÄ± takip edebilirsiniz.
> 
> 
> 
> ---
> 
> 
> 
> En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ hangisi ve neden? Teknik aÃ§Ä±dan ya da Ã§Ã¶zÃ¼m yaklaÅŸÄ±mÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™daki uzmanlÄ±k alanÄ±n nedir?
> 
> 
> 
> Uzun bir sÃ¼re boyunca odak noktam, sÄ±ralama tablolarÄ±ndaki tahminlerden ziyade **EDA (exploratory data analysis â€“ keÅŸifsel veri analizi)** not defterleri oldu. Kaggleâ€™dan Ã¶nceki deneyimlerimin Ã§oÄŸu tablo (tabular) verilerleydi ve EDA not defterlerimin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu da yeni baÅŸlayan tablo tabanlÄ± yarÄ±ÅŸmalardan karmaÅŸÄ±k iÃ§gÃ¶rÃ¼ler Ã§Ä±karmak Ã¼zerineydi. Bunu hÃ¢lÃ¢ Kaggleâ€™daki uzmanlÄ±k alanÄ±m olarak gÃ¶rÃ¼yorum ve not defterlerimin yapÄ±sÄ±nÄ±, veri gÃ¶rselleÅŸtirmelerini ve anlatÄ±m biÃ§imini tasarlamaya Ã§ok zaman harcadÄ±m.
> 
> 
> 
> ---
> 
> 
> 
> Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsun? Bu yaklaÅŸÄ±m gÃ¼nlÃ¼k iÅŸinde yaptÄ±klarÄ±ndan ne kadar farklÄ±?
> 
> 
> 
> Kaggle her ne kadar tablo tabanlÄ± yarÄ±ÅŸmalardan uzaklaÅŸmÄ±ÅŸ olsa da, ben hÃ¢lÃ¢ bir yarÄ±ÅŸmadaki en Ã¶nemli unsurun **verinin kendisi** olduÄŸuna inanÄ±yorum. Model mimarilerine ve hiperparametre ayarlamalarÄ±na fazla erken odaklanmak kolaydÄ±r. Ancak birÃ§ok yarÄ±ÅŸmada baÅŸarÄ±ya ulaÅŸmanÄ±n anahtarÄ±, verisetinin ayrÄ±ntÄ±lÄ± ÅŸekilde anlaÅŸÄ±lmasÄ±na dayanan veri merkezli bir yaklaÅŸÄ±mdÄ±r. Bu; gÃ¶rÃ¼ntÃ¼ verisi, NLP, zaman serisi ya da baÅŸka veri tÃ¼rleri iÃ§in de geÃ§erlidir.
> 
> Bu yÃ¼zden, her zaman kapsamlÄ± bir **EDA** ile baÅŸlarÄ±m; ardÄ±ndan basit bir temel model, bir Ã§apraz doÄŸrulama (CV) Ã§erÃ§evesi kurar ve bu yapÄ±nÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yavaÅŸ yavaÅŸ artÄ±rÄ±rÄ±m.
> 
> 
> 
> GÃ¼nlÃ¼k veri bilimi iÅŸimle en bÃ¼yÃ¼k fark muhtemelen ÅŸu: Deneyimli Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n, yeni bir yarÄ±ÅŸmanÄ±n ilk haftasÄ±nda kurduÄŸu temel modeller, endÃ¼stride Ã¼retime alÄ±nacak dÃ¼zeyde kabul edilir. Ã‡oÄŸu durumda, o ilk birkaÃ§ gÃ¼nÃ¼n sonunda nihai kazananÄ±n puanÄ±na %80 oranÄ±nda yaklaÅŸmÄ±ÅŸ oluruz.
> 
> Elbette Kaggleâ€™daki eÄŸlence ve zorluk, o son birkaÃ§ yÃ¼zde puanlÄ±k farkÄ± yaratacak yaratÄ±cÄ± yollar bulmaktÄ±r. Ancak bir ÅŸirkette, o zamanÄ± genellikle yeni bir projeye baÅŸlamak iÃ§in harcamak daha verimlidir.
> 
> 
> 
> ---
> 
> 
> 
> Kaggle kariyerine yardÄ±mcÄ± oldu mu? Olduysa nasÄ±l?
> 
> 
> 
> Kaggle kariyerimi olaÄŸanÃ¼stÃ¼ derecede ÅŸekillendirdi ve destekledi. Kaggle topluluÄŸundaki harika deneyimim beni akademiden endÃ¼striye geÃ§meye motive etti. Åu anda bir teknoloji giriÅŸiminde veri bilimci olarak Ã§alÄ±ÅŸÄ±yorum ve Kaggle yarÄ±ÅŸmalarÄ± aracÄ±lÄ±ÄŸÄ±yla becerilerimi sÃ¼rekli geliÅŸtiriyorum.
> 
> 
> 
> Benim durumumda, kapsamlÄ± Kaggle Notebooksâ€™larÄ± oluÅŸturma odaÄŸÄ±m Ã§ok faydalÄ± oldu; Ã§Ã¼nkÃ¼ bunlarÄ± kolayca **portfÃ¶yÃ¼m** olarak kullanabildim.
> 
> Bir iÅŸe alÄ±m yÃ¶neticisinin gerÃ§ekten bu kaynaklara ne kadar baktÄ±ÄŸÄ±nÄ± bilmiyorum ama sÄ±klÄ±kla â€œGrandmasterâ€ unvanÄ±mÄ±n, doktora (PhD) derecemden daha fazla kapÄ± aÃ§tÄ±ÄŸÄ± izlenimini edindim. Ya da belki ikisinin birleÅŸimi iÅŸe yaradÄ±.
> 
> Her durumda, herkese kamuya aÃ§Ä±k bir Notebooks portfÃ¶yÃ¼ne sahip olmayÄ± tavsiye ederim. AyrÄ±ca iÅŸ arayÄ±ÅŸÄ±m sÄ±rasÄ±nda, Kaggleâ€™da Ã¶ÄŸrendiÄŸim stratejileri ev Ã¶devi tarzÄ± deÄŸerlendirmelerde uyguladÄ±m ve bunlar bana Ã§ok yardÄ±mcÄ± oldu.
> 
> 
> 
> ---
> 
> 
> 
> Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ± ÅŸey nedir? BaÅŸlarken bilmediÄŸin ama ÅŸimdi bildiÄŸin bir ÅŸey var mÄ±?
> 
> 
> 
> Hepimiz sÃ¼rekli deneyim kazanÄ±yoruz. On yÄ±l, beÅŸ yÄ±l ya da bir yÄ±l Ã¶ncesine gÃ¶re hepimiz daha bilgeyiz.
> 
> Bunu bir kenara koyarsak, sÄ±klÄ±kla gÃ¶zden kaÃ§an en Ã¶nemli ÅŸeylerden biri, **ne yaptÄ±ÄŸÄ±nÄ±za dair bir planÄ±nÄ±zÄ±n olmasÄ±** ve bu planÄ± **uygulayÄ±p belgelemeniz** gerektiÄŸidir.
> 
> Yeni baÅŸlayan Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n bunu atlamasÄ± anlaÅŸÄ±lÄ±r bir durum, Ã§Ã¼nkÃ¼ her ÅŸey yeni, karmaÅŸÄ±k ve kafa karÄ±ÅŸtÄ±rÄ±cÄ±dÄ±r. Kaggleâ€™a ilk katÄ±ldÄ±ÄŸÄ±mda benim iÃ§in de Ã¶yleydi: forumlar, veri setleri, yarÄ±ÅŸmalar, kurslarâ€¦ Hepsi birbirine karÄ±ÅŸÄ±yordu.
> 
> Ve yarÄ±ÅŸmalar bazen gerÃ§ekten gÃ¶z korkutucu: *NÃ¶ronal HÃ¼cre Segmentasyonu*, *Borsa OynaklÄ±ÄŸÄ± Tahmini*â€¦ Bunlar ne ki?
> 
> Ama yarÄ±ÅŸmalar aynÄ± zamanda baÅŸlamanÄ±n da en iyi yoludur.
> 
> 
> 
> Bir yarÄ±ÅŸma baÅŸladÄ±ÄŸÄ±nda aslÄ±nda kimsenin tam bir fikri yoktur. Belki konuyla neredeyse aynÄ± konuda doktora yapmÄ±ÅŸ biri vardÄ±r ama bu nadirdir. Geri kalan herkes sÄ±fÄ±rdan baÅŸlar.
> 
> Veriyi inceleyerek, kayÄ±p fonksiyonlarÄ±yla oynayarak, basit baÅŸlangÄ±Ã§ modelleri Ã§alÄ±ÅŸtÄ±rarak Ã¶ÄŸrenirsiniz.
> 
> Bir yarÄ±ÅŸmaya en baÅŸÄ±nda katÄ±ldÄ±ÄŸÄ±nÄ±zda, bu Ã¶ÄŸrenme sÃ¼recini hÄ±zlandÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde, topluluÄŸun bir parÃ§asÄ± olarak yaÅŸarsÄ±nÄ±z. Topluluktaki diÄŸerleri size tonlarca fikir saÄŸlar. Ama yine de bir **planÄ±nÄ±zÄ±n** olmasÄ± gerekir.
> 
> 
> 
> Plan Ã¶nemlidir; Ã§Ã¼nkÃ¼ bazen sadece rastgele deneyler Ã§alÄ±ÅŸtÄ±rÄ±r, GPU belleÄŸinin dolduÄŸunu gÃ¶rÃ¼p mutlu olursunuz ama sonra en iyi modeli hangisiydi unutur, yerel doÄŸrulama ile lider tablosu arasÄ±nda korelasyon var mÄ±ydÄ± hatÄ±rlamazsÄ±nÄ±z.
> 
> Bu yÃ¼zden ne yapacaÄŸÄ±nÄ±zÄ± yazÄ±n ve sonuÃ§larÄ± kaydedin.
> 
> Bunun iÃ§in otomatik loglama araÃ§larÄ± giderek artÄ±yor ama basit bir Ã¶zel betik (script) ile de yapÄ±labilir.
> 
> 
> 
> Makine Ã¶ÄŸrenimi hÃ¢lÃ¢ bÃ¼yÃ¼k Ã¶lÃ§Ã¼de **deneysel bir bilimdir**, ve verimli deneylerin anahtarÄ± onlarÄ± iyi planlamak ve sonuÃ§larÄ± yazarak karÅŸÄ±laÅŸtÄ±rabilmektir.
> 
> 
> 
> ---
> 
> 
> 
> GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±n hatalar nelerdi?
> 
> 
> 
> BirÃ§ok hata yaptÄ±m ve onlardan ders Ã§Ä±karmayÄ± baÅŸardÄ±ÄŸÄ±mÄ± umuyorum.
> 
> SaÄŸlam bir **Ã§apraz doÄŸrulama (CV) Ã§erÃ§evesi** kurmamak bunlardan biriydi.
> 
> EÄŸitim ve test setleri arasÄ±ndaki farklarÄ± hesaba katmamak, Ã§ok fazla EDA yapÄ±p model kurulumunu ihmal etmek â€” bu ilk birkaÃ§ yarÄ±ÅŸmadaki â€œimza hatamâ€ olabilir.
> 
> Yeterince EDA yapmayÄ±p Ã¶nemli bir ÅŸeyi kaÃ§Ä±rmak â€” evet, onu da yaptÄ±m.
> 
> Finalde gÃ¶ndereceÄŸim iki modeli seÃ§meyi unutmak â€” Ã§ok fark yaratmadÄ± ama bir daha asla unutmam.
> 
> 
> 
> Ama hatalarla ilgili Ã¶nemli nokta ÅŸu: Deney ve plan konusundaki Ã¶nceki dÃ¼ÅŸÃ¼ncemle aynÄ±.
> 
> Hatalar **Ã¶ÄŸreniyorsanÄ±z** ve sizi geliÅŸtirmeye yardÄ±mcÄ± oluyorsa sorun deÄŸildir.
> 
> Tabii ki Ã¶ngÃ¶rÃ¼yle Ã¶nlenebilecek basit hatalardan kaÃ§Ä±nmak istersiniz.
> 
> Ama makine Ã¶ÄŸreniminde (ve bilimde!) baÅŸarÄ±sÄ±zlÄ±k sÃ¼recin bir parÃ§asÄ±dÄ±r.
> 
> Her ÅŸey her zaman iÅŸe yaramayacaktÄ±r â€” ve bu normaldir.
> 
> Ancak aynÄ± hatalarÄ± tekrar tekrar yapmak istemezsiniz.
> 
> DolayÄ±sÄ±yla gerÃ§ek hata, hatalarÄ±nÄ±zdan **ders almamaktÄ±r**.
> 
> Bu hem Kaggle yarÄ±ÅŸmalarÄ± hem de hayat iÃ§in geÃ§erlidir.
> 
> 
> 
> ---
> 
> 
> 
> Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸin araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?
> 
> 
> 
> Evet, gÃ¼nÃ¼mÃ¼zde giderek daha fazla **Python** kullanÄ±yoruz; ancak tablo verileriyle Ã§alÄ±ÅŸmak ve veri gÃ¶rselleÅŸtirmek sÃ¶z konusu olduÄŸunda hÃ¢lÃ¢ **R** ve **tidyverse** (Ã¶r. `dplyr`, `ggplot2`, `lubridate`) tercih ediyorum.
> 
> Yeni **tidymodels** Ã§erÃ§evesi de `sklearn`â€™e ciddi bir rakip.
> 
> SÄ±kÄ± bir Python hayranÄ± olsanÄ±z bile, zaman zaman `pandas` ve benzeri araÃ§larÄ±n Ã¶tesine bakmak faydalÄ±dÄ±r.
> 
> FarklÄ± araÃ§lar farklÄ± bakÄ±ÅŸ aÃ§Ä±larÄ± ve daha fazla yaratÄ±cÄ±lÄ±k getirir.
> 
> 
> 
> Derin Ã¶ÄŸrenim aÃ§Ä±sÄ±ndan **PyTorch**â€™u en sezgisel buluyorum, Ã¶zellikle de **FastAI** arayÃ¼zÃ¼yle birlikte.
> 
> Ve tabii ki gÃ¼nÃ¼mÃ¼zde herkesin sevdiÄŸi **Hugging Face** â€” hem de Ã§ok haklÄ± sebeplerle.
> 
> 
> 
> ---
> 
> 
> 
> Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± veya yapÄ±lmasÄ± gereken en Ã¶nemli ÅŸey nedir?
> 
> 
> 
> En Ã¶nemlisi **eÄŸlenmek** ve **bir ÅŸeyler Ã¶ÄŸrenmek**.
> 
> Bir yarÄ±ÅŸma sÄ±rasÄ±nda ve sonrasÄ±nda paylaÅŸÄ±lan o kadar Ã§ok deÄŸerli bilgi ve deneyim var ki, bunlardan yararlanmamak bÃ¼yÃ¼k bir kayÄ±p olur.
> 
> Sadece kazanmak isteseniz bile, bunu ancak Ã¶ÄŸrenerek, deneyerek ve topluluÄŸun desteÄŸinden faydalanarak baÅŸarabilirsiniz.
> 
> Ama Kaggle, lider tablolarÄ±ndan Ã§ok daha fazlasÄ±dÄ±r; topluluÄŸa katkÄ± yapmaya baÅŸladÄ±ÄŸÄ±nÄ±zda, Ã§ok daha bÃ¼tÃ¼nsel bir ÅŸekilde geliÅŸirsiniz.
> 
> Buna garanti verebilirim.
> 
> 

### Kaggle Learn courses *(Kaggle Learn kurslarÄ±)*

Kaggle hakkÄ±nda pek Ã§ok ÅŸey bilgi edinme ile ilgilidir. Ä°ster bir yarÄ±ÅŸmada Ã¶ÄŸrendikleriniz, ister hÄ±zla bÃ¼yÃ¼yen veri seti deposunda bulduÄŸunuz veriler, isterse de henÃ¼z keÅŸfedilmemiÅŸ bir model sÄ±nÄ±fÄ±nÄ± gÃ¶steren bir ÅŸey olsun, her zaman Ã¶ÄŸrenilecek yeni bir ÅŸey vardÄ±r. Bu koleksiyona en yeni eklenen ÅŸey, Kaggle Learn etiketinde toplanan kurslardÄ±r: [https://www.kaggle.com/learn](https://www.kaggle.com/learn). Bu kurslar, Kaggle tarafÄ±ndan "baÄŸÄ±msÄ±z veri bilimi projeleri yapmanÄ±z iÃ§in gerekli becerileri kazanmanÄ±n en hÄ±zlÄ± yolu" olarak tanÄ±tÄ±lmaktadÄ±r; ana tema, Ã§eÅŸitli konularda hÄ±zlÄ± bir giriÅŸ kursu sunmaktÄ±r. Her kurs, kÃ¼Ã§Ã¼k bÃ¶lÃ¼mlere ayrÄ±lmÄ±ÅŸtÄ±r ve ardÄ±ndan kodlama uygulama sorularÄ± gelir. Kurslar, gerekli teori ve aÃ§Ä±klamalarÄ±n, kod yazÄ±p uygulamanÄ±z gereken kÄ±sÄ±mlarla iÃ§ iÃ§e geÃ§tiÄŸi Notebooks kullanÄ±larak sunulmaktadÄ±r.

AÅŸaÄŸÄ±da, en kullanÄ±ÅŸlÄ± olanlarÄ±nÄ±n kÄ±sa bir Ã¶zeti yer almaktadÄ±r:

* **Intro to ML / Intermediate ML**: [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning) ve [https://www.kaggle.com/learn/intermediate-machine-learning](https://www.kaggle.com/learn/intermediate-machine-learning)
Bu iki kurs, birbirini tamamlayan birer parÃ§a olarak gÃ¶rÃ¼lebilir: ilki, makine Ã¶ÄŸrenmesinde kullanÄ±lan farklÄ± model sÄ±nÄ±flarÄ±nÄ± tanÄ±tarak baÅŸlar ve ardÄ±ndan farklÄ± modeller iÃ§in ortak olan konularÄ± (aÅŸÄ±rÄ±/eksik Ã¶ÄŸrenme veya model doÄŸrulama gibi) tartÄ±ÅŸÄ±r. Ä°kincisi, Ã¶zellik mÃ¼hendisliÄŸine daha derinlemesine bir bakÄ±ÅŸ sunar, eksik deÄŸerlerle baÅŸa Ã§Ä±kma ve kategorik deÄŸiÅŸkenleri ele alma gibi konularÄ± iÅŸler. Makine Ã¶ÄŸrenmesine yeni baÅŸlayanlar iÃ§in faydalÄ±dÄ±r.

* **pandas**: [https://www.kaggle.com/learn/pandas](https://www.kaggle.com/learn/pandas)
Bu kurs, modern veri biliminin en temel araÃ§larÄ±ndan birine hÄ±zlÄ± bir giriÅŸ saÄŸlar. Ä°lk olarak veri oluÅŸturma, okuma ve yazma konularÄ±nÄ± Ã¶ÄŸrenirsiniz, ardÄ±ndan veri temizleme (indeksleme, seÃ§me, birleÅŸtirme, gruplama vb.) Ã¼zerine Ã§alÄ±ÅŸÄ±rsÄ±nÄ±z. Hem yeni baÅŸlayanlar (pandas'Ä±n fonksiyonelliÄŸi zaman zaman bunaltÄ±cÄ± olabilir) hem de uygulayÄ±cÄ±lar (yeniden gÃ¶zden geÃ§irme/referans olarak) iÃ§in faydalÄ±dÄ±r.

* **Game AI**: [https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning)
Bu kurs, Kaggleâ€™Ä±n Ã¶ÄŸrenme modÃ¼llerinde sunulan teknoloji odaklÄ± kÄ±smÄ±n gÃ¼zel bir tamamlayÄ±cÄ±sÄ±dÄ±r. Bir oyun oynama ajanÄ± yazacak, performansÄ±nÄ± inceleyecek ve minimax algoritmasÄ±nÄ± kullanacaksÄ±nÄ±z. Bu kurs, muhtemelen pekiÅŸtirmeli Ã¶ÄŸrenmeye yÃ¶nelik bir uygulamalÄ± tanÄ±tÄ±m olarak gÃ¶rÃ¼lmelidir.

* **Machine Learning Explainability**: [https://www.kaggle.com/learn/machine-learning-explainability](https://www.kaggle.com/learn/machine-learning-explainability)
Modeller oluÅŸturmak eÄŸlenceli olabilir, ancak gerÃ§ek dÃ¼nyada herkes veri bilimcisi deÄŸildir, bu yÃ¼zden yaptÄ±klarÄ±nÄ±zÄ± baÅŸkalarÄ±na aÃ§Ä±klamanÄ±z gereken bir durumda olabilirsiniz. Ä°ÅŸte bu noktada model aÃ§Ä±klanabilirliÄŸi Ã¼zerine olan bu mini kurs devreye giriyor: Ã¼Ã§ farklÄ± yÃ¶ntemle (permutasyon Ã¶nemi, SHAP ve kÄ±smi baÄŸÄ±mlÄ±lÄ±k grafikleri) Ã¶zelliklerinizi nasÄ±l deÄŸerlendireceÄŸinizi Ã¶ÄŸrenirsiniz. Ã–zellikle ticari bir ortamda ML ile Ã§alÄ±ÅŸan herkes iÃ§in son derece faydalÄ±dÄ±r; burada projeler, mesajÄ±n ne kadar iyi iletildiÄŸine baÄŸlÄ± olarak varlÄ±klarÄ±nÄ± sÃ¼rdÃ¼rebilir.

* **AI Ethics**: [https://www.kaggle.com/learn/intro-to-ai-ethics](https://www.kaggle.com/learn/intro-to-ai-ethics)
Bu son kurs, sunumun oldukÃ§a ilginÃ§ bir eklemesi olarak karÅŸÄ±mÄ±za Ã§Ä±kÄ±yor: AI sistemlerinin ahlaki tasarÄ±mÄ±na rehberlik edecek pratik araÃ§larÄ± tartÄ±ÅŸmaktadÄ±r. AI modellerindeki Ã¶nyargÄ±yÄ± nasÄ±l tanÄ±yacaÄŸÄ±nÄ±zÄ±, AI adaleti kavramÄ±nÄ± incelemenizi ve ML model bilgilerini nasÄ±l ileterek ÅŸeffaflÄ±ÄŸÄ± artÄ±racaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenirsiniz. UygulayÄ±cÄ±lar iÃ§in Ã§ok faydalÄ±dÄ±r, Ã§Ã¼nkÃ¼ "sorumlu yapay zeka" artÄ±k daha sÄ±k duyacaÄŸÄ±mÄ±z bir kavram olacaktÄ±r.

Kaggle tarafÄ±ndan oluÅŸturulan orijinal iÃ§eriÄŸin dÄ±ÅŸÄ±nda, platformda kullanÄ±cÄ±lar tarafÄ±ndan oluÅŸturulmuÅŸ Notebooks aracÄ±lÄ±ÄŸÄ±yla baÅŸka Ã¶ÄŸrenme fÄ±rsatlarÄ± da bulunmaktadÄ±r; okuyucularÄ±n bunlarÄ± kendi baÅŸlarÄ±na keÅŸfetmeleri teÅŸvik edilir.

> **Andrada Olteanu**
> 
> [https://www.kaggle.com/andradaolteanu](https://www.kaggle.com/andradaolteanu)
> 
> Andrada Olteanu, Kaggle Notebooks Grandmaster'larÄ±ndan biridir ve Notebooks'tan Ã¶ÄŸrenmeyi Ã§ok teÅŸvik etmektedir. Andrada, Z by HP Global Data Science Ambassador, Endava'da Veri Bilimci ve Weights & Biases'ta Dev Expert olarak gÃ¶rev yapmaktadÄ±r. Andrada ile Notebook yarÄ±ÅŸmalarÄ±, kariyeri ve daha fazlasÄ± hakkÄ±nda sohbet ettik.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Kaggle'da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Kaggle'daki uzmanlÄ±ÄŸÄ±m, verileri gÃ¶rselleÅŸtirme konusunda yoÄŸunlaÅŸÄ±yor, Ã§Ã¼nkÃ¼ bu alan bana sanatÄ± ve yaratÄ±cÄ±lÄ±ÄŸÄ± verilerle birleÅŸtirme imkanÄ± veriyor.
> 
> Kesinlikle favori bir yarÄ±ÅŸma tÃ¼rÃ¼m yok, ama daha Ã§ok zaman zaman deÄŸiÅŸim yapmak ve ilginÃ§ bulduÄŸum yarÄ±ÅŸmalarÄ± seÃ§mek hoÅŸuma gidiyor.
> 
> Kaggleâ€™Ä±n gÃ¼zelliÄŸi, bir kiÅŸinin Veri Biliminin birÃ§ok alanÄ±nÄ± (bilgisayarla gÃ¶rme, NLP, keÅŸifsel veri analizi ve istatistik, zaman serileri vb.) Ã¶ÄŸrenebilmesinin yanÄ± sÄ±ra birÃ§ok konuya (spor, tÄ±p, finans ve kripto paralar, dÃ¼nya Ã§apÄ±ndaki olaylar vb.) da aÅŸina olma fÄ±rsatÄ± sunmasÄ±dÄ±r.
> 
> AyrÄ±ca, Ã¶rneÄŸin metin verileriyle daha fazla deneyim kazanmak isteyen biri iÃ§in, neredeyse her zaman bir Kaggle YarÄ±ÅŸmasÄ±'nda NLP gereksinimi vardÄ±r. Ya da ses dosyalarÄ±yla nasÄ±l Ã¶n iÅŸleme yapÄ±lacaÄŸÄ± ve modellerin nasÄ±l kurulacaÄŸÄ± Ã¶ÄŸrenmek isteyen biri iÃ§in de bu beceriyi geliÅŸtirecek yarÄ±ÅŸmalar bulunabilir.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlu bir yarÄ±ÅŸmadan ve gÃ¶revi ele almak iÃ§in kullandÄ±ÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼lerden bahseder misiniz?**
> 
> KatÄ±ldÄ±ÄŸÄ±m en zorlu â€œyarÄ±ÅŸmaâ€ Kaggleâ€™Ä±n â€œVeri Bilimi ve Makine Ã–ÄŸrenimi YÄ±llÄ±k Anketiâ€ydi. Bu bir â€œgerÃ§ekâ€ yarÄ±ÅŸma deÄŸil â€“ yani bir liderlik tablosu ve aÄŸÄ±r makine Ã¶ÄŸrenimi gerekmiyor â€“ ancak benim iÃ§in katÄ±ldÄ±ÄŸÄ±m ve en Ã§ok ÅŸey Ã¶ÄŸrendiÄŸim yarÄ±ÅŸmalardan biriydi.
> 
> Bu bir Notebook yarÄ±ÅŸmasÄ±dÄ±r ve katÄ±lÄ±mcÄ±larÄ±n kazanmak iÃ§in yaratÄ±cÄ± olmalarÄ± gerekmektedir. Bu yarÄ±ÅŸmaya 2 yÄ±l Ã¼st Ã¼ste katÄ±ldÄ±m. Ä°lk yÄ±l (2020), daha â€œtemelâ€ gÃ¶rselleÅŸtirme becerilerimi test etti ve bana kutunun dÄ±ÅŸÄ±na Ã§Ä±kmamÄ± saÄŸladÄ± (3. oldum); ikinci yÄ±l (2021), 4 ay boyunca D3 Ã¶ÄŸrenerek bu alandaki gÃ¶rselleÅŸtirme becerilerimi bir Ã¼st seviyeye Ã§Ä±karmayÄ± hedefledim (hala incelemede; ÅŸu ana kadar â€œErken Notebook Ã–dÃ¼lÃ¼â€nÃ¼ kazandÄ±m). Burada verebileceÄŸim en iyi iÃ§gÃ¶rÃ¼ler ÅŸunlar:
> 
> * Ã–ncelikle veriye kaybolmayÄ±n ve olabildiÄŸince doÄŸru grafikler oluÅŸturmaya Ã§alÄ±ÅŸÄ±n; gerekirse, neyi temsil ettiÄŸinizin net ve Ã¶z olduÄŸundan emin olmak iÃ§in Ã§ift doÄŸrulama yÃ¶ntemleri oluÅŸturun. GÃ¼zel bir grafiÄŸin yanÄ±ltÄ±cÄ± iÃ§gÃ¶rÃ¼ler sunduÄŸu bir ÅŸeyden daha kÃ¶tÃ¼ bir ÅŸey yoktur.
> 
> * Ã‡evrenizde ilham kaynaÄŸÄ± arayÄ±n: doÄŸadan, filmlerden, iÅŸinizden. GÃ¶rselleÅŸtirmelerinizi canlandÄ±rmak iÃ§in harika temalar ve ilginÃ§ yollar bulabilirsiniz.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? YardÄ±mcÄ± olduysa nasÄ±l?**
> 
> Evet. MÃ¼him Ã¶lÃ§Ã¼de. Åu anda bulunduÄŸum noktada Kaggle'a bÃ¼yÃ¼k bir borcum olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum ve bunun iÃ§in sonsuza dek minnettarÄ±m. Kaggle sayesinde Z by HP Ambassador'Ä± oldum; ayrÄ±ca harika bir makine Ã¶ÄŸrenimi deney platformu olan Weights & Biases'Ä± keÅŸfettim ve ÅŸu anda onlarÄ±n gururlu bir Dev Expert'Ä±yÄ±m. Son olarak, bu platform sayesinde ÅŸu anda Endava'da Lead Data Scientist olarak gÃ¶rev yapan kiÅŸiyle tanÄ±ÅŸtÄ±m, o beni iÅŸe aldÄ± ve o zamandan beri onunla Ã§alÄ±ÅŸÄ±yorum. KÄ±sacasÄ±, Endava'daki pozisyonum ve HP ile Weights & Biases gibi 2 bÃ¼yÃ¼k ÅŸirketle olan baÄŸlantÄ±larÄ±m, Kaggle platformundaki faaliyetlerimin doÄŸrudan bir sonucu.
> 
> Bence Kaggle'Ä±n en gÃ¶zden kaÃ§an yÃ¶nÃ¼, topluluktur. Kaggle, birbirleriyle baÄŸlantÄ± kurup etkileÅŸimde bulunabilecek ve birbirlerinden Ã¶ÄŸrenebilecek dev bir insan havuzuna sahiptir.
> 
> Bunun en iyi ÅŸekilde nasÄ±l deÄŸerlendirileceÄŸiyle ilgili bir Ã¶rnek: Kaggleâ€™daki her bÃ¶lÃ¼mden (YarÄ±ÅŸmalar, Veri Setleri, Notebooks â€“ ve eÄŸer isterseniz, TartÄ±ÅŸmalar) ilk 100 kiÅŸiyi alÄ±n ve profilinde bu bilgiyi paylaÅŸan herkesin Twitter/LinkedIn hesaplarÄ±nÄ± takip edin. Bu ÅŸekilde, bu harika insanlarla dÃ¼zenli olarak etkileÅŸimde bulunabilir, iÃ§gÃ¶rÃ¼ ve bilgilerinden faydalanabilirsiniz.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±m en bÃ¼yÃ¼k hata, onlara katÄ±lmamaktÄ±. Bence bu, baÅŸlangÄ±Ã§ seviyesindeki kullanÄ±cÄ±larÄ±n platforma girdiÄŸinde yaptÄ±klarÄ± en bÃ¼yÃ¼k ve en temel hatadÄ±r.
> 
> Korku nedeniyle (ve burada kiÅŸisel deneyimimden konuÅŸuyorum), hazÄ±r olmadÄ±klarÄ±nÄ± veya nasÄ±l baÅŸlayacaklarÄ±nÄ± bilmediklerini dÃ¼ÅŸÃ¼nÃ¼yorlar. Neyse ki, basit bir sistem takip ederseniz, herhangi bir yarÄ±ÅŸmaya katÄ±lmak oldukÃ§a kolay hale gelir:
> 
> * Ä°lginizi Ã§eken herhangi bir yarÄ±ÅŸmaya katÄ±lÄ±n.
> 
> * TanÄ±tÄ±m sayfasÄ±nÄ± ve verileri keÅŸfedin.
> 
> * BaÅŸlamak iÃ§in fikriniz yoksa, endiÅŸelenmeyin! â€œKodâ€ kÄ±smÄ±na girin ve Ã§ok fazla oy almÄ±ÅŸ, ya da deneyimli kiÅŸiler tarafÄ±ndan yapÄ±lmÄ±ÅŸ Notebooks'larÄ± inceleyin, Ã¶rneÄŸin Grandmasters.
> 
> Bir â€œkodla birlikte Ã§alÄ±ÅŸâ€ Notebookâ€™u yapmaya baÅŸlayÄ±n, burada baÅŸkalarÄ±nÄ±n ne yaptÄ±ÄŸÄ±nÄ± inceleyin ve â€œkopyalayÄ±n,â€ araÅŸtÄ±rÄ±n ve kendiniz geliÅŸtirmeye Ã§alÄ±ÅŸÄ±n. Bence bu, Ã¶ÄŸrenmenin en iyi yoludur â€“ hiÃ§ takÄ±lmazsÄ±nÄ±z ve belirli bir projede yaparak Ã¶ÄŸrenirsiniz.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> UnutulmamasÄ± gereken en Ã¶nemli ÅŸey, baÅŸarÄ±sÄ±z olmanÄ±n tamamen normal olduÄŸudur, Ã§Ã¼nkÃ¼ genellikle en iyi Ã¶ÄŸrenme yolu budur.
> 
> AyrÄ±ca her zaman YarÄ±ÅŸma Grandmastersâ€™larÄ±ndan Ã¶ÄŸrenmeyi unutmamalÄ±dÄ±rlar, Ã§Ã¼nkÃ¼ genellikle, bir kiÅŸinin aklÄ±na gelmeyecek makine Ã¶ÄŸrenimi tekniklerini paylaÅŸan ve aÃ§Ä±klayan kiÅŸilerdir. Bir ÅŸeyi Ã¶ÄŸrenmenin en iyi yolu, zaten â€œbaÅŸarÄ±sÄ±nÄ±â€ kanÄ±tlamÄ±ÅŸ olanlarÄ± incelemektir, bÃ¶ylece baÅŸarÄ± yolunuz daha az engebeli, daha rahat, pÃ¼rÃ¼zsÃ¼z ve hÄ±zlÄ± olur. GerÃ§ekten hayran olduÄŸunuz 2-3 Grandmasterâ€™Ä± seÃ§in ve onlarÄ± Ã¶ÄŸretmenleriniz yapÄ±n; onlarÄ±n Notebooksâ€™larÄ±nÄ± inceleyin, birlikte kod yazÄ±n ve olabildiÄŸince Ã§ok ÅŸey Ã¶ÄŸrenin.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musunuz? Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±rsÄ±nÄ±z?**
> 
> HiÃ§ baÅŸka bir yarÄ±ÅŸma platformu kullanmadÄ±m â€“ Ã§Ã¼nkÃ¼ bence Kaggle her ÅŸeyi sunuyor.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, eÄŸitim ve deney yapma amacÄ±yla kullanÄ±labilen, ayrÄ±ca veri bilimi proje portfÃ¶yÃ¼nÃ¼zÃ¼ tanÄ±tmak iÃ§in de kullanÄ±labilen Ã§ok amaÃ§lÄ±, aÃ§Ä±k kodlama ortamlarÄ± olan Kaggle Notebooks'tan bahsettik. ArtÄ±k kendi Notebook'unuzu oluÅŸturma, mevcut kaynaklarÄ± verimli bir ÅŸekilde kullanma ve sonuÃ§larÄ± yarÄ±ÅŸmalar veya bireysel projeleriniz iÃ§in kullanma aÅŸamasÄ±na geldiniz.

Bir sonraki bÃ¶lÃ¼mde, Kaggle'da fikir ve gÃ¶rÃ¼ÅŸlerinizi paylaÅŸmanÄ±n birincil yolu olan tartÄ±ÅŸma forumlarÄ±nÄ± tanÄ±tacaÄŸÄ±z.

---

## Chapter 4: Leveraging Discussion Forums *(BÃ¶lÃ¼m 4: TartÄ±ÅŸma ForumlarÄ±nÄ± Etkin Kullanma)*

TartÄ±ÅŸma forumlarÄ±, Kaggle'daki bilgi alÄ±ÅŸveriÅŸinin birincil aracÄ±dÄ±r. Ä°ster devam eden bir yarÄ±ÅŸmayÄ± tartÄ±ÅŸmak, ister bir Veri Seti hakkÄ±nda konuÅŸmak, isterse yeni bir yaklaÅŸÄ±m sunan bir Notebook'u ele almak olsun, Kaggle kullanÄ±cÄ±larÄ± her zaman bir ÅŸeyler hakkÄ±nda konuÅŸurlar.

Bu bÃ¶lÃ¼mde, tartÄ±ÅŸma forumlarÄ±nÄ± tanÄ±tÄ±yoruz: nasÄ±l organize olduklarÄ±nÄ± ve iÃ§indeki bilgilerin nasÄ±l kullanÄ±lacaÄŸÄ±nÄ± dÃ¼zenleyen davranÄ±ÅŸ kurallarÄ±nÄ±. AÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:
* ForumlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±
* Ã–rnek yarÄ±ÅŸmalar iÃ§in tartÄ±ÅŸma yaklaÅŸÄ±mlarÄ±
* Ä°nternette uygun davranÄ±ÅŸ (Netik)

### How forums work *(Forumlar nasÄ±l Ã§alÄ±ÅŸÄ±r)*

TartÄ±ÅŸma forumuna birkaÃ§ farklÄ± ÅŸekilde girebilirsiniz. En doÄŸrudan yol, sol paneldeki **TartÄ±ÅŸmalar** sekmesine tÄ±klamaktÄ±r:

![](im/1034.png)

Ãœst kÄ±sÄ±mda, genel konularÄ±n bir araya getirildiÄŸi **Forumlar** bulunur. Bunlara gÃ¶z atmak, ister ilk yarÄ±ÅŸmanÄ±za katÄ±lÄ±yor olun, ister bir Ã¶neriniz olsun, ister sadece kafanÄ±z karÄ±ÅŸtÄ±ÄŸÄ± iÃ§in genel bir soru sormak isteyin, oldukÃ§a faydalÄ±dÄ±r.

ForumlarÄ±n altÄ±nda, **Kaggle genelinde yapÄ±lan tartÄ±ÅŸmalarÄ±n birleÅŸik gÃ¶rÃ¼nÃ¼mÃ¼nÃ¼** bulabilirsiniz. Bunlar Ã§oÄŸunlukla yarÄ±ÅŸmalarla ilgili sohbetlerdir (Ã§Ã¼nkÃ¼ Kaggleâ€™daki etkinliÄŸin bÃ¼yÃ¼k kÄ±smÄ±nÄ± yarÄ±ÅŸmalar oluÅŸturur), ancak bazen Notebooks (defterler) veya dikkat Ã§ekici veri kÃ¼meleriyle ilgili konuÅŸmalar da yer alÄ±r. VarsayÄ±lan olarak bu tartÄ±ÅŸmalar **"Hotness" (PopÃ¼lerlik)** sÄ±rasÄ±na gÃ¶re listelenir; yani katÄ±lÄ±mÄ± en yÃ¼ksek ve en aktif olanlar Ã¼st sÄ±ralarda gÃ¶rÃ¼nÃ¼r.

Bu bÃ¶lÃ¼m, alanÄ±n dinamik doÄŸasÄ±na daha uygun iÃ§erikleri bulabileceÄŸiniz yerdir: Kaggleâ€™Ä±n farklÄ± alt bÃ¶lÃ¼mlerinden gelen tartÄ±ÅŸmalarÄ±n bir koleksiyonu olup, belirli Ã¶lÃ§Ã¼tlere gÃ¶re **filtreleme yapma** olanaÄŸÄ± da sunar.

![](im/1035.png)

Ä°lgi alanlarÄ±nÄ±za baÄŸlÄ± olarak, iÃ§erikleri **filtreleri kullanarak kiÅŸiselleÅŸtirmeye** baÅŸlayabilirsiniz. Tercihlerinize gÃ¶re ÅŸu Ã¶lÃ§Ã¼tlere gÃ¶re filtreleme yapabilirsiniz:

* **RECENCY (GÃ¼ncellik):** Takip ettiÄŸiniz bilgilerin zaman aralÄ±ÄŸÄ±nÄ± kontrol etmenizi saÄŸlar.
* **MY ACTIVITY (Benim EtkinliÄŸim):** TÃ¼m forumlardaki yorumlarÄ±nÄ±zÄ±n, paylaÅŸÄ±mlarÄ±nÄ±zÄ±n ve gÃ¶rÃ¼ntÃ¼lemelerinizin genel bir Ã¶zetini verir; birden fazla tartÄ±ÅŸmaya aynÄ± anda katÄ±lÄ±yorsanÄ±z oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r.
* **ADMIN (YÃ¶netici):** Kaggle yÃ¶neticilerinin duyurularÄ±na hÄ±zlÄ± bir genel bakÄ±ÅŸ saÄŸlar.
* **TYPES (TÃ¼rler):** TartÄ±ÅŸmalar genel forumlarda, belirli yarÄ±ÅŸmalarda veya veri kÃ¼meleri etrafÄ±nda gerÃ§ekleÅŸebilir.
* **TAGS (Etiketler):** Her yerde bulunmasa da birÃ§ok tartÄ±ÅŸma etiketlenmiÅŸtir; bu iÅŸlev, kullanÄ±cÄ±larÄ±n bu Ã¶zelliÄŸi kullanarak belirli konulara gÃ¶re filtreleme yapmasÄ±na olanak tanÄ±r.

![](im/1036.png)

AÅŸaÄŸÄ±daki ÅŸekil, **Beginner (Yeni BaÅŸlayan)** etiketiyle filtrelenmiÅŸ tartÄ±ÅŸmalarÄ±n Ã¶rnek bir Ã§Ä±ktÄ±sÄ±nÄ± gÃ¶stermektedir.

![](im/1037.png)

Alternatif olarak, belirli bir konuya da odaklanabilirsiniz; Ã¶rneÄŸin **bilgisayarla gÃ¶rme (computer vision)** gibi konular bÃ¼yÃ¼k ilgi Ã§ektiÄŸinden, konularÄ± **sÄ±ralamak** faydalÄ± olabilir. KonularÄ± ÅŸu Ã¶lÃ§Ã¼tlere gÃ¶re sÄ±ralayabilirsiniz:

* **Hotness (PopÃ¼lerlik):** En fazla ilgi ve katÄ±lÄ±m gÃ¶ren konular Ã¼stte gÃ¶sterilir.
* **Recent Comments (Son Yorumlar):** En son yorum yapÄ±lan konulara gÃ¶re sÄ±ralar.
* **Recently Posted (Yeni PaylaÅŸÄ±lanlar):** YakÄ±n zamanda oluÅŸturulan konulara Ã¶ncelik verir.
* **Most Votes (En Ã‡ok Oy Alanlar):** En fazla oyu almÄ±ÅŸ konularÄ± Ã¼stte gÃ¶sterir.
* **Most Comments (En Ã‡ok Yorum Alanlar):** En fazla yorum yapÄ±lan konularÄ± sÄ±ralar.

![](im/1038.png)

Ä°nsanlar **Kaggleâ€™a** farklÄ± nedenlerle gelirler; ancak **Notebooks**â€™larÄ±n popÃ¼laritesinin artmasÄ±na raÄŸmen, **yarÄ±ÅŸmalar** hÃ¢lÃ¢ temel Ã§ekim noktasÄ± olmaya devam etmektedir. Her Kaggle yarÄ±ÅŸmasÄ±nÄ±n kendine ait Ã¶zel bir **tartÄ±ÅŸma forumu** vardÄ±r. Bu foruma, yarÄ±ÅŸmanÄ±n sayfasÄ±na gidip **Discussion (TartÄ±ÅŸma)** sekmesini seÃ§erek eriÅŸebilirsiniz.

![](im/1039.png)

Eskiden bu her zaman bÃ¶yle deÄŸildi, ancak gÃ¼nÃ¼mÃ¼zde neredeyse tÃ¼m yarÄ±ÅŸmalarÄ±n, kendilerine ait tartÄ±ÅŸma forumlarÄ±nÄ±n en Ã¼st kÄ±smÄ±na sabitlenmiÅŸ bir **SSS (SÄ±kÃ§a Sorulan Sorular)** konusu bulunmaktadÄ±r. Bu bÃ¶lÃ¼mden baÅŸlamak iki temel nedenle iyi bir fikirdir:

* **Zamandan tasarruf edersiniz;** en popÃ¼ler sorularÄ±n yanÄ±tlarÄ± bÃ¼yÃ¼k olasÄ±lÄ±kla burada yer alÄ±r.
* **Gereksiz veya yinelenen sorular sormaktan kaÃ§Ä±nÄ±rsÄ±nÄ±z,** bÃ¶ylece forumdaki herkes iÃ§in daha iyi bir deneyim saÄŸlanmÄ±ÅŸ olur.

**Notebooks**â€™larda olduÄŸu gibi, tartÄ±ÅŸma forumlarÄ±nda da daha sonra tekrar bakmak Ã¼zere **Ã¶zellikle Ã¶nemli konularÄ± yer imlerine ekleme (bookmark)** seÃ§eneÄŸi bulunur.

![](im/1040.png)

Yer iÅŸareti eklediÄŸiniz (bookmarkladÄ±ÄŸÄ±nÄ±z) tÃ¼m konularÄ±n genel bir Ã¶zetini, **profil sayfanÄ±zda** bulabilirsiniz.

![](im/1041.png)

### Example discussion approaches *(TartÄ±ÅŸma Ã¶rnekleri ve yaklaÅŸÄ±mlar)*

Bir yarÄ±ÅŸmada kendinizi bir noktada kaybolmuÅŸ hissetmeniz tamamen normaldir: Geldiniz, birkaÃ§ fikir denediniz, sÄ±ralamada bir ilerleme kaydettiniz ve sonra Kaggle versiyonu ile koÅŸucularÄ±n duvarÄ±na Ã§arptÄ±nÄ±z. Ä°ÅŸte bu noktada tartÄ±ÅŸma forumlarÄ± baÅŸvurulacak yerdir.

Ã–rnek olarak, Optiver Realized Volatility Prediction yarÄ±ÅŸmasÄ±na bakalÄ±m ([https://www.kaggle.com/c/optiver-realized-volatility-prediction](https://www.kaggle.com/c/optiver-realized-volatility-prediction)). Organizasyon tarafÄ±ndan ÅŸÃ¶yle tanÄ±mlanmÄ±ÅŸ:

> Ä°lk Ã¼Ã§ ay boyunca, farklÄ± sektÃ¶rlerde yÃ¼zlerce hisse senedi iÃ§in kÄ±sa vadeli volatiliteyi tahmin eden modeller geliÅŸtireceksiniz. Elinizde yÃ¼z milyonlarca detaylÄ± finansal veri olacak ve bu verilerle 10 dakikalÄ±k periyotlar iÃ§in volatiliteyi tahmin eden bir model tasarlayacaksÄ±nÄ±z. Modelleriniz, eÄŸitim sonrasÄ± Ã¼Ã§ aylÄ±k deÄŸerlendirme dÃ¶neminde gerÃ§ek piyasa verileriyle karÅŸÄ±laÅŸtÄ±rÄ±larak deÄŸerlendirilecektir.

Burada ele alÄ±nacak Ã§ok ÅŸey var; bu yÃ¼zden bu zorluÄŸun ana bileÅŸenlerini inceleyip, tartÄ±ÅŸma forumlarÄ± aracÄ±lÄ±ÄŸÄ±yla nasÄ±l yaklaÅŸÄ±labileceÄŸini gÃ¶stereceÄŸiz. Ã–ncelikle, bu yarÄ±ÅŸmaya katÄ±lÄ±m belirli bir finansal bilgi gerektiriyor; belki deneyimli bir trader seviyesinde olmanÄ±z gerekmiyor, ama volatilitenin farklÄ± hesaplama yÃ¶ntemlerini anlamak, Ã§oÄŸu Kaggle katÄ±lÄ±mcÄ±sÄ± iÃ§in oldukÃ§a karmaÅŸÄ±ktÄ±r. Neyse ki organizatÃ¶rler yarÄ±ÅŸma boyunca oldukÃ§a aktifti ve yeni baÅŸlayanlar iÃ§in kaynaklar sundular: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273923](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273923)

EÄŸer baÅŸlangÄ±Ã§ bilgisi yeterli deÄŸilse, kamuya aÃ§Ä±k ÅŸekilde sorularÄ±nÄ±zÄ± sormaktan Ã§ekinmeyin, Ã¶rneÄŸin:
[https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/263039](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/263039)
veya
[https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250612](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250612)

YarÄ±ÅŸma ilerledikÃ§e, katÄ±lÄ±mcÄ±lar problemi Ã§Ã¶zmek iÃ§in giderek daha sofistike modeller geliÅŸtirmeye baÅŸladÄ±lar. Burada bir denge kurmak gerekiyor: bir yandan, veteriner katÄ±lÄ±mcÄ±lardan Ã¶ÄŸrendiklerinizi paylaÅŸarak geri vermek isteyebilirsiniz; diÄŸer yandan, tÃ¼m harika kodlarÄ±nÄ±zÄ± Notebook olarak paylaÅŸarak potansiyel avantajÄ±nÄ±zÄ± kaybetmek istemezsiniz. Makul bir orta yol, Ã¶rneÄŸin forumda Ã¶zellik fikirlerinizi paylaÅŸmak olabilir: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273915](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/273915)

Son yÄ±llarda, daha fazla yarÄ±ÅŸma sabit test veri seti formatÄ±ndan uzaklaÅŸÄ±p farklÄ± yaklaÅŸÄ±mlar getirdi: bazÄ±larÄ± Kaggle API kullanÄ±mÄ±nÄ± zorunlu kÄ±lÄ±yor (Notebook Ã¼zerinden gÃ¶nderim yapmanÄ±z gerekiyor), bazÄ±larÄ± ise eÄŸitim ve canlÄ± veri deÄŸerlendirmesi olarak Ã¶zel bir zaman Ã§izelgesi sunuyor. Optiver yarÄ±ÅŸmasÄ± da bÃ¶yleydi:

> Final gÃ¶nderim tarihinden sonra, seÃ§ilen notebookâ€™lar Ã¼zerinde piyasa verisi gÃ¼ncellemelerine baÄŸlÄ± olarak sÄ±ralama tablosu periyodik olarak gÃ¼ncellenecektir. GÃ¼ncellemeler yaklaÅŸÄ±k iki haftada bir yapÄ±lacak ve tatil dÃ¶nemlerinden kaÃ§Ä±nmak iÃ§in ayarlamalar yapÄ±lacaktÄ±r.

Bu kurulum, modellerin yeniden eÄŸitilmesi ve gÃ¼ncellenmesi konusunda bazÄ± zorluklar yarattÄ±. Bu tÃ¼r bir durumla karÅŸÄ±laÅŸÄ±rsanÄ±z, katÄ±lÄ±mcÄ±larÄ±n yaptÄ±ÄŸÄ± gibi sorular sormaktan Ã§ekinmeyin: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/249752](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/249752)

EÄŸitilen modeliniz iÃ§in bir doÄŸrulama ÅŸemasÄ± her zaman Ã¶nemli bir konudur ve genellikle â€œCV vs LBâ€ (Ã§apraz doÄŸrulama vs sÄ±ralama tablosu) tartÄ±ÅŸmasÄ± ile baÄŸlantÄ±lÄ±dÄ±r. Optiver yarÄ±ÅŸmasÄ± da bu kuralÄ±n istisnasÄ± deÄŸildi: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250650](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250650)

EÄŸer ilgili baÅŸlÄ±k zaten yoksa â€“ ve bunu kontrol etmek her zaman iyi bir fikirdir â€“ tek model performansÄ±yla ilgili bir baÅŸlÄ±ÄŸÄ± dÃ¼ÅŸÃ¼nmek isteyebilirsiniz. Er ya da geÃ§ herkes model ansambllarÄ±nÄ± kullanmaya baÅŸlar, ancak iyi tek model bileÅŸenleri olmadan bunlar Ã§ok verimli deÄŸildir.

EÄŸer problemi Ã§Ã¶zmenin daha iyi bir yolunu bulduysanÄ±z, paylaÅŸmak genellikle iyi bir fikirdir. Ya baÅŸkalarÄ± iÃ§in faydalÄ± bir ÅŸey yapmÄ±ÅŸ olursunuz, ya da neden yanlÄ±ÅŸ olduÄŸunuzu Ã¶ÄŸrenirsiniz (zaman ve Ã§aba tasarrufu saÄŸlar); her iki durumda da kazanÃ§lÄ± Ã§Ä±karsÄ±nÄ±z: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/260694](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/260694)

Bunun dÄ±ÅŸÄ±nda, diÄŸer katÄ±lÄ±mcÄ±larÄ±n ne yaptÄ±ÄŸÄ±na gÃ¶z atmak ve topluluk iÃ§inde bilgi paylaÅŸÄ±mÄ±na katkÄ±da bulunmak kiÅŸisel fayda saÄŸlar ve Ã¶zellikle yeni baÅŸlayanlar iÃ§in yararlÄ±dÄ±r: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250695](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250695)

TÃ¼m bu konulara gÃ¶z attÄ±ysanÄ±z, hÃ¢lÃ¢ â€œÃ–nemli bir ÅŸeyi mi kaÃ§Ä±rÄ±yorum?â€ diye dÃ¼ÅŸÃ¼nebilirsiniz. Kaggle, bu tÃ¼r sorularÄ± sormanÄ±n tamamen kabul edildiÄŸi bir platformdur: [https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/262203](https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/262203)

DiÄŸer yarÄ±ÅŸmalara gÃ¶z atalÄ±m. Daha Ã¶nce doÄŸrulama konusundan bahsettik; bu genellikle bilgi sÄ±zÄ±ntÄ±sÄ± ve aÅŸÄ±rÄ± uyum (overfitting) ile baÄŸlantÄ±lÄ±dÄ±r. SÄ±zÄ±ntÄ±lar, doÄŸrulama ÅŸemalarÄ±nÄ±n tasarlanmasÄ±na ayrÄ±lmÄ±ÅŸ olan 6. bÃ¶lÃ¼mde ayrÄ±ntÄ±lÄ± olarak ele alÄ±nmÄ±ÅŸtÄ±r. Burada, forumlar aracÄ±lÄ±ÄŸÄ±yla nasÄ±l ele alÄ±ndÄ±ÄŸÄ±nÄ± kÄ±saca inceleyeceÄŸiz. Kaggle, meraklÄ± katÄ±lÄ±mcÄ±lardan oluÅŸan bir topluluk olduÄŸundan, sÄ±zÄ±ntÄ± ÅŸÃ¼phesi varsa, biri konuyu muhtemelen gÃ¼ndeme getirir.

Ã–rneÄŸin, dosya adlarÄ± veya kayÄ±t IDâ€™leri zaman damgalarÄ± iÃ§erebilir, bu da geleceÄŸe bakmak ve hatalÄ± ÅŸekilde dÃ¼ÅŸÃ¼k hata metriÄŸi elde etmek iÃ§in tersine mÃ¼hendislik yapÄ±labileceÄŸi anlamÄ±na gelir. Bu durum, Two Sigma Connect yarÄ±ÅŸmasÄ±nda yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870#176513](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870#176513)

BaÅŸka bir Ã¶rnek, Airbus Ship Detection Challengeâ€™dÄ±r, katÄ±lÄ±mcÄ±larÄ±n uydu gÃ¶rÃ¼ntÃ¼lerinde gemileri bulmasÄ± gerekiyordu. Test gÃ¶rÃ¼ntÃ¼lerinin Ã¶nemli bir kÄ±smÄ±, eÄŸitim gÃ¶rÃ¼ntÃ¼lerinden rastgele kÄ±rpÄ±lmÄ±ÅŸtÄ± ve eÅŸleÅŸtirmek oldukÃ§a kolaydÄ±: [https://www.kaggle.com/c/airbus-ship-detection/discussion/64355#377037](https://www.kaggle.com/c/airbus-ship-detection/discussion/64355#377037)

Santander tarafÄ±ndan dÃ¼zenlenen yarÄ±ÅŸmalar da oldukÃ§a Ã¼nlÃ¼dÃ¼r. Åirketin dÃ¼zenlediÄŸi Ã¼Ã§ yarÄ±ÅŸmadan ikisinde veri sÄ±zÄ±ntÄ±sÄ± yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61172](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61172)

Sonraki adÄ±mlar yarÄ±ÅŸmadan yarÄ±ÅŸmaya deÄŸiÅŸir: BazÄ± durumlarda Kaggle, yarÄ±ÅŸmayÄ± yeni veya temizlenmiÅŸ verilerle yeniden baÅŸlatmÄ±ÅŸtÄ±r; bazen ise minimal etki algÄ±ladÄ±klarÄ± iÃ§in devam ettirmiÅŸtir. Ã–rneÄŸin, Predicting Red Hat Business Value yarÄ±ÅŸmasÄ±nda bÃ¶yle bir durum yaÅŸanmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/23788](https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/23788)

Veri sÄ±zÄ±ntÄ±larÄ± yarÄ±ÅŸmayÄ± ciddi ÅŸekilde bozabilir, ancak iyi haber ÅŸu ki, son 2-3 yÄ±lda Kaggleâ€™da sÄ±zÄ±ntÄ±lar neredeyse tamamen ortadan kalkmÄ±ÅŸtÄ±r â€“ dolayÄ±sÄ±yla bu bÃ¶lÃ¼m, bir kez okunacak ama platformdaki deneyiminizin sÃ¼rekli bir parÃ§asÄ± olmayacaktÄ±r.

Platformdaki deneyim konusuna gelince, bu Grandmaster rÃ¶portajÄ±na mÃ¼kemmel bir geÃ§iÅŸtir.

> **Yifan Xie**
> 
> [https://www.kaggle.com/yifanxie](https://www.kaggle.com/yifanxie)
> 
> 
> 
> Yifan Xie, **Discussions ve Competitions Master** unvanÄ±na sahip ve aynÄ± zamanda **Arion.ai**â€™nin kurucu ortaÄŸÄ±dÄ±r. Ä°ÅŸte yarÄ±ÅŸmalara katÄ±lma ve diÄŸer Kaggle kullanÄ±cÄ±larÄ±yla Ã§alÄ±ÅŸma konusundaki gÃ¶rÃ¼ÅŸleri:
> 
> 
> 
> **En sevdiÄŸin yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™da uzmanlÄ±ÄŸÄ±n nedir?**
> 
> AslÄ±nda Ã¶zel bir favorim yok; her tÃ¼r problemi Ã§Ã¶zmeyi seviyorum. Teknik aÃ§Ä±dan, Ã§oÄŸu veri problemi Ã¼zerinde hÄ±zlÄ±ca uygulanabilecek tipik teknikleri ve algoritmalarÄ± kapsayan saÄŸlam bir **makine Ã¶ÄŸrenimi pipelineâ€™Ä±** geliÅŸtirdim. Bunu, iÅŸ rutinleri ve teknik araÃ§lar aÃ§Ä±sÄ±ndan standartlaÅŸtÄ±rmaya odaklanmÄ±ÅŸ bir **rekabet avantajÄ±** olarak gÃ¶rÃ¼yorum. Bu sayede daha hÄ±zlÄ± iterasyonlar yapabiliyor ve veri deneyleri sÄ±rasÄ±nda verimliliÄŸi artÄ±rabiliyorum; bu da Kaggle iÃ§in temel bir bileÅŸendir.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±n? Bu yaklaÅŸÄ±m gÃ¼nlÃ¼k iÅŸlerinden ne kadar farklÄ±?**
> 
> Zamanla, bÃ¼yÃ¼k veri projelerimin Ã§oÄŸu iÃ§in **bilgi yÃ¶netimi ve toplama** konusunda Ã¶zel bir yÃ¶ntem geliÅŸtirdim. Bu yaklaÅŸÄ±m, iÅŸ projeleri, Kaggle yarÄ±ÅŸmalarÄ± ve diÄŸer yan projeler iÃ§in uygulanabilir. Genellikle yararlÄ± bilgileri (bookmarkâ€™lar, veri sÃ¶zlÃ¼kleri, yapÄ±lacaklar listesi, komutlar, deney sonuÃ§larÄ±) her yarÄ±ÅŸma iÃ§in standart bir formatta toplarÄ±m ve bir takÄ±mda yarÄ±ÅŸÄ±yorsam bu bilgileri takÄ±m arkadaÅŸlarÄ±mla paylaÅŸÄ±rÄ±m.
> 
> 
> 
> **GirdiÄŸin Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±n iÃ§gÃ¶rÃ¼lerden bahseder misin?**
> 
> Benim iÃ§in yarÄ±ÅŸmanÄ±n **genel baÄŸlamÄ±nÄ± anlamak** her zaman faydalÄ± olmuÅŸtur; Ã¶rneÄŸin, verinin ortaya Ã§Ä±kmasÄ±na neden olan sosyal/mÃ¼hendislik/finans sÃ¼reÃ§leri nedir? Deepfake Detection Challenge gibi bireysel veri noktalarÄ±nÄ±n anlamlÄ± ÅŸekilde gÃ¶zlemlenebildiÄŸi yarÄ±ÅŸmalarda, genellikle **Streamlit** kullanarak Ã¶zel bir dashboard hazÄ±rlardÄ±m. Bu dashboard ile bireysel veri noktalarÄ±nÄ± (Ã¶rneÄŸin gerÃ§ek ve sahte video Ã§iftleri) kontrol edebilir ve basit istatistik toplama ile veriyi daha iyi anlayabilirdim.
> 
> 
> 
> **Kaggle kariyerine yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?**
> 
> Kaggle, ÅŸu anki kariyerimde, veri bilimi danÄ±ÅŸmanlÄ±k firmasÄ±nda eÅŸ sahip olarak yer almamda en bÃ¼yÃ¼k katkÄ±yÄ± saÄŸlayan platform oldu diyebilirim. YÄ±llar iÃ§inde farklÄ± alanlardaki veri problemlerini Ã§Ã¶zmek iÃ§in gerekli **beceri ve metodolojiyi** kazanmamÄ± saÄŸladÄ±. Hem mÃ¼ÅŸterilerim hem de ekip arkadaÅŸlarÄ±m, Kaggle yarÄ±ÅŸmalarÄ±nda kurduÄŸum takÄ±mlardan tanÄ±ÅŸtÄ±ÄŸÄ±m kiÅŸiler. Bu platform, bilgi kaynaÄŸÄ± olarak her zaman Ã§ok faydalÄ± oldu; gÃ¼nÃ¼mÃ¼zde daha az aktif olsam da.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r? BaÅŸladÄ±ÄŸÄ±nda bilmek istediÄŸin ÅŸey neydi?**
> 
> Yeni baÅŸlayanlarÄ±n sÄ±k yaptÄ±ÄŸÄ± hata, **kritik teknik olmayan konularÄ±** gÃ¶z ardÄ± etmeleridir: takÄ±m kurallarÄ±, veri kullanÄ±mÄ±, Ã¶zel bilgilerin paylaÅŸÄ±mÄ±, masum sebeplerle birden fazla hesap kullanÄ±mÄ± vb. Bu tÃ¼r hatalar, Ã§oÄŸu zaman aylardÄ±r sÃ¼ren yarÄ±ÅŸma Ã§alÄ±ÅŸmalarÄ±nÄ± tamamen geÃ§ersiz kÄ±labilir.
> 
> 
> 
> BaÅŸladÄ±ÄŸÄ±mda bilmek istediÄŸim bir diÄŸer ÅŸey ise, **gÃ¼nlÃ¼k public leaderboard pozisyonuna takÄ±lmamak** olurdu. Bu gereksiz baskÄ± yaratÄ±r ve overfittingâ€™e yol aÃ§ar.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nereceÄŸin araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Standart araÃ§lar: **Scikit-learn, XGB/LGB, PyTorch** vb.
> 
> Ancak temel kullanÄ±mÄ±n Ã¶tesinde herkesin **NumPyâ€™yi** iyi Ã¶ÄŸrenmesini Ã¶neririm; Ã¶zellikle verileri daha geliÅŸmiÅŸ ÅŸekilde sÄ±ralamak ve alt kÃ¼melere ayÄ±rmak iÃ§in. Pandas kolaylaÅŸtÄ±rÄ±r, ama NumPy ile daha verimli yÃ¶ntemler uygulanabilir.
> 
> 
> 
> **YarÄ±ÅŸmaya girerken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Bana gÃ¶re veri bilimi ile ilgili iÅŸleri yapmanÄ±n dÃ¶rt nedeni vardÄ±r: **kar, bilgi, eÄŸlence ve iyilik**. Kaggle benim iÃ§in her zaman **bÃ¼yÃ¼k bir bilgi kaynaÄŸÄ±** ve hatÄ±rlanacak bir hafÄ±za deposu olmuÅŸtur. Bu yÃ¼zden Ã¶nerim: **SÄ±ralamanÄ±n geÃ§ici, bilginin ve hafÄ±zanÄ±n kalÄ±cÄ± olduÄŸunu hatÄ±rlayÄ±n.**
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ± kullanÄ±yor musun? Kaggle ile karÅŸÄ±laÅŸtÄ±rÄ±nca?**
> 
> Numeraiâ€™da oldukÃ§a aktifim. DÃ¶rt nedenim aÃ§Ä±sÄ±ndan, Numerai daha Ã§ok **kar amacÄ±yla** oluyor Ã§Ã¼nkÃ¼ Ã¶demeyi kripto para ile yapÄ±yorlar. Daha Ã§ok **bireysel Ã§aba** gerektiriyor; takÄ±m kurmak Ã§ok avantaj saÄŸlamÄ±yor.
> 
> 
> 
> Numerai, yoÄŸun iÅŸ takvimimde **Kaggleâ€™dan daha sÃ¼rdÃ¼rÃ¼lebilir** bir etkinlik Ã§Ã¼nkÃ¼ her turda eÄŸitim verisi genellikle deÄŸiÅŸmiyor. Ä°lk modeller kurulduktan sonra tahmin ve gÃ¶nderim sÃ¼reÃ§lerini **yÃ¼ksek derecede otomatikleÅŸtirebilirim**. AyrÄ±ca Numerai, tabular veri setleri iÃ§in Ã¶zel makine Ã¶ÄŸrenimi pipelineâ€™larÄ± geliÅŸtirmek isteyenler iÃ§in daha uygun bir platform.

### Netiquette *(Ä°nternet gÃ¶rgÃ¼ kurallarÄ±)*

Ä°nternette 15 dakikadan uzun sÃ¼re vakit geÃ§iren herkes bunu bilir: Bir tartÄ±ÅŸma sÄ±rasÄ±nda, konunun ne kadar masum olursa olsun, insanlarÄ±n duygusal tepkiler vermesi ve sohbetin medeni sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±na taÅŸmasÄ± her zaman mÃ¼mkÃ¼ndÃ¼r. Kaggle da bu kuralÄ±n istisnasÄ± deÄŸildir; bu yÃ¼zden topluluÄŸun **uygun davranÄ±ÅŸ kurallarÄ±** vardÄ±r: [https://www.kaggle.com/community-guidelines](https://www.kaggle.com/community-guidelines).

Bu kurallar yalnÄ±zca tartÄ±ÅŸmalara deÄŸil, **Notebooks** ve diÄŸer iletiÅŸim biÃ§imlerine de uygulanÄ±r. Kaggleâ€™da etkileÅŸimde bulunurken akÄ±lda tutulmasÄ± gereken baÅŸlÄ±ca noktalar ÅŸunlardÄ±r:

* **Zihinsel okuma yanÄ±lgÄ±sÄ±na dÃ¼ÅŸmeyin:** Scott Adamsâ€™Ä±n adlandÄ±rdÄ±ÄŸÄ± bu yanÄ±lgÄ±, insanlarÄ±n ne dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼ varsayma eÄŸilimidir. Kaggle, dÃ¼nyanÄ±n dÃ¶rt bir yanÄ±ndan gelen Ã§ok Ã§eÅŸitli bir topluluktur (Ã§oÄŸu iÃ§in Ä°ngilizce ikinci dil), bu nedenle nÃ¼ansÄ± korumak bÃ¼yÃ¼k bir zorluktur. VarsayÄ±mlarda bulunmayÄ±n ve mÃ¼mkÃ¼n olduÄŸunca netleÅŸtirmeye Ã§alÄ±ÅŸÄ±n.
* **Åahsi saldÄ±rÄ±lardan kaÃ§Ä±nÄ±n:** Godwinâ€™in yasasÄ± boÅŸuna yoktur. Ã–zellikle korunan ve deÄŸiÅŸtirilemez Ã¶zelliklere yÃ¶nelik referanslar kesinlikle yasaktÄ±r.
* **AÅŸaÄŸÄ±lamalardan kaÃ§Ä±nÄ±n:** Deneyimleriniz farklÄ± olabilir, ancak internetin 1990â€™larda â€œRTFMâ€ demenin normal olduÄŸu vahÅŸi batÄ± ortamÄ± artÄ±k yok. AÅŸaÄŸÄ±lamalar insanlarÄ± uzaklaÅŸtÄ±rÄ±r.
* **Ä°lerleme sistemini manipÃ¼le etmeye Ã§alÄ±ÅŸmayÄ±n:** Kaggle madalyalarÄ±nÄ±n verildiÄŸi bu sistemin manipÃ¼lasyonu, aÃ§Ä±kÃ§a oy istemekten, gizli anlaÅŸmalara, hatta doÄŸrudan hileye kadar platform kÃ¶tÃ¼ye kullanÄ±mÄ±nÄ±n tÃ¼m yelpazesini kapsar.

KÄ±saca, baÅŸkalarÄ±na kendinize davranÄ±lmasÄ±nÄ± istediÄŸiniz ÅŸekilde davranÄ±n, her ÅŸey yolunda gider.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle platformunda iletiÅŸimin birincil yolu olan **tartÄ±ÅŸma forumlarÄ±nÄ±** ele aldÄ±k. Forum mekaniklerini gÃ¶sterdik, tartÄ±ÅŸmalarÄ±n daha geliÅŸmiÅŸ yarÄ±ÅŸmalarda nasÄ±l kullanÄ±labileceÄŸine dair Ã¶rnekler sunduk ve tartÄ±ÅŸma **netiketi**ni kÄ±saca Ã¶zetledik.

Bu, kitabÄ±n ilk ve giriÅŸ niteliÄŸindeki bÃ¶lÃ¼mÃ¼nÃ¼n sonunu iÅŸaret ediyor. Bir sonraki bÃ¶lÃ¼m, Kaggleâ€™dan elde edeceÄŸiniz verimi **maksimize etme** konusunda daha derin bir incelemenin baÅŸlangÄ±cÄ±nÄ± oluÅŸturuyor ve yarÄ±ÅŸmalarda karÅŸÄ±laÅŸmanÄ±z gereken Ã§ok Ã§eÅŸitli gÃ¶revler ve metriklerle baÅŸa Ã§Ä±kmayÄ± ele alÄ±yor.

---

# Part II: Sharpening Your Skills for Competitions *(BÃ¶lÃ¼m II: YarÄ±ÅŸmalar Ä°Ã§in Becerilerini GeliÅŸtirme)*

## Chapter 5: Competition Tasks and Metrics *(BÃ¶lÃ¼m 5: YarÄ±ÅŸma GÃ¶revleri ve Ã–lÃ§Ã¼tleri)*

Bir yarÄ±ÅŸmada, iÅŸe hedef metriÄŸi inceleyerek baÅŸlarsÄ±nÄ±z. Modelinizin hatalarÄ±nÄ±n nasÄ±l deÄŸerlendirildiÄŸini anlamak, her yarÄ±ÅŸmada yÃ¼ksek puan alabilmek iÃ§in kritik Ã¶neme sahiptir. Tahminleriniz Kaggle platformuna gÃ¶nderildiÄŸinde, hedef metrik temel alÄ±narak gerÃ§ek deÄŸerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

Ã–rneÄŸin, Titanic yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/titanic/](https://www.kaggle.com/c/titanic/)) tÃ¼m gÃ¶nderimleriniz doÄŸruluk (accuracy) temelinde deÄŸerlendirilir; yani, hayatta kalan yolcularÄ± doÄŸru tahmin etme yÃ¼zdesi. Organizasyon bu metriÄŸi seÃ§miÅŸtir Ã§Ã¼nkÃ¼ yarÄ±ÅŸmanÄ±n amacÄ±, benzer koÅŸullar altÄ±nda bir yolcunun hayatta kalma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin edebilen bir model bulmaktÄ±r.

BaÅŸka bir bilgi yarÄ±ÅŸmasÄ±nda, House Prices - Advanced Regression Techniques ([https://www.kaggle.com/c/house-prices-advanced-regression-techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)), Ã§alÄ±ÅŸmalarÄ±nÄ±z tahmininiz ile gerÃ§ek deÄŸer arasÄ±ndaki ortalama fark temelinde deÄŸerlendirilir. Bu, logaritmayÄ± almayÄ±, karesini almayÄ± ve karekÃ¶kÃ¼nÃ¼ hesaplamayÄ± iÃ§erir; Ã§Ã¼nkÃ¼ modelden, satÄ±ÅŸta olan bir evin fiyat sÄ±rasÄ±nÄ± olabildiÄŸince doÄŸru bir ÅŸekilde tahmin etmesi beklenir.

GerÃ§ek dÃ¼nyadaki veri bilimi projelerinde de hedef metrikler, projenin baÅŸarÄ±sÄ± iÃ§in kritiktir; ancak gerÃ§ek dÃ¼nya ile Kaggle yarÄ±ÅŸmalarÄ± arasÄ±nda bazÄ± farklÄ±lÄ±klar vardÄ±r. Ã–zetle, gerÃ§ek dÃ¼nyada iÅŸler daha karmaÅŸÄ±ktÄ±r. GerÃ§ek dÃ¼nya projelerinde modeliniz genellikle yalnÄ±zca bir deÄŸil, birden fazla metrikle deÄŸerlendirilecektir. SÄ±klÄ±kla bazÄ± deÄŸerlendirme metrikleri, test iÃ§in kullandÄ±ÄŸÄ±nÄ±z gerÃ§ek deÄŸerlerle tahminlerinizin performansÄ± ile doÄŸrudan iliÅŸkili olmayabilir.

Ã–rneÄŸin, Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z bilgi alanÄ±, projenin kapsamÄ±, modelinizin dikkate aldÄ±ÄŸÄ± Ã¶zellik sayÄ±sÄ±, genel bellek kullanÄ±mÄ±, Ã¶zel donanÄ±m gereksinimleri (Ã¶r. GPU), tahmin sÃ¼recinin gecikmesi, modelin karmaÅŸÄ±klÄ±ÄŸÄ± ve diÄŸer birÃ§ok faktÃ¶r, yalnÄ±zca tahmin performansÄ±ndan daha fazla Ã¶nem taÅŸÄ±yabilir.

GerÃ§ek dÃ¼nyadaki problemler, dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼zden Ã§ok daha fazla iÅŸ ve teknik altyapÄ± kaygÄ±larÄ± tarafÄ±ndan ÅŸekillendirilir.

Yine de, hem gerÃ§ek dÃ¼nya projelerinde hem de Kaggle yarÄ±ÅŸmalarÄ±nda temel prensip aynÄ±dÄ±r: Ã‡alÄ±ÅŸmanÄ±z belirli kriterlere gÃ¶re deÄŸerlendirilecektir. Bu kriterlerin detaylarÄ±nÄ± anlamak, modelinizi akÄ±llÄ±ca optimize etmek veya parametrelerini bu kriterlere gÃ¶re seÃ§mek baÅŸarÄ± getirir. Kaggleâ€™da model deÄŸerlendirmesinin nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenebilirseniz, gerÃ§ek dÃ¼nyadaki veri bilimi iÅŸiniz de bundan fayda saÄŸlar.

Bu bÃ¶lÃ¼mde, belirli problem tÃ¼rleri iÃ§in deÄŸerlendirme metriklerinin, veri bilimi yarÄ±ÅŸmalarÄ±nda model Ã§Ã¶zÃ¼mÃ¼ oluÅŸtururken nasÄ±l hareket edebileceÄŸinizi gÃ¼Ã§lÃ¼ bir ÅŸekilde etkilediÄŸini detaylÄ± olarak inceleyeceÄŸiz. AyrÄ±ca, Kaggle yarÄ±ÅŸmalarÄ±nda bulunan Ã§eÅŸitli metrikleri ele alarak, hangi metriklerin daha Ã¶nemli olduÄŸunu anlamanÄ±zÄ± saÄŸlayacaÄŸÄ±z ve yan not olarak metriklerin tahmin performansÄ± Ã¼zerindeki farklÄ± etkilerini ve bunlarÄ± projelerinize nasÄ±l doÄŸru ÅŸekilde aktarabileceÄŸinizi tartÄ±ÅŸacaÄŸÄ±z.

Bu bÃ¶lÃ¼mde ele alÄ±nacak konular:

* DeÄŸerlendirme metrikleri ve amaÃ§ fonksiyonlarÄ±
* Temel gÃ¶rev tÃ¼rleri: regresyon, sÄ±nÄ±flandÄ±rma ve sÄ±ralÄ± (ordinal)
* Meta Kaggle veri seti
* Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerin ele alÄ±nmasÄ±
* Regresyon metrikleri (standart ve ordinal)
* Ä°kili sÄ±nÄ±flandÄ±rma metrikleri (etiket tahmini ve olasÄ±lÄ±k)
* Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri
* Nesne tespit problemleri iÃ§in metrikler
* Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri sistemleri metrikleri
* DeÄŸerlendirme metriklerini optimize etme

### Evaluation metrics and objective functions *(DeÄŸerlendirme metrikleri ve hedef fonksiyonlar)*

Bir Kaggle yarÄ±ÅŸmasÄ±nda, deÄŸerlendirme metriÄŸini yarÄ±ÅŸmanÄ±n **Overview (Genel BakÄ±ÅŸ)** sayfasÄ±nÄ±n sol menÃ¼sÃ¼nden bulabilirsiniz. **Evaluation (DeÄŸerlendirme)** sekmesini seÃ§tiÄŸinizde, metriÄŸe iliÅŸkin detaylarÄ± gÃ¶rebilirsiniz. Bazen burada metrik formÃ¼lÃ¼, metrikle ilgili yeniden Ã¼retim kodu ve metrik hakkÄ±nda bazÄ± tartÄ±ÅŸmalar da bulunur. AynÄ± sayfada, ayrÄ±ca gÃ¶nderim dosyasÄ± formatÄ± hakkÄ±nda aÃ§Ä±klamalar yer alÄ±r; dosyanÄ±n baÅŸlÄ±k satÄ±rÄ± ve birkaÃ§ Ã¶rnek satÄ±r gÃ¶sterilir.

DeÄŸerlendirme metriÄŸi ile gÃ¶nderim dosyasÄ± arasÄ±ndaki iliÅŸki Ã¶nemlidir, Ã§Ã¼nkÃ¼ metrik esasen modelinizi eÄŸitip tahminleri Ã¼rettikten sonra iÅŸler. DolayÄ±sÄ±yla ilk adÄ±m olarak, **deÄŸerlendirme metriÄŸi ile amaÃ§ fonksiyonu arasÄ±ndaki farkÄ±** anlamalÄ±sÄ±nÄ±z.

Temel olarak Ã¶zetlersek:

* **AmaÃ§ fonksiyonu (objective function)**, modelinizi eÄŸitirken kullanÄ±lÄ±r; hata minimizasyonu veya skor maksimizasyonu sÃ¼recinde yer alÄ±r.
* **DeÄŸerlendirme metriÄŸi (evaluation metric)** ise model eÄŸitildikten sonra bir skor saÄŸlar. Bu nedenle doÄŸrudan modelin veriyle uyumunu etkilemez, ancak dolaylÄ± olarak etkiler: en iyi hiperparametre ayarlarÄ±nÄ± seÃ§menize ve rekabet eden modeller arasÄ±nda en iyi modelleri belirlemenize yardÄ±mcÄ± olur.

BÃ¶lÃ¼mÃ¼n geri kalanÄ±nda, bunun bir Kaggle yarÄ±ÅŸmasÄ±nÄ± nasÄ±l etkileyebileceÄŸini ve neden yarÄ±ÅŸmadaki deÄŸerlendirme metriÄŸinin analizinin ilk adÄ±mÄ±nÄ±z olmasÄ± gerektiÄŸini gÃ¶stereceÄŸiz. Ã–nce, tartÄ±ÅŸma forumlarÄ±nda sÄ±kÃ§a karÅŸÄ±laÅŸabileceÄŸiniz bazÄ± terimleri ele alalÄ±m.

Genellikle **objective function, cost function ve loss function** terimlerini birbirinin yerine duyarÄ±z, ama hepsi tam olarak aynÄ± ÅŸey deÄŸildir:

* **Loss function (KayÄ±p fonksiyonu):** Tek bir veri noktasÄ± Ã¼zerine tanÄ±mlanÄ±r ve modelin tahmini ile gerÃ§ek deÄŸer arasÄ±ndaki ceza miktarÄ±nÄ± hesaplar.
* **Cost function (Maliyet fonksiyonu):** EÄŸitim iÃ§in kullanÄ±lan tÃ¼m veri setini (veya bir batchâ€™ini) dikkate alÄ±r ve veri noktalarÄ±nÄ±n kayÄ±p fonksiyonlarÄ± Ã¼zerinden toplam veya ortalama hesaplar. L1 veya L2 ceza terimleri gibi ek kÄ±sÄ±tlamalarÄ± iÃ§erebilir. Maliyet fonksiyonu doÄŸrudan eÄŸitim sÃ¼recini etkiler.
* **Objective function (AmaÃ§ fonksiyonu):** Makine Ã¶ÄŸrenimi eÄŸitiminde optimizasyon kapsamÄ±yla ilgili en genel terimdir; maliyet fonksiyonlarÄ±nÄ± iÃ§erir ama onlarla sÄ±nÄ±rlÄ± deÄŸildir. Ã–rneÄŸin, tahmin edilen modelin katsayÄ±larÄ±nÄ±n seyrek olmasÄ±nÄ± veya katsayÄ± deÄŸerlerinin minimize edilmesini gerektiren L1/L2 regularizasyonlarÄ± gibi hedefleri de iÃ§erebilir. Loss ve cost fonksiyonlarÄ± genellikle minimizasyona dayalÄ± iken, amaÃ§ fonksiyonu nÃ¶trdÃ¼r ve hem maximizasyon hem minimizasyon amaÃ§lÄ± optimizasyonu kapsayabilir.

Benzer ÅŸekilde, deÄŸerlendirme metriklerinde de **scoring function (skor fonksiyonu)** ve **error function (hata fonksiyonu)** terimlerini duyabilirsiniz:

* **Scoring function:** Fonksiyonun skoru yÃ¼ksek olduÄŸunda tahminler daha iyi kabul edilir; bu bir **maksimizasyon** sÃ¼recini ifade eder.
* **Error function:** Fonksiyonun hata deÄŸeri daha kÃ¼Ã§Ã¼k olduÄŸunda tahminler daha iyi kabul edilir; bu bir **minimizasyon** sÃ¼recini ifade eder.

### Basic types of tasks *(Temel gÃ¶rev tÃ¼rleri)*

TÃ¼m amaÃ§ fonksiyonlarÄ± her problem iÃ§in uygun deÄŸildir. Genel bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla, Kaggle yarÄ±ÅŸmalarÄ±nda iki tÃ¼r problem bulursunuz: **regresyon gÃ¶revleri** ve **sÄ±nÄ±flandÄ±rma gÃ¶revleri**.

Son zamanlarda, bazÄ± yarÄ±ÅŸmalarda **reinforcement learning (RL â€“ pekiÅŸtirmeli Ã¶ÄŸrenme)** gÃ¶revleri de gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Ancak RL, deÄŸerlendirme iÃ§in metrik kullanmaz; bunun yerine, Ã§Ã¶zÃ¼mleri sizin Ã§Ã¶zÃ¼mÃ¼nÃ¼z kadar iyi olduÄŸu varsayÄ±lan diÄŸer katÄ±lÄ±mcÄ±larla doÄŸrudan karÅŸÄ±laÅŸtÄ±rmalardan tÃ¼retilen bir sÄ±ralamaya dayanÄ±r. Bu karÅŸÄ±laÅŸtÄ±rmada diÄŸer katÄ±lÄ±mcÄ±lardan daha iyi performans gÃ¶sterirseniz sÄ±ralamanÄ±z yÃ¼kselir, daha kÃ¶tÃ¼ performans gÃ¶sterirseniz dÃ¼ÅŸer.

RL metrik kullanmadÄ±ÄŸÄ± iÃ§in, biz hÃ¢lÃ¢ **regresyon-sÄ±nÄ±flandÄ±rma ikiliÄŸini** temel alacaÄŸÄ±z. Ancak **ordinal gÃ¶revler** (sÄ±ralÄ± etiketleri, genellikle tamsayÄ±larla temsil edilen, tahmin ettiÄŸiniz gÃ¶revler) bu kategorilere tam olarak uymayabilir. Ordinal gÃ¶revler, regresyon veya sÄ±nÄ±flandÄ±rma yaklaÅŸÄ±mlarÄ±ndan biriyle baÅŸarÄ±yla ele alÄ±nabilir.

#### Regression *(Regresyon)*

**Regresyon**, gerÃ§ek bir sayÄ± tahmin edebilen bir model kurmanÄ±zÄ± gerektirir; Ã§oÄŸunlukla pozitif bir sayÄ± tahmin edilir, ancak negatif sayÄ± tahmini yapÄ±lan Ã¶rnekler de olmuÅŸtur.

Regresyon problemlerine klasik bir Ã¶rnek, **House Prices - Advanced Regression Techniques** yarÄ±ÅŸmasÄ±dÄ±r; Ã§Ã¼nkÃ¼ burada bir evin deÄŸerini tahmin etmeniz gerekir.

Bir regresyon gÃ¶revinde deÄŸerlendirme, tahminleriniz ile gerÃ§ek deÄŸerler arasÄ±ndaki **farkÄ±n Ã¶lÃ§Ã¼lmesi** ile yapÄ±lÄ±r. Bu fark farklÄ± yollarla deÄŸerlendirilebilir:

* **Karesini almak**, yani hatalarÄ± daha bÃ¼yÃ¼k olan tahminleri daha fazla cezalandÄ±rmak,
* **Logaritma uygulamak**, yani yanlÄ±ÅŸ Ã¶lÃ§eklerdeki tahminleri cezalandÄ±rmak iÃ§in.

#### Classification *(SÄ±nÄ±flandÄ±rma)*

Kaggleâ€™da bir **sÄ±nÄ±flandÄ±rma (classification)** gÃ¶revi ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda dikkate alÄ±nmasÄ± gereken daha fazla nÃ¼ans vardÄ±r. SÄ±nÄ±flandÄ±rma, aslÄ±nda **ikili (binary), Ã§ok sÄ±nÄ±flÄ± (multi-class) veya Ã§ok etiketli (multi-label)** olabilir.

* **Ä°kili sÄ±nÄ±flandÄ±rma (binary problems):**
  Bir Ã¶rneÄŸin belirli bir sÄ±nÄ±fa ait olup olmadÄ±ÄŸÄ±nÄ± tahmin etmeniz gerekir (genellikle â€œpozitif sÄ±nÄ±fâ€ olarak adlandÄ±rÄ±lÄ±r ve â€œnegatif sÄ±nÄ±fâ€ ile karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r).
  Burada deÄŸerlendirme, doÄŸrudan sÄ±nÄ±f tahminine dayanabilir veya sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ±nÄ±n tahmin edilmesini gerektirebilir.
  Ã–rnek: **Titanic** yarÄ±ÅŸmasÄ±; burada ikili bir sonuÃ§ tahmin edersiniz: hayatta kalma veya kalmama. YarÄ±ÅŸma Ã§oÄŸu zaman sadece tahmini ister, ancak bazÄ± alanlardaâ€”Ã¶zellikle tÄ±p uygulamalarÄ±ndaâ€”pozitif tahminleri farklÄ± seÃ§enekler ve durumlar arasÄ±nda sÄ±ralamak gerekebilir, bu yÃ¼zden olasÄ±lÄ±k tahmini gerekir.

* **Dengesiz sÄ±nÄ±flar (imbalanced classes):**
  Ä°kili sÄ±nÄ±flandÄ±rmada doÄŸru eÅŸleÅŸmelerin sayÄ±sÄ±nÄ± doÄŸrudan saymak mantÄ±klÄ± gÃ¶rÃ¼nse de, pozitif ve negatif sÄ±nÄ±flar arasÄ±nda Ã¶rnek sayÄ±sÄ± farklÄ± olduÄŸunda bu yÃ¶ntem iyi Ã§alÄ±ÅŸmaz.
  Dengesiz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±, model geliÅŸtirmelerini doÄŸru ÅŸekilde takip edebilmek iÃ§in **dengeyi dikkate alan deÄŸerlendirme metrikleri** gerektirir.

* **Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma (multi-class):**
  Ä°ki sÄ±nÄ±ftan fazlasÄ± varsa, bu bir **Ã§ok sÄ±nÄ±flÄ± tahmin problemi**dir. Bu durumda, modelin genel performansÄ±nÄ± izlemek ve sÄ±nÄ±flar arasÄ±ndaki performansÄ±n karÅŸÄ±laÅŸtÄ±rÄ±labilir olmasÄ±nÄ± saÄŸlamak iÃ§in uygun metrikler kullanmak gerekir.
  Ã–rnek: **Leaf Classification** yarÄ±ÅŸmasÄ±; burada her yaprak Ã¶rneÄŸinin doÄŸru bitki tÃ¼rÃ¼ ile eÅŸleÅŸtirilmesi gerekir.

* **Ã‡ok etiketli sÄ±nÄ±flandÄ±rma (multi-label):**
  EÄŸer her Ã¶rnek iÃ§in birden fazla sÄ±nÄ±f tahmin edilebiliyorsa, bu bir **Ã§ok etiketli problem**dir. Bu durumda, modelin doÄŸru sÄ±nÄ±flarÄ±, doÄŸru sayÄ± ve karÄ±ÅŸÄ±mÄ± tahmin edip etmediÄŸini kontrol etmek iÃ§in ek deÄŸerlendirmeler gerekir.
  Ã–rnek: **Greek Media Monitoring Multilabel Classification (WISE 2014)**; burada her makale, iÅŸlediÄŸi tÃ¼m konularla iliÅŸkilendirilmeliydi.

#### Ordinal *(SÄ±ralÄ± veriler)*

Bir **ordinal Ã¶lÃ§ekli tahmin probleminde**, tam sayÄ± ÅŸeklinde etiketleri tahmin etmeniz gerekir; bu etiketler doÄŸal olarak sÄ±ralÄ±dÄ±r.
Ã–rnek: Bir depremin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ordinal bir Ã¶lÃ§ektedir.
AyrÄ±ca, pazarlama araÅŸtÄ±rmalarÄ± anketlerinden elde edilen veriler de sÄ±klÄ±kla ordinal Ã¶lÃ§ekle kaydedilir (Ã¶rneÄŸin, tÃ¼ketici tercihleri veya fikir uyumu).

Ordinal Ã¶lÃ§ek **sÄ±ralÄ± deÄŸerlerden** oluÅŸtuÄŸu iÃ§in, ordinal gÃ¶revler hem regresyon hem de sÄ±nÄ±flandÄ±rma yÃ¶ntemleriyle Ã§Ã¶zÃ¼lebilir; yani adeta bu iki yÃ¶ntem arasÄ±nda bir geÃ§iÅŸ niteliÄŸindedir.

* **Ã‡ok sÄ±nÄ±flÄ± problem olarak yaklaÅŸmak:**
  Ordinal gÃ¶revi Ã§ok sÄ±nÄ±flÄ± bir problem gibi ele almak en yaygÄ±n yaklaÅŸÄ±mdÄ±r. Bu durumda, bir tam sayÄ± deÄŸeri (sÄ±nÄ±f etiketi) tahmin edersiniz, ancak tahmin **sÄ±nÄ±flarÄ±n sÄ±ralÄ± olduÄŸunu dikkate almaz**.
  EÄŸer sÄ±nÄ±flar iÃ§in tahmin olasÄ±lÄ±klarÄ±nÄ± incelerseniz, problem Ã¼zerinde Ã§ok sÄ±nÄ±flÄ± bir yaklaÅŸÄ±mÄ±n eksiklerini fark edebilirsiniz. OlasÄ±lÄ±klar genellikle tÃ¼m olasÄ± deÄŸerler boyunca daÄŸÄ±lÄ±r; bu, **Ã§ok modlu ve genellikle simetrik olmayan bir daÄŸÄ±lÄ±m** oluÅŸturur. Halbuki doÄŸru yaklaÅŸÄ±mda, maksimum olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±f etrafÄ±nda **Gaussian benzeri bir daÄŸÄ±lÄ±m** beklenir.

* **Regresyon problemine dÃ¶nÃ¼ÅŸtÃ¼rmek:**
  Ordinal tahmin problemini regresyon olarak ele alÄ±p ardÄ±ndan post-processing yapmak baÅŸka bir yaklaÅŸÄ±mdÄ±r. Bu yÃ¶ntemle, sÄ±nÄ±flar arasÄ±ndaki sÄ±ralama dikkate alÄ±nÄ±r, ancak tahmin Ã§Ä±ktÄ±sÄ± hemen deÄŸerlendirme metriÄŸinde kullanÄ±labilir deÄŸildir.
  Regresyonda Ã§Ä±ktÄ± bir tam sayÄ± deÄŸil, **float bir sayÄ±**dÄ±r ve bu sayÄ± ordinal daÄŸÄ±lÄ±mÄ±nÄ±zdaki tam sayÄ±lar arasÄ±ndaki tÃ¼m deÄŸerleri (ve hatta bazen sÄ±nÄ±rlarÄ±n dÄ±ÅŸÄ±ndaki deÄŸerleri) iÃ§erebilir. Ã‡Ä±ktÄ± deÄŸerlerini kÄ±rpÄ±p birim yuvarlamasÄ±yla tam sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rmek iÅŸe yarayabilir, ancak bu yÃ¶ntem bazÄ± hatalara yol aÃ§abilir ve daha sofistike bir post-processing gerekebilir (bunun detaylarÄ± ilerleyen bÃ¶lÃ¼mlerde ele alÄ±nacaktÄ±r).

Åimdi muhtemelen merak ediyorsunuz: **Kaggleâ€™da baÅŸarÄ±lÄ± olmak iÃ§in hangi deÄŸerlendirme metriklerini bilmemiz gerekir?**
AÃ§Ä±kÃ§a, her zaman katÄ±ldÄ±ÄŸÄ±nÄ±z yarÄ±ÅŸmanÄ±n **deÄŸerlendirme metriÄŸini** iyi bilmelisiniz. Ancak bazÄ± metrikler diÄŸerlerinden daha yaygÄ±ndÄ±r; bu bilgiyi kendi avantajÄ±nÄ±za kullanabilirsiniz.

* **SÄ±k kullanÄ±lan metrikler nelerdir?**
* **Benzer deÄŸerlendirme metrikleri kullanan yarÄ±ÅŸmalardan ipuÃ§larÄ±nÄ± nasÄ±l bulabilirsiniz?**

Bunun cevabÄ±: **Meta Kaggle veri setini** incelemektir.

### The Meta Kaggle dataset *(Meta Kaggle veri seti)*

**Meta Kaggle veri seti** ([https://www.kaggle.com/kaggle/meta-kaggle](https://www.kaggle.com/kaggle/meta-kaggle)), Kaggle topluluÄŸu ve aktiviteleri hakkÄ±nda zengin veri iÃ§eren, Kaggle tarafÄ±ndan yayÄ±mlanmÄ±ÅŸ bir halka aÃ§Ä±k veri setidir.
Veri seti, **Competitions, Datasets, Notebooks ve Discussions** gibi Kaggleâ€™daki kamuya aÃ§Ä±k aktiviteleri iÃ§eren CSV tablolarÄ±ndan oluÅŸur.

KullanÄ±mÄ± oldukÃ§a basittir:

1. Bir **Kaggle Notebook** baÅŸlatÄ±n (BÃ¶lÃ¼m 2 ve 3â€™te gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi).
2. Notebookâ€™a **Meta Kaggle veri setini** ekleyin.
3. Verileri analiz etmeye baÅŸlayÄ±n.

CSV tablolarÄ± gÃ¼nlÃ¼k olarak gÃ¼ncellenir, bu yÃ¼zden analizlerinizi sÄ±k sÄ±k yenilemeniz gerekir, ama Ã§Ä±karacaÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼ler buna deÄŸecektir.

Bu kitapta, Meta Kaggle veri setine hem **yarÄ±ÅŸmalardaki dinamikler iÃ§in ilginÃ§ Ã¶rnekler bulmak** hem de **Ã¶ÄŸrenme ve yarÄ±ÅŸma stratejileriniz iÃ§in faydalÄ± Ã¶rnekler Ã§Ä±karmak** iÃ§in atÄ±fta bulunacaÄŸÄ±z.

Burada veri setini, **son yedi yÄ±lda hangi deÄŸerlendirme metriklerinin en sÄ±k kullanÄ±ldÄ±ÄŸÄ±nÄ±** anlamak iÃ§in kullanacaÄŸÄ±z. Bu metrikleri gÃ¶rerek:

* Herhangi bir yarÄ±ÅŸmaya saÄŸlam bir temel ile baÅŸlayabilir,
* ArdÄ±ndan tartÄ±ÅŸma forumlarÄ±ndan elde ettiÄŸiniz bilgilerle metrik hakkÄ±nda yarÄ±ÅŸmaya Ã¶zgÃ¼ ince ayrÄ±ntÄ±larÄ± Ã¶ÄŸrenebilirsiniz.

---

AÅŸaÄŸÄ±daki kod, **yÄ±llara gÃ¶re kullanÄ±lan metriklerin ve sayÄ±larÄ±nÄ± tablo hÃ¢line getirmek** iÃ§in gerekli Ã¶rnek kodu gÃ¶stermektedir. Kod, doÄŸrudan Kaggle platformunda Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r:

```python
import numpy as np
import pandas as pd

# Competitions CSV tablosunu oku
comps = pd.read_csv("/kaggle/input/meta-kaggle/Competitions.csv")

# Ä°lgilenilen sÃ¼tunlar
evaluation = ['EvaluationAlgorithmAbbreviation',
              'EvaluationAlgorithmName',
              'EvaluationAlgorithmDescription',]

compt = ['Title', 'EnabledDate', 'HostSegmentTitle']

# Analiz iÃ§in kopya DataFrame oluÅŸtur
df = comps[compt + evaluation].copy()
df['year'] = pd.to_datetime(df.EnabledDate).dt.year.values
df['comps'] = 1

# 2015 ve sonrasÄ± yarÄ±ÅŸmalarÄ± seÃ§
time_select = df.year >= 2015

# Featured ve Research tÃ¼rÃ¼ndeki yarÄ±ÅŸmalar
competition_type_select = df.HostSegmentTitle.isin(['Featured', 'Research'])

# Pivot tablo oluÅŸtur ve yÄ±llara gÃ¶re metrik sayÄ±sÄ±nÄ± hesapla
pd.pivot_table(df[time_select & competition_type_select],
               values='comps',
               index=['EvaluationAlgorithmAbbreviation'],
               columns=['year'],
               fill_value=0.0,
               aggfunc=np.sum,
               margins=True
              ).sort_values(by=('All'), ascending=False).iloc[1:, :].head(20)
```

Kodun iÅŸleyiÅŸi:

1. Competitions CSVâ€™si okunur.
2. Sadece analiz iÃ§in gerekli sÃ¼tunlar seÃ§ilir: **deÄŸerlendirme algoritmasÄ±, yarÄ±ÅŸma adÄ±, baÅŸlama tarihi ve yarÄ±ÅŸma tÃ¼rÃ¼**.
3. SatÄ±rlar, 2015 sonrasÄ± ve **Featured veya Research tÃ¼rÃ¼ndeki yarÄ±ÅŸmalar** ile sÄ±nÄ±rlanÄ±r (en yaygÄ±n olanlar).
4. **Pivot tablo** ile deÄŸerlendirme algoritmalarÄ± yÄ±llara gÃ¶re gruplanÄ±r ve her birinin kaÃ§ yarÄ±ÅŸmada kullanÄ±ldÄ±ÄŸÄ± sayÄ±lÄ±r.
5. Son olarak **en Ã§ok kullanÄ±lan 20 algoritma** gÃ¶rÃ¼ntÃ¼lenir.

![](im/1042.png)

AynÄ± tablolarÄ± oluÅŸturmak iÃ§in az Ã¶nce baÅŸlattÄ±ÄŸÄ±mÄ±z deÄŸiÅŸkenleri kullanarak, ayrÄ±ca veriyi kontrol edip seÃ§tiÄŸiniz metriÄŸin kullanÄ±ldÄ±ÄŸÄ± yarÄ±ÅŸmalarÄ± da bulabilirsiniz:

```python
metric = 'AUC'
metric_select = df['EvaluationAlgorithmAbbreviation'] == metric
print(df[time_select & competition_type_select & metric_select][['Title', 'year']])
```

YukarÄ±daki Ã¶rnekte, AUC metriÄŸini kullanan yarÄ±ÅŸmalarÄ± temsil etmeye karar verdik. Sadece seÃ§tiÄŸiniz metriÄŸi temsil eden stringâ€™i deÄŸiÅŸtirmeniz yeterlidir; bÃ¶ylece ortaya Ã§Ä±kan liste buna gÃ¶re gÃ¼ncellenecektir.

Tabloya geri dÃ¶nersek, Kaggleâ€™da dÃ¼zenlenen yarÄ±ÅŸmalarda en popÃ¼ler deÄŸerlendirme metriklerini inceleyebiliriz:

* Ä°lk iki metrik birbirine ve ikili olasÄ±lÄ±k sÄ±nÄ±flandÄ±rma problemlerine yakÄ±ndan iliÅŸkilidir. AUC metriÄŸi, modelinizin tahmin ettiÄŸi olasÄ±lÄ±klarÄ±n pozitif Ã¶rnekleri yÃ¼ksek olasÄ±lÄ±kla tahmin etme eÄŸilimini Ã¶lÃ§meye yardÄ±mcÄ± olur. Log Loss ise tahmin edilen olasÄ±lÄ±klarÄ±n gerÃ§ek deÄŸerlerden ne kadar uzak olduÄŸunu Ã¶lÃ§er (ve Log Lossâ€™u optimize ettikÃ§e AUC metriÄŸini de optimize etmiÅŸ olursunuz).
* 3\. sÄ±rada MAP@{K} bulunur; bu metrik Ã¶neri sistemleri ve arama motorlarÄ±nda yaygÄ±n olarak kullanÄ±lÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda bu metrik, Ã§oÄŸunlukla bilgi getirme (information retrieval) deÄŸerlendirmeleri iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Ã–rneÄŸin, **Humpback Whale Identification** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/humpback-whale-identification](https://www.kaggle.com/c/humpback-whale-identification)) bir balinayÄ± tam olarak tanÄ±mlamanÄ±z gerekir ve beÅŸ tahmin hakkÄ±nÄ±z vardÄ±r. BaÅŸka bir Ã¶rnek, **Quick, Draw! Doodle Recognition Challenge** yarÄ±ÅŸmasÄ±dÄ±r ([https://www.kaggle.com/c/quickdraw-doodle-recognition/](https://www.kaggle.com/c/quickdraw-doodle-recognition/)), burada Ã§izilen bir karenin iÃ§eriÄŸini tahmin etmeniz gerekir ve Ã¼Ã§ deneme hakkÄ±nÄ±z vardÄ±r. Temelde, MAP@{K} metriÄŸi kullanÄ±ldÄ±ÄŸÄ±nda, sadece doÄŸru tahmin yapÄ±p yapmadÄ±ÄŸÄ±nÄ±z deÄŸil, aynÄ± zamanda doÄŸru tahmininizin belirli bir sayÄ±da (â€œKâ€ adÄ±yla belirtilen) yanlÄ±ÅŸ tahmin arasÄ±nda olup olmadÄ±ÄŸÄ± da deÄŸerlendirilir.
* 6\. sÄ±rada bir regresyon metriÄŸi olan RMSLE (Root Mean Squared Logarithmic Error) yer alÄ±r ve 7. sÄ±rada Quadratic Weighted Kappa bulunur; bu metrik, ardÄ±ÅŸÄ±k tamsayÄ± tahminleri gerektiren problemler (ordinal Ã¶lÃ§ek problemleri) iÃ§in Ã¶zellikle faydalÄ±dÄ±r.

Listeye gÃ¶z attÄ±ÄŸÄ±nÄ±zda, karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z metriklerin Ã§oÄŸunun makine Ã¶ÄŸrenmesi ders kitaplarÄ±nda sÄ±kÃ§a tartÄ±ÅŸÄ±lan metrikler olduÄŸunu gÃ¶receksiniz. Ã–nÃ¼mÃ¼zdeki birkaÃ§ bÃ¶lÃ¼mde, daha Ã¶nce hiÃ§ karÅŸÄ±laÅŸmadÄ±ÄŸÄ±nÄ±z bir metriÄŸi gÃ¶rdÃ¼ÄŸÃ¼nÃ¼zde ne yapmanÄ±z gerektiÄŸini tartÄ±ÅŸtÄ±ktan sonra, regresyon ve sÄ±nÄ±flandÄ±rma yarÄ±ÅŸmalarÄ±nda en yaygÄ±n olarak kullanÄ±lan metrikleri gÃ¶zden geÃ§ireceÄŸiz.

### Handling never-before-seen metrics *(Daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ metriklerle baÅŸa Ã§Ä±kma)*

Ä°lerlemeye baÅŸlamadan Ã¶nce, en popÃ¼ler 20 metriÄŸi gÃ¶steren tablonun yarÄ±ÅŸmalarda kullanÄ±lan tÃ¼m metrikleri kapsamadÄ±ÄŸÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±yÄ±z. Son yÄ±llarda yalnÄ±zca bir kez kullanÄ±lmÄ±ÅŸ metrikler de vardÄ±r.

**YarÄ±ÅŸma GÃ¶revleri ve Metrikler**

Ã–nceki kod sonuÃ§larÄ±nÄ± kullanarak, bu nadir kullanÄ±lan metriklerin neler olduÄŸunu bulmaya devam edelim:

```python
counts = (df[time_select & competition_type_select]
          .groupby('EvaluationAlgorithmAbbreviation'))
total_comps_per_year = (df[time_select & competition_type_select]
                        .groupby('year').sum())
single_metrics_per_year = (counts.sum()[counts.sum().comps == 1]
                           .groupby('year').sum())
single_metrics_per_year
table = (total_comps_per_year.rename(columns={'comps': 'n_comps'})
         .join(single_metrics_per_year / total_comps_per_year)
         .rename(columns={'comps': 'pct_comps'}))
print(table)
```

SonuÃ§ olarak, her yÄ±l iÃ§in aÅŸaÄŸÄ±daki tabloyu elde ederiz. Bu tabloda, her yÄ±l kaÃ§ yarÄ±ÅŸmanÄ±n daha sonra bir daha kullanÄ±lmamÄ±ÅŸ bir metrik kullandÄ±ÄŸÄ±nÄ± (`n_comps`) ve bu yarÄ±ÅŸmalarÄ±n toplam yarÄ±ÅŸmalara oranÄ±nÄ± (`pct_comps`) gÃ¶rebiliriz:

| year | n_comps | pct_comps |
| ---- | ------- | --------- |
| 2015 | 28      | 0.179     |
| 2016 | 19      | 0.158     |
| 2017 | 34      | 0.177     |
| 2018 | 35      | 0.229     |
| 2019 | 36      | 0.278     |
| 2020 | 43      | 0.302     |
| 2021 | 8       | 0.250     |

Daha sonra bir daha kullanÄ±lmamÄ±ÅŸ metriklerin payÄ±na baktÄ±ÄŸÄ±mÄ±zda, bu oranÄ±n yÄ±l geÃ§tikÃ§e arttÄ±ÄŸÄ±nÄ± ve son yÄ±llarda %25â€“%30 seviyelerine ulaÅŸtÄ±ÄŸÄ±nÄ± hemen fark ederiz. Bu, genellikle her Ã¼Ã§ veya dÃ¶rt yarÄ±ÅŸmadan birinin size metrikleri baÅŸtan Ã¶ÄŸrenip anlamayÄ± gerektirdiÄŸini gÃ¶sterir.

GeÃ§miÅŸte kullanÄ±lmÄ±ÅŸ ve bir daha tekrar edilmeyen metriklerin listesini ÅŸu kÄ±sa kodla alabilirsiniz:

```python
print(counts.sum()[counts.sum().comps == 1].index.values)
```

Bu kodu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zda, benzer bir liste elde edersiniz:

```
['AHD@{Type}', 'CVPRAutoDrivingAveragePrecision', 'CernWeightedAuc',
 'FScore_1', 'GroupMeanLogMAE', 'ImageNetObjectLocalization',
 'IndoorLocalization', 'IntersectionOverUnionObjectSegmentationBeta',
 'IntersectionOverUnionObjectSegmentationWithClassification',
 'IntersectionOverUnionObjectSegmentationWithF1', 'Jaccard',
 'JaccardDSTLParallel', 'JigsawBiasAUC', 'LaplaceLogLikelihood',
 'LevenshteinMean', 'Lyft3DObjectDetectionAP', 'M5_WRMSSE', 'MASpearmanR',
 'MCRMSE', 'MCSpearmanR', 'MWCRMSE', 'MeanColumnwiseLogLoss',
 'MulticlassLossOld', 'NDCG@{K}', 'NQMicroF1', 'NWRMSLE', 'PKUAutoDrivingAP',
 'R2Score', 'RValue', 'RootMeanSquarePercentageError', 'SIIMDice', 'SMAPE',
 'SantaResident', 'SantaRideShare', 'SantaWorkshopSchedule2019', 'TrackML',
 'TravelingSanta2', 'TwoSigmaNews', 'WeightedAUC', 'WeightedMulticlassLoss',
 'WeightedPinballLoss', 'WeightedRowwisePinballLoss', 'YT8M_MeanAveragePrecisionAtK',
 'ZillowMAE', 'football', 'halite', 'mab']
```

YakÄ±ndan incelendiÄŸinde, listede derin Ã¶ÄŸrenme ve pekiÅŸtirmeli Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ±na iliÅŸkin birÃ§ok metrik bulabilirsiniz.

Peki, daha Ã¶nce hiÃ§ karÅŸÄ±laÅŸmadÄ±ÄŸÄ±nÄ±z bir metrikle karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda ne yapmalÄ±sÄ±nÄ±z?

* Tabii ki, Kaggle tartÄ±ÅŸma forumlarÄ±ndaki paylaÅŸÄ±mlara gÃ¼venebilirsiniz; burada her zaman iyi fikirler ve size yardÄ±mcÄ± olacak birÃ§ok Kaggle katÄ±lÄ±mcÄ±sÄ± bulabilirsiniz.
* Ancak metriÄŸi kendi baÅŸÄ±nÄ±za anlamak istiyorsanÄ±z, Googleâ€™da arama yapmanÄ±n yanÄ± sÄ±ra, deÄŸerlendirme fonksiyonunu kendi kodunuzla denemeyi tavsiye ederiz. Bunu mÃ¼kemmel olmasa bile yapabilir, modelin farklÄ± hata tÃ¼rlerine karÅŸÄ± metrik nasÄ±l tepki veriyor simÃ¼le edebilirsiniz. AyrÄ±ca metrik fonksiyonunu yarÄ±ÅŸma eÄŸitim verisi Ã¶rnekleri Ã¼zerinde veya sizin hazÄ±rladÄ±ÄŸÄ±nÄ±z sentetik veri Ã¼zerinde test edebilirsiniz.

BazÄ± Kaggle kullanÄ±cÄ±larÄ±nÄ±n bu yaklaÅŸÄ±mÄ± nasÄ±l kullandÄ±ÄŸÄ±na Ã¶rnekler:

* **Carlo Lepelaars** ile Spearmanâ€™s Rho: [Link](https://www.kaggle.com/carlolepelaars/understanding-the-metric-spearman-s-rho)
* **Carlo Lepelaars** ile Quadratic Weighted Kappa: [Link](https://www.kaggle.com/carlolepelaars/understanding-the-metric-quadratic-weighted-kappa)
* **Rohan Rao** ile Laplace Log Likelihood: [Link](https://www.kaggle.com/rohanrao/osic-understanding-laplace-log-likelihood)

Bu yaklaÅŸÄ±m, deÄŸerlendirme sÃ¼reci hakkÄ±nda daha derin bir anlayÄ±ÅŸ kazandÄ±rÄ±r ve sadece Google ve forumlardan gelen cevaplara gÃ¼venen rakiplere karÅŸÄ± size avantaj saÄŸlar.

> **Rohan Rao**
> 
> [Kaggle Profili](https://www.kaggle.com/rohanrao)
> 
> 
> 
> FarklÄ± metrikleri keÅŸfetmeye baÅŸlamadan Ã¶nce, Quadruple Grandmaster ve H2O.aiâ€™de KÄ±demli Veri Bilimcisi olan Rohan Rao (namÄ± diÄŸer Vopani) ile Kaggleâ€™daki baÅŸarÄ±larÄ±nÄ± ve bizlerle paylaÅŸmak istediÄŸi bilgeliÄŸi konuÅŸalÄ±m.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±ÄŸÄ±nÄ±z nedir?**
> 
> FarklÄ± yarÄ±ÅŸma tÃ¼rleriyle ilgilenmeyi seviyorum, ama en favorim kesinlikle zaman serisi yarÄ±ÅŸmalarÄ±. EndÃ¼strideki tipik zaman serisi yaklaÅŸÄ±mlarÄ±nÄ± ve kavramlarÄ±nÄ± pek sevmiyorum, bu yÃ¼zden Ã§Ã¶zÃ¼mleri alÄ±ÅŸÄ±lmÄ±ÅŸÄ±n dÄ±ÅŸÄ±nda, yenilikÃ§i bir ÅŸekilde kurmayÄ± tercih ediyorum ve bu bana Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar getirdi.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±?**
> 
> Her Kaggle yarÄ±ÅŸmasÄ± iÃ§in tipik iÅŸ akÄ±ÅŸÄ±m ÅŸÃ¶yle:
> 
> 
> 
> * Problem tanÄ±mÄ±nÄ± anlamak ve kurallar, format, zaman Ã§izelgesi, veri setleri, metrikler ve teslimatlar ile ilgili tÃ¼m bilgileri okumak.
> 
> * Veriye derinlemesine dalmak. Veriyi her aÃ§Ä±dan inceleyip dilimleyip gÃ¶rselleÅŸtirerek her tÃ¼rlÃ¼ soruya cevap verebilecek hÃ¢le gelmek.
> 
> * Basit bir pipeline ve temel bir model kurup, sÃ¼recin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrulamak iÃ§in bir gÃ¶nderim yapmak.
> 
> * Ã–zellik mÃ¼hendisliÄŸi yapmak, hiperparametreleri ayarlamak ve hangi modellerin genellikle iÅŸe yaradÄ±ÄŸÄ±nÄ± anlamak iÃ§in Ã§eÅŸitli modellerle denemeler yapmak.
> 
> * Veriyi analiz etmeye, forum tartÄ±ÅŸmalarÄ±nÄ± okumaya ve Ã¶zellikleri ile modelleri sÃ¼rekli olarak geliÅŸtirmeye devam etmek. Belki bir noktada ekip kurmak.
> 
> * Birden fazla modeli ensemble yapmak ve hangi gÃ¶nderimleri final olarak kullanacaÄŸÄ±nÄ±za karar vermek.
> 
> 
> 
> GÃ¼nlÃ¼k veri bilimi Ã§alÄ±ÅŸmalarÄ±mda bunlarÄ±n Ã§oÄŸu da gerÃ§ekleÅŸiyor. Ama ek olarak iki kritik unsur var:
> 
> 
> 
> * Problem tanÄ±mÄ± iÃ§in veri setlerini hazÄ±rlamak ve dÃ¼zenlemek.
> 
> * Nihai model veya Ã§Ã¶zÃ¼mÃ¼ Ã¼retime almak.
> 
> 
> 
> GeÃ§miÅŸte Ã§alÄ±ÅŸtÄ±ÄŸÄ±m projelerin Ã§oÄŸunda zamanÄ±mÄ±n bÃ¼yÃ¼k kÄ±smÄ± bu iki aktiviteye harcandÄ±.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? Olduysa nasÄ±l?**
> 
> Makine Ã¶ÄŸrenmesinde Ã¶ÄŸrendiÄŸim ÅŸeylerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸu Kaggleâ€™dan geldi. Topluluk, platform ve iÃ§erik gerÃ§ekten paha biÃ§ilemez; Ã¶ÄŸrenilecek inanÄ±lmaz miktarda bilgi var.
> 
> Kaggle yarÄ±ÅŸmalarÄ±na katÄ±lmak, sorunlarÄ± anlamak, yapÄ±landÄ±rmak ve Ã§Ã¶zmek konusunda bana bÃ¼yÃ¼k gÃ¼ven kazandÄ±rdÄ±. Bu deneyimi, Kaggle dÄ±ÅŸÄ±nda Ã§alÄ±ÅŸtÄ±ÄŸÄ±m ÅŸirketler ve projelerde baÅŸarÄ±yla uygulayabildim.
> 
> BirÃ§ok iÅŸe alÄ±m gÃ¶revlisi, Kaggleâ€™daki baÅŸarÄ±larÄ±mÄ± (Ã¶zellikle yarÄ±ÅŸmalarda) gÃ¶rerek benimle iletiÅŸime geÃ§ti. Bu, adayÄ±n veri bilimi problemlerini Ã§Ã¶zme yeteneÄŸini gÃ¶steren iyi bir gÃ¶stergedir ve yeteneklerinizi sergilemek ve portfÃ¶y oluÅŸturmak iÃ§in harika bir platformdur.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar oldu mu?**
> 
> Her yarÄ±ÅŸmada bazÄ± hatalar yaptÄ±m! BÃ¶ylece Ã¶ÄŸrenip geliÅŸiyorsunuz. Bazen bir kod hatasÄ±, bazen yanlÄ±ÅŸ bir doÄŸrulama kurulumu, bazen de yanlÄ±ÅŸ bir gÃ¶nderim seÃ§imi olabiliyor.
> 
> Ã–nemli olan bu hatalardan ders almak ve tekrar etmemeyi saÄŸlamaktÄ±r. Bu sÃ¼reci tekrar etmek, Kaggleâ€™daki genel performansÄ±nÄ±zÄ± otomatik olarak artÄ±rÄ±r.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> HiÃ§bir teknolojiye â€œbaÄŸlanmamakâ€ gerektiÄŸine inanÄ±yorum. En iyi Ã§alÄ±ÅŸan, en rahat ve en etkili olanÄ± kullanÄ±n, ama sÃ¼rekli olarak yeni araÃ§lar ve kÃ¼tÃ¼phaneler Ã¶ÄŸrenmeye aÃ§Ä±k olun.

### Metrics for regression (standard and ordinal) *(Regresyon iÃ§in metrikler - standart ve sÄ±ralÄ±)*

Regresyon problemleriyle Ã§alÄ±ÅŸÄ±rken, yani sÃ¼rekli bir deÄŸeri tahmin etmeyi gerektiren (eksi sonsuzdan artÄ± sonsuza kadar deÄŸiÅŸebilen) problemlerle uÄŸraÅŸÄ±rken, en yaygÄ±n kullanÄ±lan hata Ã¶lÃ§Ã¼leri RMSE (karekÃ¶k ortalama kare hata) ve MAE (ortalama mutlak hata) yÃ¶ntemleridir. Ancak, RMSLE veya MCRMSLE gibi biraz farklÄ± hata Ã¶lÃ§Ã¼leri de faydalÄ± olabilir.

#### Mean squared error (MSE) and RÂ² *(Ortalama kare hata (MSE) ve RÂ²)*

KarekÃ¶k ortalama kare hata (RMSE), ortalama kare hatanÄ±n (MSE) karekÃ¶kÃ¼dÃ¼r. MSE, aslÄ±nda regresyon Ã§alÄ±ÅŸmasÄ±nÄ± Ã¶ÄŸrenirken tanÄ±ÅŸtÄ±ÄŸÄ±nÄ±z eski iyi hata kareleri toplamÄ±nÄ±n (SSE) ortalamasÄ±ndan baÅŸka bir ÅŸey deÄŸildir.

**MSE formÃ¼lÃ¼ ÅŸu ÅŸekildedir:**

$$
MSE = \frac{1}{n} \sum_{i=1}^{n} (\hat{y_i} - y_i)^2
$$

FormÃ¼lÃ¼n iÅŸleyiÅŸini aÃ§Ä±klayalÄ±m:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.
* Ã–nce tahminler ile gerÃ§ek deÄŸerler arasÄ±ndaki farkÄ± alÄ±rsÄ±nÄ±z.
* FarklarÄ± kareye alÄ±rsÄ±nÄ±z (pozitif ya da sÄ±fÄ±r olur).
* TÃ¼m kareleri toplarsÄ±nÄ±z; iÅŸte bu sizin SSEâ€™nizdir.
* Son olarak, SSEâ€™yi tahmin sayÄ±sÄ±na bÃ¶lerek ortalama deÄŸeri (MSE) elde edersiniz.

Genellikle tÃ¼m regresyon modelleri SSEâ€™yi minimize eder, bu yÃ¼zden MSEâ€™yi veya MSEâ€™den tÃ¼retilmiÅŸ RÂ² (determinasyon katsayÄ±sÄ±) gibi metrikleri minimize etmekte bÃ¼yÃ¼k sorun yaÅŸamazsÄ±nÄ±z. RÂ² ÅŸÃ¶yle hesaplanÄ±r:

$$
R^2 = 1 - \frac{\sum_{i=1}^{n} (\hat{y_i} - y_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

Burada SSE (hata kareleri toplamÄ±), toplam kareler toplamÄ±na (SST) karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r. SST, aslÄ±nda hedef deÄŸiÅŸkenin varyansÄ±dÄ±r ve ÅŸu ÅŸekilde tanÄ±mlanÄ±r:

$$
SST = \sum_{i=1}^{n} (y_i - \bar{y})^2
$$

BaÅŸka bir deyiÅŸle, RÂ² modelin hata karelerini, en basit model olan hedefin ortalamasÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±r. SSE ve SST aynÄ± Ã¶lÃ§eÄŸe sahip olduÄŸu iÃ§in RÂ², hedef deÄŸiÅŸkeni dÃ¶nÃ¼ÅŸtÃ¼rmenin tahminleri iyileÅŸtirip iyileÅŸtirmediÄŸini anlamanÄ±za yardÄ±mcÄ± olabilir.

> UnutmayÄ±n: min-max Ã¶lÃ§ekleme veya standardizasyon gibi lineer dÃ¶nÃ¼ÅŸÃ¼mler, herhangi bir regresyon modelinin performansÄ±nÄ± deÄŸiÅŸtirmez; Ã§Ã¼nkÃ¼ bunlar hedefin lineer dÃ¶nÃ¼ÅŸÃ¼mÃ¼dÃ¼r. Ancak karekÃ¶k, kÃ¼p kÃ¶k, logaritma, Ã¼s alma gibi **lineer olmayan dÃ¶nÃ¼ÅŸÃ¼mler** ve bunlarÄ±n kombinasyonlarÄ±, regresyon modelinizin deÄŸerlendirme metriÄŸi Ã¼zerindeki performansÄ±nÄ± kesinlikle deÄŸiÅŸtirebilir (doÄŸru dÃ¶nÃ¼ÅŸÃ¼mÃ¼ seÃ§erseniz genellikle daha iyi olur).

MSE, aynÄ± probleme uygulanan regresyon modellerini karÅŸÄ±laÅŸtÄ±rmak iÃ§in mÃ¼kemmel bir araÃ§tÄ±r. Ancak kÃ¶tÃ¼ haber ÅŸu ki, Kaggle yarÄ±ÅŸmalarÄ±nda genellikle MSE kullanÄ±lmaz; RMSE tercih edilir. Ã‡Ã¼nkÃ¼ MSEâ€™nin karekÃ¶kÃ¼nÃ¼ almak, deÄŸerleri hedefin orijinal Ã¶lÃ§eÄŸine yaklaÅŸtÄ±rÄ±r ve modelinizin performansÄ±nÄ± gÃ¶zle kontrol etmek kolaylaÅŸÄ±r. AyrÄ±ca, farklÄ± veri problemleri veya yarÄ±ÅŸmalar arasÄ±nda aynÄ± regresyon modelini deÄŸerlendiriyorsanÄ±z, RÂ² daha kullanÄ±ÅŸlÄ±dÄ±r; Ã§Ã¼nkÃ¼ MSE ile tamamen iliÅŸkili olup 0 ile 1 arasÄ±nda deÄŸer alÄ±r ve tÃ¼m karÅŸÄ±laÅŸtÄ±rmalarÄ± kolaylaÅŸtÄ±rÄ±r.

#### Root mean squared error (RMSE) *(KÃ¶k ortalama kare hata (RMSE))*

RMSE (KarekÃ¶k Ortalama Kare Hata), MSEâ€™nin karekÃ¶kÃ¼ olmakla birlikte bazÄ± ince farklÄ±lÄ±klar ortaya Ã§Ä±kar. FormÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\hat{y_i} - y_i)^2}
$$

Bu formÃ¼lde:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.

MSEâ€™de, bÃ¼yÃ¼k tahmin hatalarÄ± kare alma iÅŸlemi nedeniyle Ã§ok fazla cezalandÄ±rÄ±lÄ±r. RMSEâ€™de ise bu etki karekÃ¶k sayesinde biraz azaltÄ±lÄ±r. Ancak yine de uÃ§ deÄŸerler (outlier) performansÄ± ciddi ÅŸekilde etkileyebilir; MSE veya RMSE ile deÄŸerlendiriyor olmanÄ±z fark etmez.

SonuÃ§ olarak, probleme baÄŸlÄ± olarak, MSEâ€™yi hedef fonksiyonu olarak kullanan bir algoritmayla daha iyi bir uyum elde edebilirsiniz. Bunun iÃ§in Ã¶nce hedef deÄŸiÅŸkenin karekÃ¶kÃ¼nÃ¼ almak (pozitif deÄŸerler gerektirir), ardÄ±ndan sonuÃ§larÄ± kareye almak iÅŸe yarayabilir. Scikit-learnâ€™daki **TransformedTargetRegressor** gibi fonksiyonlar, regresyon hedefinizi uygun ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rmenize yardÄ±mcÄ± olarak deÄŸerlendirme metriÄŸinize gÃ¶re daha iyi uyumlu sonuÃ§lar almanÄ±zÄ± saÄŸlar.

> Son zamanlarda RMSEâ€™nin kullanÄ±ldÄ±ÄŸÄ± bazÄ± yarÄ±ÅŸmalar ÅŸunlardÄ±r:
> 
> 
> 
> * **Avito Demand Prediction Challenge**: [Kaggle linki](https://www.kaggle.com/c/avitodemand-prediction)
> 
> * **Google Analytics Customer Revenue Prediction**: [Kaggle linki](https://www.kaggle.com/c/ga-customer-revenue-prediction)
> 
> * **Elo Merchant Category Recommendation**: [Kaggle linki](https://www.kaggle.com/c/elo-merchant-category-recommendation)

#### Root mean squared log error (RMSLE) *(KÃ¶k ortalama log kare hata (RMSLE))*

MSEâ€™nin bir diÄŸer yaygÄ±n dÃ¶nÃ¼ÅŸÃ¼mÃ¼, **karekÃ¶k ortalama log hatasÄ± (RMSLE)**â€™dir. **MCRMSLE**, COVID-19 tahmin yarÄ±ÅŸmalarÄ±nda popÃ¼ler olan bir varyanttÄ±r ve birden fazla hedef deÄŸiÅŸken olduÄŸunda her bir hedefin RMSLE deÄŸerlerinin sÃ¼tun bazÄ±nda ortalamasÄ±nÄ± alÄ±r.

RMSLE formÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
RMSLE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (\log(\hat{y_i}+1) - \log(y_i+1))^2}
$$

FormÃ¼lde:

* (n) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir.
* (y_i) gerÃ§ek deÄŸer (ground truth), (\hat{y_i}) ise modelin tahminidir.

Logaritmik dÃ¶nÃ¼ÅŸÃ¼m, tahminlerinize ve gerÃ§ek deÄŸerlere uygulanÄ±r; ardÄ±ndan kare alma, ortalama alma ve karekÃ¶k iÅŸlemleri yapÄ±lÄ±r. Bu sayede, Ã¶zellikle bÃ¼yÃ¼k deÄŸerler iÃ§in tahmin edilen ve gerÃ§ek deÄŸerler arasÄ±ndaki bÃ¼yÃ¼k farklar Ã§ok fazla cezalandÄ±rÄ±lmaz. Yani RMSLE kullanÄ±rken en Ã§ok Ã¶nem verdiÄŸiniz ÅŸey, tahminlerinizin Ã¶lÃ§eÄŸinin gerÃ§ek deÄŸerlerin Ã¶lÃ§eÄŸiyle ne kadar uyumlu olduÄŸudur.

RMSEâ€™de olduÄŸu gibi, regresyon algoritmalarÄ± RMSLEâ€™yi daha iyi optimize edebilir. Bunun iÃ§in hedef deÄŸiÅŸkene logaritmik dÃ¶nÃ¼ÅŸÃ¼m uygulayÄ±p modeli eÄŸitmek ve ardÄ±ndan ters dÃ¶nÃ¼ÅŸÃ¼m olarak Ã¼stel fonksiyonu kullanmak gerekir.

> Son dÃ¶nemde RMSLE kullanÄ±lan bazÄ± Kaggle yarÄ±ÅŸmalarÄ±:
> 
> 
> 
> * **ASHRAE - Great Energy Predictor III**: [Kaggle linki](https://www.kaggle.com/c/ashrae-energy-prediction)
> 
> * **Santander Value Prediction Challenge**: [Kaggle linki](https://www.kaggle.com/c/santander-value-prediction-challenge)
> 
> * **Mercari Price Suggestion Challenge**: [Kaggle linki](https://www.kaggle.com/c/mercari-price-suggestion-challenge)
> 
> * **Sberbank Russian Housing Market**: [Kaggle linki](https://www.kaggle.com/olgabelitskaya/sberbank-russian-housing-market)
> 
> * **Recruit Restaurant Visitor Forecasting**: [Kaggle linki](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting)

Åu anda, Kaggle yarÄ±ÅŸmalarÄ±nda regresyon iÃ§in en yaygÄ±n kullanÄ±lan deÄŸerlendirme metriÄŸi **RMSLE**â€™dir.

#### Mean absolute error (MAE) *(Ortalama mutlak hata (MAE))*

**MAE (Mean Absolute Error â€“ Ortalama Mutlak Hata)**, tahminler ile gerÃ§ek deÄŸerler arasÄ±ndaki farkÄ±n **mutlak deÄŸerini** alÄ±r. FormÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
MAE = \frac{1}{n} \sum_{i=1}^{n} |\hat{y_i} - y_i|
$$

FormÃ¼lde:

* ($n$) gÃ¶zlem sayÄ±sÄ±nÄ± gÃ¶sterir,
* ($y_i$) gerÃ§ek deÄŸer (ground truth),
* ($\hat{y_i}$) modelin tahminidir.

**Ã–zellikleri ve avantajlarÄ±:**

* MAE, **outlierâ€™lara (aykÄ±rÄ± deÄŸerlere) karÅŸÄ± duyarlÄ± deÄŸildir**, Ã§Ã¼nkÃ¼ hatalar karelenmez. Bu nedenle outlier iÃ§eren veri setlerinde MAE sÄ±klÄ±kla tercih edilen bir deÄŸerlendirme metriÄŸidir.
* BirÃ§ok algoritma, MAEâ€™yi doÄŸrudan **objective function** olarak kullanabilir. EÄŸer algoritma bunu doÄŸrudan desteklemiyorsa, hedef deÄŸiÅŸkene karekÃ¶k uygulayÄ±p ardÄ±ndan tahminleri karesini alarak dolaylÄ± optimizasyon yapÄ±labilir.

**DezavantajlarÄ±:**

* MAE ile optimize etmek, daha yavaÅŸ **convergence** (yakÄ±nsama) saÄŸlar. Bunun nedeni, MAE ile aslÄ±nda hedefin ortalamasÄ± yerine **medyanÄ±nÄ±** tahmin etmeye Ã§alÄ±ÅŸmanÄ±zdÄ±r (L1 normu). Oysa MSE ile optimize edildiÄŸinde hedefin ortalamasÄ± (L2 normu) minimize edilir.
* Bu durum optimizasyon sÃ¼recini daha karmaÅŸÄ±k hale getirir ve eÄŸitim sÃ¼resi, gÃ¶zlem sayÄ±sÄ±na baÄŸlÄ± olarak Ã¼stel biÃ§imde artabilir. Ã–rneÄŸin, MAE kriteri ile bir Random Forest regressor eÄŸitmek, MSE kriterine gÃ¶re Ã§ok daha yavaÅŸ olabilir ([Stack Overflow Ã¶rneÄŸi](https://stackoverflow.com/questions/57243267/why-is-training-a-random-forest-regressor-with-mae-criterion-so-slow-compared-to)).

> **MAE kullanÄ±lan Ã¶nemli yarÄ±ÅŸmalar:**
> 
> 
> 
> * **LANL Earthquake Prediction**: [Kaggle linki](https://www.kaggle.com/c/LANL-Earthquake-Prediction)
> 
> * **How Much Did It Rain? II**: [Kaggle linki](https://www.kaggle.com/c/how-much-did-it-rain-ii)

Tahmin yarÄ±ÅŸmalarÄ±nda (forecasting competitions), kullanÄ±lan regresyon Ã¶lÃ§Ã¼tleri bÃ¼yÃ¼k Ã¶lÃ§Ã¼de benzerdir. Ã–rneÄŸin:

* **M5 Forecasting Competition**: [Link](https://mofc.unic.ac.cy/m5-competition/)
* DiÄŸer M serisi yarÄ±ÅŸmalar: [Hyndsight Ã¶zetleri](https://robjhyndman.com/hyndsight/forecasting-competitions/)

Forecasting yarÄ±ÅŸmalarÄ±nda bazen daha Ã¶zel Ã¶lÃ§Ã¼tler de kullanÄ±lÄ±r, Ã¶rneÄŸin:

* **Weighted Root Mean Squared Scaled Error (WRMSSE)**: [Kaggle linki](https://www.kaggle.com/c/m5-forecasting-accuracy/overview/evaluation)
* **Symmetric Mean Absolute Percentage Error (sMAPE)**: [Kaggle linki](https://www.kaggle.com/c/demand-forecasting-kernels-only/overview/evaluation)

Ancak, temel olarak bunlar RMSE veya MAEâ€™nin varyasyonlarÄ±dÄ±r ve doÄŸru hedef dÃ¶nÃ¼ÅŸÃ¼mleri ile yÃ¶netilebilirler.

### Metrics for classification (label prediction and probability) *(SÄ±nÄ±flandÄ±rma metrikleri - etiket tahmini ve olasÄ±lÄ±k)*

Regresyon problemleri iÃ§in metrikleri tartÄ±ÅŸtÄ±ktan sonra, ÅŸimdi sÄ±nÄ±flandÄ±rma problemleri iÃ§in metrikleri aÃ§Ä±klamaya geÃ§iyoruz; Ã¶nce ikili sÄ±nÄ±flandÄ±rma problemlerinden baÅŸlÄ±yoruz (iki sÄ±nÄ±ftan birini tahmin etmeniz gerektiÄŸinde), sonra Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmaya (iki sÄ±nÄ±ftan fazla olduÄŸunda) ve en sonunda Ã§ok etiketli sÄ±nÄ±flandÄ±rmaya (sÄ±nÄ±flarÄ±n birbirinin Ã¼zerine bindiÄŸi durumlarda).

#### Accuracy *(DoÄŸruluk)*

Ä°kili bir sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n performansÄ±nÄ± analiz ederken, en yaygÄ±n ve eriÅŸilebilir metrik **doÄŸruluk (accuracy)** olarak kullanÄ±lÄ±r. **YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma hatasÄ±**, modelinizin bir Ã¶rnek iÃ§in yanlÄ±ÅŸ sÄ±nÄ±fÄ± tahmin etmesi durumudur. DoÄŸruluk ise yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma hatasÄ±nÄ±n tamamlayÄ±cÄ±sÄ±dÄ±r ve doÄŸru tahmin edilen Ã¶rneklerin sayÄ±sÄ±nÄ±n toplam tahmin sayÄ±sÄ±na bÃ¶lÃ¼nmesiyle hesaplanabilir:

$$
\text{Accuracy} = \frac{\text{Correct Answers}}{\text{Total Answers}}
$$

> Bu metrik, Ã¶rneÄŸin **Cassava Leaf Disease Classification** ([https://www.kaggle.com/c/cassava-leaf-disease-classification](https://www.kaggle.com/c/cassava-leaf-disease-classification)) ve **Text Normalization Challenge - English Language** ([https://www.kaggle.com/c/text-normalization-challenge-english-language](https://www.kaggle.com/c/text-normalization-challenge-english-language)) gibi yarÄ±ÅŸmalarda kullanÄ±lmÄ±ÅŸtÄ±r. Bu yarÄ±ÅŸmalarda doÄŸru bir tahmin, yalnÄ±zca tahmin edilen metin gerÃ§ek metinle tamamen eÅŸleÅŸtiÄŸinde sayÄ±lmÄ±ÅŸtÄ±r.

Bir metrik olarak doÄŸruluk, modelin gerÃ§ek dÃ¼nyadaki etkili performansÄ±na gÃ¼Ã§lÃ¼ bir ÅŸekilde odaklanÄ±r; modelin beklendiÄŸi gibi Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± gÃ¶sterir. Ancak, eÄŸer amacÄ±nÄ±z modeli deÄŸerlendirmek, karÅŸÄ±laÅŸtÄ±rmak ve yaklaÅŸÄ±mÄ±nÄ±zÄ±n gerÃ§ekten ne kadar etkili olduÄŸunu net bir ÅŸekilde gÃ¶rmekse, doÄŸruluÄŸu kullanÄ±rken dikkatli olmanÄ±z gerekir. Ã‡Ã¼nkÃ¼ sÄ±nÄ±flar **dengesiz** olduÄŸunda (farklÄ± frekanslara sahip olduÄŸunda) yanlÄ±ÅŸ sonuÃ§lara yol aÃ§abilir. Ã–rneÄŸin, bir sÄ±nÄ±f verinin yalnÄ±zca %10â€™unu oluÅŸturuyorsa, yalnÄ±zca Ã§oÄŸunluk sÄ±nÄ±fÄ±nÄ± tahmin eden bir model %90 doÄŸruluk gÃ¶sterebilir; yÃ¼ksek doÄŸruluk gÃ¶rÃ¼nmesine raÄŸmen oldukÃ§a iÅŸe yaramaz olur.

BÃ¶yle bir problemi nasÄ±l fark edebilirsiniz? Bunu **karÄ±ÅŸÄ±klÄ±k matrisi (confusion matrix)** kullanarak kolayca gÃ¶rebilirsiniz. KarÄ±ÅŸÄ±klÄ±k matrisinde, gerÃ§ek sÄ±nÄ±flar satÄ±rlara, tahmin edilen sÄ±nÄ±flar sÃ¼tunlara yerleÅŸtirilerek iki yÃ¶nlÃ¼ bir tablo oluÅŸturulur. Scikit-learnâ€™Ã¼n **confusion_matrix** fonksiyonu ile basitÃ§e oluÅŸturabilirsiniz:

```python
sklearn.metrics.confusion_matrix(
    y_true, y_pred, *, labels=None, sample_weight=None,
    normalize=None
)
```

Sadece **y_true** ve **y_pred** vektÃ¶rlerini saÄŸlamak anlamlÄ± bir tablo oluÅŸturmak iÃ§in yeterlidir, fakat satÄ±r/sÃ¼tun etiketleri, Ã¶rnekler iÃ§in aÄŸÄ±rlÄ±klar ve normalize etme seÃ§enekleri de eklenebilir. Normalize iÅŸlemi, gerÃ§ek Ã¶rnekler (satÄ±rlar), tahmin edilen Ã¶rnekler (sÃ¼tunlar) veya tÃ¼m Ã¶rnekler Ã¼zerinde yapÄ±labilir.

MÃ¼kemmel bir sÄ±nÄ±flandÄ±rÄ±cÄ±, tÃ¼m Ã¶rnekleri matrisin ana kÃ¶ÅŸegeninde toplar. EÄŸer kÃ¶ÅŸegendeki hÃ¼crelerde Ã§ok az veya hiÃ§ Ã¶rnek yoksa, bu durum tahminleyicinin geÃ§erliliÄŸiyle ilgili ciddi sorunlarÄ± gÃ¶sterir.

NasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha iyi anlamak iÃ§in Scikit-learn tarafÄ±ndan sunulan grafiksel Ã¶rneÄŸi inceleyebilirsiniz:
[Scikit-learn plot_confusion_matrix Ã¶rneÄŸi](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)

![](im/1043.png)

DoÄŸruluÄŸun kullanÄ±labilirliÄŸini artÄ±rmak iÃ§in, her sÄ±nÄ±fa gÃ¶re doÄŸruluÄŸu dikkate alÄ±p bunlarÄ±n ortalamasÄ±nÄ± almayÄ± deneyebilirsiniz; ancak, **precision (kesinlik)**, **recall (duyarlÄ±lÄ±k)** ve **F1-score** gibi diÄŸer metriklere gÃ¼venmek genellikle daha faydalÄ± olacaktÄ±r.

#### Precision and recall *(Kesinlik ve duyarlÄ±lÄ±k)*

Precision ve recall metriklerini elde etmek iÃ§in yine **karÄ±ÅŸÄ±klÄ±k matrisinden (confusion matrix)** baÅŸlÄ±yoruz. Ã–ncelikle, matrisin her bir hÃ¼cresine isim vermemiz gerekiyor:

![](im/1044.png)

Ä°ÅŸte hÃ¼crelerin nasÄ±l tanÄ±mlandÄ±ÄŸÄ±:

* **True Positive (TP)**: Bu hÃ¼cre, doÄŸru bir ÅŸekilde pozitif olarak tahmin edilen Ã¶rnekleri iÃ§erir. Yani, modelin doÄŸru bir ÅŸekilde pozitif sÄ±nÄ±fÄ± tahmin ettiÄŸi durumlar.
* **False Positive (FP)**: Bu hÃ¼cre, aslÄ±nda negatif olan ancak model tarafÄ±ndan pozitif olarak tahmin edilen Ã¶rnekleri iÃ§erir.
* **False Negative (FN)**: Bu hÃ¼cre, aslÄ±nda pozitif olan ancak model tarafÄ±ndan negatif olarak tahmin edilen Ã¶rnekleri iÃ§erir.
* **True Negative (TN)**: Bu hÃ¼cre, doÄŸru bir ÅŸekilde negatif olarak tahmin edilen Ã¶rnekleri iÃ§erir. Yani, modelin doÄŸru bir ÅŸekilde negatif sÄ±nÄ±fÄ± tahmin ettiÄŸi durumlar.

Bu hÃ¼creleri kullanarak, sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±zÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ± hakkÄ±nda daha hassas bilgiler elde edebilir ve modelinizi daha iyi ayarlayabilirsiniz. Ä°lk olarak, doÄŸruluk formÃ¼lÃ¼nÃ¼ kolayca gÃ¶zden geÃ§irebiliriz:

**DoÄŸruluk (Accuracy) FormÃ¼lÃ¼**
$$ \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} $$

ArdÄ±ndan, ilk Ã¶nemli metrik **precision (kesinlik)** veya **specificity (Ã¶zgÃ¼llÃ¼k)** olarak adlandÄ±rÄ±lÄ±r ve aslÄ±nda pozitif vakalarÄ±n doÄŸruluÄŸunu Ã¶lÃ§er:

**Kesinlik (Precision) FormÃ¼lÃ¼**
$$ \text{Precision} = \frac{TP}{TP + FP} $$

Hesaplamada sadece **true positives (TP)** ve **false positives (FP)** sayÄ±larÄ± dikkate alÄ±nÄ±r. Temelde, bu metrik, modelin pozitif tahminlerde ne kadar doÄŸru olduÄŸunu gÃ¶sterir. AÃ§Ä±kÃ§a, modeliniz yalnÄ±zca yÃ¼ksek gÃ¼vene sahip olduÄŸu Ã¶rneklerde pozitif tahmin yaparak yÃ¼ksek skorlar alabilir. Bu Ã¶lÃ§Ã¼mÃ¼n amacÄ± da aslÄ±nda ÅŸudur: Modeli, yalnÄ±zca kesin olduÄŸunda ve bunu yapmak gÃ¼venliyse pozitif sÄ±nÄ±fÄ± tahmin etmeye zorlamak.

Ancak, eÄŸer amacÄ±nÄ±z mÃ¼mkÃ¼n olduÄŸunca fazla pozitif tahmin yapmaksa, o zaman **recall (duyarlÄ±lÄ±k)** veya **coverage (kapsama)** veya **sensitivity (hassasiyet)** ya da **true positive rate (doÄŸru pozitif oranÄ±)** metriklerini de takip etmeniz gerekir:

**DuyarlÄ±lÄ±k (Recall) FormÃ¼lÃ¼**
$$ \text{Recall} = \frac{TP}{TP + FN} $$

Burada, **false negatives (FN)** hakkÄ±nda da bilgi sahibi olmanÄ±z gerekecek. Bu iki metriÄŸin ilginÃ§ olan yanÄ±, Ã¶rneklerin sÄ±nÄ±flandÄ±rÄ±lmasÄ±na dayalÄ± olmalarÄ±dÄ±r ve bir sÄ±nÄ±flandÄ±rma aslÄ±nda olasÄ±lÄ±ÄŸa dayanÄ±r (bu genellikle pozitif ve negatif sÄ±nÄ±f arasÄ±ndaki 0.5 eÅŸiÄŸiyle belirlenir). Bu eÅŸiÄŸi deÄŸiÅŸtirdiÄŸinizde, bir metriÄŸi diÄŸerinin pahasÄ±na iyileÅŸtirebilirsiniz. Ã–rneÄŸin, eÅŸiÄŸi arttÄ±rÄ±rsanÄ±z, daha yÃ¼ksek **precision** (kesinlik) elde edersiniz (sÄ±nÄ±flandÄ±rÄ±cÄ± daha gÃ¼venlidir) ancak **recall** azalÄ±r. EÅŸiÄŸi dÃ¼ÅŸÃ¼rÃ¼rseniz, daha dÃ¼ÅŸÃ¼k **precision** ancak daha yÃ¼ksek **recall** elde edersiniz. Bu, **precision/recall trade-off (kesinlik/duyarlÄ±lÄ±k dengesi)** olarak bilinir.

Scikit-learn sitesi, bu dengeyi anlamanÄ±zÄ± saÄŸlayacak pratik bir bakÄ±ÅŸ aÃ§Ä±sÄ± sunar ([https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)), burada **precision/recall** eÄŸrisini izleyebilir ve bu iki metriÄŸin nasÄ±l deÄŸiÅŸtirilebileceÄŸini anlayarak ihtiyaÃ§larÄ±nÄ±za daha uygun bir sonuÃ§ elde edebilirsiniz.

![](im/1045.png)

**Precision/Recall dengesine** baÄŸlÄ± bir metrik de **ortalama kesinlik (average precision)**'tir. Ortalama kesinlik, **recall** deÄŸerleri 0'dan 1'e kadar olan bir aralÄ±kta (temelde eÅŸiÄŸi 1'den 0'a deÄŸiÅŸtirirken) hesaplanan ortalama kesinliÄŸi ifade eder. Ortalama kesinlik, Ã¶zellikle **nesne tespiti** ile ilgili gÃ¶revlerde oldukÃ§a popÃ¼lerdir ve bu konuyu biraz sonra tartÄ±ÅŸacaÄŸÄ±z, ancak aynÄ± zamanda **tablo verisiyle yapÄ±lan sÄ±nÄ±flandÄ±rma** iÃ§in de oldukÃ§a faydalÄ±dÄ±r.

Pratikte, **ortalama kesinlik**, model performansÄ±nÄ± Ã§ok nadir bir sÄ±nÄ±f Ã¼zerinde daha hassas ve doÄŸru bir ÅŸekilde izlemek istediÄŸinizde deÄŸerli bir metrik haline gelir. Bu, genellikle **dolandÄ±rÄ±cÄ±lÄ±k tespiti** gibi dengesiz veri setlerinde karÅŸÄ±laÅŸÄ±lan bir durumdur.

Bu konuda daha spesifik bilgiler iÃ§in Gael Varoquaux'nin tartÄ±ÅŸmasÄ±nÄ± okuyabilirsiniz:
[Gael Varoquaux'nin tartÄ±ÅŸmasÄ±](http://gael-varoquaux.info/interpreting_ml_tuto/content/01_how_well/01_metrics.html#average-precision).

#### The F1 score *(F1 skoru)*

Bu noktada, **kesinlik** (precision) veya **duyarlÄ±lÄ±k** (recall) gibi metriklerin bir deÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼ olarak ideal bir seÃ§im olmadÄ±ÄŸÄ±nÄ± muhtemelen fark etmiÅŸsinizdir, Ã§Ã¼nkÃ¼ birini optimize ettiÄŸinizde diÄŸeri pahasÄ±na olur. Bu nedenle, yalnÄ±zca bir metrik kullanarak yapÄ±lan Kaggle yarÄ±ÅŸmalarÄ± yoktur. Bu metrikleri birleÅŸtirmeniz gerekir (Ã¶rneÄŸin, **ortalama kesinlik** gibi). **F1 skoru**, kesinlik ve duyarlÄ±lÄ±ÄŸÄ±n harmonik ortalamasÄ± olarak, genellikle en iyi Ã§Ã¶zÃ¼m olarak kabul edilir:

**F1 Skoru FormÃ¼lÃ¼:**
$$ \text{F1} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} $$

EÄŸer yÃ¼ksek bir **F1 skoru** elde ediyorsanÄ±z, bu modelinizin **kesinlik** veya **duyarlÄ±lÄ±k** veya her ikisinde birden geliÅŸme gÃ¶sterdiÄŸi anlamÄ±na gelir. Bu metriÄŸin kullanÄ±mÄ±na gÃ¼zel bir Ã¶rnek, **Quora Insincere Questions Classification** yarÄ±ÅŸmasÄ±nda gÃ¶rÃ¼lebilir:
[Quora Insincere Questions Classification YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/quora-insincere-questions-classification).

BazÄ± yarÄ±ÅŸmalarda, **F-beta skoru** da kullanÄ±lÄ±r. Bu, kesinlik ve duyarlÄ±lÄ±ÄŸÄ±n aÄŸÄ±rlÄ±klÄ± harmonik ortalamasÄ±dÄ±r ve **beta** deÄŸeri, **recall**'in birleÅŸik skordaki aÄŸÄ±rlÄ±ÄŸÄ±nÄ± belirler:

**F-beta Skoru FormÃ¼lÃ¼:**
$$ \text{F}_\beta = \frac{(1 + \beta^2) \times (\text{Precision} \times \text{Recall})}{\beta^2 \times \text{Precision} + \text{Recall}} $$

Burada, **beta** parametresi, recall'un nasÄ±l aÄŸÄ±rlÄ±klÄ± olarak deÄŸerlendirileceÄŸini belirler. **F1 skoru**, **beta = 1** olduÄŸunda, yani **kesinlik** ve **duyarlÄ±lÄ±k** eÅŸit derecede Ã¶nemli kabul edildiÄŸinde elde edilir.

Åimdi, **eÅŸik** (threshold) ve **sÄ±nÄ±flandÄ±rma olasÄ±lÄ±ÄŸÄ±** kavramlarÄ±nÄ± zaten tanÄ±ttÄ±ÄŸÄ±mÄ±za gÃ¶re, yaygÄ±n kullanÄ±lan diÄŸer iki sÄ±nÄ±flandÄ±rma metriÄŸi olan **log loss** ve **ROC-AUC**'yi de tartÄ±ÅŸabiliriz.

#### Log loss and ROC-AUC *(Log kaybÄ± ve ROC-AUC)*

**Log Loss** ile baÅŸlayalÄ±m, ki bu derin Ã¶ÄŸrenme modellerinde **cross-entropy** (Ã§apraz entropi) olarak da bilinir. **Log loss**, tahmin edilen olasÄ±lÄ±k ile gerÃ§ek (ground truth) olasÄ±lÄ±k arasÄ±ndaki farkÄ± Ã¶lÃ§er:

**Log Loss FormÃ¼lÃ¼:**
$$ L = \sum_{i=1}^{n} \left[ y_i \cdot \log(\hat{y_i}) + (1 - y_i) \cdot \log(1 - \hat{y_i}) \right] $$

Burada, ( n ) Ã¶rnek sayÄ±sÄ±nÄ±, ( y_i ) ith Ã¶rneÄŸin gerÃ§ek etiketini (0 veya 1) ve ( \hat{y_i} ) ise modelin ith Ã¶rnek iÃ§in tahmin ettiÄŸi olasÄ±lÄ±ÄŸÄ± temsil eder.

EÄŸer bir yarÄ±ÅŸma **log loss** kullanÄ±yorsa, bu, amacÄ±n bir Ã¶rneÄŸin pozitif sÄ±nÄ±fa ait olma olasÄ±lÄ±ÄŸÄ±nÄ± mÃ¼mkÃ¼n olduÄŸunca doÄŸru bir ÅŸekilde tahmin etmek olduÄŸu anlamÄ±na gelir. GerÃ§ekten de log loss, birÃ§ok yarÄ±ÅŸmada kullanÄ±lan bir metriktir.

Ã–rneÄŸin, **Deepfake Detection Challenge** ([https://www.kaggle.com/c/deepfake-detection-challenge](https://www.kaggle.com/c/deepfake-detection-challenge)) veya daha eski **Quora Question Pairs** ([https://www.kaggle.com/c/quora-question-pairs](https://www.kaggle.com/c/quora-question-pairs)) gibi yarÄ±ÅŸmalarda log loss metriÄŸini bulabilirsiniz.

**ROC (Receiver Operating Characteristic)** eÄŸrisi, bir ikili sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n performansÄ±nÄ± deÄŸerlendirmek ve birden fazla sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± karÅŸÄ±laÅŸtÄ±rmak iÃ§in kullanÄ±lan grafiksel bir diyagramdÄ±r. ROC-AUC metriÄŸi, bu eÄŸrinin altÄ±ndaki alanÄ± ifade eder. ROC eÄŸrisi, **true positive rate** (doÄŸru pozitif oranÄ±, yani recall) ile **false positive rate** (yanlÄ±ÅŸ pozitif oranÄ±, yani negatif Ã¶rneklerin pozitif olarak sÄ±nÄ±flandÄ±rÄ±lmasÄ± oranÄ±) arasÄ±ndaki iliÅŸkiyi gÃ¶sterir. AyrÄ±ca, doÄŸru negatif oranÄ±nÄ±n (negatif Ã¶rneklerin doÄŸru ÅŸekilde sÄ±nÄ±flandÄ±rÄ±lma oranÄ±) bir eksiÄŸi ile eÅŸdeÄŸerdir.

![](im/1046.png)

Ä°yi bir sÄ±nÄ±flandÄ±rÄ±cÄ±ya ait **ROC eÄŸrisi**, **false positive rate** (yanlÄ±ÅŸ pozitif oranÄ±) dÃ¼ÅŸÃ¼kken **true positive rate** (doÄŸru pozitif oranÄ±, yani recall) hÄ±zla artmalÄ±dÄ±r. **ROC-AUC** deÄŸeri 0.9 ile 1.0 arasÄ±nda olan bir model, Ã§ok iyi kabul edilir.

KÃ¶tÃ¼ bir sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ±, **ROC eÄŸrisinin**, yukarÄ±daki ÅŸekilde, yalnÄ±zca rastgele bir sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n performansÄ±nÄ± temsil eden diyagonal ile Ã§ok benzer veya aynÄ± olmasÄ±yla fark edebilirsiniz. **ROC-AUC** skorlarÄ± 0.5'e yakÄ±n olduÄŸunda, sonuÃ§lar neredeyse rastgele kabul edilir.

FarklÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± karÅŸÄ±laÅŸtÄ±rÄ±rken ve **AUC** kullanÄ±yorsanÄ±z, **daha yÃ¼ksek AUC** deÄŸeri olan sÄ±nÄ±flandÄ±rÄ±cÄ± daha performanslÄ±dÄ±r.

EÄŸer sÄ±nÄ±flar dengeliyse veya Ã§ok fazla dengesiz deÄŸilse, **AUC**'deki artÄ±ÅŸlar, eÄŸitimli modelin etkinliÄŸiyle orantÄ±lÄ±dÄ±r ve modelin **doÄŸru pozitifler** iÃ§in daha yÃ¼ksek olasÄ±lÄ±klar Ã¼retme yeteneÄŸi olarak dÃ¼ÅŸÃ¼nÃ¼lebilir. AyrÄ±ca, bu, Ã¶rnekleri pozitiften negatife doÄŸru daha dÃ¼zgÃ¼n sÄ±ralama yeteneÄŸi olarak da deÄŸerlendirilebilir. Ancak, pozitif sÄ±nÄ±f nadir olduÄŸunda, **AUC** baÅŸlangÄ±Ã§ta yÃ¼ksek olur ve artÄ±ÅŸlar, nadir sÄ±nÄ±fÄ± daha iyi tahmin etme aÃ§Ä±sÄ±ndan Ã§ok fazla ÅŸey ifade etmeyebilir. Bu durumda, daha Ã¶nce de belirttiÄŸimiz gibi, **ortalama kesinlik (average precision)** daha faydalÄ± bir metrik olabilir.

> Son zamanlarda, **AUC** birÃ§ok farklÄ± yarÄ±ÅŸmada kullanÄ±lmÄ±ÅŸtÄ±r. Bu Ã¼Ã§ yarÄ±ÅŸmaya gÃ¶z atmanÄ±zÄ± Ã¶neririz:
> 
> 
> 
> * **IEEE-CIS Fraud Detection**: [https://www.kaggle.com/c/ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection)
> 
> * **Riiid Answer Correctness Prediction**: [https://www.kaggle.com/c/riiid-test-answer-prediction](https://www.kaggle.com/c/riiid-test-answer-prediction)
> 
> * **Jigsaw Multilingual Toxic Comment Classification**: [https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification](https://www.kaggle.com/c/jigsaw-multilingual-toxic-comment-classification)

**AUC ve ortalama kesinlik arasÄ±ndaki iliÅŸkiyi** daha ayrÄ±ntÄ±lÄ± olarak aÃ§Ä±klayan bir makale iÃ§in ÅŸu kaynaÄŸa gÃ¶z atabilirsiniz:
Su, W., Yuan, Y., ve Zhu, M. "A relationship between the average precision and the area under the ROC curve." Proceedings of the 2015 International Conference on The Theory of Information Retrieval, 2015.

#### Matthews correlation coefficient (MCC) *(Matthews korelasyon katsayÄ±sÄ±)*

Binary sÄ±nÄ±flandÄ±rma metriklerinin sonuna yaklaÅŸÄ±rken, **Matthews korelasyon katsayÄ±sÄ±** (MCC) Ã¶nemli bir yere sahiptir. MCC, **VSB Power Line Fault Detection** ([https://www.kaggle.com/c/vsb-power-line-fault-detection](https://www.kaggle.com/c/vsb-power-line-fault-detection)) ve **Bosch Production Line Performance** ([https://www.kaggle.com/c/bosch-production-line-performance](https://www.kaggle.com/c/bosch-production-line-performance)) gibi yarÄ±ÅŸmalarda kullanÄ±lmÄ±ÅŸtÄ±r.

MCC formÃ¼lÃ¼ ÅŸu ÅŸekildedir:

$$
MCC = \frac{(TP \cdot TN) - (FP \cdot FN)}{\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}
$$

Burada **TP** true positives (doÄŸru pozitifler), **TN** true negatives (doÄŸru negatifler), **FP** false positives (yanlÄ±ÅŸ pozitifler) ve **FN** false negatives (yanlÄ±ÅŸ negatifler) temsil eder. Bu, **precision** ve **recall** ile ilgili Ã¶nceki aÃ§Ä±klamalarda gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z aynÄ± terminolojidir.

MCC, bir korelasyon katsayÄ±sÄ± gibi davranÄ±r ve +1 (mÃ¼kemmel tahmin) ile -1 (tersine tahmin) arasÄ±nda deÄŸiÅŸir. Bu metrik, Ã¶zellikle sÄ±nÄ±flar oldukÃ§a dengesiz olduÄŸunda bile sÄ±nÄ±flandÄ±rmanÄ±n kalitesini Ã¶lÃ§mek iÃ§in kullanÄ±labilir.

FormÃ¼lÃ¼n karmaÅŸÄ±klÄ±ÄŸÄ±na raÄŸmen, **Neuron Engineer** adlÄ± bir Kaggle kullanÄ±cÄ±sÄ±, bu metriÄŸin daha anlaÅŸÄ±lÄ±r bir formÃ¼lle yeniden yapÄ±landÄ±rÄ±lmasÄ±nÄ± saÄŸlamÄ±ÅŸtÄ±r. Neuron Engineer'in reformÃ¼le ettiÄŸi MCC ÅŸu ÅŸekildedir:

Ä°ÅŸte MCC (Matthews Korelasyon KatsayÄ±sÄ±) formÃ¼lÃ¼nÃ¼n basitleÅŸtirilmiÅŸ hali ve her bir bileÅŸenin aÃ§Ä±klamalarÄ±:

$$MCC = (Posprecision + Negprecision - 1) * PosNegRatio$$

FormÃ¼ldeki her bir eleman ÅŸudur:

* **Posprecision**: Pozitif sÄ±nÄ±fÄ±n kesinliÄŸi
  $$
  \text{Posprecision} = \frac{TP}{TP + FP}
  $$

* **Negprecision**: Negatif sÄ±nÄ±fÄ±n kesinliÄŸi
  $$
  \text{Negprecision} = \frac{TN}{TN + FN}
  $$

* **PosNegRatio**: Pozitif ve negatif tahmin oranÄ±
  $$
  \text{PosNegRatio} = \sqrt{\frac{\text{PosPredictionCount} \times \text{NegPredictionCount}}{\text{PosLabelCount} \times \text{NegLabelCount}}}
  $$

  Buradaki bileÅŸenler ÅŸunlardÄ±r:

  * **PosPredictionCount**: Pozitif sÄ±nÄ±f tahmin sayÄ±sÄ±
    $$
    \text{PosPredictionCount} = TP + FP
    $$

  * **NegPredictionCount**: Negatif sÄ±nÄ±f tahmin sayÄ±sÄ±
    $$
    \text{NegPredictionCount} = TN + FN
    $$

  * **PosLabelCount**: Pozitif etiket sayÄ±sÄ±
  * **NegLabelCount**: Negatif etiket sayÄ±sÄ±

Bu reformÃ¼lasyon, hem pozitif hem de negatif sÄ±nÄ±flarÄ±n doÄŸruluÄŸunu artÄ±rarak daha iyi bir performans elde edebileceÄŸinizi gÃ¶steriyor. Ancak, bunun yeterli olmadÄ±ÄŸÄ±nÄ± da belirtiyor: Pozitif ve negatif tahminlerin, **gerÃ§ek daÄŸÄ±lÄ±mla** orantÄ±lÄ± olmasÄ± gerekir. Aksi takdirde, modeliniz bÃ¼yÃ¼k bir ÅŸekilde cezalandÄ±rÄ±lÄ±r.

### Metrics for multi-class classification *(Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma metrikleri)*

**Ã‡oklu SÄ±nÄ±f SÄ±nÄ±flandÄ±rmasÄ±**na geÃ§tiÄŸimizde, daha Ã¶nce incelediÄŸimiz ikili sÄ±nÄ±flandÄ±rma metriklerini her sÄ±nÄ±f iÃ§in ayrÄ± ayrÄ± uygularÄ±z ve sonra bu metrikleri, Ã§oklu sÄ±nÄ±f durumlarÄ±nda yaygÄ±n olarak kullanÄ±lan bazÄ± ortalama stratejileriyle Ã¶zetleriz.

Ã–rneÄŸin, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ **F1 skoru** Ã¼zerinden deÄŸerlendirmek istiyorsanÄ±z, Ã¼Ã§ olasÄ± ortalama seÃ§eneÄŸiniz vardÄ±r:

* **Makro ortalama (Macro averaging)**: Her sÄ±nÄ±f iÃ§in F1 skorunu hesaplar ve ardÄ±ndan tÃ¼m sonuÃ§larÄ±n ortalamasÄ±nÄ± alÄ±rsÄ±nÄ±z. Bu ÅŸekilde, her sÄ±nÄ±f, pozitif vakalarÄ±nÄ±n sÄ±klÄ±ÄŸÄ±na veya sorununuz iÃ§in ne kadar Ã¶nemli olduÄŸuna bakÄ±lmaksÄ±zÄ±n eÅŸit ÅŸekilde deÄŸerlendirilir ve modelin her sÄ±nÄ±fta kÃ¶tÃ¼ performans gÃ¶sterdiÄŸinde eÅŸit cezalar verilmiÅŸ olur.

  $$
  \text{Macro-F1} = \frac{F1_{class1} + F1_{class2} + \dots + F1_{classn}}{N}
  $$

* **Mikro ortalama (Micro averaging)**: Bu yaklaÅŸÄ±m, her sÄ±nÄ±fÄ±n katkÄ±sÄ±nÄ± toplayarak birleÅŸtirilmiÅŸ bir F1 skoru hesaplar. Bu yÃ¶ntem, hiÃ§bir sÄ±nÄ±fa Ã¶zel bir favori veya ceza uygulamaz, Ã§Ã¼nkÃ¼ tÃ¼m hesaplamalar her sÄ±nÄ±fÄ± dikkate almadan yapÄ±lÄ±r ve bÃ¶ylece sÄ±nÄ±f dengesizliklerini daha doÄŸru bir ÅŸekilde hesaba katar:

  $$
  \text{Micro-F1} = F1_{class1+class2+\dots+classn}
  $$

* **AÄŸÄ±rlÄ±klÄ± ortalama (Weighting)**: Makro ortalama gibi, her sÄ±nÄ±f iÃ§in F1 skoru hesaplanÄ±r, ancak ardÄ±ndan tÃ¼m F1 skorlarÄ±nÄ±n, her sÄ±nÄ±fÄ±n doÄŸru etiket sayÄ±sÄ±na baÄŸlÄ± bir aÄŸÄ±rlÄ±klÄ± ortalamasÄ± alÄ±nÄ±r. Bu aÄŸÄ±rlÄ±k seti, her sÄ±nÄ±fÄ±n pozitif vakalarÄ±nÄ±n sÄ±klÄ±ÄŸÄ±nÄ± veya o sÄ±nÄ±fÄ±n sorununuz iÃ§in Ã¶nemini dikkate almanÄ±za olanak tanÄ±r. Bu yaklaÅŸÄ±m aÃ§Ä±kÃ§a Ã§oÄŸunluk sÄ±nÄ±flarÄ±na Ã¶ncelik verir, Ã§Ã¼nkÃ¼ bu sÄ±nÄ±flar hesaplamalarda daha fazla aÄŸÄ±rlÄ±k alÄ±r:

  $$
  \text{Weighted-F1} = \frac{F1_{class1} \cdot W_{class1} + F1_{class2} \cdot W_{class2} + \dots + F1_{classn} \cdot W_{classn}}

  {W_1 + W_2 + \dots + W_n = 1}
  $$

Kaggle yarÄ±ÅŸmalarÄ±nda karÅŸÄ±laÅŸabileceÄŸiniz bazÄ± yaygÄ±n Ã§oklu sÄ±nÄ±f metrikleri ÅŸunlardÄ±r:

* **Ã‡oklu sÄ±nÄ±f doÄŸruluÄŸu (Weighted Accuracy)**: **Bengali.AI Handwritten Grapheme Classification** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/bengaliai-cv19))
* **Ã‡oklu sÄ±nÄ±f log kaybÄ± (Multiclass log loss)**: **Mechanisms of Action (MoA) Prediction** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/lish-moa/))
* **Makro-F1 ve Mikro-F1 (Macro-F1, Micro-F1)**: **University of Liverpool - Ion Switching** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/liverpool-ion-switching)), **Human Protein Atlas Image Classification** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/human-protein-atlas-image-classification/)), **TensorFlow 2.0 Question Answering** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/tensorflow2-question-answering))
* **Ortalama F1 (Mean-F1)**: **Shopee - Price Match Guarantee** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/shopee-product-matching/))

---

**Kareli AÄŸÄ±rlÄ±klÄ± Kappa (Quadratic Weighted Kappa)**, sÄ±ralÄ± tahmin problemleri iÃ§in akÄ±llÄ±ca bir deÄŸerlendirme metriÄŸi olarak daha sonra inceleyeceÄŸimiz bir diÄŸer metriktir. En basit haliyle **Cohen Kappa skoru**, tahminlerinizin ve gerÃ§eklerin arasÄ±ndaki uyumu Ã¶lÃ§er. Bu metrik aslÄ±nda, **annotasyonlar arasÄ± uyumu** Ã¶lÃ§mek iÃ§in geliÅŸtirilmiÅŸtir, ancak oldukÃ§a esnek olup daha iyi kullanÄ±mlar bulmuÅŸtur.

**Annotasyonlar arasÄ± uyum** nedir? Bir etiketleme gÃ¶reviniz olduÄŸunu varsayalÄ±m: FotoÄŸraflarÄ± **kedi**, **kÃ¶pek** veya **hiÃ§biri** olarak sÄ±nÄ±flandÄ±rmak. Bir grup kiÅŸiye bu gÃ¶revi verirseniz, yanlÄ±ÅŸ etiketler alabilirsiniz, Ã§Ã¼nkÃ¼ bir kiÅŸi (bu tÃ¼r gÃ¶revlerde "hakem" olarak adlandÄ±rÄ±lÄ±r) bir kÃ¶peÄŸi kedi olarak ya da tam tersini yanlÄ±ÅŸ tanÄ±mlayabilir. Bu iÅŸi doÄŸru yapmak iÃ§in, aynÄ± fotoÄŸraflarÄ± etiketlemek iÃ§in birden fazla hakem kullanmak ve ardÄ±ndan **Cohen Kappa skoru**na gÃ¶re uyum dÃ¼zeylerini Ã¶lÃ§mek en akÄ±llÄ±ca yoldur.

**Cohen Kappa**, iki etiketleyici arasÄ±ndaki uyum dÃ¼zeyini belirten bir skordur:

$$
\kappa = \frac{p_0 - p_e}{1 - p_e}
$$

Burada ( p_0 ) gÃ¶zlemlenen relatif uyum oranÄ±nÄ±, ( p_e ) ise olasÄ±lÄ±k aÃ§Ä±sÄ±ndan tesadÃ¼fi uyum oranÄ±nÄ± ifade eder. **KarÄ±ÅŸÄ±klÄ±k matrisi** terimlerini kullanarak bu ÅŸu ÅŸekilde yazÄ±labilir:

$$
\kappa = \frac{2 \cdot (TP \cdot TN - FP \cdot FN)}{(TP + FP) \cdot (TN + FP) + (TP + FN) \cdot (FN + TN)}
$$

Bu formÃ¼lÃ¼n ilginÃ§ yanÄ±, skoru oluÅŸtururken, uyumun sadece ÅŸans sonucu gerÃ§ekleÅŸmiÅŸ olma olasÄ±lÄ±ÄŸÄ±nÄ± hesaba katmasÄ±dÄ±r. Bu sayede, Ã¶lÃ§Ã¼m en olasÄ± sÄ±nÄ±flandÄ±rmalara gÃ¶re dÃ¼zeltilmiÅŸ olur. Metrik, **tam uyum** iÃ§in 1, **tam karÅŸÄ±tlÄ±k** (tam uyumsuzluk) iÃ§in -1 olarak tanÄ±mlanÄ±r. 0 civarÄ±ndaki deÄŸerler, hakemler arasÄ±ndaki uyum ve uyumsuzluÄŸun tesadÃ¼fen gerÃ§ekleÅŸtiÄŸini gÃ¶sterir.

Bu, modelin Ã§oÄŸu durumda ÅŸansa karÅŸÄ± gerÃ§ekten daha iyi performans gÃ¶sterip gÃ¶stermediÄŸini anlamanÄ±za yardÄ±mcÄ± olur.

> **Andrey Lukyanenko**
> 
> [https://www.kaggle.com/artgor](https://www.kaggle.com/artgor)
> 
> 
> 
> Bu bÃ¶lÃ¼mdeki ikinci rÃ¶portajÄ±mÄ±z, **Notebooklar ve TartÄ±ÅŸmalar Grandmaster'Ä±** ve **YarÄ±ÅŸmalar Master'Ä±** Andrey Lukyanenko ile. GÃ¼nlÃ¼k iÅŸinde, **MTS Group**â€™ta bir **Makine Ã–ÄŸrenimi MÃ¼hendisi ve TechLead** olarak Ã§alÄ±ÅŸmaktadÄ±r. Kaggle deneyimleri hakkÄ±nda ilginÃ§ pek Ã§ok ÅŸey paylaÅŸtÄ±!
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan, Kaggleâ€™daki uzmanlÄ±ÄŸÄ±nÄ±z nedir?**
> 
> Genel olarak baÅŸka veri setlerine/alanlara transfer edilebilecek kadar genel Ã§Ã¶zÃ¼mler gerektiren yarÄ±ÅŸmalarÄ± tercih ediyorum. FarklÄ± sinir aÄŸÄ± mimarilerini, en son teknikleri ve post-processing tekniklerini denemekle ilgileniyorum. Ters mÃ¼hendislik veya "altÄ±n Ã¶zellikler" yaratmak gibi yarÄ±ÅŸmalar hoÅŸuma gitmiyor Ã§Ã¼nkÃ¼ bu tÃ¼r yaklaÅŸÄ±mlar baÅŸka veri setlerinde uygulanamaz.
> 
> 
> 
> **Kaggleâ€™da yarÄ±ÅŸÄ±rken, aynÄ± zamanda Notebooks ve Discussions kategorilerinde Grandmaster oldunuz (ve 1. sÄ±raya yerleÅŸtiniz). Bu iki hedefe yatÄ±rÄ±m yaptÄ±nÄ±z mÄ±?**
> 
> Notebooklar yazmaya Ã§ok zaman ve emek harcadÄ±m, ancak Discussions Grandmaster sÄ±ralamam kendiliÄŸinden oldu.
> 
> 
> 
> **Notebook sÄ±ralamasÄ±na nasÄ±l baÅŸladÄ±nÄ±z?**
> 
> 2018â€™de **DonorsChoose.org Application Screening** adlÄ± Ã¶zel bir yarÄ±ÅŸma vardÄ±. DonorsChoose, Ã¼lke genelindeki kamu okulu Ã¶ÄŸretmenlerinin Ã¶ÄŸrencileri iÃ§in ihtiyaÃ§ duyduklarÄ± malzemeleri ve deneyimleri talep etmelerini saÄŸlayan bir fon. Kazanan Ã§Ã¶zÃ¼mler, leaderboardâ€™daki puanlardan ziyade, Notebookâ€™a yapÄ±lan upvote sayÄ±sÄ±na gÃ¶re belirlendi. Bu ilginÃ§ geldi ve yarÄ±ÅŸma iÃ§in bir Notebook yazdÄ±m. BirÃ§ok katÄ±lÄ±mcÄ± analizlerini sosyal medya Ã¼zerinden duyurdu, ben de aynÄ± ÅŸekilde yaptÄ±m. SonuÃ§ta ikinci sÄ±raya yerleÅŸtim ve bir **Pixelbook** kazandÄ±m (hala kullanÄ±yorum!). Bu baÅŸarÄ± beni Ã§ok motive etti ve Notebook yazmaya devam ettim. Ä°lk baÅŸta yalnÄ±zca analizimi paylaÅŸmak ve geri bildirim almak istiyordum, Ã§Ã¼nkÃ¼ analiz ve gÃ¶rselleÅŸtirme becerilerimi diÄŸer insanlarla karÅŸÄ±laÅŸtÄ±rmak istiyordum. Ä°nsanlar kernelâ€™lerimi beÄŸendi ve becerilerimi daha da geliÅŸtirmek istedim. Bir diÄŸer motivasyonum ise hÄ±zlÄ± bir **MVP** (minimum viable product) yapma becerimi geliÅŸtirmekti. Yeni bir yarÄ±ÅŸma baÅŸladÄ±ÄŸÄ±nda, birÃ§ok kiÅŸi Notebook yazmaya baÅŸlar, eÄŸer ilk olmanÄ±z gerekiyorsa, kaliteden Ã¶dÃ¼n vermeden hÄ±zlÄ± bir ÅŸekilde bunu yapabilmeniz gerekir. Bu zorlu, ancak eÄŸlenceli ve Ã¶dÃ¼llendirici bir sÃ¼reÃ§ti.
> 
> 
> 
> **2019â€™un Åubat ayÄ±nda Notebook Grandmaster sÄ±ralamasÄ±na ulaÅŸtÄ±m ve bir sÃ¼re 1. sÄ±rada kaldÄ±m. Åu anda Notebook yazma sÄ±klÄ±ÄŸÄ±m azaldÄ± ama yine de keyif alÄ±yorum.**
> 
> TartÄ±ÅŸmalar konusunda ise, aslÄ±nda kendiliÄŸinden geliÅŸti. Notebookâ€™larÄ±ma yapÄ±lan yorumlarÄ± yanÄ±tladÄ±m, katÄ±ldÄ±ÄŸÄ±m yarÄ±ÅŸmalarla ilgili fikirlerimi paylaÅŸtÄ±m ve tartÄ±ÅŸmalara katÄ±ldÄ±m, bu da sÄ±ralamamÄ±n sÃ¼rekli artmasÄ±nÄ± saÄŸladÄ±.
> 
> 
> 
> **KarÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlu bir yarÄ±ÅŸma hakkÄ±nda bilgi verir misiniz? Bu gÃ¶revi nasÄ±l ele aldÄ±nÄ±z?**
> 
> Bu, **Predicting Molecular Properties** yarÄ±ÅŸmasÄ±ydÄ±. Bu yarÄ±ÅŸmayÄ± daha detaylÄ± bir ÅŸekilde yazdÄ±m ve [burada](https://towardsdatascience.com/a-story-of-my-first-gold-medal-in-one-kaggle-competition-things-done-and-lessons-learned-c269d9c233d1) okuyabilirsiniz. Bu yarÄ±ÅŸma, molekÃ¼llerdeki atomlar arasÄ±ndaki etkileÅŸimleri tahmin etmeye yÃ¶nelik bir yarÄ±ÅŸmaydÄ±. **NÃ¼kleer Manyetik Rezonans (NMR)**, MRIâ€™ye benzer ilkeler kullanarak proteinlerin ve molekÃ¼llerin yapÄ±sÄ±nÄ± ve dinamiklerini anlamaya yarayan bir teknoloji. AraÅŸtÄ±rmacÄ±lar, dÃ¼nya Ã§apÄ±nda NMR deneyleri yaparak molekÃ¼llerin yapÄ±sÄ± ve dinamikleri hakkÄ±nda daha fazla bilgi edinmeye Ã§alÄ±ÅŸÄ±yor. Bu yarÄ±ÅŸmada, molekÃ¼ldeki iki atom arasÄ±ndaki manyetik etkileÅŸimi tahmin etmeye Ã§alÄ±ÅŸtÄ±k (skaler baÄŸlama sabiti). Kuantum mekaniÄŸinden gelen en son yÃ¶ntemler, yalnÄ±zca 3D molekÃ¼ler yapÄ± verisi kullanarak bu baÄŸlama sabitlerini hesaplayabiliyor. Ancak bu hesaplamalar kaynak aÃ§Ä±sÄ±ndan Ã§ok yoÄŸun olduÄŸu iÃ§in her zaman kullanÄ±labilir deÄŸil. Makine Ã¶ÄŸrenimi yaklaÅŸÄ±mlarÄ± bu deÄŸerleri tahmin edebilirse, bu gerÃ§ekten ilaÃ§ kimyacÄ±larÄ±nÄ±n yapÄ±sal iÃ§gÃ¶rÃ¼leri daha hÄ±zlÄ± ve daha ucuza elde etmelerine yardÄ±mcÄ± olabilir.
> 
> 
> 
> YarÄ±ÅŸmalara genellikle **EDA** (Exploratory Data Analysis) kernelâ€™leri yazarÄ±m, bu yarÄ±ÅŸmada da aynÄ± ÅŸekilde baÅŸladÄ±m. Kaggle yarÄ±ÅŸmalarÄ±nda tabular veriler iÃ§in yaygÄ±n bir yaklaÅŸÄ±m **Ã¶zellik mÃ¼hendisliÄŸi** yapmak ve **gradient boosting modelleri** kullanmaktÄ±r. Erken denemelerimde **LGBM** kullandÄ±m, ancak grafikleri daha iyi kullanmanÄ±n bir yolunun olduÄŸunu biliyordum. Alan bilgisi burada ciddi bir avantaj saÄŸlayacaktÄ±, bu yÃ¼zden bu bilgileri toplamaya baÅŸladÄ±m. Tabii ki, forumda yazan ve kernelâ€™ler oluÅŸturan birkaÃ§ aktif uzman fark ettim, bu yÃ¼zden onlardan her ÅŸeyi okudum. Bir gÃ¼n, bu alandaki bir uzmandan bir e-posta aldÄ±m ve becerilerimizin birbirini tamamlayabileceÄŸini dÃ¼ÅŸÃ¼ndÃ¼. Genelde yarÄ±ÅŸmalara yalnÄ±z baÅŸÄ±ma Ã§alÄ±ÅŸmayÄ± tercih ederim, ama bu durumda gÃ¼Ã§lerimizi birleÅŸtirmek iyi bir fikir gibi gÃ¶rÃ¼nÃ¼yordu. Bu karar Ã§ok iyi bir karar oldu! Zamanla harika bir ekip kurmayÄ± baÅŸardÄ±k.
> 
> 
> 
> Bir sÃ¼re sonra yarÄ±ÅŸmada **sinir aÄŸlarÄ±nÄ±n** potansiyelini fark ettik: TanÄ±nmÄ±ÅŸ bir Kaggle katÄ±lÄ±mcÄ±sÄ±, **MPNN (Message Passing Neural Network)** modelinin bir Ã¶rneÄŸini paylaÅŸtÄ±. Bir sÃ¼re sonra bunu Ã§alÄ±ÅŸtÄ±rmayÄ± baÅŸardÄ±m ama sonuÃ§lar bizim modellerimizden daha kÃ¶tÃ¼ydÃ¼. Yine de, ekibimiz bu modellerle yÃ¼ksek hedeflere ulaÅŸmak istiyorsa bu sinir aÄŸlarÄ±yla Ã§alÄ±ÅŸmamÄ±z gerektiÄŸini biliyordu. Christofâ€™un yeni sinir aÄŸlarÄ±nÄ± son derece hÄ±zlÄ± bir ÅŸekilde kurma yeteneÄŸi inanÄ±lmazdÄ±. KÄ±sa sÃ¼re sonra, yalnÄ±zca bu modelleri geliÅŸtirmeye odaklandÄ±k.
> 
> 
> 
> **Ekip olarak 8. sÄ±raya yerleÅŸtik ve bu yarÄ±ÅŸma boyunca Ã§ok ÅŸey Ã¶ÄŸrendim.**
> 
> 
> 
> **Kaggle kariyerinize nasÄ±l yardÄ±mcÄ± oldu?**
> 
> Kaggle kesinlikle hem becerilerime hem de kiÅŸisel markama Ã§ok yardÄ±mcÄ± oldu. Kaggle Notebookâ€™larÄ± yazmak, sadece **EDA** ve **ML** becerilerini Ã¶ÄŸrenmemi saÄŸlamakla kalmadÄ±, aynÄ± zamanda yeni konularÄ± ve gÃ¶revleri hÄ±zla anlayabilme, yaklaÅŸÄ±mlar arasÄ±nda daha verimli bir ÅŸekilde iterasyon yapabilme yeteneÄŸi kazandÄ±rdÄ±. AynÄ± zamanda, yaptÄ±ÄŸÄ±m iÅŸler takdir gÃ¶rdÃ¼ ve bu bana bir gÃ¶rÃ¼nÃ¼rlÃ¼k saÄŸladÄ±. Ä°lk portfÃ¶yÃ¼mde ([erlemar.github.io](https://erlemar.github.io/)) birÃ§ok farklÄ± Notebook vardÄ± ve bunlarÄ±n yarÄ±sÄ± eski Kaggle yarÄ±ÅŸmalarÄ±na dayalÄ±ydÄ±. Bu kesinlikle ilk iÅŸimi bulmamda yardÄ±mcÄ± oldu. Kaggle baÅŸarÄ±larÄ±m, iyi ÅŸirketlerden iÅŸe alÄ±mcÄ±larÄ± cezbetmemi saÄŸladÄ±, bazen mÃ¼lakat sÃ¼recinin bazÄ± adÄ±mlarÄ±nÄ± atlamama yardÄ±mcÄ± oldu ve birkaÃ§ danÄ±ÅŸmanlÄ±k iÅŸi almama da yol aÃ§tÄ±.
> 
> 
> 
> **Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n genellikle gÃ¶z ardÄ± ettikleri ÅŸeyler nelerdir? Åu anda bildiÄŸiniz, ilk baÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz neyi farklÄ± yapardÄ±nÄ±z?**
> 
> Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ± iki gruba ayÄ±rmak gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum: Veri bilimi konusunda deneyimsiz olanlar ve Kaggleâ€™da deneyimsiz olanlar.
> 
> Veri bilimi konusunda deneyimsiz olanlar Ã§eÅŸitli hatalar yapar (ve bu normal, herkes bir yerden baÅŸlamak zorunda):
> 
> 
> 
> * **En ciddi sorunlardan biri:** EleÅŸtirel dÃ¼ÅŸÃ¼nce eksikliÄŸi ve kendi araÅŸtÄ±rmalarÄ±nÄ± yapamama;
> 
> * Hangi araÃ§larÄ±/yaklaÅŸÄ±mlarÄ± ne zaman kullanacaklarÄ±nÄ± bilememe;
> 
> * Kamuya aÃ§Ä±k Notebookâ€™larÄ± kÃ¶rÃ¼ kÃ¶rÃ¼ne alÄ±p, nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamadan kullanma;
> 
> * Bir fikre takÄ±lÄ±p kalma ve bir ÅŸey iÅŸe yaramadÄ±ÄŸÄ±nda bile Ã§ok fazla zaman harcama;
> 
> * Denemeler baÅŸarÄ±sÄ±z olduÄŸunda umutsuzluÄŸa kapÄ±lma ve motivasyonu kaybetme.
> 
> 
> 
> Veri bilimi konusunda deneyimi olan ama Kaggle konusunda deneyimsiz olanlar iÃ§inse ÅŸunu sÃ¶yleyebilirim: **Kaggleâ€™Ä±n zorluÄŸunu kÃ¼Ã§Ã¼msemek** en ciddi hatalarÄ±ndan biridir. Kaggleâ€™Ä±n Ã§ok rekabetÃ§i olduÄŸunu, baÅŸarÄ±lÄ± olmak iÃ§in birÃ§ok farklÄ± ÅŸey denemeniz gerektiÄŸini, sadece yarÄ±ÅŸmalara Ã¶zgÃ¼ birÃ§ok numara olduÄŸunu ve profesyonel olarak yarÄ±ÅŸmalara katÄ±lan insanlar olduÄŸunu beklemiyorlar.
> 
> 
> 
> **YarÄ±ÅŸmalarda geÃ§miÅŸte yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> 
> 
> * Veriye yeterince dikkat etmemek. Bazen daha iyi Ã¶zellikler Ã¼retemedim veya daha iyi post-processing uygulayamadÄ±m.
> 
> * Bir fikre Ã§ok fazla zaman harcamak Ã§Ã¼nkÃ¼ bunun iÅŸe yarayacaÄŸÄ±nÄ± umuyordum (bu bir **sunk-cost** yanÄ±lgÄ±sÄ±).
> 
> * Yeterince deneme yapmamak. Ã‡aba karÅŸÄ±lÄ±ÄŸÄ±nÄ± verir â€“ yarÄ±ÅŸmaya yeterince zaman ve kaynak ayÄ±rmazsanÄ±z, leaderboardâ€™da Ã¼st sÄ±ralarda yer alamazsÄ±nÄ±z.
> 
> * "YanlÄ±ÅŸ" yarÄ±ÅŸmalara katÄ±lmak. SÄ±zdÄ±rma, ters mÃ¼hendislik, vb. iÃ§eren yarÄ±ÅŸmalar oldu.
> 
> * YanlÄ±ÅŸ kiÅŸilerle takÄ±m kurmak. BazÄ± takÄ±m arkadaÅŸlarÄ±m beklediÄŸim kadar aktif deÄŸildi ve bu, takÄ±m sÄ±ralamamÄ±zÄ± kÃ¶tÃ¼leÅŸtirdi.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken en Ã¶nemli ÅŸey nedir?**
> 
> Bence, hedefinizi hatÄ±rlamak, bu yarÄ±ÅŸmaya ne kadar zaman ve Ã§aba yatÄ±rmaya hazÄ±r olduÄŸunuzu bilmek ve olasÄ± sonuÃ§larÄ± dÃ¼ÅŸÃ¼nmek Ã¶nemlidir. Bir yarÄ±ÅŸmaya katÄ±lÄ±rken birÃ§ok farklÄ± hedefiniz olabilir:
> 
> 
> 
> * Para kazanmak ya da madalya almak;
> 
> * Yeni beceriler kazanmak veya mevcut becerileri geliÅŸtirmek;
> 
> * Yeni bir gÃ¶rev/alan Ã¼zerinde Ã§alÄ±ÅŸmak;
> 
> * AÄŸ kurmak;
> 
> * PR yapmak;
> 
> * vb.
> 
> 
> 
> Tabii ki, birden fazla motivasyonunuz olabilir.
> 
> 
> 
> **YarÄ±ÅŸma bittiÄŸinde olacaklarÄ± dÃ¼ÅŸÃ¼nmek Ã¶nemli.** YarÄ±ÅŸmaya Ã§ok yatÄ±rÄ±m yapabilir ve kazanabilirsiniz, ancak kaybedebilirsiniz de. Bu gerÃ§eÄŸe hazÄ±rlÄ±klÄ± mÄ±sÄ±nÄ±z? Kazanmak sizin iÃ§in kritik mi? Belki daha fazla Ã§aba harcamaya hazÄ±rlÄ±klÄ± olmanÄ±z gerekebilir; diÄŸer taraftan belki uzun vadeli hedefleriniz var ve bir baÅŸarÄ±sÄ±z yarÄ±ÅŸma sizi fazla etkilemez.

### Metrics for object detection problems *(Nesne tespiti problemleri iÃ§in metrikler)*

Son yÄ±llarda, derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ± Kaggle'da giderek daha yaygÄ±n hale geldi. Bu yarÄ±ÅŸmalarÄ±n Ã§oÄŸu, gÃ¶rÃ¼ntÃ¼ tanÄ±ma veya doÄŸal dil iÅŸleme gÃ¶revlerine odaklanmÄ±ÅŸ olup, ÅŸimdiye kadar incelediÄŸimiz deÄŸerlendirme metriklerinden Ã§ok farklÄ± metrikler kullanmayÄ± gerektirmemiÅŸtir. Ancak, bazÄ± Ã¶zel problemler, doÄŸru bir ÅŸekilde deÄŸerlendirilmesi iÃ§in Ã¶zel bir metrik kullanÄ±lmasÄ±nÄ± gerektirmiÅŸtir: bunlar, nesne tespiti ve segmentasyonla ilgili olanlardÄ±r.

![](im/1047.png)

Nesne tespitinde, bir resmi sÄ±nÄ±flandÄ±rmak yerine, resmin ilgili bÃ¶lÃ¼mlerini bulmanÄ±z ve bunlarÄ± uygun ÅŸekilde etiketlemeniz gerekir. Ã–rneÄŸin, Åekil 5.4'te, bir nesne tespit sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±na, bir fotoÄŸraf iÃ§inde kÃ¶peklerin veya kedilerin bulunduÄŸu bÃ¶lÃ¼mleri yerleÅŸtirip her birini doÄŸru etiketlemesi gÃ¶revi verilmiÅŸtir. Sol taraftaki Ã¶rnek, bir kedinin konumlandÄ±rÄ±lmasÄ±nÄ±, dikdÃ¶rtgen bir kutu (bu kutuya **bounding box** denir) kullanarak gÃ¶steriyor. SaÄŸdaki Ã¶rnek ise, bir fotoÄŸraf iÃ§inde birden fazla kedi ve kÃ¶peÄŸin nasÄ±l tespit edildiÄŸini ve ardÄ±ndan doÄŸru bir ÅŸekilde sÄ±nÄ±flandÄ±rÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶steriyor (mavi kutular kÃ¶pekler iÃ§in, kÄ±rmÄ±zÄ± kutular ise kediler iÃ§in).

Nesne tespitinde, bir nesnenin mekansal konumunu tanÄ±mlamak iÃ§in **bounding box**'lar kullanÄ±lÄ±r; bu kutular, nesnenin bulunduÄŸu dikdÃ¶rtgen alanÄ± tanÄ±mlar. Bir **bounding box** genellikle iki (x, y) koordinatÄ±yla belirtilir: Ã¼st-sol kÃ¶ÅŸe ve alt-saÄŸ kÃ¶ÅŸe. Bir makine Ã¶ÄŸrenimi algoritmasÄ± aÃ§Ä±sÄ±ndan, bounding box'larÄ±n koordinatlarÄ±nÄ± bulmak, birden fazla hedefe uygulanan bir regresyon problemine karÅŸÄ±lÄ±k gelir. Ancak, problemi sÄ±fÄ±rdan Ã§Ã¶zmeyeceksiniz; bunun yerine genellikle **Mask R-CNN** ([https://arxiv.org/abs/1703.06870](https://arxiv.org/abs/1703.06870)), **RetinaNet** ([https://arxiv.org/abs/2106.05624v1](https://arxiv.org/abs/2106.05624v1)), **FPN** ([https://arxiv.org/abs/1612.03144v2](https://arxiv.org/abs/1612.03144v2)), **YOLO** ([https://arxiv.org/abs/1506.02640v1](https://arxiv.org/abs/1506.02640v1)), **Faster R-CNN** ([https://arxiv.org/abs/1506.01497v1](https://arxiv.org/abs/1506.01497v1)) veya **SSD** ([https://arxiv.org/abs/1512.02325](https://arxiv.org/abs/1512.02325)) gibi Ã¶nceden oluÅŸturulmuÅŸ ve Ã§oÄŸu zaman Ã¶nceden eÄŸitilmiÅŸ modellere baÅŸvuracaksÄ±nÄ±z.

**Segmentasyonda** ise, piksel seviyesinde bir sÄ±nÄ±flandÄ±rma yapÄ±lÄ±r. Yani, eÄŸer 320x200 boyutlarÄ±nda bir resminiz varsa, aslÄ±nda 64.000 piksel sÄ±nÄ±flandÄ±rmasÄ± yapmanÄ±z gerekir. GÃ¶reve baÄŸlÄ± olarak, her pikseli bir fotoÄŸrafÄ±n iÃ§inde sÄ±nÄ±flandÄ±rmanÄ±z gereken **semantik segmentasyon** olabilir ya da yalnÄ±zca belirli bir ilgi tÃ¼rÃ¼ndeki nesneleri (Ã¶rneÄŸin, Åekil 5.5'teki gibi bir kedi) temsil eden pikselleri sÄ±nÄ±flandÄ±rmanÄ±z gereken **instance segmentasyon** olabilir.

![](im/1048.png)

Bu gÃ¶revler iÃ§in Ã¶zel metriklerin genel bir gÃ¶rÃ¼nÃ¼mÃ¼ne baÅŸlayalÄ±m; Ã§Ã¼nkÃ¼ her iki problemde de (nesne tespitinde dikdÃ¶rtgen, segmentasyonda ise Ã§okgen olan) bir resmin tamamÄ±nÄ± tahmin ediyorsunuz ve tahminlerinizi gerÃ§ek etiketlerle karÅŸÄ±laÅŸtÄ±rmanÄ±z gerekiyor, bu etiketler de yine alanlar olarak ifade ediliyor. Segmentasyon tarafÄ±nda, en basit metrik **piksel doÄŸruluÄŸu**dur; adÄ± Ã¼zerinde, bu metrik, piksel sÄ±nÄ±flandÄ±rmasÄ±ndaki doÄŸruluÄŸu Ã¶lÃ§er.

Bu metrik mÃ¼kemmel bir seÃ§im deÄŸildir, Ã§Ã¼nkÃ¼ **ikili ve Ã§ok sÄ±nÄ±flÄ± problemlerdeki doÄŸruluk** gibi, eÄŸer ilgili pikseller resmin Ã§ok kÃ¼Ã§Ã¼k bir kÄ±smÄ±nÄ± oluÅŸturuyorsa, skoru yÃ¼ksek gÃ¶rÃ¼nebilir (sadece Ã§oÄŸunluk sÄ±nÄ±fÄ±nÄ± tahmin edersiniz, bu da segmentasyon yapmadÄ±ÄŸÄ±nÄ±z anlamÄ±na gelir).

Bu nedenle, Ã¶zellikle yarÄ±ÅŸmalarda daha sÄ±k kullanÄ±lan iki metrik vardÄ±r: **intersection over union** (IoU) ve **dice katsayÄ±sÄ±** (Dice coefficient).

#### Intersection over union (IoU) *(KesiÅŸim/BirleÅŸim oranÄ±)*

**Intersection over union (IoU)**, aynÄ± zamanda **Jaccard indeksi** olarak da bilinir. Segmentasyon problemlerinde IoU kullanmak, karÅŸÄ±laÅŸtÄ±rmanÄ±z gereken iki resminiz olduÄŸu anlamÄ±na gelir: biri sizin tahmininiz, diÄŸeri ise genellikle **1** deÄŸeriyle doÄŸru etiketleri (ground truth) temsil eden ve **0** ile diÄŸer bÃ¶lgeleri gÃ¶steren bir **binary maske**dir. Birden fazla nesne olduÄŸunda, her bir nesne iÃ§in ayrÄ± bir maske olur ve her maske, nesnenin sÄ±nÄ±fÄ±yla etiketlenir.

Nesne tespiti problemlerinde IoU kullanÄ±ldÄ±ÄŸÄ±nda ise, tahmin ve doÄŸru etiketin (ground truth) dikdÃ¶rtgen alanlarÄ±nÄ±n sÄ±nÄ±rlarÄ± vardÄ±r, bu sÄ±nÄ±rlar da kÃ¶ÅŸe noktalarÄ±nÄ±n koordinatlarÄ±yla ifade edilir. Her bir sÄ±nÄ±flandÄ±rÄ±lan sÄ±nÄ±f iÃ§in, tahmininiz ile doÄŸru etiketin maskesi arasÄ±ndaki Ã¶rtÃ¼ÅŸen alanÄ± hesaplar ve bunu, tahmininiz ile doÄŸru etiket arasÄ±ndaki birleÅŸim alanÄ±na (yani her iki alanÄ±n toplamÄ±) bÃ¶lersiniz; bu toplam, herhangi bir Ã¶rtÃ¼ÅŸmeyi dikkate alÄ±r. Bu ÅŸekilde, tahmin ettiÄŸiniz alan fazla bÃ¼yÃ¼kse (payda daha bÃ¼yÃ¼k olur) veya Ã§ok kÃ¼Ã§Ã¼kse (pay daha kÃ¼Ã§Ã¼k olur) orantÄ±lÄ± olarak cezalandÄ±rÄ±lÄ±rsÄ±nÄ±z.

![](im/1049.png)

Åekil 5.6'da, hesaplamada yer alan alanlarÄ±n gÃ¶rsel bir temsilini gÃ¶rebilirsiniz. Karelerin daha fazla Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ hayal ederek, metriklerin, tahmininiz doÄŸru etiketi kapsasa bile, bunu aÅŸtÄ±ÄŸÄ±nda (birleÅŸim alanÄ± bÃ¼yÃ¼dÃ¼ÄŸÃ¼nde) Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ nasÄ±l etkili bir ÅŸekilde cezalandÄ±rdÄ±ÄŸÄ±nÄ± anlayabilirsiniz.

> Ä°ÅŸte IoU'nun kullanÄ±ldÄ±ÄŸÄ± bazÄ± yarÄ±ÅŸmalarÄ±n Ã¶rnekleri:
> 
> 
> 
> * **TGS Salt Identification Challenge** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/tgs-salt-identification-challenge/)) â€” Intersection Over Union Nesne Segmentasyonu
> 
> * **iMaterialist (Fashion) 2019 at FGVC6** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6)) â€” Intersection Over Union Nesne Segmentasyonu ve SÄ±nÄ±flandÄ±rma
> 
> * **Airbus Ship Detection Challenge** ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/airbus-ship-detection)) â€” Intersection Over Union Nesne Segmentasyonu Beta
> 
> 

#### Dice *(Dice katsayÄ±sÄ±)*

DiÄŸer yararlÄ± metrik ise **Dice katsayÄ±sÄ±**dÄ±r; bu, tahmin ile doÄŸru etiket arasÄ±ndaki Ã¶rtÃ¼ÅŸen alanÄ±n iki katÄ±na Ã§Ä±karÄ±lmasÄ± ve ardÄ±ndan tahmin ile doÄŸru etiket alanlarÄ±nÄ±n toplamÄ±na bÃ¶lÃ¼nmesiyle hesaplanÄ±r.

![](im/1050.png)

Bu durumda, **Jaccard indeksi**ne kÄ±yasla, tahminin doÄŸru etiketle Ã¶rtÃ¼ÅŸen kÄ±smÄ± paydada dikkate alÄ±nmaz. Burada beklenti, Ã¶rtÃ¼ÅŸen alanÄ± maksimize ederken doÄŸru alan boyutunu tahmin etmenizdir. Yine, tahmin ettiÄŸiniz alanlar olmasÄ± gerekenden daha bÃ¼yÃ¼kse cezalandÄ±rÄ±lÄ±rsÄ±nÄ±z. AslÄ±nda, bu iki metrik pozitif olarak korelasyonlu olup, tek bir sÄ±nÄ±flandÄ±rma problemi iÃ§in neredeyse aynÄ± sonuÃ§larÄ± Ã¼retir.

Farklar, aslÄ±nda birden fazla sÄ±nÄ±fla Ã§alÄ±ÅŸÄ±rken ortaya Ã§Ä±kar. Hem IoU hem de Dice katsayÄ±sÄ± ile birden fazla sÄ±nÄ±f olduÄŸunda, tÃ¼m sÄ±nÄ±flarÄ±n sonuÃ§larÄ±nÄ±n ortalamasÄ±nÄ± alÄ±rsÄ±nÄ±z. Ancak, bunu yaparken, **IoU** metrik, bir sÄ±nÄ±f tahmini yanlÄ±ÅŸ olduÄŸunda genel ortalamayÄ± daha fazla cezalandÄ±rma eÄŸilimindeyken, **Dice katsayÄ±sÄ±** daha hoÅŸgÃ¶rÃ¼lÃ¼ olup, ortalama performansÄ± temsil etme eÄŸilimindedir.

> **Dice katsayÄ±sÄ±nÄ± kullanan bazÄ± Kaggle yarÄ±ÅŸmalarÄ±nÄ±n Ã¶rnekleri** (genellikle tÄ±bbi amaÃ§lÄ± yarÄ±ÅŸmalarda sÄ±kÃ§a karÅŸÄ±laÅŸÄ±lsa da, sadece orada deÄŸil, bulutlar ve arabalar gibi diÄŸer alanlarda da kullanÄ±labilir):
> 
> 
> 
> * **HuBMAP - Hacking the Kidney**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/hubmap-kidney-segmentation)
> 
> * **Ultrasound Nerve Segmentation**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/ultrasound-nerve-segmentation)
> 
> * **Understanding Clouds from Satellite Images**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/understanding_cloud_organization)
> 
> * **Carvana Image Masking Challenge**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/carvana-image-masking-challenge)

**IoU** ve **Dice katsayÄ±sÄ±**, segmentasyon ve nesne tespiti alanÄ±ndaki daha karmaÅŸÄ±k metriklerin temelini oluÅŸturur. IoU veya Dice iÃ§in uygun bir eÅŸik seviyesi (genellikle 0.5) seÃ§erek, bir tespiti onaylayÄ±p onaylamayacaÄŸÄ±nÄ±za karar verebilirsiniz, dolayÄ±sÄ±yla bir sÄ±nÄ±flandÄ±rma yapabilirsiniz. Bu noktada, daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z sÄ±nÄ±flandÄ±rma metriklerini (kesinlik, duyarlÄ±lÄ±k, F1 gibi) kullanabilirsiniz; bu, **Pascal VOC** ([http://host.robots.ox.ac.uk/pascal/VOC/voc2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012)) veya **COCO** ([https://cocodataset.org](https://cocodataset.org)) gibi popÃ¼ler nesne tespiti ve segmentasyon yarÄ±ÅŸmalarÄ±nda olduÄŸu gibi yapÄ±lÄ±r.

### Metrics for multi-label classification and recommendation problems *(Ã‡ok etiketli sÄ±nÄ±flandÄ±rma ve Ã¶neri problemleri iÃ§in metrikler)*

**Ã–neri sistemleri**, veri analizi ve makine Ã¶ÄŸreniminin en popÃ¼ler uygulamalarÄ±ndan biridir ve Kaggle'da bu tÃ¼r Ã¶neri yaklaÅŸÄ±mlarÄ±nÄ± kullanan birÃ§ok yarÄ±ÅŸma bulunmaktadÄ±r. Ã–rneÄŸin, **Quick, Draw! Doodle Recognition Challenge**, bir Ã¶neri sistemi olarak deÄŸerlendirilen bir tahmin yarÄ±ÅŸmasÄ±ydÄ±. Ancak, Kaggle'daki diÄŸer bazÄ± yarÄ±ÅŸmalar gerÃ§ekten etkili Ã¶neri sistemleri oluÅŸturmayÄ± hedeflemiÅŸtir (Ã¶rneÄŸin, **Expedia Hotel Recommendations**: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/expedia-hotel-recommendations)) ve **RecSYS**, Ã¶neri sistemleri konferansÄ± ([https://recsys.acm.org/](https://recsys.acm.org/)), her yÄ±l dÃ¼zenlediÄŸi yarÄ±ÅŸmalardan birini Kaggle Ã¼zerinde gerÃ§ekleÅŸtirmiÅŸtir (RecSYS 2013: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/yelp-recsys-2013)).

**MAP@K (Mean Average Precision at K)**, Ã¶neri sistemlerinin performansÄ±nÄ± deÄŸerlendirmek iÃ§in tipik olarak tercih edilen metrik olup, Kaggle'da, Ã¶neri sistemleriyle ilgili yarÄ±ÅŸmalarÄ±n Ã§oÄŸunda karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z en yaygÄ±n metriktir. Bunun yanÄ± sÄ±ra, **P@K (precision at k)** veya **AP@K (average precision at k)** gibi bazÄ± diÄŸer metrikler de vardÄ±r; bunlar kayÄ±p fonksiyonlarÄ±dÄ±r, yani her bir tekil tahmin dÃ¼zeyinde hesaplanÄ±rlar. Bu metriklerin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamak, MAP@K'yi daha iyi anlamanÄ±zÄ± saÄŸlayabilir ve bu metriklerin hem Ã¶nerilerde hem de Ã§oklu etiketli sÄ±nÄ±flandÄ±rmada nasÄ±l performans gÃ¶sterdiÄŸi konusunda size yardÄ±mcÄ± olabilir.

AslÄ±nda, Ã¶neri sistemleriyle benzer ÅŸekilde, **Ã§oklu etiketli sÄ±nÄ±flandÄ±rmalar**, modelinizin bir dizi sÄ±nÄ±f tahmini Ã¼retmesini ima eder. Bu tÃ¼r sonuÃ§lar, bazÄ± **ikili sÄ±nÄ±flandÄ±rma metriklerinin** ortalamasÄ± (Ã¶rneÄŸin, **Greek Media Monitoring Multilabel Classification** (WISE 2014), bu yarÄ±ÅŸma **ortalama F1 skoru**nu kullandÄ±: [Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/wise-2014)) ve Ã¶neri sistemlerine daha Ã¶zgÃ¼ metrikler, Ã¶rneÄŸin **MAP@K** gibi metrikler kullanÄ±larak deÄŸerlendirilebilir. SonuÃ§ olarak, hem Ã¶neri sistemleri hem de Ã§oklu etiketli tahminler, bir **sÄ±ralama gÃ¶revi** olarak ele alÄ±nabilir; bu, Ã¶neri sistemlerinde sÄ±ralanmÄ±ÅŸ Ã¶neriler ve Ã§oklu etiketli sÄ±nÄ±flandÄ±rmada (belirli bir sÄ±ralama olmadan) etiketlerin bir setine dÃ¶nÃ¼ÅŸÃ¼r.

#### MAP@K *(MAP@K metriÄŸi)*

**MAP@K**, karmaÅŸÄ±k bir metriktir ve birÃ§ok hesaplamadan tÃ¼retilir. MAP@K metriÄŸini tam olarak anlayabilmek iÃ§in, Ã¶nce en basit bileÅŸeni olan **precision at k (P@K)** ile baÅŸlayalÄ±m. Bu durumda, bir Ã¶rneÄŸin tahmini, sÄ±ralanmÄ±ÅŸ tahminler dizisi (en olasÄ±dan en az olasÄ±lÄ±klÄ±ya kadar) olduÄŸundan, fonksiyon yalnÄ±zca en Ã¼stteki **k** tahmini dikkate alÄ±r ve ardÄ±ndan, doÄŸru etiketle ne kadar eÅŸleÅŸme saÄŸladÄ±ÄŸÄ±nÄ± hesaplar ve bu sayÄ±yÄ± **k**'ye bÃ¶ler. KÄ±sacasÄ±, bu, **k** tahmini Ã¼zerinden ortalama alÄ±nmÄ±ÅŸ bir doÄŸruluk Ã¶lÃ§Ã¼sÃ¼ne oldukÃ§a benzer.

Biraz daha karmaÅŸÄ±k bir hesaplama gerektiren ama kavramsal olarak basit olan **average precision at k (AP@K)**, **P@K**'nin **1**'den **k**'ye kadar olan tÃ¼m deÄŸerler Ã¼zerinde hesaplanÄ±p ortalamasÄ±nÄ±n alÄ±nmasÄ±dÄ±r. Bu ÅŸekilde, metrik, tahminin ne kadar iyi Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± genel olarak deÄŸerlendirir; ilk tahmin, ardÄ±ndan ilk iki tahmin, ve devam ederek **k** tahmine kadar.

Son olarak, **MAP@K**, tÃ¼m tahmin Ã¶rnekleri iÃ§in AP@K'nin ortalamasÄ±dÄ±r ve bu metrik, tÃ¼m tahminleri deÄŸerlendirdiÄŸi iÃ§in bir metriktir. Ä°ÅŸte **MAP@5** formÃ¼lasyonu, **Expedia Hotel Recommendations** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/expedia-hotel-recommendations](https://www.kaggle.com/c/expedia-hotel-recommendations)) bulabileceÄŸiniz formÃ¼l:

GÃ¶rÃ¼ntÃ¼de, **MAP@5** metriÄŸi iÃ§in kullanÄ±lan formÃ¼lÃ¼n bir versiyonu yer alÄ±yor. Bu formÃ¼l, Ã¶neri sistemlerinde doÄŸruluÄŸun deÄŸerlendirilmesi iÃ§in kullanÄ±lÄ±r ve ÅŸu ÅŸekilde ifade edilebilir:

$$
\text{MAP@5} = \frac{1}{|U|} \sum_{u=1}^{|U|} \sum_{k=1}^{\min(5, n)} P(k)
$$

Bu formÃ¼lde:

* **|U|**, kullanÄ±cÄ± sayÄ±sÄ±nÄ±,
* **P(k)**, k'ncÄ± tahminin doÄŸruluÄŸunu,
* **n**, tahmin edilen Ã¶ÄŸe sayÄ±sÄ±nÄ±,
* **min(5, n)**, en fazla 5 tahmin yapÄ±lmasÄ±nÄ± belirler.

Bu aÃ§Ä±klama biraz daha karmaÅŸÄ±k olsa da, formÃ¼l aslÄ±nda **MAP@K**'nin tÃ¼m tahminler Ã¼zerindeki **AP@K** deÄŸerlendirmelerinin ortalamasÄ±nÄ± ifade ettiÄŸini gÃ¶sterir.

Bu Ã¶zel metriklerin, regresyon ve sÄ±nÄ±flandÄ±rma metrikleri Ã¼zerindeki genel bakÄ±ÅŸÄ±mÄ±zÄ± tamamladÄ±ktan sonra, bir **Kaggle yarÄ±ÅŸmasÄ±nda** deÄŸerlendirme metrikleriyle nasÄ±l baÅŸa Ã§Ä±kÄ±lacaÄŸÄ±na dair tartÄ±ÅŸmaya geÃ§elim.

### Optimizing evaluation metrics *(DeÄŸerlendirme metriklerini optimize etme)*

Åimdiye kadar tartÄ±ÅŸtÄ±klarÄ±mÄ±zÄ± Ã¶zetleyecek olursak, **amaÃ§ fonksiyonu**, Ã¶ÄŸrenme algoritmanÄ±zÄ±n iÃ§inde, algoritmanÄ±n iÃ§ modelinin saÄŸlanan verilere ne kadar iyi uyduÄŸunu Ã¶lÃ§en bir fonksiyondur. AmaÃ§ fonksiyonu ayrÄ±ca algoritmaya, ardÄ±ÅŸÄ±k iterasyonlar boyunca uyumunu iyileÅŸtirebilmesi iÃ§in geri bildirim saÄŸlar. AÃ§Ä±kÃ§a sÃ¶ylemek gerekirse, algoritmanÄ±n tÃ¼m Ã§abalarÄ±, amaÃ§ fonksiyonuna dayanarak iyi performans gÃ¶stermeye yÃ¶nlendirilir. EÄŸer Kaggle deÄŸerlendirme metriÄŸi, algoritmanÄ±zÄ±n amaÃ§ fonksiyonu ile mÃ¼kemmel bir ÅŸekilde Ã¶rtÃ¼ÅŸÃ¼yorsa, en iyi sonuÃ§larÄ± alÄ±rsÄ±nÄ±z.

Ne yazÄ±k ki, bu durum sÄ±kÃ§a geÃ§erli deÄŸildir. Ã‡oÄŸu zaman, saÄŸlanan deÄŸerlendirme metriÄŸi yalnÄ±zca mevcut amaÃ§ fonksiyonlarÄ±yla yaklaÅŸÄ±k olarak elde edilebilir. Ä°yi bir yaklaÅŸÄ±k sonuÃ§ elde etmek veya tahminlerinizi deÄŸerlendirme kriterlerine gÃ¶re daha iyi hale getirmek, Kaggle yarÄ±ÅŸmalarÄ±nda iyi performans gÃ¶stermek iÃ§in sÄ±rrÄ±nÄ±zdÄ±r. AmaÃ§ fonksiyonunuz, deÄŸerlendirme metriÄŸinizle Ã¶rtÃ¼ÅŸmÃ¼yorsa, birkaÃ§ alternatifiniz vardÄ±r:

1. **Ã–ÄŸrenme algoritmanÄ±zÄ± deÄŸiÅŸtirmek** ve deÄŸerlendirme metriÄŸinizle uyumlu bir amaÃ§ fonksiyonu eklemek; ancak bu, tÃ¼m algoritmalar iÃ§in mÃ¼mkÃ¼n deÄŸildir (Ã¶rneÄŸin, **LightGBM** ve **XGBoost** gibi algoritmalar, Ã¶zel amaÃ§ fonksiyonlarÄ± ayarlamanÄ±za izin verir, ancak Ã§oÄŸu **Scikit-learn** modeli bunu desteklemez).

2. **Modelinizin hiperparametrelerini ayarlamak**, deÄŸerlendirme metriÄŸi kullanÄ±ldÄ±ÄŸÄ±nda en iyi sonucu veren parametreleri seÃ§mek.

3. **SonuÃ§larÄ±nÄ±zÄ± post-process etmek**, bÃ¶ylece deÄŸerlendirme kriterlerine daha yakÄ±n hale gelmesini saÄŸlamak. Ã–rneÄŸin, tahminleriniz Ã¼zerinde dÃ¶nÃ¼ÅŸÃ¼mler yapan bir optimizasyon algoritmasÄ± yazabilirsiniz (Ã¶rneÄŸin, **probabilite kalibrasyonu algoritmalarÄ±**, bu algoritmalarÄ± bÃ¶lÃ¼mÃ¼n sonunda tartÄ±ÅŸacaÄŸÄ±z).

YarÄ±ÅŸma metriÄŸini, makine Ã¶ÄŸrenimi algoritmanÄ±za entegre etmek, daha iyi tahminler elde etmenin gerÃ§ekten en etkili yÃ¶ntemidir; ancak yalnÄ±zca birkaÃ§ algoritma, yarÄ±ÅŸma metriÄŸini amaÃ§ fonksiyonu olarak kullanacak ÅŸekilde hacklenebilir. Bu nedenle, ikinci yaklaÅŸÄ±m daha yaygÄ±n olanÄ±dÄ±r ve birÃ§ok yarÄ±ÅŸma, modelinizin deÄŸerlendirme metriÄŸi Ã¼zerinde en iyi performansÄ± gÃ¶sterebilmesi iÃ§in doÄŸru hiperparametreleri bulma mÃ¼cadelesine dÃ¶nÃ¼ÅŸÃ¼r.

EÄŸer deÄŸerlendirme fonksiyonunuz kodlanmÄ±ÅŸsa, doÄŸru **cross-validation** yapmak veya uygun test setini seÃ§mek bÃ¼yÃ¼k bir fark yaratacaktÄ±r. EÄŸer kodlanmÄ±ÅŸ bir fonksiyonunuz yoksa, Ã¶nce Kaggle tarafÄ±ndan saÄŸlanan formÃ¼lleri takip ederek uygun ÅŸekilde kodlamanÄ±z gerekir.

Her zaman, ÅŸu adÄ±mlar fark yaratacaktÄ±r:

* DeÄŸerlendirme metriÄŸi ve kodlanmÄ±ÅŸ fonksiyonu hakkÄ±nda arama motorlarÄ±ndan tÃ¼m ilgili bilgileri aramak
* En yaygÄ±n paketleri incelemek (Ã¶rneÄŸin, **Scikit-learn**: [model deÄŸerlendirme](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation) veya **TensorFlow**: [keras kayÄ±plarÄ±](https://www.tensorflow.org/api_docs/python/tf/keras/losses))
* **GitHub projelerini** taramak (Ã¶rneÄŸin, **Ben Hammerâ€™Ä±n Metrics** projesi: [Ben Hammer Metrics GitHub](https://github.com/benhamner/Metrics))
* Forumlarda ve mevcut Kaggle Notebooks'larda (hem mevcut yarÄ±ÅŸma iÃ§in hem de benzer yarÄ±ÅŸmalar iÃ§in) sormak veya bakmak
* AyrÄ±ca, daha Ã¶nce belirttiÄŸimiz gibi, **Meta Kaggle veri setini** sorgulamak ([Meta Kaggle](https://www.kaggle.com/kaggle/meta-kaggle)) ve **Competitions** tablosuna bakmak, aynÄ± deÄŸerlendirme metriÄŸini kullanan diÄŸer Kaggle yarÄ±ÅŸmalarÄ±nÄ± bulmanÄ±za yardÄ±mcÄ± olacaktÄ±r ve bu size hemen kullanÄ±ÅŸlÄ± kodlar ve fikirler saÄŸlayacaktÄ±r.

DeÄŸerlendirme metriÄŸiniz, algoritmanÄ±zÄ±n amaÃ§ fonksiyonu ile Ã¶rtÃ¼ÅŸmediÄŸinde, sahip olduÄŸunuz alternatifleri daha ayrÄ±ntÄ±lÄ± olarak tartÄ±ÅŸalÄ±m. **Ã–zel metrikler** ile baÅŸlayalÄ±m.

### Custom metrics and custom objective functions *(Ã–zel metrikler ve Ã¶zel hedef fonksiyonlarÄ±)*

**AmaÃ§ fonksiyonunuz, deÄŸerlendirme metriÄŸinizle Ã¶rtÃ¼ÅŸmediÄŸinde ilk seÃ§enek olarak**, yukarÄ±da Ã¶ÄŸrendiÄŸimiz gibi, kendi **Ã¶zel amaÃ§ fonksiyonunuzu** yaratabilirsiniz, ancak sadece bazÄ± algoritmalar, Ã¶zel bir amaÃ§ fonksiyonunu kolayca entegre etmenize izin verir.

Ä°yi haber ÅŸu ki, bu tÃ¼r fonksiyonlarÄ± ekleyebilen birkaÃ§ algoritma, Kaggle yarÄ±ÅŸmalarÄ±nda ve veri bilimi projelerinde en etkili olanlar arasÄ±ndadÄ±r. Tabii ki, kendi Ã¶zel amaÃ§ fonksiyonunuzu oluÅŸturmak biraz karmaÅŸÄ±k gÃ¶rÃ¼nebilir, ancak bu yaklaÅŸÄ±m, bir yarÄ±ÅŸmada puanÄ±nÄ±zÄ± artÄ±rmak iÃ§in inanÄ±lmaz derecede Ã¶dÃ¼llendirici olabilir. Ã–rneÄŸin, **gradient boosting** algoritmalarÄ±nda (**XGBoost**, **CatBoost**, **LightGBM**) ve **TensorFlow** veya **PyTorch** tabanlÄ± tÃ¼m derin Ã¶ÄŸrenme modellerinde, kendi Ã¶zel amaÃ§ fonksiyonlarÄ±nÄ±zÄ± oluÅŸturma seÃ§eneÄŸiniz vardÄ±r.

**TensorFlow** ve **PyTorch**'ta Ã¶zel metrikler ve amaÃ§ fonksiyonlarÄ± iÃ§in harika Ã¶ÄŸreticiler bulabilirsiniz:

* [Custom Metrics in Keras and How Simple They Are to Use in TensorFlow2](https://towardsdatascience.com/custom-metrics-in-keras-and-how-simple-they-are-to-use-in-tensorflow2-2-6d079c2ca279)
* [Advanced Keras Custom Loss Functions](https://petamind.com/advanced-keras-custom-loss-functions/)
* [PyTorch Metric Learning Custom Loss Functions](https://kevinmusgrave.github.io/pytorch-metric-learning/extend/losses/)

Bu kaynaklar, size Ã¶zel bir amaÃ§ veya deÄŸerlendirme fonksiyonu kodlamanÄ±n temel ÅŸablonlarÄ±nÄ± ve bazÄ± kullanÄ±ÅŸlÄ± Ã¶nerileri sunacaktÄ±r.

> **Ã–zel bir amaÃ§ fonksiyonu oluÅŸturmak iÃ§in ihtiyacÄ±nÄ±z olanÄ± hemen almak isterseniz**, RNA tarafÄ±ndan yazÄ±lmÄ±ÅŸ bu Notebook'u ([https://www.kaggle.com/bigironsphere](https://www.kaggle.com/bigironsphere)): [Loss Function Library Keras/PyTorch](https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch/) inceleyebilirsiniz. Bu Notebook, farklÄ± yarÄ±ÅŸmalarda kullanÄ±lan, **TensorFlow** ve **PyTorch** iÃ§in Ã§ok sayÄ±da Ã¶zel kayÄ±p fonksiyonu iÃ§ermektedir.

**LightGBM, XGBoost veya CatBoost'ta Ã¶zel bir kayÄ±p fonksiyonu oluÅŸturmanÄ±z gerektiÄŸinde**, ilgili dokÃ¼mantasyonlarÄ±nda belirtildiÄŸi gibi, tahmin ve doÄŸru etiketleri (ground truth) girdi olarak alan ve Ã§Ä±ktÄ±larÄ±nda **gradient** ve **hessian** dÃ¶ndÃ¼ren bir fonksiyon yazmanÄ±z gerekecektir.

> Gradient ve hessian'Ä±n ne olduÄŸunu daha iyi anlamak iÃ§in ÅŸu Stack Overflow yazÄ±sÄ±nÄ± inceleyebilirsiniz: [Gradient ve Hessian HesaplamasÄ±](https://stats.stackexchange.com/questions/231220/how-to-compute-the-gradient-and-hessian-of-logarithmic-loss-question-is-based).

Kod uygulama aÃ§Ä±sÄ±ndan, yapmanÄ±z gereken tek ÅŸey, fonksiyonu yaratmak ve gerekirse daha fazla parametre geÃ§mek iÃ§in **closures** kullanmaktÄ±r. Ä°ÅŸte, **focal loss** adlÄ± bir kayÄ±p fonksiyonu Ã¶rneÄŸi (bu kayÄ±p, sÄ±nÄ±f dengesizliÄŸini dikkate alarak kayÄ±p hesaplamalarÄ±na daha fazla aÄŸÄ±rlÄ±k verir, Lin, T-Y. et al.'Ä±n **Focal loss for dense object detection** adlÄ± makalesinde aÃ§Ä±klandÄ±ÄŸÄ± gibi: [Focal Loss Makalesi](https://arxiv.org/abs/1708.02002)):

```python
from scipy.misc import derivative
import xgboost as xgb

def focal_loss(alpha, gamma):
    def loss_func(y_pred, y_true):
        a, g = alpha, gamma
        def get_loss(y_pred, y_true):
            p = 1 / (1 + np.exp(-y_pred))
            loss = (-(a * y_true + (1 - a)*(1 - y_true)) *
                    ((1 - (y_true * p + (1 - y_true) * (1 - p)))**g) *
                    (y_true * np.log(p) + (1 - y_true) * np.log(1 - p)))
            return loss
        partial_focal = lambda y_pred: get_loss(y_pred, y_true)
        grad = derivative(partial_focal, y_pred, n=1, dx=1e-6)
        hess = derivative(partial_focal, y_pred, n=2, dx=1e-6)
        return grad, hess
    return loss_func

xgb = xgb.XGBClassifier(objective=focal_loss(alpha=0.25, gamma=1))
```

YukarÄ±daki kod Ã¶rneÄŸinde, **focal_loss** adlÄ± yeni bir maliyet fonksiyonu tanÄ±mladÄ±k, ardÄ±ndan bunu bir **XGBoost** Ã¶rneÄŸine yerleÅŸtirdik. Bu Ã¶rnek, focal loss'un dÃ¼zgÃ¼n Ã§alÄ±ÅŸabilmesi iÃ§in bazÄ± parametrelerin (alpha ve gamma) doÄŸru ÅŸekilde tanÄ±mlanmasÄ±nÄ± gerektirir. Fonksiyonun iÃ§inde bu parametrelerin doÄŸrudan kodlanmasÄ± yerine, parametreler fonksiyona girildiÄŸinde bellekte saklanÄ±r ve **loss_func** fonksiyonu tarafÄ±ndan referans alÄ±nÄ±r.

Bir diÄŸer ilginÃ§ nokta ise, SciPyâ€™nin **derivative** fonksiyonu aracÄ±lÄ±ÄŸÄ±yla, maliyet fonksiyonunun **gradient** ve **hessian**'Ä±nÄ± hesaplamanÄ±n oldukÃ§a kolay olmasÄ±dÄ±r. EÄŸer maliyet fonksiyonunuz tÃ¼revlenebilir ise, herhangi bir hesaplama yapmanÄ±z gerekmez.

**Ã–zel bir amaÃ§ fonksiyonu oluÅŸturmak, matematiksel bilgi ve Ã§ok fazla Ã§aba gerektirir**, ancak bunu baÅŸarmak, Kaggle yarÄ±ÅŸmalarÄ±nda modelinizden maksimum sonucu almanÄ±zda gerÃ§ekten belirleyici olabilir.

EÄŸer kendi amaÃ§ fonksiyonunuzu oluÅŸturmak iÅŸe yaramazsa, daha az iddialÄ± olabilirsiniz, fonksiyonu **deÄŸerlendirme metriÄŸi** olarak kullanarak bunu doÄŸrudan **optimizer** iÃ§inde kullanmak yerine, bir **Ã¶zel deÄŸerlendirme metriÄŸi** olarak kodlayabilirsiniz. Modeliniz bu fonksiyonla doÄŸrudan optimize edilmemiÅŸ olsa da, yine de hiperparametre optimizasyonu yaparak tahmin performansÄ±nÄ± iyileÅŸtirebilirsiniz. Bu, Ã¶nceki bÃ¶lÃ¼mde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z ikinci seÃ§enektir.

EÄŸer sÄ±fÄ±rdan bir metrik yazÄ±yorsanÄ±z, bazen fonksiyonunuzun dÃ¼zgÃ¼n Ã§alÄ±ÅŸabilmesi iÃ§in belirli kodlama kurallarÄ±na uymanÄ±z gerektiÄŸini unutmayÄ±n. Ã–rneÄŸin, **Scikit-learn** kullanÄ±yorsanÄ±z, fonksiyonlarÄ±nÄ±zÄ± **make_scorer** fonksiyonu ile dÃ¶nÃ¼ÅŸtÃ¼rmeniz gerekir. **make_scorer** fonksiyonu, deÄŸerlendirme fonksiyonunuzu **Scikit-learn** API'si ile uyumlu hale getiren bir sarmalayÄ±cÄ±dÄ±r. Bu fonksiyon, bazÄ± meta-bilgileri dikkate alarak fonksiyonunuzu sarar, Ã¶rneÄŸin, tahminler iÃ§in eÅŸik belirleme gerekip gerekmediÄŸi veya optimizasyonun yÃ¶nÃ¼ (skoru maksimize etmek mi yoksa minimize etmek mi istediÄŸiniz gibi):

```python
from sklearn.metrics import make_scorer
from sklearn.metrics import average_precision_score

scorer = make_scorer(average_precision_score, 
                     average='weighted', greater_is_better=True, needs_proba=False)
```

YukarÄ±daki Ã¶rnekte, **average_precision_score** metriÄŸi kullanÄ±larak bir scorer hazÄ±rlanmÄ±ÅŸtÄ±r, burada Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma problemleriyle Ã§alÄ±ÅŸÄ±rken **weighted** hesaplama kullanÄ±lmasÄ± gerektiÄŸi belirtilmiÅŸtir.

> DeÄŸerlendirme metriÄŸinizi optimize ediyorsanÄ±z, **grid search**, **random search** veya daha sofistike optimizasyon tekniklerini, Ã¶rneÄŸin **Bayesian optimizasyonu** kullanarak hiperparametrelerinizi optimize edebilir ve algoritmanÄ±zÄ±, farklÄ± bir maliyet fonksiyonu kullanÄ±yor olsa bile, deÄŸerlendirme metriÄŸi iÃ§in en iyi performansÄ± gÃ¶sterecek ÅŸekilde parametreleri bulabilirsiniz. Model doÄŸrulamasÄ±nÄ± tartÄ±ÅŸtÄ±ktan sonra, Kaggle yarÄ±ÅŸmalarÄ±nda parametre optimizasyonunu nasÄ±l en iyi ÅŸekilde dÃ¼zenleyeceÄŸimizi ve en iyi sonuÃ§larÄ± nasÄ±l alacaÄŸÄ±mÄ±zÄ± inceleyeceÄŸiz.

### Post-processing your predictions *(Tahminleri sonradan iÅŸleme)*

**Post-processing ayarlamasÄ±**, tahminlerinizin, bir fonksiyon aracÄ±lÄ±ÄŸÄ±yla, daha iyi bir deÄŸerlendirme sunacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesini ifade eder. Kendi Ã¶zel kayÄ±p fonksiyonunuzu oluÅŸturduktan veya deÄŸerlendirme metriÄŸi iÃ§in optimize ettikten sonra, tahminleriniz Ã¼zerinde belirli bir fonksiyon kullanarak deÄŸerlendirme kriterinize uygun sonuÃ§lar elde etmek iÃ§in de performansÄ±nÄ±zÄ± artÄ±rabilirsiniz. Ã–rneÄŸin, **Quadratic Weighted Kappa** metriÄŸinden bahsedelim. Daha Ã¶nce bu metrik, **ordinal deÄŸer** tahminlerinde kullanÄ±ÅŸlÄ± olduÄŸunu belirtmiÅŸtik. KÄ±saca hatÄ±rlamak gerekirse, orijinal **Kappa katsayÄ±sÄ±**, algoritma ile gerÃ§ek etiket arasÄ±ndaki uyumun, ÅŸansÄ±n etkisiyle dÃ¼zeltilmiÅŸ bir Ã¶lÃ§Ã¼sÃ¼dÃ¼r. Bu, tahmin ile gerÃ§ek etiket arasÄ±ndaki eÅŸleÅŸmenin, ÅŸans sonucu olup olmadÄ±ÄŸÄ±nÄ±n olasÄ±lÄ±klarÄ± ile dÃ¼zeltilmiÅŸ bir doÄŸruluk Ã¶lÃ§Ã¼sÃ¼dÃ¼r.

Ä°ÅŸte Ã¶nceki bÃ¶lÃ¼mlerde gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z orijinal **Kappa katsayÄ±sÄ±** formÃ¼lÃ¼:

$$
\kappa = \frac{p_0 - p_e}{1 - p_e}
$$

FormÃ¼lde, **p0**, deÄŸerlendirenler arasÄ±ndaki gÃ¶zlemlenen gÃ¶reli uyumu, **pe** ise ÅŸansla olan uyum olasÄ±lÄ±ÄŸÄ±nÄ± ifade eder. Burada sadece iki matrise ihtiyacÄ±nÄ±z vardÄ±r: birisi gÃ¶zlemlenen puanlarla, diÄŸeri ise ÅŸansla uyumlu beklenen puanlarla. Kappa katsayÄ±sÄ± aÄŸÄ±rlÄ±klÄ± olduÄŸunda, ayrÄ±ca bir aÄŸÄ±rlÄ±k matrisi de dikkate alÄ±nÄ±r ve formÃ¼l ÅŸu hale gelir:

$$
\kappa = \frac{p_0 - p_e}{1 - p_e} \times p_p
$$

**pp** matrisi, hatalarÄ± farklÄ± ÅŸekilde aÄŸÄ±rlamak iÃ§in cezalandÄ±rmalarÄ± iÃ§erir ve bu, **ordinal tahminlerde** oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r Ã§Ã¼nkÃ¼ bu matris, tahminler gerÃ§ek etiketlerden daha fazla saparsa Ã§ok daha fazla ceza verebilir. **Kareli formu** kullanmak, yani sonucu kareye almak, cezalandÄ±rmayÄ± daha da ÅŸiddetli hale getirir. Ancak, bÃ¶yle bir metriÄŸi optimize etmek gerÃ§ekten kolay deÄŸildir, Ã§Ã¼nkÃ¼ bunu bir maliyet fonksiyonu olarak uygulamak oldukÃ§a zordur. Ä°ÅŸte burada **post-processing** yardÄ±ma gelir.

Bir Ã¶rnek, **PetFinder.my Adoption Prediction** yarÄ±ÅŸmasÄ±nda bulunabilir ([Kaggle YarÄ±ÅŸmasÄ±](https://www.kaggle.com/c/petfinder-adoption-prediction)). Bu yarÄ±ÅŸmada, sonuÃ§lar 5 olasÄ± puana sahip olabilirdi (0, 1, 2, 3 veya 4), bunlarÄ± ya bir sÄ±nÄ±flandÄ±rma olarak ya da bir regresyon olarak ele alabilirsiniz. EÄŸer bir regresyon kullanÄ±yorsanÄ±z, regresyon sonuÃ§larÄ±nÄ±n post-processing dÃ¶nÃ¼ÅŸÃ¼mÃ¼, **Quadratic Weighted Kappa** metriÄŸi karÅŸÄ±sÄ±nda modelinizin performansÄ±nÄ± iyileÅŸtirebilir, bu da doÄŸrudan **sÄ±nÄ±flandÄ±rma** ile yapÄ±lan tahminlerden daha iyi sonuÃ§lar verebilir.

**PetFinder** yarÄ±ÅŸmasÄ±nda post-processing, regresyon sonuÃ§larÄ±nÄ± Ã¶nce [0.5, 1.5, 2.5, 3.5] sÄ±nÄ±rlarÄ±nÄ± kullanarak tam sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmekle baÅŸlayarak, daha iyi bir sÄ±nÄ±r seti bulmak iÃ§in iteratif ince ayar yapmayÄ± iÃ§eren bir optimizasyon sÃ¼recinden oluÅŸuyordu. Bu sÄ±nÄ±rlarÄ±n ince ayarÄ±, **SciPy optimize.minimize** gibi bir optimizasyon aracÄ±nÄ±n kullanÄ±lmasÄ±yla yapÄ±lmÄ±ÅŸtÄ±r ve bu, **Nelder-Mead algoritmasÄ±**na dayanmaktadÄ±r. Optimizasyon aracÄ± tarafÄ±ndan bulunan sÄ±nÄ±rlar, bir **cross-validation** ÅŸemasÄ±yla doÄŸrulandÄ±. Bu post-processing hakkÄ±nda daha fazla detayÄ±, yarÄ±ÅŸma sÄ±rasÄ±nda **Abhishek Thakur** tarafÄ±ndan yapÄ±lan ÅŸu gÃ¶nderide okuyabilirsiniz: [PetFinder Post-Processing Discussion](https://www.kaggle.com/c/petfinder-adoption-prediction/discussion/76107).

> **PetFinder** yarÄ±ÅŸmasÄ± dÄ±ÅŸÄ±nda, birÃ§ok diÄŸer yarÄ±ÅŸma, akÄ±llÄ± post-processing'in daha iyi sonuÃ§lar ve sÄ±ralamalarla sonuÃ§lanabileceÄŸini gÃ¶stermiÅŸtir. Ä°ÅŸte bazÄ± Ã¶rnekler:
> 
> 
> 
> * [https://www.kaggle.com/khoongweihao/post-processing-technique-c-f-1st-place-jigsaw](https://www.kaggle.com/khoongweihao/post-processing-technique-c-f-1st-place-jigsaw)
> 
> * [https://www.kaggle.com/tomooinubushi/postprocessing-based-on-leakage](https://www.kaggle.com/tomooinubushi/postprocessing-based-on-leakage)
> 
> * [https://www.kaggle.com/saitodevel01/indoor-post-processing-by-cost-minimization](https://www.kaggle.com/saitodevel01/indoor-post-processing-by-cost-minimization)

Ne yazÄ±k ki, **post-processing** Ã§oÄŸunlukla kullandÄ±ÄŸÄ±nÄ±z metriÄŸe baÄŸlÄ±dÄ±r (metriÄŸi anlamak, iyi bir post-processing tasarlamak iÃ§in Ã§ok Ã¶nemlidir) ve genellikle veriye Ã¶zgÃ¼dÃ¼r; Ã¶rneÄŸin, zaman serisi verileri ve sÄ±zÄ±ntÄ±lar gibi durumlarda. Bu nedenle, herhangi bir yarÄ±ÅŸma iÃ§in doÄŸru post-processing yÃ¶ntemini bulmak Ã§ok zordur. Yine de, her zaman bu olasÄ±lÄ±ÄŸÄ±n farkÄ±nda olun ve bir yarÄ±ÅŸmada post-processing'in sonuÃ§larÄ± iyileÅŸtirdiÄŸine dair herhangi bir ipucu arayÄ±n. Benzer yarÄ±ÅŸmalarda daha Ã¶nceki post-processing ile ilgili her zaman ipuÃ§larÄ± bulabilirsiniz ve forum tartÄ±ÅŸmalarÄ± yoluyla â€“ eninde sonunda biri bu konuyu gÃ¼ndeme getirecektir.

### Predicted probability and its adjustment *(Tahmin edilen olasÄ±lÄ±ÄŸÄ±n ayarlanmasÄ±)*

YukarÄ±daki tartÄ±ÅŸmamÄ±zÄ± tamamlamak iÃ§in, doÄŸru **olasÄ±lÄ±klarÄ±** tahmin etmenin Ã§ok Ã¶nemli olduÄŸu durumlarÄ± ele alacaÄŸÄ±z, ancak kullandÄ±ÄŸÄ±nÄ±z algoritmanÄ±n bu iÅŸi iyi yapÄ±p yapmadÄ±ÄŸÄ±ndan emin olamÄ±yorsunuz. Daha Ã¶nce ayrÄ±ntÄ±lÄ± olarak aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z gibi, **sÄ±nÄ±flandÄ±rma olasÄ±lÄ±klarÄ±** hem ikili hem de Ã§oklu sÄ±nÄ±f sÄ±nÄ±flandÄ±rma problemleriyle ilgilidir ve genellikle **logaritmik kayÄ±p** (diÄŸer adÄ±yla log loss, lojistik kayÄ±p veya Ã§apraz entropi kaybÄ±) kullanÄ±larak deÄŸerlendirilir ve optimize edilir (daha fazla ayrÄ±ntÄ± iÃ§in, sÄ±nÄ±flandÄ±rma metrikleri ve Ã§oklu sÄ±nÄ±f sÄ±nÄ±flandÄ±rma metrikleri baÅŸlÄ±klarÄ±ndaki Ã¶nceki bÃ¶lÃ¼mlere bakabilirsiniz).

Ancak, sadece log kaybÄ± ile deÄŸerlendirme yapmak veya optimize etmek yeterli olmayabilir. DoÄŸru olasÄ±lÄ±k tahminleri elde etmeye Ã§alÄ±ÅŸÄ±rken dikkat etmeniz gereken ana sorunlar ÅŸunlardÄ±r:

* GerÃ§ekten olasÄ±lÄ±k tahmini yapmayan modeller
* Probleminizde sÄ±nÄ±flarÄ±n dengesiz daÄŸÄ±lÄ±mÄ±
* EÄŸitim veriniz ile test veriniz (hem public hem de private leaderboardâ€™lar) arasÄ±nda farklÄ± sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±

Ä°lk madde, modelinizin **belirtilen belirsizliÄŸe gÃ¶re sÄ±nÄ±flandÄ±rma tahminlerinin kalitesini** kontrol etme ve doÄŸrulama gerekliliÄŸini tek baÅŸÄ±na saÄŸlamaktadÄ±r. AslÄ±nda, **Scikit-learn** paketinde birÃ§ok algoritma, **predict_proba** yÃ¶ntemi ile birlikte sunulsa da, bu, gerÃ§ek bir olasÄ±lÄ±k dÃ¶ndÃ¼recekleri konusunda zayÄ±f bir teminattÄ±r.

Ã–rneÄŸin, **karar aÄŸaÃ§larÄ±nÄ±** ele alalÄ±m. Karar aÄŸaÃ§larÄ±, tabular verileri modellemek iÃ§in oldukÃ§a etkili bir yÃ¶ntemdir ve **Scikit-learn**â€™deki sÄ±nÄ±flandÄ±rma karar aÄŸaÃ§larÄ±, terminal yapraklarÄ±na dayalÄ± olarak tahminler yapar. Yani, tahmin edilen olasÄ±lÄ±k, tahmin edilecek Ã¶rneÄŸin bulunduÄŸu yapraÄŸÄ±n sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±na dayanÄ±r. EÄŸer aÄŸaÃ§ tamamen bÃ¼yÃ¼tÃ¼lmÃ¼ÅŸse, Ã¶rneÄŸin Ã§ok kÃ¼Ã§Ã¼k bir yapraya sahip olma olasÄ±lÄ±ÄŸÄ± yÃ¼ksektir ve bu da tahmin edilen olasÄ±lÄ±ÄŸÄ±n Ã§ok yÃ¼ksek olmasÄ±na yol aÃ§ar. **max_depth**, **max_leaf_nodes** veya **min_samples_leaf** gibi parametreleri deÄŸiÅŸtirirseniz, aÄŸacÄ±n bÃ¼yÃ¼mesine baÄŸlÄ± olarak tahmin edilen olasÄ±lÄ±k bÃ¼yÃ¼k Ã¶lÃ§Ã¼de deÄŸiÅŸir.

Karar aÄŸaÃ§larÄ±, **bagging** modelleri ve **random forest** gibi topluluk modelleri iÃ§in en yaygÄ±n temel modeldir, ayrÄ±ca **gradient boosting** modelleri (Ã¶rneÄŸin, **XGBoost**, **LightGBM**, ve **CatBoost**) de karar aÄŸaÃ§larÄ±nÄ± kullanÄ±r. Ancak, aynÄ± sebeplerden dolayÄ±â€”gerÃ§ekten saÄŸlam olasÄ±lÄ±k tahminleri yapmayan olasÄ±lÄ±k tahminleriâ€”bu sorun, **destek vektÃ¶r makineleri** (SVM) ve **k-en yakÄ±n komÅŸu** (k-NN) gibi yaygÄ±n olarak kullanÄ±lan diÄŸer modelleri de etkiler. Bu konular, **Otto Group Product Classification Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/otto-group-product-classification-challenge/overview/](https://www.kaggle.com/c/otto-group-product-classification-challenge/overview/)) **Christophe Bourguignat** ve diÄŸerleri tarafÄ±ndan gÃ¼ndeme getirildiÄŸinde, **Scikit-learn**â€™e yeni eklenen **kalibrasyon fonksiyonlarÄ±** kullanÄ±larak kolayca Ã§Ã¶zÃ¼ldÃ¼.

KullanacaÄŸÄ±nÄ±z model dÄ±ÅŸÄ±nda, probleminizdeki sÄ±nÄ±flar arasÄ±nda dengesizlik bulunmasÄ±, modellerinizin hiÃ§ gÃ¼venilir olmamasÄ±na yol aÃ§abilir. Bu nedenle, dengesiz sÄ±nÄ±flandÄ±rma problemlerinde iyi bir yaklaÅŸÄ±m, **undersampling** veya **oversampling** stratejileri kullanarak sÄ±nÄ±flarÄ± dengelemektir; ya da her sÄ±nÄ±f iÃ§in kaybÄ± hesaplanÄ±rken algoritmanÄ±n uygulayacaÄŸÄ± **Ã¶zel aÄŸÄ±rlÄ±klar** belirlemektir. Bu stratejiler modelinizi daha performanslÄ± hale getirebilir, ancak kesinlikle olasÄ±lÄ±k tahminlerinizi bozarlar ve bu tahminleri, leaderboard'da daha iyi bir model skoru elde etmek iÃ§in ayarlamanÄ±z gerekebilir.

Son olarak, Ã¼Ã§Ã¼ncÃ¼ Ã¶nemli nokta, **test seti**nin nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ± ile ilgilidir. Bu tÃ¼r bilgiler genellikle gizli tutulur, ancak Ã§oÄŸu zaman bunu tahmin etmenin yollarÄ± vardÄ±r (Ã¶rneÄŸin, **public leaderboard** sonuÃ§larÄ±na dayalÄ± deneme yanÄ±lma yÃ¶ntemi kullanarak, **BÃ¶lÃ¼m 1**'de **Kaggle ve Veri Bilimi YarÄ±ÅŸmalarÄ±nÄ± TanÄ±tmak** baÅŸlÄ±ÄŸÄ±nda bahsettiÄŸimiz gibi).

Ã–rneÄŸin, bu durum, **iMaterialist Furniture Challenge** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/imaterialist-challenge-furniture-2018/](https://www.kaggle.com/c/imaterialist-challenge-furniture-2018/)) ve daha popÃ¼ler olan **Quora Question Pairs** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/quora-question-pairs](https://www.kaggle.com/c/quora-question-pairs)) yaÅŸanmÄ±ÅŸtÄ±r. Her iki yarÄ±ÅŸma da, test beklentilerine uygun olasÄ±lÄ±klarÄ± ayarlamak iÃ§in **post-processing** yapmanÄ±n nasÄ±l olacaÄŸÄ±na dair Ã§eÅŸitli tartÄ±ÅŸmalar yaratmÄ±ÅŸtÄ±r (bu metodun kullanÄ±ldÄ±ÄŸÄ±na dair daha fazla bilgi iÃ§in [Burada](https://swarbrickjones.wordpress.com/2017/03/28/cross-entropy-and-training-test-class-imbalance/) ve [Burada](https://www.kaggle.com/dowakin/probability-calibration-0-005-to-lb) tartÄ±ÅŸmalarÄ± bulabilirsiniz). Genel bir bakÄ±ÅŸ aÃ§Ä±sÄ±yla, sÄ±nÄ±flarÄ± tahmin etmek iÃ§in test daÄŸÄ±lÄ±mÄ± hakkÄ±nda bir fikriniz olmasa bile, **eÄŸitim verilerinden aldÄ±ÄŸÄ±nÄ±z Ã¶ncÃ¼lleri** kullanarak doÄŸru olasÄ±lÄ±k tahmin etmek hala Ã§ok faydalÄ±dÄ±r (ve karÅŸÄ±t bir delil elde edene kadar, bu, modelinizin taklit etmesi gereken olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±dÄ±r). GerÃ§ekten de, tahmin edilen olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ±z, eÄŸitim setindekilerle uyuÅŸuyorsa, tahmin edilen olasÄ±lÄ±klarÄ± dÃ¼zeltmek Ã§ok daha kolay olacaktÄ±r.

Tahmin edilen olasÄ±lÄ±klarÄ±n, hedefin eÄŸitim daÄŸÄ±lÄ±mÄ±yla uyumsuz olduÄŸu durumdaki Ã§Ã¶zÃ¼m, **Scikit-learn** tarafÄ±ndan saÄŸlanan **calibration fonksiyonunu** kullanmaktÄ±r:

```python
sklearn.calibration.CalibratedClassifierCV(base_estimator=None, *, method='sigmoid', cv=None, n_jobs=None, ensemble=True)
```

Kalibrasyon fonksiyonunun amacÄ±, tahmin edilen olasÄ±lÄ±klarÄ±nÄ±za bir **post-processing** fonksiyonu uygulayarak onlarÄ±, gerÃ§ek etiketlerde gÃ¶zlemlenen ampirik olasÄ±lÄ±klarla daha yakÄ±n hale getirmektir. Modeliniz **Scikit-learn** tabanlÄ±ysa veya ona benzer ÅŸekilde Ã§alÄ±ÅŸÄ±yorsa, fonksiyon, modelinizi sarmalayacak ve tahminlerini doÄŸrudan bir post-processing fonksiyonuna yÃ¶nlendirecektir. Post-processing iÃ§in iki yÃ¶ntem arasÄ±ndan seÃ§im yapabilirsiniz: ilki **sigmoid** yÃ¶ntemi (diÄŸer adÄ±yla **Platâ€™s scaling**), bu sadece bir **lojistik regresyon**dur. Ä°kinci yÃ¶ntem ise **izotonik regresyon**, parametrik olmayan bir regresyondur; ancak dikkat edin, eÄŸer Ã¶rnek sayÄ±sÄ± azsa aÅŸÄ±rÄ± Ã¶ÄŸrenmeye yatkÄ±ndÄ±r.

Bu kalibratÃ¶rÃ¼ nasÄ±l fit edeceÄŸinizi de seÃ§meniz gerekir. UnutmayÄ±n ki bu bir modeldir ve modelinizin sonuÃ§larÄ±na uygulanÄ±r, bu yÃ¼zden tahminlerinizi sistematik olarak yeniden iÅŸlemekten kaÃ§Ä±narak aÅŸÄ±rÄ± Ã¶ÄŸrenmeden kaÃ§Ä±nmalÄ±sÄ±nÄ±z. **Cross-validation** kullanabilir ve bir dizi model Ã¼reterek, bunlarÄ± ortalayÄ±p tahminlerinizi elde edebilirsiniz (**ensemble=True**). Aksi takdirde, genellikle bizim tercih ettiÄŸimiz yaklaÅŸÄ±m, **out-of-fold** tahminini kullanmak ve tÃ¼m mevcut verilerle bunu kalibre etmektir (**ensemble=False**).

**CalibratedClassifierCV**, Ã§oÄŸu durumu yÃ¶netebilecek olsa da, en iyi performansÄ± test zamanÄ±nda elde etmek iÃ§in olasÄ±lÄ±k tahminlerini dÃ¼zeltmenin ampirik bir yolunu da keÅŸfetebilirsiniz. Kendi baÅŸÄ±nÄ±za geliÅŸtirilmiÅŸ herhangi bir dÃ¶nÃ¼ÅŸÃ¼m fonksiyonunu, hatta genetik algoritmalarla tÃ¼retilmiÅŸ sofistike bir fonksiyonu kullanabilirsiniz. Tek sÄ±nÄ±rÄ±nÄ±z, bunu **cross-validation** ile test etmeniz ve **public leaderboard'dan iyi bir sonuÃ§** almanÄ±zdÄ±r (ancak kesinlikle gerekli deÄŸildir, Ã§Ã¼nkÃ¼ **yerel cross-validation** skoru daha gÃ¼venilir olmalÄ±dÄ±r, bunu bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸacaÄŸÄ±z). BÃ¶yle bir stratejinin iyi bir Ã¶rneÄŸini, **Silogram** ([https://www.kaggle.com/psilogram](https://www.kaggle.com/psilogram)) **Microsoft Malware Classification Challenge** yarÄ±ÅŸmasÄ±nda bulmuÅŸ ve **random forests** algoritmasÄ±nÄ±n gÃ¼venilir olmayan olasÄ±lÄ±k Ã§Ä±ktÄ±larÄ±nÄ±n Ã¼zerine, **grid search** ile belirlenen bir gÃ¼Ã§ uygulayarak olasÄ±lÄ±klarÄ±nÄ± doÄŸru hale getirmiÅŸtir (daha fazla bilgi iÃ§in [Burada](https://www.kaggle.com/c/malware-classification/discussion/13509) bulabilirsiniz).

> **Sudalai Rajkumar**
> 
> [https://www.kaggle.com/sudalairajkumar](https://www.kaggle.com/sudalairajkumar)
> 
> 
> 
> BÃ¶lÃ¼mÃ¼mÃ¼zÃ¼n son rÃ¶portajÄ±nda, yarÄ±ÅŸmalarda, veri setlerinde ve not defterlerinde Grandmaster olan Sudalai Rajkumar (SRK) ile konuÅŸuyoruz. Analytics Vidhya veri bilimi platformunda #1 sÄ±ralamasÄ±na sahip olan SRK, ÅŸu anda start-upâ€™lar iÃ§in bir AI/ML danÄ±ÅŸmanÄ± olarak Ã§alÄ±ÅŸÄ±yor.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Kaggle'daki teknikleriniz ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ±nÄ±z hakkÄ±nda ne sÃ¶ylersiniz?**
> 
> 
> 
> Favori yarÄ±ÅŸmalarÄ±m, iyi bir Ã¶zellik mÃ¼hendisliÄŸi gerektiren yarÄ±ÅŸmalardÄ±r. Bu da benim gÃ¼Ã§lÃ¼ yÃ¶nÃ¼m diyebilirim. Genellikle, veriyi derinlemesine anlamak iÃ§in veri keÅŸfi yapmaktan ilgi duyuyorum (bunu, basit keÅŸif Not defterlerimden [https://www.kaggle.com/sudalairajkumar/code](https://www.kaggle.com/sudalairajkumar/code) gÃ¶rebilirsiniz) ve sonrasÄ±nda bu veriye dayalÄ± Ã¶zellikler yaratÄ±yorum.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±dÄ±r?**
> 
> 
> 
> Bir yarÄ±ÅŸma iÃ§in genel Ã§erÃ§eve, veri keÅŸfi, doÄŸru doÄŸrulama yÃ¶ntemini bulma, Ã¶zellik mÃ¼hendisliÄŸi, model kurma ve toplama/katmanlama (ensembling/stacking) aÅŸamalarÄ±nÄ± iÃ§erir. Bunlar gÃ¼nlÃ¼k iÅŸimde de yer alÄ±r. Ancak, gÃ¼nlÃ¼k iÅŸimde bunun dÄ±ÅŸÄ±nda daha fazla paydaÅŸ gÃ¶rÃ¼ÅŸmesi, veri toplama, veri etiketleme, model daÄŸÄ±tÄ±mÄ±, model izleme ve veri hikayeleÅŸtirme gibi unsurlar da vardÄ±r.
> 
> 
> 
> **GirdiÄŸiniz Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu zorluÄŸu nasÄ±l aÅŸtÄ±ÄŸÄ±nÄ±zdan bahseder misiniz?**
> 
> 
> 
> Santander ÃœrÃ¼n Ã–nerisi, girdiÄŸimiz hatÄ±rladÄ±ÄŸÄ±m bir yarÄ±ÅŸmadÄ±r. Rohan ile birlikte Ã§ok fazla Ã¶zellik mÃ¼hendisliÄŸi yaptÄ±k ve birden fazla model kurduk. Final toplama aÅŸamasÄ±nda, farklÄ± Ã¼rÃ¼nler iÃ§in farklÄ± aÄŸÄ±rlÄ±klar kullandÄ±k ve bazÄ±larÄ± toplamda 1â€™e eÅŸit deÄŸildi. Veri keÅŸfi ve anlayÄ±ÅŸÄ±ndan yola Ã§Ä±karak bu aÄŸÄ±rlÄ±klarÄ± manuel olarak seÃ§tik ve bu bize yardÄ±mcÄ± oldu. Bu deneyim, veri biliminin bilim olduÄŸu kadar bir sanat olduÄŸunu ve verinin/alanÄ±n problemleri Ã§Ã¶zmedeki Ã¶nemini anlamamÄ±za yardÄ±mcÄ± oldu.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? YardÄ±mcÄ± olduysa nasÄ±l?**
> 
> 
> 
> Kaggle kariyerimde Ã§ok Ã¶nemli bir rol oynadÄ±. Son iki iÅŸimi, bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Kaggle sayesinde kazandÄ±m. AyrÄ±ca, Kaggle'daki baÅŸarÄ±larÄ±m, veri bilimi alanÄ±ndaki diÄŸer Ã¶nemli kiÅŸilerle kolayca baÄŸlantÄ± kurmama ve onlardan Ã¶ÄŸrenmeme yardÄ±mcÄ± oldu. Åu anki AI/ML danÄ±ÅŸmanlÄ±k rolÃ¼mde de, Kaggleâ€™daki baÅŸarÄ±larÄ±m bÃ¼yÃ¼k bir gÃ¼venilirlik saÄŸlÄ±yor.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ±nÄ±n genellikle gÃ¶z ardÄ± ettiÄŸi ÅŸeyler nedir? BaÅŸlangÄ±Ã§ta bilseydiniz ÅŸimdi neyi farklÄ± yapardÄ±nÄ±z?**
> 
> 
> 
> Veriyi derinlemesine anlamak. Ã‡oÄŸu zaman insanlar hemen model kurmaya baÅŸlÄ±yorlar. Oysa veri keÅŸfi yapmak, herhangi bir Kaggle yarÄ±ÅŸmasÄ±nÄ±n baÅŸarÄ±sÄ± iÃ§in Ã§ok Ã¶nemli bir rol oynar. Bu, doÄŸru Ã§apraz doÄŸrulama yapmanÄ±za, daha iyi Ã¶zellikler oluÅŸturmanÄ±za ve veriden daha fazla deÄŸer elde etmenize yardÄ±mcÄ± olur.
> 
> 
> 
> **GeÃ§miÅŸte katÄ±ldÄ±ÄŸÄ±nÄ±z yarÄ±ÅŸmalarda hangi hatalarÄ± yaptÄ±nÄ±z?**
> 
> 
> 
> Ã‡ok uzun bir liste var, ama bunlar Ã¶ÄŸrenme fÄ±rsatlarÄ±ydÄ±. Her yarÄ±ÅŸmada, denediÄŸim 20-30 fikirden sadece biri iÅŸe yarayabiliyor. Bu hatalar/baÅŸarÄ±sÄ±zlÄ±klar, gerÃ§ek baÅŸarÄ±dan veya iÅŸe yarayan ÅŸeylerden Ã§ok daha fazla Ã¶ÄŸretici oldu. Ã–rneÄŸin, Ã§ok fazla overfitting (aÅŸÄ±rÄ± uyum saÄŸlama) yapmayÄ± birinci yarÄ±ÅŸmamda Ã¶ÄŸrendim; baÅŸlangÄ±Ã§taki en iyi sÄ±ralamalardan, en kÃ¶tÃ¼ sÄ±ralamalara dÃ¼ÅŸmÃ¼ÅŸtÃ¼m. Ama bu ders, hayatÄ±m boyunca benimle kaldÄ±.
> 
> 
> 
> **Veri analizi/makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> 
> 
> Tabular (tablosal) veriler iÃ§in genellikle XGBoost/LightGBM kullanÄ±yorum. Son zamanlarda, erken benchmark (ilk performans testi) almak iÃ§in aÃ§Ä±k kaynak AutoML kÃ¼tÃ¼phaneleri ve Driverless AI de kullanÄ±yorum. Derin Ã¶ÄŸrenme modelleri iÃ§in ise Keras, Transformers ve PyTorch kullanÄ±yorum.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya girerken, birinin aklÄ±nda tutmasÄ± veya yapmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> 
> 
> TutarlÄ±lÄ±k en Ã¶nemli ÅŸeydir. Her yarÄ±ÅŸmanÄ±n kendi iniÅŸ Ã§Ä±kÄ±ÅŸlarÄ± olacaktÄ±r. BirkaÃ§ gÃ¼n boyunca hiÃ§ ilerleme kaydedemeyebilirsiniz, ama pes etmemeli ve denemeye devam etmelisiniz. Bu sadece Kaggle yarÄ±ÅŸmalarÄ± iÃ§in deÄŸil, her ÅŸey iÃ§in geÃ§erlidir.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ±nÄ± kullanÄ±yor musunuz? Bunlar Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r?**
> 
> 
> 
> Analytics Vidhya DataHack platformu, Driven Data, CrowdAnalytix gibi diÄŸer platformlarda da yer aldÄ±m. Onlar da oldukÃ§a iyi, ama Kaggle daha geniÅŸ Ã§apta kabul gÃ¶rmÃ¼ÅŸ ve kÃ¼resel bir platform olduÄŸu iÃ§in, diÄŸer platformlarla karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda Kaggleâ€™daki rekabet daha yÃ¼ksektir.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggle yarÄ±ÅŸmalarÄ±ndaki deÄŸerlendirme metriklerini tartÄ±ÅŸtÄ±k. Ä°lk olarak, bir deÄŸerlendirme metriÄŸinin objektif fonksiyondan nasÄ±l farklÄ± olabileceÄŸini aÃ§Ä±kladÄ±k. AyrÄ±ca, regresyon ve sÄ±nÄ±flandÄ±rma problemleri arasÄ±ndaki farklara da deÄŸindik. Her bir problem tÃ¼rÃ¼ iÃ§in, Kaggle yarÄ±ÅŸmalarÄ±nda karÅŸÄ±nÄ±za Ã§Ä±kabilecek en yaygÄ±n metrikleri inceledik.

SonrasÄ±nda, daha Ã¶nce hiÃ§bir yarÄ±ÅŸmada karÅŸÄ±laÅŸÄ±lmamÄ±ÅŸ ve muhtemelen bir daha karÅŸÄ±laÅŸmayacaÄŸÄ±nÄ±z metrikleri ele aldÄ±k. Son olarak, farklÄ± yaygÄ±n metrikleri inceledik ve bunlarÄ±n Ã¶nceki Kaggle yarÄ±ÅŸmalarÄ±nda nasÄ±l kullanÄ±ldÄ±ÄŸÄ±na dair Ã¶rnekler verdik. ArdÄ±ndan, bir deÄŸerlendirme metriÄŸini optimize etmek iÃ§in birkaÃ§ strateji Ã¶nerdik. Ã–zellikle, kendi Ã¶zel maliyet fonksiyonlarÄ±nÄ±zÄ± kodlamayÄ± denemenizi Ã¶nerdik ve faydalÄ± olabilecek bazÄ± son iÅŸleme adÄ±mlarÄ± hakkÄ±nda tavsiyelerde bulunduk.

Åimdi, bir deÄŸerlendirme metriÄŸinin Kaggle yarÄ±ÅŸmasÄ±ndaki rolÃ¼nÃ¼ kavramÄ±ÅŸ olmalÄ±sÄ±nÄ±z. AyrÄ±ca, geÃ§miÅŸ yarÄ±ÅŸmalarÄ± inceleyerek ve bir metriÄŸin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± tam anlamak suretiyle her yaygÄ±n veya yaygÄ±n olmayan metriÄŸi nasÄ±l ele alacaÄŸÄ±nÄ±z konusunda bir stratejiniz olmalÄ±. Bir sonraki bÃ¶lÃ¼mde, deÄŸerlendirme metriklerini nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± ve Kaggle Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼n performansÄ±nÄ± dÃ¼zgÃ¼n bir ÅŸekilde nasÄ±l tahmin edeceÄŸimizi, bir doÄŸrulama stratejisi aracÄ±lÄ±ÄŸÄ±yla tartÄ±ÅŸacaÄŸÄ±z.

---

## Chapter 6: Designing Good Validation *(BÃ¶lÃ¼m 6: Ä°yi Bir DoÄŸrulama Sistemi Tasarlama)*

Bir Kaggle yarÄ±ÅŸmasÄ±nda, modelleme yaparken ve sonuÃ§larÄ± gÃ¶nderdikten sonra, liderlik tablosundan aldÄ±ÄŸÄ±nÄ±z sonuÃ§larÄ± yÃ¼zeysel bir ÅŸekilde kabul etmek yeterli gibi gÃ¶rÃ¼nebilir. SonuÃ§ta, bir yarÄ±ÅŸmada Ã¶nemli olanÄ±n sÄ±ralamanÄ±z olduÄŸunu dÃ¼ÅŸÃ¼nebilirsiniz. Bu, yarÄ±ÅŸmalarda sÄ±kÃ§a yapÄ±lan ve tekrarlanan yaygÄ±n bir hatadÄ±r. GerÃ§ekte, yarÄ±ÅŸma sona erene kadar gerÃ§ek liderlik tablosunun (Ã¶zel olan) nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ bilemezsiniz ve bunun yerine yalnÄ±zca halka aÃ§Ä±k olan kÄ±smÄ±na gÃ¼venmek tavsiye edilmez, Ã§Ã¼nkÃ¼ bu genellikle yanÄ±ltÄ±cÄ± olabilir.

Bu bÃ¶lÃ¼mde, veri yarÄ±ÅŸmalarÄ±nda doÄŸrulamanÄ±n Ã¶nemini tanÄ±tacaÄŸÄ±z. ÅunlarÄ± Ã¶ÄŸreneceksiniz:

* AÅŸÄ±rÄ± uyum (overfitting) nedir ve bir halka aÃ§Ä±k liderlik tablosu nasÄ±l yanÄ±ltÄ±cÄ± olabilir?
* KorkunÃ§ sÄ±ralama deÄŸiÅŸiklikleri (shake-ups)
* FarklÄ± doÄŸrulama stratejileri
* Adversarial doÄŸrulama
* SÄ±zÄ±ntÄ±larÄ± nasÄ±l tespit edebilir ve bunlardan nasÄ±l yararlanabilirsiniz?
* Son gÃ¶nderilerinizi seÃ§erken hangi stratejileri uygulamanÄ±z gerektiÄŸi

Modelleme sÄ±rasÄ±nda performansÄ±nÄ±zÄ± izlemek ve aÅŸÄ±rÄ± uyum yapÄ±p yapmadÄ±ÄŸÄ±nÄ±zÄ± ayÄ±rt etmek, sadece veri bilimi yarÄ±ÅŸmalarÄ±nda deÄŸil, tÃ¼m veri bilimi projelerinde anahtar bir yetkinliktir. Modellerinizi doÄŸru ÅŸekilde doÄŸrulamak, bir Kaggle yarÄ±ÅŸmasÄ±ndan Ã¶ÄŸrenebileceÄŸiniz ve profesyonel dÃ¼nyada yeniden kullanabileceÄŸiniz en Ã¶nemli becerilerden biridir.

### Snooping on the leaderboard *(Liderlik tablosunu gÃ¶zetlemek)*

Daha Ã¶nce aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z gibi, her yarÄ±ÅŸmada Kaggle, test setini bir halkaya aÃ§Ä±k bÃ¶lÃ¼m (genellikle ÅŸu anki liderlik tablosunda gÃ¶rÃ¼len) ve bir Ã¶zel bÃ¶lÃ¼m olarak ayÄ±rÄ±r. Ã–zel bÃ¶lÃ¼m, yarÄ±ÅŸma sonuÃ§larÄ± iÃ§in nihai puanlarÄ± hesaplamak iÃ§in kullanÄ±lÄ±r. Bu test bÃ¶lÃ¼mleri genellikle rastgele belirlenir (zaman serisi yarÄ±ÅŸmalarÄ±nda ise zaman bazÄ±nda belirlenir) ve tÃ¼m test seti, halka aÃ§Ä±k ve Ã¶zel bÃ¶lÃ¼mler arasÄ±nda herhangi bir ayrÄ±m yapÄ±lmadan yayÄ±nlanÄ±r.

> Son zamanlarda, belirli yarÄ±ÅŸmalarda test verilerinin Ã§ok dikkatlice incelenmesini engellemek amacÄ±yla, Kaggle test verilerini geri Ã§ekmiÅŸ ve yalnÄ±zca bazÄ± Ã¶rneklerini saÄŸlamÄ±ÅŸ, gerÃ§ek test seti ise gÃ¶nderim yapÄ±ldÄ±ÄŸÄ±nda yerine konmuÅŸtur. Bu tÃ¼r yarÄ±ÅŸmalara "Kod yarÄ±ÅŸmalarÄ±" denir Ã§Ã¼nkÃ¼ burada aslÄ±nda tahminler deÄŸil, tahminleri oluÅŸturacak kodu iÃ§eren bir Notebook sunulmaktadÄ±r.

Buna gÃ¶re, bir modelden tÃ¼retilen bir gÃ¶nderi, tÃ¼m test setini kapsayacaktÄ±r, ancak yalnÄ±zca halka aÃ§Ä±k bÃ¶lÃ¼m hemen puanlanacak, Ã¶zel bÃ¶lÃ¼mÃ¼n puanlanmasÄ± ise yarÄ±ÅŸma sona erene kadar bekleyecektir.

Bundan dolayÄ± Ã¼Ã§ Ã¶nemli nokta ortaya Ã§Ä±kmaktadÄ±r:

* Bir yarÄ±ÅŸmanÄ±n dÃ¼zgÃ¼n iÅŸleyebilmesi iÃ§in eÄŸitim verisi ve test verisi aynÄ± daÄŸÄ±lÄ±mdan gelmelidir. AyrÄ±ca, test verisinin halka aÃ§Ä±k ve Ã¶zel bÃ¶lÃ¼mleri, daÄŸÄ±lÄ±m aÃ§Ä±sÄ±ndan birbirine benzer olmalÄ±dÄ±r.
* EÄŸitim ve test verisi gÃ¶rÃ¼nÃ¼ÅŸte aynÄ± daÄŸÄ±lÄ±mdan gelmiÅŸ olsa bile, her iki sette de yeterli Ã¶rnek bulunmamasÄ±, eÄŸitim verisi ile halka aÃ§Ä±k ve Ã¶zel test verisi arasÄ±nda uyumlu sonuÃ§lar elde etmeyi zorlaÅŸtÄ±rabilir.
* Halka aÃ§Ä±k test verisi, bir veri bilimi projesinde olduÄŸu gibi yalnÄ±zca son doÄŸrulama iÃ§in kullanÄ±lacak bir "holdout" test olarak deÄŸerlendirilmelidir. Bu yÃ¼zden, "adaptif aÅŸÄ±rÄ± uyum" denilen durumu engellemek iÃ§in fazla sorgulanmamalÄ±dÄ±r. Adaptif aÅŸÄ±rÄ± uyum, bir modelin belirli bir test seti Ã¼zerinde iyi Ã§alÄ±ÅŸÄ±rken, diÄŸer test setlerinde dÃ¼ÅŸÃ¼k performans gÃ¶stermesi anlamÄ±na gelir.

Bu Ã¼Ã§ Ã¶nemli noktayÄ± akÄ±lda tutmak, bir yarÄ±ÅŸmanÄ±n dinamiklerini anlamak iÃ§in Ã§ok Ã¶nemlidir. Ã‡oÄŸu yarÄ±ÅŸmada, eÄŸitim, halka aÃ§Ä±k ve Ã¶zel test verilerinin birbirine nasÄ±l baÄŸlÄ± olduÄŸu hakkÄ±nda tartÄ±ÅŸma forumlarÄ±nda her zaman birÃ§ok soru vardÄ±r ve genellikle yÃ¼zlerce Ã§Ã¶zÃ¼m, yalnÄ±zca halka aÃ§Ä±k liderlik tablosu Ã¼zerindeki etkinliÄŸine gÃ¶re deÄŸerlendirilerek gÃ¶nderilir.

AyrÄ±ca, sÄ±ralamalarÄ± devrim niteliÄŸinde deÄŸiÅŸtiren "shake-up" (sÄ±ralama deÄŸiÅŸikliÄŸi) tartÄ±ÅŸmalarÄ±na da sÄ±kÃ§a rastlanÄ±r. AslÄ±nda, bunlar, daha Ã¶nce halka aÃ§Ä±k liderlik tablosunda daha iyi pozisyonlar elde etmiÅŸ olan birÃ§ok kiÅŸinin hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸramasÄ±na neden olabilen, nihai sÄ±ralamalarÄ±n yeniden dÃ¼zenlenmesidir. Anektodal olarak, shake-up'lar genellikle eÄŸitim verisi ile test seti arasÄ±ndaki farklardan ya da test verisinin halka aÃ§Ä±k ve Ã¶zel bÃ¶lÃ¼mleri arasÄ±ndaki farklardan kaynaklandÄ±ÄŸÄ±na inanÄ±lÄ±r. Bunlar, rakiplerin beklenen yerel puanlarÄ±nÄ±n liderlik tablosu geri bildirimiyle ne kadar iliÅŸkilendiÄŸine bakarak ex ante (yarÄ±ÅŸma baÅŸlamadan Ã¶nce) ve iki sayÄ±ya dayalÄ± yapÄ±lan analizlerle ex post (yarÄ±ÅŸma sona erdikten sonra) Ã¶lÃ§Ã¼lÃ¼r:

* Genel bir shake-up sayÄ±sÄ±, **mean(abs(private_rank-public_rank)/number_of_teams)** formÃ¼lÃ¼ ile hesaplanÄ±r.
* Sadece halka aÃ§Ä±k sÄ±ralamanÄ±n en Ã¼st %10'unu dikkate alarak hesaplanan Ã¼st sÄ±ralama shake-up sayÄ±sÄ±.

> Bu ex post sayÄ±larÄ±, ilk olarak Steve Donoho ([https://www.kaggle.com/breakfastpirate](https://www.kaggle.com/breakfastpirate)) tarafÄ±ndan geliÅŸtirilmiÅŸ ve Kaggle shake-up'larÄ±nÄ±n en kÃ¶tÃ¼ sÄ±ralamalarÄ±nÄ± iÃ§eren bir liste hazÄ±rlamÄ±ÅŸtÄ±r (buna ÅŸu baÄŸlantÄ±dan ulaÅŸabilirsiniz: [Kaggle shake-ups](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/49106#278831)). Bu sayÄ±lar gÃ¼nÃ¼mÃ¼zde, Chapter 5â€™te tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z Meta Kaggle veriseti kullanÄ±larak Ã§oÄŸu Notebook tarafÄ±ndan kolayca yeniden oluÅŸturulabilir (buna ÅŸu baÄŸlantÄ±dan eriÅŸebilirsiniz: [Meta Kaggle Competition Shake-up](https://www.kaggle.com/jtrotman/meta-kaggle-competition-shake-up)).

Ã–rneÄŸin, bu verilere bakarak RSNA Intracranial Hemorrhage Detection yarÄ±ÅŸmasÄ±nÄ±n shake-up'larÄ± nedeniyle ne kadar zorlayÄ±cÄ± olduÄŸunu anlayabilirsiniz, Ã¶zellikle de Ã¼st sÄ±ralamalarda.

Ancak, bir ex post deÄŸerlendirmesinin Ã¶tesinde, Ã¶nceki shake-up'lardan edindiÄŸimiz bazÄ± dersler, Kaggle yarÄ±ÅŸmalarÄ±nda size yardÄ±mcÄ± olabilir. UC Berkeley'den bazÄ± araÅŸtÄ±rmacÄ±lar da bu ÅŸekilde dÃ¼ÅŸÃ¼nÃ¼yor. 2019'da NIPS'te sunduklarÄ± makalelerinde, Roelofs, Fridovich-Keil ve diÄŸerleri, Kaggle yarÄ±ÅŸmalarÄ±ndaki halka aÃ§Ä±k ve Ã¶zel liderlik tablosu dinamiklerine dair iÃ§gÃ¶rÃ¼ler kazanmak amacÄ±yla birkaÃ§ bin Kaggle yarÄ±ÅŸmasÄ±nÄ± incelediler. Her ne kadar sÄ±nÄ±rlÄ± bir yarÄ±ÅŸma kÃ¼mesine odaklansalar da (120 yarÄ±ÅŸma, belirli bir katÄ±lÄ±mcÄ± sayÄ±sÄ±nÄ±n Ã¼zerindeki, ikili sÄ±nÄ±flandÄ±rmaya dayalÄ± yarÄ±ÅŸmalar), bazÄ± ilginÃ§ bulgular elde ettiler:

* Adaptif aÅŸÄ±rÄ± uyum Ã§ok azdÄ±r; diÄŸer bir deyiÅŸle, halka aÃ§Ä±k sÄ±ralamalar genellikle aÃ§Ä±ÄŸa Ã§Ä±kan Ã¶zel liderlik tablosunda tutar.
* Ã‡oÄŸu shake-up, rastgele dalgalanmalardan ve rakiplerin sÄ±ralamalarÄ±nÄ±n Ã§ok yakÄ±n olduÄŸu aÅŸÄ±rÄ± kalabalÄ±k sÄ±ralamalardan kaynaklanÄ±r; Ã¶zel test setlerindeki kÃ¼Ã§Ã¼k bir performans deÄŸiÅŸikliÄŸi, sÄ±ralamalarda bÃ¼yÃ¼k deÄŸiÅŸikliklere neden olabilir.
* Shake-up'lar, eÄŸitim seti Ã§ok kÃ¼Ã§Ã¼k olduÄŸunda veya eÄŸitim verisi baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±ma sahip deÄŸilse (i.i.d.) gerÃ§ekleÅŸir.

> Tam makale, *Roelofs, R., Fridovich-Keil, S. et al. A meta-analysis of overfitting in machine learning. Proceedings of the 33rd International Conference on Neural Information Processing Systems. 2019* ÅŸu baÄŸlantÄ±dan bulunabilir: [Makale Linki](https://papers.nips.cc/paper/2019/file/ee39e503b6bedf0c98c388b7e8589aca-Paper.pdf).

Ancak, bizim uzun Kaggle yarÄ±ÅŸmalarÄ±ndaki deneyimimize gÃ¶re, adaptif aÅŸÄ±rÄ± uyum ile ilgili oldukÃ§a fazla problem gÃ¶rdÃ¼k. Ã–rneÄŸin, Greg Park'Ä±n ilk katÄ±ldÄ±ÄŸÄ±mÄ±z yarÄ±ÅŸmalardan birinin analizini okuyabilirsiniz: [Kaggle Psychopathy Postmortem](http://gregpark.io/blog/Kaggle-PsychopathyPostmortem/). Bu, pek Ã§ok Kaggle katÄ±lÄ±mcÄ±sÄ± iÃ§in yaygÄ±n ve sÃ¼rekli bir sorun olduÄŸu iÃ§in, yalnÄ±zca halka aÃ§Ä±k liderlik tablosuna bakmak yerine daha sofistike bir strateji Ã¶neriyoruz:

* Her zaman gÃ¼venilir bir Ã§apraz doÄŸrulama sistemi kurarak yerel puanlama yapÄ±n.
* Duruma baÄŸlÄ± olarak en iyi doÄŸrulama ÅŸemasÄ±nÄ± kullanarak i.i.d. olmayan daÄŸÄ±lÄ±mlarÄ± kontrol etmeye Ã§alÄ±ÅŸÄ±n. YarÄ±ÅŸma aÃ§Ä±klamasÄ±nda aÃ§Ä±kÃ§a belirtilmedikÃ§e, i.i.d. olmayan daÄŸÄ±lÄ±mlarÄ± fark etmek kolay bir iÅŸ deÄŸildir, ancak tartÄ±ÅŸmalardan veya stratifiye doÄŸrulama ÅŸemalarÄ± kullanarak deney yaparak ipuÃ§larÄ± elde edebilirsiniz (Ã¶rneÄŸin, belirli bir Ã¶zelliÄŸe gÃ¶re sÄ±nÄ±flandÄ±rma yapÄ±ldÄ±ÄŸÄ±nda sonuÃ§lar Ã¶nemli Ã¶lÃ§Ã¼de iyileÅŸir).
* Yerel puanlama ile halka aÃ§Ä±k liderlik tablosunu iliÅŸkilendirerek, ikisinin aynÄ± yÃ¶nde olup olmadÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±n.
* Adversarial doÄŸrulama kullanarak test daÄŸÄ±lÄ±mÄ±nÄ±n eÄŸitim verisiyle benzer olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.
* Ã–zellikle kÃ¼Ã§Ã¼k veri setleriyle Ã§alÄ±ÅŸÄ±yorsanÄ±z, Ã§Ã¶zÃ¼mlerinizi toplama (ensembling) yÃ¶ntemleriyle daha dayanÄ±klÄ± hale getirin.

Sonraki bÃ¶lÃ¼mlerde, bu fikirlerin her birini (toplama dÄ±ÅŸÄ±ndaki, Ã§Ã¼nkÃ¼ bu baÅŸka bir bÃ¶lÃ¼mÃ¼n konusu) daha ayrÄ±ntÄ±lÄ± olarak inceleyeceÄŸiz ve Ã¶zel test verisi Ã¼zerinde en iyi sonuÃ§larÄ± elde etmek iÃ§in size en iyi araÃ§larÄ± ve stratejileri saÄŸlayacaÄŸÄ±z.

### The importance of validation in competitions *(YarÄ±ÅŸmalarda doÄŸrulamanÄ±n Ã¶nemi)*

Bir yarÄ±ÅŸmayÄ± dikkatlice dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼zde, onu bÃ¼yÃ¼k bir deney sistemine benzetebilirsiniz. Kim en sistematik ve verimli ÅŸekilde bu deneyleri yapabilirse, o kazanÄ±r.

GerÃ§ekten de, tÃ¼m teorik bilginize raÄŸmen, aynÄ± becerilere sahip olan yÃ¼zlerce ya da binlerce veri profesyoneliyle rekabet iÃ§inde olacaksÄ±nÄ±z. Ãœstelik, onlar da sizinle aynÄ± veriyi kullanacaklar ve veriden Ã¶ÄŸrenmek iÃ§in bÃ¼yÃ¼k Ã¶lÃ§Ã¼de aynÄ± araÃ§larÄ± kullanacaklar (TensorFlow, PyTorch, Scikit-learn vb.). BazÄ±larÄ±nÄ±n kesinlikle daha iyi hesaplama kaynaklarÄ±na eriÅŸimi olacak, ancak Kaggle Notebooksâ€™un ve genel olarak dÃ¼ÅŸen bulut biliÅŸim fiyatlarÄ±nÄ±n sayesinde bu fark artÄ±k o kadar geniÅŸ deÄŸil. DolayÄ±sÄ±yla, bilgi, veri, modeller ve kullanÄ±labilir bilgisayarlar arasÄ±ndaki farklara baktÄ±ÄŸÄ±nÄ±zda, diÄŸer rakiplerle aranÄ±zdaki bÃ¼yÃ¼k performans farklÄ±lÄ±klarÄ±nÄ± aÃ§Ä±klayacak belirgin bir faktÃ¶r bulamayabilirsiniz. Ancak, bazÄ± katÄ±lÄ±mcÄ±lar sÃ¼rekli olarak diÄŸerlerinden daha iyi performans sergiliyor, bu da arka planda bazÄ± baÅŸarÄ± faktÃ¶rlerinin olduÄŸunu ima eder.

RÃ¶portajlarda ve buluÅŸmalarda, bazÄ± Kaggle katÄ±lÄ±mcÄ±larÄ± bu baÅŸarÄ± faktÃ¶rÃ¼nÃ¼ â€œazimâ€ olarak tanÄ±mlarken, bazÄ±larÄ± â€œher ÅŸeyi denemekâ€ diyor, bazÄ±larÄ± ise â€œyarÄ±ÅŸmaya sahip olduÄŸunuz her ÅŸeyi koyma isteÄŸiâ€ olarak ifade ediyor. Bunlar biraz belirsiz ve sihirli gibi gelebilir. Biz ise buna **sistematik deney yapma** diyoruz. Bizim gÃ¶rÃ¼ÅŸÃ¼mÃ¼ze gÃ¶re, baÅŸarÄ±lÄ± bir katÄ±lÄ±mÄ±n anahtarÄ±, gerÃ§ekleÅŸtirdiÄŸiniz deneylerin sayÄ±sÄ± ve bu deneyleri nasÄ±l yÃ¶nettiÄŸinizde yatmaktadÄ±r. Ne kadar fazla deney yaparsanÄ±z, diÄŸer katÄ±lÄ±mcÄ±lardan daha iyi bir Ã§Ã¶zÃ¼m bulma ÅŸansÄ±nÄ±z o kadar artar. Bu sayÄ±, elbette bazÄ± faktÃ¶rlere baÄŸlÄ±dÄ±r, Ã¶rneÄŸin sahip olduÄŸunuz zaman, hesaplama kaynaklarÄ±nÄ±z (ne kadar hÄ±zlÄ± olursa o kadar iyi, ancak daha Ã¶nce belirttiÄŸimiz gibi bu, baÅŸlÄ± baÅŸÄ±na gÃ¼Ã§lÃ¼ bir ayÄ±rÄ±cÄ± deÄŸildir), ekip bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼z ve ekip Ã¼yelerinin gÃ¶revdeki katÄ±lÄ±mÄ± gibi. Bu, genellikle baÅŸarÄ± iÃ§in anahtarlar olarak bildirilen azim ve katÄ±lÄ±m ile uyumludur.

Ancak, bunlar sonucu etkileyen tek faktÃ¶rler deÄŸildir. Deneylerinizi nasÄ±l yÃ¼rÃ¼ttÃ¼ÄŸÃ¼nÃ¼zÃ¼n de bir etkisi vardÄ±r. **HÄ±zlÄ±ca baÅŸarÄ±sÄ±z olup ondan Ã¶ÄŸrenmek**, bir yarÄ±ÅŸmadaki Ã¶nemli faktÃ¶rlerden biridir. Tabii ki, hem baÅŸarÄ±sÄ±z olduÄŸunuzda hem de baÅŸarÄ±lÄ± olduÄŸunuzda, deneyimlerinizden bir ÅŸeyler Ã¶ÄŸrenmek iÃ§in dikkatlice dÃ¼ÅŸÃ¼nmeniz gerekir; yoksa yarÄ±ÅŸmanÄ±z sadece doÄŸru Ã§Ã¶zÃ¼mÃ¼ bulma umuduyla rastgele bir deneme dizisine dÃ¶nÃ¼ÅŸÃ¼r.

Bu nedenle, **her ÅŸey eÅŸit olduÄŸunda**, doÄŸru bir doÄŸrulama stratejisine sahip olmak, baÅŸarÄ±lÄ± Kaggle katÄ±lÄ±mcÄ±larÄ± ile sadece liderlik tablosunu aÅŸÄ±rÄ± uyum saÄŸlayan ve yarÄ±ÅŸma sonrasÄ± beklenenden daha dÃ¼ÅŸÃ¼k sÄ±ralamalarda kalanlar arasÄ±ndaki bÃ¼yÃ¼k farkÄ± yaratÄ±r.

> DoÄŸrulama, modelinizin Ã¼rettiÄŸi hatalarÄ± doÄŸru bir ÅŸekilde deÄŸerlendirmeniz ve denemelerinizin sonucunda modelinizin performansÄ±nÄ±n nasÄ±l iyileÅŸtiÄŸini ya da kÃ¶tÃ¼leÅŸtiÄŸini Ã¶lÃ§meniz iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemdir.

Genel olarak, doÄŸru doÄŸrulama seÃ§menin etkisi, genellikle daha nicel faktÃ¶rler, Ã¶rneÄŸin en son, en gÃ¼Ã§lÃ¼ GPU'ya sahip olmak ya da daha bÃ¼yÃ¼k bir ekibin gÃ¶nderim yapmasÄ± gibi faktÃ¶rler lehine gÃ¶z ardÄ± edilir. Ancak, sadece denemelerin gÃ¼cÃ¼ne ve liderlik tablosundaki sonuÃ§larÄ±na gÃ¼venmek, â€œduvara Ã§amur atmak ve bir ÅŸeyin tutmasÄ±nÄ± ummakâ€ gibi bir ÅŸey olur (buna ÅŸu baÄŸlantÄ±dan bakabilirsiniz: [Kaggle Psychopathy Postmortem](http://gregpark.io/blog/Kaggle-Psychopathy-Postmortem/)). Bazen bÃ¶yle bir strateji iÅŸe yarayabilir, ancak Ã§oÄŸu zaman iÅŸe yaramaz Ã§Ã¼nkÃ¼ doÄŸru yÃ¶nde deneme yapma fÄ±rsatlarÄ±nÄ± kaÃ§Ä±rÄ±rsÄ±nÄ±z ve o Ã§amurun iÃ§inde parlayan mÃ¼cevheri bile gÃ¶rmeniz mÃ¼mkÃ¼n olmaz. Ã–rneÄŸin, halka aÃ§Ä±k liderlik tablosunda ÅŸansÄ±nÄ±zÄ± denemek iÃ§in rastgele ve sistematik olmayan bir stratejiye fazla odaklanÄ±rsanÄ±z, harika Ã§Ã¶zÃ¼mler Ã¼retmiÅŸ olsanÄ±z bile, nihai gÃ¶nderiminizi doÄŸru seÃ§emeyebilir ve en iyi skoru elde eden Ã§Ã¶zÃ¼mÃ¼ Ã¶zel test setinde kaÃ§Ä±rabilirsiniz.

DoÄŸru bir doÄŸrulama stratejisi, hangi modellerinizin Ã¶zel test setinde sÄ±ralama yapmak iÃ§in gÃ¶nderileceÄŸine karar vermenize yardÄ±mcÄ± olabilir. Halka aÃ§Ä±k liderlik tablosunda en iyi modellerinizi gÃ¶ndermeye yÃ¶nelik bÃ¼yÃ¼k bir Ã§ekicilik olsa da, her zaman kendi doÄŸrulama puanlarÄ±nÄ±zÄ± dikkate alÄ±n. Nihai gÃ¶nderimleriniz iÃ§in, duruma gÃ¶re ve liderlik tablosuna gÃ¼venip gÃ¼venmediÄŸinize gÃ¶re, en iyi modelinizi liderlik tablosuna gÃ¶re ve en iyi modelinizi yerel doÄŸrulama sonuÃ§larÄ±nÄ±za gÃ¶re seÃ§in. EÄŸer liderlik tablosuna gÃ¼venmiyorsanÄ±z (Ã¶zellikle eÄŸitim Ã¶rnekleriniz kÃ¼Ã§Ã¼kse ya da Ã¶rnekler i.i.d. deÄŸilse), en iyi iki doÄŸrulama puanÄ±na sahip modelleri gÃ¶nderin ve Ã§ok farklÄ± iki model ya da toplama (ensemble) seÃ§in. Bu ÅŸekilde, Ã¶zel test setinde performans gÃ¶stermeyen Ã§Ã¶zÃ¼mleri seÃ§me riskini azaltmÄ±ÅŸ olursunuz.

**DoÄŸrulama Deneylerinin Pratik YÃ¶nleri**

Bir deney sistemini kurmanÄ±n Ã¶nemini belirttikten sonra, geriye kalan her ÅŸey, doÄŸrulamanÄ±n pratik yÃ¶nlerine dayanÄ±r. GerÃ§ekten de, bir Ã§Ã¶zÃ¼m modellediÄŸinizde bir dizi karÅŸÄ±lÄ±klÄ± kararÄ± verirsiniz:

1. **Verinizi nasÄ±l iÅŸleyeceksiniz?**
2. **Hangi modeli uygulayacaksÄ±nÄ±z?**
3. **Modelin mimarisini nasÄ±l deÄŸiÅŸtireceksiniz? (Ã¶zellikle derin Ã¶ÄŸrenme modelleri iÃ§in Ã¶nemlidir)**
4. **Modelin hiperparametrelerini nasÄ±l ayarlayacaksÄ±nÄ±z?**
5. **Tahminleri nasÄ±l post-process (sonraki iÅŸleme) edeceksiniz?**

Halka aÃ§Ä±k liderlik tablosu Ã¶zel tabloyla mÃ¼kemmel bir ÅŸekilde iliÅŸkili olsa bile, gÃ¼nlÃ¼k gÃ¶nderim sÄ±nÄ±rÄ± (tÃ¼m yarÄ±ÅŸmalarda bulunan bir sÄ±nÄ±rlama) size yukarÄ±da belirtilen alanlarÄ±n her birinde yapabileceÄŸiniz olasÄ± testlerin yÃ¼zeyine bile dokunmanÄ±zÄ± engeller. DoÄŸru bir doÄŸrulama sistemi, yaptÄ±ÄŸÄ±nÄ±z ÅŸeyin liderlik tablosunda iÅŸe yarayÄ±p yaramayacaÄŸÄ±nÄ± Ã¶nceden size sÃ¶yler.

> **Dmitry Larko**
> 
> 
> 
> [https://www.kaggle.com/dmitrylarko](https://www.kaggle.com/dmitrylarko)
> 
> 
> 
> Dmitry Larko, Kaggle YarÄ±ÅŸmasÄ± BÃ¼yÃ¼k UstasÄ± ve H2O.ai'da baÅŸ veri bilimcisidir. Makine Ã¶ÄŸrenimi ve veri bilimi alanÄ±nda on yÄ±lÄ± aÅŸkÄ±n bir deneyime sahiptir. Kaggle ile 2012 AralÄ±k ayÄ±nda tanÄ±ÅŸmÄ±ÅŸ ve birkaÃ§ ay sonra ilk yarÄ±ÅŸmasÄ±na katÄ±lmÄ±ÅŸtÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda doÄŸrulama konusunda gÃ¼Ã§lÃ¼ bir savunucudur, bunu rÃ¶portajÄ±nda da vurgulamÄ±ÅŸtÄ±r.
> 
> 
> 
> ---
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggle'da uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> 
> 
> Ã‡oÄŸunlukla tabular veri kÃ¼meleri iÃ§in yarÄ±ÅŸmalara katÄ±ldÄ±m ama bilgisayarla gÃ¶rme (computer vision) yarÄ±ÅŸmalarÄ±nÄ± da seviyorum.
> 
> 
> 
> ---
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rsÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±dÄ±r?**
> 
> 
> 
> Her zaman basit baÅŸlayÄ±p kÃ¼Ã§Ã¼k ve daha basit modeller iÃ§in bir gÃ¶nderi hattÄ± (submission pipeline) kurmayÄ± hedeflerim. Buradaki Ã¶nemli bir adÄ±m, fikirlerinizi saÄŸlam bir ÅŸekilde doÄŸrulamak iÃ§in doÄŸru bir doÄŸrulama (validation) ÅŸemasÄ± oluÅŸturmak. AyrÄ±ca, veri Ã¼zerinde olabildiÄŸince Ã§ok zaman geÃ§irip analiz yapmanÄ±z her zaman iyi bir fikirdir.
> 
> 
> 
> GÃ¼nlÃ¼k iÅŸimde, bir AutoML platformu geliÅŸtiriyorum, bu yÃ¼zden Kaggleâ€™da denediÄŸim Ã§oÄŸu ÅŸey, bu platformun bir parÃ§asÄ± olarak uygulanÄ±yor.
> 
> 
> 
> ---
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸma hakkÄ±nda bize bir ÅŸeyler anlatÄ±r mÄ±sÄ±nÄ±z ve gÃ¶revi ele almak iÃ§in hangi iÃ§gÃ¶rÃ¼leri kullandÄ±nÄ±z?**
> 
> 
> 
> AklÄ±ma herhangi bir ÅŸey gelmiyor ve aslÄ±nda bunun Ã§ok Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nmÃ¼yorum, Ã§Ã¼nkÃ¼ teknik olarak zorlayÄ±cÄ± olan bir ÅŸey, baÅŸkasÄ± iÃ§in Ã§ok kolay olabilir. Teknik zorluklar Ã§ok Ã¶nemli deÄŸil; Ã¶nemli olan, bir yarÄ±ÅŸmanÄ±n bir maraton gibi olduÄŸunu unutmamaktÄ±r, bir sprint deÄŸil. Ya da isterseniz bunu bir dizi sprintten oluÅŸan bir maraton olarak gÃ¶rebilirsiniz. Bu yÃ¼zden tÃ¼kenmemek Ã§ok Ã¶nemli; iyi uyumak, egzersiz yapmak ve parkta yÃ¼rÃ¼yÃ¼ÅŸe Ã§Ä±kmak, beyninizi yeni fikirlerle tazelemek iÃ§in faydalÄ±dÄ±r. Bir Kaggle yarÄ±ÅŸmasÄ±nÄ± kazanmak iÃ§in, yaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±z, uzmanlÄ±ÄŸÄ±nÄ±z ve bazen de biraz ÅŸans gerekir.
> 
> 
> 
> ---
> 
> 
> 
> **Kaggle, kariyerinize yardÄ±mcÄ± oldu mu? Olduysa, nasÄ±l?**
> 
> 
> 
> Åu anki iÅŸimi, bir Kaggle YarÄ±ÅŸmasÄ± BÃ¼yÃ¼k UstasÄ± olmam sayesinde buldum. Mevcut iÅŸverenim iÃ§in bu durum, alandaki uzmanlÄ±ÄŸÄ±mÄ±n yeterli bir kanÄ±tÄ±ydÄ±.
> 
> 
> 
> ---
> 
> 
> 
> **TecrÃ¼besine gÃ¶re, deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? Ä°lk baÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz ÅŸimdi neyi farklÄ± yapardÄ±nÄ±z?**
> 
> 
> 
> Genellikle doÄŸru doÄŸrulama ÅŸemasÄ±nÄ± gÃ¶zden kaÃ§Ä±rÄ±yorlar ve halk liderlik tablosundaki (public leaderboard) geri bildirimleri takip ediyorlar. Bu, Ã§oÄŸu durumda kÃ¶tÃ¼ sonuÃ§lanÄ±r ve â€œshake-upâ€ (sÄ±ralama Ã§alkalanmasÄ±) olarak bilinen duruma yol aÃ§ar.
> 
> 
> 
> AyrÄ±ca, keÅŸifsel veri analizi (exploratory data analysis) yapmayÄ± aceleyle geÃ§ip doÄŸrudan model kurmaya baÅŸlÄ±yorlar, bu da basit Ã§Ã¶zÃ¼mlere ve ortalama liderlik tablosu skorlarÄ±na yol aÃ§ar.
> 
> 
> 
> ---
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdir?**
> 
> 
> 
> YaptÄ±ÄŸÄ±m ana hata, aslÄ±nda deneyimsiz bir kiÅŸinin yapacaÄŸÄ± aynÄ± hatadÄ±r â€“ liderlik tablosundaki skoru takip etmek ve iÃ§ doÄŸrulama (internal validation) yerine ona odaklanmak. Her seferinde bunu yaptÄ±ÄŸÄ±mda, birkaÃ§ sÄ±ralama kaybettim.
> 
> 
> 
> ---
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶zellikle Ã¶nerdiÄŸiniz araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> 
> 
> Bunlar genellikle bilinen araÃ§lardÄ±r. Tabular veri iÃ§in: LightGBM, XGBoost, CatBoost; derin Ã¶ÄŸrenme iÃ§in: PyTorch, PyTorch-Lightning, timm; ve herkes iÃ§in Scikit-learn.
> 
> 
> 
> ---
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken dikkat edilmesi gereken en Ã¶nemli ÅŸey nedir?**
> 
> 
> 
> Basit baÅŸlayÄ±n, her zaman doÄŸrulama yapÄ±n; doÄŸrulama skorunuza gÃ¼venin, liderlik tablosu skoruna deÄŸil.

#### Bias and variance *(Ã–nyargÄ± ve varyans)*

**Ä°yi bir doÄŸrulama sistemi**, eÄŸitim setinizden aldÄ±ÄŸÄ±nÄ±z hata Ã¶lÃ§Ã¼mlerinden daha gÃ¼venilir metriklerle size yardÄ±mcÄ± olur. AslÄ±nda, eÄŸitim seti Ã¼zerinde elde edilen metrikler, her modelin kapasitesinden ve karmaÅŸÄ±klÄ±ÄŸÄ±ndan etkilenir. Bir modelin kapasitesini, verilerden Ã¶ÄŸrenmek iÃ§in kullanabileceÄŸi belleÄŸi olarak dÃ¼ÅŸÃ¼nebilirsiniz.

Her modelin, verilerden alÄ±nan desenleri kaydetmesine yardÄ±mcÄ± olan bir iÃ§ parametre seti vardÄ±r. Her modelin desenleri alma yeteneÄŸi farklÄ±dÄ±r ve bazÄ± modeller belirli kurallarÄ± veya iliÅŸkileri tespit ederken, diÄŸerleri farklÄ± kurallarÄ± bulabilir. Bir model, verilerden desenleri Ã§Ä±kardÄ±kÃ§a, bunlarÄ± "belleÄŸine" kaydeder.

AyrÄ±ca, bir modelin kapasitesinden veya ifade gÃ¼cÃ¼nden bahsederken, bu durum genellikle sapma (bias) ve varyans (variance) ile ilgilidir. Bu durumda, bir modelin sapma ve varyansÄ±, tahminlerle ilgilidir, ancak temel prensip doÄŸrudan modelin ifade gÃ¼cÃ¼yle iliÅŸkilidir. Modeller, bir girdi (gÃ¶zlemlenen veriler) ile bir sonuÃ§ (tahminler) arasÄ±nda bir baÄŸlantÄ± kuran matematiksel fonksiyonlara indirgenebilir. BazÄ± matematiksel fonksiyonlar, sahip olduklarÄ± iÃ§ parametre sayÄ±sÄ± ve bu parametreleri nasÄ±l kullandÄ±klarÄ± aÃ§Ä±sÄ±ndan diÄŸerlerinden daha karmaÅŸÄ±ktÄ±r:

* EÄŸer bir modelin matematiksel fonksiyonu, Ã§Ã¶zmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z problemin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± yakalamak iÃ§in yeterince karmaÅŸÄ±k veya ifade gÃ¼cÃ¼ yÃ¼ksek deÄŸilse, bundan **sapma (bias)** olarak bahsederiz, Ã§Ã¼nkÃ¼ tahminleriniz modelin sÄ±nÄ±rlarÄ±yla sÄ±nÄ±rlÄ± ("biased") olacaktÄ±r.

* EÄŸer bir modelin temel matematiksel fonksiyonu, ele aldÄ±ÄŸÄ±nÄ±z problem iÃ§in Ã§ok karmaÅŸÄ±ksa, o zaman **varyans (variance)** problemi vardÄ±r, Ã§Ã¼nkÃ¼ model, eÄŸitim verilerindeki gereksiz detaylarÄ± ve gÃ¼rÃ¼ltÃ¼yÃ¼ fazla kaydedecek ve tahminleri bu bilgilerden derinden etkilenecek, bu da tahminlerin dÃ¼zensiz olmasÄ±na yol aÃ§acaktÄ±r.

GÃ¼nÃ¼mÃ¼zde, makine Ã¶ÄŸrenimi alanÄ±ndaki ilerlemeler ve mevcut hesaplama kaynaklarÄ± gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, problem genellikle varyans kaynaklÄ±dÄ±r. Ã‡Ã¼nkÃ¼ derin sinir aÄŸlarÄ± ve gradyan artÄ±rma (gradient boosting) gibi en yaygÄ±n kullanÄ±lan Ã§Ã¶zÃ¼mler, Ã§oÄŸu zaman karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z problemlerin Ã§Ã¶zÃ¼lmesi iÃ§in gerekenin Ã§ok Ã¶tesinde matematiksel bir ifade gÃ¼cÃ¼ne sahiptir.

Bir model, Ã§Ä±karabileceÄŸi tÃ¼m yararlÄ± desenleri elde ettikten sonra, eÄŸer kapasitesini tÃ¼ketmemiÅŸse, veriyle ilgili olmayan (genellikle gÃ¼rÃ¼ltÃ¼ olarak adlandÄ±rÄ±lÄ±r) Ã¶zellikleri ve sinyalleri Ã¶ÄŸrenmeye baÅŸlar. Ä°lk baÅŸta Ã§Ä±karÄ±lan desenler, modelin test verisi Ã¼zerinde genelleme yapmasÄ±na ve daha doÄŸru tahminlerde bulunmasÄ±na yardÄ±mcÄ± olsa da, yalnÄ±zca eÄŸitim seti hakkÄ±nda Ã¶ÄŸrendiklerinin her biri yardÄ±mcÄ± olmayacak; bunun yerine modelin performansÄ±nÄ± zarar verebilir. EÄŸitim setinin, genelleme deÄŸeri taÅŸÄ±mayan unsurlarÄ±nÄ± Ã¶ÄŸrenme sÃ¼reci **aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting)** olarak adlandÄ±rÄ±lÄ±r.

DoÄŸrulamanÄ±n temel amacÄ±, bu deÄŸerin genelleÅŸtirilebilir kÄ±smÄ±nÄ±, eÄŸitim seti Ã¶zelliklerine aÅŸÄ±rÄ± uyum saÄŸlamanÄ±n neden olduÄŸu kÄ±smÄ±ndan ayÄ±ran bir puan veya kayÄ±p deÄŸeri tanÄ±mlamaktÄ±r.

---

**Ä°yi DoÄŸrulama TasarÄ±mÄ±**

Bu, doÄŸrulama kaybÄ±dÄ±r (validation loss). Ã–ÄŸrenme eÄŸrilerinin gÃ¶rselleÅŸtirildiÄŸi ÅŸu ÅŸekilde bir durumu gÃ¶rebilirsiniz:

![](im/1051.png)

**EÄŸer kayÄ±p Ã¶lÃ§Ã¼mÃ¼nÃ¼ (loss measure) y-yakasÄ± Ã¼zerine ve modelin Ã¶ÄŸrenme Ã§abasÄ±nÄ± (bu, sinir aÄŸlarÄ± iÃ§in epoklar veya gradyan artÄ±rma iÃ§in turlar olabilir) x-yakasÄ± Ã¼zerine grafiÄŸe dÃ¶kerseniz, Ã¶ÄŸrenmenin her zaman eÄŸitim veri setinde gerÃ§ekleÅŸtiÄŸini fark edeceksiniz, ancak bu her zaman diÄŸer verilerde geÃ§erli deÄŸildir.**

AynÄ± ÅŸey, hiperparametreleri deÄŸiÅŸtirdiÄŸinizde, veriyi iÅŸlediÄŸinizde veya tamamen farklÄ± bir model seÃ§tiÄŸinizde de olur. EÄŸri ÅŸekli deÄŸiÅŸebilir, ancak her zaman aÅŸÄ±rÄ± Ã¶ÄŸrenmenin (overfitting) baÅŸladÄ±ÄŸÄ± bir tatlÄ± nokta olacaktÄ±r. Bu nokta, modeller arasÄ±nda ve modelleme sÃ¼recinizde yaptÄ±ÄŸÄ±nÄ±z Ã§eÅŸitli seÃ§imlere gÃ¶re farklÄ±lÄ±k gÃ¶sterebilir. EÄŸer aÅŸÄ±rÄ± Ã¶ÄŸrenmenin baÅŸladÄ±ÄŸÄ± noktayÄ± doÄŸru bir doÄŸrulama stratejisi ile doÄŸru ÅŸekilde hesapladÄ±ysanÄ±z, modelinizin performansÄ± kesinlikle liderlik tablosu sonuÃ§larÄ±yla (hem halka aÃ§Ä±k hem de Ã¶zel) korele olacaktÄ±r ve doÄŸrulama metrikleriniz, herhangi bir gÃ¶nderi yapmadan Ã§alÄ±ÅŸmalarÄ±nÄ±zÄ± deÄŸerlendirmeniz iÃ§in bir proxy (temsilci) saÄŸlayacaktÄ±r.

**AÅŸÄ±rÄ± Ã¶ÄŸrenme (Overfitting) farklÄ± seviyelerde karÅŸÄ±nÄ±za Ã§Ä±kabilir:**

* EÄŸitim verisi seviyesinde, eÄŸer probleme Ã§ok karmaÅŸÄ±k bir model kullanÄ±yorsanÄ±z
* DoÄŸrulama seti seviyesinde, modelinizi belirli bir doÄŸrulama setine Ã§ok fazla gÃ¶re ayarladÄ±ÄŸÄ±nÄ±zda
* Halka aÃ§Ä±k liderlik tablosu seviyesinde, eÄŸer sonuÃ§larÄ±nÄ±z eÄŸitimle beklediÄŸinizden Ã§ok uzaksa
* Ã–zel liderlik tablosu seviyesinde, halka aÃ§Ä±k liderlik tablosunda iyi sonuÃ§lar elde etmenize raÄŸmen, Ã¶zel sonuÃ§larÄ±nÄ±z hayal kÄ±rÄ±klÄ±ÄŸÄ± yaratÄ±yorsa

Anlam aÃ§Ä±sÄ±ndan biraz farklÄ± olsalar da, hepsi de modelinizin genellenebilir olmadÄ±ÄŸÄ±nÄ± gÃ¶sterir, tÄ±pkÄ± bu bÃ¶lÃ¼mde tarif ettiÄŸimiz gibi.

### Trying different splitting strategies *(FarklÄ± veri bÃ¶lme stratejilerini denemek)*

Daha Ã¶nce tartÄ±ÅŸÄ±ldÄ±ÄŸÄ± gibi, doÄŸrulama kaybÄ±, eÄŸitim setinin parÃ§asÄ± olmayan bir veri Ã¶rneÄŸine dayanmaktadÄ±r. Bu, modelinizin tahmin etme konusundaki ne kadar iyi olduÄŸunu belirten ampirik bir Ã¶lÃ§Ã¼dÃ¼r ve eÄŸitim verilerinin desenlerini ne kadar ezberlediÄŸini belirten eÄŸitimde elde edilen sonuÃ§lardan daha doÄŸru bir Ã¶lÃ§Ã¼dÃ¼r. DoÄŸrulama iÃ§in kullanÄ±lan veri Ã¶rneÄŸini doÄŸru bir ÅŸekilde seÃ§mek, doÄŸrulama stratejinizin temelini oluÅŸturur.

Modelinizi doÄŸrulamak ve performansÄ±nÄ± doÄŸru ÅŸekilde Ã¶lÃ§mek iÃ§in birkaÃ§ seÃ§eneÄŸiniz vardÄ±r:

* Ä°lk seÃ§enek, bir holdout (ayÄ±rma) sistemi kullanmaktÄ±r. Ancak, bu, verilerinizi temsil eden bir Ã¶rneklem seÃ§me riskini taÅŸÄ±r veya doÄŸrulama holdout'unuza aÅŸÄ±rÄ± uyum saÄŸlama riski iÃ§erir.

* Ä°kinci seÃ§enek, olasÄ±lÄ±ksal bir yaklaÅŸÄ±m kullanmak ve sonuÃ§lara varmak iÃ§in bir dizi Ã¶rneklem kullanmaktÄ±r. OlasÄ±lÄ±ksal yaklaÅŸÄ±mlar arasÄ±nda Ã§apraz doÄŸrulama, birer bir bÄ±rakma (LOO) ve bootstrap bulunmaktadÄ±r. Ã‡apraz doÄŸrulama stratejileri arasÄ±nda, verinizin Ã¶zelliÄŸine baÄŸlÄ± olarak Ã§eÅŸitli numaralar vardÄ±r (basit rastgele Ã¶rnekleme, katmanlÄ± Ã¶rnekleme, gruplar halinde Ã¶rnekleme, zamanlÄ± Ã¶rnekleme).

TÃ¼m bu stratejilerin ortak noktasÄ±, Ã¶rnekleme stratejileridir. Bu stratejiler, kÃ¼Ã§Ã¼k bir veri parÃ§asÄ±na dayalÄ± olarak genel bir Ã¶lÃ§Ã¼m Ã§Ä±karÄ±lmasÄ±na yardÄ±mcÄ± olur (modelinizin performansÄ± gibi). Ã–rnekleme, istatistiÄŸin temelidir ve kesin bir prosedÃ¼r deÄŸildir, Ã§Ã¼nkÃ¼ Ã¶rnekleme yÃ¶nteminiz, mevcut veriniz ve Ã¶rnekleme sÃ¼recindeki rastlantÄ±sallÄ±k nedeniyle belirli durumlarÄ±n Ã¶rnekleme dahil edilmesi, belirli bir hata payÄ±na yol aÃ§abilir.

**Ä°yi Bir DoÄŸrulama TasarÄ±mÄ±**

Ã–rneÄŸin, eÄŸer taraflÄ± bir Ã¶rneklem kullanÄ±rsanÄ±z, doÄŸrulama metriÄŸiniz yanlÄ±ÅŸ bir ÅŸekilde (aÅŸÄ±rÄ± veya eksik) tahmin edilebilir. Ancak, doÄŸru bir ÅŸekilde tasarlanÄ±p uygulanÄ±rsa, Ã¶rnekleme stratejileri genel Ã¶lÃ§Ã¼mÃ¼nÃ¼zÃ¼n iyi bir tahminini saÄŸlar.

Bu stratejilerin ortak bir diÄŸer Ã¶zelliÄŸi de bunlarÄ±n bÃ¶lÃ¼mler olmasÄ±dÄ±r, yani her bir vaka, eÄŸitim veya doÄŸrulama olarak birbirinden dÄ±ÅŸlanmÄ±ÅŸ ÅŸekilde ayrÄ±lÄ±r. GerÃ§ekten de, Ã§oÄŸu modelin belirli bir ezberleme yeteneÄŸi olduÄŸundan, aynÄ± vakalarÄ±n hem eÄŸitim hem de doÄŸrulama iÃ§in kullanÄ±lmasÄ±, modelin ezberleme yeteneklerini sergilemesine izin verdiÄŸi iÃ§in ÅŸiÅŸirilmiÅŸ tahminlere yol aÃ§ar; bunun yerine, modelin hiÃ§ gÃ¶rÃ¼lmemiÅŸ Ã¶rneklerde Ã§alÄ±ÅŸacak desenler ve fonksiyonlar tÃ¼retme yeteneÄŸi Ã¼zerinde deÄŸerlendirilmesini istiyoruz.

#### The basic train-test split *(Temel eÄŸitim-test bÃ¶lÃ¼nmesi)*

Ä°lk analiz edeceÄŸimiz strateji, eÄŸitim-test bÃ¶lme (train-test split) stratejisidir. Bu stratejide, eÄŸitim setinizin bir kÄ±smÄ±nÄ± (aynÄ± zamanda holdout olarak da bilinir) Ã¶rnek alÄ±r ve bu kÄ±smÄ±, geri kalan verilerle eÄŸittiÄŸiniz tÃ¼m modeller iÃ§in test seti olarak kullanÄ±rsÄ±nÄ±z.

Bu stratejinin bÃ¼yÃ¼k avantajÄ±, Ã§ok basit olmasÄ±dÄ±r: Verinizin bir kÄ±smÄ±nÄ± seÃ§er ve bu kÄ±smÄ± kullanarak modelinizin baÅŸarÄ±sÄ±nÄ± test edersiniz. Genellikle veriler %80/%20 oranÄ±nda, eÄŸitim seti lehine bÃ¶lÃ¼nÃ¼r. Scikit-learn'de, bu yÃ¶ntem train_test_split fonksiyonu ile uygulanÄ±r. Bu yÃ¶ntemi birkaÃ§ aÃ§Ä±dan ele alalÄ±m:

* BÃ¼yÃ¼k veri setleriniz olduÄŸunda, Ã§Ä±kardÄ±ÄŸÄ±nÄ±z test verisinin orijinal veri setinin daÄŸÄ±lÄ±mÄ±na benzer (temsil edici) olmasÄ±nÄ± bekleyebilirsiniz. Ancak, Ã§Ä±kartma iÅŸlemi rastlantÄ±sal bir ÅŸekilde yapÄ±ldÄ±ÄŸÄ± iÃ§in her zaman temsili olmayan bir Ã¶rnekleme Ã§Ä±karma ÅŸansÄ±nÄ±z vardÄ±r. Ã–zellikle, baÅŸladÄ±ÄŸÄ±nÄ±z eÄŸitim Ã¶rneÄŸiniz kÃ¼Ã§Ã¼kse bu ÅŸans artar. Ã‡Ä±karÄ±lan holdout bÃ¶lÃ¼mÃ¼nÃ¼, adversarial validasyon (bunun hakkÄ±nda birkaÃ§ bÃ¶lÃ¼m sonra daha fazla bilgi verilecektir) kullanarak karÅŸÄ±laÅŸtÄ±rmak, Ã§abalarÄ±nÄ±zÄ± doÄŸru bir ÅŸekilde deÄŸerlendirdiÄŸinizden emin olmanÄ±za yardÄ±mcÄ± olabilir.

* AyrÄ±ca, test Ã¶rneklemenizin temsil edici olmasÄ±nÄ± saÄŸlamak iÃ§in, Ã¶zellikle eÄŸitim verilerinizin hedef deÄŸiÅŸkenle nasÄ±l iliÅŸkilendiÄŸi konusunda, stratifikasyonu (katmanlÄ± Ã¶rnekleme) kullanabilirsiniz. Bu, belirli Ã¶zelliklerin oranlarÄ±nÄ±n Ã¶rneklenen veride korunmasÄ±nÄ± saÄŸlar. Bunu yapmak iÃ§in train_test_split fonksiyonundaki **stratify** parametresini kullanabilir ve korumak istediÄŸiniz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± iÃ§eren bir dizi verebilirsiniz.

Bir temsilci holdout'a sahip olsanÄ±z bile, bazen basit bir train-test bÃ¶lmesi, yarÄ±ÅŸmalarda Ã§abalarÄ±nÄ±zÄ± doÄŸru bir ÅŸekilde takip etmek iÃ§in yeterli olmayabilir.

AslÄ±nda, bu test setinde sÃ¼rekli deÄŸerlendirme yaparken, seÃ§imlerinizi bir tÃ¼r adaptasyon aÅŸÄ±rÄ± uyumuna (diÄŸer bir deyiÅŸle, eÄŸitim setinin gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ yanlÄ±ÅŸ bir ÅŸekilde sinyal olarak almak) yol aÃ§acak ÅŸekilde yÃ¶nlendirebilirsiniz. Bu, Ã¶zellikle sÄ±k sÄ±k halk liderliÄŸi tablosunda deÄŸerlendirme yapÄ±ldÄ±ÄŸÄ±nda meydana gelir. Bu nedenle, olasÄ±lÄ±ksal bir deÄŸerlendirme, daha fazla hesaplama gerektirse de, bir yarÄ±ÅŸma iÃ§in daha uygun bir yaklaÅŸÄ±mdÄ±r.

#### Probabilistic evaluation methods *(OlasÄ±lÄ±ksal deÄŸerlendirme yÃ¶ntemleri)*

Makine Ã¶ÄŸrenimi modelinin performansÄ±nÄ±n olasÄ±lÄ±ksal deÄŸerlendirilmesi, bir daÄŸÄ±lÄ±mdan alÄ±nan Ã¶rneÄŸin istatistiksel Ã¶zelliklerine dayanÄ±r. Ã–rnekleme yaparak, orijinal verinizin daha kÃ¼Ã§Ã¼k bir kÃ¼mesini oluÅŸturmuÅŸ olursunuz ve bu kÃ¼menin, orijinal verinin aynÄ± Ã¶zelliklere sahip olmasÄ± beklenir. AyrÄ±ca, Ã¶rneklemeye dokunulmayan kÄ±sÄ±m da bir Ã¶rneklem oluÅŸturur ve bu kÄ±sÄ±m da orijinal verinin Ã¶zelliklerine sahip olmalÄ±dÄ±r. Modelinizi bu Ã¶rneklenmiÅŸ veriler Ã¼zerinde eÄŸitip test ederek ve bu iÅŸlemi birÃ§ok kez tekrarlayarak, temelde modelinizin performansÄ±nÄ± Ã¶lÃ§en bir istatistiksel tahminci yaratÄ±yorsunuz. Her Ã¶rneklemin iÃ§inde bir "hata" olabilir; yani, orijinal verinin gerÃ§ek daÄŸÄ±lÄ±mÄ±nÄ± tam olarak temsil etmeyebilir. Ancak daha fazla Ã¶rnekleme yaptÄ±kÃ§a, bu birden fazla Ã¶rneklemdeki tahmincilerinizin ortalamasÄ±, tahmin etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z Ã¶lÃ§Ã¼tÃ¼n gerÃ§ek ortalamasÄ±na yakÄ±nsama gÃ¶sterir (bu, olasÄ±lÄ±k teorisinde BÃ¼yÃ¼k SayÄ±lar Kanunu adÄ± verilen bir teoremle aÃ§Ä±klanan gÃ¶zlemlenen bir sonuÃ§tur).

OlasÄ±lÄ±ksal tahminciler, basit bir train-test bÃ¶lmesine gÃ¶re doÄŸal olarak daha fazla hesaplama gerektirir, ancak doÄŸru Ã¶lÃ§Ã¼tÃ¼, yani modelinizin genel performansÄ±nÄ± doÄŸru bir ÅŸekilde tahmin ettiÄŸinizden daha fazla emin olmanÄ±zÄ± saÄŸlar.

##### k-fold cross-validation *(k-katlÄ± Ã§apraz doÄŸrulama)*

En yaygÄ±n kullanÄ±lan olasÄ±lÄ±ksal doÄŸrulama yÃ¶ntemi, k-katlÄ± Ã§apraz doÄŸrulama (k-fold cross-validation) olup, modelinizin daha Ã¶nce gÃ¶rmediÄŸi, aynÄ± daÄŸÄ±lÄ±mdan Ã§ekilmiÅŸ test verileri Ã¼zerindeki performansÄ±nÄ± doÄŸru bir ÅŸekilde tahmin etme yeteneÄŸiyle tanÄ±nÄ±r.

> Bu konu, Bates, S., Hastie, T., ve Tibshirani, R.'nin **Cross-validation: what does it estimate and how well does it do it?** baÅŸlÄ±klÄ± makalesinde aÃ§Ä±kÃ§a aÃ§Ä±klanmÄ±ÅŸtÄ±r (arXiv preprint arXiv:2104.00673, 2021, [makale baÄŸlantÄ±sÄ±](https://arxiv.org/pdf/2104.00673.pdf)).

k-katlÄ± Ã§apraz doÄŸrulama, hem tahminsel modelleri karÅŸÄ±laÅŸtÄ±rmak hem de test seti Ã¼zerinde en iyi performansÄ± gÃ¶sterecek olan modelin hiperparametrelerini seÃ§mek iÃ§in baÅŸarÄ±yla kullanÄ±labilir.

k-katlÄ± Ã§apraz doÄŸrulamanÄ±n pek Ã§ok farklÄ± Ã§eÅŸidi olsa da, en basiti, Scikit-learn'deki **KFold** fonksiyonunda uygulanan versiyonudur. Bu yÃ¶ntemde, mevcut eÄŸitim veriniz k parÃ§aya ayrÄ±lÄ±r. ArdÄ±ndan, k iterasyon iÃ§in bu parÃ§alardan birisi test seti olarak alÄ±nÄ±r, diÄŸer k-1 parÃ§a ise modelin eÄŸitimi iÃ§in kullanÄ±lÄ±r.

k doÄŸrulama skoru daha sonra ortalanÄ±r ve bu ortalama skor deÄŸeri, k-katlÄ± doÄŸrulama skoru olur; bu skor, modelinizin herhangi bir gÃ¶rÃ¼lmemiÅŸ veri Ã¼zerindeki tahmin edilen ortalama performansÄ±nÄ± gÃ¶sterir. SkorlarÄ±n standart sapmasÄ± ise, tahminin ne kadar belirsiz olduÄŸunu size bildirir. Åekil 6.2, 5-katlÄ± Ã§apraz doÄŸrulamanÄ±n nasÄ±l yapÄ±landÄ±rÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir.

![](im/1052.png)

K-katlamalÄ± Ã§apraz doÄŸrulama skorunun Ã¶nemli bir yÃ¶nÃ¼, modelinizin k-1 katÄ±ndan aynÄ± miktarda veri ile eÄŸitilmiÅŸ olarak ortalama skorunu tahmin etmesidir. Ancak sonrasÄ±nda modelinizi tÃ¼m verinizle eÄŸittiÄŸinizde, Ã¶nceki doÄŸrulama tahmini geÃ§erliliÄŸini yitirir. K, Ã¶rnek sayÄ±sÄ± n'ye yaklaÅŸtÄ±kÃ§a, modelinizin tÃ¼m eÄŸitim seti Ã¼zerinde eÄŸitilmiÅŸ haline iliÅŸkin giderek daha doÄŸru bir tahmin elde edersiniz; ancak her katÄ±n tahminleri arasÄ±ndaki artan korelasyon nedeniyle, doÄŸrulamanÄ±n tÃ¼m olasÄ±lÄ±k tahminlerini kaybedersiniz. Bu durumda, elde ettiÄŸiniz sayÄ±, modelinizin eÄŸitim verisi Ã¼zerindeki performansÄ±nÄ± gÃ¶sterir (ki bu hala karÅŸÄ±laÅŸtÄ±rma amaÃ§larÄ± iÃ§in yararlÄ± bir tahmin olabilir, ancak modelinizin genelleme gÃ¼cÃ¼nÃ¼ doÄŸru ÅŸekilde tahmin etmenize yardÄ±mcÄ± olmaz).

K = n'ye ulaÅŸtÄ±ÄŸÄ±nÄ±zda, bunun LOO (Leave-One-Out) doÄŸrulama yÃ¶ntemi olduÄŸunu gÃ¶rÃ¼rsÃ¼nÃ¼z, bu yÃ¶ntem birkaÃ§ Ã¶rneÄŸiniz olduÄŸunda yararlÄ±dÄ±r. Bu yÃ¶ntem Ã§oÄŸunlukla tarafsÄ±z bir uyum Ã¶lÃ§Ã¼tÃ¼dÃ¼r, Ã§Ã¼nkÃ¼ mevcut verilerin neredeyse tamamÄ±nÄ± eÄŸitmek iÃ§in kullanÄ±r ve sadece bir Ã¶rneÄŸi test iÃ§in ayÄ±rÄ±r. Ancak, bu, gÃ¶rÃ¼nmeyen verilerdeki beklenen performansÄ±n iyi bir tahmini deÄŸildir. Verisetindeki her bir testin tekrar edilmesi, birbirleriyle yÃ¼ksek oranda korelasyonlu olur ve ortaya Ã§Ä±kan LOO metriÄŸi, modelin veri seti Ã¼zerindeki performansÄ±nÄ± daha Ã§ok temsil eder, bilinmeyen verilerdeki performansÄ±ndan ziyade.

DoÄŸru k sayÄ±sÄ±, sahip olduÄŸunuz veriye iliÅŸkin birkaÃ§ aÃ§Ä±ya baÄŸlÄ± olarak belirlenir:

* K kÃ¼Ã§Ã¼kse (minimum 2'dir), her kat daha kÃ¼Ã§Ã¼k olacak ve bu nedenle k-1 katÄ±nda eÄŸitilen bir model iÃ§in Ã¶ÄŸrenmede daha fazla bias (sapma) olacaktÄ±r: daha kÃ¼Ã§Ã¼k bir k ile doÄŸrulanan model, daha bÃ¼yÃ¼k bir k ile eÄŸitilen bir modele gÃ¶re daha dÃ¼ÅŸÃ¼k performans gÃ¶sterir.
* K daha bÃ¼yÃ¼kse, daha fazla veri olacaktÄ±r, ancak doÄŸrulama tahminleriniz daha fazla korelasyon gÃ¶sterir: K-katlamalÄ± Ã§apraz doÄŸrulamanÄ±n, gÃ¶rÃ¼nmeyen verilere olan performansÄ± tahmin etme Ã¶zelliklerini kaybedersiniz.

Genellikle, k 5, 7 veya 10 olarak belirlenir, nadiren 20 katlama kullanÄ±lÄ±r. K = 5 veya k = 10 genellikle bir yarÄ±ÅŸma iÃ§in iyi bir seÃ§enek olarak kabul edilir, Ã§Ã¼nkÃ¼ 10 katlama daha fazla veriyi her eÄŸitimde kullanÄ±r (mevcut verilerin %90'Ä±) ve bu nedenle modelinizin tÃ¼m veri kÃ¼mesiyle yeniden eÄŸitildiÄŸinde beklenen performansÄ±nÄ± anlamada daha uygundur.

Bir yarÄ±ÅŸmadaki belirli bir veri seti iÃ§in hangi k'nÄ±n seÃ§ileceÄŸini karar verirken, iki perspektifi gÃ¶z Ã¶nÃ¼nde bulundurmak faydalÄ±dÄ±r.

Ä°lk olarak, katlamalÄ± sayÄ±nÄ±n seÃ§imi hedeflerinize gÃ¶re olmalÄ±dÄ±r:

* AmacÄ±nÄ±z performans tahmini yapmaksa, dÃ¼ÅŸÃ¼k biaslÄ± (yanlÄ±lÄ±ksÄ±z) modeller gerekir (yani tahminlerde sistematik bir distorsiyon olmamalÄ±dÄ±r). Bunu baÅŸarmak iÃ§in daha yÃ¼ksek sayÄ±da katlama kullanmanÄ±z gerekir, genellikle 10 ila 20 arasÄ±nda.
* AmacÄ±nÄ±z parametre ayarlamasÄ± yapmaksa, bias ve varyans karÄ±ÅŸÄ±mÄ±na ihtiyacÄ±nÄ±z vardÄ±r, bu nedenle orta sayÄ±da katlama kullanmak uygundur, genellikle 5 ila 7 arasÄ±nda.
* Son olarak, amacÄ±nÄ±z sadece deÄŸiÅŸken seÃ§imi yapmak ve veri setinizi basitleÅŸtirmekse, dÃ¼ÅŸÃ¼k varyanslÄ± tahminler (ya da anlaÅŸmazlÄ±k yaÅŸamamak) gerekir. Bu nedenle daha dÃ¼ÅŸÃ¼k sayÄ±da katlama yeterlidir, genellikle 3 ila 5 arasÄ±nda.

Mevcut verilerin boyutu oldukÃ§a bÃ¼yÃ¼kse, Ã¶nerilen bantlarÄ±n alt tarafÄ±nda kalmak gÃ¼venlidir.

Ä°kinci olarak, sadece performans tahmini yapmayÄ± amaÃ§lÄ±yorsanÄ±z, kullandÄ±ÄŸÄ±nÄ±z daha fazla katlamanÄ±n, doÄŸrulama setinizde daha az Ã¶rnek olacaÄŸÄ± anlamÄ±na geldiÄŸini ve bu nedenle her katÄ±n tahminlerinin daha fazla korelasyon gÃ¶stereceÄŸini unutmayÄ±n. Belirli bir noktadan sonra, k'yÄ± artÄ±rmak, Ã§apraz doÄŸrulama tahminlerinizi gÃ¶rÃ¼nmeyen test setlerine dair daha az Ã¶ngÃ¶rÃ¼cÃ¼ hale getirir ve modelinizin eÄŸitim setindeki performansÄ±nÄ±n tahmini olarak daha Ã§ok temsil eder. Bu, daha fazla katlama ile, sizin iÃ§in doÄŸru bir "out-of-fold" tahmini almanÄ±zÄ± saÄŸladÄ±ÄŸÄ±ndan, model birleÅŸtirme ve yÄ±ÄŸÄ±lma (stacking) gibi teknikler iÃ§in daha faydalÄ± olabilir.

> Kaggle yarÄ±ÅŸmalarÄ±nda, k-katlamalÄ± Ã§apraz doÄŸrulama genellikle sadece Ã§Ã¶zÃ¼m yaklaÅŸÄ±mÄ±nÄ±zÄ± doÄŸrulamak ve modelinizin performansÄ±nÄ± anlamak iÃ§in deÄŸil, aynÄ± zamanda tahmininizi Ã¼retmek iÃ§in de uygulanÄ±r. Ã‡apraz doÄŸrulama yaparken, alt Ã¶rnekleme yapÄ±yorsunuz ve verinin alt Ã¶rneklerine dayalÄ± olarak birden Ã§ok modelin sonuÃ§larÄ±nÄ± ortalamak, genellikle tÃ¼m mevcut verilerle eÄŸitim yapmaktan daha etkili bir stratejidir. Bu, genellikle varyansla mÃ¼cadele etmek iÃ§in daha etkili bir yol olur (bunu daha detaylÄ± olarak 9. BÃ¶lÃ¼m'de, "Blending ve Stacking Ã‡Ã¶zÃ¼mleriyle BirleÅŸtirme" baÅŸlÄ±ÄŸÄ±nda tartÄ±ÅŸacaÄŸÄ±z). Bu nedenle birÃ§ok Kaggle katÄ±lÄ±mcÄ±sÄ±, Ã§apraz doÄŸrulama sÄ±rasÄ±nda oluÅŸturulan modelleri kullanarak test setinde bir dizi tahmin saÄŸlar ve bunlarÄ± ortaladÄ±ÄŸÄ±nda en iyi Ã§Ã¶zÃ¼mÃ¼ elde eder.

**K-KatlamalÄ± Ã‡apraz DoÄŸrulama VaryasyonlarÄ±**

K-katlamalÄ± Ã§apraz doÄŸrulama, rastgele Ã¶rneklemeye dayandÄ±ÄŸÄ± iÃ§in bazÄ± durumlarda uygun olmayan bÃ¶lmeler verebilir:

* **KÃ¼Ã§Ã¼k sÄ±nÄ±flarÄ±n oranÄ±nÄ± korumanÄ±z gerektiÄŸinde**, hem hedef seviyesinde hem de Ã¶zellikler seviyesinde. Bu durum, hedef deÄŸiÅŸkeninizin oldukÃ§a dengesiz olduÄŸu durumlarda yaygÄ±ndÄ±r. Tipik Ã¶rnekler arasÄ±nda spam veri setleri (Ã§Ã¼nkÃ¼ spam, normal e-posta hacminin kÃ¼Ã§Ã¼k bir kÄ±smÄ±dÄ±r) veya bir kredi riski veri seti (dÃ¼ÅŸÃ¼k ihtimalle gerÃ§ekleÅŸen bir kredi temerrÃ¼dÃ¼ olayÄ±nÄ± tahmin etmek) bulunur.

* **Bir sayÄ±sal deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±nÄ± korumanÄ±z gerektiÄŸinde**, hem hedef seviyesinde hem de Ã¶zellikler seviyesinde. Bu durum, daÄŸÄ±lÄ±mÄ±n oldukÃ§a Ã§arpÄ±k olduÄŸu veya uzun kuyruklar iÃ§erdiÄŸi regresyon problemlerinde yaygÄ±ndÄ±r. YaygÄ±n bir Ã¶rnek, ev fiyatÄ± tahmini olabilir, Ã§Ã¼nkÃ¼ satÄ±ÅŸa Ã§Ä±kan bazÄ± evler, ortalama evden Ã§ok daha yÃ¼ksek fiyatlarla satÄ±lmaktadÄ±r.

* **Verileriniz baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda (i.i.d.) deÄŸilse**, Ã¶zellikle zaman serisi tahmini yapÄ±yorsanÄ±z.

Ä°lk iki senaryoda Ã§Ã¶zÃ¼m, **stratifiye k-katlamalÄ± doÄŸrulama** (stratified k-fold) olacaktÄ±r. Bu yÃ¶ntemde, Ã¶rnekleme kontrol edilmiÅŸ bir ÅŸekilde yapÄ±lÄ±r ve korumak istediÄŸiniz daÄŸÄ±lÄ±mÄ± korur. EÄŸer tek bir sÄ±nÄ±fÄ±n daÄŸÄ±lÄ±mÄ±nÄ± korumanÄ±z gerekiyorsa, Scikit-learn'deki `StratifiedKFold` fonksiyonunu kullanabilirsiniz. Bu fonksiyon, genellikle hedef deÄŸiÅŸkeniniz olan, ancak aynÄ± zamanda daÄŸÄ±lÄ±mÄ±nÄ± korumanÄ±z gereken baÅŸka bir Ã¶zellik ile stratifikasyon deÄŸiÅŸkeni kullanarak, verilerinizi doÄŸru bir ÅŸekilde bÃ¶lmenize yardÄ±mcÄ± olacak indeksler Ã¼retir. AynÄ± sonuca, sayÄ±sal bir deÄŸiÅŸken ile, onu Ã¶nce diskretize ettikten sonra `pandas.cut` veya Scikit-learnâ€™Ã¼n `KBinsDiscretizer` fonksiyonlarÄ± ile de ulaÅŸabilirsiniz.

Birden fazla deÄŸiÅŸken veya Ã¶rtÃ¼ÅŸen etiketler (Ã¶rneÄŸin, Ã§ok etiketli sÄ±nÄ±flandÄ±rma) ile stratifikasyon yapmanÄ±z gerektiÄŸinde durum biraz daha karmaÅŸÄ±k hale gelir.

Bu durumu, **Scikit-multilearn** paketinde bulabilirsiniz ([http://scikit.ml/](http://scikit.ml/)), Ã¶zellikle birden fazla deÄŸiÅŸkenin birleÅŸik oranlarÄ±nÄ± korumak istediÄŸiniz sÄ±rayÄ± kontrol etmenizi saÄŸlayan **IterativeStratification** komutuyla ([http://scikit.ml/api/skmultilearn.model_selection.iterative_stratification.html](http://scikit.ml/api/skmultilearn.model_selection.iterative_stratification.html)). Bu, aÅŸaÄŸÄ±daki makalelerde aÃ§Ä±klanan algoritmayÄ± uygular:

* Sechidis, K., Tsoumakas, G., ve Vlahavas, I. (2011). *On the stratification of multi-label data*. Machine Learning and Knowledge Discovery in Databases, 145-158. [Makale Linki](http://lpis.csd.auth.gr/publications/sechidis-ecmlpkdd-2011.pdf)
* SzymaÅ„ski, P. ve Kajdanowicz, T.; *Proceedings of the First International Workshop on Learning with Imbalanced Domains: Theory and Applications*, PMLR 74:22-35, 2017. [Makale Linki](http://proceedings.mlr.press/v74/szyma%C5%84ski17a.html)

Stratifikasyonu, bir sÄ±nÄ±flandÄ±rma problemi deÄŸil de bir regresyon problemi ile uÄŸraÅŸÄ±yorsanÄ±z da oldukÃ§a faydalÄ± bir ÅŸekilde kullanabilirsiniz. Regresyon problemlerinde stratifikasyon kullanmak, regressor'Ã¼nÃ¼zÃ¼n Ã§apraz doÄŸrulama sÄ±rasÄ±nda hedef (veya prediktÃ¶rler) deÄŸiÅŸkeninin, tÃ¼m Ã¶rneklemdeki daÄŸÄ±lÄ±ma benzer bir daÄŸÄ±lÄ±mda eÄŸitim yapmasÄ±nÄ± saÄŸlar. Bu durumda, `StratifiedKFold`'un dÃ¼zgÃ¼n Ã§alÄ±ÅŸmasÄ± iÃ§in sÃ¼rekli hedefiniz yerine hedefinizin diskretize edilmiÅŸ bir proxyâ€™sini kullanmanÄ±z gerekir.

Bunu baÅŸarmanÄ±n ilk ve en basit yolu, pandas `cut` fonksiyonunu kullanarak hedefinizi 10 veya 20 gibi yeterince bÃ¼yÃ¼k bir bin sayÄ±sÄ±na bÃ¶lmektir:

```python
import pandas as pd
y_proxy = pd.cut(y_train, bins=10, labels=False)
```

KullanÄ±lacak bin sayÄ±sÄ±nÄ± belirlemek iÃ§in, Abhishek Thakur, mevcut Ã¶rnek sayÄ±sÄ±na dayalÄ± olarak **Sturges kuralÄ±nÄ±** kullanmayÄ± tercih eder ve bu sayÄ±yÄ± pandas `cut` fonksiyonuna saÄŸlar (bkz. [https://www.kaggle.com/abhishek/step-1-create-folds](https://www.kaggle.com/abhishek/step-1-create-folds)):

```python
import numpy as np
bins = int(np.floor(1 + np.log2(len(X_train))))
```

Alternatif bir yaklaÅŸÄ±m, eÄŸitim setindeki Ã¶zelliklerin daÄŸÄ±lÄ±mlarÄ±na odaklanmak ve bunlarÄ± yeniden Ã¼retmeye Ã§alÄ±ÅŸmaktÄ±r. Bu, eÄŸitim setinin yalnÄ±zca hedef deÄŸiÅŸkeni ve herhangi bir tanÄ±mlayÄ±cÄ±yÄ± hariÃ§ tutarak, Ã¶zellikler Ã¼zerinde kÃ¼me analizi (denetimsiz bir yaklaÅŸÄ±m) yapÄ±lmasÄ±nÄ± gerektirir. SonrasÄ±nda, tahmin edilen kÃ¼meler strata olarak kullanÄ±labilir. Bunun bir Ã¶rneÄŸini bu Not Defteriâ€™nde gÃ¶rebilirsiniz ([https://www.kaggle.com/lucamassaron/are-you-doing-cross-validation-the-best-way](https://www.kaggle.com/lucamassaron/are-you-doing-cross-validation-the-best-way)), burada ilk olarak **PCA** (temel bileÅŸen analizi) yapÄ±lÄ±r, korelasyonlar kaldÄ±rÄ±lÄ±r ve ardÄ±ndan **k-means** kÃ¼me analizi yapÄ±lÄ±r. KullanÄ±lacak kÃ¼me sayÄ±sÄ±nÄ±, deneysel testler yaparak belirleyebilirsiniz.

---

**Uygunsuz BÃ¶lmeler Ä°Ã§in Ã‡Ã¶zÃ¼mler**

K-katlamalÄ± doÄŸrulamanÄ±n uygun olmayan bÃ¶lmeler verebileceÄŸi durumu tartÄ±ÅŸmaya devam edersek, iÅŸlerin karmaÅŸÄ±klaÅŸtÄ±ÄŸÄ± Ã¼Ã§Ã¼ncÃ¼ senaryo, **baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmayan (non-i.i.d.) verilerle** karÅŸÄ±laÅŸÄ±ldÄ±ÄŸÄ±nda yaÅŸanÄ±r. Bu durum, Ã¶rnekler arasÄ±nda bir gruplaÅŸma olduÄŸunda meydana gelir. BaÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmayan Ã¶rneklerin sorunu, Ã¶zellikler ve hedef deÄŸiÅŸkenin Ã¶rnekler arasÄ±nda birbirleriyle korelasyonlu olmasÄ±dÄ±r (yani, sadece bir Ã¶rneÄŸi biliyorsanÄ±z, tÃ¼m Ã¶rnekleri tahmin etmek daha kolay olur). GerÃ§ekten de, eÄŸer aynÄ± grup eÄŸitim ve test setlerine bÃ¶lÃ¼nÃ¼rse, modeliniz gruplarÄ± ayÄ±rt etmeyi Ã¶ÄŸrenebilir, ancak hedefi Ã¶ÄŸrenmeyebilir ve bu da iyi bir doÄŸrulama skoru elde etmenize ancak liderlik tablosunda Ã§ok kÃ¶tÃ¼ sonuÃ§lar almanÄ±za neden olabilir. Buradaki Ã§Ã¶zÃ¼m, **GroupKFold** kullanmaktÄ±r: bir gruplama deÄŸiÅŸkeni saÄŸlayarak, her grubun ya eÄŸitim setinde ya da doÄŸrulama setinde yer almasÄ±nÄ±, ancak asla her iki set arasÄ±nda bÃ¶lÃ¼nmemesini saÄŸlarsÄ±nÄ±z.

Verilerinizdeki gruplamalarÄ± keÅŸfetmek, verinizin baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmamasÄ±nÄ± saÄŸlayan zor bir gÃ¶rev olabilir. YarÄ±ÅŸma probleminiz tarafÄ±ndan belirtilmedikÃ§e, veriyi araÅŸtÄ±rma (denetimsiz Ã¶ÄŸrenme teknikleri, Ã¶rneÄŸin kÃ¼me analizi kullanarak) ve problemin domainini anlamanÄ±zÄ± gerektirir. Ã–rneÄŸin, veriniz mobil telefon kullanÄ±mÄ±yla ilgiliyse, bazÄ± Ã¶rneklerin aynÄ± kullanÄ±cÄ±ya ait olduÄŸunu, Ã¶zelliklerdeki benzer deÄŸer sÄ±ralamalarÄ±na bakarak fark edebilirsiniz.

Zaman serisi analizi de aynÄ± sorunu sunar; veriler baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mda olmadÄ±ÄŸÄ± iÃ§in, rastgele Ã¶rneklemeyle doÄŸrulama yapamazsÄ±nÄ±z Ã§Ã¼nkÃ¼ farklÄ± zaman dilimlerini karÄ±ÅŸtÄ±rmÄ±ÅŸ olursunuz ve sonraki zaman dilimleri Ã¶nceki zaman dilimlerinin izlerini taÅŸÄ±yabilir (bu, istatistikte *otokorelasyon* olarak adlandÄ±rÄ±lan bir Ã¶zelliktir). Zaman serisi doÄŸrulamasÄ±nÄ±n en temel yaklaÅŸÄ±mÄ±nda, zamanÄ± temel alarak eÄŸitim ve doÄŸrulama setlerini ayÄ±rabilirsiniz, bu, Åekil 6.3'te gÃ¶sterildiÄŸi gibi:

![](im/1053.png)

"DoÄŸrulama yetenekleriniz sÄ±nÄ±rlÄ± olacaktÄ±r, Ã§Ã¼nkÃ¼ doÄŸrulamanÄ±z belirli bir zamana dayanacaktÄ±r. Daha karmaÅŸÄ±k bir yaklaÅŸÄ±m iÃ§in, Scikit-learn paketi (sklearn.model_selection.TimeSeriesSplit) tarafÄ±ndan saÄŸlanan zaman dilimi doÄŸrulamasÄ±nÄ±, TimeSeriesSplit'i kullanabilirsiniz. TimeSeriesSplit, zaman serisinin eÄŸitim ve test kÄ±sÄ±mlarÄ±nÄ±n zaman dilimini ayarlamanÄ±za yardÄ±mcÄ± olabilir.


EÄŸitim zaman dilimi durumunda, TimeSeriesSplit fonksiyonu, eÄŸitim verilerinizi test zaman diliminden Ã¶nceki tÃ¼m geÃ§miÅŸ verileri iÃ§erecek ÅŸekilde ayarlamanÄ±za yardÄ±mcÄ± olabilir veya sabit bir dÃ¶nem geriye bakma sÃ¼resiyle (Ã¶rneÄŸin, her zaman test zaman diliminden Ã¶nceki Ã¼Ã§ ayÄ± eÄŸitim iÃ§in kullanmak gibi) sÄ±nÄ±rlayabilirsiniz.

Åekil 6.4'te, bÃ¼yÃ¼yen bir eÄŸitim seti ve hareketli bir doÄŸrulama seti iÃ§eren zaman tabanlÄ± doÄŸrulama stratejisinin yapÄ±sÄ±nÄ± gÃ¶rebilirsiniz."

![](im/1054.png)

Åekil 6.5'te, eÄŸitim setinin sabit bir geriye bakma sÃ¼resi olduÄŸu durumda stratejinin nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶rebilirsiniz.

![](im/1055.png)

Deneyimlerimize gÃ¶re, sabit bir bakÄ±ÅŸ aralÄ±ÄŸÄ± kullanmak, zaman serisi modellerinin deÄŸerlendirilmesinde daha adil bir sonuÃ§ saÄŸlar Ã§Ã¼nkÃ¼ her zaman aynÄ± eÄŸitim veri seti boyutuna gÃ¼venirsiniz.

Bunun yerine zamanla bÃ¼yÃ¼yen bir eÄŸitim seti boyutu kullanmak, model performansÄ±nÄ±n zaman dilimlerine gÃ¶re etkilerini, modeldeki azalan yanlÄ±lÄ±k ile karÄ±ÅŸtÄ±rmanÄ±za neden olur (Ã§Ã¼nkÃ¼ daha fazla Ã¶rnek, daha az yanlÄ±lÄ±k anlamÄ±na gelir).

Son olarak, TimeSeriesSplit'in, eÄŸitim ve test zamanlarÄ± arasÄ±nda Ã¶nceden tanÄ±mlanmÄ±ÅŸ bir boÅŸluk bÄ±rakacak ÅŸekilde ayarlanabileceÄŸini unutmayÄ±n. Bu, test setinizin belirli bir sÃ¼re sonra (Ã¶rneÄŸin, eÄŸitim verisinden bir ay sonra) olduÄŸunu biliyorsanÄ±z ve modelinizin gelecekte bu kadar ileriye tahmin yapÄ±p yapamayacaÄŸÄ±nÄ± test etmek istiyorsanÄ±z son derece kullanÄ±ÅŸlÄ±dÄ±r.

**Ä°Ã§ Ä°Ã§e Ã‡apraz DoÄŸrulama**

Bu noktada, iÃ§ iÃ§e Ã§apraz doÄŸrulamanÄ±n tanÄ±tÄ±lmasÄ± Ã¶nemlidir. Åimdiye kadar yalnÄ±zca modelleri son performanslarÄ±na gÃ¶re test etmeyi tartÄ±ÅŸtÄ±k, ancak Ã§oÄŸu zaman hiperparametrelerini ayarlarken ara performanslarÄ±nÄ± da test etmeniz gerekir. GerÃ§ekten de, test setinizde model parametrelerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test edemezsiniz ve ardÄ±ndan aynÄ± veriyi nihai performansÄ± deÄŸerlendirmek iÃ§in kullanamazsÄ±nÄ±z. Ã‡Ã¼nkÃ¼ test setinde en iyi Ã§alÄ±ÅŸan parametreleri belirlemiÅŸsinizdir ve aynÄ± test setindeki deÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼nÃ¼z Ã§ok iyimser olacaktÄ±r; farklÄ± bir test setinde, muhtemelen aynÄ± sonucu elde edemezsiniz. Bu durumda, Ã§eÅŸitli modellerin ve hiperparametrelerin performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lan **doÄŸrulama seti** ile nihai model performansÄ±nÄ± tahmin etmek iÃ§in kullanÄ±lan **test seti** arasÄ±ndaki farkÄ± ayÄ±rt etmeniz gerekir.

EÄŸer test-eÄŸitim ayrÄ±mÄ± kullanÄ±yorsanÄ±z, bu, test kÄ±smÄ±nÄ± iki yeni parÃ§aya ayÄ±rarak yapÄ±lÄ±r. YaygÄ±n olarak kullanÄ±lan ayrÄ±m 70/20/10'dur: eÄŸitim, doÄŸrulama ve test, sÄ±rasÄ±yla (ancak farklÄ± bir oran seÃ§ebilirsiniz). EÄŸer Ã§apraz doÄŸrulama kullanÄ±yorsanÄ±z, iÃ§ iÃ§e Ã§apraz doÄŸrulama yapmanÄ±z gerekir; yani baÅŸka bir Ã§apraz doÄŸrulamanÄ±n bÃ¶lÃ¼nmesine dayalÄ± olarak Ã§apraz doÄŸrulama yaparsÄ±nÄ±z. Temelde, her zamanki Ã§apraz doÄŸrulamanÄ±zÄ± Ã§alÄ±ÅŸtÄ±rÄ±rsÄ±nÄ±z, ancak farklÄ± modelleri veya parametreleri deÄŸerlendirmek zorunda olduÄŸunuzda, deÄŸerlendirme ve optimizasyon yapmak iÃ§in eÄŸitim verileriyle birlikte Ã§apraz doÄŸrulama yaparsÄ±nÄ±z.

Åekil 6.6'daki Ã¶rnek, bu iÃ§sel ve dÄ±ÅŸsal Ã§apraz doÄŸrulama yapÄ±sÄ±nÄ± gÃ¶sterir. DÄ±ÅŸsal kÄ±sÄ±mda, deÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼nÃ¼zÃ¼ test etmek iÃ§in kullanÄ±lan veri kÄ±smÄ±nÄ± belirlersiniz. Ä°Ã§sel kÄ±sÄ±mda ise, dÄ±ÅŸsal kÄ±sÄ±mdan gelen eÄŸitim verileriyle, model seÃ§imlerini optimize etmek ve hangi model veya hiperparametre deÄŸerlerinin seÃ§ileceÄŸini belirlemek amacÄ±yla eÄŸitim/doÄŸrulama bÃ¶lÃ¼nmeleri dÃ¼zenlersiniz.

![](im/1056.png)

**Bu yaklaÅŸÄ±mÄ±n avantajÄ±, test ve parametre aramanÄ±zÄ± tamamen gÃ¼venilir hale getirmesidir, ancak bunu yaparken birkaÃ§ problemle karÅŸÄ±laÅŸÄ±rsÄ±nÄ±z:**

* Ã‡apraz doÄŸrulama ile ilk bÃ¶lmeyi yaptÄ±ktan sonra, bir kez daha bÃ¶lme yapmanÄ±z gerektiÄŸi iÃ§in eÄŸitim setiniz azalÄ±r.
* Daha Ã¶nemlisi, Ã§ok sayÄ±da model oluÅŸturmanÄ±z gerekir: EÄŸer iki iÃ§ iÃ§e geÃ§miÅŸ 10 katlÄ± Ã§apraz doÄŸrulama yaparsanÄ±z, 100 model Ã§alÄ±ÅŸtÄ±rmanÄ±z gerekir.

Ã–zellikle son sebepten dolayÄ± bazÄ± Kaggle yarÄ±ÅŸmacÄ±larÄ±, iÃ§ iÃ§e Ã§apraz doÄŸrulamayÄ± gÃ¶z ardÄ± eder ve model/parametre arama ile performans deÄŸerlendirmesi iÃ§in aynÄ± Ã§apraz doÄŸrulamayÄ± kullanmayÄ± ya da nihai deÄŸerlendirme iÃ§in sabit bir test Ã¶rneÄŸi kullanmayÄ± tercih ederler. Deneyimlerimize gÃ¶re bu yaklaÅŸÄ±m da iÅŸe yarayabilir, ancak model performansÄ±nÄ±n aÅŸÄ±rÄ± tahmin edilmesine ve aÅŸÄ±rÄ± uyum (overfitting) durumlarÄ±na yol aÃ§abilir. Bu durum, modelleme sÃ¼recinde kullanÄ±lan katman dÄ±ÅŸÄ± (out-of-fold) tahminler oluÅŸturuyorsanÄ±z daha belirgin hale gelebilir (ki bu konuyu bir sonraki bÃ¶lÃ¼mde ele alacaÄŸÄ±z). Biz her zaman, modellerinizi test etmek iÃ§in en uygun metodolojiyi denemenizi Ã¶neriyoruz. EÄŸer amacÄ±nÄ±z modelinizin performansÄ±nÄ± doÄŸru bir ÅŸekilde tahmin etmek ve tahminlerini baÅŸka modellerde yeniden kullanmaksa, iÃ§ iÃ§e Ã§apraz doÄŸrulama kullanmak, mÃ¼mkÃ¼n olduÄŸunda size daha az aÅŸÄ±rÄ± uyumlu bir Ã§Ã¶zÃ¼m sunabilir ve bazÄ± yarÄ±ÅŸmalarda fark yaratabilir.

**Katman DÄ±ÅŸÄ± Tahminler (OOF) Ãœretme**

Ã‡apraz doÄŸrulamanÄ±n ilginÃ§ bir uygulamasÄ±, deÄŸerlendirme metriÄŸinizin performansÄ±nÄ± tahmin etmenin yanÄ± sÄ±ra test tahminleri ve katman dÄ±ÅŸÄ± tahminler (OOF) Ã¼retmektir. GerÃ§ekten de, eÄŸitim verinizin bazÄ± bÃ¶lÃ¼mleri Ã¼zerinde eÄŸitim yaparken ve geri kalanlar Ã¼zerinde tahminler yaparken ÅŸunlarÄ± yapabilirsiniz:

* **Test seti Ã¼zerinde tahmin yapmak**: TÃ¼m tahminlerin ortalamasÄ±, genellikle tÃ¼m veriler Ã¼zerinde aynÄ± modeli tekrar eÄŸitmekten daha etkili olabilir. Bu, blending ile iliÅŸkili bir topluluk (ensemble) tekniÄŸidir ve 9. BÃ¶lÃ¼m olan *Ensemble: Blending ve Stacking Ã‡Ã¶zÃ¼mleri*'nde ele alÄ±nacaktÄ±r.

* **DoÄŸrulama seti Ã¼zerinde tahmin yapmak**: Sonunda, tÃ¼m eÄŸitim seti iÃ§in tahminleriniz olacak ve bunlarÄ±, orijinal eÄŸitim verileriyle aynÄ± sÄ±rada yeniden sÄ±ralayabilirsiniz. Bu tahminlere genellikle "katman dÄ±ÅŸÄ± (OOF) tahminleri" denir ve oldukÃ§a faydalÄ± olabilirler.

OOF tahminlerinin ilk kullanÄ±mÄ±, performansÄ±nÄ±zÄ± tahmin etmektir Ã§Ã¼nkÃ¼ deÄŸerlendirme metriÄŸinizi doÄŸrudan OOF tahminleri Ã¼zerinde hesaplayabilirsiniz. Elde edilen performans, Ã§apraz doÄŸrulama tahminlerinden (Ã¶rneklemeye dayalÄ±) farklÄ±dÄ±r; aynÄ± olasÄ±lÄ±k Ã¶zelliklerine sahip deÄŸildir, bu yÃ¼zden genelleme performansÄ±nÄ± Ã¶lÃ§mek iÃ§in geÃ§erli bir yol deÄŸildir, ancak modelinizin eÄŸitildiÄŸiniz belirli set Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸi hakkÄ±nda size bilgi verebilir.

Ä°kinci bir kullanÄ±m, tahminleri zemin gerÃ§ek deÄŸerleriyle veya farklÄ± modellerden elde edilen diÄŸer tahminlerle karÅŸÄ±laÅŸtÄ±rarak gÃ¶rselleÅŸtirmek ve bir grafik oluÅŸturmak olabilir. Bu, her bir modelin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve tahminlerinin birbiriyle ne kadar korelasyonlu olduÄŸunu anlamanÄ±za yardÄ±mcÄ± olacaktÄ±r.

Son kullanÄ±m ise meta Ã¶zellikler veya meta tahminciler (meta-predictors) yaratmaktÄ±r. Bu konu, 9. BÃ¶lÃ¼m'de tam olarak ele alÄ±nacaktÄ±r, ancak burada ÅŸunu belirtmek Ã¶nemlidir ki, OOF tahminleri Ã§apraz doÄŸrulamanÄ±n bir yan Ã¼rÃ¼nÃ¼ olup, Ã§alÄ±ÅŸtÄ±klarÄ± iÃ§in kullanÄ±lÄ±r; Ã§Ã¼nkÃ¼ Ã§apraz doÄŸrulama sÄ±rasÄ±nda, modeliniz her zaman eÄŸitim sÄ±rasÄ±nda gÃ¶rmediÄŸi Ã¶rnekler Ã¼zerinde tahmin yapar.

Her OOF tahmininin farklÄ± bir veri seti Ã¼zerinde eÄŸitilmiÅŸ bir model tarafÄ±ndan Ã¼retildiÄŸinden, bu tahminler yanlÄ±lÄ±k iÃ§ermez ve bunlarÄ± aÅŸÄ±rÄ± uyum (overfitting) riskinden korkmadan kullanabilirsiniz (bununla ilgili bazÄ± uyarÄ±lar bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸÄ±lacaktÄ±r).

OOF tahminlerini Ã¼retmenin iki yolu vardÄ±r:

* **Bir prosedÃ¼r kodlayarak** doÄŸrulama tahminlerini bir tahmin vektÃ¶rÃ¼ne kaydetmek ve bunlarÄ± eÄŸitim verilerindeki Ã¶rneklerle aynÄ± indeks konumuna yerleÅŸtirmek.
* **Scikit-learn fonksiyonu olan `cross_val_predict`'i kullanarak**, OOF tahminlerini otomatik olarak Ã¼retmek.

Bu ikinci tekniÄŸi, bu bÃ¶lÃ¼mÃ¼n ilerleyen kÄ±sÄ±mlarÄ±nda *adversarial validation*'Ä± incelediÄŸimizde gÃ¶receÄŸiz.

##### Subsampling *(Alt Ã¶rnekleme)*

**k-katlÄ± Ã§apraz doÄŸrulama dÄ±ÅŸÄ±nda baÅŸka doÄŸrulama stratejileri de vardÄ±r, ancak bunlar aynÄ± genelleme Ã¶zelliklerine sahip deÄŸildir.**

Zaten LOO'yu (Leave-One-Out) tartÄ±ÅŸtÄ±k, bu durum k = n olduÄŸunda (burada n, Ã¶rneklerin sayÄ±sÄ±dÄ±r). DiÄŸer bir seÃ§enek ise **alt Ã¶rnekleme**dir. Alt Ã¶rnekleme, k-katlÄ±ya benzer, ancak sabit katlarÄ±nÄ±z yoktur; ihtiyacÄ±nÄ±z olduÄŸuna dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z kadarÄ±nÄ± kullanÄ±rsÄ±nÄ±z (baÅŸka bir deyiÅŸle, eÄŸitilmiÅŸ bir tahminde bulunursunuz). Verinizi tekrar tekrar alt Ã¶rneklerken, her seferinde Ã¶rneklediÄŸiniz veriyi eÄŸitim verisi olarak kullanÄ±r, geri kalan veriyi ise doÄŸrulama iÃ§in bÄ±rakÄ±rsÄ±nÄ±z. TÃ¼m alt Ã¶rneklerin deÄŸerlendirme metriklerinin ortalamasÄ±nÄ± alarak, modelinizin performanslarÄ± iÃ§in bir doÄŸrulama tahmini elde edersiniz.

k-katlÄ± doÄŸrulama gibi, tÃ¼m Ã¶rneklerinizi sistematik olarak test ettiÄŸiniz iÃ§in, bunlarÄ±n hepsini test etme ÅŸansÄ±nÄ±zÄ±n iyi olabilmesi iÃ§in oldukÃ§a fazla deneme yapmanÄ±z gerekir. AynÄ± sebeple, yeterli sayÄ±da alt Ã¶rnekleme uygulamazsanÄ±z, bazÄ± Ã¶rnekler diÄŸerlerinden daha fazla test edilebilir. Bu tÃ¼r bir doÄŸrulamayÄ±, Scikit-learn'deki **ShuffleSplit** kullanarak yapabilirsiniz.

##### The bootstrap *(Bootstrap yÃ¶ntemi)*

Son olarak, hata daÄŸÄ±lÄ±mÄ±nÄ± sonuÃ§landÄ±rmak iÃ§in istatistiklerde geliÅŸtirilen bootstrap yÃ¶ntemini kullanmayÄ± deneyebilirsiniz; aynÄ± nedenlerden Ã¶tÃ¼rÃ¼, bu yÃ¶ntem performans tahmini iÃ§in de kullanÄ±labilir. Bootstrap, verilerinizi Ã¶rnekleme yaparak, yani yerine koyarak, aynÄ± boyutta bir Ã¶rneklem oluÅŸturmanÄ±zÄ± gerektirir.

Bu noktada bootstrap'Ä± iki farklÄ± ÅŸekilde kullanabilirsiniz:

* Ä°statistiklerde olduÄŸu gibi, bootstrap'Ä± birden Ã§ok kez uygulayarak modelinizi Ã¶rnekler Ã¼zerinde eÄŸitebilir ve eÄŸitim verisi Ã¼zerinde deÄŸerlendirme metriÄŸinizi hesaplayabilirsiniz. Bootstrap'larÄ±n ortalamasÄ±, nihai deÄŸerlendirmenizi saÄŸlar.
* Alternatif olarak, alt Ã¶rnekleme (subsampling) gibi, bootstrap edilmiÅŸ Ã¶rneklemi eÄŸitim iÃ§in kullanabilir ve Ã¶rnekleme yapÄ±lmayan veri kÄ±smÄ±nÄ± test setiniz olarak bÄ±rakabilirsiniz.

Deneyimlerimize gÃ¶re, bootstrap ile eÄŸitim verisi Ã¼zerinde deÄŸerlendirme metriÄŸi hesaplamak, doÄŸrusal modeller iÃ§in modelin katsayÄ±larÄ±nÄ± ve hata daÄŸÄ±lÄ±mlarÄ±nÄ± tahmin etmek amacÄ±yla istatistiklerde sÄ±klÄ±kla kullanÄ±lan bir yÃ¶ntem olmasÄ±na raÄŸmen, makine Ã¶ÄŸreniminde pek faydalÄ± deÄŸildir. Ã‡Ã¼nkÃ¼ birÃ§ok makine Ã¶ÄŸrenimi algoritmasÄ± eÄŸitim verilerine aÅŸÄ±rÄ± uyum saÄŸlama eÄŸilimindedir, bu nedenle eÄŸitim verisi Ã¼zerinde geÃ§erli bir metrik deÄŸerlendirmesi elde edilemez. Bu sebeple, Efron ve Tibshirani (bkz: Efron, B. ve Tibshirani, R. "Cross-validation'da iyileÅŸtirmeler: 632+ bootstrap yÃ¶ntemi". *Journal of the American Statistical Association* 92.438 (1997): 548-560.) final doÄŸrulama metriÄŸi olarak 632+ estimator'Ä±nÄ± Ã¶nermiÅŸlerdir.

BaÅŸlangÄ±Ã§ta, basit bir versiyon olan 632 bootstrapâ€™Ä± Ã¶nermiÅŸlerdir:

$$
Err_{632} = 0.368 * err_{fit} + 0.632 * err_{bootstrap}
$$

Bu formÃ¼lde, deÄŸerlendirme metriÄŸiniz err, errfit eÄŸitim verisi Ã¼zerinde hesapladÄ±ÄŸÄ±nÄ±z metrik ve errbootstrap ise bootstrap edilmiÅŸ veriler Ã¼zerinde hesapladÄ±ÄŸÄ±nÄ±z metriktir. Ancak, aÅŸÄ±rÄ± uyum saÄŸlamÄ±ÅŸ bir eÄŸitim modelinde, errfit sÄ±fÄ±ra yaklaÅŸacak ve bu durumda estimator pek faydalÄ± olmayacaktÄ±r. Bu yÃ¼zden, 632+ bootstrapâ€™Ä±n ikinci versiyonunu geliÅŸtirmiÅŸlerdir:

$$
Err_{.632} + (1 - w) * err_{fit} + w * err_{bootstrap}
$$

Burada w, ÅŸu ÅŸekilde tanÄ±mlanÄ±r:

$$
w = \frac{0.632}{1 - 0.632R}
$$
$$
R = \frac{err_{bootstrap} - err_{fit}}{\gamma - err_{fit}}
$$

Yeni bir parametre olan (\gamma) burada "no-information error rate" (bilgi iÃ§ermeyen hata oranÄ±) olarak tanÄ±mlanÄ±r ve hedefler ile prediktÃ¶rlerin tÃ¼m olasÄ± kombinasyonlarÄ± Ã¼zerinde tahmin modelini deÄŸerlendirerek tahmin edilir. Ancak, (\gamma)â€™yÄ± hesaplamak pratikte imkansÄ±zdÄ±r, bu konuda Scikit-learn geliÅŸtiricilerinin ([https://github.com/scikit-learn/scikit-learn/issues/9153](https://github.com/scikit-learn/scikit-learn/issues/9153)) de tartÄ±ÅŸtÄ±ÄŸÄ± gibi.

Statistiklerdeki klasik bootstrap kullanÄ±mÄ±nÄ±n makine Ã¶ÄŸrenimine uygulanmasÄ±ndaki sÄ±nÄ±rlamalar ve iÅŸlem zorluklarÄ± gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, bunun yerine bootstrap'Ä±n ikinci yÃ¶ntemini kullanmak daha uygundur; bootstrap Ã¶rnekleme yapÄ±lmamÄ±ÅŸ verileri test verisi olarak kullanarak deÄŸerlendirme yapmaktÄ±r.

Bu ÅŸekilde bootstrap, Ã§apraz doÄŸrulamaya (cross-validation) bir alternatif olabilir. Ancak, subsampling gibi, Ã§apraz doÄŸrulama yÃ¶ntemine gÃ¶re daha fazla model inÅŸa edilmesi ve test edilmesi gerekmektedir. Ancak, Ã§apraz doÄŸrulama metrik deÄŸerlendirmesinde yÃ¼ksek varyans gÃ¶steren durumlar ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zda, bootstrapâ€™Ä± bu tÃ¼r durumlar iÃ§in daha yoÄŸun test ve yeniden test yaparak model doÄŸrulamanÄ±zda kullanmanÄ±z faydalÄ± olacaktÄ±r.

Daha Ã¶nce bu yÃ¶ntem Scikit-learn'de uygulanmÄ±ÅŸtÄ± ([https://github.com/scikit-learn/scikit-learn/blob/0.16.X/sklearn/cross_validation.py#L613](https://github.com/scikit-learn/scikit-learn/blob/0.16.X/sklearn/cross_validation.py#L613)), ancak sonrasÄ±nda kaldÄ±rÄ±ldÄ±. Ã‡Ã¼nkÃ¼ Scikit-learn'deki bootstrap hem test verilerini hem de eÄŸitim verilerini bootstrap'lamaktaydÄ±. Åimdi bootstrap'Ä± bulamayacaÄŸÄ±nÄ±z iÃ§in, kendi uygulamamÄ±zÄ± kullanabilirsiniz. Ä°ÅŸte Ã¶rnek:

```python
import random
def Bootstrap(n, n_iter=3, random_state=None):
    """
    Yerine koyarak rastgele Ã¶rnekleme yapan Ã§apraz doÄŸrulama jeneratÃ¶rÃ¼.
    Her iterasyonda, [0, n) aralÄ±ÄŸÄ±ndaki indekslerden bir bootstrap Ã¶rneÄŸi oluÅŸturulur
    ve fonksiyon elde edilen Ã¶rneklem ve dÄ±ÅŸarÄ±da kalan tÃ¼m indekslerin listesini dÃ¶ndÃ¼rÃ¼r.
    """
    if random_state:
        random.seed(random_state)
    for j in range(n_iter):
        bs = [random.randint(0, n-1) for i in range(n)]
        out_bs = list({i for i in range(n)} - set(bs))
        yield bs, out_bs
```

SonuÃ§ olarak, bootstrap, Ã§apraz doÄŸrulamaya bir alternatif olarak deÄŸerlendirilebilir. Ä°statistik ve finans alanlarÄ±nda daha yaygÄ±n kullanÄ±lsa da, makine Ã¶ÄŸreniminde altÄ±n kural genellikle k-kat Ã§apraz doÄŸrulama yaklaÅŸÄ±mÄ±nÄ± kullanmaktÄ±r. Ancak, Ã§apraz doÄŸrulama metriÄŸinizde Ã§ok yÃ¼ksek bir varyans varsa ve daha yoÄŸun test ve yeniden test yapmanÄ±z gerekiyorsa, bootstrap'Ä± unutmayÄ±n. Bu tÃ¼r durumlarda bootstrap, modellerinizi doÄŸrulamak iÃ§in Ã§ok daha faydalÄ± olacaktÄ±r.

> **Ryan Chesler**
> 
> [https://www.kaggle.com/ryches](https://www.kaggle.com/ryches)
> 
> 
> 
> BÃ¶lÃ¼mÃ¼n ikinci rÃ¶portajÄ± Ryan Chesler ile yapÄ±lmÄ±ÅŸtÄ±r. Kendisi bir *Discussions Grandmaster* ve *Notebooks ve Competitions Master* unvanlarÄ±na sahiptir. H2O.aiâ€™de veri bilimcisidir ve aynÄ± zamanda Meetup'ta San Diego Makine Ã–ÄŸrenimi grubunun organizatÃ¶rlerinden birisidir ([https://www.meetup.com/San-Diego-Machine-Learning/](https://www.meetup.com/San-Diego-Machine-Learning/)). YanÄ±tlarÄ±nÄ±n birkaÃ§Ä±nda doÄŸrulamanÄ±n Ã¶nemi vurgulanmÄ±ÅŸtÄ±r.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggle'da hangi tekniklerde ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ±nda uzmanlaÅŸtÄ±nÄ±z?**
> 
> Ben genellikle her tÃ¼r yarÄ±ÅŸmaya katÄ±lmaya Ã§alÄ±ÅŸÄ±rÄ±m. Belirli bir alanda uzmanlaÅŸmak yerine farklÄ± problemlerin Ã§Ã¶zÃ¼mÃ¼nÃ¼ denemek daha ilgi Ã§ekici. En ilginÃ§ bulduÄŸum yarÄ±ÅŸmalar, verilerden ve tahmin hatalarÄ±ndan derinlemesine Ã§Ä±karÄ±mlar yapabileceÄŸimiz yarÄ±ÅŸmalardÄ±r. Benim iÃ§in hata analizi en aydÄ±nlatÄ±cÄ± sÃ¼reÃ§lerden birisidir; modelin nerelerde baÅŸarÄ±sÄ±z olduÄŸunu anlamak ve modelin ya da girdi verisi temsilinin zayÄ±f yÃ¶nlerini dÃ¼zeltmek iÃ§in bir yol aramak Ã§ok Ã¶nemlidir.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±dÄ±r?**
> 
> YaklaÅŸÄ±mÄ±m her iki durumda da benzer. BirÃ§ok kiÅŸi, herhangi bir modelleme Ã§abasÄ±na baÅŸlamadan Ã¶nce keÅŸifsel veri analizini tercih eder, ancak ben veriyi modelleme iÃ§in hazÄ±rlama sÃ¼recinin genellikle yeterli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. Tipik yaklaÅŸÄ±mÄ±m, veriyi manuel olarak gÃ¶zden geÃ§irmek ve veriyi nasÄ±l en iyi ÅŸekilde modelleyeceÄŸim ve keÅŸfedebileceÄŸim farklÄ± seÃ§enekler hakkÄ±nda bazÄ± Ã¶n kararlar almak. SonrasÄ±nda modelimi kurarÄ±m, performansÄ±nÄ± deÄŸerlendiririm, ardÄ±ndan hatalarÄ± analiz etmeye odaklanÄ±rÄ±m ve modelin nerelerde hata yaptÄ±ÄŸÄ±na dayanarak bir sonraki modelleme adÄ±mlarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼rÃ¼m.
> 
> 
> 
> **Kaggle kariyerinizde size yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?**
> 
> Evet, ÅŸu anki iÅŸimi bu sayede buldum. H2Oâ€™da Ã§alÄ±ÅŸÄ±yorum ve Kaggle baÅŸarÄ±larÄ±na Ã§ok deÄŸer veriyorlar. Ã–nceki iÅŸim de yarÄ±ÅŸmalarda iyi performans sergilememi beÄŸeniyordu.
> 
> 
> 
> **AynÄ± zamanda San Diego'da 2000'den fazla katÄ±lÄ±mcÄ±sÄ± olan bir meet-upâ€™Ä±n organizatÃ¶rÃ¼sÃ¼nÃ¼z. Bu, Kaggle deneyiminizle ilgili mi?**
> 
> Evet, kesinlikle ilgili. Ã‡ok az bilgiyle baÅŸladÄ±m ve ilk baÅŸta pek baÅŸarÄ±lÄ± olamadÄ±ÄŸÄ±m bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±ldÄ±m. Bir yerel meet-up'a katÄ±ldÄ±m ve burada birlikte Ã§alÄ±ÅŸacak ve Ã¶ÄŸrenecek insanlarla tanÄ±ÅŸtÄ±m. O zamanlar, benden Ã§ok daha yÃ¼ksek beceri seviyesine sahip insanlarla Ã§alÄ±ÅŸtÄ±m ve bir yarÄ±ÅŸmada gerÃ§ekten iyi bir performans gÃ¶sterdik, 4500+ takÄ±m arasÄ±nda 3. olduk.
> 
> Bundan sonra grup eskisi kadar dÃ¼zenli olmadÄ± ve topluluÄŸu devam ettirmek istedim, bu yÃ¼zden kendi grubumu oluÅŸturdum ve kendi etkinliklerimi dÃ¼zenlemeye baÅŸladÄ±m. Bunu yaklaÅŸÄ±k 4 yÄ±ldÄ±r yapÄ±yorum ve ÅŸimdi insanlarÄ±n Ã¶ÄŸretildiÄŸi ve onlara makine Ã¶ÄŸrenimine baÅŸlama konusunda yardÄ±mcÄ± olduÄŸum tarafÄ±nda yer alÄ±yorum. BaÅŸlangÄ±Ã§ta sadece Kaggle yarÄ±ÅŸmalarÄ±na odaklandÄ±k ve takÄ±mlar kurmaya Ã§alÄ±ÅŸtÄ±k, ancak zamanla kitap kulÃ¼pleri ve Ã§eÅŸitli ilgi alanlarÄ±na yÃ¶nelik dersler yapmaya baÅŸladÄ±k. BaÅŸarÄ±larÄ±mdan birÃ§oÄŸunu bu haftalÄ±k zamanÄ± makine Ã¶ÄŸrenimini Ã§alÄ±ÅŸmak ve dÃ¼ÅŸÃ¼nmek iÃ§in ayÄ±rmaya borÃ§luyum.
> 
> 
> 
> **Deneyiminize gÃ¶re, deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle hangi noktalarÄ± gÃ¶zden kaÃ§Ä±rÄ±yor? Ä°lk baÅŸladÄ±ÄŸÄ±nÄ±zda ÅŸimdi bildiÄŸiniz ÅŸeyleri bilseydiniz, neyi daha iyi yapardÄ±nÄ±z?**
> 
> Deneyimlerime gÃ¶re, birÃ§ok kiÅŸi bias-variance (yanlÄ±lÄ±k-Ã§eÅŸitlilik) ticaretini ve aÅŸÄ±rÄ± uyum saÄŸlamayÄ± (overfitting) Ã§ok fazla Ã¶nemseme eÄŸiliminde. Bu, insanlarÄ±n sÃ¼rekli olarak Ã§ok fazla endiÅŸe duyduÄŸu bir ÅŸeydir. Odak noktasÄ±, eÄŸitim ve doÄŸrulama performansÄ±nÄ± yakÄ±nlaÅŸtÄ±rmak deÄŸil, doÄŸrulama performansÄ±nÄ± mÃ¼mkÃ¼n olduÄŸunca iyi hale getirmektir.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda hangi hatalarÄ± yaptÄ±nÄ±z?**
> 
> SÃ¼rekli yaptÄ±ÄŸÄ±m hata yeterince keÅŸif yapmamaktÄ±r. Bazen Ã§ok erken bir ÅŸekilde fikirlerimi gÃ¶z ardÄ± ederim, ancak sonradan bu fikirlerin performansÄ± iyileÅŸtirmek iÃ§in Ã¶nemli olduÄŸunu gÃ¶rÃ¼rÃ¼m. Genellikle ilk denememde rekabetÃ§i bir performansa yakÄ±n bir sonuÃ§ alabiliyorum ama iterasyon yaparak ve yeni ÅŸeyler deneyerek devam etmek farklÄ± bir beceri gerektiriyor ve bunun Ã¼zerinde hala Ã§alÄ±ÅŸÄ±yorum.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in kullanmanÄ±zÄ± Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Ã‡oÄŸunlukla standart araÃ§larÄ± kullanÄ±rÄ±m: XGBoost, LightGBM, Pytorch, TensorFlow, Scikit-learn. Belirli bir araca ya da kÃ¼tÃ¼phaneye Ã¶zel bir baÄŸlÄ±lÄ±ÄŸÄ±m yoktur, sadece probleme uygun olan ne varsa onu kullanÄ±rÄ±m.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken birinin aklÄ±nda tutmasÄ± veya yapmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Bence en Ã¶nemli ÅŸey, iyi bir doÄŸrulama yapmaktÄ±r. Ã‡oÄŸu zaman insanlarÄ±n performanslarÄ±nÄ±n iyileÅŸtiÄŸini dÃ¼ÅŸÃ¼nerek kendilerini kandÄ±rdÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yorum, ancak sonra liderlik panosuna gÃ¶nderdiklerinde bekledikleri gibi gitmediÄŸini fark ediyorlar. Yeni gÃ¶rÃ¼lmemiÅŸ verilerle varsayÄ±mlarÄ± eÅŸleÅŸtirmeyi ve yeni koÅŸullara dayanÄ±klÄ± bir model inÅŸa etmeyi Ã¶ÄŸrenmek Ã¶nemli bir beceridir.

### Tuning your model validation system *(Model doÄŸrulama sistemini ayarlamak)*

Bu noktada, tÃ¼m olasÄ± doÄŸrulama stratejilerinin tam bir genel bakÄ±ÅŸÄ±nÄ± elde etmiÅŸ olmalÄ±sÄ±nÄ±z. Bir yarÄ±ÅŸmaya yaklaÅŸtÄ±ÄŸÄ±nÄ±zda, doÄŸrulama stratejinizi belirler ve uygularsÄ±nÄ±z. ArdÄ±ndan, seÃ§tiÄŸiniz stratejinin doÄŸru olup olmadÄ±ÄŸÄ±nÄ± test edersiniz.
AltÄ±n kural olarak, doÄŸrulama stratejinizi belirlerken, yarÄ±ÅŸmanÄ±n organizatÃ¶rlerinin veriyi eÄŸitim, Ã¶zel ve genel test setlerine ayÄ±rma yaklaÅŸÄ±mÄ±nÄ± taklit etmeye Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z. Kendinize ÅŸu sorularÄ± sorun: Organizatorler veriyi nasÄ±l ayÄ±rmÄ±ÅŸ? Rastgele bir Ã¶rneklem mi almÄ±ÅŸlar? Verinin belirli bir daÄŸÄ±lÄ±mÄ±nÄ± mÄ± korumaya Ã§alÄ±ÅŸmÄ±ÅŸlar? Test setleri gerÃ§ekten eÄŸitim verisi ile aynÄ± daÄŸÄ±lÄ±mdan mÄ± seÃ§ilmiÅŸ?
Bunlar, gerÃ§ek dÃ¼nya projelerinde kendinize sormayacaÄŸÄ±nÄ±z sorulardÄ±r. GerÃ§ek dÃ¼nya projelerinde amacÄ±nÄ±z her koÅŸulda genelleme yapabilmektir, ancak bir yarÄ±ÅŸma Ã§ok daha dar bir odakla, modelin verilen test setinde (Ã¶zellikle Ã¶zel test seti) nasÄ±l performans gÃ¶sterdiÄŸi Ã¼zerine yoÄŸunlaÅŸÄ±r. BaÅŸlangÄ±Ã§tan itibaren bu dÃ¼ÅŸÃ¼nceye odaklanÄ±rsanÄ±z, en iyi doÄŸrulama stratejisini bulma ÅŸansÄ±nÄ±z daha yÃ¼ksek olur ve bu da sizi yarÄ±ÅŸmada daha yÃ¼ksek sÄ±ralara taÅŸÄ±yabilir.
Bu sÃ¼reÃ§ deneme-yanÄ±lma yÃ¶ntemidir, bu yÃ¼zden yarÄ±ÅŸma iÃ§in en iyi doÄŸrulama stratejisini bulmaya Ã§alÄ±ÅŸÄ±rken, doÄŸru yolda olup olmadÄ±ÄŸÄ±nÄ±zÄ± anlamak iÃ§in aÅŸaÄŸÄ±daki iki tutarlÄ±lÄ±k kontrolÃ¼nÃ¼ sistematik olarak uygulayabilirsiniz:

1. **Yerel testlerinizin tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol etmelisiniz**. Yani, tek bir Ã§apraz doÄŸrulama katmanÄ±ndaki hata oranlarÄ±nÄ±n birbirinden Ã§ok farklÄ± olmadÄ±ÄŸÄ±ndan emin olmalÄ±sÄ±nÄ±z veya basit bir eÄŸitim-test bÃ¶lmesi kullandÄ±ÄŸÄ±nÄ±zda, aynÄ± sonuÃ§larÄ±n farklÄ± eÄŸitim-test bÃ¶lmeleri kullanÄ±larak tekrarlanabilir olup olmadÄ±ÄŸÄ±nÄ± kontrol etmelisiniz.
2. **Yerel doÄŸrulama hatanÄ±zÄ±n, genel liderlik panosundaki sonuÃ§larla tutarlÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol etmelisiniz**.
   EÄŸer ilk kontrolÃ¼ geÃ§emediyseniz, sorunun ÅŸu olasÄ±lÄ±klardan biri olabileceÄŸini gÃ¶z Ã¶nÃ¼nde bulundurabilirsiniz:

* EÄŸitim veriniz Ã§ok az
* Veriniz Ã§ok Ã§eÅŸitli ve her bir eÄŸitim parÃ§asÄ± diÄŸerlerinden Ã§ok farklÄ± (Ã¶rneÄŸin, Ã§ok yÃ¼ksek kardinaliteye sahip Ã¶zellikleriniz varsa, yani Ã§ok fazla seviyeye sahip Ã¶zellikler â€“ zip kodlarÄ± gibi â€“ ya da Ã§ok deÄŸiÅŸken dÄ±ÅŸ deÄŸerleriniz varsa).
  Her iki durumda da, modelinizin eÄŸitimi iÃ§in veriniz yetersizdir.
  Veri Ã§ok Ã§eÅŸitli gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ durumlarda bile, Ã¶ÄŸrenme eÄŸrilerini Ã§izmek, modelinizin daha fazla veriye ihtiyaÃ§ duyduÄŸunu size gÃ¶sterecektir.
  Bu durumda, daha basit bir algoritmaya geÃ§menin deÄŸerlendirme metriÄŸi Ã¼zerinde iÅŸe yaradÄ±ÄŸÄ±nÄ± keÅŸfetmediÄŸiniz sÃ¼rece (bu durumda varyansÄ± bias ile takas yaparak modelinizin performansÄ±nÄ± kÃ¶tÃ¼leÅŸtirebilirsiniz, ancak her zaman bÃ¶yle olmayabilir), en iyi seÃ§eneÄŸiniz kapsamlÄ± bir doÄŸrulama yaklaÅŸÄ±mÄ± kullanmak olacaktÄ±r. Bunu ÅŸu ÅŸekilde uygulayabilirsiniz:
* Daha bÃ¼yÃ¼k k deÄŸerleri kullanmak (bu, k = n olduÄŸunda LOO'ya yaklaÅŸÄ±r). DoÄŸrulama sonuÃ§larÄ±nÄ±z artÄ±k modelinizin gÃ¶rÃ¼lmemiÅŸ veriler Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸinden Ã§ok, daha bÃ¼yÃ¼k eÄŸitim parÃ§alarÄ± kullanarak daha kararlÄ± deÄŸerlendirmeler yapmanÄ±z konusunda olacaktÄ±r.
* FarklÄ± rastgele tohum baÅŸlangÄ±Ã§larÄ±yla seÃ§ilen farklÄ± veri bÃ¶lmeleri temelinde, birden fazla k-katlamalÄ± doÄŸrulamanÄ±n sonuÃ§larÄ±nÄ± ortalamak.
* TekrarlÄ± bootstrap kullanmak.
  UnutmayÄ±n ki, yerel doÄŸrulama sonuÃ§larÄ±nÄ±zÄ±n kararsÄ±z olmasÄ± durumunda, yalnÄ±zca siz bu sorunu yaÅŸamÄ±yorsunuzdur. Genellikle, bu sorun verinin kaynaÄŸÄ± ve Ã¶zelliklerinden dolayÄ± yaygÄ±n bir problemdir. TartÄ±ÅŸma forumlarÄ±na kulak vererek olasÄ± Ã§Ã¶zÃ¼mler hakkÄ±nda ipuÃ§larÄ± alabilirsiniz. Ã–rneÄŸin, yÃ¼ksek kardinaliteli Ã¶zellikler iÃ§in hedef kodlama (target encoding) iyi bir Ã§Ã¶zÃ¼m olabilir; aykÄ±rÄ± deÄŸerlerle baÅŸa Ã§Ä±kmak iÃ§in ise stratifikasyon yardÄ±mcÄ± olabilir; ve benzeri.
  Ä°lk kontrolÃ¼ geÃ§ip ikinciyi geÃ§emediyseniz, yerel Ã§apraz doÄŸrulamanÄ±z tutarlÄ± ancak liderlik panosundaki sonuÃ§larla tutarsÄ±zsa, bu problemi fark edebilmeniz iÃ§in tÃ¼m deneylerinizi, doÄŸrulama test tÃ¼rlerini, kullanÄ±lan rastgele tohumlarÄ± ve gÃ¶nderilen tahminlerin liderlik panosundaki sonuÃ§larÄ±nÄ± dikkatlice not etmeniz gerekir. Bu ÅŸekilde, basit bir daÄŸÄ±lÄ±m grafiÄŸi Ã§izebilir ve doÄŸrusal regresyon uyumlamayÄ± ya da daha basit olarak, yerel sonuÃ§larÄ±nÄ±z ile iliÅŸkili genel liderlik panosu skorlarÄ± arasÄ±nda bir korelasyon hesaplayabilirsiniz.
  TÃ¼m bunlarÄ± not almak ve analiz etmek zaman ve sabÄ±r gerektirir, ancak yarÄ±ÅŸmadaki performanslarÄ±nÄ±zÄ±n en Ã¶nemli meta-analizini yapmak, sizi baÅŸarÄ±ya taÅŸÄ±yacak en Ã¶nemli adÄ±mdÄ±r.
  EÄŸer uyuÅŸmazlÄ±k, doÄŸrulama skorunuzun sistematik olarak liderlik panosu skorlarÄ±ndan daha dÃ¼ÅŸÃ¼k ya da daha yÃ¼ksek olmasÄ± nedeniyle ortaya Ã§Ä±kÄ±yorsa, doÄŸrulama stratejinizde eksik bir ÅŸeyler olduÄŸuna dair gÃ¼Ã§lÃ¼ bir sinyal alÄ±yorsunuz demektir. Ancak bu sorun, modelinizi geliÅŸtirmenizi engellemez. Modeliniz Ã¼zerinde Ã§alÄ±ÅŸmaya devam edebilir ve ilerlemelerinizi liderlik panosunda gÃ¶rmek bekleyebilirsiniz, ancak bu her zaman orantÄ±lÄ± olmayacaktÄ±r. Ancak sistematik farklar her zaman bir kÄ±rmÄ±zÄ± bayrak anlamÄ±na gelir, bu da sizin yaptÄ±ÄŸÄ±nÄ±zla organizatÃ¶rlerin modelinizi test etme yaklaÅŸÄ±mÄ± arasÄ±nda bir fark olduÄŸunu gÃ¶sterir.

Ã‡ok daha kÃ¶tÃ¼ bir senaryo, yerel Ã§apraz doÄŸrulama skorlarÄ±nÄ±zÄ±n, liderlik panosundaki geri bildirimle hiÃ§biriyle korelasyon gÃ¶stermediÄŸi durumdur. Bu gerÃ§ekten bir kÄ±rmÄ±zÄ± bayraktÄ±r. BÃ¶yle bir durumla karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±zÄ± fark ettiÄŸinizde, derhal bir dizi test ve araÅŸtÄ±rma yaparak bunun nedenini anlamaya Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z, Ã§Ã¼nkÃ¼ bu durum, final sÄ±ralamanÄ±z iÃ§in ciddi bir tehdit oluÅŸturur. BÃ¶yle bir senaryoda birkaÃ§ olasÄ±lÄ±k vardÄ±r:

* Test setinin eÄŸitim setinden farklÄ± bir daÄŸÄ±lÄ±mdan seÃ§ildiÄŸini fark edebilirsiniz. Bu durumda, "adversarial validation" testi (bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸacaÄŸÄ±z) size bu konuda aydÄ±nlatÄ±cÄ± olabilir.
* Veriler baÄŸÄ±msÄ±z ve aynÄ± daÄŸÄ±lÄ±mdan (i.i.d.) deÄŸil, ancak bu durum aÃ§Ä±kÃ§a belirtilmemiÅŸtir. Ã–rneÄŸin, The Nature Conservancy Fisheries Monitoring yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring)), eÄŸitim setindeki gÃ¶rÃ¼ntÃ¼ler benzer durumlardan (balÄ±kÃ§Ä± tekneleri) alÄ±nmÄ±ÅŸtÄ±. Modelin, gÃ¶rÃ¼ntÃ¼lerin baÄŸlamÄ±nÄ± Ã¶ÄŸrenmek yerine hedefi tanÄ±mamayÄ± engellemek iÃ§in bu gÃ¶rÃ¼ntÃ¼leri nasÄ±l dÃ¼zenlemeniz gerektiÄŸini kendiniz keÅŸfetmeniz gerekiyordu (Ã¶rneÄŸin, Anokas'Ä±n bu Ã§alÄ±ÅŸmasÄ±na bakabilirsiniz: [https://www.kaggle.com/anokas/finding-boatids](https://www.kaggle.com/anokas/finding-boatids)).
* Ã–zelliklerin Ã§ok deÄŸiÅŸkenli daÄŸÄ±lÄ±mÄ± aynÄ± olabilir, ancak bazÄ± gruplar test setinde farklÄ± ÅŸekilde daÄŸÄ±labilir. FarklÄ±lÄ±klarÄ± keÅŸfedebilirseniz, eÄŸitim setinizi ve doÄŸrulamanÄ±zÄ± buna gÃ¶re ayarlayarak avantaj saÄŸlayabilirsiniz. Bunun Ã¼zerinde Ã§alÄ±ÅŸabilmek iÃ§in, genel liderlik panosuna bakmanÄ±z gerekecek.
* Test verisi kaymÄ±ÅŸ veya trendlenmiÅŸ olabilir; bu, genellikle zaman serisi tahminlerinde gÃ¶rÃ¼len bir durumdur. Yine, liderlik panosuna bakarak bazÄ± olasÄ± post-processing iÅŸlemleri hakkÄ±nda fikir sahibi olabilirsiniz. Ã–rneÄŸin, tahminlerinize bir Ã§arpan uygulamak, test verisindeki azalan veya artan bir trendi taklit edebilir.

Daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, liderlik panosunu incelemek, Ã¶zellikle kamu test setinin bileÅŸimi hakkÄ±nda ipuÃ§larÄ± elde etmek amacÄ±yla Ã¶zel olarak tasarlanmÄ±ÅŸ gÃ¶nderimler yapma eylemidir. Bu, Ã¶zel test seti kamu test setine benziyorsa Ã¶zellikle iyi Ã§alÄ±ÅŸÄ±r. Ä°nceleme iÃ§in genel bir yÃ¶ntem yoktur, bu yÃ¼zden her yarÄ±ÅŸma ve problem tÃ¼rÃ¼ne gÃ¶re bir inceleme metodolojisi geliÅŸtirmeniz gerekir.

Ã–rneÄŸin, *Climbing the Kaggle Leaderboard by Exploiting the Log-Loss Oracle* ([https://export.arxiv.org/pdf/1707.01825](https://export.arxiv.org/pdf/1707.01825)) adlÄ± makalede, Jacob, eÄŸitim verisini bile indirmeden bir yarÄ±ÅŸmada nasÄ±l dÃ¶rdÃ¼ncÃ¼ sÄ±raya Ã§Ä±kÄ±labileceÄŸini aÃ§Ä±klar.

Regresyon problemleriyle ilgili olarak, Kaggle tarafÄ±ndan dÃ¼zenlenen *30 Days of ML* etkinliÄŸinde, Hung Khoi, liderlik panosunu incelemenin, eÄŸitim seti ile kamu test verisi arasÄ±ndaki hedef sÃ¼tununun ortalama ve standart sapma farklarÄ±nÄ± anlamasÄ±na nasÄ±l yardÄ±mcÄ± olduÄŸunu aÃ§Ä±klamÄ±ÅŸtÄ±r (bkz: [https://www.kaggle.com/c/30-days-of-ml/discussion/269541](https://www.kaggle.com/c/30-days-of-ml/discussion/269541)).

AÅŸaÄŸÄ±daki denklemi kullandÄ±:

$$
RMSE^2 = MSE = variance + (mean - guessed\_value)^2
$$

Esasen, test hedefinin ortalamasÄ±nÄ± ve varyansÄ±nÄ± Ã§Ã¶zmek iÃ§in yalnÄ±zca iki sunum gereklidir, Ã§Ã¼nkÃ¼ iki bilinmeyen terim vardÄ±r â€“ varyans ve ortalama.

AyrÄ±ca, liderlik panosundan bilgi sorgulama hakkÄ±nda bazÄ± diÄŸer fikirleri Chris Deotte'den ([https://www.kaggle.com/cdeotte](https://www.kaggle.com/cdeotte)) ÅŸu gÃ¶nderisinde bulabilirsiniz: [https://www.kaggle.com/cdeotte/lb-probing-strategies-0-890-2nd-place](https://www.kaggle.com/cdeotte/lb-probing-strategies-0-890-2nd-place), bu gÃ¶nderi "Don't Overfit II" yarÄ±ÅŸmasÄ±yla ilgilidir ([https://www.kaggle.com/c/dont-overfit-ii](https://www.kaggle.com/c/dont-overfit-ii)).

> Liderlik panosundan bilgi sorgulamanÄ±n Ã§ift taraflÄ± bir kÄ±lÄ±Ã§ olduÄŸunu hissetmek isterseniz, Zahar Chikishevâ€™in LANL Deprem Tahmin YarÄ±ÅŸmasÄ±â€™ndan nasÄ±l bilgi sorguladÄ±ÄŸÄ±nÄ± okuyabilirsiniz, sonuÃ§ olarak halkada birinci olduÄŸu halde Ã¶zel liderlik panosunda 87. sÄ±rada yer aldÄ±: [https://towardsdatascience.com/how-to-lb-probe-on-kaggle-c0aa21458bfe](https://towardsdatascience.com/how-to-lb-probe-on-kaggle-c0aa21458bfe)

### Using adversarial validation *(ZÄ±t doÄŸrulama yÃ¶ntemini kullanmak)*

Ã‡apraz doÄŸrulama, modelinizin, eÄŸitim verisinden aynÄ± daÄŸÄ±lÄ±mdan gelen, gÃ¶rÃ¼lmemiÅŸ veri setlerine ne kadar iyi genelleme yapabileceÄŸini test etmenize olanak tanÄ±r. UmarÄ±m, bir Kaggle yarÄ±ÅŸmasÄ±nda, modelinizin hem kamu (public) hem de Ã¶zel (private) veri setlerinde tahmin yapmasÄ± istendiÄŸi iÃ§in, bu test verisinin eÄŸitim verisiyle aynÄ± daÄŸÄ±lÄ±mdan geldiÄŸini varsayabilirsiniz. GerÃ§ek hayatta, bu her zaman bÃ¶yle deÄŸildir.

EÄŸer test verisine aÅŸÄ±rÄ± uyum saÄŸlamazsanÄ±z, Ã§Ã¼nkÃ¼ kararÄ±nÄ±zÄ± yalnÄ±zca liderlik panosu sonuÃ§larÄ±na dayandÄ±rmak yerine Ã§apraz doÄŸrulamanÄ±zÄ± da gÃ¶z Ã¶nÃ¼nde bulundurduysanÄ±z, yine de sonuÃ§lardan ÅŸaÅŸÄ±rabilirsiniz. Bu, test seti eÄŸitim setinden biraz farklÄ± olduÄŸunda gerÃ§ekleÅŸebilir. AslÄ±nda, hedef olasÄ±lÄ±ÄŸÄ± ve bunun daÄŸÄ±lÄ±mÄ± ile Ã¶ngÃ¶rÃ¼cÃ¼ deÄŸiÅŸkenlerin buna nasÄ±l baÄŸlandÄ±ÄŸÄ±, modelinizi eÄŸitim sÄ±rasÄ±nda, test verisi farklÄ± olduÄŸunda yerine getiremeyeceÄŸi belirli beklentiler hakkÄ±nda bilgilendirir.

Bu nedenle, yalnÄ±zca liderlik panosuna aÅŸÄ±rÄ± uyum saÄŸlamaktan kaÃ§Ä±nmak yeterli deÄŸildir, ilk baÅŸta test verinizin eÄŸitim verisiyle karÅŸÄ±laÅŸtÄ±rÄ±labilir olup olmadÄ±ÄŸÄ±nÄ± araÅŸtÄ±rmak da Ã¶nemlidir. EÄŸer farklÄ±larsa, bu daÄŸÄ±lÄ±m farklarÄ±nÄ± test verisi Ã¼zerinde hafifletme ÅŸansÄ±nÄ±z olup olmadÄ±ÄŸÄ±nÄ± bulmanÄ±z ve bu test seti Ã¼zerinde iyi performans gÃ¶steren bir model inÅŸa etmeniz gerekecektir.

Adversarial doÄŸrulama, eÄŸitim ve test verisi arasÄ±ndaki farkÄ± tahmin etmek amacÄ±yla geliÅŸtirilmiÅŸ bir tekniktir. Bu teknik, Kaggle katÄ±lÄ±mcÄ±larÄ± arasÄ±nda uzun zamandÄ±r sÃ¶ylenti olarak dolaÅŸÄ±yor ve takÄ±m takÄ±m aktarÄ±lmaya Ã§alÄ±ÅŸÄ±lmÄ±ÅŸtÄ±, ta ki Zygmunt ZajÄ…c'Ä±n FastML blogunda ([https://www.kaggle.com/zygmunt](https://www.kaggle.com/zygmunt)) paylaÅŸtÄ±ÄŸÄ± bir yazÄ± sayesinde halka aÃ§Ä±k hale gelene kadar.

Fikir basittir: EÄŸitim verinizi alÄ±n, hedefi (target) Ã§Ä±karÄ±n, eÄŸitim verinizi ve test verinizi birleÅŸtirin ve yeni bir ikili sÄ±nÄ±flandÄ±rma hedefi oluÅŸturun. Burada pozitif etiket test verisine atanÄ±r. Bu noktada, bir makine Ã¶ÄŸrenmesi sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ± Ã§alÄ±ÅŸtÄ±rÄ±n ve ROC-AUC deÄŸerlendirme metriÄŸiyle deÄŸerlendirin (bu metriÄŸi Ã¶nceki "YarÄ±ÅŸma GÃ¶revleri ve Metreleri DetaylandÄ±rma" bÃ¶lÃ¼mÃ¼nde ele almÄ±ÅŸtÄ±k).

EÄŸer ROC-AUC deÄŸeri 0.5 civarÄ±ndaysa, bu, eÄŸitim ve test verisinin kolayca ayÄ±rt edilemediÄŸi ve muhtemelen aynÄ± daÄŸÄ±lÄ±mdan geldiÄŸi anlamÄ±na gelir. ROC-AUC deÄŸerleri 0.5'ten yÃ¼ksek ve 1.0'a yakÄ±nsa, algoritmanÄ±n eÄŸitim setinden neyin olduÄŸunu ve test setinden neyin olduÄŸunu anlamasÄ±nÄ±n Ã§ok kolay olduÄŸunu gÃ¶sterir; bÃ¶yle bir durumda, test setine kolayca genelleme yapmayÄ± beklemeyin Ã§Ã¼nkÃ¼ bu aÃ§Ä±kÃ§a farklÄ± bir daÄŸÄ±lÄ±mdan gelmektedir.

> Sberbank Rus Konut PiyasasÄ± yarÄ±ÅŸmasÄ± iÃ§in yazÄ±lmÄ±ÅŸ bir Ã¶rnek Notebook'u burada bulabilirsiniz: [Adversarial DoÄŸrulama ve DiÄŸer Korkutucu Terimler](https://www.kaggle.com/konradb/adversarial-validation-and-other-scary-terms), bu, adversarial doÄŸrulama ve yarÄ±ÅŸmalarda nasÄ±l kullanÄ±ldÄ±ÄŸÄ± hakkÄ±nda pratik bir Ã¶rnek sunmaktadÄ±r.

Verileriniz farklÄ± tÃ¼rlerde olabilir (sayÄ±sal veya metin etiketleri gibi) ve eksik veriler olabilir, bu nedenle sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±rmadan Ã¶nce bazÄ± veri iÅŸleme adÄ±mlarÄ±na ihtiyacÄ±nÄ±z olacak. Ã–nerimiz, rastgele orman sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± kullanmanÄ±zdÄ±r Ã§Ã¼nkÃ¼:

* GerÃ§ek olasÄ±lÄ±klarÄ± vermez, ancak sonuÃ§larÄ± sadece sÄ±ralÄ± olarak sunar, bu da ROC-AUC skoru iÃ§in mÃ¼kemmel bir uyum saÄŸlar.
* Rastgele orman, karar aÄŸaÃ§larÄ±na dayalÄ± esnek bir algoritmadÄ±r ve Ã¶zellik seÃ§imini kendisi yapabilir, farklÄ± tÃ¼rdeki Ã¶zelliklerle Ã§alÄ±ÅŸabilir ve tÃ¼m verileri sayÄ±sal hale getirebilir. AyrÄ±ca, aÅŸÄ±rÄ± uyuma karÅŸÄ± oldukÃ§a dayanÄ±klÄ±dÄ±r ve hiperparametreleri Ã§ok fazla dÃ¼ÅŸÃ¼nmek zorunda kalmazsÄ±nÄ±z.
* Verinin Ã§oÄŸu zaman iÅŸlenmesine gerek yoktur, Ã§Ã¼nkÃ¼ aÄŸaÃ§ tabanlÄ±dÄ±r. Eksik veriler iÃ§in, deÄŸerleri -999 gibi olasÄ±lÄ±ÄŸÄ± dÃ¼ÅŸÃ¼k bir negatif deÄŸerle deÄŸiÅŸtirebilirsiniz ve metin deÄŸiÅŸkenlerini sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rebilirsiniz (Ã¶rneÄŸin, Scikit-learn etiket kodlayÄ±cÄ±sÄ±, `sklearn.preprocessing.LabelEncoder` kullanarak). Bu Ã§Ã¶zÃ¼m, one-hot encoding'den daha dÃ¼ÅŸÃ¼k performans gÃ¶sterebilir ancak Ã§ok hÄ±zlÄ±dÄ±r ve problem iÃ§in yeterince iyi Ã§alÄ±ÅŸacaktÄ±r.

SÄ±nÄ±flandÄ±rÄ±cÄ± kullanmak, test setinizi adversary doÄŸrulama yoluyla deÄŸerlendirmek iÃ§in en doÄŸrudan yol olsa da, baÅŸka yaklaÅŸÄ±mlar da kullanabilirsiniz. Bir yaklaÅŸÄ±m, hem eÄŸitim hem de test verilerini daha dÃ¼ÅŸÃ¼k boyutlu bir alana yerleÅŸtirmektir. Bu, NanoMathias tarafÄ±ndan yazÄ±lmÄ±ÅŸ ÅŸu yazÄ±da ([https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data](https://www.kaggle.com/nanomathias/distribution-of-test-vs-training-data)) ele alÄ±nmaktadÄ±r. Daha fazla ayar yapmayÄ± gerektirse de, t-SNE ve PCA'ya dayalÄ± bir yaklaÅŸÄ±m, veriyi grafiksel olarak temsil etmenin yanÄ± sÄ±ra anlaÅŸÄ±lmasÄ± kolay ve cazip bir ÅŸekilde sunulabilir. Ã‡Ã¼nkÃ¼ beyinlerimiz sayÄ±sal verilere kÄ±yasla gÃ¶rsel temsil edilen desenleri fark etmekte daha beceriklidir (gÃ¶rsel yeteneklerimiz Ã¼zerine detaylÄ± bir tartÄ±ÅŸma iÃ§in ÅŸu makaleye bakabilirsiniz: [https://onlinelibrary.wiley.com/doi/full/10.1002/qua.24480](https://onlinelibrary.wiley.com/doi/full/10.1002/qua.24480)).

> PCA ve t-SNE, verinizin boyutunu dÃ¼ÅŸÃ¼rmek ve gÃ¶rselleÅŸtirmek iÃ§in kullanÄ±labilecek tek araÃ§lar deÄŸildir. UMAP ([https://github.com/lmcinnes/umap](https://github.com/lmcinnes/umap)), genellikle daha hÄ±zlÄ± bir dÃ¼ÅŸÃ¼k boyutlu Ã§Ã¶zÃ¼m sunar ve net ve ayrÄ±lmÄ±ÅŸ veri kÃ¼meleri saÄŸlar. Varyasyonel oto-encoders (VAE), doÄŸrusal olmayan boyut indirgeme iÅŸlemi yapabilir ve PCA'dan daha faydalÄ± bir temsil sunabilir; ancak daha karmaÅŸÄ±k bir kurulum ve ayar gerektirir.

#### Example implementation *(Uygulama Ã¶rneÄŸi)*

Zygmunt'un orijinal makalesinde ve baÄŸlantÄ± verdiÄŸimiz Not Defteri'nde, adversarial doÄŸrulama (adversarial validation) Ã¶rneklerine rastlayabilirsiniz. Ancak sizin iÃ§in, Playground yarÄ±ÅŸmasÄ± olan **Tabular Playground Series â€“ Jan 2021** ([https://www.kaggle.com/c/tabular-playground-series-jan-2021](https://www.kaggle.com/c/tabular-playground-series-jan-2021)) verisi Ã¼zerinden yeni bir Ã¶rnek oluÅŸturduk.

BaÅŸlamak iÃ§in bazÄ± Python paketlerini iÃ§eri aktararak ve yarÄ±ÅŸmanÄ±n eÄŸitim ve test verilerini alarak iÅŸlemlere baÅŸlÄ±yoruz:

```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import roc_auc_score

train = pd.read_csv("../input/tabular-playground-series-jan-2021/train.csv")
test = pd.read_csv("../input/tabular-playground-series-jan-2021/test.csv")
```

Veri hazÄ±rlÄ±ÄŸÄ± oldukÃ§a kÄ±sa ve net. TÃ¼m Ã¶zellikler sayÄ±sal olduÄŸundan, etiketleme yapmanÄ±za gerek yok, ancak eksik deÄŸerleri (-1 genellikle uygun olur) doldurmanÄ±z gerekiyor. AyrÄ±ca, hedef sÃ¼tununu ve kimlik sÃ¼tunlarÄ±nÄ± (id) dÃ¼ÅŸÃ¼rmeniz gerekli. Kimlik sÃ¼tunu ardÄ±ÅŸÄ±k bir sayÄ±ya sahipse, adversarial doÄŸrulama sonucu yÃ¼ksek bir ROC-AUC skoru elde edebilirsiniz:

```python
train = train.fillna(-1).drop(["id", "target"], axis=1)
test = test.fillna(-1).drop(["id"], axis=1)

X = train.append(test)
y = [0] * len(train) + [1] * len(test)
```

Bu noktada, sadece verilerinizi kullanarak RandomForestClassifier ile tahminler Ã¼retmeniz gerekiyor. Bunun iÃ§in **cross_val_predict** fonksiyonunu kullanÄ±yoruz. Bu fonksiyon otomatik olarak bir Ã§apraz doÄŸrulama ÅŸemasÄ± oluÅŸturur ve tahminleri doÄŸrulama katmanÄ±nda depolar:

```python
model = RandomForestClassifier()
cv_preds = cross_val_predict(model, X, y, cv=5, n_jobs=-1, method='predict_proba')
```

SonuÃ§ olarak, doÄŸrulama setinde modelin Ã¼zerinde overfitting yapmadÄ±ÄŸÄ± (Ã§Ã¼nkÃ¼ eÄŸitilen veriye gÃ¶re tahmin yapÄ±lmamÄ±ÅŸtÄ±r) ve hata tahmini iÃ§in kullanÄ±labilen, tarafsÄ±z tahminler elde edersiniz. **cross_val_predict**, modelinizi fit etmediÄŸi iÃ§in, modelinize ait herhangi bir bilgi (Ã¶rneÄŸin, hangi Ã¶zelliklerin Ã¶nemli olduÄŸu gibi) almazsÄ±nÄ±z. BÃ¶yle bir bilgiye ihtiyacÄ±nÄ±z varsa, Ã¶nce modelinizi fit etmeniz gerekir:

```python
model.fit(X, y)
```

Son olarak, tahminler iÃ§in ROC-AUC skorunu sorgulayabilirsiniz:

```python
print(roc_auc_score(y_true=y, y_score=cv_preds[:, 1]))
```

YaklaÅŸÄ±k 0.49-0.50 arasÄ±nda bir deÄŸer elde etmeniz gerekir (cross_val_predict deterministik deÄŸildir, ancak sabit bir random_seed kullanÄ±rsanÄ±z sabit sonuÃ§lar alabilirsiniz). Bu, eÄŸitim verisi ile test verisinin kolayca ayÄ±rt edilemediÄŸi anlamÄ±na gelir. DolayÄ±sÄ±yla, her iki veri de aynÄ± daÄŸÄ±lÄ±mdan gelmektedir.

#### Handling different distributions of training and test data *(EÄŸitim ve test verilerindeki farklÄ± daÄŸÄ±lÄ±mlarla baÅŸa Ã§Ä±kma)*

ROC-AUC skoru 0.8 veya daha fazla olan bir test seti, eÄŸitim verilerinizden Ã§ok farklÄ± ve ayÄ±rt edilebilir olduÄŸunu gÃ¶sterir. Bu tÃ¼r bir durumda, birkaÃ§ strateji uygulayarak bu farkÄ± yÃ¶netebilirsiniz:

**BaskÄ±lama (Suppression):**

Bu yÃ¶ntemle, test setindeki en Ã¶nemli deÄŸiÅŸkenleri Ã§Ä±kararak eÄŸitim verisi ile test verisinin daÄŸÄ±lÄ±mlarÄ±nÄ± eÅŸitlemeyi amaÃ§larsÄ±nÄ±z. Bunu yapmak iÃ§in, modelinizi tÃ¼m verilerle eÄŸitir ve ardÄ±ndan **feature_importances_** gibi araÃ§lar ile deÄŸiÅŸkenlerin Ã¶nem derecelerini Ã¶lÃ§ersiniz. Daha sonra, modelinizi tekrar eÄŸitirken, en Ã¶nemli deÄŸiÅŸkeni veriden Ã§Ä±karÄ±rsÄ±nÄ±z. Bu iÅŸlemi, ROC-AUC skorunuz yaklaÅŸÄ±k 0.5'lere dÃ¼ÅŸene kadar tekrarlarsÄ±nÄ±z.

Ancak bu yÃ¶ntemle karÅŸÄ±laÅŸÄ±lan ana sorun, Ã¶nemli deÄŸiÅŸkenlerin Ã§oÄŸunu veriden Ã§Ä±karmak zorunda kalmanÄ±zdÄ±r. Bu durumda, modelinizin tahmin performansÄ± Ã¶nemli Ã¶lÃ§Ã¼de dÃ¼ÅŸer Ã§Ã¼nkÃ¼ model, bilgilendirici Ã¶zelliklerden yoksun olacaktÄ±r.

**Test Setine En Benzer Ã–rneklerle EÄŸitim Yapmak:**

Bu yÃ¶ntemde, odak noktanÄ±z deÄŸiÅŸkenlerde deÄŸil, **eÄŸitim Ã¶rnekleriniz** Ã¼zerindedir. EÄŸitim setinden yalnÄ±zca, test daÄŸÄ±lÄ±mÄ±na en yakÄ±n olan Ã¶rnekleri seÃ§ersiniz. Bu ÅŸekilde, eÄŸitilen modeliniz yalnÄ±zca test setiyle uyumlu olur (ancak baÅŸka bir test verisi Ã¼zerinde genellenemez). Ancak bu yaklaÅŸÄ±mda dikkat edilmesi gereken bir sÄ±nÄ±rlama vardÄ±r: EÄŸitim setindeki Ã¶rneklerin sayÄ±sÄ±nÄ± azaltÄ±rsÄ±nÄ±z ve test daÄŸÄ±lÄ±mÄ±na benzer olan Ã¶rnek sayÄ±sÄ± dÃ¼ÅŸÃ¼kse, modeliniz Ã§ok daha dar bir veri kÃ¼mesiyle eÄŸitilmiÅŸ olur. Bu da, eÄŸitim Ã¶rneklerinin yetersizliÄŸi nedeniyle modelin oldukÃ§a **Ã¶nyargÄ±lÄ±** olmasÄ±na neden olabilir.

Ã–rneÄŸin, eÄŸitim verilerinde yalnÄ±zca test setindeki adverser (anormal) tahminlerin **0.5'ten bÃ¼yÃ¼k** olanlarÄ±nÄ± seÃ§erseniz, eÄŸitim verinizin boyutu oldukÃ§a kÃ¼Ã§Ã¼lÃ¼r. Bu durumda, modelinizin genelleme yeteneÄŸi azalÄ±r.

**Test Setini Taklit Ederek DoÄŸrulama Yapmak:**

Bu stratejide, tÃ¼m verilerle modelinizi eÄŸitirken, doÄŸrulama amacÄ±yla yalnÄ±zca **adverser tahminlerin 0.5'ten bÃ¼yÃ¼k** olduÄŸu Ã¶rnekleri seÃ§ersiniz. Bu doÄŸrulama seti, modelin performansÄ±nÄ± **test seti Ã¼zerinde optimize etmek** iÃ§in kullanÄ±lÄ±r.

Bu strateji, Ã¶zellikle modelin **hyperparametrelerinin ve seÃ§imlerinin** test setine gÃ¶re en iyi ÅŸekilde ayarlanmasÄ±na yardÄ±mcÄ± olur. Ancak dikkat edilmesi gereken bir diÄŸer ÅŸey, test setini tam anlamÄ±yla taklit etmeye Ã§alÄ±ÅŸmanÄ±n, modelin baÅŸka durumlar iÃ§in genellenebilirliÄŸini kaybettirebilmesidir.

**Adversarial DoÄŸrulama (Adversarial Validation) ile Ä°lgili Ek Notlar:**

* Adversarial doÄŸrulama, genellikle **yarÄ±ÅŸmalarda** performansÄ±nÄ±zÄ± artÄ±rmaya yardÄ±mcÄ± olur. Ancak her zaman iÅŸe yaramayabilir. Ã–rneÄŸin, Kaggle gibi platformlarda, **test setine tam eriÅŸiminiz olmadÄ±ÄŸÄ± iÃ§in adversarial doÄŸrulama** kullanmak mÃ¼mkÃ¼n deÄŸildir.

* Adversarial doÄŸrulama, test setinin **genel yapÄ±sÄ±nÄ±** anlamanÄ±zÄ± saÄŸlar, ancak **private** ve **public** test verisi arasÄ±ndaki farkÄ± anlamanÄ±za yardÄ±mcÄ± olamaz. Bu, genellikle **public leaderboard overfitting** sorununu ve takip eden sÄ±ralama deÄŸiÅŸikliklerini oluÅŸturur.

* GerÃ§ek dÃ¼nyada, adversarial doÄŸrulama birÃ§ok **pratik kullanÄ±m** sunar. Ã–rneÄŸin, test setinizi yanlÄ±ÅŸ seÃ§meniz durumunda, bu yÃ¶ntem size doÄŸru test verilerini kullanÄ±p kullanmadÄ±ÄŸÄ±nÄ±zÄ± anlamanÄ±zÄ± saÄŸlar. AyrÄ±ca, **modelin Ã¼retim ortamÄ±nda** zamanla bozulabileceÄŸini ve **concept drift** yaÅŸandÄ±ÄŸÄ±nÄ± fark edebilirsiniz. Bu durumda, modelinizi yeniden eÄŸitmeniz gerekebilir.

SonuÃ§ olarak, adversarial doÄŸrulama, doÄŸru test verisini seÃ§mek ve test setinizin eÄŸitim verisinden farklÄ±lÄ±klarÄ±nÄ± anlamak iÃ§in gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r. AyrÄ±ca, zaman iÃ§inde verinizde meydana gelen deÄŸiÅŸikliklerin modelinizin tahmin gÃ¼cÃ¼nÃ¼ nasÄ±l etkileyebileceÄŸi konusunda size bilgi verir.


> Giuliano Janson
> 
> https://www.kaggle.com/adjgiulio
> 
> 
> 
> > Giuliano Janson, Kaggle'da *Competitions Grandmaster* unvanÄ±na sahip ve ÅŸu anda Zillow Group'ta makine Ã¶ÄŸrenimi ve doÄŸal dil iÅŸleme (NLP) alanÄ±nda kÄ±demli bir uygulamalÄ± bilim insanÄ± olarak gÃ¶rev yapÄ±yor. Onunla yapÄ±lan bir rÃ¶portajda, Kaggleâ€™daki yarÄ±ÅŸmalar, veri sÄ±zÄ±ntÄ±larÄ±, Ã§apraz doÄŸrulama ve yaratÄ±cÄ± Ã¶zellik mÃ¼hendisliÄŸi gibi konularda deÄŸerli bilgiler paylaÅŸÄ±yor. Ä°ÅŸte Ã¶nemli bazÄ± noktalar:
> 
> 
> 
> **Favori YarÄ±ÅŸma TÃ¼rÃ¼**
> 
> 
> 
> Giuliano'nun en sevdiÄŸi yarÄ±ÅŸma tipi, Ã§Ã¶zmek iÃ§in ilginÃ§ bir problem sunan, hafÄ±zaya sÄ±ÄŸacak bÃ¼yÃ¼klÃ¼kte fakat aÅŸÄ±rÄ± kÃ¼Ã§Ã¼k olmayacak, yaratÄ±cÄ± Ã¶zellik mÃ¼hendisliÄŸi iÃ§in fÄ±rsatlar tanÄ±yan yarÄ±ÅŸmalardÄ±r. Bu tÃ¼r yarÄ±ÅŸmalar, ona hem dikkatli bir analiz hem de yaratÄ±cÄ± bir yaklaÅŸÄ±m sergileyebilme imkÃ¢nÄ± tanÄ±r.
> 
> 
> 
> **Kaggle YarÄ±ÅŸmalarÄ±na YaklaÅŸÄ±m**
> 
> 
> 
> Bir Kaggle yarÄ±ÅŸmasÄ±nÄ± bir maraton gibi gÃ¶rÃ¼r. Ä°lk birkaÃ§ gÃ¼n iÃ§inde en iyi puanlarÄ±nÄ±n %90-95'ini alabilirken, kalan %5 iÃ§in yoÄŸun bir ÅŸekilde Ã§alÄ±ÅŸmak gerekir. GÃ¼nlÃ¼k iÅŸ yaÅŸamÄ± ise farklÄ±dÄ±r. Burada model performansÄ± sadece bir faktÃ¶rdÃ¼r. Zaman yÃ¶netimi, Ã¶lÃ§eklenebilirlik, sÃ¼rdÃ¼rÃ¼lebilirlik gibi faktÃ¶rler de Ã¶nemli olup, projenin zamanÄ±nda hayata geÃ§mesi iÃ§in sÃ¼rekli Ã¶nceliklendirme yapÄ±lÄ±r.
> 
> 
> 
> **Zorlu Bir YarÄ±ÅŸma Deneyimi**
> 
> 
> 
> Genentech Kanser YarÄ±ÅŸmasÄ±, Giuliano'nun kazandÄ±ÄŸÄ± iki yarÄ±ÅŸmadan biridir. Bu yarÄ±ÅŸma, tÄ±bbi verilerle ilgili ham veriler sundu ve burada veriyi doÄŸru ÅŸekilde iÅŸlemek bÃ¼yÃ¼k bir zorluktu. Ã–zellik mÃ¼hendisliÄŸinde, veri sÄ±zÄ±ntÄ±larÄ±nÄ± tespit etme ve bunlarÄ± kullanarak modelin performansÄ±nÄ± artÄ±rma konusunda Ã¶nemli bir baÅŸarÄ± elde etti. Veri sÄ±zÄ±ntÄ±sÄ±, modelin yanlÄ±ÅŸ sonuÃ§lar Ã¼retmesine neden olabileceÄŸinden Ã§ok dikkat edilmesi gereken bir konu.
> 
> 
> 
> **Kaggle'Ä±n Kariyerine Etkisi**
> 
> 
> 
> Kaggle, Giuliano'ya iki ana aÃ§Ä±dan fayda saÄŸlamÄ±ÅŸtÄ±r: Modern makine Ã¶ÄŸrenimi tekniklerine eriÅŸim ve gÃ¼Ã§lÃ¼ bir model doÄŸrulama anlayÄ±ÅŸÄ± geliÅŸtirme. AyrÄ±ca Kaggle'da diÄŸer yetenekli katÄ±lÄ±mcÄ±larla iÅŸbirliÄŸi yaparak pek Ã§ok Ã¶nemli ders almÄ±ÅŸ ve bu deneyimlerini iÅŸ yerindeki diÄŸer insanlarla da paylaÅŸmaktadÄ±r.
> 
> 
> 
> **Yeni BaÅŸlayanlarÄ±n SÄ±klÄ±kla GÃ¶zden KaÃ§Ä±rdÄ±ÄŸÄ± Noktalar**
> 
> 
> 
> Yeni baÅŸlayanlarÄ±n en Ã§ok gÃ¶z ardÄ± ettiÄŸi konu doÄŸru Ã§apraz doÄŸrulamanÄ±n Ã¶nemi. Ä°yi bir Ã§apraz doÄŸrulama Ã§erÃ§evesi, modelin iyileÅŸtirilmesini doÄŸru ve objektif bir ÅŸekilde Ã¶lÃ§menizi saÄŸlar. YarÄ±ÅŸmalar uzun sÃ¼reli olduÄŸu iÃ§in, baÅŸarÄ±lÄ± olmak yalnÄ±zca iyi bir ilk fikre sahip olmakla deÄŸil, veriden gelen geribildirimle iterasyon yapabilme yeteneÄŸiyle de ilgilidir.
> 
> 
> 
> **Hangi AraÃ§larÄ± ve KÃ¼tÃ¼phaneleri Tavsiye Ediyor?**
> 
> 
> 
> Giuliano'nun tercih ettiÄŸi araÃ§lar arasÄ±nda **Pandas** ve **Scikit-learn** yer alÄ±yor. Pandas, veri manipÃ¼lasyonu ve keÅŸfi iÃ§in harika bir araÃ§ken, Scikit-learn ile hÄ±zlÄ±ca prototipler geliÅŸtirebilir. Nihai modelleri ise genellikle **XGBoost** ile kuruyor. Derin Ã¶ÄŸrenme iÃ§inse **Keras** kullanmayÄ± tercih ediyor.
> 
> 
> 
> Bu gibi deneyimler, Kaggleâ€™da baÅŸarÄ±lÄ± olmak iÃ§in gereken derin bilgi ve pratik deneyimi pekiÅŸtiriyor.

### Handling leakage *(Veri sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nleme)*

Kaggle yarÄ±ÅŸmalarÄ±nda sonucu etkileyebilecek yaygÄ±n bir sorun **veri sÄ±zÄ±ntÄ±sÄ±**dÄ±r. Genellikle basitÃ§e **sÄ±zÄ±ntÄ±** (leakage) olarak veya baÅŸka sÃ¼slÃ¼ isimlerle (Ã¶rneÄŸin, **golden features - altÄ±n Ã¶zellikler**) anÄ±lan veri sÄ±zÄ±ntÄ±sÄ±, eÄŸitim aÅŸamasÄ±nda mevcut olan ancak **tahmin anÄ±nda kullanÄ±lamayacak** bilgileri iÃ§erir. BÃ¶yle bir bilginin (sÄ±zÄ±ntÄ±nÄ±n) varlÄ±ÄŸÄ±, modelinizin eÄŸitimde ve testte aÅŸÄ±rÄ± performans gÃ¶stermesine izin vererek sizi yarÄ±ÅŸmada Ã¼st sÄ±ralara taÅŸÄ±yacak, ancak sponsÃ¶rÃ¼n bakÄ±ÅŸ aÃ§Ä±sÄ±ndan bu bilgiye dayalÄ± herhangi bir Ã§Ã¶zÃ¼mÃ¼ **kullanÄ±lmaz** veya en iyi ihtimalle **en iyi olmayan** hale getirecektir.

> Michael Kim'in ([https://www.kaggle.com/mikeskim](https://www.kaggle.com/mikeskim)) 2019'da Kaggle Days San Francisco'daki sunumunda belirttiÄŸi gibi, sÄ±zÄ±ntÄ±yÄ± "**gerÃ§ek hakkÄ±nda bilgi, yapay ve kasÄ±tsÄ±z olarak eÄŸitim Ã¶zellik verilerine veya eÄŸitim meta verilerine dahil edildiÄŸinde**" ÅŸeklinde tanÄ±mlayabiliriz.

Sponsor ve Kaggle ekibinin dikkatli kontrolÃ¼ne raÄŸmen, sÄ±zÄ±ntÄ±nÄ±n beklenmedik bir ÅŸekilde ortaya Ã§Ä±kabilen **ince ve sinsi doÄŸasÄ±** nedeniyle, Kaggle yarÄ±ÅŸmalarÄ±nda sÄ±zÄ±ntÄ± sÄ±kÃ§a bulunur. Bu durum, her zaman bir yarÄ±ÅŸmada daha iyi puan almanÄ±n yollarÄ±nÄ± arayan Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n yÃ¼rÃ¼ttÃ¼ÄŸÃ¼ yoÄŸun arama faaliyetinden kaynaklanmaktadÄ±r.

> **Veri sÄ±zÄ±ntÄ±sÄ±nÄ±, sÄ±zÄ±ntÄ±lÄ± bir doÄŸrulama stratejisiyle karÄ±ÅŸtÄ±rmayÄ±n.** SÄ±zÄ±ntÄ±lÄ± bir doÄŸrulama stratejisinde, sorun, bazÄ± bilgilerin eÄŸitim verilerinden sÄ±zmasÄ± nedeniyle doÄŸrulama stratejinizi daha iyi doÄŸrulama puanlarÄ±nÄ± destekleyecek ÅŸekilde dÃ¼zenlemiÅŸ olmanÄ±zdÄ±r. Bu, yarÄ±ÅŸmanÄ±n kendisiyle ilgili deÄŸildir, ancak doÄŸrulamanÄ±zÄ± nasÄ±l ele aldÄ±ÄŸÄ±nÄ±zla ilgilidir. Bu, verilerinizi (normalleÅŸtirme, boyutluluk azaltma, eksik deÄŸer doldurma) eÄŸitim ve doÄŸrulama veya test verilerini ayÄ±rmadan **Ã¶nce** deÄŸiÅŸtiren herhangi bir Ã¶n iÅŸleme uygulamanÄ±z durumunda ortaya Ã§Ä±kar.
> SÄ±zÄ±ntÄ±lÄ± doÄŸrulamayÄ± Ã¶nlemek iÃ§in, verilerinizi manipÃ¼le etmek ve iÅŸlemek iÃ§in **Scikit-learn** kullanÄ±yorsanÄ±z, doÄŸrulama verilerinizi kesinlikle herhangi bir **uyumlandÄ±rma (fitting) iÅŸleminden** hariÃ§ tutmalÄ±sÄ±nÄ±z. Uyumlama iÅŸlemleri, doÄŸrulama iÃ§in kullandÄ±ÄŸÄ±nÄ±z herhangi bir veriye uygulanÄ±rsa sÄ±zÄ±ntÄ± oluÅŸturma eÄŸilimindedir. Bunu Ã¶nlemenin en iyi yolu, hem veri iÅŸleme hem de modeli bir araya getirecek olan Scikit-learn **pipelines** ([https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)) kullanmaktÄ±r, bÃ¶ylece verilerinize yanlÄ±ÅŸlÄ±kla herhangi bir sÄ±zÄ±ntÄ± oluÅŸturan dÃ¶nÃ¼ÅŸÃ¼m uygulama riskini ortadan kaldÄ±rÄ±rsÄ±nÄ±z.
> Buna karÅŸÄ±lÄ±k, veri sÄ±zÄ±ntÄ±sÄ±, doÄŸrulama iÅŸlemlerinden kesinlikle kaynaklanmaz, ancak onlarÄ± derinden etkiler. Bu bÃ¶lÃ¼m esas olarak doÄŸrulama stratejilerine ayrÄ±lmÄ±ÅŸ olsa da, modellerinizi ve genelleme yeteneklerini derinden etkileyebileceÄŸi iÃ§in veri sÄ±zÄ±ntÄ±sÄ±nÄ± tartÄ±ÅŸmayÄ± gerekli gÃ¶rÃ¼yoruz.

Genel olarak konuÅŸursak, sÄ±zÄ±ntÄ± **Ã¶zellik (feature)** veya **Ã¶rnek (example)** dÃ¼zeyinde ortaya Ã§Ä±kabilir. **Ã–zellik sÄ±zÄ±ntÄ±sÄ±** aÃ§Ä±k ara en yaygÄ±n olanÄ±dÄ±r. Hedefin bir vekilinin (proxy) varlÄ±ÄŸÄ±ndan veya hedefin kendisine **sonradan gelen** bir Ã¶zellikten kaynaklanabilir. Bir hedef vekili, etiketin kendisinin iÅŸlenmesinden veya test ayÄ±rma sÃ¼recinden tÃ¼retilmiÅŸ herhangi bir ÅŸey olabilir; Ã¶rneÄŸin, tanÄ±mlayÄ±cÄ±lar belirlenirken, belirli tanÄ±mlayÄ±cÄ±lar (bir numaralandÄ±rma yayÄ± gibi) belirli hedef yanÄ±tlarÄ±yla iliÅŸkilendirilebilir, bu da doÄŸru ÅŸekilde iÅŸlenen bilgiyle beslenirse modelin tahmin etmesini kolaylaÅŸtÄ±rÄ±r. Veri iÅŸlemenin sÄ±zÄ±ntÄ±ya neden olabileceÄŸi daha incelikli bir yol, yarÄ±ÅŸma organizatÃ¶rlerinin eÄŸitim ve test setlerini **ayÄ±rmadan Ã¶nce birlikte iÅŸlemesidir**. Tarihsel olarak, Kaggle yarÄ±ÅŸmalarÄ±ndaki sÄ±zÄ±ntÄ±lar ÅŸunlarda bulunmuÅŸtur:

1.  Organizasyon ekibinin **yanlÄ±ÅŸ ele alÄ±nmÄ±ÅŸ veri hazÄ±rlÄ±ÄŸÄ±**, Ã¶zellikle eÄŸitim ve test verilerinin birleÅŸimi Ã¼zerinde Ã§alÄ±ÅŸtÄ±klarÄ±nda (Ã¶rneÄŸin, Loan Default Prediction'da, organizatÃ¶rler baÅŸlangÄ±Ã§ta **gelecekteki bilgileri sÄ±zdÄ±ran** toplu geÃ§miÅŸ verilere sahip Ã¶zellikler kullandÄ±lar).
2.  **SatÄ±r sÄ±rasÄ±nÄ±n** bir zaman endeksi veya belirli veri gruplarÄ±yla baÄŸlantÄ±lÄ± olmasÄ± (Ã¶rneÄŸin, Telstra Network Disruptions'da, bir Ã¶zellikteki kayÄ±tlarÄ±n sÄ±rasÄ±, veride bulunmayan ve Ã§ok tahmine dayalÄ± olan bir vekil bilgiye, **konuma**, iÅŸaret ediyordu).
3.  **SÃ¼tun sÄ±rasÄ±nÄ±n** bir zaman endeksiyle baÄŸlantÄ±lÄ± olmasÄ± (sÃ¼tunlarÄ± satÄ±r olarak kullanarak ipuÃ§larÄ± elde edebilirsiniz).
4.  **ArdÄ±ÅŸÄ±k satÄ±rlardaki Ã¶zellik tekrarÄ±**, korelasyonlu yanÄ±tlara sahip Ã¶rneklere iÅŸaret edebileceÄŸi iÃ§in (Bosch Production Line Performance'da olduÄŸu gibi).
5.  **GÃ¶rÃ¼ntÃ¼ meta verileri** (Two Sigma Connect: Rental Listing Inquiries'da olduÄŸu gibi).
6.  **Hash'ler** veya kodlamalarÄ±n ve tanÄ±mlayÄ±cÄ±larÄ±n diÄŸer kolayca kÄ±rÄ±labilir anonimleÅŸtirme uygulamalarÄ±.

**Sonradan gelen bilgiyle** ilgili sorun, zamanÄ±n etkilerini ve zaman boyunca uzanan neden-sonuÃ§ dizisini dikkate almadÄ±ÄŸÄ±mÄ±zda bilgiyle baÅŸa Ã§Ä±kma ÅŸeklimizden kaynaklanÄ±r. GeÃ§miÅŸe baktÄ±ÄŸÄ±mÄ±z iÃ§in, ÅŸimdiki anda anlam ifade eden bazÄ± deÄŸiÅŸkenlerin geÃ§miÅŸte bir deÄŸeri olmadÄ±ÄŸÄ±nÄ± sÄ±k sÄ±k unuturuz. Ã–rneÄŸin, yeni bir ÅŸirkete kredi iÃ§in kredi puanÄ± hesaplamanÄ±z gerekiyorsa, Ã¶dÃ¼nÃ§ alÄ±nan paranÄ±n Ã¶demelerinin sÄ±klÄ±kla geÃ§ olduÄŸunu bilmek, borÃ§lunun daha dÃ¼ÅŸÃ¼k gÃ¼venilirliÄŸinin ve temsil ettiÄŸi daha yÃ¼ksek riskin harika bir gÃ¶stergesidir, ancak bunu parayÄ± Ã¶dÃ¼nÃ§ vermeden **Ã¶nce** bilemezsiniz. Bu, projelerinizde ÅŸirket veritabanlarÄ±nÄ± analiz ederken de sÄ±kÃ§a karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z bir sorundur: sorguladÄ±ÄŸÄ±nÄ±z veriler geÃ§miÅŸ durumlarÄ± deÄŸil, **ÅŸimdiki durumlarÄ±** temsil edecektir. GeÃ§miÅŸ bilgileri yeniden oluÅŸturmak, yalnÄ±zca belirli bir zamanda mevcut olan bilgileri almak istediÄŸinizi belirtemezseniz de zor bir gÃ¶rev olabilir. Bu nedenle, herhangi bir model oluÅŸturmadan Ã¶nce bu sÄ±zÄ±ntÄ± yapan Ã¶zellikleri bulmaya ve hariÃ§ tutmaya veya ayarlamaya bÃ¼yÃ¼k Ã§aba harcanmalÄ±dÄ±r.

Benzer sorunlar, aynÄ± tÃ¼r verilere (Ã¶rneÄŸin, bankacÄ±lÄ±k veya sigorta) dayalÄ± Kaggle yarÄ±ÅŸmalarÄ±nda da yaygÄ±ndÄ±r, ancak verilerin yarÄ±ÅŸma iÃ§in hazÄ±rlanmasÄ±na Ã§ok dikkat edildiÄŸinden, daha incelikli yollarla ve biÃ§imlerde ortaya Ã§Ä±karlar. Genel olarak, bu sÄ±zÄ±ntÄ± yapan Ã¶zellikleri tespit etmek kolaydÄ±r, Ã§Ã¼nkÃ¼ hedefle gÃ¼Ã§lÃ¼ bir ÅŸekilde iliÅŸkilidirler ve bir alan uzmanÄ± nedenini Ã§Ã¶zebilir (Ã¶rneÄŸin, verilerin veritabanlarÄ±nda hangi aÅŸamada kaydedildiÄŸini bilmek). Bu nedenle, yarÄ±ÅŸmalarda asla bu kadar bariz Ã¶zellikler bulamazsÄ±nÄ±z, ancak sponsorun kontrolÃ¼nden kaÃ§an, genellikle dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veya iÅŸlenmiÅŸ, bunlarÄ±n tÃ¼revlerini bulursunuz. Ã–zellikler, sponsorun iÅŸini korumak iÃ§in genellikle anonimleÅŸtirildiÄŸinden, diÄŸerlerinin arasÄ±nda gizlenmiÅŸ olarak kalÄ±rlar. Bu, **altÄ±n/sihirli Ã¶zellikler** iÃ§in bir dizi avÄ±n doÄŸmasÄ±na neden olmuÅŸtur, yani sÄ±zÄ±ntÄ±nÄ±n ortaya Ã§Ä±kmasÄ± iÃ§in veri kÃ¼mesindeki mevcut Ã¶zellikleri birleÅŸtirme arayÄ±ÅŸÄ±.

> Corey Levison'Ä±n aydÄ±nlatÄ±cÄ± bir yazÄ±sÄ±nÄ± buradan okuyabilirsiniz: [https://www.linkedin.com/pulse/winning-13th-place-kaggles-magic-competition-coreylevinson/](https://www.google.com/search?q=https://www.linkedin.com/pulse/winning-13th-place-kaggles-magic-competition-coreylevinson/). Bu, Santander Customer Transaction Prediction yarÄ±ÅŸmasÄ±nÄ±n ekibi iÃ§in nasÄ±l sihirli Ã¶zellikler avÄ±na dÃ¶nÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼n hikayesini anlatÄ±yor.
> 
> 
> 
> BaÅŸka bir iyi Ã¶rnek dune\_dweller tarafÄ±ndan burada sunulmuÅŸtur: [https://www.kaggle.com/c/telstra-recruiting-network/discussion/19239\#109766](https://www.google.com/search?q=https://www.kaggle.com/c/telstra-recruiting-network/discussion/19239%23109766). dune\_dweller, verilerin nasÄ±l sÄ±ralandÄ±ÄŸÄ±na bakarak, verilerin bÃ¼yÃ¼k olasÄ±lÄ±kla zaman sÄ±rasÄ±na gÃ¶re olduÄŸunu buldu. Bu bilgiyi yeni bir Ã¶zelliÄŸe koymak puanÄ± artÄ±rdÄ±.

SÄ±zÄ±ntÄ±nÄ±n diÄŸer ortaya Ã§Ä±kma yolu ise **eÄŸitim Ã¶rneÄŸi sÄ±zÄ±ntÄ±sÄ±dÄ±r**. Bu, Ã¶zellikle **i.i.d olmayan (baÄŸÄ±msÄ±z ve Ã¶zdeÅŸ daÄŸÄ±lÄ±mlÄ± olmayan)** verilerde olur. Bu, bazÄ± vakalarÄ±n aynÄ± dÃ¶nemden (veya ardÄ±ÅŸÄ±k olanlardan) veya aynÄ± gruptan olmalarÄ± nedeniyle kendi aralarÄ±nda korelasyonlu olduÄŸu anlamÄ±na gelir. Bu tÃ¼r vakalarÄ±n hepsi eÄŸitim veya test verilerinde bir arada deÄŸil, aralarÄ±nda ayrÄ±lmÄ±ÅŸlarsa, makine Ã¶ÄŸrenimi algoritmasÄ±nÄ±n genel kurallar kullanmak yerine vakalarÄ± nasÄ±l tespit edeceÄŸini (ve tahminleri nasÄ±l tÃ¼reteceÄŸini) Ã¶ÄŸrenme ÅŸansÄ± yÃ¼ksektir. BÃ¶yle bir durumun sÄ±kÃ§a bahsedilen bir Ã¶rneÄŸi, Prof. Andrew Ng'nin ekibini iÃ§erir (bkz. [https://twitter.com/nizkroberts/status/931121395748270080](https://twitter.com/nizkroberts/status/931121395748270080)). 2017'de, 30.000 hastadan alÄ±nan 100.000 rÃ¶ntgen gÃ¶rÃ¼ntÃ¼sÃ¼nden oluÅŸan bir veri kÃ¼mesi kullanarak bir makale yazdÄ±lar. EÄŸitim ve test verilerini ayÄ±rmak iÃ§in rastgele bir bÃ¶lme kullandÄ±lar, ancak aynÄ± hastanÄ±n rÃ¶ntgenlerinin kÄ±smen eÄŸitim setinde ve kÄ±smen test setinde olabileceÄŸini fark etmediler. Nick Roberts gibi uygulayÄ±cÄ±lar bu gerÃ§eÄŸi fark ederek, modelin performanslarÄ±nÄ± ÅŸiÅŸirebilecek olasÄ± bir sÄ±zÄ±ntÄ±ya dikkat Ã§ekti ve bu da makalenin Ã¶nemli Ã¶lÃ§Ã¼de revize edilmesine yol aÃ§tÄ±.

Kaggle yarÄ±ÅŸmasÄ±nda veri sÄ±zÄ±ntÄ±sÄ± olduÄŸunda ne olur? Kaggle'Ä±n bu konuda net politikalarÄ± vardÄ±r ve ya:

  * YarÄ±ÅŸmanÄ±n olduÄŸu gibi devam etmesine izin verir (Ã¶zellikle sÄ±zÄ±ntÄ±nÄ±n yalnÄ±zca kÃ¼Ã§Ã¼k bir etkisi varsa)
  * SÄ±zÄ±ntÄ±yÄ± setten kaldÄ±rÄ±r ve yarÄ±ÅŸmayÄ± yeniden baÅŸlatÄ±r
  * SÄ±zÄ±ntÄ±nÄ±n bulunmadÄ±ÄŸÄ± yeni bir test seti oluÅŸturur

Ã–zellikle, Kaggle bulunan herhangi bir sÄ±zÄ±ntÄ±yÄ± **kamuya aÃ§Ä±klamayÄ±** tavsiye eder, ancak bu zorunlu deÄŸildir veya yapÄ±lmazsa yaptÄ±rÄ±m uygulanmaz. Ancak, deneyimlerimize gÃ¶re, bir yarÄ±ÅŸmada herhangi bir sÄ±zÄ±ntÄ± varsa, yakÄ±nda Ã§ok belirgin hale gelecek ve tartÄ±ÅŸma forumlarÄ± sihirli ÅŸeyler ve benzerleri hakkÄ±nda bir tartÄ±ÅŸmayla aydÄ±nlanmaya baÅŸlayacaktÄ±r. Forumlarda sÃ¶ylenenlere dikkat ederseniz ve farklÄ± Kaggle katÄ±lÄ±mcÄ±larÄ± tarafÄ±ndan saÄŸlanan tÃ¼m ipuÃ§larÄ±nÄ± bir araya getirebilirseniz, kÄ±sa sÃ¼rede bileceksiniz.

Ancak, bazÄ± oyuncularÄ±n diÄŸer yarÄ±ÅŸmacÄ±larÄ± ciddi modellemeden uzaklaÅŸtÄ±rmak iÃ§in sihirli Ã¶zellikler hakkÄ±ndaki tartÄ±ÅŸmalarÄ± bile kullanabileceÄŸine lÃ¼tfen dikkat edin. Ã–rneÄŸin, Santander Customer Transaction Prediction'da, bazÄ± Kaggle katÄ±lÄ±mcÄ±larÄ±nÄ±n diÄŸer katÄ±lÄ±mcÄ±larÄ± aslÄ±nda o kadar da sihirli olmayan sihirli Ã¶zelliklere ilgi duymaya teÅŸvik ettiÄŸi, Ã§abalarÄ±nÄ± yanlÄ±ÅŸ yÃ¶ne yÃ¶nlendirdiÄŸi Ã¼nlÃ¼ bir durum vardÄ± (tartÄ±ÅŸmaya buradan bakÄ±n: [https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/87057\#502362](https://www.google.com/search?q=https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/87057%23502362)).

Ã–nerimiz, yarÄ±ÅŸma forumunda ortaya Ã§Ä±kan sÄ±zÄ±ntÄ± ve sihirli Ã¶zellikler hakkÄ±ndaki tartÄ±ÅŸmalarÄ± dikkatlice okumanÄ±z ve yarÄ±ÅŸmaya katÄ±lma ilgi ve motivasyonlarÄ±nÄ±za dayanarak araÅŸtÄ±rmayÄ± sÃ¼rdÃ¼rÃ¼p sÃ¼rdÃ¼rmemeye ve bulunan herhangi bir sÄ±zÄ±ntÄ±yÄ± kullanÄ±p kullanmamaya karar vermenizdir.

Herhangi bir sÄ±zÄ±ntÄ±yÄ± kullanmamak, nihai sÄ±ralamanÄ±za gerÃ§ekten zarar verebilir, ancak Ã¶ÄŸrenme deneyiminizi kesinlikle bozacaktÄ±r (Ã§Ã¼nkÃ¼ sÄ±zÄ±ntÄ± bir Ã§arpÄ±tmadÄ±r ve onu kullanan modeller hakkÄ±nda herhangi bir iddiada bulunamazsÄ±nÄ±z). Bir itibar kazanmak veya daha sonra bir iÅŸe alÄ±nma fÄ±rsatÄ± iÃ§in sponsora yaklaÅŸmak amacÄ±yla bir yarÄ±ÅŸmaya katÄ±lmÄ±yorsanÄ±z, karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z herhangi bir sÄ±zÄ±ntÄ±yÄ± kullanmanÄ±z tamamen normaldir. Aksi takdirde, onu gÃ¶rmezden gelin ve modelleriniz Ã¼zerinde sÄ±kÄ± Ã§alÄ±ÅŸmaya devam edin (kim bilir; belki Kaggle sonunda yarÄ±ÅŸmayÄ± sÄ±fÄ±rlar veya dÃ¼zeltir, sÄ±zÄ±ntÄ±yÄ± kullanan birÃ§ok kiÅŸinin bÃ¼yÃ¼k hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸramasÄ±na neden olur).

> SÄ±zÄ±ntÄ±lar, yarÄ±ÅŸmadan yarÄ±ÅŸmaya Ã§ok farklÄ±dÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda gerÃ§ekleÅŸen birkaÃ§ gerÃ§ek sÄ±zÄ±ntÄ± hakkÄ±nda fikir edinmek isterseniz, bu Ã¼Ã§ unutulmaz Ã¶rneÄŸe bakabilirsiniz:
> 
> 
> 
> * [https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/22807](https://www.google.com/search?q=https://www.kaggle.com/c/predicting-red-hat-business-value/discussion/22807) Predicting Red Hat Business Value'dan, sorunun yarÄ±ÅŸmanÄ±n kusurlu bir eÄŸitim/test bÃ¶lme metodolojisinden kaynaklandÄ±ÄŸÄ± yer.
> 
> * [https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23403](https://www.google.com/search?q=https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23403) TalkingData Mobile User Demographics'ten, bir dizi sorun ve i.i.d olmayan vakalarÄ±n yarÄ±ÅŸmanÄ±n doÄŸru eÄŸitim/test bÃ¶lmesini etkilediÄŸi yer.
> 
> * [https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870](https://www.google.com/search?q=https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries/discussion/31870) Two Sigma Connect: Rental Listing Inquiries'dan, meta verilerin (her klasÃ¶rÃ¼n oluÅŸturulma zamanÄ±) iÅŸe yaradÄ±ÄŸÄ± yer.


### Summary *(Ã–zet)*

BÃ¶lÃ¼mÃ¼n sonuna gelmiÅŸ bulunuyoruz, bu nedenle doÄŸrulama (validation) stratejinizi dÃ¼zenleyebilmeniz ve bir yarÄ±ÅŸmanÄ±n sonuna gÃ¶ndereceÄŸiniz birkaÃ§ uygun modelle ulaÅŸabilmeniz iÃ§in yolda tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z tavsiyeleri Ã¶zetleyeceÄŸiz.

Bu bÃ¶lÃ¼mde, Ã¶ncelikle **halka aÃ§Ä±k liderlik tablosunun (public leaderboard) dinamiklerini** analiz ettik, uyarlanabilir aÅŸÄ±rÄ± Ã¶ÄŸrenme (adaptive overfitting) ve bÃ¼yÃ¼k deÄŸiÅŸiklikler (shake-ups) gibi sorunlarÄ± araÅŸtÄ±rdÄ±k. ArdÄ±ndan, bir veri bilimi yarÄ±ÅŸmasÄ±nda doÄŸrulamanÄ±n Ã¶nemini, **gÃ¼venilir bir sistem oluÅŸturmayÄ±**, bunu liderlik tablosuna gÃ¶re ayarlamayÄ± ve ardÄ±ndan Ã§abalarÄ±nÄ±zÄ±n kaydÄ±nÄ± tutmayÄ± tartÄ±ÅŸtÄ±k.

Ã‡eÅŸitli doÄŸrulama stratejilerini tartÄ±ÅŸtÄ±k ve **hiperparametrelerinizi ayarlamanÄ±n** ve test verilerinizi veya doÄŸrulama bÃ¶lÃ¼mlerinizi **dÃ¼ÅŸmanca doÄŸrulama (adversarial validation)** kullanarak kontrol etmenin en iyi yolunu da gÃ¶rdÃ¼k.

Son olarak, **Kaggle yarÄ±ÅŸmalarÄ±nda karÅŸÄ±laÅŸÄ±lan bazÄ± veri sÄ±zÄ±ntÄ±larÄ±nÄ± (leakages)** tartÄ±ÅŸtÄ±k ve bunlarla nasÄ±l baÅŸa Ã§Ä±kÄ±lacaÄŸÄ±na dair tavsiyeler sunduk.

Ä°ÅŸte kapanÄ±ÅŸ Ã¶nerilerimiz:

* Daima yarÄ±ÅŸmanÄ±n ilk kÄ±smÄ±nÄ±, **gÃ¼venilir bir doÄŸrulama ÅŸemasÄ± oluÅŸturmaya** ayÄ±rÄ±n. OlasÄ±lÄ±ksal doÄŸasÄ± ve daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ verilere genelleme yeteneÄŸi gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, bir **eÄŸitim-test bÃ¶lmesinden (train-test split) ziyade k-katlÄ± Ã§apraz doÄŸrulama (k-fold)** yÃ¶ntemini tercih edin.
* DoÄŸrulama ÅŸemanÄ±z **kararsÄ±zsa**, daha fazla kat (fold) kullanÄ±n veya farklÄ± veri bÃ¶lmeleriyle **birden Ã§ok kez Ã§alÄ±ÅŸtÄ±rÄ±n**. Test setinizi daima dÃ¼ÅŸmanca doÄŸrulama kullanarak kontrol edin.
* Hem doÄŸrulama ÅŸemanÄ±za hem de liderlik tablosuna dayalÄ± olarak **sonuÃ§larÄ±n kaydÄ±nÄ± tutun**. OlasÄ± optimizasyonlar ve Ã§Ä±ÄŸÄ±r aÃ§Ä±cÄ± buluÅŸlar (sihirli Ã¶zellikler veya sÄ±zÄ±ntÄ±lar gibi) iÃ§in **doÄŸrulama puanÄ±nÄ±za daha Ã§ok gÃ¼venin**.
* BÃ¶lÃ¼mÃ¼n baÅŸÄ±nda aÃ§Ä±kladÄ±ÄŸÄ±mÄ±z gibi, yarÄ±ÅŸmaya yapacaÄŸÄ±nÄ±z **nihai gÃ¶nderimlerinize karar verirken doÄŸrulama puanlarÄ±nÄ±zÄ± kullanÄ±n**. Nihai gÃ¶nderimleriniz iÃ§in, duruma ve liderlik tablosuna gÃ¼venip gÃ¼venmediÄŸinize baÄŸlÄ± olarak, **en iyi yerel Ã§apraz doÄŸrulama yapÄ±lmÄ±ÅŸ modelleriniz** ve liderlik tablosunda iyi puan alan gÃ¶nderimleriniz arasÄ±ndan seÃ§im yapÄ±n, **birinciyi ikinciye tercih edin**.

---

Bu yolculuÄŸumuzun bu noktasÄ±nda, satÄ±rlarÄ±n Ã¶rnekleri (examples) ve sÃ¼tunlarÄ±n Ã¶zellikleri (features) temsil ettiÄŸi matrisler halinde dÃ¼zenlenmiÅŸ sayÄ±sal veya kategorik veriler olan **tablosal verilerle** yarÄ±ÅŸmalara nasÄ±l yaklaÅŸacaÄŸÄ±mÄ±zÄ± tartÄ±ÅŸmaya hazÄ±rÄ±z. Bir sonraki bÃ¶lÃ¼mde, Kaggle tarafÄ±ndan tablosal veriler kullanÄ±larak dÃ¼zenlenen aylÄ±k bir yarÄ±ÅŸma olan **Tabular Playground Series**'i (Inversion tarafÄ±ndan organize edilmiÅŸtir: [https://www.kaggle.com/inversion](https://www.kaggle.com/inversion)) tartÄ±ÅŸacaÄŸÄ±z.

AyrÄ±ca, bu yarÄ±ÅŸmalarda Ã¶ne Ã§Ä±kmanÄ±za yardÄ±mcÄ± olacak **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering), hedef kodlama (target encoding), gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±lar (denoising autoencoders)** ve tablosal veri sorunlarÄ±nda kabul gÃ¶rmÃ¼ÅŸ son teknoloji Ã¶ÄŸrenme algoritmalarÄ±na (XGBoost, LightGBM veya CatBoost gibi gradyan artÄ±rma algoritmalarÄ±) bir alternatif olarak **tablosal veriler iÃ§in bazÄ± sinir aÄŸlarÄ±** gibi bazÄ± Ã¶zel teknikleri tanÄ±tacaÄŸÄ±z.

---

## Chapter 7: Modeling for Tabular Competitions *(BÃ¶lÃ¼m 7: Tablo Verisi YarÄ±ÅŸmalarÄ± Ä°Ã§in Modellemede YaklaÅŸÄ±mlar)*

2017 yÄ±lÄ±na kadar, yarÄ±ÅŸma tÃ¼rleri arasÄ±nda Ã§ok fazla ayrÄ±m yapmaya gerek yoktu ve yarÄ±ÅŸmalarÄ±n bÃ¼yÃ¼k Ã§oÄŸunluÄŸu **tablosal verilere** dayandÄ±ÄŸÄ± iÃ§in Kaggle forumlarÄ±nda "tablosal yarÄ±ÅŸmalar" diye bir ifade bile bulamazdÄ±nÄ±z. Aniden bir ÅŸeyler deÄŸiÅŸti. GÃ¶rece bir yarÄ±ÅŸma kÄ±tlÄ±ÄŸÄ±nÄ±n ardÄ±ndan (bkz. [https://www.kaggle.com/general/49904](https://www.kaggle.com/general/49904)), **derin Ã¶ÄŸrenme** (deep learning) yarÄ±ÅŸmalarÄ± Ã¼stÃ¼nlÃ¼k saÄŸladÄ± ve tablosal yarÄ±ÅŸmalar nadir hale gelerek pek Ã§ok kiÅŸiyi hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸrattÄ±. O kadar nadir hale geldiler ki, Kaggle kÄ±sa sÃ¼re Ã¶nce sentetik verilere dayalÄ± bir dizi tablosal yarÄ±ÅŸma baÅŸlatmak zorunda kaldÄ±. Ne oldu?

2017-2018'e gelindiÄŸinde, veri bilimi tam olgunluÄŸa eriÅŸmiÅŸti ve birÃ§ok ÅŸirket kendi veri yolculuklarÄ±na baÅŸlamÄ±ÅŸtÄ±. Veri bilimi hala sÄ±cak bir konuydu, ancak artÄ±k o kadar da sÄ±ra dÄ±ÅŸÄ± deÄŸildi. O zamanlar Kaggle'Ä± yÄ±llardÄ±r dolduran sorunlara benzer sorunlarÄ±n Ã§Ã¶zÃ¼mleri, birÃ§ok ÅŸirkette **standart bir uygulama** haline gelmiÅŸti. Bu koÅŸullar altÄ±nda, sponsorlar artÄ±k dÄ±ÅŸarÄ±dan tablosal yarÄ±ÅŸmalar dÃ¼zenlemeye daha az motive oldular, Ã§Ã¼nkÃ¼ zaten aynÄ± sorunlarla **iÃ§eride** baÅŸ ediyorlardÄ±. Buna karÅŸÄ±lÄ±k, derin Ã¶ÄŸrenme hala bÃ¼yÃ¼k Ã¶lÃ§Ã¼de keÅŸfedilmemiÅŸ bir alandÄ±r ve uzun bir sÃ¼re daha Ã¶yle kalmaya devam edecektir, bu nedenle en son teknolojiyi zorlamak ve yeni bir ÅŸeyin ortaya Ã§Ä±kÄ±p Ã§Ä±kmadÄ±ÄŸÄ±nÄ± gÃ¶rmek iÃ§in yarÄ±ÅŸmalar baÅŸlatmak mantÄ±klÄ±dÄ±r.

Bu bÃ¶lÃ¼mde **tablosal yarÄ±ÅŸmalarÄ±** ele alacaÄŸÄ±z. BazÄ± Ã¼nlÃ¼ tarihi yarÄ±ÅŸmalara deÄŸinecek ve ayrÄ±ca **Tabular Playground Series**'in daha yeni gerÃ§ekliÄŸine odaklanacaÄŸÄ±z, Ã§Ã¼nkÃ¼ tablosal problemler Ã§oÄŸu veri bilimci iÃ§in standart uygulamadÄ±r ve Kaggle'dan gerÃ§ekten Ã¶ÄŸrenilecek Ã§ok ÅŸey vardÄ±r. **KeÅŸifÃ§i Veri Analizi (EDA)** ve **Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)**, bu yarÄ±ÅŸmalardaki iki yaygÄ±n aktiviteyi tartÄ±ÅŸarak baÅŸlayacaÄŸÄ±z.

Ã–zellik mÃ¼hendisliÄŸi iÃ§in temel stratejileri sunduktan sonra, **kategorik kodlama, Ã¶zellik seÃ§imi, hedef dÃ¶nÃ¼ÅŸÃ¼mleri ve sÃ¶zde etiketleme (pseudo-labeling)** gibi birÃ§ok ilgili konuya geniÅŸleyeceÄŸiz. Tablosal veriler iÃ§in derin Ã¶ÄŸrenme metodolojilerine deÄŸinerek, **TabNet** gibi birkaÃ§ uzmanlaÅŸmÄ±ÅŸ derin sinir aÄŸÄ±nÄ± tanÄ±tacak ve bir **gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±yÄ± (denoising autoencoder)** gÃ¶stereceÄŸiz. Otomatik kodlayÄ±cÄ±larÄ±n, gerÃ§ek dÃ¼nya uygulamalarÄ±nda hala marjinal olmasÄ±na raÄŸmen, son Kaggle yarÄ±ÅŸmalarÄ± iÃ§in neden bu kadar alakalÄ± hale geldiÄŸini aÃ§Ä±klayacaÄŸÄ±z.

Ä°ÅŸleyeceÄŸimiz konular:
* **Tabular Playground Series**
* Tekrarlanabilirlik iÃ§in **rastgele durum (random state) ayarlama**
* **EDA'nÄ±n Ã¶nemi**
* Verilerinizin **boyutunu kÃ¼Ã§Ã¼ltme**
* **Ã–zellik mÃ¼hendisliÄŸi** uygulama
* **SÃ¶zde etiketleme (Pseudo-labeling)**
* **Otomatik kodlayÄ±cÄ±lar** ile gÃ¼rÃ¼ltÃ¼ giderme
* Tablosal yarÄ±ÅŸmalar iÃ§in **sinir aÄŸlarÄ±**

Bu bÃ¶lÃ¼m, tablosal yarÄ±ÅŸmalarla ilgili her konuyu kapsamayacaktÄ±r, ancak veri biliminin Ã¶zÃ¼nÃ¼ oluÅŸturduklarÄ± iÃ§in bunlarÄ± diÄŸer birÃ§ok kitapta kolayca bulabilirsiniz. Bu bÃ¶lÃ¼mÃ¼n yapacaÄŸÄ± ÅŸey, Kaggle'daki tablosal yarÄ±ÅŸmalarÄ± karakterize eden ve Kaggle forumlarÄ± dÄ±ÅŸÄ±nda baÅŸka bir yerde kolay kolay bulamayacaÄŸÄ±nÄ±z bir dizi Ã¶zel teknik ve yaklaÅŸÄ±m sunmaktÄ±r.

### The Tabular Playground Series *(Tabular Playground Serisi)*

Tablosal problemlere yÃ¶nelik bÃ¼yÃ¼k talep nedeniyle, Kaggle Ã§alÄ±ÅŸanlarÄ± 2021'de bir deney baÅŸlattÄ± ve **Tabular Playground Series** adÄ±nÄ± verdikleri aylÄ±k bir yarÄ±ÅŸma dÃ¼zenledi. YarÄ±ÅŸmalar, halka aÃ§Ä±k verileri veya Ã¶nceki yarÄ±ÅŸmalardan elde edilen verileri kopyalayan **sentetik veri setlerine** dayanÄ±yordu. Sentetik veriler, **CTGAN** adlÄ± derin Ã¶ÄŸrenme Ã¼retken aÄŸÄ± sayesinde oluÅŸturuldu.

> **CTGAN** kodunu [https://github.com/sdv-dev/CTGAN](https://github.com/sdv-dev/CTGAN) adresinde bulabilirsiniz. AyrÄ±ca, tablosal verilerdeki satÄ±rlarÄ±n olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± modelleyerek ve ardÄ±ndan gerÃ§ekÃ§i sentetik veriler Ã¼reterek nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± aÃ§Ä±klayan ilgili bir makale de mevcuttur (bkz. [https://arxiv.org/pdf/1907.00503v2.pdf](https://www.google.com/search?q=https://arxiv.org/pdf/1907.00503v2.pdf)).


> MIT giriÅŸimi olan **Synthetic Data Vault (SDV)** ([https://sdv.dev/](https://sdv.dev/)), CTGAN'Ä±n arkasÄ±ndaki teknolojiyi ve etrafÄ±ndaki oldukÃ§a fazla sayÄ±da aracÄ± yarattÄ±. SonuÃ§, iÅŸletmelerin gerÃ§ek verileri taklit eden sentetik veriler Ã¼retmesine yardÄ±mcÄ± olmak iÃ§in oluÅŸturulmuÅŸ bir dizi aÃ§Ä±k kaynaklÄ± yazÄ±lÄ±m sistemidir; veri bilimcilerinin gerÃ§ek verilere dayalÄ± anonim veri setleri oluÅŸturmasÄ±na ve ayrÄ±ca modelleme amaÃ§larÄ± iÃ§in mevcut olanlarÄ± artÄ±rmasÄ±na yardÄ±mcÄ± olabilir.

Kaggle, 2021'de puan, madalya veya Ã¶dÃ¼l (yalnÄ±zca bazÄ± promosyon Ã¼rÃ¼nleri) sunmamasÄ±na raÄŸmen birÃ§ok Kaggle kullanÄ±cÄ±sÄ±nÄ±n ilgisini Ã§eken 13 oldukÃ§a baÅŸarÄ±lÄ± yarÄ±ÅŸma baÅŸlattÄ±. Ä°ÅŸte 2021 listesi; belirli problemleri tÃ¼re veya metriÄŸe gÃ¶re bulmak ve ilgili kaynaklarÄ± (odaklanmÄ±ÅŸ tartÄ±ÅŸmalar veya Notebook'lar gibi) aramak iÃ§in kullanabilirsiniz:

| Ay | Problem | DeÄŸiÅŸkenler | Metrik | Eksik Veri |
| :--- | :--- | :--- | :--- | :--- |
| Ocak 2021 | BelirtilmemiÅŸ bir problem Ã¼zerine Regresyon | SayÄ±sal | RMSE | HayÄ±r |
| Åubat 2021 | Bir sigorta talebinin deÄŸerini tahmin eden Regresyon | SayÄ±sal ve Kategorik | RMSE | HayÄ±r |
| Mart 2021 | Bir sigorta talebini tahmin eden Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | AUC | HayÄ±r |
| Nisan 2021 | Orijinal **Titanic** veri setine Ã§ok benzeyen bir kopyasÄ± Ã¼zerine Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | DoÄŸruluk (Accuracy) | Evet |
| MayÄ±s 2021 | Listeleme ile ilgili Ã§eÅŸitli nitelikler verildiÄŸinde bir e-ticaret Ã¼rÃ¼nÃ¼ndeki kategoriyi tahmin eden Ã‡oklu SÄ±nÄ±flandÄ±rma | Kategorik | Ã‡oklu SÄ±nÄ±f LogLoss | HayÄ±r |
| Haziran 2021 | Listeleme ile ilgili Ã§eÅŸitli nitelikler verildiÄŸinde bir e-ticaret Ã¼rÃ¼nÃ¼ndeki kategoriyi tahmin eden Ã‡oklu SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | Ã‡oklu SÄ±nÄ±f LogLoss | HayÄ±r |
| Temmuz 2021 | Ã‡eÅŸitli girdi sensÃ¶r deÄŸerleri (Ã¶rneÄŸin, bir zaman serisi) aracÄ±lÄ±ÄŸÄ±yla bir ÅŸehirdeki hava kirliliÄŸini tahmin eden Ã‡oklu Regresyon | SayÄ±sal, Zaman | RMSLE | Evet |
| AÄŸustos 2021 | Bir kredi temerrÃ¼dÃ¼ (loan default) ile iliÅŸkili kaybÄ± hesaplayan Regresyon | SayÄ±sal | RMSE | HayÄ±r |
| 30 GÃ¼n ML | Bir sigorta talebinin deÄŸeri Ã¼zerine Regresyon | SayÄ±sal ve Kategorik | RMSE | HayÄ±r |
| EylÃ¼l 2021 | Bir sigorta poliÃ§esi iÃ§in talepte bulunulup bulunulmayacaÄŸÄ±nÄ± tahmin eden Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal | AUC | Evet |
| Ekim 2021 | Ã‡eÅŸitli kimyasal Ã¶zellikler verildiÄŸinde molekÃ¼llerin biyolojik tepkisini tahmin eden Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | AUC | HayÄ±r |
| KasÄ±m 2021 | E-postadan Ã§Ä±karÄ±lan Ã§eÅŸitli Ã¶zellikler aracÄ±lÄ±ÄŸÄ±yla spam e-postalarÄ± tanÄ±mlayan Ä°kili SÄ±nÄ±flandÄ±rma | SayÄ±sal | AUC | HayÄ±r |
| AralÄ±k 2021 | Orijinal Forest Cover Type Prediction yarÄ±ÅŸmasÄ±na dayanan Ã‡oklu SÄ±nÄ±flandÄ±rma | SayÄ±sal ve Kategorik | Ã‡oklu SÄ±nÄ±flandÄ±rma DoÄŸruluÄŸu | HayÄ±r |

Tabular Playground yarÄ±ÅŸmalarÄ±, daha sofistike ve zorlu problemlerle 2022'de de devam etti:

| Ay | Problem | DeÄŸiÅŸkenler | Metrik | Eksik Veri |
| :--- | :--- | :--- | :--- | :--- |
| Ocak 2022 | Ä°ki kurgusal baÄŸÄ±msÄ±z maÄŸaza zincirinden Kaggle Ã¼rÃ¼nlerinin satÄ±ÅŸlarÄ±nÄ± tahmin etme | Tarihler ve Kategorik | Simetrik Ortalama Mutlak YÃ¼zde HatasÄ± (SMAPE) | HayÄ±r |
| Åubat 2022 | Veri sÄ±kÄ±ÅŸtÄ±rma ve veri kaybÄ± iÃ§eren bir genomik analiz tekniÄŸinden elde edilen verileri kullanarak 10 farklÄ± bakteri tÃ¼rÃ¼nÃ¼ sÄ±nÄ±flandÄ±rma | SayÄ±sal | Kategorizasyon DoÄŸruluÄŸu | HayÄ±r |

Bu bÃ¶lÃ¼mÃ¼n bÃ¼yÃ¼k bir kÄ±smÄ±, geÃ§miÅŸteki daha gÃ¶rkemli yarÄ±ÅŸmalarÄ± analiz etmek yerine, bu yarÄ±ÅŸmalarda ortaya Ã§Ä±kan kod ve tartÄ±ÅŸmalar gÃ¶zlemlenerek yazÄ±lmÄ±ÅŸtÄ±r. BelirttiÄŸimiz gibi, deÄŸiÅŸen profesyonel ortam gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, tablosal yarÄ±ÅŸmalarÄ±n gerÃ§ekten ortadan kalktÄ±ÄŸÄ±na ve geÃ§miÅŸten ziyade **ÅŸimdiki zamana iliÅŸkin Ã¶neri ve ipuÃ§larÄ±nÄ±** okumanÄ±n sizin iÃ§in daha yararlÄ± olacaÄŸÄ±na inanÄ±yoruz.

Kaggle puanlarÄ± ve madalyalarÄ± iÃ§eren diÄŸer tam teÅŸekkÃ¼llÃ¼ yarÄ±ÅŸmalarda olduÄŸu gibi, tablosal yarÄ±ÅŸmalarda da kitabÄ±n baÅŸka bir yerinde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z basit ama Ã§ok etkili bir sÃ¼reÃ§ (pipeline) izlemenizi Ã¶neririz:

  * **KeÅŸifÃ§i Veri Analizi (EDA)**
  * **Veri HazÄ±rlama**
  * **Modelleme** (model doÄŸrulamasÄ± iÃ§in bir Ã§apraz doÄŸrulama stratejisi kullanarak)
  * **Ä°ÅŸlem SonrasÄ± (Post-processing)**
  * **GÃ¶nderim (Submission)**

Kural olarak, ayrÄ±ca **tekrarlanabilirliÄŸi** saÄŸlamaya ve tÃ¼m modelleri (her bir katmandan/fold'dan), kullanÄ±lan parametrelerin listesini, tÃ¼m katman tahminlerini, katman dÄ±ÅŸÄ± (out-of-fold) tahminlerin tÃ¼mÃ¼nÃ¼ ve tÃ¼m veriler Ã¼zerinde eÄŸitilmiÅŸ modellerden gelen tÃ¼m tahminleri kaydetmeye Ã¶zen gÃ¶stermelisiniz.

TÃ¼m bu bilgileri, Ã¶rneÄŸin uygun etiketleme kullanarak, **MD5 karma deÄŸerlerini** takip ederek (ayrÄ±ntÄ±lar iÃ§in bu Stack Overflow yanÄ±tÄ±na bakabilirsiniz: [https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python](https://stackoverflow.com/questions/16874598/how-do-i-calculate-the-md5-checksum-of-a-file-in-python)) ve her deneyden elde edilen **CV puanlarÄ±nÄ± ve liderlik tablosu sonuÃ§larÄ±nÄ±** izleyerek, kurtarÄ±lmasÄ± ve yeniden yapÄ±landÄ±rÄ±lmasÄ± kolay olacak ÅŸekilde kaydetmelisiniz. Kaggle kullanÄ±cÄ±larÄ±nÄ±n Ã§oÄŸu bunu .txt dosyalarÄ± veya Excel elektronik tablolarÄ± gibi basit araÃ§larla yapar, ancak aÅŸaÄŸÄ±dakiler gibi daha sofistike yollar da mevcuttur:

  * DVC ([https://dvc.org/](https://dvc.org/))
  * Weights and Biases ([https://wandb.ai/site](https://wandb.ai/site))
  * MLflow ([https://mlflow.org/](https://mlflow.org/))
  * Neptune ([https://neptune.ai/experiment-tracking](https://neptune.ai/experiment-tracking))

SonuÃ§ta, Ã¶nemli olan kullandÄ±ÄŸÄ±nÄ±z araÃ§ deÄŸil, **sonuÃ§lardÄ±r**, bu yÃ¼zden bir yarÄ±ÅŸmanÄ±n heyecanÄ± iÃ§inde bile deneylerinizde ve modellerinizde dÃ¼zeni saÄŸlamak iÃ§in elinizden geleni yapÄ±n.

Devam etmeden Ã¶nce, Kaggle'Ä±n bu yarÄ±ÅŸmalar iÃ§in verileri oluÅŸturmak iÃ§in kullandÄ±ÄŸÄ± teknolojiyi de dÃ¼ÅŸÃ¼nÃ¼n; **verilerin nasÄ±l oluÅŸturulduÄŸunu doÄŸru bir ÅŸekilde anlayabilirseniz**, Ã¶nemli bir avantaj elde edersiniz. Buna ek olarak, sentetik verilerin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamak, gerÃ§ek dÃ¼nyada veri bilimi yapma ÅŸekliniz Ã¼zerinde gerÃ§ekten bir etki yaratabilir, Ã§Ã¼nkÃ¼ size eÄŸitim iÃ§in daha Ã§eÅŸitli verileri kolayca elde etme yolu sunar.

> Ã–rneÄŸin, **Google Brain â€“ Ventilator Pressure Prediction** yarÄ±ÅŸmasÄ±nÄ± ([https://www.kaggle.com/c/ventilator-pressure-prediction](https://www.kaggle.com/c/ventilator-pressure-prediction)) ele alalÄ±m. Bu yarÄ±ÅŸmada, mekanik ventilasyon kontrolÃ¼ iÃ§in makine Ã¶ÄŸrenimi geliÅŸtirmeniz gerekiyordu.
>
> SaÄŸlanan verileri derin Ã¶ÄŸrenme ile modelleyerek iyi sonuÃ§lar elde edebilmenize raÄŸmen, verilerin sentetik kÃ¶keni gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, **Ã¼retici sÃ¼recini tersine mÃ¼hendislikle Ã§Ã¶zebilir** ve Jun Koda'nÄ±n ([https://www.kaggle.com/junkoda](https://www.kaggle.com/junkoda)) yaptÄ±ÄŸÄ± ve gÃ¶nderisinde aÃ§Ä±kladÄ±ÄŸÄ± gibi liderlik tablosunda en Ã¼st sÄ±ralarda yer alan bir sonuÃ§ elde edebilirdiniz: [https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285278](https://www.google.com/search?q=https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285278).

Yapay verileri kendi baÅŸÄ±nÄ±za Ã¼retmek ve sentetik verileri anlamak hiÃ§ bu kadar kolay olmamÄ±ÅŸtÄ±; Dariush Bahrami ([https://www.kaggle.com/dariushbahrami](https://www.kaggle.com/dariushbahrami)) tarafÄ±ndan orijinal olarak kodlanmÄ±ÅŸ ve test edilmiÅŸ bir Notebook'tan tÃ¼retilen bu Notebook'tan ([https://www.kaggle.com/lucamassaron/how-to-use-ctgan-to-generate-more-data](https://www.kaggle.com/lucamassaron/how-to-use-ctgan-to-generate-more-data)) doÄŸrulayabilirsiniz.

### Setting a random state for reproducibility *(Tekrarlanabilirlik iÃ§in rastgele durum belirleme)*

Tablosal bir yarÄ±ÅŸmada kullanabileceÄŸiniz adÄ±mlarÄ± ve modelleri tartÄ±ÅŸmaya baÅŸlamadan Ã¶nce, yukarÄ±da bahsettiÄŸimiz **tekrarlanabilirlik** temasÄ±na geri dÃ¶nmek faydalÄ± olacaktÄ±r.

Kaggle Notebook'larÄ±nda gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z Ã§oÄŸu komutta, **rastgele durum (random state)** olarak bir sayÄ±, yani bir **Ã§ekirdek (seed)** bildiren bir parametre bulacaksÄ±nÄ±z. Bu ayar, sonuÃ§larÄ±nÄ±zÄ±n **tekrarlanabilirliÄŸi** iÃ§in Ã¶nemlidir. BirÃ§ok algoritma deterministik (belirlenimci) deÄŸil, rastgeleliÄŸe dayandÄ±ÄŸÄ± iÃ§in, bir Ã§ekirdek ayarlayarak rastgele Ã¼reticinin davranÄ±ÅŸÄ±nÄ± etkiler, bÃ¶ylece rastgeleliÄŸini **Ã¶ngÃ¶rÃ¼lebilir** hale getirirsiniz: aynÄ± rastgele Ã§ekirdek, aynÄ± rastgele sayÄ± dizisine karÅŸÄ±lÄ±k gelir. BaÅŸka bir deyiÅŸle, aynÄ± kodun her Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±ndan sonra aynÄ± sonuÃ§larÄ± almanÄ±zÄ± saÄŸlar.

Bu nedenle, Scikit-learn'deki tÃ¼m makine Ã¶ÄŸrenimi algoritmalarÄ±nda ve Scikit-learn uyumlu tÃ¼m modellerde (en popÃ¼ler olanlardan bahsetmek gerekirse, Ã¶rneÄŸin **XGBoost, LightGBM** ve **CatBoost**) bir rastgele Ã§ekirdek ayarlama parametresi bulursunuz.

SonuÃ§larÄ±n tekrarlanabilirliÄŸi, gerÃ§ek dÃ¼nya projelerinde olduÄŸu kadar Kaggle yarÄ±ÅŸmalarÄ±nda da Ã¶nemlidir. GerÃ§ek dÃ¼nyada, tekrarlanabilir bir modele sahip olmak, model geliÅŸtirmenin daha iyi izlenmesine ve tutarlÄ±lÄ±ÄŸa olanak tanÄ±r. Kaggle yarÄ±ÅŸmalarÄ±nda, tekrarlanabilirlik, modellerinizdeki herhangi bir varyasyon kaynaÄŸÄ±nÄ± kontrol ettiÄŸiniz iÃ§in **hipotezleri daha iyi test etmenize** yardÄ±mcÄ± olur. Ã–rneÄŸin, yeni bir Ã¶zellik oluÅŸturduysanÄ±z, bunu tekrarlanabilir bir sÃ¼rece (pipeline) dahil etmek, Ã¶zelliÄŸin avantajlÄ± olup olmadÄ±ÄŸÄ±nÄ± anlamanÄ±za yardÄ±mcÄ± olacaktÄ±r. Modeldeki herhangi bir iyileÅŸmenin veya kÃ¶tÃ¼leÅŸmenin yalnÄ±zca Ã¶zelliÄŸe atfedilebileceÄŸinden ve modeli en son Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan beri deÄŸiÅŸen bazÄ± rastgele sÃ¼reÃ§lerin etkilerine atfedilemeyeceÄŸinden emin olursunuz.

Yine, tekrarlanabilirlik **halka aÃ§Ä±k Notebook'larla** uÄŸraÅŸÄ±rken sizin avantajÄ±nÄ±za kullanÄ±labilir. Ã‡oÄŸu zaman, bu Notebook'lar **0, 1 veya 42** gibi sabit bir Ã§ekirdeÄŸe sahip olacaktÄ±r. **42** deÄŸeri oldukÃ§a popÃ¼lerdir Ã§Ã¼nkÃ¼ Douglas Adam'Ä±n *OtostopÃ§unun Galaksi Rehberi*'ne bir gÃ¶ndermedir; kitapta, 7,5 milyon yÄ±llÄ±k bir sÃ¼re boyunca Deep Thought adlÄ± devasa bir sÃ¼per bilgisayar tarafÄ±ndan hesaplanan "HayatÄ±n, Evrenin ve Her Åeyin Nihai Sorununa Cevap"tÄ±r. Åimdi, bir yarÄ±ÅŸmadaki herkes aynÄ± rastgele Ã§ekirdeÄŸi kullanÄ±yorsa, bunun Ã§ifte bir etkisi olabilir:

* Rastgele Ã§ekirdek, halka aÃ§Ä±k liderlik tablosuyla **Ã§ok iyi Ã§alÄ±ÅŸÄ±yor olabilir**, bu da **aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting)** anlamÄ±na gelir.
* BirÃ§ok Kaggle kullanÄ±cÄ±sÄ± benzer sonuÃ§lar Ã¼retecek ve bu da onlarÄ±n Ã¶zel liderlik tablosundaki sÄ±ralamalarÄ±nÄ± aynÄ± ÅŸekilde etkileyecektir.

Rastgele Ã§ekirdeÄŸi deÄŸiÅŸtirerek, aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemiÅŸ ve aynÄ± zamanda **sÄ±ralamayÄ± bozmuÅŸ** olursunuz; baÅŸka bir deyiÅŸle, herkesten farklÄ± sonuÃ§lar alÄ±rsÄ±nÄ±z, bu da sonuÃ§ta size bir avantaj saÄŸlayabilir. Ek olarak, bir Kaggle yarÄ±ÅŸmasÄ±nÄ± kazanÄ±rsanÄ±z, modellerinizin kazanan gÃ¶nderimi nasÄ±l Ã¼rettiÄŸini gÃ¶stermeniz gerekir, bu nedenle Ã¶dÃ¼lÃ¼nÃ¼zÃ¼ hÄ±zlÄ± bir ÅŸekilde almak istiyorsanÄ±z her ÅŸeyin tamamen **tekrarlanabilir** olmasÄ± Ã§ok Ã¶nemlidir.

**TensorFlow** ve **PyTorch** modelleri aÃ§Ä±kÃ§a bir rastgele Ã§ekirdek parametresi kullanmaz, bu nedenle bunlarÄ±n tam tekrarlanabilirliÄŸini saÄŸlamak daha zordur. AÅŸaÄŸÄ±daki kod parÃ§acÄ±ÄŸÄ±, Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda TensorFlow ve PyTorch modelleri iÃ§in aynÄ± rastgele Ã§ekirdeÄŸi ayarlar:

```python
def seed_everything(seed,
                    tensorflow_init=True,
                    pytorch_init=True):
    """
    SonuÃ§larÄ±n tekrarlanabilirliÄŸi iÃ§in temel parametreleri Ã§ekirdekler.
    """
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
    if tensorflow_init is True:
        tf.random.set_seed(seed)
    if pytorch_init is True:
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
```

Scikit-learn'e gelince, bunun yerine, izin verildiÄŸi durumlarda, **`random_state`** parametresini kullanarak rastgele Ã§ekirdeÄŸi doÄŸrudan sÄ±nÄ±fta veya fonksiyonda ayarlamak tavsiye edilir.

### The importance of EDA *(KeÅŸifsel veri analizinin Ã¶nemi)*

**EDA** terimi, modern istatistiksel metodolojinin en Ã¶nde gelen temsilcilerinden biri olan **John W. Tukey**'in Ã§alÄ±ÅŸmalarÄ±ndan gelmektedir. Tukey, 1977 tarihli *Exploratory Data Analysis* (dolayÄ±sÄ±yla EDA kÄ±saltmasÄ±) adlÄ± kitabÄ±nda, EDA'yÄ± veriyi keÅŸfetme, kanÄ±tlarÄ± ortaya Ã§Ä±karma ve daha sonra istatistiksel testlerle doÄŸrulanabilecek **hipotezler geliÅŸtirme** yolu olarak dÃ¼ÅŸÃ¼nÃ¼r.

Onun fikri, istatistiksel hipotezleri nasÄ±l tanÄ±mladÄ±ÄŸÄ±mÄ±zÄ±n, yalnÄ±zca matematiksel hesaplamalara dayalÄ± sÄ±ralÄ± testlerden ziyade **gÃ¶zlem ve muhakemeye** daha fazla dayanabileceÄŸiydi. Bu fikir, makine Ã¶ÄŸrenimi dÃ¼nyasÄ±na iyi bir ÅŸekilde tercÃ¼me edilir, Ã§Ã¼nkÃ¼ bir sonraki bÃ¶lÃ¼mde tartÄ±ÅŸacaÄŸÄ±mÄ±z gibi, Ã¶ÄŸrenme algoritmalarÄ±nÄ±n daha iyi ve daha verimli Ã§alÄ±ÅŸabilmesi iÃ§in veriler iyileÅŸtirilebilir ve Ã¶nceden sindirilebilir.

Bir Kaggle yarÄ±ÅŸmasÄ± iÃ§in yapÄ±lan EDA'da ÅŸunlarÄ± arayacaksÄ±nÄ±z:

  * **Eksik deÄŸerler** ve en Ã¶nemlisi, hedef (target) ile iliÅŸkili eksik deÄŸer **Ã¶rÃ¼ntÃ¼leri**.
  * **Ã‡arpÄ±k (skewed) sayÄ±sal deÄŸiÅŸkenler** ve bunlarÄ±n olasÄ± dÃ¶nÃ¼ÅŸÃ¼mleri.
  * **Birlikte gruplandÄ±rÄ±labilecek** kategorik deÄŸiÅŸkenlerdeki **nadir kategoriler**.
  * Hem tek deÄŸiÅŸkenli (univariate) hem de Ã§ok deÄŸiÅŸkenli (multivariate) **potansiyel aykÄ±rÄ± deÄŸerler** (outliers).
  * **YÃ¼ksek dÃ¼zeyde korelasyonlu** (hatta yinelenen) **Ã¶zellikler**. Kategorik deÄŸiÅŸkenler iÃ§in, **Ã¶rtÃ¼ÅŸen kategorilere** odaklanÄ±n.
  * Problem iÃ§in **en Ã§ok tahmin edici** olan Ã¶zellikler.

Bunu, Ã§eÅŸitli tanÄ±mlayÄ±cÄ± analizler, grafikler ve Ã§izelgeler aracÄ±lÄ±ÄŸÄ±yla baÅŸarÄ±rsÄ±nÄ±z; Ã¶nce her bir ayrÄ± Ã¶zelliÄŸi (istatistiksel terimlerle **tek deÄŸiÅŸkenli analiz**), ardÄ±ndan birkaÃ§ deÄŸiÅŸkeni eÅŸleÅŸtirerek (**iki deÄŸiÅŸkenli analiz**, Ã¶rneÄŸin bir daÄŸÄ±lÄ±m grafiÄŸinde) ve son olarak daha fazla Ã¶zelliÄŸi aynÄ± anda birlikte ele alarak (**Ã§ok deÄŸiÅŸkenli yaklaÅŸÄ±m**) incelersiniz.

-----

**ğŸš€ Otomatik EDA AraÃ§larÄ±**

Tembel hissediyorsanÄ±z veya nasÄ±l ve nereden baÅŸlayacaÄŸÄ±nÄ±zdan emin deÄŸilseniz, baÅŸlangÄ±Ã§ta **otomatik stratejilere** gÃ¼venmek size yardÄ±mcÄ± olabilir. Ã–rneÄŸin, popÃ¼ler bir hÄ±zlÄ± EDA Ã¼cretsiz yazÄ±lÄ±m aracÄ± olan **AutoViz** ([https://github.com/AutoViML/AutoViz](https://github.com/AutoViML/AutoViz)) size Ã§ok zaman kazandÄ±rabilir. AÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rarak onu Notebook'unuza kurabilirsiniz:

```bash
pip install git+git://github.com/AutoViML/AutoViz.git 
```

> AutoViz'in sizin iÃ§in neler yapabileceÄŸine dair daha net bir anlayÄ±ÅŸ elde etmek iÃ§in Dan Roth'un bu Medium makalesini ([https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad](https://www.google.com/search?q=https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad)) okuyabilir veya Georgii Vyshnia'nÄ±n ([https://www.kaggle.com/gvyshnya](https://www.kaggle.com/gvyshnya)) [https://www.kaggle.com/gvyshnya/automating-eda-and-feature-importance-detection](https://www.google.com/search?q=https://www.kaggle.com/gvyshnya/automating-eda-and-feature-importance-detection) gibi birkaÃ§ ilginÃ§ genel Notebook'a gÃ¶z atabilirsiniz.
>
> Ä°kinci baÄŸlantÄ±da, baÅŸka bir araÃ§ olan **Sweetviz**'e ([https://github.com/fbdesignpro/sweetviz](https://github.com/fbdesignpro/sweetviz)) de referanslar bulacaksÄ±nÄ±z. Sweetviz'in Titanic veri setine dayalÄ± bir genel bakÄ±ÅŸ makalesi ve eÄŸitim iÃ§eriÄŸi vardÄ±r: [https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34](https://towardsdatascience.com/powerful-eda-exploratory-data-analysis-in-just-two-lines-of-code-using-sweetviz-6c943d32f34). KullanÄ±ÅŸlÄ± bulabileceÄŸiniz bir diÄŸer popÃ¼ler araÃ§ ise, bu makalede aÃ§Ä±klandÄ±ÄŸÄ± gibi, klasik istatistiksel tanÄ±mlayÄ±cÄ± istatistiklere ve gÃ¶rselleÅŸtirmeye daha fazla dayanan **Pandas Profiling**'dir ([https://github.com/pandas-profiling/pandas-profiling](https://github.com/pandas-profiling/pandas-profiling)): [https://medium.com/analytics-vidhya/pandas-profiling-5ecd0b977ecd](https://medium.com/analytics-vidhya/pandas-profiling-5ecd0b977ecd).

**ğŸ’¡ En Ã–nemli Ä°pucu: Ã–zelleÅŸtirme**

DiÄŸer Kaggle kullanÄ±cÄ±larÄ±nÄ±n ilginÃ§ EDA Notebook'larÄ± yayÄ±nlamasÄ±nÄ± beklemek de bir Ã§Ã¶zÃ¼m olabilir, bu yÃ¼zden her zaman Notebook bÃ¶lÃ¼mlerini takip edin; bazen deÄŸerli ipuÃ§larÄ± ortaya Ã§Ä±kabilir. Bu, modelleme aÅŸamanÄ±zÄ± baÅŸlatmalÄ± ve yarÄ±ÅŸmanÄ±n temel yapÄ±lmasÄ± ve yapÄ±lmamasÄ± gerekenlerini anlamanÄ±za yardÄ±mcÄ± olmalÄ±dÄ±r.

Ancak, unutmayÄ±n ki EDA, eldeki **probleme yÃ¼ksek oranda Ã¶zgÃ¼ olduÄŸunda** bir metadan Ã§Ä±kÄ±p yarÄ±ÅŸma iÃ§in bir **varlÄ±k (asset)** haline gelir; bu, otomatik Ã§Ã¶zÃ¼mlerde asla bulamayacaÄŸÄ±nÄ±z ve genel Notebook'larda nadiren karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z bir ÅŸeydir. **Kendi EDA'nÄ±zÄ± yapmalÄ±** ve kilit, kazandÄ±ran iÃ§gÃ¶rÃ¼leri toplamalÄ±sÄ±nÄ±z.

TÃ¼m bunlar gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, Ã¶nerimiz, Ã¶ÄŸrenilmesi ve Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± gerÃ§ekten kolay olduklarÄ± iÃ§in **otomatik araÃ§lara** biraz bakmanÄ±zdÄ±r. Bu, size, onun yerine grafiklere bakarak ve olasÄ± iÃ§gÃ¶rÃ¼ler hakkÄ±nda akÄ±l yÃ¼rÃ¼terek geÃ§irebileceÄŸiniz bolca zaman kazandÄ±racaktÄ±r ve bu da rekabet performansÄ±nÄ±za kesinlikle yardÄ±mcÄ± olacaktÄ±r.

Ancak, bunu yaptÄ±ktan sonra, **Matplotlib** ve **Seaborn**'u almalÄ± ve saÄŸlanan veri tÃ¼rÃ¼ne ve probleme baÄŸlÄ± olan standart dÄ±ÅŸÄ± Ã§izimler Ã¼zerinde kendiniz bir ÅŸeyler denemelisiniz.

> Ã–rneÄŸin, zaman iÃ§inde gerÃ§ekleÅŸtirilen bir dizi Ã¶lÃ§Ã¼m size verilirse, daha iyi tahminler iÃ§in aÃ§Ä±ÄŸa Ã§Ä±karÄ±cÄ± iÃ§gÃ¶rÃ¼lere iÅŸaret edebilecek bir olgu olan, bir gÃ¶zlem ile diÄŸeri arasÄ±ndaki farklÄ± gecikmeleri gÃ¶stererek, **tek kaydedilen zaman noktalarÄ±nÄ± Ã§izmek** kadar **zamana dayalÄ± sÃ¼rekli fonksiyonu Ã§izmek** de faydalÄ±dÄ±r.

### Dimensionality reduction with t-SNE and UMAP *(t-SNE ve UMAP ile boyut indirgeme)*

EDA yaparken oluÅŸturabileceÄŸiniz pek Ã§ok olasÄ± grafik vardÄ±r ve amacÄ±mÄ±z bunlarÄ±n hepsini burada listelemek deÄŸildir, ancak Ã§ok spesifik ve verilere Ã¶zel Ã§izelgeler kadar bilgi saÄŸlayabilecek, Ã¼zerinde birkaÃ§ sÃ¶z harcamaya deÄŸer birkaÃ§ **boyut indirgeme grafiÄŸi** bulunmaktadÄ±r. Bunlar **t-SNE** ([https://lvdmaaten.github.io/tsne/](https://lvdmaaten.github.io/tsne/)) ve **UMAP** ([https://github.com/lmcinnes/umap)'tÄ±r](https://github.com/lmcinnes/umap)'tÄ±r).

t-SNE ve UMAP, veri bilimcileri tarafÄ±ndan sÄ±klÄ±kla kullanÄ±lan ve Ã§ok deÄŸiÅŸkenli verileri **daha dÃ¼ÅŸÃ¼k boyutlara yansÄ±tmanÄ±za** olanak tanÄ±yan iki tekniktir. Genellikle karmaÅŸÄ±k veri setlerini iki boyutta temsil etmek iÃ§in kullanÄ±lÄ±rlar. 2 boyutlu UMAP ve t-SNE grafikleri, veri probleminiz iÃ§in **aykÄ±rÄ± deÄŸerlerin (outliers)** ve **ilgili kÃ¼melerin (clusters)** varlÄ±ÄŸÄ±nÄ± ortaya Ã§Ä±karabilir.

> Zaman iÃ§inde gerÃ§ekleÅŸtirilen bir dizi Ã¶lÃ§Ã¼m size verilirse, daha iyi tahminler iÃ§in aÃ§Ä±ÄŸa Ã§Ä±karÄ±cÄ± iÃ§gÃ¶rÃ¼lere iÅŸaret edebilecek bir olgu olan, bir gÃ¶zlem ile diÄŸeri arasÄ±ndaki farklÄ± gecikmeleri gÃ¶stererek, tek kaydedilen zaman noktalarÄ±nÄ± Ã§izmek kadar zamana dayalÄ± sÃ¼rekli fonksiyonu Ã§izmek de faydalÄ±dÄ±r.

AslÄ±nda, ortaya Ã§Ä±kan **2 boyutlu yansÄ±tmanÄ±n daÄŸÄ±lÄ±m grafiÄŸini Ã§izebilir** ve onu hedef deÄŸere gÃ¶re renklendirebilirseniz, grafik size **alt gruplarla baÅŸa Ã§Ä±kmak iÃ§in olasÄ± stratejiler** hakkÄ±nda ipuÃ§larÄ± verebilir.

Bir gÃ¶rÃ¼ntÃ¼ yarÄ±ÅŸmasÄ±yla ilgili olmasÄ±na raÄŸmen, UMAP ve t-SNE'nin verilerinizi daha iyi anlamanÄ±za nasÄ±l yardÄ±mcÄ± olabileceÄŸinin iyi bir Ã¶rneÄŸi, Chris Deotte'nin SIIM-ISIC Melanoma SÄ±nÄ±flandÄ±rma yarÄ±ÅŸmasÄ± iÃ§in yaptÄ±ÄŸÄ± analizdir (bkz. [https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/168028](https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/168028)). Bu Ã¶rnekte, Chris eÄŸitim ve test verilerini aynÄ± dÃ¼ÅŸÃ¼k boyutlu yansÄ±tmalarda iliÅŸkilendirmiÅŸ, yalnÄ±zca test Ã¶rneklerinin bulunduÄŸu kÄ±sÄ±mlarÄ± vurgulamÄ±ÅŸtÄ±r.

> UMAP ve t-SNE, verilerde bulunmasÄ± zor olan Ã¶rÃ¼ntÃ¼leri keÅŸfetmede paha biÃ§ilmez bir yardÄ±m sunsa da, onlarÄ± modelleme Ã§abalarÄ±nÄ±zda **Ã¶zellikler** olarak da kullanabilirsiniz. Bu kullanÄ±mÄ±n ilginÃ§ bir Ã¶rneÄŸi, Mike Kim'in t-SNE yansÄ±tÄ±mlarÄ±nÄ± yarÄ±ÅŸma iÃ§in eÄŸitim Ã¶zellikleri olarak kullandÄ±ÄŸÄ± Otto Group ÃœrÃ¼n SÄ±nÄ±flandÄ±rma YarÄ±ÅŸmasÄ±'nda gÃ¶sterilmiÅŸtir ([https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295](https://www.google.com/search?q=https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/14295)).

-----

**âš ï¸ Dikkat Edilmesi Gerekenler ve Ä°yileÅŸtirmeler**

*How to t-SNE Effectively* ([https://distill.pub/2016/misread-tsne/](https://distill.pub/2016/misread-tsne/)) makalesinde belirtildiÄŸi gibi, bu teknikleri doÄŸru bir ÅŸekilde kullanmanÄ±z gerekir, Ã§Ã¼nkÃ¼ **olmayan yerlerde kÃ¼meler ve Ã¶rÃ¼ntÃ¼ler gÃ¶rmek kolaydÄ±r**. AynÄ± uyarÄ± UMAP iÃ§in de geÃ§erlidir, Ã§Ã¼nkÃ¼ yanlÄ±ÅŸ okunabilecek grafikler de Ã¼retebilir. [https://pair-code.github.io/understanding-umap/](https://pair-code.github.io/understanding-umap/) gibi kÄ±lavuzlar, hem UMAP hem de t-SNE'nin gerÃ§ek dÃ¼nya verileri Ã¼zerindeki performansÄ± hakkÄ±nda saÄŸlam tavsiyeler sunarak Ã¶neriler ve uyarÄ±lar saÄŸlar.

Bu tehlikelere raÄŸmen, deneyimlerimize gÃ¶re, bu yaklaÅŸÄ±mlar PCA veya SVD gibi **doÄŸrusal kombinasyonla varyans yeniden yapÄ±landÄ±rmasÄ±na dayanan klasik yÃ¶ntemlerden kesinlikle daha aÃ§Ä±klayÄ±cÄ±dÄ±r**. Bu yaklaÅŸÄ±mlarla karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, UMAP ve t-SNE, verilerin topografyasÄ±nÄ± korurken sonuÃ§larÄ±n gÃ¶rsel olarak Ã§izilmesine izin vererek, boyutu aÅŸÄ±rÄ± derecede azaltmayÄ± baÅŸarÄ±r. Yan etki olarak, uydurulmalarÄ± (fit) Ã§ok daha yavaÅŸtÄ±r. Ancak, NVIDIA, bir GPU destekli Notebook veya betik kullanarak hem UMAP hem de t-SNE sonuÃ§larÄ±nÄ± Ã§ok makul bir zaman diliminde geri dÃ¶ndÃ¼ren ve etkili bir EDA aracÄ± olarak kullanÄ±mlarÄ±na izin veren CUDA tabanlÄ± **RAPIDS** paketini ([https://developer.nvidia.com/rapids](https://developer.nvidia.com/rapids)) yayÄ±nladÄ±.

> Hem UMAP hem de t-SNE'yi bir RAPIDS uygulamasÄ± ve GPU ile veri keÅŸif amaÃ§lÄ± uygulamanÄ±n yararlÄ± bir Ã¶rneÄŸini 30 GÃ¼n ML yarÄ±ÅŸmasÄ± iÃ§in aÅŸaÄŸÄ±daki baÄŸlantÄ±da bulabilirsiniz: [https://www.kaggle.com/lucamassaron/interesting-eda-tsne-umap/](https://www.google.com/search?q=https://www.kaggle.com/lucamassaron/interesting-eda-tsne-umap/).

YukarÄ±daki Ã¶rnek Notebook'un Ã§Ä±ktÄ±sÄ± olan ÅŸekilde, veri kÃ¼mesini birden Ã§ok kÃ¼menin nasÄ±l doldurduÄŸunu gÃ¶rebilirsiniz, ancak bunlarÄ±n hiÃ§biri hedefle belirli bir iliÅŸkiyi ortaya Ã§Ä±karacak ÅŸekilde kabul edilemez:

![](im/1057.png)

BaÅŸka bir Notebook'ta ([https://www.kaggle.com/lucamassaron/really-not-missing-at-random](https://www.google.com/search?q=https://www.kaggle.com/lucamassaron/really-not-missing-at-random)), aynÄ± teknikler bunun yerine **eksik Ã¶rneklere ait ikili gÃ¶stergelere** uygulanmÄ±ÅŸ ve belirli bir yanÄ±t tÃ¼rÃ¼nÃ¼n hakim olduÄŸu spesifik ve ayrÄ± alanlara iÅŸaret eden dÃ¼ÅŸÃ¼ndÃ¼rÃ¼cÃ¼ figÃ¼rler ortaya Ã§Ä±karmÄ±ÅŸtÄ±r. GerÃ§ekten de, o Ã¶rnekte, eksik Ã¶rnekler rastgele oluÅŸmamÄ±ÅŸ ve oldukÃ§a tahmin edici olmuÅŸtur:

![](im/1058.png)

### Reducing the size of your data *(Veri boyutunu kÃ¼Ã§Ã¼ltme)*

**ğŸ’¾ Verilerinizin Boyutunu KÃ¼Ã§Ã¼ltme (Bellek KullanÄ±mÄ±nÄ± Azaltma)**

Kaggle Notebook'larÄ±nda doÄŸrudan Ã§alÄ±ÅŸÄ±yorsanÄ±z, bunlarÄ±n sÄ±nÄ±rlamalarÄ± oldukÃ§a can sÄ±kÄ±cÄ± gelebilir ve bunlarla uÄŸraÅŸmak zaman kaybÄ±na neden olabilir. Bu sÄ±nÄ±rlamalardan biri, yÃ¼rÃ¼tmeyi durduracak ve betiÄŸi baÅŸtan baÅŸlatmaya zorlayacak olan **bellek yetersizliÄŸi (out-of-memory)** hatalarÄ±dÄ±r. Bu, birÃ§ok yarÄ±ÅŸmada oldukÃ§a yaygÄ±ndÄ±r. Ancak, verileri kÃ¼Ã§Ã¼k yÄ±ÄŸÄ±nlar halinde diskten alÄ±p iÅŸleyebileceÄŸiniz metin veya gÃ¶rÃ¼ntÃ¼lere dayalÄ± derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ±nÄ±n aksine, tablosal verilerle Ã§alÄ±ÅŸan algoritmalarÄ±n Ã§oÄŸu, **tÃ¼m verilerin bellekte iÅŸlenmesini** gerektirir.

En yaygÄ±n durum, Pandas'Ä±n `read_csv` iÅŸlevi kullanÄ±larak bir CSV dosyasÄ±ndan verileri yÃ¼klediÄŸinizde, ancak **DataFrame'in Ã¶zellik mÃ¼hendisliÄŸi ve makine Ã¶ÄŸrenimi iÃ§in Kaggle Notebook'unda iÅŸlenemeyecek kadar bÃ¼yÃ¼k** olmasÄ±dÄ±r. Ã‡Ã¶zÃ¼m, kullandÄ±ÄŸÄ±nÄ±z Pandas DataFrame'in boyutunu **hiÃ§bir bilgi kaybetmeden (kayÄ±psÄ±z sÄ±kÄ±ÅŸtÄ±rma)** sÄ±kÄ±ÅŸtÄ±rmaktÄ±r. Bu, Guillaume Martin'in Ã§alÄ±ÅŸmasÄ±ndan tÃ¼retilen aÅŸaÄŸÄ±daki betik kullanÄ±larak kolayca baÅŸarÄ±labilir (orijinal Notebook'u burada bulabilirsiniz: [https://www.kaggle.com/gemartin/load-data-reduce-memory-usage](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)).

```python
def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)
            else: # float types
                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
    end_mem = df.memory_usage().sum() / 1024**2
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))
    return df
```

> Guillaume Martin, Kaggle'da bÃ¶yle bir fikri Ã¶neren ilk kiÅŸi deÄŸildi. Pandas DataFrame'i sÄ±kÄ±ÅŸtÄ±rma fikrine sahip ilk Kaggle kullanÄ±cÄ±sÄ±, Zillow yarÄ±ÅŸmasÄ± sÄ±rasÄ±nda bir kÃ¼Ã§Ã¼ltme iÅŸlevi yazan Arjan Groen'di ([https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65](https://www.kaggle.com/arjanso/reducing-dataframe-memory-size-by-65)).

-----

**ğŸ¤” Bu YaklaÅŸÄ±m NasÄ±l Ã‡alÄ±ÅŸÄ±r?**

Bu betik, bir veri setindeki tÃ¼m **sayÄ±sal Ã¶zelliklerin** belirli bir deÄŸer aralÄ±ÄŸÄ±nda bulunmasÄ± gerÃ§eÄŸinden yararlanÄ±r. Python'da bellekte kapladÄ±klarÄ± bayt sayÄ±sÄ±na gÃ¶re farklÄ± tÃ¼rde tam sayÄ± ve kayan noktalÄ± sayÄ±sal deÄŸiÅŸkenler bulunduÄŸundan, betik her Ã¶zellikte bulunan deÄŸer aralÄ±ÄŸÄ±nÄ±, her bir sayÄ±sal tipin kabul edebileceÄŸi maksimum ve minimum deÄŸerle karÅŸÄ±laÅŸtÄ±rÄ±r. Bu, Ã¶zelliÄŸi, kendi deÄŸer aralÄ±ÄŸÄ±yla Ã§alÄ±ÅŸan ve **en az bellek gerektiren sayÄ±sal tipe** ayarlamak iÃ§in yapÄ±lÄ±r.

Bu yaklaÅŸÄ±m, Kaggle Notebook'larÄ±nda sorunsuz Ã§alÄ±ÅŸÄ±r, ancak bazÄ± uyarÄ±larla birlikte. SÄ±kÄ±ÅŸtÄ±rma yoluyla her Ã¶zellik iÃ§in en uygun sayÄ±sal tipi ayarladÄ±ktan sonra, ayarlanan sayÄ±sal tiplerin kapasitesini aÅŸan deÄŸerlerle sonuÃ§lanabilecek herhangi bir **Ã¶zellik mÃ¼hendisliÄŸi** uygulayamazsÄ±nÄ±z, Ã§Ã¼nkÃ¼ bÃ¶yle bir iÅŸlem **hatalÄ± sonuÃ§lar** Ã¼retecektir. Ã–nerimiz, bunu Ã¶zellik mÃ¼hendisliÄŸinden **sonra** veya mevcut verilerinizi yeniden Ã¶lÃ§eklendirmeyen bÃ¼yÃ¼k dÃ¶nÃ¼ÅŸÃ¼mlerden **Ã¶nce** uygulamanÄ±zdÄ±r. Bunu **Ã§Ã¶p toplama (garbage collection)** kitaplÄ±ÄŸÄ± `gc` ve `gc.collect()` metodu ile birleÅŸtirmek, Kaggle Notebook'unuzun bellek durumunu iyileÅŸtirecektir.

Verilerinizin boyutunu azaltmanÄ±n (diÄŸer ÅŸeylerin yanÄ± sÄ±ra) baÅŸka bir yolu da Ã¶zellik mÃ¼hendisliÄŸini (Ã¶zellikle **Ã¶zellik seÃ§imi** ve **veri sÄ±kÄ±ÅŸtÄ±rma**) kullanmaktÄ±r.

### Applying feature engineering *(Ã–zellik mÃ¼hendisliÄŸi uygulama)*

GerÃ§ek dÃ¼nyadaki projelerde, baÅŸarÄ±lÄ± bir makine Ã¶ÄŸrenimi modeliyle vasat bir model arasÄ±ndaki farkÄ± yaratan ÅŸey Ã§oÄŸu zaman **modelin kendisi deÄŸil, veridir**.
Veriden bahsederken, kÃ¶tÃ¼, iyi ve mÃ¼kemmel veri arasÄ±ndaki fark yalnÄ±zca **eksik deÄŸerlerin bulunmamasÄ±** veya **deÄŸerlerin gÃ¼venilirliÄŸi** (yani verinin â€œkalitesiâ€) ya da **mevcut Ã¶rnek sayÄ±sÄ±** (yani verinin â€œmiktarÄ±â€) deÄŸildir. Deneyimlerimize gÃ¶re, asÄ±l farkÄ± yaratan unsur, verinin iÃ§eriÄŸinin **bilgi deÄŸeri**dir ve bu deÄŸer **Ã¶zelliklerin (features)** tÃ¼rÃ¼yle temsil edilir.

**Ã–zellikler**, veri bilimi projelerinin ÅŸekil verilen gerÃ§ek â€œham maddesidirâ€, Ã§Ã¼nkÃ¼ modellerin sÄ±nÄ±flarÄ± ayÄ±rmak veya deÄŸerleri tahmin etmek iÃ§in kullandÄ±klarÄ± bilgi onlarda bulunur. Her modelin bir ifade gÃ¼cÃ¼ ve Ã¶zellikleri tahminlere dÃ¶nÃ¼ÅŸtÃ¼rme yeteneÄŸi vardÄ±r. Ancak eÄŸer Ã¶zellikler aÃ§Ä±sÄ±ndan yetersizseniz, hiÃ§bir model sizi kurtaramaz ve daha iyi tahminler sunamaz. Modeller yalnÄ±zca verideki deÄŸeri gÃ¶rÃ¼nÃ¼r hale getirir â€” kendileri baÅŸlÄ± baÅŸÄ±na sihirli deÄŸildir.

**Kaggle** Ã¼zerinde, nadir yarÄ±ÅŸmalar dÄ±ÅŸÄ±nda tÃ¼m katÄ±lÄ±mcÄ±lar baÅŸlangÄ±Ã§ta aynÄ± veriye sahiptir. Bu noktada farkÄ± yaratan, **veriyi nasÄ±l iÅŸlediÄŸinizdir**. Elinizdeki veriyi iyileÅŸtirebileceÄŸinizi gÃ¶z ardÄ± etmek, birÃ§ok Kaggle katÄ±lÄ±mcÄ±sÄ±nÄ±n yaptÄ±ÄŸÄ± yaygÄ±n bir hatadÄ±r. **Ã–zellik mÃ¼hendisliÄŸi (feature engineering)**, veriyi modeller iÃ§in daha yararlÄ± bilgilere dÃ¶nÃ¼ÅŸtÃ¼rmeye yÃ¶nelik teknikler bÃ¼tÃ¼nÃ¼dÃ¼r ve yarÄ±ÅŸmalarda daha iyi performans elde etmenin deÄŸiÅŸmez anahtarÄ±dÄ±r. En gÃ¼Ã§lÃ¼ modeller bile, verinin daha anlaÅŸÄ±lÄ±r bir biÃ§imde iÅŸlenmesini gerektirir.

Ã–zellik mÃ¼hendisliÄŸi aynÄ± zamanda, genellikle konuya Ã¶zel uzmanlÄ±k bilgisi olan **Ã¶n bilgileri** veriye dahil etmenin bir yoludur. Mevcut Ã¶zellikleri toplamak, Ã§Ä±karmak veya bÃ¶lmek gibi iÅŸlemlerle, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z problemi daha iyi aÃ§Ä±klayan gÃ¶stergeler veya tahminler elde edebilirsiniz.

Ã–zellik mÃ¼hendisliÄŸinin, Kaggle yarÄ±ÅŸmalarÄ±nda o kadar Ã¶nemli olmasa da, **gerÃ§ek dÃ¼nya projelerinde deÄŸerli olabilecek baÅŸka amaÃ§larÄ±** da vardÄ±r.
Birincisi, eÄŸitim verisinin boyutunu azaltmaktÄ±r (bu, Ã¶zellikle bellek sÄ±nÄ±rlamalarÄ± olan Kaggle Notebook ortamlarÄ±nda da faydalÄ± olabilir).
Ä°kincisi ise, sonuÃ§ modelinin **yorumlanabilirliÄŸini artÄ±rmaktÄ±r** â€” yani insanlar tarafÄ±ndan daha kolay anlaÅŸÄ±labilen Ã¶zellikler kullanmak.

Her alan, uzmanlarÄ± tarafÄ±ndan bilinen fakat kendiliÄŸinden fark edilmeyen belirli **deÄŸiÅŸken dÃ¶nÃ¼ÅŸÃ¼mlerine** sahip olabilir. Ã–rneÄŸin, finans alanÄ±nda, piyasa ve ÅŸirket verilerini temsil eden farklÄ± Ã¶zellik kÃ¼melerinde sinyali gÃ¼rÃ¼ltÃ¼den ayÄ±rmak iÃ§in **Kalman filtreleri** veya **dalgacÄ±k dÃ¶nÃ¼ÅŸÃ¼mleri (wavelet transformations)** gibi Ã¶zel dÃ¶nÃ¼ÅŸÃ¼mler uygulanÄ±r.

Ã‡ok sayÄ±da alan ve karmaÅŸÄ±k Ã¶zellik mÃ¼hendisliÄŸi yÃ¶ntemleri bulunduÄŸundan, bu bÃ¶lÃ¼mde belirli alanlara Ã¶zgÃ¼ tekniklere girmeyeceÄŸiz. Bunun yerine, **her tÃ¼rlÃ¼ tablo (tabular) verisi yarÄ±ÅŸmasÄ±nda uygulanabilecek en yaygÄ±n ve genel teknikleri** sunacaÄŸÄ±z.

#### Easily derived features *(Kolay tÃ¼retilen Ã¶zellikler)*

DÃ¶nÃ¼ÅŸÃ¼mler yoluyla Ã¶zellikler tÃ¼retmek, **en basit ama genellikle en etkili** yaklaÅŸÄ±mdÄ±r.
Ã–rneÄŸin, **Ã¶zellik oranlarÄ±nÄ±** (bir Ã¶zelliÄŸi diÄŸerine bÃ¶lmek) hesaplamak oldukÃ§a etkili olabilir, Ã§Ã¼nkÃ¼ birÃ§ok algoritma (Ã¶rneÄŸin *gradient boosting*) bu tÃ¼r bÃ¶lme iÅŸlemlerini doÄŸrudan taklit edemez veya (Ã¶rneÄŸin derin sinir aÄŸlarÄ± gibi) bunu yapmakta zorlanabilir.
Denemeye deÄŸer en yaygÄ±n dÃ¶nÃ¼ÅŸÃ¼mler aÅŸaÄŸÄ±da listelenmiÅŸtir:

---

* **Zaman Ã–zelliklerinin Ä°ÅŸlenmesi (Time Feature Processing):**

Bir tarihi bileÅŸenlerine (yÄ±l, ay, gÃ¼n) ayÄ±rmak; yÄ±lÄ± haftalara veya haftanÄ±n gÃ¼nlerine dÃ¶nÃ¼ÅŸtÃ¼rmek; tarihler arasÄ±ndaki farklarÄ± hesaplamak; Ã¶nemli olaylarla (Ã¶rneÄŸin tatillerle) olan farklarÄ± hesaplamak.

Tarihler iÃ§in baÅŸka bir yaygÄ±n dÃ¶nÃ¼ÅŸÃ¼m, bir tarih veya saatten zamanla ilgili bileÅŸenleri Ã§Ä±karmaktÄ±r.
ZamanÄ±n sÃ¼rekliliÄŸini temsil etmek ve **periyodik Ã¶zellikler** oluÅŸturmak iÃ§in **sinÃ¼s (sine)** ve **kosinÃ¼s (cosine)** tabanlÄ± dÃ¶ngÃ¼sel sÃ¼rekli dÃ¶nÃ¼ÅŸÃ¼mler de oldukÃ§a kullanÄ±ÅŸlÄ±dÄ±r:

```python
cycle = 7
df['weekday_sin'] = np.sin(2 * np.pi * df['col1'].dt.dayofweek / cycle)
df['weekday_cos'] = np.cos(2 * np.pi * df['col1'].dt.dayofweek / cycle)
```

---

* **SayÄ±sal Ã–zellik DÃ¶nÃ¼ÅŸÃ¼mleri (Numeric Feature Transformations):**

Ã–zelliklerin Ã¶lÃ§eklenmesi (scaling), normalizasyon, logaritmik veya Ã¼stel dÃ¶nÃ¼ÅŸÃ¼mler; tam sayÄ± ve ondalÄ±k kÄ±sÄ±mlarÄ±n ayrÄ±lmasÄ±; iki sayÄ±sal Ã¶zelliÄŸin toplanmasÄ±, Ã§Ä±karÄ±lmasÄ±, Ã§arpÄ±lmasÄ± veya bÃ¶lÃ¼nmesi gibi iÅŸlemler yapÄ±labilir.

SayÄ±sal Ã¶zelliklerin **standartlaÅŸtÄ±rma (z-score)** veya **normalizasyon (min-max scaling)** yoluyla Ã¶lÃ§eklenmesi, Ã¶zellikle **Ã¶lÃ§ek duyarlÄ± algoritmalar** (Ã¶rneÄŸin sinir aÄŸlarÄ±) kullanÄ±ldÄ±ÄŸÄ±nda mantÄ±klÄ± bir seÃ§imdir.

---

* **SayÄ±sal Ã–zelliklerin GruplandÄ±rÄ±lmasÄ± (Binning):**

Bu yÃ¶ntem, sÃ¼rekli deÄŸiÅŸkenleri belirli aralÄ±klara (bin) ayÄ±rarak **ayrÄ±k** hale getirmek iÃ§in kullanÄ±lÄ±r.
Binning, verideki gÃ¼rÃ¼ltÃ¼ ve hatalarÄ± azaltmaya yardÄ±mcÄ± olur ve **binned** Ã¶zellikler ile hedef deÄŸiÅŸken arasÄ±nda doÄŸrusal olmayan iliÅŸkilerin kolayca modellenmesini saÄŸlar. Ã–zellikle one-hot encoding ile birlikte kullanÄ±ldÄ±ÄŸÄ±nda etkilidir.
Ã–rnek olarak ÅŸu Scikit-learn uygulamasÄ±na bakÄ±labilir:
[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html)

---

* **Kategorik Ã–zellik Kodlama (Categorical Feature Encoding):**

One-hot encoding, iki veya Ã¼Ã§ kategorik Ã¶zelliÄŸin birleÅŸtirilmesi gibi iÅŸlemler ya da daha geliÅŸmiÅŸ **target encoding** yÃ¶ntemleri (ilerleyen bÃ¶lÃ¼mlerde anlatÄ±lacaktÄ±r) kullanÄ±labilir.

---

* **Kategorik Ã–zelliklerin AyrÄ±ÅŸtÄ±rÄ±lmasÄ± ve BirleÅŸtirilmesi:**

Ã–rneÄŸin, [Titanic yarÄ±ÅŸmasÄ±nda](https://www.kaggle.com/c/titanic), isimleri ve soyisimleri ayÄ±rmak veya baÅŸ harflerini (Ã¶rneÄŸin unvanlarÄ±) Ã§Ä±karmak yeni Ã¶zellikler oluÅŸturmak iÃ§in kullanÄ±labilir.

---

* **Polinomial Ã–zellikler (Polynomial Features):**

Mevcut Ã¶zelliklerin Ã¼sse yÃ¼kseltilmesiyle oluÅŸturulan yeni Ã¶zelliklerdir.
Ã–rneÄŸin Scikit-learnâ€™de ÅŸu fonksiyon kullanÄ±labilir:
[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)

---

* **Eksik Veriler ve AykÄ±rÄ± DeÄŸerlerin Ä°ÅŸlenmesi (Missing Data & Outlier Treatment):**

Bu iÅŸlemler teknik olarak doÄŸrudan Ã¶zellik mÃ¼hendisliÄŸi olmasa da, verideki sinyalleri daha gÃ¶rÃ¼nÃ¼r hale getirdikleri iÃ§in Ã¶zellikleri dÃ¶nÃ¼ÅŸtÃ¼rmenin bir parÃ§asÄ± sayÄ±labilir.

* **Eksik DeÄŸerlerin Ele AlÄ±nmasÄ±:**

Eksik deÄŸerleri belirten **ikili (binary) Ã¶zellikler** oluÅŸturmak yararlÄ±dÄ±r; Ã§Ã¼nkÃ¼ eksikliÄŸin kendisi rastgele olmayabilir ve Ã¶nemli bir nedeni olabilir.
Eksik veri, Ã§oÄŸu zaman verinin nasÄ±l toplandÄ±ÄŸÄ± hakkÄ±nda bilgi verir ve baÅŸka bir deÄŸiÅŸkenin **dolaylÄ± bir gÃ¶stergesi (proxy)** gibi davranabilir.

Ã–rneÄŸin, nÃ¼fus sayÄ±mÄ± anketlerinde bir kiÅŸi gelirini bildirmiyorsa, bu genellikle ya Ã§ok dÃ¼ÅŸÃ¼k ya da Ã§ok yÃ¼ksek gelire sahip olduÄŸunu ima eder.

Modelinizin gerektirmesi durumunda, eksik deÄŸerleri **ortalama (mean)**, **medyan (median)** veya **mod (mode)** ile doldurabilirsiniz.
Daha karmaÅŸÄ±k yÃ¶ntemlere genellikle gerek yoktur.

> Parul Pandey tarafÄ±ndan yazÄ±lmÄ±ÅŸ olan bu kapsamlÄ± rehbere baÅŸvurabilirsiniz ([https://www.kaggle.com/parulpandey](https://www.kaggle.com/parulpandey)):
ğŸ‘‰ [Eksik DeÄŸerlerle BaÅŸ Etme Rehberi â€“ Pythonâ€™da Eksik Verilerin Ä°ÅŸlenmesi](https://www.kaggle.com/parulpandey/a-guide-to-handling-missing-values-in-python).

UnutmayÄ±n ki bazÄ± modeller, **eksik deÄŸerleri kendi baÅŸlarÄ±na iÅŸleyebilir** ve bunu birÃ§ok standart yaklaÅŸÄ±mdan daha iyi yaparlar. Bunun nedeni, eksik deÄŸerlerin iÅŸlenmesinin bu modellerin **optimizasyon sÃ¼recinin bir parÃ§asÄ±** olmasÄ±dÄ±r.

Eksik deÄŸerleri kendi iÃ§inde ele alabilen modellerin tamamÄ± **gradient boosting** algoritmalarÄ±dÄ±r:

* **XGBoost:** [https://xgboost.readthedocs.io/en/latest/faq.html](https://xgboost.readthedocs.io/en/latest/faq.html)
* **LightGBM:** [https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html](https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html)
* **CatBoost:** [https://catboost.ai/docs/concepts/algorithm-missing-valuesprocessing.html](https://catboost.ai/docs/concepts/algorithm-missing-valuesprocessing.html)

---

* **AykÄ±rÄ± DeÄŸerlerin SÄ±nÄ±rlandÄ±rÄ±lmasÄ± veya KaldÄ±rÄ±lmasÄ± (Outlier Capping or Removal)**

AykÄ±rÄ± deÄŸerleri (outlier) veriden tamamen Ã§Ä±karmak, belirli bir **maksimum veya minimum deÄŸere sÄ±nÄ±rlandÄ±rmak**, ya da doÄŸrudan **deÄŸerlerini deÄŸiÅŸtirmek** mÃ¼mkÃ¼ndÃ¼r.
Bunu yapmak iÃ§in, **Scikit-learn** kÃ¼tÃ¼phanesinde yer alan Ã§ok deÄŸiÅŸkenli (multivariate) aykÄ±rÄ± deÄŸer tespit modelleri gibi geliÅŸmiÅŸ yÃ¶ntemleri kullanabilirsiniz:
ğŸ”— [https://scikit-learn.org/stable/modules/outlier_detection.html](https://scikit-learn.org/stable/modules/outlier_detection.html)

Daha basit bir yÃ¶ntem olarak, **tek deÄŸiÅŸkenli (univariate)** yaklaÅŸÄ±mlarla da aykÄ±rÄ± deÄŸerleri bulabilirsiniz.
Bunun iÃ§in, deÄŸerlerin ortalamadan **kaÃ§ standart sapma** uzakta olduÄŸuna veya **Ã§eyrekler arasÄ± aralÄ±k (IQR)** sÄ±nÄ±rlarÄ±ndan ne kadar uzak olduÄŸuna bakÄ±lÄ±r.

Bu durumda ÅŸu kurallar uygulanabilir:

* **Ãœst aykÄ±rÄ± deÄŸerler (upper outliers):** Q3 + 1.5 Ã— IQR deÄŸerinden bÃ¼yÃ¼k olan noktalar,
* **Alt aykÄ±rÄ± deÄŸerler (lower outliers):** Q1 â€“ 1.5 Ã— IQR deÄŸerinden kÃ¼Ã§Ã¼k olan noktalar.

AykÄ±rÄ± deÄŸerleri belirledikten sonra, bu gÃ¶zlemleri belirtmek iÃ§in **ikili (binary) bir deÄŸiÅŸken** de oluÅŸturabilirsiniz.

---

TÃ¼m bu veri dÃ¶nÃ¼ÅŸÃ¼mleri, modellerinizin **tahmin performansÄ±nÄ± artÄ±rabilir**, ancak yarÄ±ÅŸmalarda **tek baÅŸÄ±na belirleyici** olmazlar.
Bu iÅŸlemler gerekli olsa da, yalnÄ±zca temel Ã¶zellik mÃ¼hendisliÄŸine gÃ¼venemezsiniz.
Bir sonraki bÃ¶lÃ¼mlerde, verinizden **daha fazla deÄŸer Ã§Ä±karmak iÃ§in** daha karmaÅŸÄ±k yÃ¶ntemler ele alÄ±nacaktÄ±r.

#### Meta-features based on rows and columns *(SatÄ±r ve sÃ¼tunlara dayalÄ± meta-Ã¶zellikler)*

RekabetÃ§i bir performans elde edebilmek iÃ§in, **daha karmaÅŸÄ±k Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** tekniklerine ihtiyacÄ±nÄ±z vardÄ±r. BaÅŸlamak iÃ§in iyi bir nokta, **her satÄ±rÄ±n (Ã¶rneÄŸin her Ã¶rneÄŸin) kendi baÅŸÄ±na incelendiÄŸi Ã¶zellikleri** ele almaktÄ±r:

* SayÄ±sal deÄŸerlerin (veya bunlarÄ±n bir alt kÃ¼mesinin) **ortalamasÄ±nÄ±, medyanÄ±nÄ±, toplamÄ±nÄ±, standart sapmasÄ±nÄ±, minimum veya maksimumunu** hesaplayÄ±n.
* **Eksik deÄŸerlerin sayÄ±sÄ±nÄ±** belirleyin.
* SatÄ±rlarda bulunan yaygÄ±n deÄŸerlerin **frekanslarÄ±nÄ±** hesaplayÄ±n (Ã¶rneÄŸin ikili (binary) Ã¶zelliklerde pozitif deÄŸerlerin sayÄ±sÄ±nÄ±).
* Her satÄ±rÄ±, **k-means** gibi bir kÃ¼meleme (clustering) analizinden elde edilen bir kÃ¼meye atayÄ±n.

Bu tÃ¼rden Ã¶zelliklere **meta-Ã¶zellikler (meta-features)** denir; Ã§Ã¼nkÃ¼ bunlar, birden fazla Ã¶zelliÄŸi temsil eden Ã¶zet niteliklerdir. Meta-Ã¶zellikler, algoritmanÄ±zÄ±n veri kÃ¼menizdeki farklÄ± Ã¶rnek tÃ¼rlerini daha kolay ayÄ±rt etmesini saÄŸlar; Ã§Ã¼nkÃ¼ belirli Ã¶rnek gruplarÄ±nÄ± vurgular.

---

Meta-Ã¶zellikler yalnÄ±zca satÄ±rlara deÄŸil, **sÃ¼tunlara dayalÄ± olarak** da oluÅŸturulabilir.
Tek bir Ã¶zelliÄŸin Ã¼zerinde yapÄ±lan **toplama (aggregation)** ve **Ã¶zetleme (summarization)** iÅŸlemleri, sayÄ±sal veya kategorik deÄŸiÅŸkenlerin deÄŸeri hakkÄ±nda ek bilgi saÄŸlamayÄ± amaÃ§lar.
Yani, â€œbu Ã¶zellik deÄŸeri yaygÄ±n mÄ±, yoksa nadir mi?â€ gibi sorulara yanÄ±t verir.
Bu tÃ¼r bilgileri modeller doÄŸrudan Ã§Ä±karamaz; Ã§Ã¼nkÃ¼ bir kategorik deÄŸiÅŸkende deÄŸerlerin kaÃ§ kez tekrarlandÄ±ÄŸÄ±nÄ± â€œsaymaâ€ yeteneÄŸine sahip deÄŸildir.

---

Meta-Ã¶zellikler olarak, sÃ¼tunlara iliÅŸkin herhangi bir istatistiksel Ã¶lÃ§Ã¼yÃ¼ kullanabilirsiniz.
Bunlara Ã¶rnek olarak: **mod, ortalama, medyan, toplam, standart sapma, minimum, maksimum, Ã§arpÄ±klÄ±k (skewness)** ve **basÄ±klÄ±k (kurtosis)** sayÄ±labilir.

SÃ¼tun bazlÄ± meta-Ã¶zellikleri oluÅŸturmak iÃ§in birkaÃ§ farklÄ± yÃ¶ntem uygulanabilir:

---

* **Frekans Kodlama (Frequency Encoding):**

Bir kategorik Ã¶zelliÄŸin deÄŸerlerinin veri setinde kaÃ§ kez tekrarlandÄ±ÄŸÄ±nÄ± sayÄ±n ve bu frekansla orijinal deÄŸeri deÄŸiÅŸtirerek yeni bir Ã¶zellik oluÅŸturun.
AyrÄ±ca, belirli sayÄ±sal deÄŸerlerin sÄ±klÄ±kla tekrarlandÄ±ÄŸÄ± durumlarda **sayÄ±sal Ã¶zelliklere** de frekans kodlama uygulanabilir.

---

* **Gruplara GÃ¶re Frekans ve SÃ¼tun Ä°statistikleri:**

Bu yÃ¶ntemde, verideki farklÄ± **gruplar** dikkate alÄ±narak yeni Ã¶zellikler oluÅŸturulur.
Gruplar, kÃ¼meleme analiziyle (Ã¶rneÄŸin k-means) oluÅŸturulabilir veya doÄŸrudan bir Ã¶zellik Ã¼zerinden tanÄ±mlanabilir (Ã¶rneÄŸin yaÅŸa gÃ¶re yaÅŸ gruplarÄ±, konuma gÃ¶re bÃ¶lgeler vb.).

Her grubun tanÄ±mlayÄ±cÄ± meta-Ã¶zellikleri, o gruba ait Ã¶rneklere atanÄ±r.
Bunu yapmak iÃ§in **Pandas `groupby`** fonksiyonu kullanÄ±labilir:
Bu fonksiyonla grup bazlÄ± istatistikler hesaplanÄ±r ve daha sonra **gruplama deÄŸiÅŸkenine gÃ¶re** orijinal veriye eklenir.

Bu yÃ¶ntemdeki en zor kÄ±sÄ±m, veride **anlamlÄ± gruplar** bulmaktÄ±r.

---

* **GruplarÄ±n BirleÅŸtirilmesiyle Ek Frekans ve Ä°statistikler:**

Birden fazla grubu birleÅŸtirerek ek sÃ¼tun istatistikleri veya frekanslar tÃ¼retmek mÃ¼mkÃ¼ndÃ¼r.

---

Bu liste elbette tÃ¼m yÃ¶ntemleri kapsamÄ±yor; ancak size, **Ã¶zellik dÃ¼zeyinde** ve **satÄ±r dÃ¼zeyinde** frekanslar ve istatistikler kullanarak yeni Ã¶zellikler tÃ¼retmenin yollarÄ± hakkÄ±nda bir fikir verir.

---

* **Basit Bir Uygulama Ã–rneÄŸi: Amazon Employee Access Challenge**

AÅŸaÄŸÄ±da, **ROLE_TITLE** Ã¶zelliÄŸine frekans kodlamasÄ± uygulanan bir Ã¶rnek verilmiÅŸtir:

```python
import pandas as pd
train = pd.read_csv("../input/amazon-employee-access-challenge/train.csv")

# Bir Ã¶zelliÄŸin frekans sayÄ±mÄ±
feature_counts = train.groupby('ROLE_TITLE').size()
print(train['ROLE_TITLE'].apply(lambda x: feature_counts[x]))
```

Bu iÅŸlemin sonucunda, **ROLE_TITLE** deÄŸiÅŸkenindeki sÄ±nÄ±flar, veri setinde gÃ¶rÃ¼lme sÄ±klÄ±klarÄ±yla (frekanslarÄ±yla) deÄŸiÅŸtirilmiÅŸ olur.

Åimdi ise, **ROLE_TITLE** Ã¶zelliÄŸini **ROLE_DEPTNAME** (departman adÄ±) deÄŸiÅŸkeniyle gruplayarak kodlayacaÄŸÄ±z; Ã§Ã¼nkÃ¼ farklÄ± unvanlarÄ±n bazÄ± departmanlarda daha yaygÄ±n, bazÄ±larÄ±nda ise daha nadir olabileceÄŸini varsayÄ±yoruz.

SonuÃ§ olarak, her iki Ã¶zelliÄŸi (departman ve unvan) birleÅŸtirerek yeni bir Ã¶zellik oluÅŸturuyoruz ve bu birleÅŸik deÄŸerin frekansÄ±nÄ± hesaplÄ±yoruz:

```python
feature_counts = train.groupby(['ROLE_DEPTNAME', 'ROLE_TITLE']).size()
print(train[['ROLE_DEPTNAME', 'ROLE_TITLE']].apply(lambda x: feature_counts[x[0]][x[1]], axis=1))
```

Bu ÅŸekilde, verideki gruplarÄ±n ve kategorilerin birbiriyle iliÅŸkisini yansÄ±tan **daha bilgilendirici yeni Ã¶zellikler** elde edilmiÅŸ olur.

TÃ¼m Ã§alÄ±ÅŸan kodlarÄ± ve sonuÃ§larÄ± bu Kaggle Notebookâ€™ta bulabilirsiniz:
ğŸ‘‰ [https://www.kaggle.com/lucamassaron/meta-features-and-target-encoding/](https://www.kaggle.com/lucamassaron/meta-features-and-target-encoding/)

#### Target encoding *(Hedef kodlama)*

Kategorik Ã¶zelliklerle Ã§alÄ±ÅŸmak genellikle zorlayÄ±cÄ± deÄŸildir, Ã§Ã¼nkÃ¼ Scikit-learn tarafÄ±ndan sunulan bazÄ± basit fonksiyonlar bu iÅŸlemi kolaylaÅŸtÄ±rÄ±r:

* **LabelEncoder**
* **OneHotEncoder**
* **OrdinalEncoder**

Bu fonksiyonlar, kategorileri sayÄ±sal Ã¶zelliklere ve ardÄ±ndan ikili (binary) Ã¶zelliklere dÃ¶nÃ¼ÅŸtÃ¼rerek makine Ã¶ÄŸrenimi algoritmalarÄ±nÄ±n bunlarÄ± kolayca iÅŸlemesini saÄŸlar.
Ancak, eÄŸer kategorilerin sayÄ±sÄ± Ã§ok fazlaysa, **one-hot encoding** stratejisiyle oluÅŸturulan veri kÃ¼mesi seyrek (sparse) hale gelir (yani Ã§oÄŸu deÄŸer sÄ±fÄ±r olur) ve bu durum bilgisayarÄ±nÄ±zÄ±n veya Notebookâ€™un belleÄŸi ve iÅŸlemcisi aÃ§Ä±sÄ±ndan yÃ¶netilmesi zor bir hale gelir.
Bu tÃ¼r durumlarda, **yÃ¼ksek kardinaliteli Ã¶zellik (high-cardinality feature)** olarak adlandÄ±rÄ±lan bir Ã¶zellikten bahsederiz ve bu tÃ¼r veriler Ã¶zel bir ÅŸekilde ele alÄ±nmalÄ±dÄ±r.

Kaggle yarÄ±ÅŸmalarÄ±nÄ±n erken dÃ¶nemlerinden beri, yÃ¼ksek kardinaliteli deÄŸiÅŸkenler genellikle **Micci-Barreca (2001)** tarafÄ±ndan Ã¶nerilen bir kodlama yÃ¶ntemi kullanÄ±larak iÅŸlenmiÅŸtir:

> Micci-Barreca, D. *A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems.*
> *ACM SIGKDD Explorations Newsletter 3.1 (2001): 27â€“32.*

Bu yaklaÅŸÄ±mÄ±n temel fikri, kategorik bir Ã¶zelliÄŸin sahip olduÄŸu birÃ§ok kategoriyi, o kategoriye karÅŸÄ±lÄ±k gelen beklenen hedef (target) deÄŸeriyle dÃ¶nÃ¼ÅŸtÃ¼rmektir.

* Regresyon durumunda, bu kategoriye ait **ortalama beklenen deÄŸer**,
* Ä°kili sÄ±nÄ±flandÄ±rmada (binary classification), **koÅŸullu olasÄ±lÄ±k (conditional probability)**,
* Ã‡ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rmada (multiclass classification) ise **her olasÄ± sonuÃ§ iÃ§in koÅŸullu olasÄ±lÄ±k** kullanÄ±lÄ±r.

Ã–rneÄŸin, **Titanic GettingStarted** yarÄ±ÅŸmasÄ±nda ([https://www.kaggle.com/competitions/titanic](https://www.kaggle.com/competitions/titanic)), her yolcunun hayatta kalma olasÄ±lÄ±ÄŸÄ±nÄ± tahmin etmeniz gerekir.
Bu durumda, **gender (cinsiyet)** gibi bir kategorik Ã¶zelliÄŸe hedef kodlama (target encoding) uygulamak, cinsiyet deÄŸerini o cinsiyetin ortalama hayatta kalma olasÄ±lÄ±ÄŸÄ±yla deÄŸiÅŸtirmek anlamÄ±na gelir.

Bu yÃ¶ntemle, kategorik Ã¶zellik, veriyi bÃ¼yÃ¼tmeden veya seyrekleÅŸtirmeden sayÄ±sal bir Ã¶zelliÄŸe dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ olur.
KÄ±saca, **hedef kodlama (target encoding)** budur â€” ve birÃ§ok durumda oldukÃ§a etkilidir, Ã§Ã¼nkÃ¼ yÃ¼ksek kardinaliteli Ã¶zelliklere dayalÄ± bir â€œtahminâ€ mantÄ±ÄŸÄ±na benzer ÅŸekilde Ã§alÄ±ÅŸÄ±r.

Ancak, **stacked prediction** (yani baÅŸka bir modelin tahminini bir Ã¶zellik olarak kullanma) yaklaÅŸÄ±mÄ±na benzer ÅŸekilde, hedef kodlama da **aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting)** riski taÅŸÄ±r.
BazÄ± kategoriler Ã§ok nadirse, hedef kodlama neredeyse hedef etiketin doÄŸrudan verilmesiyle eÅŸdeÄŸer hale gelir.
Bu riski Ã¶nlemenin yollarÄ± vardÄ±r.

UygulamanÄ±za doÄŸrudan dahil edebileceÄŸiniz implementasyonu gÃ¶rmeden Ã¶nce, **hedef kodlama (target encoding)** iÃ§in kullanÄ±lan gerÃ§ek bir Ã¶rneÄŸe bakalÄ±m.
AÅŸaÄŸÄ±daki kod, **PetFinder.my Adoption Prediction** yarÄ±ÅŸmasÄ±nda en yÃ¼ksek puanlÄ± gÃ¶nderimlerden birinde kullanÄ±lmÄ±ÅŸtÄ±r:

```python
import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator, TransformerMixin

class TargetEncode(BaseEstimator, TransformerMixin):
    
    def __init__(self, categories='auto', k=1, f=1, noise_level=0, random_state=None):
        if type(categories) == str and categories != 'auto':
            self.categories = [categories]
        else:
            self.categories = categories
        self.k = k
        self.f = f
        self.noise_level = noise_level
        self.encodings = dict()
        self.prior = None
        self.random_state = random_state
        
    def add_noise(self, series, noise_level):
        return series * (1 + noise_level * np.random.randn(len(series)))
```

Fonksiyonun **girdi parametreleri** ÅŸunlardÄ±r:

* **categories:** Hedef kodlama (target encoding) uygulamak istediÄŸiniz sÃ¼tun adlarÄ±. `'auto'` olarak bÄ±rakÄ±lÄ±rsa, sÄ±nÄ±f otomatik olarak string tipindeki sÃ¼tunlarÄ± seÃ§er.
* **k (int):** Bir kategorinin ortalamasÄ±nÄ±n dikkate alÄ±nabilmesi iÃ§in gereken minimum Ã¶rnek sayÄ±sÄ±.
* **f (int):** Kategori ortalamasÄ± ile genel ortalama (prior probability) arasÄ±ndaki **dengelenme (smoothing)** miktarÄ±nÄ± belirler.
* **noise_level:** AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in hedef kodlamaya eklenecek **gÃ¼rÃ¼ltÃ¼ (noise)** miktarÄ±. KÃ¼Ã§Ã¼k deÄŸerlerle baÅŸlamak gerekir.
* **random_state:** GÃ¼rÃ¼ltÃ¼ seviyesi sÄ±fÄ±rdan bÃ¼yÃ¼k olduÄŸunda aynÄ± kodlamayÄ± yeniden Ã¼retebilmek iÃ§in rastgelelik tohumu (seed).

Burada dikkat edilmesi gereken, **k** ve **f** parametrelerinin varlÄ±ÄŸÄ±dÄ±r.
Bir kategorik Ã¶zelliÄŸin bir seviyesi iÃ§in (Ã¶rneÄŸin bir ÅŸehir, bir Ã¼rÃ¼n tÃ¼rÃ¼ vb.), hedefi tahmin etmede yardÄ±mcÄ± olabilecek yaklaÅŸÄ±k bir deÄŸer arÄ±yoruz.
Bu seviyeyi doÄŸrudan gÃ¶zlenen koÅŸullu olasÄ±lÄ±kla deÄŸiÅŸtirmek bir Ã§Ã¶zÃ¼m olabilir, ancak az gÃ¶zlemli seviyelerde iyi Ã§alÄ±ÅŸmaz.

Ã‡Ã¶zÃ¼m, **empirik Bayes yaklaÅŸÄ±mÄ± (empirical Bayesian approach)** kullanmaktÄ±r â€” yani, o seviyedeki gÃ¶zlenen koÅŸullu olasÄ±lÄ±ÄŸÄ± (posterior) tÃ¼m Ã¶rnekler Ã¼zerindeki genel olasÄ±lÄ±kla (prior) birleÅŸtiririz.
Bu karÄ±ÅŸÄ±mÄ± belirleyen faktÃ¶r **lambda**â€™dÄ±r.

Pratikte, her kategori seviyesi iÃ§in ÅŸu soruya cevap veririz:

> â€œKoÅŸullu hedef deÄŸerini mi, genel ortalamayÄ± mÄ±, yoksa ikisinin karÄ±ÅŸÄ±mÄ±nÄ± mÄ± kullanmalÄ±yÄ±z?â€

Bu dengeyi belirleyen ÅŸey **f parametresidir**, ve **k parametresi** (genellikle 1 veya 2 gibi kÃ¼Ã§Ã¼k deÄŸerler) minimum gÃ¶zlem sayÄ±sÄ±nÄ± ifade eder.

![](im/1059.png)

Grafikte gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi, x ekseni belirli bir kategorik seviyedeki Ã¶rnek sayÄ±sÄ±nÄ±, y ekseni ise koÅŸullu hedef deÄŸerinin aÄŸÄ±rlÄ±ÄŸÄ±nÄ± temsil etmektedir. KÃ¼Ã§Ã¼k **f** deÄŸerleri, ortalama hedef deÄŸerini kullanmaktan koÅŸullu deÄŸeri kullanmaya ani bir ÅŸekilde geÃ§meye eÄŸilimlidir. Daha yÃ¼ksek **f** deÄŸerleri ise, Ã¶rnek sayÄ±sÄ± bÃ¼yÃ¼k olmayan seviyeler dÄ±ÅŸÄ±nda, koÅŸullu deÄŸeri ortalama ile harmanlamaya meyillidir.

DolayÄ±sÄ±yla, sabit bir **k** iÃ§in, yÃ¼ksek **f** deÄŸerleri gÃ¶zlenen empirik frekansa daha az gÃ¼venmeyi ve tÃ¼m hÃ¼creler iÃ§in empirik olasÄ±lÄ±ÄŸa daha fazla dayanmayÄ± ifade eder. **f** iÃ§in doÄŸru deÄŸer genellikle deneme-yanÄ±lma yoluyla (cross-validation ile desteklenmiÅŸ) bulunur, Ã§Ã¼nkÃ¼ **f** parametresi kendi baÅŸÄ±na bir hiperparametre olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.

TÃ¼m bu aÃ§Ä±klamalardan sonra, sÄ±nÄ±fÄ±n kullanÄ±mÄ± aslÄ±nda oldukÃ§a basittir. Target encoding uygulamak istediÄŸiniz Ã¶zelliklerin adlarÄ±nÄ± ve denemek istediÄŸiniz parametreleri belirterek sÄ±nÄ±fÄ± baÅŸlatabilir ve eÄŸitim verisine fit edebilirsiniz. ArdÄ±ndan, yalnÄ±zca fit edilen Ã¶zellikleri target encoding uygulayarak baÅŸka herhangi bir veri Ã¼zerinde dÃ¶nÃ¼ÅŸÃ¼m yapabilirsiniz:

```python
te = TargetEncode(categories='ROLE_TITLE')
te.fit(train, train['ACTION'])
te.transform(train[['ROLE_TITLE']])
```

Bu Ã¶rnek, daha Ã¶nce kullandÄ±ÄŸÄ±mÄ±z **Amazon Employee Access Challenge** verisi Ã¼zerinde Ã§alÄ±ÅŸÄ±r ve yalnÄ±zca **ROLE_TITLE** Ã¶zelliÄŸini hedef kodlar.

> Kendi kodunuzu yazmak yerine, [scikit-learn-contrib/category_encoders](https://github.com/scikit-learn-contrib/category_encoders) paketindeki **TargetEncoder**â€™Ä± da kullanabilirsiniz ([TargetEncoder dokÃ¼mantasyonu](http://contrib.scikit-learn.org/category_encoders/targetencoder.html)). Bu paket, bu bÃ¶lÃ¼mdeki kodla aynÄ± ÅŸekilde Ã§alÄ±ÅŸÄ±r ve kutudan Ã§Ä±ktÄ±ÄŸÄ± haliyle kullanÄ±labilir.

### Using feature importance to evaluate your work *(Ã–zellik Ã¶nemini kullanarak Ã§alÄ±ÅŸmanÄ± deÄŸerlendirme)*

AÅŸÄ±rÄ± Ã¶zellik mÃ¼hendisliÄŸi uygulamanÄ±n yan etkileri olabilir. EÄŸer Ã§ok fazla korelasyonlu Ã¶zellik veya problem iÃ§in Ã¶nemsiz Ã¶zellikler oluÅŸturursanÄ±z, modellerin eÄŸitimi Ã§ok uzun sÃ¼rebilir ve sonuÃ§larÄ±nÄ±z kÃ¶tÃ¼leÅŸebilir. Bu, paradoks gibi gÃ¶rÃ¼nse de, her deÄŸiÅŸkenin Ã¶lÃ§Ã¼m veya kayÄ±t hatalarÄ±ndan kaynaklanan bazÄ± rastgele bileÅŸenler (gÃ¼rÃ¼ltÃ¼) taÅŸÄ±masÄ±yla aÃ§Ä±klanÄ±r. Model, yanlÄ±ÅŸlÄ±kla bu gÃ¼rÃ¼ltÃ¼yÃ¼ sinyal olarak algÄ±layabilir: kullandÄ±ÄŸÄ±nÄ±z deÄŸiÅŸken sayÄ±sÄ± arttÄ±kÃ§a, modelin gÃ¼rÃ¼ltÃ¼yÃ¼ sinyal yerine yakalama olasÄ±lÄ±ÄŸÄ± da artar. Bu nedenle, yalnÄ±zca eÄŸitim iÃ§in kullandÄ±ÄŸÄ±nÄ±z veri setinde ilgili Ã¶zellikleri tutmaya Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z; Ã¶zellik seÃ§imini, Ã¶zellik mÃ¼hendisliÄŸi sÃ¼recinizin bir parÃ§asÄ± olarak dÃ¼ÅŸÃ¼nÃ¼n (budama aÅŸamasÄ±).

Hangi Ã¶zellikleri tutmanÄ±z gerektiÄŸini belirlemek zor bir problemdir Ã§Ã¼nkÃ¼ mevcut Ã¶zellik sayÄ±sÄ± arttÄ±kÃ§a, olasÄ± kombinasyonlarÄ±n sayÄ±sÄ± da artar. Ã–zellik seÃ§menin Ã§eÅŸitli yollarÄ± vardÄ±r, ancak Ã¶ncelikle seÃ§im iÅŸleminin veri hazÄ±rlama hattÄ±nÄ±zÄ±n hangi aÅŸamasÄ±nda yapÄ±lmasÄ± gerektiÄŸini dÃ¼ÅŸÃ¼nmek Ã¶nemlidir.

Deneyimlerimize dayanarak, Ã¶zellik seÃ§imini veri hazÄ±rlama hattÄ±nÄ±zÄ±n sonunda yapmanÄ±zÄ± Ã¶neririz. Ã–zellikler, varyanslarÄ±nÄ±n bir kÄ±smÄ±nÄ± diÄŸer Ã¶zelliklerle paylaÅŸÄ±r, bu nedenle bunlarÄ±n etkinliÄŸini tek tek test ederek deÄŸerlendiremezsiniz; doÄŸru bir ÅŸekilde hangi Ã¶zellikleri kullanmanÄ±z gerektiÄŸini belirlemek iÃ§in hepsini birlikte deÄŸerlendirmelisiniz.

AyrÄ±ca, seÃ§tiÄŸiniz Ã¶zelliklerin etkinliÄŸini Ã§apraz doÄŸrulama (cross-validation) ile test etmelisiniz. Bu nedenle, tÃ¼m Ã¶zellikleri hazÄ±rladÄ±ktan ve tutarlÄ± bir pipeline ile Ã§alÄ±ÅŸan bir modeliniz (tam optimize edilmiÅŸ olmasÄ± gerekmez, ancak dÃ¼zgÃ¼n Ã§alÄ±ÅŸmalÄ± ve yarÄ±ÅŸma iÃ§in kabul edilebilir sonuÃ§lar vermelidir) olduktan sonra, hangi Ã¶zelliklerin tutulacaÄŸÄ±nÄ± ve hangi Ã¶zelliklerin Ã§Ä±karÄ±labileceÄŸini test etmeye hazÄ±rsÄ±nÄ±z. Bu noktada, Ã¶zellik seÃ§imi iÃ§in Ã§eÅŸitli yollar vardÄ±r:

* Ä°statistikte kullanÄ±lan klasik yaklaÅŸÄ±mlar, her bir Ã¶zelliÄŸi tahmin edici setine ekleyerek veya Ã§Ä±kararak test eden ileri ekleme (forward addition) veya geri eleme (backward elimination) yÃ¶ntemlerine baÅŸvurur. Bu yaklaÅŸÄ±m oldukÃ§a zaman alÄ±cÄ± olabilir Ã§Ã¼nkÃ¼ her adÄ±mda her Ã¶zellik iÃ§in deÄŸiÅŸkenlerin iÃ§ Ã¶nemini veya modelin performansÄ±na olan etkisini belirlemek iÃ§in bir Ã¶lÃ§Ã¼m yeniden hesaplanmak zorundadÄ±r.
* Regresyon modelleri iÃ§in, lasso seÃ§imi kullanmak, tÃ¼m Ã¶nemli ve yinelemeli (korelasyonlu) Ã¶zellikler hakkÄ±nda ipucu verebilir (bu yÃ¶ntem aslÄ±nda yÃ¼ksek korelasyonlu Ã¶zellikleri bile tutabilir) ve stabilite seÃ§imi (stability selection) prosedÃ¼rÃ¼nÃ¼ kullanÄ±r. Stabilite seÃ§iminde, hangi Ã¶zelliklerin tutulmasÄ± gerektiÄŸini birden fazla kez test edersiniz (bagging prosedÃ¼rÃ¼ kullanarak) â€“ her testte katsayÄ±larÄ± sÄ±fÄ±r olmayan Ã¶zellikleri dikkate alÄ±rsÄ±nÄ±z â€“ ve ardÄ±ndan en sÄ±k sÄ±fÄ±r olmayan katsayÄ±ya sahip olanlarÄ± tutmak iÃ§in bir oylama sistemi uygularsÄ±nÄ±z.

> Ä°ÅŸlemle ilgili daha fazla detayÄ± bu depoda bulabilirsiniz: [https://github.com/scikit-learn-contrib/stability-selection](https://github.com/scikit-learn-contrib/stability-selection).

* AÄŸaÃ§ tabanlÄ± modeller iÃ§in, Ã¶rneÄŸin rastgele ormanlar (random forests) veya gradient boosting gibi modellerde, Ã¶zellikleri sÄ±ralamanÄ±n yaygÄ±n yollarÄ±, bÃ¶lÃ¼nmelere dayalÄ± saflÄ±k azalmasÄ± veya hedef metriÄŸindeki kazanÃ§tÄ±r. Bir eÅŸik deÄŸeri en az Ã¶nemli Ã¶zellikleri elemek iÃ§in kullanÄ±labilir.
* Yine aÄŸaÃ§ tabanlÄ± modeller iÃ§in, ancak diÄŸer modellere kolayca genellenebilir ÅŸekilde, test tabanlÄ± Ã¶zellik rastgeleleÅŸtirmesi (veya basitÃ§e rastgele Ã¶zelliklerle karÅŸÄ±laÅŸtÄ±rmalar) modelin doÄŸru tahmin yapmasÄ±na gerÃ§ekten yardÄ±mcÄ± olan Ã¶zellikleri, yalnÄ±zca gÃ¼rÃ¼ltÃ¼ veya gereksiz olanlardan ayÄ±rmaya yardÄ±mcÄ± olur.

Ã–zellikleri rastgeleleÅŸtirmenin Ã¶nemli Ã¶zellikleri seÃ§mede nasÄ±l yardÄ±mcÄ± olduÄŸunu gÃ¶steren bir Ã¶rnek, Chris Deotte tarafÄ±ndan Ventilator Pressure Prediction yarÄ±ÅŸmasÄ±nda sunulmuÅŸtur: [https://www.kaggle.com/cdeotte/lstm-feature-importance](https://www.kaggle.com/cdeotte/lstm-feature-importance). Bu Notebook, LSTM tabanlÄ± bir sinir aÄŸÄ±nda Ã¶zelliklerin rolÃ¼nÃ¼ test eder. Ä°lk olarak, model oluÅŸturulur ve temel performans kaydedilir. Daha sonra, Ã¶zellikler tek tek karÄ±ÅŸtÄ±rÄ±lÄ±r ve model tekrar tahmin yapmak zorunda bÄ±rakÄ±lÄ±r. EÄŸer tahmin performansÄ± kÃ¶tÃ¼leÅŸirse, bu, Ã¶nemli bir Ã¶zelliÄŸi karÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±z ve dokunulmamasÄ± gerektiÄŸini gÃ¶sterir. EÄŸer performans aynÄ± kalÄ±r veya artarsa, karÄ±ÅŸtÄ±rÄ±lan Ã¶zellik model iÃ§in etkili deÄŸildir veya hatta zararlÄ± olabilir.

> Ã–zellik Ã¶neminin deÄŸerlendirilmesinde â€œNo Free Lunchâ€ prensibi geÃ§erlidir. KarÄ±ÅŸtÄ±rma iÅŸlemi yeniden eÄŸitim gerektirmez; bu, yeni bir modelin eÄŸitiminin zaman aldÄ±ÄŸÄ± durumlarda bÃ¼yÃ¼k bir avantajdÄ±r. Ancak bazÄ± durumlarda baÅŸarÄ±sÄ±z olabilir. KarÄ±ÅŸtÄ±rma, bazen deÄŸerlendirilmesi mantÄ±ksÄ±z olan gerÃ§ekÃ§i olmayan giriÅŸ kombinasyonlarÄ± oluÅŸturabilir. DiÄŸer durumlarda, yÃ¼ksek korelasyonlu Ã¶zelliklerin varlÄ±ÄŸÄ± tarafÄ±ndan yanÄ±ltÄ±labilir (birinin Ã¶nemli, diÄŸerinin Ã¶nemsiz olduÄŸunu yanlÄ±ÅŸ deÄŸerlendirebilir). Bu durumda, Ã¶zelliÄŸi karÄ±ÅŸtÄ±rmak yerine kaldÄ±rmak, modeli yeniden eÄŸitmek ve performansÄ±nÄ± temel deÄŸerle karÅŸÄ±laÅŸtÄ±rmak en iyi Ã§Ã¶zÃ¼mdÃ¼r.

KarÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ Ã¶zelliklere dayanan baÅŸka bir yaklaÅŸÄ±ma Boruta Ã¶rnek verilebilir ([https://github.com/scikit-learn-contrib/boruta_py](https://github.com/scikit-learn-contrib/boruta_py)). Boruta, modelin geÃ§erliliÄŸini yinelemeli olarak test etmek iÃ§in rastgele Ã¶zellikler kullanÄ±r. Boruta seÃ§me prosedÃ¼rÃ¼nÃ¼n alternatif bir versiyonu olan BorutaShap ([https://github.com/Ekeany/Boruta-Shap](https://github.com/Ekeany/Boruta-Shap)), SHAP deÄŸerlerini kullanarak hem Ã¶zellik seÃ§imi hem de aÃ§Ä±klanabilirlik saÄŸlar. Elde edilen seÃ§im genellikle basit kaldÄ±rma veya rastgeleleÅŸtirme turlarÄ±ndan daha gÃ¼venilirdir, Ã§Ã¼nkÃ¼ Ã¶zellikler, Ã¶nemlerini istatistiksel olarak kanÄ±tlayana kadar rastgele Ã¶zelliklere karÅŸÄ± birden fazla kez test edilir. Boruta veya BorutaShap 100 iterasyona kadar sÃ¼rebilir ve yalnÄ±zca aÄŸaÃ§ tabanlÄ± makine Ã¶ÄŸrenimi algoritmalarÄ±yla gerÃ§ekleÅŸtirilebilir.

DoÄŸrusal model iÃ§in Ã¶zellik seÃ§iyorsanÄ±z, Boruta aslÄ±nda aÅŸÄ±rÄ±ya kaÃ§abilir. Ã‡Ã¼nkÃ¼ hem ana etkiler hem de diÄŸer Ã¶zelliklerle olan etkileÅŸimler aÃ§Ä±sÄ±ndan Ã¶zellikleri Ã¶nemli kabul eder (doÄŸrusal modelde yalnÄ±zca ana etkiler ve seÃ§ilmiÅŸ bir alt kÃ¼me etkileÅŸimler Ã¶nemlidir). Yine de Borutaâ€™yÄ± doÄŸrusal model seÃ§imi iÃ§in etkili ÅŸekilde kullanabilirsiniz; bunun iÃ§in maksimum derinliÄŸi bir aÄŸaÃ§ olarak ayarlanmÄ±ÅŸ bir gradient boosting kullanarak yalnÄ±zca Ã¶zelliklerin ana etkilerini dikkate alÄ±rsÄ±nÄ±z, etkileÅŸimlerini deÄŸil.

BorutaShap ile Ã¶zellik seÃ§iminin ne kadar basit ve hÄ±zlÄ± kurulduÄŸunu gÃ¶rmek iÃ§in, 30 Days of ML yarÄ±ÅŸmasÄ±nda sunulan bu tutorial Notebookâ€™a gÃ¶z atabilirsiniz: [https://www.kaggle.com/lucamassaron/tutorial-feature-selection-with-boruta-shap](https://www.kaggle.com/lucamassaron/tutorial-feature-selection-with-boruta-shap).

> Bojan Tunguz
> 
> [https://www.kaggle.com/tunguz](https://www.kaggle.com/tunguz)
> 
> 
> 
> Bojan Tunguz, kesinlikle Ã¶zellik mÃ¼hendisliÄŸinin Ã¶nemini iyi anlayan bir Kaggle yarÄ±ÅŸmacÄ±sÄ±dÄ±r (ve ayrÄ±ca XGBoostâ€™un bÃ¼yÃ¼k bir hayranÄ±dÄ±r). NVIDIAâ€™da Makine Ã–ÄŸrenimi Modelleyicisi olarak edindiÄŸi deneyimlerini ve etkileyici ÅŸekilde Kaggleâ€™da DÃ¶rt Kat Grandmaster unvanÄ±nÄ± konuÅŸmak iÃ§in kendisiyle sohbet etmek istedik.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknik ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Her tÃ¼rlÃ¼ kodsuz yarÄ±ÅŸmayÄ± seviyorum. Bu yÄ±llar iÃ§inde Ã§ok deÄŸiÅŸti. Eskiden gÃ¶rÃ¼ntÃ¼ yarÄ±ÅŸmalarÄ±na Ã§ok ilgiliydim, ancak bu yarÄ±ÅŸmalarda rekabetÃ§i olabilmek iÃ§in gereken mÃ¼hendislik yÄ±ÄŸÄ±nÄ± yÄ±llar iÃ§inde inanÄ±lmaz derecede karmaÅŸÄ±k hale geldi. Bir sÃ¼re NLP yarÄ±ÅŸmalarÄ±na da ilgim vardÄ±, ama bunlar Kaggleâ€™da her zaman nadir olmuÅŸtur. Ancak yÄ±llar boyunca deÄŸiÅŸmeyen tek ÅŸey, tablo (tabular) veri problemlerine olan ilgim oldu. Bu problemler eskiden tipik Kaggle yarÄ±ÅŸma problemleriydi ama ne yazÄ±k ki artÄ±k neredeyse yok oldular. HÃ¢lÃ¢ bu alanla Ã§ok ilgileniyorum ve bu alanda bazÄ± temel araÅŸtÄ±rmalar yapmaya baÅŸladÄ±m. ML/DLâ€™nin diÄŸer alanlarÄ±na kÄ±yasla tablo verilerinde makine Ã¶ÄŸrenimini geliÅŸtirme konusunda Ã§ok az ilerleme kaydedildi ve burada bÃ¼yÃ¼k fÄ±rsatlar olduÄŸuna inanÄ±yorum.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizle ne kadar farklÄ±?**
> 
> Kaggleâ€™Ä±n oyun yÃ¶nÃ¼nÃ¼ her zaman ciddiye aldÄ±m. Bu benim iÃ§in, yeni Kaggle yarÄ±ÅŸmalarÄ±na genellikle Ã§ok eÄŸlenceli bir ÅŸekilde baÅŸlamam anlamÄ±na geliyor â€“ basit Ã§Ã¶zÃ¼mler, esprili Ã§Ã¶zÃ¼mler, diÄŸer oyunculardan modifiye edilmiÅŸ Ã§Ã¶zÃ¼mler, karÄ±ÅŸÄ±mlar vb. Bu yÃ¶ntemler, problemi anlamama, hangi tÃ¼r Ã§Ã¶zÃ¼mlerin iÅŸe yaradÄ±ÄŸÄ±nÄ± gÃ¶rmeme ve birkaÃ§ basit hile ile ne kadar ilerleyebileceÄŸimi test etmeme yardÄ±mcÄ± oluyor. Bunun bir kÄ±smÄ± gÃ¼nlÃ¼k modelleme Ã§alÄ±ÅŸmalarÄ±mda da geÃ§erli, ama orada eksik olan Ã¶nemli bir unsur var â€“ o da topluluktan ve lider tablodan gelen destek ve geri bildirim. Kendi baÅŸÄ±nÄ±za veya kÃ¼Ã§Ã¼k bir ekiple Ã§alÄ±ÅŸÄ±rken, oluÅŸturduÄŸunuz Ã§Ã¶zÃ¼mÃ¼n en iyi olup olmadÄ±ÄŸÄ±nÄ± veya daha iyi bir Ã§Ã¶zÃ¼mÃ¼n mÃ¼mkÃ¼n olup olmadÄ±ÄŸÄ±nÄ± asla bilemezsiniz.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu gÃ¶revi nasÄ±l Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼zden bahseder misiniz?**
> 
> Kaggle kariyerimdeki en zor ve en Ã¶nemli yarÄ±ÅŸma, Home Credit Default Risk yarÄ±ÅŸmasÄ±ydÄ±. TÃ¼m zamanlarÄ±n ikinci en bÃ¼yÃ¼k Kaggle yarÄ±ÅŸmasÄ±ydÄ± ve hayatÄ±mda Ã¶zellikle zor bir dÃ¶nemde gerÃ§ekleÅŸti.
> 
> 
> 
> Kredi deÄŸerliliÄŸi (credit underwriting) Ã§ok zor bir veri bilimi problemidir ve Ã§ok zeki bir Ã¶zellik mÃ¼hendisliÄŸi ile gÃ¼venilir bir doÄŸrulama ÅŸemasÄ± gerektirir. Benim kiÅŸisel iÃ§gÃ¶rÃ¼m, Ã¶zellik seÃ§imi iÃ§in basit lineer modellemeyi kullanmaktÄ± ve bu genel modelimize yardÄ±mcÄ± oldu. Ekibimiz bu yarÄ±ÅŸmayÄ± kazandÄ± ve bugÃ¼n hÃ¢lÃ¢ bu zaferi Kaggle kariyerimin en Ã¶nemli noktasÄ± olarak gÃ¶rÃ¼yorum.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? NasÄ±l?**
> 
> Kaggle, ML kariyerimin en bÃ¼yÃ¼k hÄ±zlandÄ±rÄ±cÄ±sÄ± oldu. Sahip olduÄŸum dÃ¶rt ML iÅŸinden Ã¼Ã§Ã¼nÃ¼n doÄŸrudan Kaggle baÅŸarÄ±mÄ±n bir sonucu olduÄŸunu sÃ¶yleyebilirim. Kaggle baÅŸarÄ±sÄ±nÄ±n bir kariyer iÃ§in ne kadar Ã¶nemli olabileceÄŸini abartmak imkÃ¢nsÄ±zdÄ±r.
> 
> 
> 
> **Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neleri gÃ¶z ardÄ± ediyor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilmenizi istediÄŸiniz ÅŸeyler nelerdi?**
> 
> TÃ¼m ML problemlerinin, Ã¶zellikle Kaggle yarÄ±ÅŸmalarÄ±nÄ±n, uzun sÃ¼re ya az deÄŸer verdiÄŸim ya da yeterince Ã¶nemsemediÄŸim iki yÃ¶nÃ¼ vardÄ±r: Ã¶zellik mÃ¼hendisliÄŸi ve saÄŸlam bir doÄŸrulama stratejisi. ML kÃ¼tÃ¼phanelerini ve algoritmalarÄ±nÄ± Ã§ok seviyorum ve genellikle mÃ¼mkÃ¼n olan en kÄ±sa sÃ¼rede ML algoritmasÄ±nÄ± kurmaya baÅŸlÄ±yorum. Ama model performansÄ±na en bÃ¼yÃ¼k etkiyi Ã§ok iyi Ã¶zellikler saÄŸlar. Ne yazÄ±k ki, Ã¶zellik mÃ¼hendisliÄŸi daha Ã§ok bir sanat ve daha az bir bilimdir ve genellikle modele ve veri setine baÄŸlÄ±dÄ±r. Daha ilginÃ§ Ã¶zellik mÃ¼hendisliÄŸi hilelerinin ve uygulamalarÄ±nÄ±n Ã§oÄŸu standart ML kurslarÄ±nda veya kaynaklarÄ±nda nadiren Ã¶ÄŸretilir. BirÃ§oÄŸu Ã¶ÄŸretilmez ve Ã¶zel problem bazlÄ± iÃ§gÃ¶rÃ¼lere baÄŸÄ±mlÄ±dÄ±r. Ama Ã¶zellik mÃ¼hendisliÄŸine varsayÄ±lan olarak odaklanma zihniyeti geliÅŸtirilebilir ve genellikle iyi hale gelmek yÄ±llar alÄ±r.
> 
> 
> 
> **Kaggle iÃ§in kullanmanÄ±zÄ± Ã¶nereceÄŸiniz araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> XGBoost her ÅŸey iÃ§in yeter!
> 
> 

### Pseudo-labeling *(Sahte etiketleme)*

EÄŸitim iÃ§in kullanÄ±lan Ã¶rnek sayÄ±sÄ±nÄ±n fark yaratabileceÄŸi yarÄ±ÅŸmalarda, **sahte etiketleme (pseudo-labeling)**, test setinden alÄ±nan ek Ã¶rnekler sayesinde skorlarÄ±nÄ±zÄ± artÄ±rabilir. Fikir, tahminlerinden emin olduÄŸunuz test seti Ã¶rneklerini eÄŸitim setinize eklemektir.

Kredi deÄŸerliliÄŸi (credit underwriting) Ã§ok zor bir veri bilimi problemidir ve Ã§ok akÄ±llÄ±ca Ã¶zellik mÃ¼hendisliÄŸi ve gÃ¼venilir bir doÄŸrulama ÅŸemasÄ± gerektirir. Benim kiÅŸisel iÃ§gÃ¶rÃ¼m, Ã¶zellik seÃ§imi iÃ§in basit lineer modellemeyi kullanmaktÄ± ve bu genel modelimize yardÄ±mcÄ± oldu. Ekibimiz bu yarÄ±ÅŸmayÄ± kazandÄ± ve bugÃ¼n hÃ¢lÃ¢ bu zaferi Kaggle kariyerimin en Ã¶nemli noktasÄ± olarak gÃ¶rÃ¼yorum.

Kaggle kariyerinize yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?
Kaggle, ML kariyerimin en bÃ¼yÃ¼k hÄ±zlandÄ±rÄ±cÄ±sÄ± oldu. Sahip olduÄŸum dÃ¶rt ML iÅŸinden Ã¼Ã§Ã¼nÃ¼n doÄŸrudan Kaggle baÅŸarÄ±mÄ±n bir sonucu olduÄŸunu sÃ¶yleyebilirim. Kaggle baÅŸarÄ±sÄ±nÄ±n bir kariyer iÃ§in ne kadar Ã¶nemli olabileceÄŸini abartmak imkÃ¢nsÄ±zdÄ±r.

Deneyimsiz Kaggle katÄ±lÄ±mcÄ±larÄ± genellikle neleri gÃ¶z ardÄ± ediyor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilmenizi istediÄŸiniz ÅŸeyler nelerdi?
TÃ¼m ML problemlerinin, Ã¶zellikle Kaggle yarÄ±ÅŸmalarÄ±nÄ±n, uzun sÃ¼re ya az deÄŸer verdiÄŸim ya da yeterince Ã¶nemsemediÄŸim iki yÃ¶nÃ¼ vardÄ±r: **Ã¶zellik mÃ¼hendisliÄŸi** ve **saÄŸlam bir doÄŸrulama stratejisi**. ML kÃ¼tÃ¼phanelerini ve algoritmalarÄ±nÄ± Ã§ok seviyorum ve genellikle mÃ¼mkÃ¼n olan en kÄ±sa sÃ¼rede ML algoritmasÄ±nÄ± kurmaya baÅŸlÄ±yorum. Ama model performansÄ±na en bÃ¼yÃ¼k etkiyi Ã§ok iyi Ã¶zellikler saÄŸlar. Ne yazÄ±k ki, Ã¶zellik mÃ¼hendisliÄŸi daha Ã§ok bir sanat ve daha az bir bilimdir ve genellikle modele ve veri setine baÄŸlÄ±dÄ±r. Daha ilginÃ§ Ã¶zellik mÃ¼hendisliÄŸi hilelerinin ve uygulamalarÄ±nÄ±n Ã§oÄŸu standart ML kurslarÄ±nda veya kaynaklarÄ±nda nadiren Ã¶ÄŸretilir. BirÃ§oÄŸu Ã¶ÄŸretilmez ve Ã¶zel problem bazlÄ± iÃ§gÃ¶rÃ¼lere baÄŸÄ±mlÄ±dÄ±r. Ama Ã¶zellik mÃ¼hendisliÄŸine varsayÄ±lan olarak odaklanma zihniyeti geliÅŸtirilebilir ve genellikle iyi hale gelmek yÄ±llar alÄ±r.

Kaggle iÃ§in kullanmanÄ±zÄ± Ã¶nereceÄŸiniz araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?
**XGBoost her ÅŸey iÃ§in yeter!**

---

Sahte etiketleme ilk olarak **Santander Customer Transaction Prediction** yarÄ±ÅŸmasÄ±nda team Wizardry tarafÄ±ndan tanÄ±tÄ±ldÄ± (detaylar: [https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003](https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/89003)). Sahte etiketleme, modele daha fazla veri saÄŸladÄ±ÄŸÄ± iÃ§in katsayÄ±larÄ±nÄ± geliÅŸtirmesine yardÄ±mcÄ± olur, ancak her zaman iÅŸe yaramayabilir. Ã–ncelikle bazÄ± yarÄ±ÅŸmalarda buna gerek yoktur; sahte etiketler eklemek sonucu deÄŸiÅŸtirmeyebilir ve eklenen gÃ¼rÃ¼ltÃ¼ varsa sonucu kÃ¶tÃ¼leÅŸtirebilir.

> Ne yazÄ±k ki, sahte etiketlemenin bir yarÄ±ÅŸmada iÅŸe yarayÄ±p yaramayacaÄŸÄ±nÄ± Ã¶nceden kesin olarak bilmek mÃ¼mkÃ¼n deÄŸildir (bunu deneysel olarak test etmeniz gerekir). Ã–ÄŸrenme eÄŸrilerini Ã§izmek, daha fazla verinin faydalÄ± olup olmayacaÄŸÄ±na dair ipucu verebilir (Ã¶rnek: [https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html)).

Ä°kinci olarak, test seti tahminlerinin hangi kÄ±sÄ±mlarÄ±nÄ± ekleyeceÄŸinize veya tÃ¼m prosedÃ¼rÃ¼ en iyi sonuÃ§ iÃ§in nasÄ±l ayarlayacaÄŸÄ±nÄ±za karar vermek kolay deÄŸildir. Genel prosedÃ¼r ÅŸudur:

1. Modelinizi eÄŸitin
2. Test setinde tahmin yapÄ±n
3. GÃ¼ven Ã¶lÃ§Ã¼sÃ¼ belirleyin
4. Eklenecek test seti Ã¶rneklerini seÃ§in
5. BirleÅŸtirilmiÅŸ veri ile yeni bir model oluÅŸturun
6. Bu modelle tahmin yapÄ±n ve gÃ¶nderin

Ã–rnek bir sahte etiketleme prosedÃ¼rÃ¼ Chris Deotte tarafÄ±ndan **Instant Gratification** yarÄ±ÅŸmasÄ±nda sunulmuÅŸtur: [https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969](https://www.kaggle.com/cdeotte/pseudo-labeling-qda-0-969)

Sahte etiketleme uygularken dikkate almanÄ±z gereken birkaÃ§ nokta:

* EÄŸitilebilir ve iyi tahminler Ã¼reten bir modeliniz olmalÄ±; aksi takdirde sadece gÃ¼rÃ¼ltÃ¼ eklemiÅŸ olursunuz.
* Test setinde mÃ¼kemmel tahminler mÃ¼mkÃ¼n olmadÄ±ÄŸÄ±ndan, iyi olanlarÄ± kÃ¶tÃ¼ olanlardan ayÄ±rmanÄ±z gerekir. CV katlarÄ±yla tahmin yapÄ±yorsanÄ±z, tahminlerin standart sapmasÄ±nÄ± kontrol edin ve yalnÄ±zca standart sapmasÄ± en dÃ¼ÅŸÃ¼k olan test Ã¶rneklerini seÃ§in. OlasÄ±lÄ±k tahmini yapÄ±yorsanÄ±z, yalnÄ±zca yÃ¼ksek veya dÃ¼ÅŸÃ¼k uÃ§ tahminleri kullanÄ±n (modelin daha emin olduÄŸu durumlar).
* Ä°kinci aÅŸamada, eÄŸitim Ã¶rneklerini test Ã¶rnekleriyle birleÅŸtirirken, test Ã¶rneklerinin %50â€™den fazla olmamasÄ±na dikkat edin. Ä°deal olarak, %70 orijinal eÄŸitim ve %30 sahte etiketli Ã¶rnek en iyisidir. Ã‡ok fazla sahte etiket eklerseniz, yeni modeliniz orijinal veriden Ã§ok test Ã¶rneklerinden Ã¶ÄŸrenir ve performans dÃ¼ÅŸer.

> Sahte etiketlere tamamen gÃ¼venemeyeceÄŸinizi unutmayÄ±n; test tahminlerini eÄŸitim Ã¶rnekleri olarak kullanmak verilerinizi kÄ±smen bozmak demektir. Bu yÃ¶ntem, saÄŸladÄ±ÄŸÄ± faydalar olumsuz etkilerden fazlaysa iÅŸe yarar.

* EÄŸer doÄŸrulama ile erken durdurma, hiperparametre ayarlama veya model deÄŸerlendirme yapÄ±yorsanÄ±z, sahte etiketleri doÄŸrulamada kullanmayÄ±n. YanÄ±ltÄ±cÄ± olabilir. Her zaman orijinal eÄŸitim verisini kullanÄ±n.
* MÃ¼mkÃ¼nse sahte etiketleri tahmin etmek iÃ§in farklÄ± bir model, final modeli eÄŸitmek iÃ§in ise orijinal ve sahte etiketlerle baÅŸka bir model kullanÄ±n. BÃ¶ylece Ã¶nceki modelden aynÄ± bilgiyi tekrar etmeyip, sahte etiketlerden yeni bilgiler Ã§Ä±karÄ±rsÄ±nÄ±z.

Ã–zetle, sahte etiketleme daha Ã§ok bir sanattÄ±r. BazÄ± yarÄ±ÅŸmalarda fark yaratabilir, ancak iyi uygulanmasÄ± gerekir. Bir kaynak olarak dÃ¼ÅŸÃ¼nÃ¼n ve her zaman en az bir sahte etiket tabanlÄ± gÃ¶nderim deneyin.

### Denoising with autoencoders *(Otoenkoderlerle gÃ¼rÃ¼ltÃ¼ giderme)*

Otomatik kodlayÄ±cÄ±lar (Autoencoders), baÅŸlangÄ±Ã§ta doÄŸrusal olmayan veri sÄ±kÄ±ÅŸtÄ±rma (bir tÃ¼r doÄŸrusal olmayan PCA) ve gÃ¶rÃ¼ntÃ¼ gÃ¼rÃ¼ltÃ¼ giderme iÅŸlemleriyle daha Ã§ok tanÄ±nÄ±rken, Michael Jahrerâ€™in ([https://www.kaggle.com/mjahrer](https://www.kaggle.com/mjahrer)) Porto Seguroâ€™s Safe Driver Prediction yarÄ±ÅŸmasÄ±nÄ± ([https://www.kaggle.com/c/porto-seguro-safe-driver-prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)) kazanmak iÃ§in bunlarÄ± baÅŸarÄ±lÄ± bir ÅŸekilde kullanmasÄ±ndan sonra tabular veri yarÄ±ÅŸmalarÄ±nda ilginÃ§ bir araÃ§ olarak tanÄ±nmaya baÅŸladÄ±. Porto Seguro, Ã¶zellikle gÃ¼rÃ¼ltÃ¼lÃ¼ Ã¶zelliklerle karakterize edilmiÅŸ, popÃ¼ler bir sigorta tabanlÄ± risk analiz yarÄ±ÅŸmasÄ±ydÄ± ve 5.000â€™den fazla katÄ±lÄ±mcÄ±ya sahipti.

Michael Jahrer, sayÄ±sal verilerin sonraki sinir aÄŸÄ± denetimli Ã¶ÄŸrenme iÃ§in daha iyi bir temsilini nasÄ±l bulduÄŸunu, gÃ¼rÃ¼ltÃ¼ giderici otomatik kodlayÄ±cÄ±lar (Denoising Autoencoders - DAE) kullanarak aÃ§Ä±klamaktadÄ±r. Bir DAE, aÄŸÄ±n ortasÄ±ndaki gizli katmanlarÄ±n aktivasyonlarÄ±na ve bilgiyi kodlayan orta katman aktivasyonlarÄ±na dayanarak Ã§ok sayÄ±da yeni Ã¶zellik Ã¼reten bir veri seti oluÅŸturabilir.

ÃœnlÃ¼ gÃ¶nderisinde ([https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629)), Michael Jahrer, bir DAEâ€™nin sadece gÃ¼rÃ¼ltÃ¼yÃ¼ kaldÄ±rmakla kalmayÄ±p aynÄ± zamanda otomatik olarak yeni Ã¶zellikler oluÅŸturabileceÄŸini ve bÃ¶ylece Ã¶zelliklerin temsilinin, gÃ¶rÃ¼ntÃ¼ yarÄ±ÅŸmalarÄ±nda olduÄŸu gibi Ã¶ÄŸrenildiÄŸini anlatmaktadÄ±r. GÃ¶nderide, DAE yÃ¶nteminin gizli sÄ±rrÄ±nÄ±n sadece katmanlar deÄŸil, veriyi artÄ±rmak iÃ§in eklenen gÃ¼rÃ¼ltÃ¼ olduÄŸunu belirtmiÅŸtir. AyrÄ±ca bu tekniÄŸin, eÄŸitim ve test verilerinin birleÅŸtirilmesini gerektirdiÄŸini ve dolayÄ±sÄ±yla yÃ¶ntemin Kaggle yarÄ±ÅŸmasÄ±nÄ± kazanmanÄ±n Ã¶tesinde uygulamalarÄ± olmayacaÄŸÄ±nÄ± vurgulamÄ±ÅŸtÄ±r. AslÄ±nda, bu kazanma baÅŸarÄ±sÄ±ndan sonra teknik forumlardan ve Ã§oÄŸu yarÄ±ÅŸmadan kaybolmuÅŸ, ta ki Tabular Playground Series sÄ±rasÄ±nda tekrar ortaya Ã§Ä±kana kadar.

DAEâ€™ler teknik olarak bir kodlayÄ±cÄ± (encoder) ve bir Ã§Ã¶zÃ¼cÃ¼den (decoder) oluÅŸur. KodlayÄ±cÄ± kÄ±smÄ±, eÄŸitim verilerini giriÅŸ olarak alÄ±r ve ardÄ±ndan birkaÃ§ yoÄŸun katman (dense layer) gelir. Ä°deal olarak, tÃ¼m eÄŸitim bilgisini kodlayan bir gizli orta katman bulunur. Bu orta katmandaki dÃ¼ÄŸÃ¼m sayÄ±sÄ± orijinal giriÅŸ boyutundan kÃ¼Ã§Ã¼kse, bir sÄ±kÄ±ÅŸtÄ±rma yapÄ±lmÄ±ÅŸ olur ve istatistiksel olarak giriÅŸ verisinin Ã¼retim sÃ¼recinin arkasÄ±ndaki gizli boyutlarÄ± temsil edersiniz; aksi takdirde, sadece fazlalÄ±klarÄ± ortadan kaldÄ±rÄ±r ve gÃ¼rÃ¼ltÃ¼yÃ¼ sinyalden ayÄ±rÄ±rsÄ±nÄ±z (bu da kÃ¶tÃ¼ bir sonuÃ§ deÄŸildir).

KatmanÄ±n ikinci kÄ±smÄ± olan Ã§Ã¶zÃ¼cÃ¼ (decoder) kÄ±smÄ±nda ise katmanlarÄ± tekrar geniÅŸleterek orijinal giriÅŸ boyutuna kavuÅŸturursunuz. Ã‡Ä±ktÄ±, aÄŸÄ±n geri yayÄ±lÄ±mÄ± (backpropagation) iÃ§in hata kaybÄ±nÄ± (error loss) hesaplamak Ã¼zere giriÅŸle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.

Bu Ã§Ã¶zÃ¼mlerden, DAEâ€™lerin iki tÃ¼rde olduÄŸunu Ã§Ä±karabiliriz:
* **Bottleneck DAEâ€™ler**: GÃ¶rÃ¼ntÃ¼ iÅŸleme yÃ¶ntemlerini taklit ederek, kodlayÄ±cÄ± kÄ±smÄ± Ã§Ã¶zÃ¼cÃ¼ kÄ±sÄ±mdan ayÄ±ran orta katmandaki aktivasyonlarÄ± yeni Ã¶zellik olarak alÄ±rsÄ±nÄ±z. Bu mimariler kum saati (hourglass) ÅŸekline sahiptir; Ã¶nce katman katman nÃ¶ron sayÄ±sÄ±nÄ± orta bottleneck katmanÄ±na kadar azaltÄ±r, ardÄ±ndan ikinci kÄ±sÄ±mda tekrar geniÅŸletirsiniz. Gizli katman sayÄ±sÄ± her zaman tek sayÄ±dÄ±r.

![](im/1060.png)

* **Derin yÄ±ÄŸÄ±n (deep stack) DAEâ€™lerde**, kodlayÄ±cÄ±, Ã§Ã¶zÃ¼cÃ¼ veya orta katman ayrÄ±mÄ± yapmadan tÃ¼m gizli katmanlarÄ±n aktivasyonlarÄ± alÄ±nÄ±r. Bu mimarilerde katmanlar aynÄ± boyuttadÄ±r. Gizli katman sayÄ±sÄ± tek veya Ã§ift olabilir.

![](im1061.png)

BahsettiÄŸimiz gibi, sÄ±kÃ§a tartÄ±ÅŸÄ±lan Ã¶nemli bir konu, DAEâ€™nize (Denoising Autoencoder) biraz rastgele gÃ¼rÃ¼ltÃ¼ eklemektir. Her tÃ¼rlÃ¼ DAEâ€™yi eÄŸitmeye yardÄ±mcÄ± olmak iÃ§in, eÄŸitim verilerini artÄ±racak ve aÅŸÄ±rÄ± parametreli sinir aÄŸÄ±nÄ±n sadece girdileri ezberlemesini (baÅŸka bir deyiÅŸle overfittingâ€™i) Ã¶nleyecek gÃ¼rÃ¼ltÃ¼yÃ¼ eklemeniz gerekir. Porto Seguro yarÄ±ÅŸmasÄ±nda Michael Jahrer, swap noise adÄ± verilen bir teknik kullanarak gÃ¼rÃ¼ltÃ¼ eklemiÅŸtir ve bunu ÅŸÃ¶yle aÃ§Ä±klamÄ±ÅŸtÄ±r:

> Burada yukarÄ±daki tabloda â€œinputSwapNoiseâ€ olarak belirtilen belirli bir olasÄ±lÄ±k ile Ã¶zellikten Ã¶rnek alÄ±yorum. 0.15, Ã¶zelliklerin %15â€™inin baÅŸka bir satÄ±rdan alÄ±nan deÄŸerlerle deÄŸiÅŸtirilmesi anlamÄ±na geliyor.

Burada anlatÄ±lan, temel olarak mixup adÄ± verilen bir veri artÄ±rma (augmentation) tekniÄŸidir (bu yÃ¶ntem gÃ¶rÃ¼ntÃ¼ artÄ±rmada da kullanÄ±lÄ±r: [https://arxiv.org/abs/1710.09412](https://arxiv.org/abs/1710.09412)). Tablo verileri iÃ§in mixup uygularken, karÄ±ÅŸtÄ±rma olasÄ±lÄ±ÄŸÄ±nÄ± belirlersiniz. Bu olasÄ±lÄ±ÄŸa baÄŸlÄ± olarak, bir Ã¶rnekteki bazÄ± orijinal deÄŸerleri, aynÄ± eÄŸitim verisinden daha az veya daha Ã§ok benzer bir Ã¶rnekten alÄ±nan deÄŸerlerle deÄŸiÅŸtirirsiniz.

Danzel, walkthroughâ€™unda ([https://www.kaggle.com/springmanndaniel/1st-place-turn-your-data-into-daeta](https://www.kaggle.com/springmanndaniel/1st-place-turn-your-data-into-daeta)) bunun Ã¼Ã§ yaklaÅŸÄ±mÄ±nÄ± aÃ§Ä±klamaktadÄ±r: sÃ¼tun bazlÄ±, satÄ±r bazlÄ± ve rastgele:

* **SÃ¼tun bazlÄ± gÃ¼rÃ¼ltÃ¼ deÄŸiÅŸimi (column-wise noise swapping)**: Belirli sayÄ±da sÃ¼tundaki deÄŸerleri deÄŸiÅŸtirirsiniz. DeÄŸiÅŸtirilecek sÃ¼tun oranÄ±, mixup olasÄ±lÄ±ÄŸÄ±na gÃ¶re belirlenir.
* **SatÄ±r bazlÄ± gÃ¼rÃ¼ltÃ¼ deÄŸiÅŸimi (row-wise noise swapping)**: Her satÄ±rdaki belirli sayÄ±da deÄŸeri deÄŸiÅŸtirirsiniz. Temelde, her satÄ±r aynÄ± oranda deÄŸiÅŸtirilmiÅŸ deÄŸer iÃ§erir, ancak deÄŸiÅŸtirilen Ã¶zellikler satÄ±rdan satÄ±ra farklÄ±lÄ±k gÃ¶sterir.
* **Rastgele gÃ¼rÃ¼ltÃ¼ deÄŸiÅŸimi (random noise swapping)**: DeÄŸiÅŸtirilecek deÄŸer sayÄ±sÄ±nÄ± mixup olasÄ±lÄ±ÄŸÄ±na gÃ¶re belirler ve tÃ¼m veri setinden rastgele seÃ§ersiniz (etki olarak satÄ±r bazlÄ± deÄŸiÅŸime benzerdir).

TÄ±pkÄ± pseudo-labelingâ€™de olduÄŸu gibi, DAE de bilimden Ã§ok bir sanattÄ±r; yani tamamen deneme-yanÄ±lma yÃ¶ntemine dayanÄ±r. Her zaman iÅŸe yaramayabilir ve bir problemde iÅŸe yarayan detaylar baÅŸka bir problemde faydalÄ± olmayabilir. YarÄ±ÅŸmanÄ±z iÃ§in iyi bir DAE elde etmek istiyorsanÄ±z, test edilmesi ve ayarlanmasÄ± gereken bir dizi unsuru gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±sÄ±nÄ±z:

* DAEâ€™nin mimarisi (derin yÄ±ÄŸÄ±n genellikle daha iyi Ã§alÄ±ÅŸÄ±r, ancak katman baÅŸÄ±na birim sayÄ±sÄ± ve katman sayÄ±sÄ±nÄ± belirlemeniz gerekir)
* Ã–ÄŸrenme oranÄ± ve batch boyutu
* Loss (sayÄ±sal ve kategorik Ã¶zelliklerin lossâ€™larÄ±nÄ± ayÄ±rmak da faydalÄ±dÄ±r)
* Durdurma noktasÄ± (en dÃ¼ÅŸÃ¼k loss her zaman en iyi sonuÃ§ deÄŸildir; mÃ¼mkÃ¼nse validation ve early stopping kullanÄ±n)

Probleme baÄŸlÄ± olarak, doÄŸru mimariyi kurmak ve dÃ¼zgÃ¼n Ã§alÄ±ÅŸacak ÅŸekilde ayarlamakta zorluk yaÅŸayabilirsiniz. Ancak Ã§abalarÄ±nÄ±z, nihai Ã¶zel leaderboardâ€™da yÃ¼ksek bir sonuÃ§la Ã¶dÃ¼llendirilebilir. AslÄ±nda, son tablo yarÄ±ÅŸmalarÄ±nda DAE teknikleri, birÃ§ok kazanan gÃ¶nderinin tarifinin bir parÃ§asÄ± olarak gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r:

* Danzel ([https://www.kaggle.com/springmanndaniel](https://www.kaggle.com/springmanndaniel)), [https://www.kaggle.com/c/tabular-playground-series-jan-2021/discussion/216037](https://www.kaggle.com/c/tabular-playground-series-jan-2021/discussion/216037) adresinde Ã¼Ã§ adet 1,500 nÃ¶ronlu gizli katmanÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± kullanarak, orijinal 14 sÃ¼tunu 4,500 sÃ¼tuna geniÅŸlettiÄŸini bildirmiÅŸtir. Bu yeni iÅŸlenmiÅŸ veri seti, diÄŸer sinir aÄŸlarÄ± ve gradient boosting modelleri iÃ§in girdi olarak kullanÄ±lmÄ±ÅŸtÄ±r.
* Ren Zhang ([https://www.kaggle.com/ryanzhang](https://www.kaggle.com/ryanzhang)), Ã§Ã¶zÃ¼mÃ¼nÃ¼ ([https://www.kaggle.com/c/tabular-playground-series-feb-2021/discussion/222745](https://www.kaggle.com/c/tabular-playground-series-feb-2021/discussion/222745)) paylaÅŸmÄ±ÅŸ ve kodunu ([https://github.com/ryancheunggit/Denoise-Transformer-AutoEncoder](https://github.com/ryancheunggit/Denoise-Transformer-AutoEncoder)) aÃ§Ä±klamÄ±ÅŸtÄ±r. Tipik lineer ve ReLU aktivasyonlu gizli katmanlar yerine stacked transformer encoder kullandÄ±ÄŸÄ±nÄ± ve uygun bir DAEâ€™yi eÄŸitmenin 20 saate kadar sÃ¼rebileceÄŸini belirtmiÅŸtir. Bu yaklaÅŸÄ±mda, veriye rastgele gÃ¼rÃ¼ltÃ¼ eklemeyi (gÃ¼rÃ¼ltÃ¼ maskesi kullanarak) ve lossâ€™u yalnÄ±zca orijinal veriyi yeniden oluÅŸturma hatasÄ±ndan deÄŸil, aynÄ± zamanda gÃ¼rÃ¼ltÃ¼ maskesinden hesaplamayÄ± Ã¶nermiÅŸtir. Bu birleÅŸik loss, aÄŸÄ±n daha iyi yakÄ±nsamasÄ±na yardÄ±mcÄ± olur.
* JianTT ([https://www.kaggle.com/jiangtt](https://www.kaggle.com/jiangtt)), Ã¶zellikle yeni gÃ¶zlemler oluÅŸturmak iÃ§in gÃ¼rÃ¼ltÃ¼ eklemenin, eksiksiz bir DAE oluÅŸturmadan daha iyi algoritmalar eÄŸitmek iÃ§in faydalÄ± olabileceÄŸini fark etmiÅŸtir: [https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/235739](https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/235739).

> Kendi DAEâ€™nizi kurmak iÃ§in Ã§ok fazla zaman harcamak istemiyorsanÄ±z, ama yarÄ±ÅŸmada iÅŸe yarayÄ±p yaramayacaÄŸÄ±nÄ± keÅŸfetmek istiyorsanÄ±z, Ã¶nceden hazÄ±rlanmÄ±ÅŸ birkaÃ§ Ã§Ã¶zÃ¼mÃ¼ deneyebilirsiniz. Ã–ncelikle Hung Khoiâ€™nin PyTorch aÄŸÄ± iÃ§in hazÄ±rladÄ±ÄŸÄ± Notebookâ€™a ([https://www.kaggle.com/hungkhoi/train-denoise-transformer-autoencoder](https://www.kaggle.com/hungkhoi/train-denoise-transformer-autoencoder)) bakabilir ve ihtiyacÄ±nÄ±za gÃ¶re uyarlayabilirsiniz. Ya da Jeong-Yoon Leeâ€™nin Kaggler kÃ¼tÃ¼phanesini ([https://www.kaggle.com/jeongyoonlee](https://www.kaggle.com/jeongyoonlee)) kullanabilirsiniz. Jeong-Yoon Lee Notebookâ€™unda, bunun Tabular Playground yarÄ±ÅŸmalarÄ±ndan birinde nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶stermektedir: [https://www.kaggle.com/jeongyoonlee/dae-with-2-lines-of-code-with-kaggler](https://www.kaggle.com/jeongyoonlee/dae-with-2-lines-of-code-with-kaggler).

### Neural networks for tabular competitions *(Tablo verisi yarÄ±ÅŸmalarÄ± iÃ§in sinir aÄŸlarÄ±)*

DAEâ€™li sinir aÄŸlarÄ±nÄ± tartÄ±ÅŸtÄ±ktan sonra, bu bÃ¶lÃ¼mÃ¼ sinir aÄŸlarÄ±nÄ±n tablo yarÄ±ÅŸmalarÄ±nda daha genel olarak nasÄ±l yardÄ±mcÄ± olabileceÄŸini ele alarak tamamlamamÄ±z gerekiyor. Gradient boosting Ã§Ã¶zÃ¼mleri hÃ¢lÃ¢ tablo yarÄ±ÅŸmalarÄ±nda (ve gerÃ§ek dÃ¼nya projelerinde) aÃ§Ä±k ara Ã¶nde olsa da, bazen sinir aÄŸlarÄ± gradient boosting modellerinin yakalayamadÄ±ÄŸÄ± sinyalleri yakalayabilir ve tek baÅŸÄ±na mÃ¼kemmel modeller veya bir ensemble iÃ§inde Ã¶ne Ã§Ä±kan modeller olabilir.

> GeÃ§miÅŸin ve gÃ¼nÃ¼mÃ¼zÃ¼n birÃ§ok Grandmasterâ€™Ä±nÄ±n sÄ±kÃ§a belirttiÄŸi gibi, farklÄ± modelleri (Ã¶rneÄŸin bir sinir aÄŸÄ± ve bir gradient boosting modeli) bir araya getirmek, tablo verisi problemlerinde tek baÅŸÄ±na kullanÄ±lan modellerden her zaman daha iyi sonuÃ§lar verir. Kaggleâ€™da daha Ã¶nce birinci olan Owen Zhang, sinir aÄŸlarÄ± ve GBMâ€™lerin bir yarÄ±ÅŸmada daha iyi sonuÃ§lar iÃ§in nasÄ±l uyumlu bir ÅŸekilde birleÅŸtirilebileceÄŸini ÅŸu rÃ¶portajda ayrÄ±ntÄ±lÄ± ÅŸekilde tartÄ±ÅŸÄ±yor: [https://www.youtube.com/watch?v=LgLcfZjNF44](https://www.youtube.com/watch?v=LgLcfZjNF44)

Bir tablo yarÄ±ÅŸmasÄ± iÃ§in hÄ±zlÄ±ca bir sinir aÄŸÄ± kurmak artÄ±k gÃ¶z korkutucu bir zorluk deÄŸil. TensorFlow/Keras ve PyTorch gibi kÃ¼tÃ¼phaneler iÅŸleri kolaylaÅŸtÄ±rÄ±yor ve TabNet gibi Ã¶nceden hazÄ±rlanmÄ±ÅŸ aÄŸlarÄ±n kÃ¼tÃ¼phanelerde paketlenmiÅŸ olmasÄ± iÅŸleri daha da kolaylaÅŸtÄ±rÄ±yor.

Kendi aÄŸÄ±nÄ±zÄ± hÄ±zlÄ± bir ÅŸekilde oluÅŸturmaya baÅŸlamak iÃ§in Ã§eÅŸitli kaynaklarÄ± kullanabilirsiniz. Ã–zellikle, yayÄ±nladÄ±ÄŸÄ±mÄ±z **Machine Learning Using TensorFlow Cookbook** kitabÄ±na ([https://www.packtpub.com/product/machine-learning-using-tensorflow-cookbook/9781800208865](https://www.packtpub.com/product/machine-learning-using-tensorflow-cookbook/9781800208865)) baÅŸvurmanÄ±zÄ± ÅŸiddetle Ã¶neririz; Ã§Ã¼nkÃ¼ kitabÄ±n bir bÃ¶lÃ¼mÃ¼, tablo verileri iÃ§in TensorFlow ile DNN (Derin Sinir AÄŸlarÄ±) kurmayÄ± kapsamlÄ± ÅŸekilde ele alÄ±yor (BÃ¶lÃ¼m 7, Predicting with Tabular Data). Kitapta ayrÄ±ca Kaggleâ€™da TensorFlow kullanÄ±mÄ±yla ilgili birÃ§ok Ã¶neri ve tarif de bulabilirsiniz.

Bunun dÄ±ÅŸÄ±nda, konuyu tanÄ±tmak iÃ§in bazÄ± Ã§evrimiÃ§i kaynaklara da baÅŸvurabilirsiniz. 30 Days of ML yarÄ±ÅŸmasÄ±nda Ã¶nerilen kaynaklar ÅŸunlardÄ±r:

* TensorFlowâ€™u tablo verileri iÃ§in nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± anlatan videoyu izleyin: [https://www.youtube.com/watch?v=nQgUt_uADSE](https://www.youtube.com/watch?v=nQgUt_uADSE)
* GitHubâ€™daki eÄŸitim kodunu kullanÄ±n: [https://github.com/lmassaron/deep_learning_for_tabular_data](https://github.com/lmassaron/deep_learning_for_tabular_data)
* En Ã¶nemlisi, yarÄ±ÅŸmada uygulanan eÄŸitim Notebookâ€™una gÃ¶z atÄ±n: [https://www.kaggle.com/lucamassaron/tutorial-tensorflow-2-x-for-tabular-data](https://www.kaggle.com/lucamassaron/tutorial-tensorflow-2-x-for-tabular-data)

Bu Ã§Ã¶zÃ¼mleri kurarken gÃ¶z Ã¶nÃ¼nde bulundurmanÄ±z gereken temel noktalar ÅŸunlardÄ±r:

* ReLU yerine GeLU, SeLU veya Mish gibi aktivasyon fonksiyonlarÄ±nÄ± kullanÄ±n; birÃ§ok Ã§alÄ±ÅŸmada tablo verilerini modellemek iÃ§in daha uygun olduÄŸu belirtilmiÅŸtir ve kendi deneyimlerimiz de genellikle daha iyi performans gÃ¶sterdiklerini doÄŸrulamaktadÄ±r.
* Batch boyutu ile denemeler yapÄ±n.
* Mixup ile veri artÄ±rmayÄ± (augmentation) kullanÄ±n (autoencoder bÃ¶lÃ¼mÃ¼nde tartÄ±ÅŸÄ±lmÄ±ÅŸtÄ±).
* SayÄ±sal Ã¶zelliklerde quantile dÃ¶nÃ¼ÅŸÃ¼mÃ¼ kullanÄ±n ve bunun sonucunda uniform veya Gaussian daÄŸÄ±lÄ±mlarÄ± zorlayÄ±n.
* Embedding katmanlarÄ±ndan faydalanÄ±n, ancak embeddinglerin her ÅŸeyi modellemediÄŸini unutmayÄ±n. AslÄ±nda, embeddingler gÃ¶mÃ¼lÃ¼ Ã¶zelliÄŸin diÄŸer tÃ¼m Ã¶zelliklerle etkileÅŸimlerini kaÃ§Ä±rÄ±r (bu yÃ¼zden bu etkileÅŸimleri doÄŸrudan feature engineering ile aÄŸa dahil etmelisiniz).

Ã–zellikle, embedding katmanlarÄ±nÄ±n yeniden kullanÄ±labilir olduÄŸunu unutmayÄ±n. AslÄ±nda, sadece giriÅŸ (yÃ¼ksek kardinaliteli deÄŸiÅŸkenin seyrek one-hot kodlamasÄ±) ile dÃ¼ÅŸÃ¼k boyutlu yoÄŸun bir vektÃ¶r arasÄ±ndaki matris Ã§arpÄ±mÄ±ndan oluÅŸur. EÄŸitilmiÅŸ bir sinir aÄŸÄ±nÄ±n embeddingini kaydederek, aynÄ± Ã¶zelliÄŸi dÃ¶nÃ¼ÅŸtÃ¼rebilir ve ortaya Ã§Ä±kan embeddingleri gradient boostingâ€™tan lineer modellere kadar birÃ§ok farklÄ± algoritmada kullanabilirsiniz.

24 seviyeli kategorik bir deÄŸiÅŸkeni iÃ§eren sÃ¼reci daha iyi anlamak iÃ§in Åekil 7.6â€™daki diyagrama bakÄ±n. Grafikte, bir kategorik Ã¶zelliÄŸin deÄŸerinin metin veya tamsayÄ±dan, bir sinir aÄŸÄ±nÄ±n iÅŸleyebileceÄŸi bir deÄŸerler vektÃ¶rÃ¼ne nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼ÄŸÃ¼ gÃ¶sterilmektedir.

![](im/1062.png)

Her ÅŸey, Ã¶zelliÄŸin kaÃ§ farklÄ± deÄŸere sahip olduÄŸunu bilmekle baÅŸlar. Bu, sÃ¶zlÃ¼k boyutunu oluÅŸturur ve Ã¶nemli bir bilgidir. Bu Ã¶rnekte, 24 farklÄ± deÄŸere sahip bir Ã¶zellik ele alÄ±nmÄ±ÅŸtÄ±r. Bu bilgi, her olasÄ± Ã¶zellik deÄŸerini temsil eden 24 boyutlu bir one-hot kodlamalÄ± vektÃ¶r oluÅŸturmamÄ±zÄ± saÄŸlar. Elde edilen vektÃ¶r, satÄ±r boyutu one-hot vektÃ¶rÃ¼nÃ¼n boyutuna, sÃ¼tun boyutu ise Ã§Ä±ktÄ± boyutlarÄ±na karÅŸÄ±lÄ±k gelen bir matris ile Ã§arpÄ±lÄ±r. Bu ÅŸekilde, vektÃ¶r-matris Ã§arpÄ±mÄ±yla kategorik deÄŸiÅŸkenin girdisi Ã§ok boyutlu sayÄ±sal bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Ã‡arpmanÄ±n etkinliÄŸi, sinir aÄŸÄ±nÄ±n geri yayÄ±lÄ±m (backpropagation) algoritmasÄ± tarafÄ±ndan saÄŸlanÄ±r; algoritma matrisin her deÄŸerini gÃ¼ncelleyerek Ã§arpÄ±mdan en Ã¶ngÃ¶rÃ¼cÃ¼ sonucu elde eder.

EÄŸer TensorFlow veya PyTorch ile kendi derin sinir aÄŸÄ±nÄ±zÄ± kurmak istemiyorsanÄ±z, birkaÃ§ hazÄ±r mimari Ã§Ã¶zÃ¼mden faydalanabilirsiniz. Bu Ã§Ã¶zÃ¼mlerin tÃ¼mÃ¼ â€œout-of-the-boxâ€ yani kutudan Ã§Ä±ktÄ±ÄŸÄ± gibi kullanÄ±labilir; ya paketlenmiÅŸlerdir ya da diÄŸer Kaggle kullanÄ±cÄ±larÄ± orijinal makalelere dayanarak kodlamÄ±ÅŸlardÄ±r. Tablo yarÄ±ÅŸmalarÄ±ndaki baÅŸarÄ±larÄ±na dayanarak, kendiniz bir tablo yarÄ±ÅŸmasÄ±na girerken deneyebileceÄŸiniz baÅŸlÄ±ca Ã§Ã¶zÃ¼mler ÅŸunlardÄ±r:

* **TabNet**: Google araÅŸtÄ±rmacÄ±larÄ± tarafÄ±ndan geliÅŸtirilmiÅŸ bir aÄŸdÄ±r (ArÄ±k, S. O. ve Pfister, T. TabNet: Attentive interpretable tabular learning. arXiv 2020. [https://www.aaai.org/AAAI21Papers/AAAI-1063.ArikS.pdf](https://www.aaai.org/AAAI21Papers/AAAI-1063.ArikS.pdf)). Ä°lgili Ã¶zellikleri seÃ§ip iÅŸleme ve hem kategorik hem sayÄ±sal Ã¶zelliklerle akÄ±llÄ±ca baÅŸa Ã§Ä±kma sÃ¶zÃ¼ verir. Ayarlanacak Ã§ok hiperparametresi yoktur, ancak sonuÃ§lar ayarlanmamÄ±ÅŸ ve ayarlanmÄ±ÅŸ bir aÄŸ arasÄ±nda bÃ¼yÃ¼k farklÄ±lÄ±k gÃ¶sterebilir (bu yÃ¼zden en iyi performans iÃ§in biraz zaman harcamak gerekir). Uygulamalar arasÄ±nda mÃ¼kemmel **pytorch-tabnet** paketi ([https://github.com/dreamquark-ai/tabnet](https://github.com/dreamquark-ai/tabnet)) veya Yirun Zhang tarafÄ±ndan kodlanmÄ±ÅŸ uygulamalar ([https://www.kaggle.com/gogo827jz](https://www.kaggle.com/gogo827jz)) yer alÄ±r. Bu uygulamalar Mechanism of Action (MoA) Prediction yarÄ±ÅŸmasÄ± iÃ§in tasarlanmÄ±ÅŸtÄ±r.

* **Neural Oblivious Decision Ensembles (NODE)**: Sinir aÄŸÄ±nda karar aÄŸacÄ±nÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± taklit etmeye Ã§alÄ±ÅŸan bir mimaridir (Popov, S., Morozov, S., ve Babenko, A. Neural oblivious decision ensembles for deep learning on tabular data. arXiv preprint arXiv:1909.06312, 2019. [https://arxiv.org/abs/1909.06312](https://arxiv.org/abs/1909.06312)). TensorFlow iÃ§in Yirun Zhangâ€™Ä±n sunduÄŸu uygulamayÄ± kullanabilirsiniz: [https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras](https://www.kaggle.com/gogo827jz/moa-neural-oblivious-decision-ensembles-tf-keras) veya PyTorch iÃ§in: [https://www.kaggle.com/gogo827jz/moa-public-pytorch-node](https://www.kaggle.com/gogo827jz/moa-public-pytorch-node)

* **DiÄŸer modeller**: Wide & Deep, DeepFM, xDeepFM, AutoInt gibi geniÅŸ bir model yelpazesi mevcuttur; bunlarÄ±n Ã§oÄŸu faktorizasyon makinelerine dayanÄ±r ve genellikle tÄ±klama oranÄ± tahmini iÃ§in tasarlanmÄ±ÅŸtÄ±r. TÃ¼m bu sinir aÄŸlarÄ±nÄ± kendiniz kurmak zorunda deÄŸilsiniz; **DeepCTR** ([https://github.com/shenweichen/DeepCTR](https://github.com/shenweichen/DeepCTR)) veya **DeepTables** ([https://github.com/DataCanvasIO/deeptables](https://github.com/DataCanvasIO/deeptables)) gibi paketlere gÃ¼venebilirsiniz. Bu paketler, Categorical Feature Encoding Challenge II yarÄ±ÅŸmasÄ±nda ikinci ve birinci olan Changhao Lee ([https://www.kaggle.com/leechh](https://www.kaggle.com/leechh)) ve Jian Yang ([https://www.kaggle.com/jackguagua](https://www.kaggle.com/jackguagua)) tarafÄ±ndan Ã¶nerilmiÅŸtir.

SonuÃ§ olarak, kategorik Ã¶zellikler iÃ§in embedding katmanlarÄ± ve sayÄ±sal Ã¶zellikler iÃ§in dense katmanlarÄ± birleÅŸtirerek kendi tablo verisi sinir aÄŸÄ±nÄ±zÄ± oluÅŸturabilirsiniz. Ancak bu iÅŸe yaramazsa, iyi yazÄ±lmÄ±ÅŸ paketlerin saÄŸladÄ±ÄŸÄ± geniÅŸ Ã§Ã¶zÃ¼mlere her zaman gÃ¼venebilirsiniz. Yeni bir paket Ã§Ä±ktÄ±ÄŸÄ±nda gÃ¶zÃ¼nÃ¼z aÃ§Ä±k olsun; hem Kaggle yarÄ±ÅŸmalarÄ±nda hem de gerÃ§ek dÃ¼nya projelerinde performansÄ±nÄ±zÄ± artÄ±rabilir. AyrÄ±ca deneyimlerimize dayanarak bir tavsiye: Bir tablo yarÄ±ÅŸmasÄ±nda sinir aÄŸÄ±nÄ±n en iyi model olmasÄ±nÄ± beklemeyin; bu nadiren olur. Bunun yerine, klasik tablo veri modellerinden (gradient boosting modelleri ve sinir aÄŸlarÄ± gibi) Ã§Ã¶zÃ¼mleri harmanlayÄ±n; Ã§Ã¼nkÃ¼ bu modeller veriden farklÄ± sinyalleri yakalar ve bir ensemble iÃ§inde birleÅŸtirilebilir.

> Jean-FranÃ§ois Puget
> 
> [https://www.kaggle.com/cpmpml](https://www.kaggle.com/cpmpml)
> 
> 
> 
> Jean-FranÃ§ois Puget, namÄ± diÄŸer CPMP ile reproducibility (tekrarlanabilirlik) konusunun Ã¶nemi, veri ile Ã§alÄ±ÅŸma yÃ¶ntemleri, en iyi yarÄ±ÅŸmasÄ± ve daha fazlasÄ± hakkÄ±nda konuÅŸtuk. Kaggleâ€™da Competitions ve Discussions Grandmasterâ€™Ä± ve NVIDIA RAPIDSâ€™te Distinguished Engineer olarak birÃ§ok deÄŸerli gÃ¶rÃ¼ÅŸ paylaÅŸtÄ±. EditÃ¶r Ã¶zellikle onun bilimsel yÃ¶ntemle ilgili sÃ¶ylediklerini Ã§ok beÄŸendi.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Bilimsel bir temele sahip yarÄ±ÅŸmalarÄ± ya da kendimle iliÅŸki kurabileceÄŸim bir temeli olan yarÄ±ÅŸmalarÄ± severim. Anonim veya sentetik verilerden hoÅŸlanmam, ancak veri Ã§ok hassas bir fizik simÃ¼lasyonu ile Ã¼retilmiÅŸse kabul edebilirim. Genel olarak, Ã§ok az bilgi sahibi olduÄŸum alanlardaki Kaggle yarÄ±ÅŸmalarÄ±nÄ± severim; Ã§Ã¼nkÃ¼ en Ã§ok Ã¶ÄŸrenme fÄ±rsatÄ±nÄ± burada buluyorum. Bu, sÄ±ralama puanÄ± kazanmak iÃ§in en etkili yol deÄŸil ama en Ã§ok eÄŸlendiÄŸim yol.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±lÄ±r? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±klarÄ±nÄ±zdan ne kadar farklÄ±?**
> 
> Veriye bakarak ve mÃ¼mkÃ¼n olduÄŸunca iyi anlayarak baÅŸlarÄ±m. Ã–zellikle Ã¶ngÃ¶rÃ¼cÃ¼ desenleri bulmaya Ã§alÄ±ÅŸÄ±rÄ±m. SÄ±klÄ±kla iki Ã¶zelliÄŸi veya tÃ¼retilmiÅŸ Ã¶zellikleri x ve y eksenine, Ã¼Ã§Ã¼ncÃ¼ bir Ã¶zelliÄŸi ise renk kodlamasÄ± iÃ§in kullanarak Ã¶rnekleri Ã§izerim. ÃœÃ§ Ã¶zellikten biri hedef olabilir. GÃ¶rselleÅŸtirme Ã§ok kullanÄ±rÄ±m; Ã§Ã¼nkÃ¼ insan gÃ¶rselliÄŸinin veri analizinde en iyi araÃ§ olduÄŸuna inanÄ±yorum.
> 
> 
> 
> Ä°kinci olarak, model veya pipeline performansÄ±nÄ± deÄŸerlendirmeye zaman ayÄ±rÄ±rÄ±m. Model performansÄ±nÄ± olabildiÄŸince doÄŸru bir ÅŸekilde deÄŸerlendirebilmek son derece Ã¶nemlidir. DeÄŸerlendirme genellikle k-fold cross-validationâ€™Ä±n bir Ã§eÅŸididir, ancak fold tanÄ±mÄ± yarÄ±ÅŸma tÃ¼rÃ¼ne gÃ¶re uyarlanabilir (Ã¶rneÄŸin tahmin yarÄ±ÅŸmalarÄ±nda zaman bazlÄ± foldâ€™lar, Ã¶rnekler bir ÅŸekilde baÄŸlantÄ±lÄ±ysa group k-fold, Ã¶r. aynÄ± kullanÄ±cÄ± IDâ€™sine sahip aksiyonlar).
> 
> 
> 
> ArdÄ±ndan, veri giriÅŸinden submissionâ€™a kadar giden bir baseline pipeline oluÅŸturur ve test ederim. Kod yarÄ±ÅŸmalarÄ±nda, pipelineâ€™Ä±n doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± test etmek kritik Ã¶nemdedir.
> 
> 
> 
> Daha sonra daha karmaÅŸÄ±k modelleri (derin Ã¶ÄŸrenme kullanÄ±yorsam) veya daha fazla Ã¶zelliÄŸi (XGBoost veya RAPIDS/sklearn modelleri kullanÄ±yorsam) denerim. BunlarÄ± submit ederek lokal deÄŸerlendirme skorum ile public test skorunun korelasyonunu gÃ¶zlemlerim. Korelasyon iyiyse submit sayÄ±sÄ±nÄ± azaltÄ±rÄ±m.
> 
> 
> 
> BirkaÃ§ hafta sonra hiperparametre ayarlamasÄ± yaparÄ±m, ama bunu yalnÄ±zca bir kez ya da belki yarÄ±ÅŸma sonuna yakÄ±n ikinci kez yaparÄ±m. Ã‡Ã¼nkÃ¼ hiperparametre ayarlamasÄ± overfittingâ€™e neden olabilecek en kolay yollardan biridir ve overfitting konusunda Ã§ok dikkatliyim.
> 
> 
> 
> **GirdiÄŸiniz Ã¶zellikle zor bir yarÄ±ÅŸmadan ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntemlerden bahseder misiniz?**
> 
> En gurur duyduÄŸum yarÄ±ÅŸmalardan biri, TalkingData AdTracking Fraud Detection Challengeâ€™dir. Ã‡ok bÃ¼yÃ¼k bir tÄ±klama geÃ§miÅŸi vardÄ± ve hangi tÄ±klamalarÄ±n uygulama indirmelerine yol aÃ§tÄ±ÄŸÄ±nÄ± tahmin etmemiz gerekiyordu. Ã–zellikler Ã§ok az, satÄ±r sayÄ±sÄ± Ã§ok fazlaydÄ± (yaklaÅŸÄ±k yarÄ±m milyar). O zamanlar yalnÄ±zca 64 GB makinam vardÄ± ve yeni Ã¶zellikler oluÅŸturup deÄŸerlendirmek iÃ§in Ã§ok verimli bir yÃ¶ntem uygulamak zorundaydÄ±m.
> 
> 
> 
> BazÄ± Ã§Ä±karÄ±mlarÄ±m oldu:
> 
> 
> 
> 1. Uygulama indirmeye yol aÃ§an tÄ±klama, kullanÄ±cÄ±nÄ±n uygulama indirme sayfasÄ±ndaki son tÄ±klamaydÄ±. Bu nedenle â€œaynÄ± kullanÄ±cÄ± ve uygulama iÃ§in bir sonraki tÄ±klamaya kadar geÃ§en sÃ¼reâ€ en Ã¶nemli Ã¶zellikti.
> 
> 2. AynÄ± kullanÄ±cÄ± ve uygulamadan aynÄ± zaman damgasÄ±na sahip birÃ§ok tÄ±klama vardÄ±; indirme olan varsa, bunun son tÄ±klama olduÄŸunu varsaydÄ±m.
> 
> 3. Ã–zellik deÄŸerlerinin eÅŸzamanlÄ±lÄ±klarÄ±nÄ± tahmin etmek iÃ§in matris faktorizasyonu kullandÄ±m. O zaman Kerasâ€™ta bir libFM modeli uyguladÄ±m ve latent vektÃ¶rleri Ã¶zellik olarak eklemek faydalÄ± oldu.
> 
> 
> 
> Bunu uygulayan tek diÄŸer ekip, yarÄ±ÅŸmayÄ± kazanan ekipti. Bununla, Grandmaster olmayan birisi olarak ekipler arasÄ±nda 6. oldum.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? EÄŸer evet ise, nasÄ±l?**
> 
> Kaggle bana iki kez yardÄ±mcÄ± oldu:
> 
> 
> 
> 1. IBMâ€™de Kaggle, SOTA makine Ã¶ÄŸrenimi uygulamalarÄ± hakkÄ±nda bÃ¼yÃ¼k bir bilgi kaynaÄŸÄ±ydÄ±. Bu bilgiyi IBMâ€™in makine Ã¶ÄŸrenimi araÃ§larÄ±nÄ± (Watson Studio ve Watson Machine Learning) geliÅŸtirmek iÃ§in kullandÄ±m. Ã–rneÄŸin, 2016â€™da IBMâ€™in Python paketlerini desteklemesini saÄŸladÄ±m; o dÃ¶nemde IBM tamamen Java/Scala aÄŸÄ±rlÄ±klÄ±ydÄ±. Ben olmasaydÄ±m, IBM Spark ve Scalaâ€™ya yatÄ±rÄ±m yapacak ve Python dalgasÄ±nÄ± tamamen kaÃ§Ä±racaktÄ±. AyrÄ±ca IBMâ€™in yalnÄ±zca Spark ML veya TensorFlowâ€™u desteklemek istediÄŸi dÃ¶nemde XGBoostâ€™u erken desteklemeleri iÃ§in zorladÄ±m.
> 
> 2. Ä°kinci olarak, ÅŸu anki iÅŸimi elde etmemde Kaggle yardÄ±mcÄ± oldu. NVIDIA, Kaggle yarÄ±ÅŸma Grandmasterâ€™larÄ±nÄ± sosyal varlÄ±klarÄ± gÃ¼Ã§lÃ¼ olan kiÅŸileri arÄ±yordu ve bu kiÅŸiler NVIDIA stackâ€™ini ve RAPIDS GPU hÄ±zlandÄ±rmalÄ± ML paketini tanÄ±tmak iÃ§in Ã§alÄ±ÅŸÄ±yordu.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilmek istediÄŸiniz bir ÅŸey var mÄ±ydÄ±?**
> 
> Kagglers ile diÄŸer veri bilimciler arasÄ±ndaki fark, model performansÄ±nÄ± deÄŸerlendirme konusudur. EÄŸer bunu bilmezlerse, public leaderboardâ€™da iyi gÃ¶rÃ¼nen ancak private leaderboardâ€™da kÃ¶tÃ¼ performans gÃ¶steren submissionâ€™lar seÃ§erler. Private leaderboardâ€™da iyi performans gÃ¶steren modelleri kurmayÄ± bilen bir Kaggler, yeni veride de iyi performans gÃ¶steren, yani overfit olmayan modelleri kurmayÄ± Ã¶ÄŸrenir.
> 
> 
> 
> Deneyimsiz Kagglers sÄ±k sÄ±k â€œX yÃ¶ntemi/bu model bu yarÄ±ÅŸmada iÅŸe yarar mÄ±?â€ diye sorar. Benim cevabÄ±m her zaman: â€œDeneyin ve iÅŸe yarayÄ±p yaramadÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼n.â€ Makine Ã¶ÄŸrenimin deneysel bir bilim olduÄŸunu Ã§oÄŸu kiÅŸi kaÃ§Ä±rÄ±yor. Ä°yi modeller kurmak iÃ§in bilimsel yÃ¶ntem izlenmelidir:
> 
> 
> 
> * Hipotez oluÅŸturun (Ã¶rn. bu Ã¶zellik veya bu NN katmanÄ± pipeline performansÄ±nÄ± artÄ±racak)
> 
> * Hipotezi test etmek iÃ§in bir deney yÃ¼rÃ¼tÃ¼n (deÄŸiÅŸtirilen pipelineâ€™Ä± eÄŸitin)
> 
> * Deney sonuÃ§larÄ±nÄ± analiz edin (CV skoru Ã¶ncekinden daha iyi mi? Nerede daha iyi? Nerede kÃ¶tÃ¼?)
> 
> 
> 
> Her deney, bir hipotezi doÄŸrulamak veya reddetmek iÃ§in yapÄ±lmalÄ±dÄ±r ve her deney yalnÄ±zca bir deÄŸiÅŸkeni deÄŸiÅŸtirmelidir. Deneyimsiz kiÅŸiler genellikle birÃ§ok ÅŸeyi aynÄ± anda deÄŸiÅŸtirir ve neyin iÅŸe yaradÄ±ÄŸÄ±nÄ± Ã§Ä±karamaz.
> 
> 
> 
> **Veri analizi ve makine Ã¶ÄŸrenimi iÃ§in Ã¶nereceÄŸiniz araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> 
> 
> * Veri keÅŸfi iÃ§in Ã§oÄŸunlukla **Matplotlib** kullanÄ±rÄ±m.
> 
> * KÃ¼Ã§Ã¼k veri setlerinde **Pandas**, bÃ¼yÃ¼k veri setlerinde **cuDF (RAPIDS)** ile veri iÅŸleme yaparÄ±m.
> 
> * Makine Ã¶ÄŸrenimi iÃ§in **cuML (RAPIDS)**, GPU hÄ±zlandÄ±rmalÄ± **XGBoost** ve **PyTorch** kullanÄ±rÄ±m.
> 
> * MÃ¼mkÃ¼nse Ã¶nceden eÄŸitilmiÅŸ modelleri kullanÄ±rÄ±m; Ã¶rneÄŸin Hugging Faceâ€™den NLP modelleri veya **timm** paketinden gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma modelleri.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken en Ã¶nemli ÅŸey nedir?**
> 
> YarÄ±ÅŸmaya yeterince zaman ayÄ±rabileceÄŸinizden emin olun.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, Kaggleâ€™daki tabular (tablo tabanlÄ±) yarÄ±ÅŸmalarÄ± ele aldÄ±k. Tablo tabanlÄ± bir yarÄ±ÅŸmada uygulanabilecek bilgilerin Ã§oÄŸu standart veri bilimi bilgi ve uygulamalarÄ±yla Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼ iÃ§in, dikkatimiz daha Ã§ok Kaggleâ€™a Ã¶zgÃ¼ tekniklere odaklandÄ±.

Yeni tanÄ±tÄ±lan **Tabular Playground Series**â€™den baÅŸlayarak, reproducibility (tekrarlanabilirlik), EDA (Exploratory Data Analysis â€“ KeÅŸifsel Veri Analizi), feature engineering (Ã¶zellik mÃ¼hendisliÄŸi), feature selection (Ã¶zellik seÃ§imi), target encoding (hedef kodlama), pseudo-labeling (sahte etiketleme) ve tablo veri setlerine uygulanan neural network (sinir aÄŸÄ±) konularÄ±na deÄŸindik.

**EDA**, bir yarÄ±ÅŸmayÄ± kazanmak iÃ§in iÃ§gÃ¶rÃ¼ elde etmek istiyorsanÄ±z kritik bir aÅŸamadÄ±r. Ancak oldukÃ§a yapÄ±sÄ±zdÄ±r ve sahip olduÄŸunuz veri tÃ¼rÃ¼ne gÃ¼Ã§lÃ¼ ÅŸekilde baÄŸlÄ±dÄ±r. Genel EDA Ã¶nerilerinin yanÄ± sÄ±ra, tÃ¼m veri setinizi bir bakÄ±ÅŸta Ã¶zetleyebilecek **t-SNE** ve **UMAP** gibi tekniklere de dikkatinizi Ã§ektik.

Bir sonraki aÅŸama olan **feature engineering**, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z veri tÃ¼rÃ¼ne gÃ¼Ã§lÃ¼ bir ÅŸekilde baÄŸlÄ±dÄ±r. Bu nedenle, belirli durumunuza uygulayabileceÄŸiniz bir dizi olasÄ± Ã¶zellik mÃ¼hendisliÄŸi fikri sunduk.

**Feature selection** konusunda kÄ±sa bir genel bakÄ±ÅŸÄ±n ardÄ±ndan, hemen hemen her makine Ã¶ÄŸrenimi algoritmasÄ±na uygulanabilecek **Ã¶zellik Ã¶nemi** ve **rastgeleleÅŸtirme** temelli tekniklere dikkatinizi Ã§ektik.

Otomatik olarak iÅŸlenemeyeceÄŸini vurgulamak istediÄŸimiz **target encoding**â€™i aÃ§Ä±kladÄ±ktan sonra, muhtemelen gerÃ§ek dÃ¼nya projelerinizde uygulamayacaÄŸÄ±nÄ±z ama Kaggle yarÄ±ÅŸmalarÄ±nda Ã§ok iyi Ã§alÄ±ÅŸabilecek Ã¶zel tekniklere geÃ§tik: **pseudo-labeling** ve tablo yarÄ±ÅŸmalarÄ± iÃ§in **denoising autoencoder**.

Son olarak, kategorik Ã¶zelliklerin sinir aÄŸlarÄ±nda embedding katmanlarÄ± kullanÄ±larak nasÄ±l iÅŸlenebileceÄŸini tartÄ±ÅŸtÄ±ktan sonra, tablo verileri iÃ§in kullanÄ±labilecek hazÄ±r sinir aÄŸÄ± mimarilerinin kÄ±sa bir Ã¶zetini verdik.

Bir sonraki bÃ¶lÃ¼mde, tabular yarÄ±ÅŸmalara katÄ±lÄ±rken bilmeniz gereken tÃ¼m tekniklerin incelemesini **hyperparameter optimizasyonu** konusunu tartÄ±ÅŸarak tamamlayacaÄŸÄ±z.

---

## Chapter 8: Hyperparameter Optimization *(BÃ¶lÃ¼m 8: Hiperparametre Optimizasyonu)*

Bir Kaggle Ã§Ã¶zÃ¼mÃ¼nÃ¼n performansÄ±, yalnÄ±zca seÃ§tiÄŸiniz Ã¶ÄŸrenme algoritmasÄ±nÄ±n tÃ¼rÃ¼ ile belirlenmez. Verilerin ve kullandÄ±ÄŸÄ±nÄ±z Ã¶zelliklerin yanÄ± sÄ±ra, algoritmanÄ±n **hyperparameter**â€™larÄ± (eÄŸitim Ã¶ncesinde sabitlenmesi gereken ve eÄŸitim sÄ±rasÄ±nda Ã¶ÄŸrenilemeyen algoritma parametreleri) da performansÄ± gÃ¼Ã§lÃ¼ bir ÅŸekilde etkiler. Tablo veri yarÄ±ÅŸmalarÄ±nda doÄŸru deÄŸiÅŸkenleri/verileri/Ã¶zellikleri seÃ§mek en etkili yÃ¶ntemdir; ancak hyperparameter optimizasyonu, tÃ¼rÃ¼ ne olursa olsun tÃ¼m yarÄ±ÅŸmalarda etkilidir. AslÄ±nda, veri ve algoritma sabit olduÄŸunda, hyperparameter optimizasyonu algoritmanÄ±n tahmin performansÄ±nÄ± artÄ±rmanÄ±n ve leaderboardâ€™da yÃ¼kselmenin tek gÃ¼venilir yoludur. AyrÄ±ca, hyperparameter optimizasyonu **ensemble** yÃ¶ntemlerinde de faydalÄ±dÄ±r; Ã§Ã¼nkÃ¼ optimize edilmiÅŸ modellerin birleÅŸiminden oluÅŸan bir ensemble, optimize edilmemiÅŸ modellerin birleÅŸiminden her zaman daha iyi performans gÃ¶sterir.

Hyperparameterâ€™larÄ± manuel olarak ayarlamanÄ±n mÃ¼mkÃ¼n olduÄŸunu duyabilirsiniz; Ã¶zellikle seÃ§imlerinizin algoritma Ã¼zerindeki etkilerini biliyor ve anlÄ±yorsanÄ±z. BirÃ§ok Kaggle Grandmaster ve Master, yarÄ±ÅŸmalarda modellerini doÄŸrudan ayarlamaya sÄ±klÄ±kla gÃ¼vendiklerini belirtmiÅŸtir. Bu kiÅŸiler, en Ã¶nemli hyperparameterâ€™lar Ã¼zerinde **bisection (ikiye bÃ¶lme) yÃ¶ntemi** tarzÄ±nda Ã§alÄ±ÅŸÄ±r, bir parametrenin deÄŸer aralÄ±ÄŸÄ±nÄ± gittikÃ§e daraltarak en iyi sonucu Ã¼reten deÄŸeri bulurlar. ArdÄ±ndan diÄŸer parametreye geÃ§erler. Bu yÃ¶ntem, her parametre iÃ§in tek bir minimum varsa ve parametreler birbirinden baÄŸÄ±msÄ±zsa oldukÃ§a iyi Ã§alÄ±ÅŸÄ±r. Bu durumda arama, Ã§oÄŸunlukla deneyim ve Ã¶ÄŸrenme algoritmalarÄ±na dair bilgi ile yÃ¶nlendirilir.

Ancak deneyimlerimize gÃ¶re, Kaggleâ€™da karÅŸÄ±laÅŸacaÄŸÄ±nÄ±z Ã§oÄŸu gÃ¶revde durum bÃ¶yle deÄŸildir. Problemlerin ve kullanÄ±lan algoritmalarÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±, yalnÄ±zca bir arama algoritmasÄ±nÄ±n saÄŸlayabileceÄŸi sistematik bir yaklaÅŸÄ±m gerektirir. Bu nedenle, bu bÃ¶lÃ¼mÃ¼ yazmaya karar verdik.

Bu bÃ¶lÃ¼mde, **cross-validation** yaklaÅŸÄ±mÄ±nÄ±zÄ± test setine genellenebilecek en iyi hyperparameterâ€™larÄ± bulacak ÅŸekilde nasÄ±l geniÅŸletebileceÄŸinizi inceleyeceÄŸiz. AmaÃ§, yarÄ±ÅŸmalarda karÅŸÄ±laÅŸtÄ±ÄŸÄ±nÄ±z zaman ve kaynak kÄ±sÄ±tlamalarÄ±nÄ± yÃ¶netmektir. Bu nedenle, sahip olduÄŸunuz kaynaklara gÃ¶re karmaÅŸÄ±k modeller ve veri problemleri iÃ§in optimize edilmiÅŸ **Bayesian optimizasyon** yÃ¶ntemlerine odaklanacaÄŸÄ±z. YalnÄ±zca Ã¶nceden tanÄ±mlanmÄ±ÅŸ hyperparameterâ€™lar iÃ§in en iyi deÄŸerleri aramakla sÄ±nÄ±rlÄ± kalmayacak, aynÄ± zamanda **sinir aÄŸÄ± mimarisi** sorununa da deÄŸineceÄŸiz.

Ele alacaÄŸÄ±mÄ±z konular ÅŸunlardÄ±r:

* Temel optimizasyon teknikleri
* Ana parametreler ve nasÄ±l kullanÄ±lacaÄŸÄ±
* Bayesian optimizasyon

Hadi baÅŸlayalÄ±m!

### Basic optimization techniques *(Temel optimizasyon teknikleri)*

Hyperparameter optimizasyonunun temel algoritmalarÄ±, Scikit-learn paketinde bulunan **grid search** ve **random search**â€™tir. Son zamanlarda, Scikit-learn katkÄ±cÄ±larÄ±, hem grid search hem de random search stratejilerinin performansÄ±nÄ± artÄ±rmak iÃ§in **halving algoritmasÄ±nÄ±** da eklemiÅŸlerdir.

Bu bÃ¶lÃ¼mde, bu temel tekniklerin hepsini ele alacaÄŸÄ±z. BunlarÄ± Ã¶ÄŸrenerek, yalnÄ±zca bazÄ± Ã¶zel problemler iÃ§in etkili optimizasyon araÃ§larÄ±na sahip olmakla kalmayacak (Ã¶rneÄŸin, SVMâ€™ler genellikle grid search ile optimize edilir), aynÄ± zamanda hyperparameter optimizasyonunun temel mantÄ±ÄŸÄ±nÄ± da kavrayacaksÄ±nÄ±z.

BaÅŸlamak iÃ§in, gerekli bileÅŸenlerin neler olduÄŸunu belirlemek Ã§ok Ã¶nemlidir:

* Hyperparameterâ€™larÄ± optimize edilmesi gereken bir model
* Her hyperparameter iÃ§in aranacak deÄŸerlerin sÄ±nÄ±rlarÄ±nÄ± iÃ§eren bir **arama alanÄ±**
* Bir **cross-validation** ÅŸemasÄ±
* Bir **deÄŸerlendirme metriÄŸi** ve buna ait skor fonksiyonu

TÃ¼m bu Ã¶ÄŸeler, aradÄ±ÄŸÄ±nÄ±z Ã§Ã¶zÃ¼mÃ¼ belirlemek iÃ§in **arama yÃ¶ntemi** iÃ§inde bir araya gelir. Hadi nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± inceleyelim.

#### Grid search *(Izgara aramasÄ±)*

**Grid search**, hyperparameterâ€™larÄ± eksiksiz bir ÅŸekilde tarayan bir yÃ¶ntemdir ve yÃ¼ksek boyutlu uzaylarda uygulanabilirliÄŸi sÄ±nÄ±rlÄ±dÄ±r. Her parametre iÃ§in test etmek istediÄŸiniz bir deÄŸer kÃ¼mesi seÃ§ersiniz ve ardÄ±ndan bu kÃ¼medeki tÃ¼m olasÄ± kombinasyonlarÄ± denersiniz. Bu nedenle â€œeksiksizâ€ (exhaustive) olarak adlandÄ±rÄ±lÄ±r: her ÅŸeyi denersiniz. OldukÃ§a basit bir algoritmadÄ±r ve boyutsallÄ±k lanetine (curse of dimensionality) maruz kalÄ±r, ancak olumlu tarafÄ±, **embarrassingly parallel** olmasÄ±dÄ±r (bu bilgisayar bilimi teriminin tanÄ±mÄ± iÃ§in bkz. [link](https://www.cs.iusb.edu/~danav/teach/b424/b424_23_embpar.html)). Bu, yeterli sayÄ±da iÅŸlemciniz varsa, optimal ayarlamayÄ± Ã§ok hÄ±zlÄ± bir ÅŸekilde elde edebileceÄŸiniz anlamÄ±na gelir.

Ã–rnek olarak, bir sÄ±nÄ±flandÄ±rma problemi ve **support-vector machine (SVM)** sÄ±nÄ±flandÄ±rmasÄ±nÄ± ele alalÄ±m. SVMâ€™ler, hem sÄ±nÄ±flandÄ±rma hem de regresyon problemleri iÃ§in, grid searchâ€™Ã¼n en Ã§ok kullanÄ±lacaÄŸÄ± makine Ã¶ÄŸrenmesi algoritmalarÄ±ndan biridir. Scikit-learnâ€™Ã¼n **make_classification** fonksiyonunu kullanarak hÄ±zlÄ±ca bir sÄ±nÄ±flandÄ±rma veri seti oluÅŸturabiliriz:

```python
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

X, y = make_classification(n_samples=300, n_features=50,
                           n_informative=10,
                           n_redundant=25, n_repeated=15,
                           n_clusters_per_class=5,
                           flip_y=0.05, class_sep=0.5,
                           random_state=0)
```

Sonraki adÄ±m olarak, temel bir SVC algoritmasÄ± tanÄ±mlar ve arama alanÄ±nÄ± belirleriz. SVCâ€™nin kernel fonksiyonu (SVMâ€™de girdi verilerini dÃ¶nÃ¼ÅŸtÃ¼ren iÃ§ fonksiyon) farklÄ± hyperparameterâ€™larÄ± belirlediÄŸi iÃ§in, kernel tipine baÄŸlÄ± olarak kullanÄ±lacak parametrelerin iki farklÄ± sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ iÃ§eren bir liste saÄŸlarÄ±z. AyrÄ±ca deÄŸerlendirme metriÄŸini de belirleriz (bu Ã¶rnekte hedef dengeli olduÄŸundan **accuracy** kullanÄ±yoruz):

```python
from sklearn import svm
svc = svm.SVC(probability=True, random_state=1)

from sklearn import model_selection
search_grid = [
    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},
    {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}
]

scorer = 'accuracy'
```

Ã–rneÄŸimizde, lineer kernel gamma parametresinin ayarlanmasÄ±nÄ± gerektirmez, ancak radial basis function (RBF) kernel iÃ§in bu parametre Ã§ok Ã¶nemlidir. Bu nedenle iki sÃ¶zlÃ¼k saÄŸlÄ±yoruz: ilki lineer kernel iÃ§in, ikincisi RBF kernel iÃ§in. Her sÃ¶zlÃ¼k yalnÄ±zca ilgili kernel ve bu kernel iÃ§in geÃ§erli parametre aralÄ±klarÄ±nÄ± iÃ§erir.

DeÄŸerlendirme metriÄŸinin, algoritmanÄ±n optimize ettiÄŸi **maliyet fonksiyonundan** farklÄ± olabileceÄŸini unutmamak Ã¶nemlidir. BÃ¶lÃ¼m 5â€™te tartÄ±ÅŸÄ±ldÄ±ÄŸÄ± gibi, bazÄ± yarÄ±ÅŸmalarda deÄŸerlendirme metriÄŸi farklÄ± olabilir, ancak algoritmanÄ±n maliyet fonksiyonu deÄŸiÅŸtirilemez. Bu durumlarda, hyperparameterâ€™larÄ± deÄŸerlendirme metriÄŸine gÃ¶re ayarlamak, iyi performans gÃ¶steren bir model elde etmeye yardÄ±mcÄ± olabilir. Optimal hyperparameter seti, bu kÄ±sÄ±tlar altÄ±nda en iyi deÄŸerlendirme metriÄŸini dÃ¶ndÃ¼recektir. Teorik olarak en iyi sonuÃ§ olmayabilir, ama genellikle ona yakÄ±n olur.

TÃ¼m bu bileÅŸenler (model, arama alanÄ±, deÄŸerlendirme metriÄŸi, cross-validation ÅŸemasÄ±) **GridSearchCV** Ã¶rneÄŸinde birleÅŸtirilir ve model veriye uyarlanÄ±r:

```python
search_func = model_selection.GridSearchCV(estimator=svc, 
                                           param_grid=search_grid,
                                           scoring=scorer, 
                                           n_jobs=-1,
                                           cv=5)

search_func.fit(X, y)
print(search_func.best_params_)
print(search_func.best_score_)
```

Bir sÃ¼re sonra, kullandÄ±ÄŸÄ±nÄ±z makineye baÄŸlÄ± olarak, **cross-validated** sonuÃ§lara gÃ¶re en iyi kombinasyonu elde edeceksiniz.

Ã–zetle, grid search Ã§ok basit bir optimizasyon algoritmasÄ±dÄ±r ve Ã§ok Ã§ekirdekli bilgisayarlarÄ±n avantajÄ±nÄ± kullanabilir. Ã‡ok az ayarlama gerektiren algoritmalarla (SVM, ridge veya lasso regresyonlarÄ± gibi) iyi Ã§alÄ±ÅŸabilir, ancak diÄŸer durumlarda uygulanabilirliÄŸi sÄ±nÄ±rlÄ±dÄ±r. Ã–ncelikle, yalnÄ±zca **diskret seÃ§imler** ile hyperparameter optimizasyonunu sÄ±nÄ±rlÄ±dÄ±r (yani sÄ±nÄ±rlÄ± bir deÄŸer kÃ¼mesi gerekir). AyrÄ±ca, birden fazla hyperparameterâ€™Ä±n ayarlanmasÄ± gereken algoritmalarda etkili olmasÄ±nÄ± bekleyemezsiniz. Bunun nedeni, arama alanÄ±nÄ±n karmaÅŸÄ±klÄ±ÄŸÄ±nÄ±n hÄ±zla artmasÄ± ve Ã§oÄŸu parametre deÄŸerinin soruna uygun olmadan **kÃ¶r bir ÅŸekilde** denenmesinden kaynaklanan hesaplama verimsizliÄŸidir.

#### Random search *(Rastgele arama)*

**Random search**, arama alanÄ±nÄ± rastgele Ã¶rnekleyen bir yÃ¶ntemdir ve yÃ¼ksek boyutlu uzaylarda uygulanabilirliÄŸi vardÄ±r; bu nedenle pratikte yaygÄ±n olarak kullanÄ±lÄ±r. Ancak random searchâ€™Ã¼n dezavantajÄ±, bir Ã¶nceki denemelerden elde edilen bilgiyi bir sonraki ayarÄ± seÃ§mek iÃ§in kullanmamasÄ±dÄ±r (bu sorun, grid search iÃ§in de geÃ§erlidir). AyrÄ±ca, en iyi Ã§Ã¶zÃ¼mÃ¼ mÃ¼mkÃ¼n olan en hÄ±zlÄ± ÅŸekilde bulmak iÃ§in yapabileceÄŸiniz tek ÅŸey, doÄŸru hyperparameterâ€™larÄ± yakalayabilmeyi ummaktÄ±r.

Random search inanÄ±lmaz derecede iyi Ã§alÄ±ÅŸÄ±r ve anlaÅŸÄ±lmasÄ± oldukÃ§a basittir. RastgeleliÄŸe dayanmasÄ±na raÄŸmen, yalnÄ±zca ÅŸansa baÄŸlÄ± deÄŸildir; baÅŸlangÄ±Ã§ta Ã¶yle gÃ¶rÃ¼nse de istatistikteki rastgele Ã¶rnekleme gibi Ã§alÄ±ÅŸÄ±r. Teknikteki ana nokta ÅŸudur: yeterince rastgele test yaparsanÄ±z, benzer performans gÃ¶steren kombinasyonlarÄ±n hafifÃ§e farklÄ± varyasyonlarÄ±nÄ± denemekle enerji harcamadan doÄŸru parametreleri bulma olasÄ±lÄ±ÄŸÄ±nÄ±z yÃ¼ksektir.

BirÃ§ok AutoML sistemi, ayarlanacak Ã§ok fazla parametre olduÄŸunda random searchâ€™e dayanÄ±r (bkz. Golovin, D. ve ark., *Google Vizier: A Service for Black-Box Optimization*, 2017). Genel bir kural olarak, hyperparameter optimizasyon probleminizin boyutu yeterince yÃ¼ksekse (Ã¶rneÄŸin 16â€™nÄ±n Ã¼zerinde), random searchâ€™e bakmayÄ± dÃ¼ÅŸÃ¼nebilirsiniz.

AÅŸaÄŸÄ±da, Ã¶nceki Ã¶rneÄŸi random search kullanarak Ã§alÄ±ÅŸtÄ±rÄ±yoruz:

```python
import scipy.stats as stats
from sklearn.utils.fixes import loguniform

search_dict = {
    'kernel': ['linear', 'rbf'], 
    'C': loguniform(1, 1000),
    'gamma': loguniform(0.0001, 0.1)
}

scorer = 'accuracy'

search_func = model_selection.RandomizedSearchCV(
    estimator=svc,
    param_distributions=search_dict,
    n_iter=6,
    scoring=scorer,
    n_jobs=-1,
    cv=5
)

search_func.fit(X, y)
print(search_func.best_params_)
print(search_func.best_score_)
```

Dikkat edin, artÄ±k farklÄ± kernelâ€™ler iÃ§in ayrÄ± arama alanlarÄ±nda Ã§alÄ±ÅŸtÄ±rmaya gerek yok. Grid searchâ€™Ã¼n aksine, burada her parametre, etkisiz olanlar dahil, sistematik olarak test edilmez; bu da hesaplama sÃ¼resi gerektirir. Burada aramanÄ±n verimliliÄŸi, test edilen hyperparameter kÃ¼mesinden etkilenmez. Arama, ilgisiz parametrelere baÄŸlÄ± deÄŸildir; ÅŸansa dayalÄ±dÄ±r. SeÃ§ilen kernel iÃ§in birÃ§ok parametre arasÄ±ndan yalnÄ±zca bir geÃ§erli parametreyi test etseniz bile her deneme faydalÄ±dÄ±r.

#### Halving search *(YarÄ±ya indirme aramasÄ±)*

DediÄŸimiz gibi, hem grid search hem de random search bilgiye dayalÄ± olmayan bir ÅŸekilde Ã§alÄ±ÅŸÄ±r: bazÄ± testler belirli hyperparameterâ€™larÄ±n sonucu etkilemediÄŸini veya belirli deÄŸer aralÄ±klarÄ±nÄ±n etkisiz olduÄŸunu ortaya Ã§Ä±karsa bile, bu bilgi sonraki aramalara aktarÄ±lmaz.

Bu nedenle, Scikit-learn yakÄ±n zamanda **HalvingGridSearchCV** ve **HalvingRandomSearchCV** tahmin edicilerini tanÄ±ttÄ±. Bunlar, grid search ve random search stratejilerini ardÄ±ÅŸÄ±k yarÄ±ya indirme (successive halving) yÃ¶ntemiyle parametre arama iÃ§in kullanÄ±labilir.

**Halving** yÃ¶nteminde, baÅŸlangÄ±Ã§ turunda Ã§ok sayÄ±da hyperparameter kombinasyonu deÄŸerlendirilir, ancak kÃ¼Ã§Ã¼k miktarda hesaplama kaynaÄŸÄ± kullanÄ±lÄ±r. Bu, testleri eÄŸitim verinizden seÃ§ilen kÃ¼Ã§Ã¼k bir alt Ã¶rnek Ã¼zerinde Ã§alÄ±ÅŸtÄ±rarak gerÃ§ekleÅŸtirilir. Daha kÃ¼Ã§Ã¼k bir eÄŸitim seti, test edilmesi iÃ§in daha az hesaplama gerektirir; bÃ¶ylece daha az kaynak (Ã¶zellikle zaman) kullanÄ±lÄ±r, ancak performans tahminleri daha az hassas olur. Bu baÅŸlangÄ±Ã§ turu, problem Ã¼zerinde daha iyi performans gÃ¶steren bir hyperparameter alt kÃ¼mesinin seÃ§ilmesini saÄŸlar ve ikinci turda eÄŸitim seti boyutu artÄ±rÄ±lÄ±r.

Sonraki turlar benzer ÅŸekilde ilerler: test edilen deÄŸer aralÄ±ÄŸÄ± daraltÄ±ldÄ±kÃ§a, aranan eÄŸitim seti alt kÃ¼meleri giderek bÃ¼yÃ¼tÃ¼lÃ¼r (bu, testin Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ± iÃ§in daha fazla zaman gerektirir, ancak daha hassas performans tahmini saÄŸlar) ve aday sayÄ±sÄ± yarÄ±ya indirilmeye devam eder.

Ã–nceki probleme uygulanan bir Ã¶rnek ÅŸÃ¶yle:

```python
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingRandomSearchCV

search_func = HalvingRandomSearchCV(
    estimator=svc,
    param_distributions=search_dict,
    resource='n_samples',
    max_resources=100,
    aggressive_elimination=True,
    scoring=scorer,
    n_jobs=-1,
    cv=5,
    random_state=0
)

search_func.fit(X, y)
print(search_func.best_params_)
print(search_func.best_score_)
```

Bu ÅŸekilde, halving yÃ¶ntemi adaylarÄ±n seÃ§imi yoluyla ardÄ±ÅŸÄ±k optimizasyon adÄ±mlarÄ±na bilgi saÄŸlar. Sonraki bÃ¶lÃ¼mlerde, hyperparameter uzayÄ±nda daha hassas ve verimli bir arama yapmak iÃ§in daha akÄ±llÄ± yÃ¶ntemleri tartÄ±ÅŸacaÄŸÄ±z.

> Kazuki Onodera
> 
> [https://www.kaggle.com/onodera](https://www.kaggle.com/onodera)
> 
> 
> 
> BaÅŸka bir Kaggler ile kÄ±sa bir rÃ¶portaj yapalÄ±m. Kazuki Onodera, **Competitions Grandmaster** ve **Discussions Master** unvanlarÄ±na sahip, yaklaÅŸÄ±k 7 yÄ±llÄ±k yarÄ±ÅŸma deneyimi olan bir Kaggle kullanÄ±cÄ±sÄ±dÄ±r. AyrÄ±ca NVIDIAâ€™da KÄ±demli Derin Ã–ÄŸrenme Veri Bilimcisi olarak Ã§alÄ±ÅŸmakta ve NVIDIA KGMON (Kaggle Grandmasters of NVIDIA) ekibinin bir Ã¼yesidir.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggleâ€™daki uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Instacart Market Basket Analysis. Bu yarÄ±ÅŸma, Kaggle topluluÄŸu iÃ§in oldukÃ§a zorluydu Ã§Ã¼nkÃ¼ kullanÄ±cÄ±larÄ±n Ã¶nceki sipariÅŸlerine dayanarak bir sonraki sipariÅŸlerinde hangi Ã¼rÃ¼nlerin olacaÄŸÄ±nÄ± tahmin etmek iÃ§in anonimleÅŸtirilmiÅŸ veriler kullanÄ±lÄ±yordu. Bu yarÄ±ÅŸmayÄ± sevme sebebim, Ã¶zellik mÃ¼hendisliÄŸini Ã§ok seviyor olmam ve diÄŸerlerinin aklÄ±na gelmeyen ilginÃ§ ve iyi Ã¶zellikler geliÅŸtirebilmem. Bu sayede yarÄ±ÅŸmada ikinci olabildim.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±klarÄ±nÄ±zdan ne kadar farklÄ±?**
> 
> Bir modelin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± hayal etmeye Ã§alÄ±ÅŸÄ±yorum ve yanlÄ±ÅŸ negatifler ile yanlÄ±ÅŸ pozitiflere derinlemesine bakÄ±yorum. GÃ¼nlÃ¼k iÅŸimde yaptÄ±klarÄ±mla aynÄ±.
> 
> 
> 
> **GirdiÄŸiniz Ã¶zellikle zorlu bir yarÄ±ÅŸmadan bahseder misiniz ve gÃ¶revi Ã§Ã¶zmek iÃ§in hangi iÃ§gÃ¶rÃ¼leri kullandÄ±nÄ±z?**
> 
> Human Protein Atlas - Single Cell Classification. Bu yarÄ±ÅŸma aslÄ±nda bir tÃ¼r instance segmentation yarÄ±ÅŸmasÄ±ydÄ±, fakat maskeler saÄŸlanmamÄ±ÅŸtÄ±. Bu yÃ¼zden zayÄ±f denetimli Ã§ok etiketli bir sÄ±nÄ±flandÄ±rma problemine dÃ¶nÃ¼ÅŸtÃ¼. Etiket gÃ¼rÃ¼ltÃ¼sÃ¼nÃ¼ temizlemek iÃ§in iki aÅŸamalÄ± bir pipeline oluÅŸturdum.
> 
> 
> 
> **Kaggle kariyerinize katkÄ±da bulundu mu? EÄŸer Ã¶yleyse, nasÄ±l?**
> 
> Evet. Åu anda NVIDIA KGMON ekibinde Ã§alÄ±ÅŸÄ±yorum. Kaggle, tablo verisi, gÃ¶rsel, doÄŸal dil ve sinyal verisi gibi farklÄ± veri tÃ¼rlerinde, ayrÄ±ca sektÃ¶r ve alan aÃ§Ä±sÄ±ndan farklÄ± yarÄ±ÅŸmalar (sanayi, finans, astronomi, patoloji, spor, perakende vb.) dÃ¼zenliyor. Bu tÃ¼r verilere eriÅŸim ve deneyim edinmek iÃ§in en uygun yer kesinlikle Kaggle.
> 
> 
> 
> **Deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz iyi olurdu dediÄŸiniz ÅŸey nedir?**
> 
> Hedef analizi. AyrÄ±ca seed averaging de oldukÃ§a gÃ¶z ardÄ± ediliyor: her zaman basit ama gÃ¼Ã§lÃ¼.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> Hedef analizi. En iyi takÄ±mlar her zaman hedefi diÄŸerlerinden daha iyi analiz eder, bu yÃ¼zden bir yarÄ±ÅŸmada daha iyi bir yerde olamÄ±yorsam, en iyi Ã§Ã¶zÃ¼mleri okuyorum; Ã§Ã¼nkÃ¼ bu Ã§Ã¶zÃ¼mler bana yarÄ±ÅŸma sÄ±rasÄ±nda kaÃ§Ä±rdÄ±ÄŸÄ±m veri bilgilerini aÃ§Ä±klÄ±yor.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Sadece Python ve Jupyter Notebook.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken insanlarÄ±n akÄ±lda tutmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Bir yenilgiden Ã¶ÄŸrenebiliyorsanÄ±z, aslÄ±nda kaybetmemiÅŸsiniz demektir.
> 
> 
> 
> **BaÅŸka yarÄ±ÅŸma platformlarÄ±nÄ± kullanÄ±yor musunuz? Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±lÄ±rlar?**
> 
> KDD Cup ve RecSys. Her ikisi de ilginÃ§ ve zorlu olma aÃ§Ä±sÄ±ndan minimum gereksinimleri karÅŸÄ±lÄ±yor.
> 
> 

### Key parameters and how to use them *(Temel parametreler ve nasÄ±l kullanÄ±lacaklarÄ±)*

Bir sonraki sorun, kullandÄ±ÄŸÄ±nÄ±z her model tÃ¼rÃ¼ iÃ§in doÄŸru hiperparametre setini kullanmaktÄ±r. Ã–zellikle optimizasyonunuzu verimli yapmak iÃ§in, her farklÄ± algoritma iÃ§in hangi hiperparametre deÄŸerlerini test etmenin gerÃ§ekten anlamlÄ± olduÄŸunu bilmeniz gerekir.

Bu bÃ¶lÃ¼mde, Kaggle yarÄ±ÅŸmalarÄ±nda, Ã¶zellikle tablo verisi yarÄ±ÅŸmalarÄ±nda, en yaygÄ±n olarak kullanÄ±lan modelleri inceleyecek ve en iyi sonuÃ§larÄ± elde etmek iÃ§in ayarlamanÄ±z gereken hiperparametreleri tartÄ±ÅŸacaÄŸÄ±z. Genel tablo verisi problemleri iÃ§in klasik makine Ã¶ÄŸrenimi modelleri ile (parametre alanÄ± aÃ§Ä±sÄ±ndan Ã§ok daha talepkar olan) gradient boosting modelleri arasÄ±nda ayrÄ±m yapacaÄŸÄ±z.

Sinir aÄŸlarÄ±na gelince, standart modelleri tanÄ±tÄ±rken ayarlanmasÄ± gereken bazÄ± Ã¶zel parametreler hakkÄ±nda fikir verebiliriz (Ã¶rneÄŸin, TabNet sinir modeli dÃ¼zgÃ¼n Ã§alÄ±ÅŸmasÄ± iÃ§in bazÄ± Ã¶zel parametrelere ihtiyaÃ§ duyar). Ancak, Kaggle yarÄ±ÅŸmalarÄ±nda derin sinir aÄŸlarÄ± optimizasyonunun Ã§oÄŸu standart modeller Ã¼zerinde deÄŸil, Ã¶zel olarak geliÅŸtirilmiÅŸ modeller Ã¼zerinde yapÄ±lmaktadÄ±r. DolayÄ±sÄ±yla, Ã¶ÄŸrenme oranÄ± ve batch boyutu gibi temel Ã¶ÄŸrenme parametreleri dÄ±ÅŸÄ±nda, sinir aÄŸlarÄ±nda optimizasyon modelinizin sinir mimarisinin Ã¶zel Ã¶zelliklerine dayanmaktadÄ±r. Bu problemi ad hoc (duruma Ã¶zel) bir ÅŸekilde ele almanÄ±z gerekir. BÃ¶lÃ¼mÃ¼n sonunda, KerasTuner kullanarak bir sinir mimarisi arama (NAS) Ã¶rneÄŸini tartÄ±ÅŸacaÄŸÄ±z ([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)).

#### Linear models *(DoÄŸrusal modeller)*

AyarlanmasÄ± gereken lineer modeller genellikle dÃ¼zenlemeli (regularized) lineer regresyon veya lojistik regresyon modelleridir:

* **C**: AramanÄ±z gereken deÄŸer aralÄ±ÄŸÄ± `np.logspace(-4, 4, 10)`â€™dur; daha kÃ¼Ã§Ã¼k deÄŸerler daha gÃ¼Ã§lÃ¼ regularizasyon uygular.
* **alpha**: AramanÄ±z gereken deÄŸer aralÄ±ÄŸÄ± `np.logspace(-2, 2, 10)`â€™dur; daha kÃ¼Ã§Ã¼k deÄŸerler daha gÃ¼Ã§lÃ¼ regularizasyon uygular, daha bÃ¼yÃ¼k deÄŸerler ise daha gÃ¼Ã§lÃ¼ regularizasyon uygular. AyrÄ±ca, Lasso kullanÄ±rken daha yÃ¼ksek deÄŸerlerin iÅŸlenmesinin daha fazla zaman aldÄ±ÄŸÄ±nÄ± unutmayÄ±n.
* **l1_ratio**: SeÃ§ebileceÄŸiniz deÄŸerler `[.1, .5, .7, .9, .95, .99, 1]` listesindendir; yalnÄ±zca Elastic Net iÃ§in geÃ§erlidir.

Scikit-learnâ€™de, algoritmaya baÄŸlÄ± olarak, ya hiperparametre **C** (lojistik regresyon iÃ§in) ya da **alpha** (Lasso, Ridge, Elastic Net iÃ§in) bulunur.

#### Support-vector machines *(Destek vektÃ¶r makineleri)*

SVMâ€™ler, sÄ±nÄ±flandÄ±rma ve regresyon iÃ§in gÃ¼Ã§lÃ¼ ve ileri dÃ¼zey gÃ¶zetimli Ã¶ÄŸrenme teknikleri ailesidir ve hem lineer hem de lineer olmayan modelleri otomatik olarak uyarlayabilir. Scikit-learn, SVM sÄ±nÄ±flandÄ±rma ve regresyon uygulamalarÄ±nÄ±n eksiksiz bir kÃ¼tÃ¼phanesi olan **LIBSVM** ve Ã¶zellikle bÃ¼yÃ¼k veri kÃ¼meleri, Ã¶zellikle seyrek metin tabanlÄ± veri kÃ¼meleri iÃ§in uygun, Ã¶lÃ§eklenebilir bir lineer sÄ±nÄ±flandÄ±rma kÃ¼tÃ¼phanesi olan **LIBLINEAR**â€™a dayalÄ± bir uygulama sunar. SVM optimizasyonunda, sÄ±nÄ±flandÄ±rma problemlerinde hedef sÄ±nÄ±flarÄ± ayÄ±rmak iÃ§in sÄ±nÄ±flar arasÄ±ndaki mÃ¼mkÃ¼n olan en geniÅŸ marj ile karakterize edilen bir karar sÄ±nÄ±rÄ± kullanÄ±lÄ±r.

VarsayÄ±lan parametrelerle SVMâ€™ler iyi Ã§alÄ±ÅŸsa da Ã§oÄŸu zaman optimal deÄŸildir ve en iyi deÄŸerleri bulmak iÃ§in Ã§eÅŸitli deÄŸer kombinasyonlarÄ±nÄ± Ã§apraz doÄŸrulama ile test etmeniz gerekir. Ã–ncelik sÄ±rasÄ±na gÃ¶re ayarlanmasÄ± gereken parametreler ÅŸunlardÄ±r:

* **C**: Ceza deÄŸeri. AzaltÄ±lmasÄ± sÄ±nÄ±flar arasÄ±ndaki marjÄ± bÃ¼yÃ¼tÃ¼r, bÃ¶ylece daha fazla gÃ¼rÃ¼ltÃ¼yÃ¼ gÃ¶rmezden gelir ancak modelin genellenebilirliÄŸini artÄ±rÄ±r. Genellikle en iyi deÄŸer aralÄ±ÄŸÄ± `np.logspace(-3, 3, 7)`â€™dir.
* **kernel**: SVMâ€™de doÄŸrusal olmayan yapÄ±nÄ±n nasÄ±l uygulanacaÄŸÄ±nÄ± belirler ve `'linear'`, `'poly'`, `'rbf'`, `'sigmoid'` veya Ã¶zel bir kernel olarak ayarlanabilir. En yaygÄ±n kullanÄ±lan deÄŸer kesinlikle `'rbf'`â€™dir.
* **degree**: `kernel='poly'` ile Ã§alÄ±ÅŸÄ±r ve polinom geniÅŸlemesinin boyutunu belirtir. DiÄŸer kernelâ€™ler tarafÄ±ndan gÃ¶z ardÄ± edilir. Genellikle 2 ile 5 arasÄ± deÄŸerler en iyi sonucu verir.
* **gamma**: `'rbf'`, `'poly'` ve `'sigmoid'` iÃ§in bir katsayÄ±dÄ±r. YÃ¼ksek deÄŸerler veriye daha iyi uyum saÄŸlar, ancak aÅŸÄ±rÄ± Ã¶ÄŸrenmeye (overfitting) yol aÃ§abilir. Gammaâ€™yÄ±, tek bir Ã¶rneÄŸin model Ã¼zerindeki etkisi olarak dÃ¼ÅŸÃ¼nebiliriz. DÃ¼ÅŸÃ¼k deÄŸerler, her bir Ã¶rneÄŸin etkisinin daha geniÅŸ alana yayÄ±lmasÄ±nÄ± saÄŸlar; bu da SVM eÄŸri Ã§izgisinin lokal noktalardan daha az etkilenmesine ve daha dÃ¼zgÃ¼n bir karar sÄ±nÄ±rÄ± elde edilmesine yol aÃ§ar. YÃ¼ksek gamma deÄŸerleri ise eÄŸrinin lokal noktalarÄ±n dÃ¼zenini daha Ã§ok dikkate almasÄ±na sebep olur ve daha dÃ¼zensiz, kÄ±vrÄ±mlÄ± bir karar eÄŸrisi ortaya Ã§Ä±kar. Ã–nerilen grid search aralÄ±ÄŸÄ± `np.logspace(-3, 3, 7)`â€™dir.
* **nu**: `nuSVR` ve `nuSVC` ile regresyon ve sÄ±nÄ±flandÄ±rmada, marja yakÄ±n ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ eÄŸitim noktalarÄ± iÃ§in tolerans belirler. YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ noktalarÄ± gÃ¶z ardÄ± etmeye yardÄ±mcÄ± olur ve karar eÄŸrisinin daha dÃ¼zgÃ¼n olmasÄ±nÄ± saÄŸlar. [0,1] aralÄ±ÄŸÄ±nda olmalÄ±dÄ±r Ã§Ã¼nkÃ¼ eÄŸitim setine gÃ¶re oransaldÄ±r. Temel olarak **C** gibi davranÄ±r; yÃ¼ksek oranlar marjÄ± bÃ¼yÃ¼tÃ¼r.
* **epsilon**: SVRâ€™nin kabul edeceÄŸi hata miktarÄ±nÄ± belirler; algoritmanÄ±n eÄŸitiminde bir Ã¶rneÄŸin yanlÄ±ÅŸ tahmini iÃ§in ceza uygulanmayan geniÅŸ bir epsilon aralÄ±ÄŸÄ± tanÄ±mlar. Ã–nerilen aralÄ±k `np.logspace(-4, 2, 7)`â€™dir.
* **penalty, loss ve dual**: `LinearSVC` iÃ§in bu parametreler `('l1', 'squared_hinge', False)`, `('l2', 'hinge', True)`, `('l2', 'squared_hinge', True)` ve `('l2', 'squared_hinge', False)` kombinasyonlarÄ±nÄ± alabilir. `('l2', 'hinge', True)` kombinasyonu, `SVC(kernel='linear')` ile eÅŸdeÄŸerdir.

SVMâ€™nin ayarlanacak Ã§ok fazla hiperparametresi var gibi gÃ¶rÃ¼nebilir, ancak birÃ§ok ayar yalnÄ±zca belirli implementasyonlara veya kernelâ€™lere Ã¶zgÃ¼dÃ¼r; bu nedenle yalnÄ±zca ilgili parametreleri seÃ§meniz yeterlidir.

#### Random forests and extremely randomized trees *(Rastgele ormanlar ve aÅŸÄ±rÄ± rastgele aÄŸaÃ§lar)*

Leo Breiman ve Adele Cutler, rastgele orman (random forest) algoritmasÄ±nÄ±n temel fikrini ilk olarak geliÅŸtirmiÅŸlerdir ve algoritmanÄ±n adÄ± bugÃ¼n hÃ¢lÃ¢ onlarÄ±n tescilli markasÄ±dÄ±r (algoritma aÃ§Ä±k kaynak olmasÄ±na raÄŸmen). Scikit-learnâ€™de rastgele ormanlar **RandomForestClassifier** veya **RandomForestRegressor** sÄ±nÄ±flarÄ± ile uygulanÄ±r.

Rastgele orman, Leo Breiman tarafÄ±ndan geliÅŸtirilen bagging yÃ¶ntemine benzer ÅŸekilde Ã§alÄ±ÅŸÄ±r, ancak yalnÄ±zca ikili bÃ¶lÃ¼nme karar aÄŸaÃ§larÄ±nÄ± kullanÄ±r ve bu aÄŸaÃ§lar uÃ§larÄ±na kadar bÃ¼yÃ¼tÃ¼lÃ¼r. AyrÄ±ca her modelde kullanÄ±lacak Ã¶rnekleri **bootstrap** yÃ¶ntemiyle seÃ§er. AÄŸaÃ§ bÃ¼yÃ¼tÃ¼lÃ¼rken, her dalÄ±n bÃ¶lÃ¼nmesinde, bÃ¶lÃ¼nmede dikkate alÄ±nacak deÄŸiÅŸkenler de rastgele seÃ§ilir.

Ä°ÅŸte algoritmanÄ±n kalbindeki sÄ±r budur: FarklÄ± Ã¶rnekler ve farklÄ± deÄŸiÅŸkenler nedeniyle birbirinden Ã§ok farklÄ± aÄŸaÃ§larÄ± bir araya getirir. Bu aÄŸaÃ§lar farklÄ± olduklarÄ± iÃ§in aynÄ± zamanda **korelasyonsuzdur**. Bu faydalÄ±dÄ±r Ã§Ã¼nkÃ¼ sonuÃ§lar birleÅŸtirildiÄŸinde, daÄŸÄ±lÄ±mÄ±n uÃ§ deÄŸerleri birbirini dengeler ve varyans azalÄ±r. BaÅŸka bir deyiÅŸle, bagging algoritmalarÄ± tahminlerde belirli bir Ã§eÅŸitlilik dÃ¼zeyi saÄŸlar ve tek bir Ã¶ÄŸrenicinin (Ã¶rneÄŸin bir karar aÄŸacÄ±nÄ±n) keÅŸfetmeyeceÄŸi kurallarÄ± geliÅŸtirmelerine olanak tanÄ±r. Bu Ã§eÅŸitlilik, bireysel aÄŸaÃ§larÄ±n ortalamasÄ±nÄ±n tahmin performansÄ±nÄ± artÄ±ran bir daÄŸÄ±lÄ±m oluÅŸturulmasÄ±na yardÄ±mcÄ± olur.

**Extra Trees** (aÅŸÄ±rÄ± rastgeleleÅŸtirilmiÅŸ aÄŸaÃ§lar), Scikit-learnâ€™de **ExtraTreesClassifier/ExtraTreesRegressor** sÄ±nÄ±flarÄ±yla temsil edilir ve daha rastgele bir rastgele orman tÃ¼rÃ¼dÃ¼r. Tahminlerde daha dÃ¼ÅŸÃ¼k varyans Ã¼retirken, estimatÃ¶rlerde daha yÃ¼ksek bias (sapma) ortaya Ã§Ä±kar. Ancak CPU verimliliÄŸi aÃ§Ä±sÄ±ndan Extra Trees, rastgele ormanlara kÄ±yasla Ã¶nemli bir hÄ±z kazanÄ±mÄ± saÄŸlayabilir; bu nedenle hem Ã¶rnek sayÄ±sÄ± hem de Ã¶zellik sayÄ±sÄ± aÃ§Ä±sÄ±ndan bÃ¼yÃ¼k veri kÃ¼meleriyle Ã§alÄ±ÅŸÄ±rken ideal olabilir. Bu daha yÃ¼ksek bias ama daha hÄ±zlÄ± performansÄ±n nedeni, Extra Treeâ€™da bÃ¶lÃ¼nmelerin rastgele oluÅŸturulmasÄ±dÄ±r. Rastgele ormanlarda, bir dalÄ± bÃ¶lmek iÃ§in rastgele seÃ§ilen Ã¶zellikler arasÄ±nda en iyi deÄŸerleri bulmak iÃ§in dikkatli bir arama yapÄ±lÄ±r. Buna karÅŸÄ±lÄ±k, Extra Treesâ€™da hem bÃ¶lÃ¼nmede kullanÄ±lacak Ã¶zellikler hem de bÃ¶lÃ¼nme deÄŸeri tamamen rastgele seÃ§ilir. Bu nedenle hesaplama maliyeti dÃ¼ÅŸÃ¼ktÃ¼r, ancak seÃ§ilen rastgele bÃ¶lÃ¼nme her zaman en etkili olan olmayabilir (iÅŸte bias burada ortaya Ã§Ä±kar).

Her iki algoritma iÃ§in de ayarlanmasÄ± gereken temel hiperparametreler ÅŸunlardÄ±r:

* **max_features**: Her bÃ¶lÃ¼nmede kullanÄ±lacak Ã¶rneklenmiÅŸ Ã¶zellik sayÄ±sÄ±dÄ±r ve algoritmanÄ±n performansÄ±nÄ± belirleyebilir. DÃ¼ÅŸÃ¼k deÄŸer daha hÄ±zlÄ± Ã§alÄ±ÅŸmayÄ± saÄŸlar, ancak bias artar.
* **min_samples_leaf**: AÄŸaÃ§larÄ±n derinliÄŸini belirler. BÃ¼yÃ¼k deÄŸerler varyansÄ± azaltÄ±r ve biasâ€™Ä± artÄ±rÄ±r.
* **bootstrap**: Bootstrapping uygulanÄ±p uygulanmayacaÄŸÄ±nÄ± belirten Boolean parametredir.
* **n_estimators**: AÄŸaÃ§ sayÄ±sÄ±dÄ±r. Daha fazla aÄŸaÃ§ genellikle daha iyidir, ancak veri problemine baÄŸlÄ± olarak belli bir noktadan sonra getiriler azalÄ±r. AyrÄ±ca hesaplama maliyeti artar; bu, mevcut kaynaklarÄ±nÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurmayÄ± gerektirir.

Extra Trees, Ã¶zellikle verileriniz oldukÃ§a gÃ¼rÃ¼ltÃ¼lÃ¼ olduÄŸunda rastgele ormanlara iyi bir alternatiftir. BÃ¶lÃ¼nmelerin rastgele seÃ§imi nedeniyle bazÄ± varyans azalÄ±mÄ± karÅŸÄ±lÄ±ÄŸÄ±nda daha yÃ¼ksek bias verirler ve bu sayede rastgele ormanda baskÄ±n olabilecek Ã¶nemli ancak gÃ¼rÃ¼ltÃ¼lÃ¼ Ã¶zelliklerde daha az aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) eÄŸilimi gÃ¶sterirler.

#### Gradient tree boosting *(Gradyan aÄŸaÃ§ gÃ¼Ã§lendirmesi)*

Gradyan aÄŸaÃ§ gÃ¼Ã§lendirme (Gradient Tree Boosting) veya gradyan artÄ±rmalÄ± karar aÄŸaÃ§larÄ± (GBDT), **boosting** yÃ¶nteminin geliÅŸtirilmiÅŸ bir versiyonudur (boosting, zayÄ±f Ã¶ÄŸreniciler dizisini verilerin yeniden aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ versiyonlarÄ±na uygulayarak Ã§alÄ±ÅŸÄ±r). AdaBoost gibi, GBDT de bir **gradyan iniÅŸ fonksiyonuna** dayanÄ±r. Algoritma, topluluk (ensemble) tabanlÄ± modeller ailesinin en yetkinlerinden biri olduÄŸunu kanÄ±tlamÄ±ÅŸtÄ±r; ancak **tahminlerde artan varyans**, **verideki gÃ¼rÃ¼ltÃ¼ye karÅŸÄ± daha yÃ¼ksek hassasiyet** (her iki sorun da alt Ã¶rnekleme, subsampling, ile hafifletilebilir) ve **paralel olmayan iÅŸlemler nedeniyle yÃ¼ksek hesaplama maliyetleri** ile karakterizedir.

Derin Ã¶ÄŸrenme dÄ±ÅŸÄ±nda, gradyan gÃ¼Ã§lendirme en geliÅŸmiÅŸ makine Ã¶ÄŸrenimi algoritmalarÄ±ndan biridir. Jerome Friedman tarafÄ±ndan geliÅŸtirilen AdaBoost ve ilk gradyan gÃ¼Ã§lendirme uygulamasÄ±ndan bu yana, algoritmanÄ±n Ã§eÅŸitli baÅŸka sÃ¼rÃ¼mleri ortaya Ã§Ä±kmÄ±ÅŸtÄ±r; en gÃ¼ncel olanlar **XGBoost**, **LightGBM** ve **CatBoost**â€™tur.

#### LightGBM *(LightGBM algoritmasÄ±)*

YÃ¼ksek performanslÄ± **LightGBM** algoritmasÄ± ([https://github.com/Microsoft/LightGBM](https://github.com/Microsoft/LightGBM)), birden fazla bilgisayarda daÄŸÄ±tÄ±k olarak Ã§alÄ±ÅŸabilir ve bÃ¼yÃ¼k veri setlerini hÄ±zlÄ± bir ÅŸekilde iÅŸleyebilir. Microsoftâ€™taki bir ekip tarafÄ±ndan GitHubâ€™da aÃ§Ä±k kaynak proje olarak geliÅŸtirilmiÅŸtir (ayrÄ±ca akademik bir makale de mevcuttur: [https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html](https://papers.nips.cc/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html)).

LightGBM, XGBoost gibi karar aÄŸaÃ§larÄ±na dayanÄ±r, ancak farklÄ± bir strateji izler. XGBoost, bir deÄŸiÅŸkene gÃ¶re dallanma yapar ve o deÄŸiÅŸkende farklÄ± aÄŸaÃ§ dallanmalarÄ±nÄ± keÅŸfeder (**seviye-odaklÄ± aÄŸaÃ§ bÃ¼yÃ¼me stratejisi**), LightGBM ise tek bir dallanmaya odaklanÄ±r ve oradan dallanmayÄ± sÃ¼rdÃ¼rerek daha iyi bir uyum saÄŸlar (**yaprak-odaklÄ± aÄŸaÃ§ bÃ¼yÃ¼me stratejisi**). Bu sayede LightGBM, veriye hÄ±zlÄ±ca iyi bir uyum saÄŸlar ve XGBoostâ€™a kÄ±yasla alternatif Ã§Ã¶zÃ¼mler Ã¼retebilir (bu, tahminlerin varyansÄ±nÄ± azaltmak iÃ§in iki Ã§Ã¶zÃ¼mÃ¼ birleÅŸtirmeyi planlÄ±yorsanÄ±z avantajlÄ±dÄ±r). Algoritmik olarak dÃ¼ÅŸÃ¼nÃ¼rsek, bir karar aÄŸacÄ±nÄ±n dallanma yapÄ±sÄ±nÄ± bir grafik olarak hayal edersek, **XGBoost geniÅŸlik Ã¶ncelikli arama (BFS)**, **LightGBM derinlik Ã¶ncelikli arama (DFS)** uygular.

LightGBMâ€™i ayarlamak baÅŸlangÄ±Ã§ta gÃ¶z korkutucu gÃ¶rÃ¼nebilir; ayarlanabilecek **yÃ¼zden fazla parametre** vardÄ±r. Bu parametreleri buradan inceleyebilirsiniz:

* GitHub: [https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst)
* DokÃ¼mantasyon: [https://lightgbm.readthedocs.io/en/latest/Parameters.html](https://lightgbm.readthedocs.io/en/latest/Parameters.html)

Genel olarak, sonuÃ§larÄ± en Ã§ok etkileyen ve odaklanmanÄ±z gereken baÅŸlÄ±ca hiperparametreler ÅŸunlardÄ±r:

* **n_estimators**: 10â€“10.000 arasÄ±nda bir tamsayÄ±; yineleme sayÄ±sÄ±nÄ± belirler.
* **learning_rate**: 0.01â€“1.0 arasÄ±nda bir gerÃ§ek sayÄ±, genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir. AlgoritmanÄ±n tÃ¼m iterasyonlarÄ±nÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ± hesaplayan gradyan iniÅŸ adÄ±m boyutunu temsil eder.
* **max_depth**: 1â€“16 arasÄ±nda bir tamsayÄ±; Ã¶zelliklerdeki maksimum dallanma sayÄ±sÄ±nÄ± belirler. 0â€™dan kÃ¼Ã§Ã¼k deÄŸer verilirse maksimum olasÄ± dallanma saÄŸlanÄ±r, bu genellikle aÅŸÄ±rÄ± uyum (overfitting) riskini artÄ±rÄ±r.
* **num_leaves**: 2â€“2^max_depth arasÄ±nda bir tamsayÄ±; her aÄŸacÄ±n alacaÄŸÄ± maksimum yaprak sayÄ±sÄ±nÄ± belirler.
* **min_data_in_leaf**: 0â€“300 arasÄ±nda bir tamsayÄ±; bir yapraktaki minimum veri sayÄ±sÄ±nÄ± belirler.
* **min_gain_to_split**: 0â€“15 arasÄ±nda bir float; aÄŸacÄ±n dallanma yapmasÄ± iÃ§in gereken minimum kazancÄ± ayarlar. Gereksiz dallanmalarÄ± Ã¶nleyerek overfittingâ€™i azaltÄ±r (XGBoostâ€™ta gamma parametresine karÅŸÄ±lÄ±k gelir).
* **max_bin**: 32â€“512 arasÄ±nda bir tamsayÄ±; Ã¶zellik deÄŸerlerinin kaÃ§ binde gruplanacaÄŸÄ±nÄ± belirler. 255â€™in Ã¼stÃ¼nde deÄŸerler overfitting riskini artÄ±rÄ±r.
* **subsample**: 0.01â€“1.0 arasÄ±nda bir gerÃ§ek sayÄ±; eÄŸitimde kullanÄ±lacak Ã¶rnek oranÄ±nÄ± temsil eder.
* **subsample_freq**: 0â€“10 arasÄ±nda bir tamsayÄ±; algoritmanÄ±n Ã¶rnekleri kaÃ§ iterasyonda bir alt Ã¶rnekleyeceÄŸini belirler. 0 ise subsample parametresi gÃ¶z ardÄ± edilir (varsayÄ±lan 0â€™dÄ±r).
* **feature_fraction**: 0.1â€“1.0 arasÄ±nda bir gerÃ§ek sayÄ±; alt Ã¶rnekleme ile kullanÄ±lacak Ã¶zelliklerin oranÄ±nÄ± belirler. Bu, eÄŸitimde rastgeleliÄŸi artÄ±rarak gÃ¼rÃ¼ltÃ¼ ve multicollinearity ile mÃ¼cadele eder.
* **subsample_for_bin**: 30â€™dan Ã¶rnek sayÄ±sÄ±na kadar bir tamsayÄ±; histogram binleri iÃ§in Ã¶rnek alÄ±nacak veri sayÄ±sÄ±nÄ± belirler.
* **reg_lambda**: 0â€“100 arasÄ±nda bir gerÃ§ek sayÄ±; L2 dÃ¼zenlileÅŸtirmeyi belirler. Parametre Ã¶lÃ§eÄŸe duyarlÄ±dÄ±r, genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir.
* **reg_alpha**: 0â€“100 arasÄ±nda bir gerÃ§ek sayÄ±; L1 dÃ¼zenlileÅŸtirmeyi belirler, genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir.
* **scale_pos_weight**: 1e-6â€“500 arasÄ±nda bir gerÃ§ek sayÄ±; pozitif Ã¶rnekleri aÄŸÄ±rlÄ±klandÄ±rÄ±r (dolayÄ±sÄ±yla etkili olarak upsampling veya downsampling yapar), negatif Ã¶rnekler 1 deÄŸeri ile tutulur.

LightGBMâ€™de Ã§ok sayÄ±da hiperparametre bulunmasÄ±na raÄŸmen, aslÄ±nda yalnÄ±zca birkaÃ§ tanesi bÃ¼yÃ¼k etkiye sahiptir. Sabit iterasyon ve Ã¶ÄŸrenme hÄ±zÄ± iÃ§in en etkili olanlar: **feature_fraction, num_leaves, subsample, reg_lambda, reg_alpha, min_data_in_leaf**. Bu konu hakkÄ±nda Kaggle Grandmaster **Kohei Ozaki** tarafÄ±ndan yazÄ±lmÄ±ÅŸ blog yazÄ±sÄ±: [https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258). Ozaki, Optuna iÃ§in hÄ±zlÄ± bir hiperparametre ayarlama prosedÃ¼rÃ¼ oluÅŸtururken bu bilgiden faydalanÄ±r.

#### XGBoost *(XGBoost algoritmasÄ±)*

**XGBoost** ([https://github.com/dmlc/XGBoost](https://github.com/dmlc/XGBoost)), eXtreme Gradient Boostingâ€™in kÄ±saltmasÄ±dÄ±r. AÃ§Ä±k kaynaklÄ± bir projedir ve Scikit-learnâ€™Ã¼n bir parÃ§asÄ± deÄŸildir; ancak son zamanlarda bir Scikit-learn sarmalayÄ±cÄ± (wrapper) arayÃ¼zÃ¼ eklenmiÅŸtir, bu sayede XGBoostâ€™u Scikit-learn tarzÄ± veri pipelineâ€™larÄ±na entegre etmek kolaylaÅŸmÄ±ÅŸtÄ±r.

XGBoost algoritmasÄ±, 2015 yÄ±lÄ±nda Kaggle ve KDD Cup 2015 gibi veri bilimi yarÄ±ÅŸmalarÄ±nda popÃ¼lerlik kazanmÄ±ÅŸtÄ±r. AlgoritmanÄ±n yaratÄ±cÄ±sÄ± Tianqi Chen, Tong He ve Carlos Guestrinâ€™in makalelerinde belirttiÄŸi gibi, 2015â€™te Kaggleâ€™da dÃ¼zenlenen 29 yarÄ±ÅŸmadan 17â€™sinin kazanan Ã§Ã¶zÃ¼mÃ¼ XGBoostâ€™u ya tek baÅŸÄ±na ya da birden fazla modelden oluÅŸan bir ensemble iÃ§inde kullanmÄ±ÅŸtÄ±r. O tarihten sonra algoritma veri bilimi topluluÄŸu arasÄ±nda popÃ¼laritesini korumuÅŸ, ancak LightGBM ve CatBoost gibi diÄŸer GBM uygulamalarÄ±nÄ±n getirdiÄŸi yeniliklerle yarÄ±ÅŸmakta zaman zaman zorlanmÄ±ÅŸtÄ±r.

XGBoost, hem doÄŸruluk hem de hesaplama verimliliÄŸi aÃ§Ä±sÄ±ndan iyi performans gÃ¶stermesinin yanÄ± sÄ±ra, Ã§ok Ã§ekirdekli iÅŸlemciler ve daÄŸÄ±tÄ±k makineler kullanarak Ã¶lÃ§eklenebilir bir Ã§Ã¶zÃ¼mdÃ¼r.

XGBoost, ilk tree-boost GBM algoritmasÄ±na yapÄ±lan Ã¶nemli iyileÅŸtirmeler sayesinde GBM algoritmalarÄ±nÄ±n yeni neslini temsil eder:

* **Sparsity-awareness (seyreklik farkÄ±ndalÄ±ÄŸÄ±)**: Seyrek matrislerden faydalanabilir, bÃ¶ylece hem bellek tasarrufu saÄŸlar (yoÄŸun matris gerekmez) hem de iÅŸlem sÃ¼resini kÄ±saltÄ±r (sÄ±fÄ±r deÄŸerler Ã¶zel olarak iÅŸlenir).
* **YaklaÅŸÄ±k aÄŸaÃ§ Ã¶ÄŸrenimi (weighted quantile sketch)**: Klasik dallanma kesitlerinin tÃ¼m olasÄ± kombinasyonlarÄ±nÄ± araÅŸtÄ±rmaya gÃ¶re benzer sonuÃ§larÄ± Ã§ok daha kÄ±sa sÃ¼rede Ã¼retir.
* **Tek makinada paralel hesaplama**: En iyi bÃ¶lÃ¼nmeyi ararken Ã§oklu iÅŸ parÃ§acÄ±ÄŸÄ± kullanÄ±r; benzer ÅŸekilde, birden fazla makinede daÄŸÄ±tÄ±k hesaplamalar yapÄ±labilir.
* **Out-of-core hesaplama**: Tek bir makinede, sÃ¼tun bloklarÄ± olarak adlandÄ±rÄ±lan veri depolama Ã§Ã¶zÃ¼mÃ¼ kullanÄ±r. Bu yÃ¶ntem, veriyi diskte sÃ¼tunlar halinde dÃ¼zenleyerek optimizasyon algoritmasÄ±nÄ±n (sÃ¼tun vektÃ¶rleri Ã¼zerinde Ã§alÄ±ÅŸÄ±r) beklediÄŸi ÅŸekilde hÄ±zlÄ± veri Ã§ekimi saÄŸlar.

XGBoost ayrÄ±ca eksik verilerle etkili bir ÅŸekilde baÅŸa Ã§Ä±kabilir. Standart karar aÄŸaÃ§larÄ±na dayalÄ± diÄŸer aÄŸaÃ§ ensembleâ€™larÄ±, eksik verileri iÅŸlemden Ã¶nce Ã¶rneÄŸin negatif bir deÄŸer gibi Ã¶zel bir deÄŸerle doldurmak zorundadÄ±r; XGBoost bunu gereksiz kÄ±larak uygun dallanmayÄ± doÄŸrudan oluÅŸturabilir.

XGBoost parametreleri ([https://xgboost.readthedocs.io/en/latest/parameter.html](https://xgboost.readthedocs.io/en/latest/parameter.html)) arasÄ±nda, yarÄ±ÅŸmalarda ve projelerde sÄ±kÃ§a kullanÄ±lan baÅŸlÄ±ca parametreler ÅŸunlardÄ±r:

* **n_estimators**: Genellikle 10â€“5.000 arasÄ± bir tamsayÄ±.
* **learning_rate**: 0.01â€“1.0 arasÄ± bir gerÃ§ek sayÄ±, log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.
* **min_child_weight**: Genellikle 1â€“10 arasÄ± bir tamsayÄ±.
* **max_depth**: Genellikle 1â€“50 arasÄ± bir tamsayÄ±.
* **max_delta_step**: Genellikle 0â€“20 arasÄ± bir tamsayÄ±; her yaprak Ã§Ä±ktÄ±sÄ± iÃ§in izin verilen maksimum delta adÄ±mÄ±nÄ± temsil eder.
* **subsample**: 0.1â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; Ã¶rneklerin alt Ã¶rneklenme oranÄ±nÄ± belirtir.
* **colsample_bytree**: 0.1â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; aÄŸaÃ§ baÅŸÄ±na sÃ¼tun alt Ã¶rnekleme oranÄ±nÄ± belirtir.
* **colsample_bylevel**: 0.1â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; aÄŸaÃ§taki her seviyede sÃ¼tun alt Ã¶rnekleme oranÄ±nÄ± belirtir.
* **reg_lambda**: 1e-9â€“100 arasÄ± bir gerÃ§ek sayÄ±, L2 dÃ¼zenlileÅŸtirmeyi kontrol eder; log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi tercih edilir.
* **reg_alpha**: 1e-9â€“100 arasÄ± bir gerÃ§ek sayÄ±, L1 dÃ¼zenlileÅŸtirmeyi kontrol eder; log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi tercih edilir.
* **gamma**: AÄŸacÄ±n dallanmasÄ± iÃ§in gereken minimum kayÄ±p azaltÄ±mÄ±nÄ± belirtir; 1e-9â€“0.5 arasÄ± bir gerÃ§ek sayÄ± olmalÄ±, log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.
* **scale_pos_weight**: 1e-6â€“500 arasÄ± bir gerÃ§ek sayÄ±; pozitif sÄ±nÄ±f iÃ§in aÄŸÄ±rlÄ±ÄŸÄ± temsil eder, log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.

LightGBMâ€™de olduÄŸu gibi, XGBoostâ€™un da ayarlanmasÄ± gereken birÃ§ok benzer hiperparametresi vardÄ±r. DolayÄ±sÄ±yla LightGBM iÃ§in yapÄ±lan tÃ¼m deÄŸerlendirmeler XGBoost iÃ§in de geÃ§erlidir.

#### CatBoost *(CatBoost algoritmasÄ±)*

2017 Temmuzâ€™unda, Rus arama motoru Yandex, baÅŸka bir ilginÃ§ GBM algoritmasÄ±nÄ± kamuya aÃ§tÄ±: **CatBoost** ([https://catboost.ai/](https://catboost.ai/)). AdÄ±, â€œCategoryâ€ ve â€œBoostingâ€ kelimelerinin birleÅŸtirilmesinden gelir. AslÄ±nda gÃ¼Ã§lÃ¼ yÃ¶nÃ¼, Ã§oÄŸu iliÅŸkisel veritabanÄ±nda yer alan bilgilerin bÃ¼yÃ¼k kÄ±smÄ±nÄ± oluÅŸturan kategorik deÄŸiÅŸkenleri iÅŸleyebilme yeteneÄŸidir. Bunu, **one-hot encoding** ve **target encoding** yÃ¶ntemlerini harmanlayarak gerÃ§ekleÅŸtirir. Target encoding, kategorik seviyeleri, Ã¼zerinde Ã§alÄ±ÅŸÄ±lan probleme uygun sayÄ±sal bir deÄŸer atayarak ifade etme yÃ¶ntemidir; bunun detaylarÄ± **BÃ¶lÃ¼m 7, Tabular Competitions iÃ§in Modelleme** kÄ±smÄ±nda bulunabilir.

CatBoostâ€™un kategorik deÄŸiÅŸkenleri kodlamak iÃ§in kullandÄ±ÄŸÄ± fikir yeni deÄŸildir; aslÄ±nda bu, daha Ã¶nce Ã¶zellikle veri bilimi yarÄ±ÅŸmalarÄ±nda kullanÄ±lan bir tÃ¼r **feature engineering** (Ã¶zellik mÃ¼hendisliÄŸi) yÃ¶ntemidir. **Target encoding**, aynÄ± zamanda **likelihood encoding**, **impact coding** veya **mean encoding** olarak da bilinir ve temel olarak etiketlerinizi hedef deÄŸiÅŸkenle olan iliÅŸkilerine gÃ¶re sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rmenin bir yoludur. EÄŸer regresyon problemi varsa, etiketler tipik hedef deÄŸerinin ortalamasÄ±na gÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lebilir; sÄ±nÄ±flandÄ±rmada ise, bir etiket iÃ§in hedef sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ±dÄ±r (her kategori deÄŸeri iÃ§in hedefin koÅŸullu olasÄ±lÄ±ÄŸÄ±). Basit ve akÄ±llÄ±ca bir Ã¶zellik mÃ¼hendisliÄŸi hilesi gibi gÃ¶rÃ¼nse de, Ã§oÄŸunlukla **overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme)** riski taÅŸÄ±r Ã§Ã¼nkÃ¼ hedeften alÄ±nan bilgi tahminleyicilere dahil edilir.

CatBoostâ€™un oldukÃ§a fazla parametresi vardÄ±r ([https://catboost.ai/en/docs/references/training-parameters/](https://catboost.ai/en/docs/references/training-parameters/)). Biz tartÄ±ÅŸmamÄ±zÄ± en Ã¶nemli sekiz parametre ile sÄ±nÄ±rladÄ±k:

* **iterations**: Genellikle 10â€“1.000 arasÄ± bir tamsayÄ±; problem durumuna gÃ¶re artabilir.
* **depth**: 1â€“8 arasÄ± bir tamsayÄ±; genellikle daha yÃ¼ksek deÄŸerler daha uzun eÄŸitim sÃ¼resi gerektirir ve daha iyi sonuÃ§lar Ã¼retmez.
* **learning_rate**: 0.01â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenmesi Ã¶nerilir.
* **random_strength**: 1e-9â€“10.0 arasÄ± log-lineer Ã¶rneklenen bir gerÃ§ek sayÄ±; dallanma puanlamasÄ±nda rastgelelik seviyesini belirtir.
* **bagging_temperature**: 0.0â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; Bayesian bootstrapâ€™u ayarlar.
* **border_count**: 1â€“255 arasÄ± bir tamsayÄ±; sayÄ±sal Ã¶zellikler iÃ§in bÃ¶lÃ¼nmeleri belirtir.
* **l2_leaf_reg**: 2â€“30 arasÄ± bir tamsayÄ±; L2 dÃ¼zenlileÅŸtirme iÃ§in deÄŸeri belirtir.
* **scale_pos_weight**: 0.01â€“10.0 arasÄ± bir gerÃ§ek sayÄ±; pozitif sÄ±nÄ±fÄ±n aÄŸÄ±rlÄ±ÄŸÄ±nÄ± temsil eder.

CatBoost, sadece baÅŸka bir GBM uygulamasÄ± gibi gÃ¶rÃ¼nse de, kullanÄ±lan farklÄ± parametrelerle de gÃ¶rÃ¼lebileceÄŸi Ã¼zere, yarÄ±ÅŸmalarda hem **tek model Ã§Ã¶zÃ¼mÃ¼** hem de **daha bÃ¼yÃ¼k bir ensemble iÃ§inde** bÃ¼yÃ¼k avantaj saÄŸlayabilecek birÃ§ok farklÄ±lÄ±ÄŸa sahiptir.

#### HistGradientBoosting *(Histogram tabanlÄ± gradyan gÃ¼Ã§lendirme)*

Son zamanlarda, Scikit-learn, LightGBMâ€™in **binned data** ve histogramlarÄ±ndan esinlenerek yeni bir gradient boosting sÃ¼rÃ¼mÃ¼ tanÄ±ttÄ± (EuroPythonâ€™daki Olivier Grisel sunumuna bakabilirsiniz: [https://www.youtube.com/watch?v=urVUlKbQfQ4](https://www.youtube.com/watch?v=urVUlKbQfQ4)). Bu algoritma, sÄ±nÄ±flandÄ±rÄ±cÄ± (**HistGradientBoostingClassifier**) veya regresÃ¶r (**HistGradientBoostingRegressor**) olarak kullanÄ±labilir. FarklÄ± modellerle ensemble oluÅŸturmak iÃ§in uygundur ve ayarlanmasÄ± gereken hiperparametreler Ã§ok daha kÄ±sa ve temel bir aralÄ±kta sunulmuÅŸtur:

* **learning_rate**: 0.01â€“1.0 arasÄ± bir gerÃ§ek sayÄ±; genellikle log-uniform daÄŸÄ±lÄ±mdan Ã¶rneklenir.
* **max_iter**: 10â€“10.000 arasÄ± bir tamsayÄ±.
* **max_leaf_nodes**: 2â€“500 arasÄ± bir tamsayÄ±; **max_depth** ile etkileÅŸimlidir. Tavsiye edilen, iki parametreden yalnÄ±zca birini ayarlamak ve diÄŸerini **None** bÄ±rakmaktÄ±r.
* **max_depth**: 2â€“12 arasÄ± bir tamsayÄ±.
* **min_samples_leaf**: 2â€“300 arasÄ± bir tamsayÄ±.
* **l2_regularization**: 0.0â€“100.0 arasÄ± bir gerÃ§ek sayÄ±.
* **max_bins**: 32â€“512 arasÄ± bir tamsayÄ±.

Scikit-learnâ€™Ã¼n **HistGradientBoosting** algoritmasÄ±, LightGBM veya XGBoostâ€™tan Ã§ok farklÄ± olmasa da, bir yarÄ±ÅŸmada GBMâ€™leri uygulamak iÃ§in farklÄ± bir yol sunar. HistGradientBoosting ile oluÅŸturulan modeller, **blending** ve **stacking** gibi birden fazla tahminin ensemble edilmesinde katkÄ± saÄŸlayabilir.

Bu bÃ¶lÃ¼mÃ¼n sonunda, en yaygÄ±n makine Ã¶ÄŸrenimi algoritmalarÄ±na (sadece derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mleri hariÃ§) ve ayarlanmasÄ± gereken en Ã¶nemli hiperparametrelere daha aÅŸina olmalÄ±sÄ±nÄ±z. Bu bilgiler, Kaggle yarÄ±ÅŸmalarÄ±nda etkileyici Ã§Ã¶zÃ¼mler oluÅŸturmanÄ±zda yardÄ±mcÄ± olacaktÄ±r. Temel optimizasyon stratejilerini, kullanÄ±labilir algoritmalarÄ± ve bunlarÄ±n anahtar hiperparametrelerini bilmek yalnÄ±zca bir baÅŸlangÄ±Ã§tÄ±r. Bir sonraki bÃ¶lÃ¼mde, **Bayesian optimizasyon** kullanarak hiperparametreleri daha optimal ÅŸekilde ayarlamayÄ± derinlemesine ele alacaÄŸÄ±z.

> Alberto Danese
> 
> [https://www.kaggle.com/albedan](https://www.kaggle.com/albedan)
> 
> 
> 
> Bu bÃ¶lÃ¼mÃ¼n ikinci rÃ¶portajÄ±, Ä°talyan kredi kartÄ± ve dijital Ã¶deme ÅŸirketi Nexiâ€™de Veri Bilimi MÃ¼dÃ¼rÃ¼ olan Alberto Danese ile. 2015 yÄ±lÄ±nda Kaggleâ€™a katÄ±lmÄ±ÅŸ bir **Competitions Grandmaster** olan Danese, Ã§oÄŸu altÄ±n madalyasÄ±nÄ± bireysel olarak kazanmÄ±ÅŸtÄ±r.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z hangisi ve neden? Kaggleâ€™da teknik ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Finans sektÃ¶rÃ¼nde Ã§alÄ±ÅŸtÄ±m ve Ã§oÄŸunlukla yapÄ±landÄ±rÄ±lmÄ±ÅŸ verilerle ilgilendim, bu nedenle bu kategoriye ait yarÄ±ÅŸmalarÄ± tercih ediyorum. Verinin ne hakkÄ±nda olduÄŸunu pratik olarak anlamak ve veriden her bir bilgiyi Ã§Ä±karmak iÃ§in akÄ±llÄ±ca Ã¶zellik mÃ¼hendisliÄŸi yapmaktan keyif alÄ±yorum.
> 
> Teknik aÃ§Ä±dan, klasik ML kÃ¼tÃ¼phaneleri ve Ã¶zellikle **Gradient Boosting Decision Trees** konusunda deneyimim var: en yaygÄ±n kÃ¼tÃ¼phaneler (**XGBoost, LightGBM, CatBoost**) her zaman ilk tercihimdir.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±klarÄ±nÄ±zdan ne kadar farklÄ±?**
> 
> Veriyi keÅŸfetmeye ve sponsorun makine Ã¶ÄŸrenimi ile gerÃ§ekten Ã§Ã¶zmek istediÄŸi problemi anlamaya Ã§ok zaman harcarÄ±m. Yeni baÅŸlayanlarÄ±n dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼n aksine, ML algoritmasÄ±nÄ±n spesifik â€œayarlamalarÄ±â€na fazla zaman harcamam â€“ ve gÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re bu yaklaÅŸÄ±m iÅŸe yarÄ±yor!
> 
> GÃ¼nlÃ¼k iÅŸimde veri anlayÄ±ÅŸÄ± da Ã§ok Ã¶nemli, ancak Kaggle yarÄ±ÅŸmalarÄ±nda tamamen eksik olan bazÄ± ek aÅŸamalar var:
> 
> 
> 
> * ML ile Ã§Ã¶zÃ¼lmesi gereken bir iÅŸ problemi tanÄ±mlamak (iÅŸ birimindeki meslektaÅŸlarla birlikte)
> 
> * Veriyi bulmak, bazen harici veri saÄŸlayÄ±cÄ±lardan da
> 
> * ML kÄ±smÄ± tamamlandÄ±ÄŸÄ±nda, bunu Ã¼retime almak ve geliÅŸimlerini yÃ¶netmek
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zor bir yarÄ±ÅŸmayÄ± ve bu gÃ¶revi Ã§Ã¶zmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z iÃ§gÃ¶rÃ¼leri anlatÄ±r mÄ±sÄ±nÄ±z?**
> 
> Grandmaster olduÄŸum **TalkingData AdTracking Fraud Detection Challenge** yarÄ±ÅŸmasÄ±nÄ± Ã§ok sevdim. Konu oldukÃ§a ilginÃ§ti (click-farm dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ±yla mÃ¼cadele) ve bÃ¼yÃ¼k hacimler (100Mâ€™den fazla etiketli satÄ±r) nedeniyle verimli Ã¶zellik mÃ¼hendisliÄŸi yapmamÄ± zorunlu kÄ±ldÄ±. AyrÄ±ca, farklÄ± yaklaÅŸÄ±mlarÄ± test etmek iÃ§in hesaplama sÃ¼relerini azaltmak ve lag/lead Ã¶zellikleri ile diÄŸer pencere fonksiyonlarÄ±nÄ± en iyi ÅŸekilde kullanarak klasik bir ML problemine zaman serisi benzeri bir yapÄ± kazandÄ±rmak zorundaydÄ±m.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? NasÄ±l?**
> 
> Kesinlikle! BÃ¼yÃ¼k ve doÄŸrulanabilir sonuÃ§lar elde edebilmek, Ã¶zgeÃ§miÅŸte Ã¶ne Ã§Ä±kmanÄ±zÄ± saÄŸlar. 2016â€™da Cerved (bir pazarlama istihbarat ÅŸirketi) tarafÄ±ndan iÅŸe alÄ±ndÄ±ÄŸÄ±mda, iÅŸe alÄ±m yÃ¶neticisi Kaggleâ€™Ä±n ne olduÄŸunu Ã§ok iyi biliyordu â€“ ve gÃ¶rÃ¼ÅŸmede gerÃ§ek dÃ¼nya projelerinden bahsedebilmek Ã§ok deÄŸerliydi. Kesinlikle Kaggle, kariyerimin geliÅŸiminde Ã¶nemli bir rol oynadÄ±.
> 
> 
> 
> **Deneyiminize gÃ¶re, acemi Kagglers genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? Ä°lk baÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz iyi olurdu dediÄŸiniz ÅŸey nedir?**
> 
> Herkesin genellikle kodlamaya baÅŸladÄ±ÄŸÄ±nÄ±, bir public kernelâ€™i forkladÄ±ÄŸÄ±nÄ± ve birkaÃ§ satÄ±r veya parametre deÄŸiÅŸtirdiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. BaÅŸlangÄ±Ã§ta bu tamamen normal! Ancak kodlamadan Ã¶nce veriyi incelemeye ve problemi anlamaya ciddi zaman ayÄ±rmak gerekir.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdir?**
> 
> Belki hata sayÄ±lmaz ama genellikle solo yarÄ±ÅŸmayÄ± tercih ettim: bir yandan her yÃ¶nÃ¼yle ilgilenmek zorunda olduÄŸunuz iÃ§in iyi, zamanÄ±nÄ±zÄ± istediÄŸiniz gibi yÃ¶netebilirsiniz. Ancak birkaÃ§ yarÄ±ÅŸmada takÄ±m arkadaÅŸlarÄ±yla Ã§alÄ±ÅŸmak da Ã§ok keyifliydi; muhtemelen daha sÄ±k takÄ±m kurmayÄ± dÃ¼ÅŸÃ¼nmeliyim, Ã§Ã¼nkÃ¼ iÅŸ birliÄŸi Ã§ok ÅŸey Ã¶ÄŸretiyor.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenimi iÃ§in Ã¶nerdiÄŸiniz Ã¶zel araÃ§ veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> AlÄ±ÅŸÄ±lmÄ±ÅŸlarÄ±n dÄ±ÅŸÄ±nda, her zaman **data.table** (R versiyonundan itibaren) hayranÄ± oldum: yeterince takdir edilmiyor bence! BÃ¼yÃ¼k veriyle yerel bir makinede Ã§alÄ±ÅŸmak iÃ§in gerÃ§ekten harika bir paket.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Ã–nce problemi ve veriyi anlayÄ±n: hemen kodlamaya baÅŸlamayÄ±n!

### Bayesian optimization *(Bayesyen optimizasyon)*

Grid searchâ€™Ã¼ geride bÄ±raktÄ±ÄŸÄ±mÄ±zda (ki bu yalnÄ±zca deney alanÄ± sÄ±nÄ±rlÄ± olduÄŸunda uygulanabilir), uygulayÄ±cÄ±larÄ±n genellikle tercih ettiÄŸi yÃ¶ntem **random search optimizasyonu** uygulamak veya daha karmaÅŸÄ±k bir kurulum gerektiren **Bayesian optimizasyon (BO)** tekniÄŸini denemektir.

Bayesian optimizasyon kavramÄ±, Snoek, J., Larochelle, H. ve Adams, R. P. tarafÄ±ndan **â€œPractical Bayesian Optimization of Machine Learning Algorithmsâ€** ([http://export.arxiv.org/pdf/1206.2944](http://export.arxiv.org/pdf/1206.2944)) adlÄ± makalede tanÄ±tÄ±lmÄ±ÅŸtÄ±r. Temel fikir ÅŸudur: **GerÃ§ek amaÃ§ fonksiyonu yerine bir vekil fonksiyon (surrogate function) optimize edilir**. Grid search ve random search ise doÄŸrudan gerÃ§ek amaÃ§ fonksiyonunu optimize eder. Bu yaklaÅŸÄ±m, gradyanlar yoksa, gerÃ§ek amaÃ§ fonksiyonunu test etmek maliyetliyse (aksi takdirde random search tercih edilir) veya arama alanÄ± karmaÅŸÄ±k ve gÃ¼rÃ¼ltÃ¼lÃ¼ ise kullanÄ±lÄ±r.

Bayesian arama, **keÅŸif (exploration)** ile **sÃ¶mÃ¼rÃ¼ (exploitation)** arasÄ±nda bir denge kurar. BaÅŸlangÄ±Ã§ta rastgele keÅŸif yaparak vekil fonksiyonu eÄŸitir. Bu vekil fonksiyon temel alÄ±narak, arama, tahminleyicinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair ilk yaklaÅŸÄ±k bilgiyi kullanarak daha faydalÄ± Ã¶rnekler seÃ§er ve maliyet fonksiyonunu minimize eder. Bayesian yaklaÅŸÄ±mÄ± adÄ±nda belirtildiÄŸi gibi, optimizasyon sÄ±rasÄ±nda daha akÄ±llÄ±ca kararlar almak iÃ§in **Ã¶ncÃ¼l bilgiler (priors)** kullanÄ±lÄ±r. BÃ¶ylece, gerekli deÄŸerlendirme sayÄ±sÄ±nÄ± sÄ±nÄ±rlayarak minimizasyon daha hÄ±zlÄ± gerÃ§ekleÅŸtirilir.

Bayesian optimizasyon, bir gÃ¶zlemin ne kadar faydalÄ± olacaÄŸÄ±nÄ± belirlemek iÃ§in bir **acquisition function (edinim fonksiyonu)** kullanÄ±r. KeÅŸif ve sÃ¶mÃ¼rÃ¼ arasÄ±ndaki dengeyi yÃ¶netmek iÃ§in algoritma, herhangi bir noktanÄ±n denenmesinin ne kadar faydalÄ± olacaÄŸÄ±nÄ± tek bir Ã¶lÃ§Ã¼ ile saÄŸlar.

Genellikle Bayesian optimizasyon **Gaussian sÃ¼reÃ§leri (Gaussian processes)** ile desteklenir. Gaussian sÃ¼reÃ§leri, arama alanÄ± dÃ¼zgÃ¼n ve tahmin edilebilir bir yanÄ±t verdiÄŸinde daha iyi performans gÃ¶sterir. Arama alanÄ± daha karmaÅŸÄ±ksa, alternatif olarak **aÄŸaÃ§ algoritmalarÄ±** (Ã¶r. random forests) veya tamamen farklÄ± bir yaklaÅŸÄ±m olan **Tree Parzen Estimators (TPE)** / **Tree-structured Parzen Estimators** kullanÄ±labilir.

TPEâ€™ler, parametrelerin baÅŸarÄ±sÄ±nÄ± tahmin eden bir model kurmak yerine, deneylerden elde edilen ardÄ±ÅŸÄ±k yaklaÅŸÄ±mlara dayanarak **en iyi performans gÃ¶steren parametrelerin Ã§ok deÄŸiÅŸkenli daÄŸÄ±lÄ±mÄ±nÄ± tahmin eder**. BÃ¶ylece TPEâ€™ler, parametreleri doÄŸrudan bir ML modeli Ã¼zerinden (Gaussian sÃ¼reÃ§leri gibi) almak yerine, olasÄ±lÄ±ksal bir daÄŸÄ±lÄ±mdan Ã¶rnekleyerek en iyi parametre setini elde eder.

Bu yaklaÅŸÄ±mlarÄ± inceleyeceÄŸiz: Ã¶nce **Gaussian sÃ¼reÃ§lerine dayalÄ±** Scikit-optimize ve KerasTuner (Scikit-optimize ayrÄ±ca random forests, KerasTuner ise multi-armed bandits kullanabilir), ardÄ±ndan esas olarak **TPE tabanlÄ± Optuna** (farklÄ± stratejiler de sunar: [https://optuna.readthedocs.io/en/stable/reference/samplers.html](https://optuna.readthedocs.io/en/stable/reference/samplers.html)) ele alÄ±nacak.

> Bayesian optimizasyon, hiperparametre ayarlamada **en geliÅŸmiÅŸ yÃ¶ntem** olarak kabul edilse de, daha karmaÅŸÄ±k parametre alanlarÄ±nda zaman ve hesaplama aÃ§Ä±sÄ±ndan **random search ile bulunan bir Ã§Ã¶zÃ¼me gÃ¶re avantaj saÄŸlamayabileceÄŸini** unutmamak gerekir. Ã–rneÄŸin Google Cloud Machine Learning Engine hizmetlerinde Bayesian optimizasyon, en fazla 16 parametreli problemlerle sÄ±nÄ±rlÄ±dÄ±r; daha fazla parametre olduÄŸunda **random sampling** kullanÄ±lÄ±r.

#### Using Scikit-optimize *(Scikit-optimize kullanÄ±mÄ±)*

Scikit-optimize (skopt), **Scikit-learn ile aynÄ± API kullanÄ±larak geliÅŸtirilmiÅŸ** ve **NumPy ile SciPy fonksiyonlarÄ±ndan yoÄŸun ÅŸekilde yararlanÄ±lmÄ±ÅŸtÄ±r**. AyrÄ±ca, Scikit-learn projesine katkÄ±da bulunan bazÄ± kiÅŸiler (Ã¶r. Gilles Louppe) tarafÄ±ndan oluÅŸturulmuÅŸtur.

Gaussian sÃ¼reÃ§ algoritmalarÄ±na dayalÄ± bu paket, iyi bir ÅŸekilde bakÄ±m yapÄ±lmaktadÄ±r; ancak bazen Scikit-learn, NumPy veya SciPy tarafÄ±ndaki gÃ¼ncellemeleri yakalamak iÃ§in geri kalmasÄ± gerekebilir. Ã–rneÄŸin yazÄ±m sÄ±rasÄ±nda, Kaggle Notebooks Ã¼zerinde dÃ¼zgÃ¼n Ã§alÄ±ÅŸtÄ±rmak iÃ§in bu paketlerin eski sÃ¼rÃ¼mlerine dÃ¶nmek gerekebilir (detaylar GitHubâ€™da: [https://github.com/scikit-optimize/scikit-optimize/issues/981](https://github.com/scikit-optimize/scikit-optimize/issues/981)).

Paket **sezgisel bir APIâ€™ye sahiptir** ve iÅŸlevlerini kendi optimizasyon stratejilerinizde kullanmak oldukÃ§a kolaydÄ±r. Skopt ayrÄ±ca **grafiksel gÃ¶rselleÅŸtirmeleriyle** de tanÄ±nÄ±r. Ã–rneÄŸin, optimizasyon sÃ¼recinin sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirerek (`plot_objective` fonksiyonu ile) arama alanÄ±nÄ± yeniden tanÄ±mlayÄ±p, optimizasyonun problem iÃ§in nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± aÃ§Ä±klayabilirsiniz.

Ã–rnekler iÃ§in baÅŸvurulan Kaggle Notebooks:

* [https://www.kaggle.com/lucamassaron/tutorial-bayesian-optimization-with-lightgbm](https://www.kaggle.com/lucamassaron/tutorial-bayesian-optimization-with-lightgbm)
* [https://www.kaggle.com/lucamassaron/scikit-optimize-for-lightgbm](https://www.kaggle.com/lucamassaron/scikit-optimize-for-lightgbm)

Bu Ã¶rnekte, **30 Days of ML** yarÄ±ÅŸmasÄ± Ã¼zerinden bir optimizasyon problemini nasÄ±l hÄ±zlÄ±ca Ã§Ã¶zebileceÄŸimizi gÃ¶stereceÄŸiz. Bu yarÄ±ÅŸma, katÄ±lÄ±mcÄ±lara yeni beceriler kazandÄ±rmayÄ± ve 30 gÃ¼n sÃ¼ren bir yarÄ±ÅŸmada uygulamayÄ± amaÃ§lamaktadÄ±r. YarÄ±ÅŸma, bir sigorta talebinin deÄŸerini tahmin etmeyi hedeflediÄŸi iÃ§in **regresyon problemi** olarak sÄ±nÄ±flandÄ±rÄ±lÄ±r. Daha fazla bilgi ve veri indirmek iÃ§in: [https://www.kaggle.com/thirty-days-of-ml](https://www.kaggle.com/thirty-days-of-ml)

---

* AdÄ±m 1: KÃ¼tÃ¼phaneleri yÃ¼klemek

```python
# Temel kÃ¼tÃ¼phaneler
import numpy as np
import pandas as pd
from time import time
import pprint
import joblib
from functools import partial

# UyarÄ±larÄ± gizlemek
import warnings
warnings.filterwarnings("ignore")

# SÄ±nÄ±flandÄ±rÄ±cÄ±lar
import lightgbm as lgb

# Model seÃ§imi
from sklearn.model_selection import KFold

# Metrikler
from sklearn.metrics import mean_squared_error, make_scorer

# Skopt fonksiyonlarÄ±
from skopt import BayesSearchCV
from skopt.callbacks import DeadlineStopper, DeltaYStopper
from skopt.space import Real, Categorical, Integer
```

* AdÄ±m 2: Veriyi yÃ¼klemek ve hazÄ±rlamak

```python
# Veriyi yÃ¼kleme
X = pd.read_csv("../input/30-days-of-ml/train.csv")
X_test = pd.read_csv("../input/30-days-of-ml/test.csv")

# Hedef ve indeks ayarlama
y = X.target
X = X.set_index('id').drop('target', axis='columns')
X_test = X_test.set_index('id')

# Kategorik verileri sayÄ±sal hale getirme
categoricals = [item for item in X.columns if 'cat' in item]
cat_values = np.unique(X[categoricals].values)
cat_dict = dict(zip(cat_values, range(len(cat_values))))
X[categoricals] = X[categoricals].replace(cat_dict).astype('category')
X_test[categoricals] = X_test[categoricals].replace(cat_dict).astype('category')
```

* AdÄ±m 3: Raporlama fonksiyonunu tanÄ±mlamak

```python
def report_perf(optimizer, X, y, title="model", callbacks=None):
    """
    Optimizer performansÄ±nÄ± ve sÃ¼reyi raporlamak iÃ§in bir wrapper
    """
    start = time()
    if callbacks is not None:
        optimizer.fit(X, y, callback=callbacks)
    else:
        optimizer.fit(X, y)
    
    d = pd.DataFrame(optimizer.cv_results_)
    best_score = optimizer.best_score_
    best_score_std = d.iloc[optimizer.best_index_].std_test_score
    best_params = optimizer.best_params_
    
    print((title + " took %.2f seconds, candidates checked: %d, best CV score: %.3f Â± %.3f") %
          (time() - start, len(optimizer.cv_results_['params']), best_score, best_score_std))
    print('Best parameters:')
    pprint.pprint(best_params)
    print()
    
    return best_params
```

* AdÄ±m 4: DeÄŸerlendirme metriÄŸi, doÄŸrulama stratejisi ve model

```python
scoring = make_scorer(partial(mean_squared_error, squared=False), greater_is_better=False)
kf = KFold(n_splits=5, shuffle=True, random_state=0)

reg = lgb.LGBMRegressor(
    boosting_type='gbdt',
    metric='rmse',
    objective='regression',
    n_jobs=1,
    verbose=-1,
    random_state=0
)
```

* AdÄ±m 5: Hiperparametre arama alanÄ±nÄ± tanÄ±mlamak

```python
search_spaces = {
    'learning_rate': Real(0.01, 1.0, 'log-uniform'),
    'n_estimators': Integer(30, 5000),
    'num_leaves': Integer(2, 512),
    'max_depth': Integer(-1, 256),
    'min_child_samples': Integer(1, 256),
    'max_bin': Integer(100, 1000),
    'subsample': Real(0.01, 1.0, 'uniform'),
    'subsample_freq': Integer(0, 10),
    'colsample_bytree': Real(0.01, 1.0, 'uniform'),
    'min_child_weight': Real(0.01, 10.0, 'uniform'),
    'reg_lambda': Real(1e-9, 100.0, 'log-uniform'),
    'reg_alpha': Real(1e-9, 100.0, 'log-uniform'),
}
```

* AdÄ±m 6: Bayesian optimizasyonunu baÅŸlatmak

```python
opt = BayesSearchCV(
    estimator=reg,
    search_spaces=search_spaces,
    scoring=scoring,
    cv=kf,
    n_iter=60,           # Maksimum deneme sayÄ±sÄ±
    n_jobs=-1,           # Ä°ÅŸlem sayÄ±sÄ±
    iid=False,           # CV skoruna gÃ¶re optimize et
    return_train_score=False,
    refit=False,
    optimizer_kwargs={'base_estimator': 'GP'},  # Gaussian Processes
    random_state=0
)

# Kontroller
overdone_control = DeltaYStopper(delta=0.0001)   # KazanÃ§ Ã§ok az ise dur
time_limit_control = DeadlineStopper(total_time=60*60*6)  # 6 saat limit

best_params = report_perf(opt, X, y, 'LightGBM_regression',
                          callbacks=[overdone_control, time_limit_control])
```

Bu Ã¶rnekte, **Bayesian optimizasyon** keÅŸif ve sÃ¶mÃ¼rÃ¼ stratejilerini birleÅŸtirdiÄŸi iÃ§in, herhangi bir zamanda durdurulsa bile o ana kadar bulunan **en iyi Ã§Ã¶zÃ¼mÃ¼** dÃ¶ndÃ¼rÃ¼r. Ancak bu, mutlaka **en iyi teorik Ã§Ã¶zÃ¼m** olduÄŸu anlamÄ±na gelmez; Ã§Ã¼nkÃ¼ acquisition function, vekil fonksiyon ve belirsizlik aralÄ±klarÄ±na gÃ¶re **en umut verici bÃ¶lgeleri Ã¶nceliklendirir**.

#### Customizing a Bayesian optimization search *(Bayesyen aramayÄ± Ã¶zelleÅŸtirme)*

Scikit-optimize tarafÄ±ndan sunulan **BayesSearchCV** fonksiyonu kesinlikle kullanÄ±ÅŸlÄ±dÄ±r; Ã§Ã¼nkÃ¼ bir hiperparametre aramasÄ±nÄ±n tÃ¼m Ã¶ÄŸelerini kendi baÅŸÄ±na sarar ve dÃ¼zenler. Ancak, bazÄ± sÄ±nÄ±rlamalarÄ± da vardÄ±r. Ã–rneÄŸin, bir yarÄ±ÅŸmada ÅŸu durumlarda faydalÄ± olabilir:

* Her arama iterasyonu Ã¼zerinde daha fazla kontrol sahibi olmak (Ã¶rneÄŸin, rastgele arama ile Bayesian aramayÄ± karÄ±ÅŸtÄ±rmak)
* Algoritmalarda erken durdurmayÄ± uygulayabilmek
* DoÄŸrulama stratejinizi daha fazla Ã¶zelleÅŸtirmek
* Ã‡alÄ±ÅŸmayan deneyleri erken durdurmak (Ã¶rneÄŸin, tÃ¼m katlarÄ±n ortalamasÄ±nÄ± beklemek yerine, tek bir Ã§apraz doÄŸrulama katÄ±nÄ±n performansÄ±nÄ± hemen deÄŸerlendirmek)
* Benzer performans gÃ¶steren hiperparametre setlerinden kÃ¼meler oluÅŸturmak (Ã¶rneÄŸin, yalnÄ±zca kullanÄ±lan hiperparametreler farklÄ± olan birden fazla model oluÅŸturmak ve bunlarÄ± bir *blending ensemble* iÃ§in kullanmak)

Bu gÃ¶revlerin her biri, BayesSearchCVâ€™nin dahili prosedÃ¼rÃ¼nÃ¼ deÄŸiÅŸtirebilseydiniz Ã§ok karmaÅŸÄ±k olmazdÄ±. Neyse ki, Scikit-optimize bunu yapmanÄ±za izin veriyor. AslÄ±nda, BayesSearchCVâ€™nin ve paketteki diÄŸer sarÄ±cÄ±larÄ±n arkasÄ±nda, kendi arama fonksiyonunuzun baÄŸÄ±msÄ±z bir parÃ§asÄ± olarak kullanabileceÄŸiniz belirli minimize fonksiyonlarÄ± vardÄ±r:

* **gp_minimize**: Gauss sÃ¼reÃ§leri kullanarak Bayesian optimizasyonu
* **forest_minimize**: Rastgele ormanlar veya aÅŸÄ±rÄ± rastgeleleÅŸtirilmiÅŸ aÄŸaÃ§lar kullanarak Bayesian optimizasyonu
* **gbrt_minimize**: Gradient boosting kullanarak Bayesian optimizasyonu
* **dummy_minimize**: Sadece rastgele arama

AÅŸaÄŸÄ±daki Ã¶rnekte, Ã¶nceki aramayÄ± kendi Ã¶zel arama fonksiyonumuzu kullanarak deÄŸiÅŸtireceÄŸiz. Yeni Ã¶zel fonksiyon, eÄŸitim sÄ±rasÄ±nda erken durdurmayÄ± kabul edecek ve kat doÄŸrulama sonuÃ§larÄ±ndan biri iyi performans gÃ¶stermiyorsa deneyleri budayacaktÄ±r.

> Ã–rneÄŸin Ã§alÄ±ÅŸÄ±r hÃ¢li, Kaggle Notebookâ€™ta bulunabilir: [Hacking Bayesian Optimization](https://www.kaggle.com/lucamassaron/hacking-bayesian-optimization).

Ã–nceki Ã¶rnekte olduÄŸu gibi, gerekli paketleri import ederek baÅŸlÄ±yoruz:

```python
# Temel kÃ¼tÃ¼phaneler
import numpy as np
import pandas as pd
from time import time
import pprint
import joblib
from functools import partial
import warnings
warnings.filterwarnings("ignore")  # skopt verbosity nedeniyle uyarÄ±larÄ± kapatma

# SÄ±nÄ±flandÄ±rÄ±cÄ±/RegresÃ¶r
from xgboost import XGBRegressor

# Model seÃ§imi
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split

# Ã–lÃ§Ã¼tler
from sklearn.metrics import mean_squared_error, make_scorer

# Skopt fonksiyonlarÄ±
from skopt import BayesSearchCV
from skopt.callbacks import DeadlineStopper, DeltaYStopper
from skopt.space import Real, Categorical, Integer
from skopt import gp_minimize, forest_minimize, gbrt_minimize, dummy_minimize
from skopt.utils import use_named_args  # Parametre listesini isimlendirilmiÅŸ argÃ¼manlara Ã§eviren decorator

# Veri iÅŸleme
from sklearn.preprocessing import OrdinalEncoder
```

Verileri, **30 Days of ML** yarÄ±ÅŸmasÄ±ndan yÃ¼kleyelim:

```python
X_train = pd.read_csv("../input/30-days-of-ml/train.csv")
X_test = pd.read_csv("../input/30-days-of-ml/test.csv")

y_train = X_train.target
X_train = X_train.set_index('id').drop('target', axis='columns')
X_test = X_test.set_index('id')

# Kategorik deÄŸiÅŸkenleri belirleme
categoricals = [item for item in X_train.columns if 'cat' in item]

# Kategorik verileri OrdinalEncoder ile iÅŸleme
ordinal_encoder = OrdinalEncoder()
X_train[categoricals] = ordinal_encoder.fit_transform(X_train[categoricals])
X_test[categoricals] = ordinal_encoder.transform(X_test[categoricals])
```

Åimdi hiperparametre aramasÄ± iÃ§in gerekli tÃ¼m Ã¶ÄŸeleri ayarlÄ±yoruz: scoring fonksiyonu, doÄŸrulama stratejisi, arama alanÄ± ve optimize edilecek makine Ã¶ÄŸrenimi modeli. Scoring fonksiyonu ve doÄŸrulama stratejisi, daha sonra Bayesian optimizasyonunun minimize etmeye Ã§alÄ±ÅŸacaÄŸÄ± **objective function**â€™Ä±n temel Ã¶ÄŸeleri olacak:

```python
# Scoring fonksiyonu
scoring = partial(mean_squared_error, squared=False)

# CV stratejisi
kf = KFold(n_splits=5, shuffle=True, random_state=0)

# Arama alanÄ±
space = [
    Real(0.01, 1.0, 'uniform', name='learning_rate'),
    Integer(1, 8, name='max_depth'),
    Real(0.1, 1.0, 'uniform', name='subsample'),
    Real(0.1, 1.0, 'uniform', name='colsample_bytree'),  
    Real(0, 100., 'uniform', name='reg_lambda'),
    Real(0, 100., 'uniform', name='reg_alpha'),
    Real(1, 30, 'uniform', name='min_child_weight')
]

model = XGBRegressor(n_estimators=10_000, booster='gbtree', random_state=0)
```

Bu sefer **n_estimators** parametresini arama alanÄ±na dahil etmedik; bunun yerine model Ã¶rneÄŸi oluÅŸtururken yÃ¼ksek bir deÄŸer verdik, Ã§Ã¼nkÃ¼ modelin erken durdurulmasÄ±nÄ± doÄŸrulama setine gÃ¶re yapmayÄ± planlÄ±yoruz.

---

DevamÄ±nda, objective functionâ€™Ä± tanÄ±mlayacaÄŸÄ±z. Bu fonksiyon, optimize edilecek parametreleri alacak ve skoru dÃ¶ndÃ¼recek. Ancak aynÄ± zamanda hazÄ±rladÄ±ÄŸÄ±nÄ±z arama Ã¶ÄŸelerini de kabul etmelidir. Ä°yi bir uygulama olarak, bu Ã¶ÄŸeleri fonksiyonun iÃ§ine almak daha avantajlÄ±dÄ±r; bÃ¶ylece Ã¶ÄŸeler deÄŸiÅŸmez olur ve fonksiyonla birlikte taÅŸÄ±nabilir.

```python
# Minimize edilecek objective function
def make_objective(model, X, y, space, cv, scoring, validation=0.2):
    @use_named_args(space)
    def objective(**params):
        model.set_params(**params)
        print("\nTesting: ", params)
        validation_scores = list()
        for k, (train_index, test_index) in enumerate(kf.split(X, y)):
            val_index = list()
            train_examples = int(train_examples * (1 - validation))
            train_index, val_index = (train_index[:train_examples], train_index[train_examples:])
            start_time = time()
            model.fit(
                X.iloc[train_index,:], y[train_index],
                early_stopping_rounds=50,
                eval_set=[(X.iloc[val_index,:], y[val_index])], 
                verbose=0
            )
            end_time = time()
            
            rounds = model.best_iteration
            test_preds = model.predict(X.iloc[test_index,:])
            test_score = scoring(y[test_index], test_preds)
            print(f"CV Fold {k+1} rmse:{test_score:0.5f}-{rounds} rounds - it took {end_time-start_time:0.0f} secs")
            validation_scores.append(test_score)

            # Erken durdurma kontrolÃ¼
            if len(history[k]) >= 10:
                threshold = np.percentile(history[k], q=25)
                if test_score > threshold:
                    print(f"Early stopping for under-performing fold: threshold is {threshold:0.5f}")
                    return np.mean(validation_scores)
            history[k].append(test_score)
        return np.mean(validation_scores)
    return objective
```

Bu fonksiyon, veri ve modeli kullanarak Ã§apraz doÄŸrulama yapar ve erken durdurma uygular. Daha sonra tÃ¼m bu Ã¶ÄŸeleri **make_objective** ile birleÅŸtirip yalnÄ±zca parametreleri alan bir fonksiyon elde ediyoruz:

```python
objective = make_objective(model, X_train, y_train, space=space, cv=kf, scoring=scoring)
```

AyrÄ±ca her iterasyonu kaydedecek bir callback fonksiyonu hazÄ±rlÄ±yoruz:

```python
def onstep(res):
    global counter
    x0 = res.x_iters   
    y0 = res.func_vals
    print('Last eval: ', x0[-1], ' - Score ', y0[-1])
    print('Current iter: ', counter, ' - Best Score ', res.fun, ' - Best Args: ', res.x)
    joblib.dump((x0, y0), 'checkpoint.pkl') 
    counter += 1
```

BaÅŸlangÄ±Ã§ iÃ§in rastgele arama ile birkaÃ§ deney oluÅŸturuyoruz:

```python
counter = 0
history = {i:list() for i in range(5)}
used_time = 0

gp_round = dummy_minimize(func=objective,
                          dimensions=space,
                          n_calls=30,
                          callback=[onstep],
                          random_state=0)
```

Kaydedilen deneyleri geri Ã§aÄŸÄ±rabilir ve Bayes optimizasyonunu devam ettirebiliriz:

```python
x0, y0 = joblib.load('checkpoint.pkl')
gp_round = gp_minimize(func=objective,
                       x0=x0,
                       y0=y0,
                       dimensions=space,
                       acq_func='gp_hedge',
                       n_calls=30,
                       n_initial_points=0,
                       callback=[onstep],
                       random_state=0)
```

Son olarak, en iyi skoru ve hiperparametre setini yazdÄ±rabiliriz:

```python
x0, y0 = joblib.load('checkpoint.pkl')
print(f"Best score: {gp_round.fun:0.5f}")
print("Best hyperparameters:")
for sp, x in zip(gp_round.space, gp_round.x):
    print(f"{sp.name:25} : {x}")
```

Bu parametreler ile modelimizi yeniden eÄŸitip yarÄ±ÅŸmada kullanabiliriz. AyrÄ±ca sonuÃ§larÄ± analiz edip benzer performans gÃ¶steren ancak farklÄ± parametre setlerine sahip modelleri gruplayabiliriz; bu da **blending** iÃ§in idealdir ve daha Ã§eÅŸitli bir model seti oluÅŸturur.

#### Extending Bayesian optimization to neural architecture search *(Bayesyen optimizasyonu sinir aÄŸÄ± mimarisi aramasÄ±na geniÅŸletme)*

Derin Ã¶ÄŸrenmeye geÃ§erken, sinir aÄŸlarÄ±nÄ±n da sabitlenmesi gereken oldukÃ§a fazla hiperparametreye sahip olduÄŸunu gÃ¶rebiliyoruz:

* Batch boyutu
* Ã–ÄŸrenme oranÄ±
* KullanÄ±lacak optimizer tÃ¼rÃ¼ ve onun iÃ§ parametreleri

TÃ¼m bu parametreler, aÄŸÄ±n nasÄ±l Ã¶ÄŸrendiÄŸini etkiler ve bÃ¼yÃ¼k bir fark yaratabilir; batch boyutu veya Ã¶ÄŸrenme oranÄ±ndaki kÃ¼Ã§Ã¼k bir deÄŸiÅŸiklik, bir aÄŸÄ±n hatasÄ±nÄ± belirli bir eÅŸikten daha fazla azaltÄ±p azaltamayacaÄŸÄ±nÄ± belirleyebilir.

Bununla birlikte, bu Ã¶ÄŸrenme parametreleri derin sinir aÄŸlarÄ± (DNNâ€™ler) ile Ã§alÄ±ÅŸÄ±rken optimize edebileceÄŸiniz tek ÅŸey deÄŸildir. AÄŸÄ±n katmanlar halinde nasÄ±l organize edildiÄŸi ve mimarisinin detaylarÄ± Ã§ok daha bÃ¼yÃ¼k bir fark yaratabilir.

AslÄ±nda teknik olarak, bir mimari, derin sinir aÄŸÄ±nÄ±n temsil kapasitesini ifade eder; yani kullandÄ±ÄŸÄ±nÄ±z katmanlara baÄŸlÄ± olarak, aÄŸ verilerde mevcut olan tÃ¼m bilgileri okuyup iÅŸleyebilir ya da bunu yapamayabilir. DiÄŸer makine Ã¶ÄŸrenmesi algoritmalarÄ±nda sÄ±nÄ±rlÄ± bir seÃ§im yelpazeniz varken, DNNâ€™lerde seÃ§enekleriniz neredeyse sÄ±nÄ±rsÄ±zdÄ±r, Ã§Ã¼nkÃ¼ tek sÄ±nÄ±rlama, sinir aÄŸlarÄ±nÄ±n parÃ§alarÄ±nÄ± kullanma ve bir araya getirme konusundaki bilgi ve deneyiminizdir.

BaÅŸarÄ±lÄ± derin Ã¶ÄŸrenme uygulayÄ±cÄ±larÄ±nÄ±n iyi performans gÃ¶steren DNNâ€™ler oluÅŸtururken izlediÄŸi bazÄ± yaygÄ±n en iyi uygulamalar ÅŸunlardÄ±r:

* Ã–nceden eÄŸitilmiÅŸ modellere gÃ¼venmek (bÃ¶ylece Hugging Face ([https://huggingface.co/models](https://huggingface.co/models)) veya GitHubâ€™da mevcut Ã§Ã¶zÃ¼mler hakkÄ±nda Ã§ok bilgi sahibi olmalÄ±sÄ±nÄ±z)
* GÃ¼ncel araÅŸtÄ±rma makalelerini okumak
* AynÄ± veya Ã¶nceki yarÄ±ÅŸmalardan en iyi Kaggle Notebooksâ€™u kopyalamak
* Deneme yanÄ±lma yÃ¶ntemi
* YaratÄ±cÄ±lÄ±k ve ÅŸans

ÃœnlÃ¼ ProfesÃ¶r Geoffrey Hintonâ€™Ä±n verdiÄŸi bir derste belirttiÄŸi gibi, Bayes optimizasyonu gibi otomatik yÃ¶ntemleri kullanarak benzer ve Ã§oÄŸu zaman daha iyi sonuÃ§lar elde edebilirsiniz. Bayes optimizasyonu ayrÄ±ca, Ã§ok sayÄ±da hiperparametrenin olasÄ± en iyi kombinasyonlarÄ±nÄ± bulmakta zorlandÄ±ÄŸÄ±nÄ±zda sÄ±kÄ±ÅŸmanÄ±zÄ± Ã¶nler.

Prof. Geoffrey Hintonâ€™Ä±n ders kaydÄ± iÃ§in: [https://www.youtube.com/watch?v=i0cKa0di_lo](https://www.youtube.com/watch?v=i0cKa0di_lo)
Slaytlar iÃ§in: [https://www.cs.toronto.edu/~hinton/coursera/lecture16/lec16.pdf](https://www.cs.toronto.edu/~hinton/coursera/lecture16/lec16.pdf)

Daha Ã¶nce bahsettiÄŸimiz gibi, en sofistike AutoML sistemlerinde bile, hiperparametre sayÄ±sÄ± Ã§ok fazla olduÄŸunda rastgele optimizasyon, Bayes optimizasyonu ile aynÄ± sÃ¼re iÃ§inde daha iyi veya aynÄ± sonuÃ§larÄ± Ã¼retebilir. AyrÄ±ca, bu durumda keskin dÃ¶nÃ¼ÅŸlere ve yÃ¼zeylere sahip bir optimizasyon manzarasÄ±yla mÃ¼cadele etmeniz gerekir; DNN optimizasyonunda parametrelerinizin Ã§oÄŸu sÃ¼rekli deÄŸil, Boolean olabilir ve sadece bir deÄŸiÅŸiklik, aÄŸÄ±n performansÄ±nÄ± beklenmedik ÅŸekilde artÄ±rabilir veya dÃ¼ÅŸÃ¼rebilir.

Rastgele optimizasyon, Kaggle yarÄ±ÅŸmasÄ± iÃ§in genellikle uygun deÄŸildir Ã§Ã¼nkÃ¼:

* ZamanÄ±nÄ±z ve kaynaklarÄ±nÄ±z sÄ±nÄ±rlÄ±dÄ±r
* Daha iyi Ã§Ã¶zÃ¼mler bulmak iÃ§in Ã¶nceki optimizasyon sonuÃ§larÄ±nÄ±zÄ± kullanabilirsiniz

Bu senaryoda Bayes optimizasyonu idealdir: Sahip olduÄŸunuz zaman ve hesaplama kaynaklarÄ±na gÃ¶re Ã§alÄ±ÅŸacak ÅŸekilde ayarlayabilirsiniz ve bunu aÅŸamalÄ± olarak yapabilir, ayarlarÄ±nÄ±zÄ± birden fazla oturumda rafine edebilirsiniz. AyrÄ±ca, gÃ¼Ã§lÃ¼ birden fazla makineniz olmadÄ±kÃ§a DNNâ€™leri optimize etmek iÃ§in paralelliÄŸi kolayca kullanamazsÄ±nÄ±z. Bayes optimizasyonu ise yalnÄ±zca bir iyi makine ile Ã§alÄ±ÅŸabilir. AyrÄ±ca, optimizasyon manzarasÄ± nedeniyle optimal mimarileri bulmak zor olsa da, Ã¶zellikle baÅŸlangÄ±Ã§ta Ã¶nceki deneylerden bilgi edinirsiniz ve Ã§alÄ±ÅŸmayacak parametre kombinasyonlarÄ±nÄ± tamamen Ã¶nlersiniz. Rastgele optimizasyonda ise, arama alanÄ±nÄ± deÄŸiÅŸtirmediÄŸiniz sÃ¼rece, tÃ¼m kombinasyonlar her zaman test edilmeye aÃ§Ä±ktÄ±r.

Bunun da bazÄ± dezavantajlarÄ± vardÄ±r. Bayes optimizasyonu, hiperparametre alanÄ±nÄ± Ã¶nceki denemelerden oluÅŸturulan bir surrogate fonksiyon ile modellemektedir ve bu sÃ¼reÃ§ hatasÄ±z deÄŸildir. SÃ¼recin sadece arama alanÄ±nÄ±n bir kÄ±smÄ±na yoÄŸunlaÅŸmasÄ± ve diÄŸer kÄ±sÄ±mlarÄ± (ki bunlar minimumu iÃ§erebilir) gÃ¶rmezden gelmesi olasÄ±dÄ±r. Ã‡Ã¶zÃ¼m, gÃ¼venli olmak iÃ§in Ã§ok sayÄ±da deney yapmak veya rastgele arama ile Bayes optimizasyonunu alternatif olarak kullanmak ve rastgele denemelerle Bayes modelini daha optimal bir ÅŸekilde yeniden ÅŸekillendirmeye zorlamaktÄ±r.

Ã–rneÄŸimizde, tekrar Kaggleâ€™Ä±n 30 GÃ¼nlÃ¼k ML giriÅŸiminden aldÄ±ÄŸÄ±mÄ±z verileri kullanÄ±yoruz; bu bir regresyon gÃ¶revi. Ã–rneÄŸimiz TensorFlowâ€™a dayanÄ±yor, ama kÃ¼Ã§Ã¼k deÄŸiÅŸikliklerle PyTorch veya MXNet gibi diÄŸer derin Ã¶ÄŸrenme Ã§erÃ§evelerinde de Ã§alÄ±ÅŸabilir.

Ã–ncelikle:

```python
import tensorflow as tf
```

TensorFlow paketini iÃ§e aktardÄ±ktan sonra, Dataset fonksiyonunu kullanarak sinir aÄŸÄ±mÄ±za veri besleyen iterable bir yapÄ± oluÅŸturuyoruz:

```python
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
    dataframe = dataframe.copy()
    labels = dataframe.pop('target')
    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
    if shuffle:
        ds = ds.shuffle(buffer_size=len(dataframe))
    ds = ds.batch(batch_size)
    return ds
```

AyrÄ±ca, leaky ReLU aktivasyonunu modelimiz iÃ§in Ã¶zel bir nesne olarak tanÄ±mladÄ±k; bu sayede string olarak Ã§aÄŸÄ±rabilir ve doÄŸrudan fonksiyonu kullanmanÄ±za gerek kalmaz:

```python
tf.keras.utils.get_custom_objects().update(
    {'leaky-relu': tf.keras.layers.Activation(tf.keras.layers.LeakyReLU(alpha=0.2))}
)
```

ArdÄ±ndan, hiperparametrelere baÄŸlÄ± olarak derin sinir aÄŸÄ±mÄ±zÄ± oluÅŸturan bir fonksiyon yazÄ±yoruz:

```python
def create_model(cat0_dim, cat1_dim, ..., layers, layer_1, ..., layer_5,
                 activation, dropout, batch_normalization, learning_rate, **others):
    dims = {'cat0': cat0_dim, 'cat1': cat1_dim, ..., 'cat9': cat9_dim}
    vocab = {h:X_train['cat4'].unique().astype(int) for h in ['cat0', ..., 'cat9']}
    layers = [layer_1, layer_2, layer_3, layer_4, layer_5][:layers]
    feature_columns = list()
    for header in ['cont1', ..., 'cont13']:
        feature_columns.append(tf.feature_column.numeric_column(header))
    for header in ['cat0', ..., 'cat9']:
        feature_columns.append(tf.feature_column.embedding_column(
            tf.feature_column.categorical_column_with_vocabulary_list(
                header, vocabulary_list=vocab[header]), dimension=dims[header]))
    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)
    network_struct = [feature_layer]
    for nodes in layers:
        network_struct.append(tf.keras.layers.Dense(nodes, activation=activation))
    if batch_normalization:
        network_struct.append(tf.keras.layers.BatchNormalization())
    if dropout > 0:
        network_struct.append(tf.keras.layers.Dropout(dropout))
    model = tf.keras.Sequential(network_struct + [tf.keras.layers.Dense(1)])
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=tf.keras.losses.MeanSquaredError(),
                  metrics=['mean_squared_error'])
    return model
```

`create_model` fonksiyonu, iÃ§ parametreler aracÄ±lÄ±ÄŸÄ±yla aÄŸ mimarisini Ã¶zelleÅŸtirir. Ã–rneÄŸin, her kategorik deÄŸiÅŸkenin embedding boyutunu veya aÄŸdaki dense katman sayÄ±sÄ±nÄ± tanÄ±mlayabilirsiniz. TÃ¼m bu parametreler Bayes optimizasyonu tarafÄ±ndan keÅŸfedilecek parametre alanÄ±yla ilgilidir.

ArdÄ±ndan, bu parametreleri bir listeye yerleÅŸtiriyoruz ve `create_model` fonksiyonunun beklediÄŸi sÄ±raya uygun hale getiriyoruz:

```python
space = [Integer(1, 2, name='cat0_dim'),
         Integer(1, 2, name='cat1_dim'),
         ...,
         Categorical([0.01, 0.005, 0.002, 0.001], name='learning_rate'),
         Integer(256, 1024, name='batch_size')]
```

Sonraki adÄ±m, tÃ¼m arama ile ilgili unsurlarÄ± objective fonksiyonunda birleÅŸtirmektir:

```python
def make_objective(model_fn, X, space, cv, scoring, validation=0.2):
    @use_named_args(space) 
    def objective(**params):
        print("\nTesting: ", params)
        validation_scores = list()
        for k, (train_index, test_index) in enumerate(kf.split(X)):
            val_index = list()
            train_examples = int(len(train_index) * (1 - validation))
            train_index, val_index = train_index[:train_examples], train_index[train_examples:]
            start_time = time()
            model = model_fn(**params)
            early_stopping = tf.keras.callbacks.EarlyStopping(
                monitor='val_mean_squared_error', mode='min', patience=5, verbose=0)
            model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
                'best.model', monitor='val_mean_squared_error', mode='min', save_best_only=True, verbose=0)
            run = model.fit(df_to_dataset(X_train.iloc[train_index, :], batch_size=params['batch_size']),
                            validation_data=df_to_dataset(X_train.iloc[val_index, :], batch_size=1024),
                            epochs=1_000,
                            callbacks=[model_checkpoint, early_stopping],
                            verbose=0)
            end_time = time()
            rounds = np.argmin(run.history['val_mean_squared_error']) + 1
            model = tf.keras.models.load_model('best.model')
            shutil.rmtree('best.model')
            test_preds = model.predict(df_to_dataset(X.iloc[test_index, :], shuffle=False, batch_size=1024)).flatten()
            test_score = scoring(X.iloc[test_index, :]['target'], test_preds)
            print(f"CV Fold {k+1} rmse:{test_score:0.5f} - {rounds} rounds - it took {end_time-start_time:0.0f} secs")
            validation_scores.append(test_score)
        return np.mean(validation_scores)
    return objective
```

Ä°lk olarak rastgele arama ile bazÄ± sonuÃ§lar toplarÄ±z, ardÄ±ndan Bayes optimizasyonunu baÅŸlatÄ±rÄ±z ve `forest_minimize` kullanÄ±rÄ±z:

```python
gp_round = dummy_minimize(func=objective, dimensions=space, n_calls=10, callback=[onstep], random_state=0)
x0, y0 = joblib.load('checkpoint.pkl')
gp_round = gp_minimize(func=objective, x0=x0, y0=y0, dimensions=space, n_calls=30, n_initial_points=0, callback=[onstep], random_state=0)
```

Ä°lk on tur rastgele aramadan sonra, rastgele orman algoritmasÄ±nÄ± surrogate fonksiyon olarak kullanÄ±yoruz; bu, Gaussian sÃ¼reÃ§ kullanÄ±mÄ±na kÄ±yasla daha iyi ve hÄ±zlÄ± sonuÃ§ saÄŸlar.

Optimizasyon sÃ¼recini zaman ve kaynaklarÄ±mÄ±za uygun hale getirmek iÃ§in (`n_calls` deÄŸerini dÃ¼ÅŸÃ¼k tutmak gibi) arama iterasyonlarÄ±nÄ± partiler halinde yÃ¼rÃ¼tebilir, optimizasyonun durumunu kaydedebilir ve elde edilen sonuÃ§larÄ± kontrol ederek devam veya sonlandÄ±rma kararÄ± alabiliriz.

#### Creating lighter and faster models with KerasTuner *(KerasTuner ile daha hafif ve hÄ±zlÄ± modeller oluÅŸturma)*

Ã–nceki bÃ¶lÃ¼m karmaÅŸÄ±klÄ±ÄŸÄ± nedeniyle sizi ÅŸaÅŸÄ±rtmÄ±ÅŸ olabilir; KerasTuner, optimizasyonu zahmetsiz bir ÅŸekilde kurmanÄ±z iÃ§in hÄ±zlÄ± bir Ã§Ã¶zÃ¼m sunabilir. Her ne kadar varsayÄ±lan olarak Bayes optimizasyonu ve Gauss sÃ¼reÃ§lerini kullansa da, KerasTunerâ€™Ä±n yeni fikri **Hyperband optimizasyonu**dur. Hyperband optimizasyonu, en iyi parametreleri bulmak iÃ§in **bandit yaklaÅŸÄ±mÄ±nÄ±** kullanÄ±r (bkz. [http://web.eecs.umich.edu/~mosharaf/Readings/HyperBand.pdf](http://web.eecs.umich.edu/~mosharaf/Readings/HyperBand.pdf)). Bu yÃ¶ntem, optimizasyon yÃ¼zeyi oldukÃ§a dÃ¼zensiz ve kesintili olan sinir aÄŸlarÄ±nda oldukÃ§a iyi Ã§alÄ±ÅŸÄ±r; dolayÄ±sÄ±yla her zaman Gauss sÃ¼reÃ§leri iÃ§in uygun deÄŸildir.

UnutmayÄ±n ki, Ã¶zel bir aÄŸ oluÅŸturan fonksiyonu yazmaktan kaÃ§Ä±namazsÄ±nÄ±z; KerasTuner sadece bunu yÃ¶netmeyi Ã§ok daha kolay hale getirir.

BaÅŸlangÄ±Ã§tan baÅŸlayalÄ±m. KerasTuner ([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)) FranÃ§ois Chollet tarafÄ±ndan â€œKeras modelleri iÃ§in esnek ve verimli hiperparametre ayarlamaâ€ olarak duyurulmuÅŸtur.

Cholletâ€™in Ã¶nerdiÄŸi KerasTuner Ã§alÄ±ÅŸma tarifi, mevcut Keras modelinizden baÅŸlamak Ã¼zere basit adÄ±mlardan oluÅŸur:

1. Modelinizi **hp** parametresi ile bir fonksiyon iÃ§ine sarÄ±n.
2. Fonksiyonun baÅŸÄ±nda hiperparametreleri tanÄ±mlayÄ±n.
3. DNNâ€™deki statik deÄŸerleri hiperparametrelerle deÄŸiÅŸtirin.
4. Verilen hiperparametrelerden karmaÅŸÄ±k bir sinir aÄŸÄ± modelleyen kodu yazÄ±n.
5. Gerekirse, aÄŸÄ± inÅŸa ederken hiperparametreleri dinamik olarak tanÄ±mlayÄ±n.

Åimdi bu adÄ±mlarÄ±n bir Kaggle yarÄ±ÅŸmasÄ±nda nasÄ±l Ã§alÄ±ÅŸabileceÄŸini bir Ã¶rnek Ã¼zerinden inceleyeceÄŸiz. Åu anda KerasTuner, herhangi bir Kaggle Notebookâ€™un sunduÄŸu yÄ±ÄŸÄ±n iÃ§inde yer alÄ±r; dolayÄ±sÄ±yla kurulum yapmanÄ±z gerekmez. AyrÄ±ca, TensorFlow eklentileri de Notebookâ€™larda Ã¶nceden yÃ¼klÃ¼dÃ¼r.

---

EÄŸer Kaggle Notebook kullanmÄ±yorsanÄ±z ve KerasTunerâ€™Ä± denemek istiyorsanÄ±z, her ikisini de ÅŸu komutlarla kolayca yÃ¼kleyebilirsiniz:

```bash
!pip install -U keras-tuner
!pip install -U tensorflow-addons
```

Ã–rneÄŸin Ã¶nceden hazÄ±rlanmÄ±ÅŸ Kaggle Notebook versiyonunu burada bulabilirsiniz: [https://www.kaggle.com/lucamassaron/kerastuner-for-imdb/](https://www.kaggle.com/lucamassaron/kerastuner-for-imdb/).

Ä°lk adÄ±m olarak gerekli paketleri iÃ§e aktaralÄ±m ve Kerasâ€™tan kullanacaÄŸÄ±mÄ±z veriyi yÃ¼kleyelim:

```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import tensorflow_addons as tfa
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LeakyReLU, Activation
from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

pad_sequences = keras.preprocessing.sequence.pad_sequences

imdb = keras.datasets.imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)

train_data, val_data, train_labels, val_labels = train_test_split(
    train_data, train_labels, test_size=0.30, shuffle=True, random_state=0
)
```

---

Bu Ã¶rnekte **IMDb veri setini** kullanÄ±yoruz; Keras paketinde mevcuttur ([https://keras.io/api/datasets/imdb/](https://keras.io/api/datasets/imdb/)). Veri setinin bazÄ± ilginÃ§ Ã¶zellikleri ÅŸunlardÄ±r:

* 25.000 IMDb film yorumundan oluÅŸur.
* Yorumlar duygu etiketine sahiptir (pozitif/negatif).
* Hedef sÄ±nÄ±flar dengelidir (dolayÄ±sÄ±yla doÄŸruluk iyi bir Ã¶lÃ§Ã¼t olarak kullanÄ±labilir).
* Her yorum, kelime indeksleri listesi (tamsayÄ±lar) olarak kodlanmÄ±ÅŸtÄ±r.
* KolaylÄ±k iÃ§in kelimeler, genel frekanslarÄ±na gÃ¶re indekslenmiÅŸtir.

AyrÄ±ca bu veri seti, popÃ¼ler bir Kaggle yarÄ±ÅŸmasÄ±nda da kullanÄ±lmÄ±ÅŸtÄ±r: [https://www.kaggle.com/c/word2vec-nlp-tutorial/overview](https://www.kaggle.com/c/word2vec-nlp-tutorial/overview).

Bu Ã¶rnek **doÄŸal dil iÅŸleme (NLP)** iÃ§erir. Bu tÃ¼r problemler genellikle LSTM veya GRU katmanlarÄ±na dayalÄ± **tekrarlayan sinir aÄŸlarÄ± (RNN)** ile Ã§Ã¶zÃ¼lÃ¼r. BERT, RoBERTa gibi transformer tabanlÄ± modeller genellikle daha iyi sonuÃ§ verir; Ã§Ã¼nkÃ¼ bÃ¼yÃ¼k dil korpuslarÄ± Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸtir. Ancak her problemde RNNâ€™ler gÃ¼Ã§lÃ¼ bir temel oluÅŸturabilir veya modellerin ensembleâ€™Ä±na katkÄ±da bulunabilir.

---

TÃ¼m kelimeler zaten sayÄ±sal olarak indekslenmiÅŸ olduÄŸundan, cÃ¼mleleri normalleÅŸtirmek iÃ§in **padding, start, unknown ve unused** kodlarÄ±nÄ± ekliyoruz:

```python
word_index = imdb.get_word_index()
word_index = {k:(v+3) for k,v in word_index.items()}
word_index["<PAD>"] = 0
word_index["<START>"] = 1
word_index["<UNK>"] = 2
word_index["<UNUSED>"] = 3
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])

def decode_review(text):
    return ' '.join([reverse_word_index.get(i, '?') for i in text])
```

---

Sonraki adÄ±m, **attention katmanÄ±** oluÅŸturmaktÄ±r. Attention, transformer modellerinin temelini oluÅŸturur ve NLPâ€™de son yÄ±llarÄ±n en yenilikÃ§i fikirlerinden biridir.

* LSTM ve GRU katmanlarÄ± iÅŸlenmiÅŸ diziler Ã¼retir; ancak dizilerin tÃ¼m Ã¶ÄŸeleri tahminler iÃ§in Ã¶nemli deÄŸildir.
* Dizi Ã¶ÄŸelerini ortalamak yerine, aÄŸÄ±rlÄ±klÄ± ortalama alabilir ve doÄŸru aÄŸÄ±rlÄ±klarÄ± Ã¶ÄŸrenmek iÃ§in eÄŸitim sÄ±rasÄ±nda optimize edebilirsiniz.
* Bu, model performansÄ±nÄ± artÄ±rÄ±r. Ã‡oklu attention katmanlarÄ± (multi-head attention) kullanÄ±labilir; ancak bu Ã¶rnekte tek katman yeterlidir.

```python
from tensorflow.keras.layers import Dense, Dropout, Flatten, RepeatVector, dot, multiply, Permute, Lambda
K = keras.backend

def attention(layer):
    _,_,units = layer.shape.as_list()
    attention = Dense(1, activation='tanh')(layer)
    attention = Flatten()(attention)
    attention = Activation('softmax')(attention)
    attention = RepeatVector(units)(attention)
    attention = Permute([2, 1])(attention)
    representation = multiply([layer, attention])
    representation = Lambda(lambda x: K.sum(x, axis=-2), output_shape=(units,))(representation)
    return representation
```

Detaylar iÃ§in: Vaswani, A. ve ark., *Attention is All You Need*, NeurIPS 2017: [https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

---

AyrÄ±ca farklÄ± optimizasyon yÃ¶ntemlerini de test etmek isteriz:

* **Rectified Adam (RAdam)**: Adaptif Ã¶ÄŸrenme oranÄ±na sahip Adam tÃ¼revi
* **SWA (Stochastic Weight Averaging)**: AÄŸÄ±rlÄ±klarÄ±n ortalamasÄ±nÄ± alarak aÅŸÄ±rÄ± uyum veya aÅŸÄ±rÄ± sapmayÄ± azaltÄ±r

```python
def get_optimizer(option=0, learning_rate=0.001):
    if option==0:
        return tf.keras.optimizers.Adam(learning_rate)
    elif option==1:
        return tf.keras.optimizers.SGD(learning_rate, momentum=0.9, nesterov=True)
    elif option==2:
        return tfa.optimizers.RectifiedAdam(learning_rate)
    elif option==3:
        return tfa.optimizers.Lookahead(tf.optimizers.Adam(learning_rate), sync_period=3)
    elif option==4:
        return tfa.optimizers.SWA(tf.optimizers.Adam(learning_rate))
    elif option==5:
        return tfa.optimizers.SWA(tf.keras.optimizers.SGD(learning_rate, momentum=0.9, nesterov=True))
    else:
        return tf.keras.optimizers.Adam(learning_rate)
```

---

En Ã¶nemli fonksiyon: Hiperparametreler Ã¼zerinden farklÄ± aÄŸ mimarileri Ã¼reten fonksiyon:

```python
layers = keras.layers
models = keras.models

def create_tunable_model(hp, vocab_size=10000, pad_length=256):
    # Hiperparametreleri tanÄ±mla
    embedding_size = hp.Int('embedding_size', 8, 512, 8)
    spatial_dropout = hp.Float('spatial_dropout', 0, 0.5, 0.05)
    conv_layers = hp.Int('conv_layers', 1, 5, 1)
    rnn_layers = hp.Int('rnn_layers', 1, 5, 1)
    dense_layers = hp.Int('dense_layers', 1, 3, 1)
    conv_filters = hp.Int('conv_filters', 32, 512, 32)
    conv_kernel = hp.Int('conv_kernel', 1, 8, 1)
    concat_dropout = hp.Float('concat_dropout', 0, 0.5, 0.05)
    dense_dropout = hp.Float('dense_dropout', 0, 0.5, 0.05)

    # Input ve embedding
    inputs = layers.Input(name='inputs',shape=[pad_length])
    layer  = layers.Embedding(vocab_size, embedding_size, input_length=pad_length)(inputs)
    layer  = layers.SpatialDropout1D(spatial_dropout)(layer)

    # Conv katmanlarÄ±
    for l in range(conv_layers):
        if l==0:
            conv = layers.Conv1D(filters=conv_filters, kernel_size=conv_kernel, padding='valid', kernel_initializer='he_uniform')(layer)
        else:
            conv = layers.Conv1D(filters=conv_filters, kernel_size=conv_kernel, padding='valid', kernel_initializer='he_uniform')(conv)
    avg_pool_conv = layers.GlobalAveragePooling1D()(conv)
    max_pool_conv = layers.GlobalMaxPooling1D()(conv)

    # RNN ve attention
    representations = list()
    for l in range(rnn_layers):
        use_bidirectional = hp.Choice(f'use_bidirectional_{l}', values=[0, 1])
        use_lstm = hp.Choice(f'use_lstm_{l}', values=[0, 1])
        units = hp.Int(f'units_{l}', 8, 512, 8)
        rnl = layers.LSTM if use_lstm==1 else layers.GRU
        if use_bidirectional==1:
            layer = layers.Bidirectional(rnl(units, return_sequences=True))(layer)
        else:
            layer = rnl(units, return_sequences=True)(layer)
        representations.append(attention(layer))

    layer = layers.concatenate(representations + [avg_pool_conv, max_pool_conv])
    layer = layers.Dropout(concat_dropout)(layer)

    # Dense katmanlarÄ±
    for l in range(dense_layers):
        dense_units = hp.Int(f'dense_units_{l}', 8, 512, 8)
        layer = layers.Dense(dense_units)(layer)
        layer = layers.LeakyReLU()(layer)
        layer = layers.Dropout(dense_dropout)(layer)

    layer = layers.Dense(1, name='out_layer')(layer)
    outputs = layers.Activation('sigmoid')(layer)
    model = models.Model(inputs=inputs, outputs=outputs)

    # Ã–ÄŸrenme oranÄ± ve optimizer
    hp_learning_rate = hp.Choice('learning_rate', [0.002, 0.001, 0.0005])
    optimizer_type = hp.Choice('optimizer', list(range(6)))
    optimizer = get_optimizer(option=optimizer_type, learning_rate=hp_learning_rate)

    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])
    return model
```

---

Fonksiyonel API kullanÄ±larak model oluÅŸturuldu. Sequential API Ã¶nerilmez; esnekliÄŸi sÄ±nÄ±rlÄ±dÄ±r.

KerasTuner ile hiperparametre optimizasyonu ÅŸÃ¶yle yapÄ±lÄ±r:

```python
import keras_tuner as kt

tuner = kt.BayesianOptimization(
    hypermodel=create_tunable_model,
    objective='val_acc',
    max_trials=100,
    num_initial_points=3,
    directory='storage',
    project_name='imdb',
    seed=42
)

tuner.search(
    train_data, train_labels, 
    epochs=30,
    batch_size=64, 
    validation_data=(val_data, val_labels),
    shuffle=True,
    verbose=2,
    callbacks=[EarlyStopping('val_acc', patience=3, restore_best_weights=True)]
)
```

* Bayes optimizasyonu kullanÄ±ldÄ±; isterseniz Hyperband da deneyebilirsiniz.
* `hypermodel` parametresine model fonksiyonunu veriyoruz.
* `objective` ile hedefi belirliyoruz.
* `max_trials` maksimum deneme sayÄ±sÄ±dÄ±r; daha Ã¶nce bir Ã§Ã¶zÃ¼m yoksa durur.
* `num_initial_points` baÅŸlangÄ±Ã§ rastgele deneme sayÄ±sÄ±dÄ±r.

Optimizasyon tamamlandÄ±ktan sonra en iyi hiperparametreleri ve modeli alabilirsiniz:

```python
best_hps = tuner.get_best_hyperparameters()[0]
model = tuner.hypermodel.build(best_hps)
print(best_hps.values)
model.summary()
model.save("best_model.h5")
```

Bu Ã¶rnekte KerasTuner ÅŸunlarÄ± bulur:

* Daha bÃ¼yÃ¼k embedding katmanÄ±
* Sadece dÃ¼z GRU ve LSTM katmanlarÄ± (bidirectional yok)
* Ã‡oklu Conv1D katmanlarÄ±
* Daha bÃ¼yÃ¼k ve daha fazla dense katman

Chollet, KerasTunerâ€™Ä±n DNN performansÄ±nÄ± artÄ±rmak iÃ§in deÄŸil, aynÄ± zamanda **daha yÃ¶netilebilir ve hÄ±zlÄ± modeller** elde etmek iÃ§in de kullanÄ±lmasÄ±nÄ± Ã¶neriyor. Bu, yarÄ±ÅŸmalarda birden fazla modelin sÄ±nÄ±rlÄ± sÃ¼rede Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlamak aÃ§Ä±sÄ±ndan Ã¶nemlidir.

#### The TPE approach in Optuna *(Optunaâ€™daki TPE yaklaÅŸÄ±mÄ±)*

Bayes optimizasyonu ile ilgili genel bakÄ±ÅŸÄ±mÄ±zÄ±, bu konuya dair baÅŸka ilginÃ§ bir araÃ§ ve yaklaÅŸÄ±mÄ± inceleyerek tamamlÄ±yoruz. Daha Ã¶nce de tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, Scikit-optimize Gaussian sÃ¼reÃ§lerini (ve ayrÄ±ca aÄŸaÃ§ algoritmalarÄ±nÄ±) kullanÄ±r ve doÄŸrudan vekil fonksiyon (surrogate function) ve edinim fonksiyonunu (acquisition function) modellemektedir.

KerasTuner kullanÄ±mÄ±na dair daha fazla Ã¶rnek incelemek isterseniz, FranÃ§ois Chollet, optimizerâ€™Ä±nÄ±n Ã§alÄ±ÅŸma ve fonksiyonlarÄ±nÄ± gÃ¶stermek amacÄ±yla Kaggle yarÄ±ÅŸmalarÄ± iÃ§in bir dizi Notebook da hazÄ±rlamÄ±ÅŸtÄ±r:

* [Digit Recognizer veri seti iÃ§in en iyi uygulamalar](https://www.kaggle.com/fchollet/keras-kerastuner-best)
* [Titanic veri seti iÃ§in en iyi uygulamalar](https://www.kaggle.com/fchollet/titanic-keras-kerastuner)
* [Mechanisms of Action (MoA) Prediction yarÄ±ÅŸmasÄ± iÃ§in en iyi uygulamalar](https://www.kaggle.com/fchollet/moa-keras-kerastuner-best)

HatÄ±rlatmak gerekirse, vekil fonksiyon, belirli bir hiperparametre seti denendiÄŸinde olasÄ± performans sonucunu modelleyerek optimizasyon sÃ¼recine yardÄ±mcÄ± olur. Vekil fonksiyon, Ã¶nceki deneyler ve sonuÃ§larÄ± kullanÄ±larak oluÅŸturulur; bu, belirli bir makine Ã¶ÄŸrenimi algoritmasÄ±nÄ±n belirli bir problem Ã¼zerindeki davranÄ±ÅŸÄ±nÄ± tahmin etmek iÃ§in uygulanan bir Ã¶ngÃ¶rÃ¼ modelidir. Vekil fonksiyona verilen her parametre giriÅŸi iÃ§in beklenen bir performans Ã§Ä±ktÄ±sÄ± elde edilir. Bu sezgisel ve aynÄ± zamanda oldukÃ§a esnek bir yÃ¶ntemdir, gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z gibi.

Edinim fonksiyonu ise, vekil fonksiyonun makine Ã¶ÄŸrenimi algoritmasÄ±nÄ±n performanslarÄ±nÄ± tahmin etme yeteneÄŸini artÄ±rmak iÃ§in hangi hiperparametre setlerinin test edilebileceÄŸini gÃ¶sterir. AyrÄ±ca, vekil fonksiyonun tahminlerine dayanarak en yÃ¼ksek performanslÄ± sonuca ulaÅŸÄ±p ulaÅŸamayacaÄŸÄ±mÄ±zÄ± gerÃ§ekten test etmek iÃ§in faydalÄ±dÄ±r. Bu iki amaÃ§, Bayes optimizasyon sÃ¼recinin keÅŸfetme kÄ±smÄ±nÄ± (deneyler yaptÄ±ÄŸÄ±nÄ±z bÃ¶lÃ¼m) ve kullanma kÄ±smÄ±nÄ± (performansÄ± test ettiÄŸiniz bÃ¶lÃ¼m) temsil eder.

---

TPE tabanlÄ± optimizasyon araÃ§larÄ± ise, parametre deÄŸerlerinin baÅŸarÄ± olasÄ±lÄ±ÄŸÄ±nÄ± tahmin ederek problemi Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±r. BaÅŸka bir deyiÅŸle, parametrelerin baÅŸarÄ± daÄŸÄ±lÄ±mÄ±nÄ± ardÄ±ÅŸÄ±k iyileÅŸtirmelerle modelleyerek, daha baÅŸarÄ±lÄ± deÄŸer kombinasyonlarÄ±na daha yÃ¼ksek olasÄ±lÄ±k atar.

Bu yaklaÅŸÄ±mda, hiperparametre seti iyi ve kÃ¶tÃ¼ olarak bu daÄŸÄ±lÄ±mlar aracÄ±lÄ±ÄŸÄ±yla ayrÄ±lÄ±r. Bu daÄŸÄ±lÄ±mlar, Bayes optimizasyondaki vekil ve edinim fonksiyonlarÄ±nÄ±n rolÃ¼nÃ¼ Ã¼stlenir Ã§Ã¼nkÃ¼ daÄŸÄ±lÄ±mlar, daha iyi performans elde etmek iÃ§in nereden Ã¶rnek alÄ±nacaÄŸÄ±nÄ± veya belirsizlik olan alanlarÄ± keÅŸfetmeyi sÃ¶yler.

TPEâ€™nin teknik detaylarÄ±nÄ± keÅŸfetmek iÃ§in ÅŸu kaynaÄŸÄ± okumanÄ±zÄ± Ã¶neririz:
Bergstra, J. ve ark., *Algorithms for hyper-parameter optimization*, Advances in Neural Information Processing Systems 24, 2011 ([PDF](https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf)).

Bu nedenle TPE, arama alanÄ±nÄ± modelleyebilir ve aynÄ± zamanda algoritmanÄ±n bir sonraki adÄ±mda denemesi gereken deÄŸerleri Ã¶nerebilir; parametrelerin ayarlanmÄ±ÅŸ olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±ndan Ã¶rnekleme yaparak bunu gerÃ§ekleÅŸtirir.

Uzun sÃ¼re Hyperopt, TPE kullanmayÄ± tercih edenler iÃ§in bir seÃ§enekti. Ancak Ekim 2018â€™de Optuna aÃ§Ä±k kaynak olarak yayÄ±mlandÄ± ve Kaggle kullanÄ±cÄ±larÄ± iÃ§in esnekliÄŸi (sinir aÄŸlarÄ± ve toplu modeller dahil kutudan Ã§Ä±ktÄ±ÄŸÄ± gibi Ã§alÄ±ÅŸÄ±r), hÄ±zÄ± ve Ã¶nceki optimizatÃ¶rlere gÃ¶re daha iyi Ã§Ã¶zÃ¼mler bulmadaki verimliliÄŸi nedeniyle tercih edilen araÃ§ haline geldi.

Bu bÃ¶lÃ¼mde, Optuna terminolojisine gÃ¶re â€œstudyâ€ olarak adlandÄ±rÄ±lan bir arama (search) kurmanÄ±n ne kadar kolay olduÄŸunu gÃ¶stereceÄŸiz. YapmanÄ±z gereken tek ÅŸey, Optuna tarafÄ±ndan test edilecek parametreleri alan ve bir deÄŸerlendirme dÃ¶ndÃ¼ren bir hedef fonksiyon (objective function) yazmaktÄ±r. DoÄŸrulama ve diÄŸer algoritmik detaylar, hedef fonksiyon iÃ§inde doÄŸrudan yÃ¶netilebilir; ayrÄ±ca fonksiyon dÄ±ÅŸÄ±ndaki deÄŸiÅŸkenlere (hem global hem de lokal) referans verebilirsiniz.

Optuna ayrÄ±ca budama (pruning) Ã¶zelliÄŸi sunar; bu, belirli bir deneyin iyi gitmediÄŸini iÅŸaret eder ve Optunaâ€™nÄ±n bu deneyi durdurup unutmasÄ±nÄ± saÄŸlar. Optuna, bu geri Ã§aÄŸrÄ±yÄ± (callback) etkinleÅŸtiren fonksiyonlar listesi saÄŸlar ([kaynak](https://optuna.readthedocs.io/en/stable/reference/integration.html)); algoritma bundan sonra her ÅŸeyi verimli bir ÅŸekilde Ã§alÄ±ÅŸtÄ±rÄ±r, bÃ¶ylece optimizasyon iÃ§in gereken sÃ¼re Ã¶nemli Ã¶lÃ§Ã¼de azalÄ±r.

---

Ã–rnek olarak, 30 Days of ML yarÄ±ÅŸmasÄ± iÃ§in optimizasyonu tekrar ele alÄ±yoruz. Bu sefer, XGBoost algoritmasÄ±nÄ± bu yarÄ±ÅŸma iÃ§in Ã§alÄ±ÅŸtÄ±racak parametreleri bulmaya Ã§alÄ±ÅŸÄ±yoruz.

Ä°lk adÄ±m olarak kÃ¼tÃ¼phaneleri ve veriyi yÃ¼kleyelim:

```python
import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder
from xgboost import XGBRegressor
import optuna
from optuna.integration import XGBoostPruningCallback

# Veriyi yÃ¼kleme
X_train = pd.read_csv("../input/30-days-of-ml/train.csv").iloc[:100_000, :]
X_test = pd.read_csv("../input/30-days-of-ml/test.csv")

# Veriyi tabular matris olarak hazÄ±rlama
y_train = X_train.target
X_train = X_train.set_index('id').drop('target', axis='columns')
X_test = X_test.set_index('id')

# Kategorik Ã¶zellikleri belirleme
categoricals = [item for item in X_train.columns if 'cat' in item]

# Kategorik verilerle OrdinalEncoder kullanÄ±mÄ±
ordinal_encoder = OrdinalEncoder()
X_train[categoricals] = ordinal_encoder.fit_transform(X_train[categoricals])
X_test[categoricals] = ordinal_encoder.transform(X_test[categoricals])
```

Optuna kullanÄ±rken, hedef fonksiyonun iÃ§inde model, Ã§apraz doÄŸrulama mantÄ±ÄŸÄ±, deÄŸerlendirme Ã¶lÃ§Ã¼tÃ¼ ve arama alanÄ±nÄ± tanÄ±mlamanÄ±z yeterlidir. Bu Ã¶rnek iÃ§in Notebookâ€™a [buradan](https://www.kaggle.com/lucamassaron/optuna-bayesian-optimization) ulaÅŸabilirsiniz.

Fonksiyonun iÃ§inde, veriyi dÄ±ÅŸarÄ±dan referans alarak fonksiyonun oluÅŸturulmasÄ±nÄ± kolaylaÅŸtÄ±rabilirsiniz. KerasTunerâ€™daki gibi, burada da Ã¶zel bir giriÅŸ parametresi kullanmanÄ±z gerekir:

```python
def objective(trial):
    params = {
        'learning_rate': trial.suggest_float("learning_rate", 0.01, 1.0, log=True),
        'reg_lambda': trial.suggest_loguniform("reg_lambda", 1e-9, 100.0),
        'reg_alpha': trial.suggest_loguniform("reg_alpha", 1e-9, 100.0),
        'subsample': trial.suggest_float("subsample", 0.1, 1.0),
        'colsample_bytree': trial.suggest_float("colsample_bytree", 0.1, 1.0),
        'max_depth': trial.suggest_int("max_depth", 1, 7),
        'min_child_weight': trial.suggest_int("min_child_weight", 1, 7),
        'gamma': trial.suggest_float("gamma", 0.1, 1.0, step=0.1)
    }
    model = XGBRegressor(
        random_state=0,
        tree_method="gpu_hist",
        predictor="gpu_predictor",
        n_estimators=10_000,
        **params
    )
    model.fit(x, y, early_stopping_rounds=300,
              eval_set=[(x_val, y_val)], verbose=1000,
              callbacks=[XGBoostPruningCallback(trial, 'validation_0-rmse')])
    preds = model.predict(x_test)
    rmse = mean_squared_error(y_test, preds, squared=False)
    return rmse
```

Performans nedenleriyle, bu Ã¶rnekte Ã§apraz doÄŸrulama yapmayacaÄŸÄ±z; bir veri seti eÄŸitim, bir veri seti doÄŸrulama (early stopping) ve bir veri seti test iÃ§in kullanÄ±lacak. GPU kullanÄ±yoruz ve 60 denemeyi makul sÃ¼re iÃ§inde Ã§alÄ±ÅŸtÄ±rabilmek iÃ§in veriyi alt kÃ¼meledik. GPU kullanmak istemezseniz, XGBRegressor tanÄ±mlamasÄ±ndaki `tree_method` ve `predictor` parametrelerini kaldÄ±rabilirsiniz. AyrÄ±ca `fit` yÃ¶nteminde bir callback belirleyerek Optunaâ€™ya model performansÄ± hakkÄ±nda bilgi saÄŸlÄ±yoruz; bÃ¶ylece optimizer dÃ¼ÅŸÃ¼k performanslÄ± deneyleri erken durdurup diÄŸer denemelere yer aÃ§abilir.

```python
x, x_val, y, y_val = train_test_split(X_train, y_train, random_state=0, test_size=0.2)
x, x_test, y, y_test = train_test_split(x, y, random_state=0, test_size=0.25)
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=100)
```

Bir diÄŸer Ã¶nemli nokta, optimizasyonu problem tÃ¼rÃ¼ne gÃ¶re minimuma veya maksimuma gÃ¶re ayarlayabilmenizdir (Scikit-optimize yalnÄ±zca minimizasyon problemlerinde Ã§alÄ±ÅŸÄ±r).

```python
print(study.best_value)
print(study.best_params)
```

Optimizasyon tamamlandÄ±ÄŸÄ±nda, en iyi test performansÄ±nÄ± ve optimizasyon tarafÄ±ndan bulunan en iyi parametreleri yazdÄ±rabilir veya dÄ±ÅŸa aktarabilirsiniz.

> **Ruchi Bhatia**
> 
> [https://www.kaggle.com/ruchi798](https://www.kaggle.com/ruchi798)
> 
> 
> 
> Bu yoÄŸun bÃ¶lÃ¼mÃ¼n sonunda, son bir rÃ¶portaja gÃ¶z atalÄ±m. Bu sefer, veri setleri ve Notebooks konusunda Grandmaster olan **Ruchi Bhatia** ile konuÅŸuyoruz. Ruchi ÅŸu anda Carnegie Mellon Ãœniversitesiâ€™nde yÃ¼ksek lisans Ã¶ÄŸrencisi, OpenMinedâ€™da Veri Bilimci ve Z by HPâ€™de KÃ¼resel Veri Bilimi ElÃ§isi olarak Ã§alÄ±ÅŸÄ±yor.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggleâ€™da hangi teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± konusunda uzmansÄ±nÄ±z?**
> 
> En sevdiÄŸim yarÄ±ÅŸma tÃ¼rleri NLP ve Analitik yarÄ±ÅŸmalarÄ±dÄ±r. Ã‡ok dilli olmak, ana ilgi alanÄ±m ve odak noktam olan **DoÄŸal Dil Ä°ÅŸleme (NLP)** konusundaki Ã§alÄ±ÅŸmalarÄ±mda Ã¶nemli bir rol oynadÄ±.
> 
> 
> 
> Analitik yarÄ±ÅŸmalar aÃ§Ä±sÄ±ndan ise karmaÅŸÄ±k verilerden anlam Ã§Ä±karmayÄ± ve sorulara verdiÄŸim yanÄ±tlarÄ± veri ile desteklemeyi seviyorum! Kaggleâ€™daki her yarÄ±ÅŸma yenidir ve farklÄ± teknikler gerektirir. Algoritma seÃ§iminde genellikle veri odaklÄ± bir yaklaÅŸÄ±mÄ± takip ederim ve belirli favorilerim yoktur.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±ÄŸÄ±nÄ±z ÅŸeylerden ne kadar farklÄ±?**
> 
> Yeni bir yarÄ±ÅŸma duyurulduÄŸunda Ã¶nceliÄŸim problem tanÄ±mÄ±nÄ± derinlemesine anlamaktÄ±r. Bazen problem tanÄ±mlarÄ± kendi konfor alanÄ±mÄ±zÄ±n veya uzmanlÄ±k alanÄ±mÄ±zÄ±n dÄ±ÅŸÄ±nda olabilir, bu yÃ¼zden EDAâ€™ya (KeÅŸifsel Veri Analizi) geÃ§meden Ã¶nce bunlarÄ± iyi kavramak Ã¶nemlidir.
> 
> 
> 
> EDA sÄ±rasÄ±nda, veri daÄŸÄ±lÄ±mÄ±nÄ± anlamayÄ± ve eldeki veriyi tanÄ±mayÄ± hedeflerim. Bu sÃ¼reÃ§te belirli kalÄ±plarla karÅŸÄ±laÅŸabiliriz; bu kalÄ±plarÄ± anlamaya ve uÃ§ deÄŸerler veya istisnai durumlar iÃ§in hipotez oluÅŸturmaya Ã§alÄ±ÅŸmalÄ±yÄ±z.
> 
> 
> 
> Bundan sonra yarÄ±ÅŸma metriklerini anlamaya zaman ayÄ±rÄ±rÄ±m. SÄ±zÄ±ntÄ±sÄ±z bir Ã§apraz doÄŸrulama stratejisi oluÅŸturmak bir sonraki adÄ±mdÄ±r. ArdÄ±ndan bir temel model seÃ§er ve ilk gÃ¶nderimi yaparÄ±m. Yerel doÄŸrulama ile yarÄ±ÅŸma sÄ±ralamasÄ± arasÄ±ndaki korelasyon tatmin edici deÄŸilse, olasÄ± tutarsÄ±zlÄ±klarÄ± anlamak ve bunlarÄ± hesaba katmak iÃ§in gerekene kadar iterasyon yaparÄ±m.
> 
> 
> 
> SonrasÄ±nda, modelleme yaklaÅŸÄ±mÄ±mÄ± zamanla geliÅŸtirmeye devam ederim. Parametreleri ayarlamak ve yeni deneyler yapmak, verilerle en iyi ÅŸekilde neyin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamama yardÄ±mcÄ± olur (tÃ¼m sÃ¼reÃ§ boyunca aÅŸÄ±rÄ± uyumdan kaÃ§Ä±narak). YarÄ±ÅŸmanÄ±n son birkaÃ§ haftasÄ±nda ise model ansamblasyonu uygular ve Ã§Ã¶zÃ¼mÃ¼n saÄŸlamlÄ±ÄŸÄ±nÄ± kontrol ederim.
> 
> 
> 
> Kaggle dÄ±ÅŸÄ±ndaki projelerimde ise zamanÄ±mÄ±n Ã§oÄŸu veri toplama, temizleme ve veriden deÄŸer elde etme Ã¼zerine geÃ§iyor.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? NasÄ±l?**
> 
> Kaggle kariyerimi hÄ±zla ilerletmemde bÃ¼yÃ¼k katkÄ± saÄŸladÄ±. Sadece veri bilimine olan ilgimi bulmama yardÄ±mcÄ± olmakla kalmadÄ±, aynÄ± zamanda etkili katkÄ±da bulunmamÄ± ve tutarlÄ± olmamÄ± da motive etti. BÃ¼yÃ¼k miktarda veriyle uygulamalÄ± deneyler yapma ve Ã§alÄ±ÅŸmalarÄ±mÄ±zÄ± global Ã¶lÃ§ekte sergileme imkÃ¢nÄ± sunmasÄ± mÃ¼kemmel bir fÄ±rsat. AyrÄ±ca Ã§alÄ±ÅŸmalarÄ±mÄ±z kolayca eriÅŸilebilir, bu sayede daha geniÅŸ bir kitleye ulaÅŸabiliyoruz.
> 
> 
> 
> Kaggleâ€™daki Ã§alÄ±ÅŸmalarÄ±mÄ±n Ã§oÄŸunu portfÃ¶yÃ¼mde kullandÄ±m; bu, yolculuÄŸum boyunca yaptÄ±ÄŸÄ±m Ã§eÅŸitli iÅŸleri gÃ¶stermek iÃ§in iyi bir yÃ¶ntem oldu. Kaggle yarÄ±ÅŸmalarÄ±, yenilikÃ§i ve gerÃ§ek dÃ¼nya problemlerini Ã§Ã¶zmeyi hedefler ve iÅŸverenler de bu tÃ¼r problemlere Ã§Ã¶zÃ¼m Ã¼retebilme yeteneÄŸimizi gÃ¶rmek ister. Ã‡eÅŸitli veri setleri derleyerek, ham verilerle Ã§alÄ±ÅŸma becerimi sergileyebildim. Bu projeler bana birden fazla iÅŸ fÄ±rsatÄ± saÄŸladÄ±.
> 
> 
> 
> **TecrÃ¼belerinize gÃ¶re, deneyimsiz Kaggle kullanÄ±cÄ±larÄ±nÄ±n sÄ±kÃ§a gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ± ÅŸeyler nelerdir? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz iyi olurdu dediÄŸiniz ÅŸeyler var mÄ±?**
> 
> TecrÃ¼belerime gÃ¶re, birÃ§ok Kaggle kullanÄ±cÄ±sÄ± yarÄ±ÅŸmalarda bekledikleri sÄ±ralamayÄ± elde edemediklerinde moralini kaybediyor. Haftalar ve aylar sÃ¼ren yoÄŸun Ã§alÄ±ÅŸmanÄ±n ardÄ±ndan, erken vazgeÃ§melerini anlayabiliyorum, ancak Kaggle yarÄ±ÅŸmalarÄ±nÄ± kazanmak kolay deÄŸil. FarklÄ± eÄŸitim geÃ§miÅŸine ve iÅŸ deneyimine sahip birÃ§ok kiÅŸi yarÄ±ÅŸÄ±yor ve denemeye cesaret etmek en Ã¶nemli ÅŸeydir. Bireysel olarak bÃ¼yÃ¼meye odaklanmalÄ± ve yolculuÄŸumuzda ne kadar ilerlediÄŸimizi gÃ¶rmeliyiz.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in Ã¶nereceÄŸiniz belirli araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> KapsamlÄ± keÅŸifsel veri analizi ve uygun gÃ¶rselleÅŸtirmeler, veri trendlerini ve metodolojiyi iyileÅŸtirebilecek baÄŸlamÄ± anlamamÄ±za yardÄ±mcÄ± olur. GÃ¶rselleÅŸtirmenin gÃ¼cÃ¼ne inandÄ±ÄŸÄ±m iÃ§in, favori veri bilimi kÃ¼tÃ¼phanelerim **Seaborn** ve **TensorBoard**â€™dur. Seaborn EDA iÃ§in, TensorBoard ise makine Ã¶ÄŸrenmesi iÅŸ akÄ±ÅŸÄ± sÄ±rasÄ±nda gerekli gÃ¶rselleÅŸtirmeler iÃ§in kullanÄ±lÄ±r. Ara sÄ±ra **Tableau** da kullanÄ±rÄ±m.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken en Ã¶nemli ÅŸey nedir?**
> 
> Bir yarÄ±ÅŸmaya katÄ±lÄ±rken, problem tanÄ±mÄ±nÄ± derinlemesine anlamaya ve araÅŸtÄ±rma yapmaya hazÄ±rlÄ±klÄ± olunmalÄ±dÄ±r. Kaggle yarÄ±ÅŸmalarÄ± Ã¶zellikle zorludur ve Ã§oÄŸu zaman gerÃ§ek hayattaki problemleri Ã§Ã¶zmeye yardÄ±mcÄ± olur. Ä°nsanlar olumlu bir zihniyete sahip olmalÄ± ve moralini kaybetmemelidir. Kaggle yarÄ±ÅŸmalarÄ±, Ã¶ÄŸrenmek ve geliÅŸmek iÃ§in mÃ¼kemmel bir fÄ±rsat sunar!

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, modelinizin performansÄ±nÄ± artÄ±rmak ve liderlik tablosunda daha yÃ¼ksek puanlar almak iÃ§in **hiperparametre optimizasyonunu** detaylÄ± bir ÅŸekilde ele aldÄ±k. Ã–ncelikle, **Scikit-learn**'Ã¼n kod iÅŸlevlerini, grid search (Ä±zgara aramasÄ±) ve random search (rastgele arama) gibi yÃ¶ntemleri, ayrÄ±ca daha yeni olan **yarÄ±ya indirme algoritmalarÄ±nÄ±** aÃ§Ä±kladÄ±k.

SonrasÄ±nda, **Bayesyen optimizasyonuna** geÃ§tik ve **Scikit-optimize**, **KerasTuner** ve son olarak **Optuna**'yÄ± inceledik. Ã–zellikle **Gaussian sÃ¼reÃ§leri** ile **surrogate fonksiyonunun** doÄŸrudan modellenmesi ve bu sÃ¼recin nasÄ±l hacklenebileceÄŸi Ã¼zerinde daha fazla durduk. Ã‡Ã¼nkÃ¼ bu yÃ¶ntem, size daha fazla sezgi ve daha ad hoc Ã§Ã¶zÃ¼mler saÄŸlama imkanÄ± sunabiliyor. Åu an itibarÄ±yla, **Optuna**'nÄ±n, Ã¶zellikle **tabular (tablolarla Ã§alÄ±ÅŸÄ±lan) yarÄ±ÅŸmalar** ve **derin sinir aÄŸlarÄ±** yarÄ±ÅŸmalarÄ±nda, Kaggle'da **altÄ±n standart** haline geldiÄŸini kabul ediyoruz. Optuna'nÄ±n, Kaggle Notebook'larÄ±nda verilen sÃ¼re iÃ§inde optimal parametrelere daha hÄ±zlÄ± bir ÅŸekilde ulaÅŸmasÄ±, onu diÄŸer optimizasyon yÃ¶ntemlerine gÃ¶re Ã¶ne Ã§Ä±karÄ±yor.

---

**TecrÃ¼belerinize gÃ¶re, deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neleri gÃ¶zden kaÃ§Ä±rÄ±r? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz iyi olurdu dediÄŸiniz ÅŸeyler nelerdir?**
TecrÃ¼belerime gÃ¶re, birÃ§ok Kaggle kullanÄ±cÄ±sÄ±nÄ±n yarÄ±ÅŸmalarda bekledikleri sÄ±ralamayÄ± alamadÄ±klarÄ± zaman moralinin bozulduÄŸunu fark ettim. Haftalarca ve aylarca sÃ¼ren yoÄŸun Ã§alÄ±ÅŸmanÄ±n ardÄ±ndan, erken pes etmelerini anlayabiliyorum, ancak Kaggle yarÄ±ÅŸmalarÄ±nÄ± kazanmak kolay bir iÅŸ deÄŸil. FarklÄ± eÄŸitim geÃ§miÅŸlerine ve iÅŸ deneyimlerine sahip birÃ§ok kiÅŸi yarÄ±ÅŸÄ±yor ve Ã¶nemli olan, denemeye cesaret edebilmek. Bireysel olarak ne kadar ilerlediÄŸimize odaklanmalÄ±yÄ±z ve yolculuÄŸumuzda ne kadar yol katettiÄŸimizi gÃ¶rmeliyiz.

**Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in Ã¶nerdiÄŸiniz belirli araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
KapsamlÄ± bir keÅŸifsel veri analizi ve ilgili gÃ¶rselleÅŸtirmeler, veri trendlerini ve metodolojimizi geliÅŸtirebilecek baÄŸlamlarÄ± gÃ¶rmemizi saÄŸlar. GÃ¶rselleÅŸtirmenin gÃ¼cÃ¼ne inandÄ±ÄŸÄ±m iÃ§in, en sevdiÄŸim veri bilimi kÃ¼tÃ¼phaneleri **Seaborn** ve **TensorBoard**â€™dur. **Seaborn** EDA (KeÅŸifsel Veri Analizi) iÃ§in, **TensorBoard** ise makine Ã¶ÄŸrenmesi iÅŸ akÄ±ÅŸÄ±nda gerekli gÃ¶rselleÅŸtirmeler iÃ§in kullanÄ±lÄ±r. Ara sÄ±ra **Tableau** da kullanÄ±rÄ±m.

**Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
YarÄ±ÅŸmaya katÄ±lanlarÄ±n, problem tanÄ±mÄ±na derinlemesine inip araÅŸtÄ±rma yapmaya kendilerini hazÄ±rlamalarÄ± gerektiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum. Kaggleâ€™daki yarÄ±ÅŸmalar Ã¶zellikle zorludur ve Ã§oÄŸu zaman gerÃ§ek hayattaki problemleri Ã§Ã¶zmeye yardÄ±mcÄ± olur. Ä°nsanlar olumlu bir zihniyete sahip olmalÄ± ve moralini kaybetmemelidir. Kaggle yarÄ±ÅŸmalarÄ±, Ã¶ÄŸrenmek ve geliÅŸmek iÃ§in mÃ¼kemmel bir fÄ±rsat sunar!

---

Ancak, yarÄ±ÅŸmada Ã¶ne Ã§Ä±kmak istiyorsanÄ±z, diÄŸer optimizatÃ¶rlerden de Ã§Ã¶zÃ¼m testleri yapmaya Ã§alÄ±ÅŸmalÄ±sÄ±nÄ±z.

Bir sonraki bÃ¶lÃ¼mde, Kaggle yarÄ±ÅŸmalarÄ±nda performansÄ±nÄ±zÄ± artÄ±rmanÄ±n bir diÄŸer yolunu tartÄ±ÅŸacaÄŸÄ±z: **model ansamblajÄ±**. **Ortalama alma**, **blending (karÄ±ÅŸtÄ±rma)** ve **stacking (yÄ±ÄŸÄ±lama)** yÃ¶ntemlerini keÅŸfederek, hiperparametre ayarlarÄ± ile tek baÅŸÄ±na elde edebileceÄŸinizden daha iyi sonuÃ§lar elde etmenin nasÄ±l mÃ¼mkÃ¼n olduÄŸunu gÃ¶stereceÄŸiz.

---

## Chapter 9: Ensembling with Blending and Stacking Solutions *(BÃ¶lÃ¼m 9: KarÄ±ÅŸtÄ±rma ve YÄ±ÄŸÄ±nlama (Ensemble) Ã‡Ã¶zÃ¼mleri)*

Kaggle'da yarÄ±ÅŸmaya baÅŸladÄ±ÄŸÄ±nÄ±zda, tek bir iyi tasarlanmÄ±ÅŸ modelle kazanamayacaÄŸÄ±nÄ±zÄ± fark etmek uzun sÃ¼rmez; birden fazla modeli ansambl yapmanÄ±z gerekir. SonrasÄ±nda, hemen nasÄ±l Ã§alÄ±ÅŸÄ±r bir ansambl kurulacaÄŸÄ± hakkÄ±nda dÃ¼ÅŸÃ¼nmeye baÅŸlarsÄ±nÄ±z. Bu konuda pek fazla rehber bulunmaz ve Ã§oÄŸu ÅŸey Kaggle'Ä±n halk arasÄ±nda yaygÄ±n olan bilgileriyle, bilimsel makalelerden daha Ã§ok iliÅŸkilidir.

Buradaki nokta ÅŸu: EÄŸer ansamblaj, Kaggle yarÄ±ÅŸmalarÄ±nda kazanmanÄ±n anahtarÄ±ysa, gerÃ§ek dÃ¼nyada bu, karmaÅŸÄ±klÄ±k, kÃ¶tÃ¼ bakÄ±m yapÄ±labilirlik, zor tekrar Ã¼retilebilirlik ve az bir avantajla gizli teknik maliyetlerle iliÅŸkilidir. Ã‡oÄŸu zaman, sizi dÃ¼ÅŸÃ¼k sÄ±ralamalardan liderlik tablosunun zirvesine taÅŸÄ±yacak olan kÃ¼Ã§Ã¼k bir artÄ±ÅŸ, gerÃ§ek dÃ¼nya uygulamalarÄ± iÃ§in aslÄ±nda Ã§ok Ã¶nemli deÄŸildir Ã§Ã¼nkÃ¼ maliyetler avantajlarÄ± gÃ¶lgeler. Ancak bu, ansamblajÄ±n gerÃ§ek dÃ¼nyada hiÃ§ kullanÄ±lmadÄ±ÄŸÄ± anlamÄ±na gelmez. **Ortalama alma** ve birkaÃ§ farklÄ± modeli karÄ±ÅŸtÄ±rma gibi sÄ±nÄ±rlÄ± bir biÃ§imde ansamblaj, veri bilimi problemlerini daha etkili ve verimli bir ÅŸekilde Ã§Ã¶zebilecek modeller oluÅŸturmanÄ±za olanak tanÄ±r.

Kaggleâ€™daki ansamblaj yalnÄ±zca ekstra tahmin performansÄ± kazanmanÄ±n bir yolu deÄŸil, aynÄ± zamanda bir takÄ±m stratejisidir. DiÄŸer takÄ±m arkadaÅŸlarÄ±nÄ±zla Ã§alÄ±ÅŸÄ±rken, herkesin katkÄ±larÄ±nÄ± birleÅŸtirmek, genellikle bireysel Ã§abalarla elde edilebilen sonuÃ§lardan daha iyi performans gÃ¶steren bir sonuÃ§ ortaya Ã§Ä±karÄ±r ve aynÄ± zamanda takÄ±mÄ±n Ã§alÄ±ÅŸmalarÄ±nÄ± dÃ¼zenlemeye yardÄ±mcÄ± olabilir. Herkesin Ã§abalarÄ±nÄ± net bir hedefe yÃ¶nlendirerek organize etmeye yardÄ±mcÄ± olabilir. AslÄ±nda, iÅŸin farklÄ± zaman dilimlerinde ve her katÄ±lÄ±mcÄ± iÃ§in farklÄ± kÄ±sÄ±tlamalar altÄ±nda yapÄ±ldÄ±ÄŸÄ± durumlarda, **pair coding** gibi iÅŸbirlikÃ§i teknikler aÃ§Ä±kÃ§a uygulanabilir deÄŸildir. Bir takÄ±m Ã¼yesi ofis saatlerinden dolayÄ± kÄ±sÄ±tlamalara tabi olabilir, diÄŸer bir Ã¼yeyse sÄ±navlar veya dersler nedeniyle kÄ±sÄ±tlamalar yaÅŸayabilir ve buna benzer durumlar sÃ¶z konusu olabilir.

YarÄ±ÅŸmalarda takÄ±mlar, genellikle tÃ¼m katÄ±lÄ±mcÄ±larÄ± aynÄ± gÃ¶revde senkronize etmek ve hizalamak zorunda kalmazlar ve hatta bunu yapmalarÄ± gerekmez. AyrÄ±ca, bir takÄ±mÄ±n iÃ§indeki beceriler de farklÄ± olabilir.

Bir takÄ±m arasÄ±nda paylaÅŸÄ±lan iyi bir ansamblaj stratejisi, bireylerin kendi rutinlerine ve stillerine gÃ¶re Ã§alÄ±ÅŸmaya devam etmelerini saÄŸlar, ancak yine de grup baÅŸarÄ±sÄ±na katkÄ±da bulunabilirler. Bu nedenle, farklÄ± beceriler, **tahmin Ã§eÅŸitliliÄŸine dayalÄ± ansamblaj teknikleri** kullanÄ±ldÄ±ÄŸÄ±nda avantaj haline gelebilir.

Bu bÃ¶lÃ¼mde, zaten bildiÄŸiniz ansamblaj tekniklerinden baÅŸlayacaÄŸÄ±z, Ã§Ã¼nkÃ¼ bunlar **rastgele ormanlar** ve **gradyan gÃ¼Ã§lendirme** gibi algoritmalarda yerleÅŸik olarak bulunur ve sonra **ortalama alma**, **blending (karÄ±ÅŸtÄ±rma)** ve **stacking (yÄ±ÄŸÄ±lama)** gibi birden fazla modelin ansamblajÄ±na yÃ¶nelik tekniklere geÃ§eceÄŸiz. Size bazÄ± teoriler, bazÄ± uygulamalar ve aynÄ± zamanda Kaggleâ€™da kendi Ã§Ã¶zÃ¼mlerinizi oluÅŸtururken ÅŸablon olarak kullanabileceÄŸiniz bazÄ± kod Ã¶rnekleri de sunacaÄŸÄ±z.

Bu konularÄ± ele alacaÄŸÄ±z:

* Ansamblaj algoritmalarÄ±na kÄ±sa bir giriÅŸ
* Modelleri bir ansamblajda ortalama almak
* Meta-model kullanarak modelleri karÄ±ÅŸtÄ±rmak
* Modelleri yÄ±ÄŸÄ±lama (stacking) yapmak
* KarmaÅŸÄ±k stacking ve blending Ã§Ã¶zÃ¼mleri oluÅŸturmak

> Bu bÃ¶lÃ¼mÃ¼ okumanÄ±z ve tÃ¼m teknikleri denemeniz iÃ§in sizi baÅŸ baÅŸa bÄ±rakmadan Ã¶nce, Kaggle'da yarÄ±ÅŸÄ±rken hem bizim hem de tÃ¼m uygulayÄ±cÄ±lar iÃ§in harika bir ansamblaj kaynaÄŸÄ±nÄ± paylaÅŸmalÄ±yÄ±z: **Triskelion** (Hendrik Jacob van Veen) ve birkaÃ§ iÅŸbirlikÃ§isi (**Le Nguyen The Dat**, **Armando Segnini**) tarafÄ±ndan 2015 yÄ±lÄ±nda yazÄ±lan blog yazÄ±sÄ±. Kaggle Ensembling Guide, aslÄ±nda mlwave blogunda bulunuyordu ([https://mlwave.com/kaggle-ensembling-guide](https://mlwave.com/kaggle-ensembling-guide)), ancak bu blog artÄ±k aktif deÄŸil, ancak rehberin iÃ§eriÄŸini **[https://usermanual.wiki/Document/Kaggle20ensembling20guide.685545114.pdf](https://usermanual.wiki/Document/Kaggle20ensembling20guide.685545114.pdf)** adresinden temin edebilirsiniz. Bu yazÄ±, o dÃ¶nemde Kaggle forumlarÄ±nda ansamblaj hakkÄ±nda yer alan, hem Ã¶rtÃ¼k hem de aÃ§Ä±k bilgileri derlemiÅŸti.

### A brief introduction to ensemble algorithms *(Topluluk (ensemble) algoritmalarÄ±na kÄ±sa bir giriÅŸ)*

Modellerin ansamblajlarÄ±nÄ±n tek modellerden daha iyi performans gÃ¶sterebileceÄŸi fikri, yeni bir fikir deÄŸildir. Bu dÃ¼ÅŸÃ¼nceyi, Viktorya dÃ¶nemi Britanya'sÄ±nda yaÅŸayan **Sir Francis Galton**'a kadar izleyebiliriz. Galton, bir kasaba festivalinde bir Ã¶kÃ¼zÃ¼n aÄŸÄ±rlÄ±ÄŸÄ±nÄ± tahmin etmenin, kalabalÄ±ktan alÄ±nan eÄŸitimli ya da eÄŸitimsiz tahminlerin ortalamasÄ±nÄ± almak kadar, tek bir uzman tarafÄ±ndan yapÄ±lmÄ±ÅŸ dikkatle hazÄ±rlanmÄ±ÅŸ tahminden daha faydalÄ± olduÄŸunu fark etti.

1996 yÄ±lÄ±nda, **Leo Breiman** birden fazla modelin daha tahmin edici bir model oluÅŸturacak ÅŸekilde birleÅŸtirilmesi fikrini resmiyet kazanmÄ±ÅŸtÄ±. Breiman, bagging (bootstrap aggregating) tekniÄŸini tanÄ±tarak, bunun daha sonra daha etkili olan **random forests (rastgele ormanlar)** algoritmalarÄ±nÄ±n geliÅŸimine yol aÃ§tÄ±ÄŸÄ±nÄ± gÃ¶sterdi. ArdÄ±ndan, diÄŸer ansamblaj teknikleri, Ã¶rneÄŸin **gradient boosting (gradyan gÃ¼Ã§lendirme)** ve **stacking (yÄ±ÄŸÄ±lama)** de tanÄ±tÄ±ldÄ±, bÃ¶ylece bugÃ¼n kullandÄ±ÄŸÄ±mÄ±z ansamblaj yÃ¶ntemlerinin yelpazesi tamamlandÄ±.

Bu ansamblaj algoritmalarÄ±nÄ±n ilk nasÄ±l tasarlandÄ±ÄŸÄ±nÄ± Ã¶ÄŸrenmek iÃ§in birkaÃ§ makaleye baÅŸvurabilirsiniz:

* **Random forests** iÃ§in, Breiman, L. "Bagging predictors". *Machine learning*, 24.2 â€“ 1996: 123-140â€™Ä± okuyabilirsiniz.
* **Boosting**'in ilk nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha ayrÄ±ntÄ±lÄ± Ã¶ÄŸrenmek isterseniz, Freund, Y. ve Schapire, R.E. "Experiments with a new boosting algorithm", icml, Vol. 96 â€“ 1996 ve Friedman, J. H. "Greedy function approximation: a gradient boosting machine". *Annals of Statistics* (2001): 1189-1232'yi okuyabilirsiniz.
* **Stacking** iÃ§in, teknik hakkÄ±nda ilk resmi taslak iÃ§in Ting, K. M. ve Witten, I. H. "Stacking bagged and dagged models", 1997'ye baÅŸvurabilirsiniz.

Kaggle yarÄ±ÅŸmalarÄ±ndaki ilk ansamblaj stratejileri, doÄŸrudan **bagging** ve **random forest** stratejilerinden alÄ±nmÄ±ÅŸ, sÄ±nÄ±flandÄ±rma ve regresyon iÃ§in kullanÄ±lmÄ±ÅŸtÄ±r. Bu stratejiler, Ã§eÅŸitli tahminlerin ortalamasÄ±nÄ± almayÄ± iÃ§eriyordu ve bu nedenle **ortalama alma teknikleri** olarak adlandÄ±rÄ±ldÄ±lar. Bu yaklaÅŸÄ±mlar, Kaggle'daki ilk yarÄ±ÅŸmalardan 11 yÄ±l Ã¶nce, farklÄ± modellerin sonuÃ§larÄ±nÄ±n ortalamasÄ±na dayalÄ± stratejilerin Netflix yarÄ±ÅŸmasÄ±ndan Ã¶nce de Ã¶ne Ã§Ä±kmasÄ±yla hÄ±zla ortaya Ã§Ä±ktÄ±. BaÅŸarÄ±larÄ± sayesinde, ortalama alma temelli temel ansamblaj teknikleri, gelecek yarÄ±ÅŸmalar iÃ§in bir standart oluÅŸturdu ve hala bugÃ¼n dahi liderlik tablosunda daha yÃ¼ksek puanlar almak iÃ§in oldukÃ§a faydalÄ±dÄ±r ve geÃ§erlidir.

Daha karmaÅŸÄ±k ve hesaplama aÃ§Ä±sÄ±ndan daha pahalÄ± olan **stacking**, yarÄ±ÅŸmalardaki problemler daha karmaÅŸÄ±k hale geldiÄŸinde ve katÄ±lÄ±mcÄ±lar arasÄ±ndaki rekabet daha ÅŸiddetli bir ÅŸekilde ortaya Ã§Ä±ktÄ±ÄŸÄ±nda biraz daha sonra ortaya Ã§Ä±kmÄ±ÅŸtÄ±r. TÄ±pkÄ± **random forest** yaklaÅŸÄ±mÄ±nÄ±n farklÄ± tahminleri ortalama almayÄ± teÅŸvik etmesi gibi, **boosting** de **stacking** yaklaÅŸÄ±mlarÄ±nÄ± bÃ¼yÃ¼k Ã¶lÃ§Ã¼de etkilemiÅŸtir. Boostingâ€™de, bilgiyi ardÄ±ÅŸÄ±k bir ÅŸekilde yeniden iÅŸleyerek, Ã¶ÄŸrenme algoritmanÄ±z, problemleri daha iyi ve daha tam bir ÅŸekilde modelleyebilir. AslÄ±nda, **gradyan boosting**'de, ardÄ±ÅŸÄ±k karar aÄŸaÃ§larÄ±, Ã¶nceki iterasyonlarÄ±n yakalayamadÄ±ÄŸÄ± verilerin kÄ±sÄ±mlarÄ±nÄ± modellemek iÃ§in inÅŸa edilir. Bu fikir, **stacking** ansamblajlarÄ±nda tekrar edilir, burada Ã¶nceki modellerin sonuÃ§larÄ±nÄ± yÄ±ÄŸÄ±p, bunlarÄ± tekrar iÅŸleyerek tahmin performansÄ±nda bir artÄ±ÅŸ elde edilir.

> **Rob Mulla**
> 
> [Kaggle Profil](https://www.kaggle.com/robikscube)
> 
> 
> 
> Rob, ansamblaj konusundaki gÃ¶rÃ¼ÅŸlerini ve Kaggle'dan Ã¶ÄŸrendiklerini bizimle paylaÅŸtÄ±. **YarÄ±ÅŸmalar, Not Defterleri ve TartÄ±ÅŸmalar** alanlarÄ±nda Grandmaster olan ve Biocore LLC'de KÄ±demli Veri Bilimcisi olarak Ã§alÄ±ÅŸan Rob'dan Ã§ok ÅŸey Ã¶ÄŸrenebiliriz.
> 
> 
> 
> **Soru:** En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Kaggle'daki teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan, uzmanlÄ±k alanÄ±nÄ±z nedir?
> 
> **Cevap:** En sevdiÄŸim yarÄ±ÅŸmalar, benzersiz veri setlerini iÃ§eren ve farklÄ± modelleme yaklaÅŸÄ±mlarÄ±nÄ± gerektiren yarÄ±ÅŸmalardÄ±r. Bir yarÄ±ÅŸmanÄ±n sadece bÃ¼yÃ¼k modellerin eÄŸitilmesini istememesi, veriyi gerÃ§ekten Ã§ok iyi anlamayÄ± ve gÃ¶revle ilgili Ã¶zel mimarileri kullanarak fikirler uygulamayÄ± gerektirmesi hoÅŸuma gider. Belirli bir yaklaÅŸÄ±mda uzmanlaÅŸmaya Ã§alÄ±ÅŸmÄ±yorum. Kaggle'a ilk baÅŸladÄ±ÄŸÄ±mda, Ã§oÄŸunlukla **gradient boosting** modellerine odaklanÄ±yordum, ancak son yÄ±llarda rekabetÃ§i olabilmek iÃ§in derin Ã¶ÄŸrenme, bilgisayarla gÃ¶rme (computer vision), doÄŸal dil iÅŸleme (NLP) ve optimizasyon konularÄ±nda bilgi sahibi oldum. En sevdiÄŸim yarÄ±ÅŸmalar, sadece tek bir teknik kullanmakla kalmayÄ±p, birden fazla tekniÄŸin bir arada kullanÄ±lmasÄ±nÄ± gerektiren yarÄ±ÅŸmalardÄ±r.
> 
> 
> 
> **Soru:** Kaggle yarÄ±ÅŸmalarÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±?
> 
> **Cevap:** Kaggle yarÄ±ÅŸmalarÄ±na bazÄ± aÃ§Ä±lardan iÅŸ projelerime Ã§ok benzer bir ÅŸekilde yaklaÅŸÄ±rÄ±m. Ä°lk olarak, veri anlayÄ±ÅŸÄ± gelir. GerÃ§ek dÃ¼nyadaki projelerde, problemi tanÄ±mlamak ve iyi bir metrik geliÅŸtirmek gerekebilir. Kaggle'da ise bu zaten sizin iÃ§in yapÄ±lmÄ±ÅŸ olur. SonrasÄ±nda, verilerin ve metriklerin nasÄ±l birbirleriyle iliÅŸkili olduÄŸunu anlamak ve problemi en iyi ÅŸekilde Ã§Ã¶zeceÄŸini dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼nÃ¼z modelleme tekniklerini geliÅŸtirmek ve test etmek gerekir. Kaggle ile gerÃ§ek dÃ¼nya veri bilimi arasÄ±ndaki en bÃ¼yÃ¼k fark, en son aÅŸamada modelleri ansamblajlamak ve ayarlarÄ±nÄ± yapmak iÃ§in gereken kÃ¼Ã§Ã¼k ince ayarlarÄ± yapmaktÄ±r; birÃ§ok gerÃ§ek dÃ¼nya uygulamasÄ±nda, bu tÃ¼r bÃ¼yÃ¼k ansamblajlara gerek yoktur Ã§Ã¼nkÃ¼ hesaplama maliyeti ve performans artÄ±ÅŸÄ± Ã§ok kÃ¼Ã§Ã¼k olabilir.
> 
> 
> 
> **Soru:** KatÄ±ldÄ±ÄŸÄ±nÄ±z ve zorlayÄ±cÄ± bulduÄŸunuz bir yarÄ±ÅŸma hakkÄ±nda bilgi verir misiniz? Bu gÃ¶revi nasÄ±l ele aldÄ±nÄ±z?
> 
> **Cevap:** KatÄ±ldÄ±ÄŸÄ±m oldukÃ§a zorlayÄ±cÄ± bir yarÄ±ÅŸma, **NFL Helmet Impact Detection** yarÄ±ÅŸmasÄ±ydÄ±. Bu yarÄ±ÅŸma video verisi iÃ§eriyordu ve bu konuda hiÃ§ deneyimim yoktu. AyrÄ±ca, yaygÄ±n yaklaÅŸÄ±mlarÄ± araÅŸtÄ±rmam ve konuyla ilgili mevcut makaleleri okumam gerekiyordu. Ã‡Ã¶zÃ¼mÃ¼n karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± artÄ±ran bir iki aÅŸamalÄ± bir yaklaÅŸÄ±m Ã¼zerinde Ã§alÄ±ÅŸmak zorunda kaldÄ±m. ZorlayÄ±cÄ± bulduÄŸum bir baÅŸka yarÄ±ÅŸma da **Indoor Location Navigation** yarÄ±ÅŸmasÄ±ydÄ±. Bu yarÄ±ÅŸma modelleme, optimizasyon ve veriyi gerÃ§ekten iyi anlama gerektiriyordu. YarÄ±ÅŸmada Ã§ok iyi bir sonuÃ§ alamadÄ±m, ancak Ã§ok ÅŸey Ã¶ÄŸrendim.
> 
> 
> 
> **Soru:** Kaggle, kariyerinize nasÄ±l yardÄ±mcÄ± oldu?
> 
> **Cevap:** Evet, Kaggle veri bilimi alanÄ±nda tanÄ±nmamÄ± saÄŸladÄ±. AyrÄ±ca yeni teknikler hakkÄ±nda bilgi ve anlayÄ±ÅŸÄ±m arttÄ± ve Ã§ok sayÄ±da zeki insanla tanÄ±ÅŸÄ±p Ã§alÄ±ÅŸarak makine Ã¶ÄŸrenmesi konusundaki becerilerimi geliÅŸtirdim.
> 
> TakÄ±mÄ±m, **NFL Helmet Impact Detection** yarÄ±ÅŸmasÄ±nda ikinci oldu. Bunun Ã¶ncesinde NFL ile ilgili birÃ§ok yarÄ±ÅŸmaya katÄ±ldÄ±m. YarÄ±ÅŸmanÄ±n dÃ¼zenleyicileri benimle iletiÅŸime geÃ§ti ve sonunda ÅŸu anki rolÃ¼mÃ¼ almama yardÄ±mcÄ± oldu.
> 
> 
> 
> **Soru:** Deneyimsiz Kagglersâ€™Ä±n genellikle gÃ¶z ardÄ± ettiÄŸi ÅŸeyler nelerdir? BaÅŸlangÄ±Ã§ta bilseydiniz, hangi bilgileri Ã¶ÄŸrenmek isterdiniz?
> 
> **Cevap:** Deneyimsiz Kagglersâ€™Ä±n bazen modellerin ansamblajÄ±nÄ± ve hiperparametre ayarlamalarÄ±nÄ± gereÄŸinden fazla dert ettiklerini dÃ¼ÅŸÃ¼nÃ¼yorum. Bunlar yarÄ±ÅŸmanÄ±n sonlarÄ±na doÄŸru Ã¶nemli olsa da, iyi bir temel modeliniz yoksa Ã§ok da Ã¶nemli deÄŸillerdir. AyrÄ±ca, yarÄ±ÅŸma metriÄŸini tamamen anlamanÄ±n son derece Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yorum. BirÃ§ok Kagglers, Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ deÄŸerlendirme metriÄŸine nasÄ±l optimize edeceÄŸinizi anlamanÄ±n ne kadar Ã¶nemli olduÄŸunu gÃ¶z ardÄ± eder.
> 
> 
> 
> **Soru:** GeÃ§miÅŸte yarÄ±ÅŸmalarda hangi hatalarÄ± yaptÄ±nÄ±z?
> 
> **Cevap:** BirÃ§ok hata yaptÄ±m. Modelleri aÅŸÄ±rÄ± uyum saÄŸladÄ±m (overfitting) ve sonunda faydalÄ± olmayan ÅŸeylere zaman harcadÄ±m. Ancak bunun, gelecekteki yarÄ±ÅŸmalara daha iyi yaklaÅŸmayÄ± Ã¶ÄŸrenmem iÃ§in gerekli olduÄŸunu hissediyorum. HatalarÄ±m, belirli bir yarÄ±ÅŸmadaki baÅŸarÄ±mÄ± olumsuz etkileyebilir, ancak sonraki yarÄ±ÅŸmalarda daha iyi olmama yardÄ±mcÄ± oldular.
> 
> 
> 
> **Soru:** Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in kullanmanÄ±zÄ± tavsiye edeceÄŸiniz Ã¶zel araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?
> 
> **Cevap:** **EDA** (KeÅŸifsel Veri Analizi) iÃ§in, verileri **NumPy**, **Pandas** ve **Matplotlib** veya baÅŸka bir gÃ¶rselleÅŸtirme kÃ¼tÃ¼phanesi ile manipÃ¼le edebilmeyi bilmek gerekir. Modelleme iÃ§in, uygun bir Ã§apraz doÄŸrulama (cross-validation) ÅŸemasÄ± kurmayÄ± bilmek Ã¶nemlidir, bunun iÃ§in **Scikit-learn** kullanabilirsiniz. **XGBoost/LightGBM** gibi standart modelleri nasÄ±l temel alacaÄŸÄ±nÄ±zÄ± (baseline) bilmek faydalÄ±dÄ±r. Derin Ã¶ÄŸrenme kÃ¼tÃ¼phaneleri genellikle **TensorFlow/Keras** veya **PyTorch**'tur. Bu iki ana derin Ã¶ÄŸrenme kÃ¼tÃ¼phanesinden birini Ã¶ÄŸrenmek Ã¶nemlidir.

### Averaging models into an ensemble *(Modelleri ortalama alarak birleÅŸtirme)*

**Averaging Ansamblaj TekniÄŸini TanÄ±tmak Ä°Ã§in**

Averaging ansamblaj tekniÄŸini daha iyi tanÄ±tabilmek iÃ§in, Leo Breiman tarafÄ±ndan geliÅŸtirilen tÃ¼m stratejileri hÄ±zlÄ±ca gÃ¶zden geÃ§irelim. Breimanâ€™Ä±n Ã§alÄ±ÅŸmasÄ±, ansamblaj stratejileri iÃ§in bir dÃ¶nÃ¼m noktasÄ±ydÄ± ve o zamanlar keÅŸfettikleri, geniÅŸ bir problem yelpazesinde hala oldukÃ§a iyi iÅŸliyor.

Breiman, gÃ¼Ã§lÃ¼ modellerin hata varyansÄ±nÄ± azaltacak bir yol bulmak amacÄ±yla bu olasÄ±lÄ±klarÄ± araÅŸtÄ±rdÄ±. Bu tÃ¼r modeller, eÄŸitim verisine aÅŸÄ±rÄ± uyum saÄŸlama (overfitting) eÄŸilimindeydi, Ã¶rneÄŸin karar aÄŸaÃ§larÄ± gibi.

**Breiman'Ä±n KeÅŸfettiÄŸi Temel Ã–ÄŸeler**

Konsept olarak, Breiman, ansamblajÄ±n etkinliÄŸinin Ã¼Ã§ temel Ã¶ÄŸeye dayandÄ±ÄŸÄ±nÄ± keÅŸfetti:

1. EÄŸitim Ã¶rneklerinin nasÄ±l Ã¶rneklenip seÃ§ildiÄŸi,
2. Modellerin nasÄ±l oluÅŸturulduÄŸu,
3. Son olarak, elde edilen farklÄ± modellerin nasÄ±l birleÅŸtirildiÄŸi.

**Ã–rnekleme YÃ¶ntemleri**

Ã–rnekleme konusunda test edilen ve bulunan yaklaÅŸÄ±mlar ÅŸunlardÄ±r:

* **Pasting**: Bir dizi model, Ã¶rneklerin alt Ã¶rneklerinden (yerine koyma yapmadan) oluÅŸturulur.
* **Bagging**: Bir dizi model, bootstrapped Ã¶rneklerinin rastgele seÃ§imiyle (yerine koyma ile Ã¶rnekleme) oluÅŸturulur.
* **Random Subspaces**: Bir dizi model, Ã¶zelliklerin alt Ã¶rneklerinden (yerine koyma yapmadan) oluÅŸturulur.
* **Random Patches**: Bagging'e benzer bir yaklaÅŸÄ±m, ancak burada her model seÃ§ildiÄŸinde Ã¶zellikler de Ã¶rneklenir, tÄ±pkÄ± random subspacesâ€™te olduÄŸu gibi.

**Ã–rnekleme YÃ¶ntemlerinin AmacÄ±**

AynÄ± bilgiyi kullanmak yerine Ã¶rnekleme yapmamÄ±zÄ±n nedeni ÅŸudur: Alt Ã¶rnekleme yaparak ve farklÄ± Ã¶zellikler seÃ§erek, aynÄ± probleme yÃ¶nelik farklÄ± fakat ilgili modeller oluÅŸturmuÅŸ oluruz. Bu fark, her modelin aÅŸÄ±rÄ± uyum saÄŸlama ÅŸekliyle de ilgilidir; tÃ¼m modeller, veriden genelleÅŸtirilebilen faydalÄ± bilgiyi aynÄ± ÅŸekilde yakalar ve tahmin yaparken kullanÄ±ÅŸsÄ±z olan gÃ¼rÃ¼ltÃ¼yÃ¼ farklÄ± ÅŸekillerde ele alÄ±r. Bu nedenle modellemedeki varyasyon, tahminlerdeki varyasyonu azaltÄ±r Ã§Ã¼nkÃ¼ hatalar birbirini dengeler.

**Modellerin Ã‡eÅŸitlendirilmesi**

EÄŸer varyasyon bu kadar faydalÄ±ysa, bir sonraki adÄ±m sadece veriyi deÄŸiÅŸtirmek deÄŸil, aynÄ± zamanda modeli de deÄŸiÅŸtirmek olmalÄ±dÄ±r. Modeller iÃ§in iki ana yaklaÅŸÄ±m vardÄ±r:

* AynÄ± tip modellerin ansamblajÄ±
* FarklÄ± modellerin ansamblajÄ±

Ä°lginÃ§ bir ÅŸekilde, ansamblajÄ± bir ÅŸekilde yapmak, modellerin tahmin gÃ¼cÃ¼ Ã§ok farklÄ±ysa pek iÅŸe yaramaz. Buradaki ana fikir ÅŸudur: AynÄ± tÃ¼rde tahminleri doÄŸru tahmin edebilen modelleri birleÅŸtirerek, tahminlerini ortalama alÄ±rken hatalarÄ±nÄ± dÃ¼zeltme avantajÄ± elde edersiniz. PerformanslarÄ± Ã§ok farklÄ± olan modelleri ansamblajlarsanÄ±z, bunun bir anlamÄ± olmadÄ±ÄŸÄ±nÄ± gÃ¶receksiniz Ã§Ã¼nkÃ¼ net etki negatif olacaktÄ±r: YanlÄ±ÅŸ tahminlerinizi dÃ¼zeltmek yerine, doÄŸru tahminlerinizi de kÃ¶tÃ¼leÅŸtirmiÅŸ olursunuz.

**Averagingâ€™in SÄ±nÄ±rlamalarÄ±**

Bu, averagingâ€™in Ã¶nemli bir sÄ±nÄ±rÄ±dÄ±r: FarklÄ± modelleri (Ã¶rneÄŸin, farklÄ± Ã¶rnekler ve Ã¶zellikler kullanÄ±larak eÄŸitilmiÅŸ modeller) ancak tahmin gÃ¼cÃ¼ aÃ§Ä±sÄ±ndan benzer olmalarÄ± durumunda kullanabilirsiniz. Bir Ã¶rnek vermek gerekirse, **doÄŸrusal regresyon** ve **k-en yakÄ±n komÅŸu algoritmasÄ±** (k-NN) problem Ã§Ã¶zme ve veriden sinyalleri yakalama aÃ§Ä±sÄ±ndan farklÄ± yollar kullanÄ±r; bu algoritmalar, veri Ã¼zerindeki belirli tahmin gÃ¶revlerinde daha iyi performans gÃ¶sterebilir, ancak averaging kullanÄ±rken bunlardan faydalanamazsÄ±nÄ±z. Aksine, algoritmalarÄ±n sinyalleri yakalamak iÃ§in kullandÄ±klarÄ± farklÄ± yollar, stackingâ€™de gerÃ§ekten faydalanabileceÄŸiniz bir ÅŸeydir, Ã§Ã¼nkÃ¼ stacking her algoritmanÄ±n en iyi sonuÃ§larÄ±nÄ± alabilir.

**Averagingâ€™in Etkili OlmasÄ± Ä°Ã§in Gereksinimler**

Buna dayanarak, bir averaging ansamblajÄ±nÄ±n etkili olabilmesi iÃ§in ÅŸunlar gereklidir:

* FarklÄ± Ã¶rnekler Ã¼zerinde eÄŸitilmiÅŸ modellerden oluÅŸturulmalÄ±,
* Mevcut Ã¶zelliklerden farklÄ± alt Ã¶rnekler kullanan modellerden oluÅŸturulmalÄ±,
* Tahmin gÃ¼cÃ¼ aÃ§Ä±sÄ±ndan benzer olan modellerden oluÅŸmalÄ±.

Bu, teknik olarak, modellerin tahminlerinin olabildiÄŸince birbirinden baÄŸÄ±msÄ±z olmasÄ±nÄ± ve aynÄ± doÄŸruluk seviyesinde performans gÃ¶stermelerini gerektirir.

**Averaging YÃ¶ntemleri**

Åimdi, birden fazla sÄ±nÄ±flandÄ±rma veya regresyon modelini ortalamak iÃ§in Ã¼Ã§ ana yÃ¶ntem bulunmaktadÄ±r:

* **Ã‡oÄŸunluk oylamasÄ±**: Birden fazla modelin en sÄ±k gÃ¶rÃ¼len sÄ±nÄ±flandÄ±rmasÄ± kullanÄ±lÄ±r (sadece sÄ±nÄ±flandÄ±rma modelleri iÃ§in).
* **DeÄŸerlerin veya olasÄ±lÄ±klarÄ±n ortalamasÄ±**: Modellerin Ã§Ä±ktÄ±larÄ±nÄ±n ortalamasÄ± alÄ±nÄ±r.
* **AÄŸÄ±rlÄ±klÄ± ortalama**: DeÄŸerlerin veya olasÄ±lÄ±klarÄ±n aÄŸÄ±rlÄ±klÄ± ortalamasÄ± alÄ±nÄ±r.

**Sonraki BÃ¶lÃ¼mlerde**
Bu Ã¼Ã§ yaklaÅŸÄ±mÄ± detaylÄ± bir ÅŸekilde, Ã¶zellikle Kaggle yarÄ±ÅŸmalarÄ± baÄŸlamÄ±nda tartÄ±ÅŸacaÄŸÄ±z.

#### Majority voting *(Ã‡oÄŸunluk oylamasÄ±)*

**Averaging ve Ensembling ile Ä°lgili Stratejiler**

FarklÄ± modeller oluÅŸturmak, kullandÄ±ÄŸÄ±mÄ±z Ã¶rnekler, Ã¶zellikler ve modelleri deÄŸiÅŸtirerek (daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, bu modeller tahmin gÃ¼cÃ¼ aÃ§Ä±sÄ±ndan karÅŸÄ±laÅŸtÄ±rÄ±labilir olmalÄ±) belirli bir hesaplama Ã§abasÄ± gerektirir, ancak bu, tek bir model kullandÄ±ÄŸÄ±nÄ±zda kuracaÄŸÄ±nÄ±z veri iÅŸleme hattÄ±ndan Ã§ok farklÄ± bir ÅŸey kurmanÄ±zÄ± gerektirmez.

Bu iÅŸleme hattÄ±nda, sadece farklÄ± test tahminlerini toplamanÄ±z gerekir. AyrÄ±ca, kullanÄ±lan modelleri, eÄŸitim sÄ±rasÄ±nda nasÄ±l Ã¶rnekleme yaptÄ±ÄŸÄ±nÄ±zÄ±, kullandÄ±ÄŸÄ±nÄ±z hiperparametreleri ve sonuÃ§ olarak elde edilen Ã§apraz doÄŸrulama performansÄ±nÄ± takip etmeniz Ã¶nemlidir.

EÄŸer yarÄ±ÅŸma bir sÄ±nÄ±f tahmin etmenizi gerektiriyorsa, **Ã§oÄŸunluk oylamasÄ±** (majority voting) yÃ¶ntemini kullanabilirsiniz; yani, her tahmin iÃ§in, modellerinizin en sÄ±k tahmin ettiÄŸi sÄ±nÄ±fÄ± alÄ±rsÄ±nÄ±z. Bu yÃ¶ntem, hem ikili tahminlerde hem de Ã§ok sÄ±nÄ±flÄ± tahminlerde Ã§alÄ±ÅŸÄ±r Ã§Ã¼nkÃ¼ modellerinizin bazen hata yapabileceÄŸini ancak Ã§oÄŸu zaman doÄŸru tahminlerde bulunabileceÄŸini varsayar. Ã‡oÄŸunluk oylamasÄ±, bir **"hata dÃ¼zeltme prosedÃ¼rÃ¼"** olarak kullanÄ±lÄ±r; gÃ¼rÃ¼ltÃ¼yÃ¼ atar ve anlamlÄ± sinyalleri korur.

**Averaging ve Ã‡oÄŸunluk OylamasÄ± ile Ã‡alÄ±ÅŸma**

Ä°lk basit Ã¶rneÄŸimizde, Ã§oÄŸunluk oylamasÄ±nÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶sterelim. BaÅŸlangÄ±Ã§ olarak Ã¶rnek veri setimizi oluÅŸturacaÄŸÄ±z. **Scikit-learn**'Ã¼n `make_classification` fonksiyonunu kullanarak, **Madelon** benzeri bir veri seti oluÅŸturacaÄŸÄ±z.

Bu Madelon veri setinin bir rekreasyonunu, bu bÃ¶lÃ¼m boyunca ansamblaj tekniklerini test etmek iÃ§in temel alacaÄŸÄ±z:

```python
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
X, y = make_classification(n_samples=5000, n_features=50, 
                           n_informative=10,
                           n_redundant=25, n_repeated=15, 
                           n_clusters_per_class=5,
                           flip_y=0.05, class_sep=0.5, 
                           random_state=0)
```

> Orijinal Madelon, bazÄ± boyutlu hiper kÃ¼plerin kÃ¶ÅŸe noktalarÄ±na yerleÅŸtirilmiÅŸ ve rastgele etiketlenmiÅŸ veri noktalarÄ±ndan oluÅŸan yapay bir veri setiydi. BirkaÃ§ anlamlÄ± Ã¶zellik, alakasÄ±z ve tekrar eden Ã¶zelliklerle karÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r (Ã¶zellikler arasÄ±nda Ã§oklu baÄŸlantÄ±lÄ±lÄ±k yaratmak iÃ§in) ve belli miktarda rastgele gÃ¼rÃ¼ltÃ¼ eklenmiÅŸtir. Isabelle Guyon (SVM algoritmasÄ±nÄ±n yaratÄ±cÄ±sÄ±) tarafÄ±ndan **NIPS 2003 Feature Selection Challenge** iÃ§in tasarlanmÄ±ÅŸtÄ±r. Madelon veri seti, yarÄ±ÅŸmalar iÃ§in zorlu bir yapay veri seti Ã¶rneÄŸi olarak kabul edilir. Hatta bazÄ± Kaggle yarÄ±ÅŸmalarÄ± bu veri setinden esinlenmiÅŸtir: [https://www.kaggle.com/c/overfitting](https://www.kaggle.com/c/overfitting) ve daha yeni olan [https://www.kaggle.com/c/dont-overfit-ii](https://www.kaggle.com/c/dont-overfit-ii).

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)
```

EÄŸitim ve test verilerini ayÄ±rdÄ±ktan sonra, Ã¶ÄŸrenme algoritmalarÄ±mÄ±zÄ± baÅŸlatÄ±yoruz. GÃ¶stermek amacÄ±yla sadece Ã¼Ã§ temel algoritma kullanacaÄŸÄ±z: **SVM** (Destek VektÃ¶r Makineleri), **random forests** ve **k-en yakÄ±n komÅŸu sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±**, varsayÄ±lan hiperparametrelerle. Hiperparametreleri deÄŸiÅŸtirmeyi ya da sayÄ±yÄ± artÄ±rmayÄ± deneyebilirsiniz:

```python
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import log_loss, roc_auc_score, accuracy_score

model_1 = SVC(probability=True, random_state=0)
model_2 = RandomForestClassifier(random_state=0)
model_3 = KNeighborsClassifier()
```

Sonraki adÄ±m, her bir modeli eÄŸitim verisiyle eÄŸitmek olacak:

```python
model_1.fit(X_train, y_train)
model_2.fit(X_train, y_train)
model_3.fit(X_train, y_train)
```

Bu noktada, her model iÃ§in test verisi Ã¼zerinde tahmin yapmamÄ±z ve bu tahminleri Ã§oÄŸunluk oylamasÄ±yla ansamblajlamamÄ±z gerekiyor. Bunu yapmak iÃ§in, **SciPy**'nin `mode` fonksiyonunu kullanacaÄŸÄ±z:

```python
import numpy as np
from scipy.stats import mode

preds = np.stack([model_1.predict(X_test),
                  model_2.predict(X_test),
                  model_3.predict(X_test)]).T
max_voting = np.apply_along_axis(mode, 1, preds)[:, 0]
```

Ã–ncelikle, her bir modelin doÄŸruluÄŸunu kontrol edelim:

```python
for i, model in enumerate(['SVC', 'RF ', 'KNN']):
    acc = accuracy_score(y_true=y_test, y_pred=preds[:, i])
    print(f"Accuracy for model {model} is: {acc:0.3f}")
```

ÃœÃ§ modelin de benzer performans gÃ¶sterdiÄŸini, doÄŸruluklarÄ±nÄ±n yaklaÅŸÄ±k olarak 0.8 olduÄŸunu gÃ¶rÃ¼yoruz. Åimdi, Ã§oÄŸunluk oylamasÄ± ansamblajÄ±nÄ± kontrol edelim:

```python
max_voting_accuracy = accuracy_score(y_true=y_test, y_pred=max_voting)
print(f"Accuracy for majority voting is: {max_voting_accuracy:0.3f}")
```

Ã‡oÄŸunluk oylamasÄ± ansamblajÄ± aslÄ±nda daha doÄŸru: 0.817, Ã§Ã¼nkÃ¼ doÄŸru sinyalleri Ã§oÄŸunluktan derlemeyi baÅŸarmÄ±ÅŸtÄ±r.

**Ã‡oklu Etiketli (Multilabel) Problemler**

Ã‡ok etiketli problemlerde (birden fazla sÄ±nÄ±f tahmin etmeniz gerektiÄŸinde), sadece belirli bir sayÄ±da tahmin edilen sÄ±nÄ±fÄ± seÃ§ebilirsiniz. Bu, bir sÄ±nÄ±f iÃ§in tahminin sinyal, deÄŸil gÃ¼rÃ¼ltÃ¼ olduÄŸunu belirten bir alaka eÅŸiÄŸi varsayarak yapÄ±lÄ±r. Ã–rneÄŸin, beÅŸ modeliniz varsa, bu eÅŸiÄŸi 3 olarak belirleyebilirsiniz, yani bir sÄ±nÄ±f en az Ã¼Ã§ model tarafÄ±ndan tahmin edilirse, tahmin doÄŸru kabul edilir.

**Regresyon Problemleri ve OlasÄ±lÄ±k Tahminleri**

Regresyon problemlerinde ve olasÄ±lÄ±k tahminlerinde, Ã§oÄŸunluk oylamasÄ± kullanÄ±lamaz. Ã‡oÄŸunluk oylamasÄ± yalnÄ±zca sÄ±nÄ±f sahipliÄŸi ile Ã§alÄ±ÅŸÄ±r. Bunun yerine, sayÄ±lar tahmin etmeniz gerektiÄŸinde, sonuÃ§larÄ± sayÄ±sal olarak birleÅŸtirmeniz gerekir. Bu durumda, **ortalama** veya **aÄŸÄ±rlÄ±klÄ± ortalama** kullanmak, tahminleri birleÅŸtirmenin doÄŸru yolu olacaktÄ±r.

#### Averaging of model predictions *(Model tahminlerinin ortalamasÄ±)*

FarklÄ± modellerden aldÄ±ÄŸÄ±nÄ±z tahminleri bir yarÄ±ÅŸmada ortalama alÄ±rken, tÃ¼m tahminlerinizi potansiyel olarak aynÄ± tahmin gÃ¼cÃ¼ne sahip kabul edebilir ve bir ortalama deÄŸer tÃ¼retmek iÃ§in aritmetik ortalamayÄ± kullanabilirsiniz.
Aritmetik ortalama dÄ±ÅŸÄ±nda, ÅŸu yÃ¶ntemlerin de oldukÃ§a etkili olduÄŸunu gÃ¶rdÃ¼k:
* **Geometrik Ortalama:** Burada, n tahminini Ã§arparsÄ±nÄ±z, sonra elde edilen Ã§arpÄ±mÄ±n 1/n'inci kuvvetini alÄ±rsÄ±nÄ±z.
* **Logaritmik Ortalama:** Geometrik ortalamaya benzer ÅŸekilde, tahminlerinizin logaritmasÄ±nÄ± alÄ±r, bunlarÄ± ortalarsÄ±nÄ±z ve elde edilen ortalamanÄ±n Ã¼ssÃ¼nÃ¼ alÄ±rsÄ±nÄ±z.
* **Harmonik Ortalama:** Burada, tahminlerinizin karÅŸÄ±tlarÄ±nÄ±n aritmetik ortalamasÄ±nÄ± alÄ±r, sonra elde edilen ortalamanÄ±n karÅŸÄ±tÄ±nÄ± alÄ±rsÄ±nÄ±z.
* **Kuvvetlerin OrtalamasÄ±:** Burada, tahminlerin n'inci kuvvetinin ortalamasÄ±nÄ± alÄ±r, sonra elde edilen ortalamanÄ±n 1/n'inci kuvvetini alÄ±rsÄ±nÄ±z.
Aritmetik ortalama genellikle oldukÃ§a etkili olup, beklenenden daha sÄ±k iÅŸe yarayan bir yÃ¶ntemdir. Bazen, geometrik ortalama veya harmonik ortalama gibi varyantlar daha iyi sonuÃ§ verebilir.

Ã–nceki Ã¶rneÄŸi devam ettirerek, ÅŸimdi ROC-AUC'yi deÄŸerlendirme metriÄŸi olarak kullandÄ±ÄŸÄ±mÄ±zda hangi ortalamanÄ±n en iyi sonucu vereceÄŸini bulmaya Ã§alÄ±ÅŸacaÄŸÄ±z. BaÅŸlangÄ±Ã§ olarak, her bir modelin performansÄ±nÄ± deÄŸerlendireceÄŸiz:

```python
proba = np.stack([model_1.predict_proba(X_test)[:, 1],
                  model_2.predict_proba(X_test)[:, 1],
                  model_3.predict_proba(X_test)[:, 1]]).T
for i, model in enumerate(['SVC', 'RF', 'KNN']):
    ras = roc_auc_score(y_true=y_test, y_score=proba[:, i])
    print(f"ROC-AUC for model {model} is: {ras:0.5f}")
```

SonuÃ§lar bize 0.875 ile 0.881 arasÄ±nda bir aralÄ±k veriyor.
Ä°lk testimizi aritmetik ortalama kullanarak yapÄ±yoruz:

```python
arithmetic = proba.mean(axis=1)
ras = roc_auc_score(y_true=y_test, y_score=arithmetic)
print(f"Mean averaging ROC-AUC is: {ras:0.5f}")
```

Elde edilen ROC-AUC skoru, tekli performanslardan belirgin ÅŸekilde daha iyi: 0.90192. AyrÄ±ca, geometrik, harmonik, logaritmik ortalama veya kuvvetlerin ortalamasÄ±nÄ±n basit ortalamadan daha iyi performans gÃ¶sterip gÃ¶stermediÄŸini test ediyoruz:

```python
geometric = proba.prod(axis=1)**(1/3)
ras = roc_auc_score(y_true=y_test, y_score=geometric)
print(f"Geometric averaging ROC-AUC is: {ras:0.5f}")
harmonic = 1 / np.mean(1. / (proba + 0.00001), axis=1)
ras = roc_auc_score(y_true=y_test, y_score=harmonic)
print(f"Harmonic averaging ROC-AUC is: {ras:0.5f}")
n = 3
mean_of_powers = np.mean(proba**n, axis=1)**(1/n)
ras = roc_auc_score(y_true=y_test, y_score=mean_of_powers)
print(f"Mean of powers averaging ROC-AUC is: {ras:0.5f}")
logarithmic = np.expm1(np.mean(np.log1p(proba), axis=1))
ras = roc_auc_score(y_true=y_test, y_score=logarithmic)
print(f"Logarithmic averaging ROC-AUC is: {ras:0.5f}")
```

Kodun Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±, hiÃ§biri basit ortalamanÄ±n daha iyi performans gÃ¶steremediÄŸini gÃ¶steriyor. Bu durumda, aritmetik ortalama en iyi seÃ§enek olarak Ã¶ne Ã§Ä±kÄ±yor. GerÃ§ekten de, Ã§oÄŸu durumda basit ortalamadan daha iyi bir Ã§Ã¶zÃ¼m, sayÄ±larÄ± birleÅŸtirirken bazÄ± Ã¶n bilgilerinizi kullanmaktÄ±r. Bu, modellerinizi ortalama hesaplamasÄ±nda aÄŸÄ±rlÄ±klandÄ±rdÄ±ÄŸÄ±nÄ±zda gerÃ§ekleÅŸir.

#### Weighted averages *(AÄŸÄ±rlÄ±klÄ± ortalamalar)*

Modellerinizi aÄŸÄ±rlÄ±klandÄ±rÄ±rken, doÄŸru aÄŸÄ±rlÄ±klarÄ± bulmak iÃ§in ampirik bir yÃ¶ntem geliÅŸtirmelisiniz. YaygÄ±n bir yÃ¶ntem, ancak adaptif aÅŸÄ±rÄ± uyum (overfitting) yapmaya Ã§ok yatkÄ±n bir yÃ¶ntem, farklÄ± kombinasyonlarÄ± halka aÃ§Ä±k liderlik tablosunda test etmek ve en iyi skoru veren kombinasyonu bulmaktÄ±r. Tabii ki, bu durum, Ã¶zel liderlik tablosunda aynÄ± sonucu almanÄ±zÄ± garanti etmez. Burada ilke, daha iyi Ã§alÄ±ÅŸanlarÄ± aÄŸÄ±rlÄ±klandÄ±rmaktÄ±r. Ancak daha Ã¶nce uzun uzun tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, halka aÃ§Ä±k liderlik tablosundan alÄ±nan geribildirim genellikle Ã¶zel test verileriyle Ã¶nemli farklar olduÄŸu iÃ§in gÃ¼venilmez olabilir. Yine de, Ã§apraz doÄŸrulama (cross-validation) skorlarÄ±nÄ±zÄ± veya kat dÄ±ÅŸÄ± (out-of-fold) skorlarÄ± kullanabilirsiniz (kat dÄ±ÅŸÄ± skorlar, daha sonra yÄ±ÄŸÄ±nlama (stacking) ile birlikte tartÄ±ÅŸÄ±lacaktÄ±r). AslÄ±nda, baÅŸka bir uygulanabilir strateji, modellerin Ã§apraz doÄŸrulama performanslarÄ±na orantÄ±lÄ± aÄŸÄ±rlÄ±klar kullanmaktÄ±r.

Biraz ters bir mantÄ±k olsa da, baÅŸka Ã§ok etkili bir yÃ¶ntem, tahminler arasÄ±ndaki kovaryanslara ters orantÄ±lÄ± olarak aÄŸÄ±rlÄ±klandÄ±rma yapmaktÄ±r. AslÄ±nda, hatalarÄ± ortalamayla iptal etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in, her bir tahminin benzersiz varyansÄ±na dayalÄ± ortalama almak, daha az korele ve daha Ã§eÅŸitli tahminlere daha fazla aÄŸÄ±rlÄ±k vermemizi saÄŸlar ve bu da tahminlerin varyansÄ±nÄ± daha etkili bir ÅŸekilde azaltÄ±r.

Bir sonraki Ã¶rneÄŸimizde, Ã¶nce tahmin edilen olasÄ±lÄ±klarÄ±n korelasyon matrisini oluÅŸturacaÄŸÄ±z ve sonra ÅŸu adÄ±mlarÄ± izleyerek iÅŸlemi gerÃ§ekleÅŸtireceÄŸiz:

1. Diyagonal Ã¼zerindeki 1'leri kaldÄ±rÄ±p, bunlarÄ± sÄ±fÄ±rlarla deÄŸiÅŸtireceÄŸiz
2. Korelasyon matrisini satÄ±rlara gÃ¶re ortalayarak bir vektÃ¶r elde edeceÄŸiz
3. Her satÄ±rÄ±n toplamÄ±nÄ±n karÅŸÄ±tÄ±nÄ± alacaÄŸÄ±z
4. SonuÃ§larÄ±n toplamÄ±nÄ± 1.0 olacak ÅŸekilde normalize edeceÄŸiz
5. Elde edilen aÄŸÄ±rlÄ±klandÄ±rma vektÃ¶rÃ¼nÃ¼, tahmin edilen olasÄ±lÄ±klarÄ±n matris Ã§arpÄ±mÄ±nda kullanacaÄŸÄ±z

Ä°ÅŸte bunun iÃ§in kullanÄ±lan kod:

```python
cormat = np.corrcoef(proba.T)  
np.fill_diagonal(cormat, 0.0)  
W = 1 / np.mean(cormat, axis=1)  
W = W / sum(W)  # normalizing to sum==1.0  
weighted = proba.dot(W)  
ras = roc_auc_score(y_true=y_test, y_score=weighted)  
print(f"Weighted averaging ROC-AUC is: {ras:0.5f}")
```

Elde edilen ROC-AUC skoru 0.90206, basit ortalamadan biraz daha iyi. Korelasyonu daha dÃ¼ÅŸÃ¼k olan tahminlere daha fazla aÄŸÄ±rlÄ±k vermek, genellikle baÅŸarÄ±lÄ± bir toplama (ensembling) stratejisidir. Bu sadece kÃ¼Ã§Ã¼k iyileÅŸtirmeler saÄŸlasa bile, bu tÃ¼r bir strateji, rekabeti lehine Ã§evirebilmek iÃ§in yeterli olabilir.

#### Averaging in your cross-validation strategy *(Ã‡apraz doÄŸrulama stratejinde ortalama alma)*

Daha Ã¶nce de bahsettiÄŸimiz gibi, ortalama almak, herhangi bir Ã¶zel karmaÅŸÄ±k pipeline kurmanÄ±zÄ± gerektirmez; yalnÄ±zca tahminlerinizi ortalamaya alacaÄŸÄ±nÄ±z modelleri oluÅŸturan tipik veri pipeline'larÄ±ndan belli bir sayÄ±da oluÅŸturmanÄ±z yeterlidir. Bu modelleri ortalamak iÃ§in, tÃ¼m tahminler iÃ§in aynÄ± aÄŸÄ±rlÄ±klarÄ± kullanabilir veya ampirik olarak bulunan bazÄ± aÄŸÄ±rlÄ±klarÄ± kullanabilirsiniz. Bunu test etmenin tek yolu, halka aÃ§Ä±k liderlik tablosuna bir gÃ¶nderi yapmaktÄ±r; bÃ¶ylece, deÄŸerlendirme yalnÄ±zca Kaggle'Ä±n verdiÄŸi geri bildirime dayalÄ± olacaktÄ±r ve bu da adaptif aÅŸÄ±rÄ± uyuma (adaptive fitting) yol aÃ§abilir.

Ancak, doÄŸrudan liderlik tablosunda test etmeden Ã¶nce, eÄŸitim aÅŸamasÄ±nda da doÄŸrulama katmanÄ±nda (modelinizi eÄŸitmek iÃ§in kullanmadÄ±ÄŸÄ±nÄ±z katman) ortalama alma iÅŸlemlerini Ã§alÄ±ÅŸtÄ±rarak test edebilirsiniz. Bu, liderlik tablosundan alÄ±nan geri bildirime gÃ¶re daha az yanlÄ± sonuÃ§lar elde etmenizi saÄŸlar. AÅŸaÄŸÄ±daki kodda, Ã§apraz doÄŸrulama (cross-validation) tahmininin nasÄ±l dÃ¼zenlendiÄŸine dair bir Ã¶rnek bulabilirsiniz:

```python
from sklearn.model_selection import KFold  
kf = KFold(n_splits=5, shuffle=True, random_state=0)  
scores = list()  
for k, (train_index, test_index) in enumerate(kf.split(X_train)):  
    model_1.fit(X_train[train_index, :], y_train[train_index])  
    model_2.fit(X_train[train_index, :], y_train[train_index])  
    model_3.fit(X_train[train_index, :], y_train[train_index])  

    proba = np.stack(  
        [model_1.predict_proba(X_train[test_index, :])[:, 1],  
         model_2.predict_proba(X_train[test_index, :])[:, 1],  
         model_3.predict_proba(X_train[test_index, :])[:, 1]]).T  

    arithmetic = proba.mean(axis=1)  
    ras = roc_auc_score(y_true=y_train[test_index], y_score=arithmetic)  
    scores.append(ras)  
    print(f"FOLD {k} Mean averaging ROC-AUC is: {ras:0.5f}")  
print(f"CV Mean averaging ROC-AUC is: {np.mean(scores):0.5f}")  
```

YukarÄ±daki gibi bir Ã§apraz doÄŸrulama sonucuna gÃ¼venmek, hangi ortalama stratejisinin daha umut verici olduÄŸunu, doÄŸrudan halka aÃ§Ä±k liderlik tablosunda test yapmadan deÄŸerlendirmenize yardÄ±mcÄ± olabilir.

#### Correcting averaging for ROC-AUC evaluations *(ROC-AUC deÄŸerlendirmeleri iÃ§in ortalamayÄ± dÃ¼zeltme)*

EÄŸer gÃ¶reviniz ROC-AUC skoru ile deÄŸerlendirilecekse, sadece sonuÃ§larÄ±nÄ±zÄ± ortalamak yeterli olmayabilir. Bunun nedeni, farklÄ± modellerin farklÄ± optimizasyon stratejileri benimsemiÅŸ olmasÄ± ve dolayÄ±sÄ±yla Ã§Ä±ktÄ±larÄ±nÄ±n oldukÃ§a farklÄ± olabilmesidir. Bir Ã§Ã¶zÃ¼m, modelleri kalibre etmektir; bu, daha Ã¶nce 5. BÃ¶lÃ¼m, YarÄ±ÅŸma GÃ¶revleri ve Metrikleri'nde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z bir tÃ¼r son iÅŸlem (post-processing) yÃ¶ntemidir, ancak bu aÃ§Ä±kÃ§a daha fazla zaman ve hesaplama gÃ¼cÃ¼ gerektirir.

Bu gibi durumlarda, basit Ã§Ã¶zÃ¼m, Ã§Ä±ktÄ± olasÄ±lÄ±klarÄ±nÄ± sÄ±ralara dÃ¶nÃ¼ÅŸtÃ¼rmek ve sadece sÄ±ralarÄ± ortalamaktÄ±r (ya da bunlarÄ±n aÄŸÄ±rlÄ±klÄ± ortalamasÄ±nÄ± almak). Min-max Ã¶lÃ§ekleyici (scaler) yaklaÅŸÄ±mÄ±nÄ± kullanarak, her bir modelin tahminlerini 0-1 aralÄ±ÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼p, ardÄ±ndan tahminleri ortalamaya alÄ±rsÄ±nÄ±z. Bu, modelinizin olasÄ±lÄ±k Ã§Ä±ktÄ±sÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±labilir sÄ±ralara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r:

```python
from sklearn.preprocessing import MinMaxScaler  
proba = np.stack(  
    [model_1.predict_proba(X_train)[:, 1],  
     model_2.predict_proba(X_train)[:, 1],  
     model_3.predict_proba(X_train)[:, 1]]).T  

arithmetic = MinMaxScaler().fit_transform(proba).mean(axis=1)  
ras = roc_auc_score(y_true=y_test, y_score=arithmetic)  
print(f"Mean averaging ROC-AUC is: {ras:0.5f}")
```

Bu yaklaÅŸÄ±m, doÄŸrudan test tahminleri ile Ã§alÄ±ÅŸÄ±rken mÃ¼kemmel ÅŸekilde iÅŸler. Ancak, bunun yerine Ã§apraz doÄŸrulama (cross-validation) sÄ±rasÄ±nda sonuÃ§larÄ± ortalamaya Ã§alÄ±ÅŸÄ±yorsanÄ±z, eÄŸitim verilerinizin tahmin aralÄ±ÄŸÄ±nÄ±n, test tahminlerinizin aralÄ±ÄŸÄ±ndan farklÄ± olmasÄ± nedeniyle sorunlarla karÅŸÄ±laÅŸabilirsiniz. Bu durumda, sorunu Ã§Ã¶zmek iÃ§in bir kalibrasyon modeli eÄŸitebilirsiniz (Scikit-learn'deki olasÄ±lÄ±k kalibrasyonu iÃ§in [bu baÄŸlantÄ±ya](https://scikit-learn.org/stable/modules/calibration.html) bakabilirsiniz ve 5. BÃ¶lÃ¼me de gÃ¶z atabilirsiniz), bÃ¶ylece her bir modelinizin tahminlerini doÄŸru ve karÅŸÄ±laÅŸtÄ±rÄ±labilir olasÄ±lÄ±klara dÃ¶nÃ¼ÅŸtÃ¼rebilirsiniz.

### Blending models using a meta-model *(Meta-model kullanarak modelleri karÄ±ÅŸtÄ±rma)*

Netflix yarÄ±ÅŸmasÄ± (1. BÃ¶lÃ¼mde ayrÄ±ntÄ±lÄ± olarak tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z) yalnÄ±zca ortalama almanÄ±n veri bilimi yarÄ±ÅŸmalarÄ±ndaki zor problemler iÃ§in avantajlÄ± olacaÄŸÄ±nÄ± gÃ¶stermedi; aynÄ± zamanda, bir modelin, modellerinizin sonuÃ§larÄ±nÄ± daha etkili bir ÅŸekilde ortalamak iÃ§in kullanÄ±labileceÄŸi fikrini de ortaya koydu. YarÄ±ÅŸmayÄ± kazanan BigChaos takÄ±mÄ±, makalelerinde (TÃ¶scher, A., Jahrer, M., ve Bell, R.M. *The BigChaos Solution to the Netflix Grand Prize. Netflix prize documentation â€“ 2009*) pek Ã§ok kez *blending* (karÄ±ÅŸtÄ±rma) konusuna deÄŸindi ve bunun etkinliÄŸi ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ± hakkÄ±nda birÃ§ok ipucu verdi.

KÄ±saca sÃ¶ylemek gerekirse, *blending*, tahminleri birleÅŸtirmek iÃ§in kullanÄ±lan aÄŸÄ±rlÄ±klarÄ±n, bir *holdout* seti ve bu set Ã¼zerinde eÄŸitilmiÅŸ bir meta-model aracÄ±lÄ±ÄŸÄ±yla tahmin edildiÄŸi bir tÃ¼r aÄŸÄ±rlÄ±klÄ± ortalama iÅŸlemidir. Meta-model, baÅŸka makine Ã¶ÄŸrenimi modellerinin Ã§Ä±ktÄ±larÄ±ndan Ã¶ÄŸrenen bir makine Ã¶ÄŸrenimi algoritmasÄ±dÄ±r. Genellikle bir meta-Ã¶ÄŸrenici (meta-learner) doÄŸrusal bir modeldir (ama bazen doÄŸrusal olmayan bir model de olabilir; bu konuda daha fazla bilgi bir sonraki bÃ¶lÃ¼mde verilecektir), ancak aslÄ±nda istediÄŸiniz herhangi bir modeli kullanabilirsiniz, ancak bunun bazÄ± riskleri vardÄ±r ki bunlarÄ± daha sonra tartÄ±ÅŸacaÄŸÄ±z.

Bir *blending* elde etme iÅŸlemi oldukÃ§a basittir:

1. **Modelinizi inÅŸa etmeye baÅŸlamadan Ã¶nce**, eÄŸitim verilerinden rastgele bir *holdout* Ã¶rneÄŸi Ã§Ä±karÄ±rsÄ±nÄ±z (bir takÄ±mda iseniz, herkesin aynÄ± *holdout* Ã¶rneÄŸini kullanmasÄ± gerekir). Genellikle *holdout*, mevcut verilerin %10'u civarÄ±ndadÄ±r; ancak durumlara gÃ¶re (Ã¶rneÄŸin, eÄŸitim verilerinizdeki Ã¶rnek sayÄ±sÄ±, katmanlar) bu daha az veya daha fazla da olabilir. Her zamanki gibi, Ã¶rnekleme iÅŸleminde temsiliyet saÄŸlamak iÃ§in *stratifikasyon* kullanabilir ve Ã¶rnekleminizin eÄŸitim setinin geri kalanÄ±yla gerÃ§ekten uyumlu olup olmadÄ±ÄŸÄ±nÄ± test etmek iÃ§in *adversarial validation* (dÃ¼ÅŸman doÄŸrulama) kullanabilirsiniz.
2. Kalan eÄŸitim verisi Ã¼zerinde tÃ¼m modellerinizi eÄŸitirsiniz.
3. *Holdout* ve test verisi Ã¼zerinde tahmin yaparsÄ±nÄ±z.
4. *Holdout* tahminlerini bir meta-Ã¶ÄŸrenicide eÄŸitim verisi olarak kullanÄ±rsÄ±nÄ±z ve meta-Ã¶ÄŸrenici modelini kullanarak, modellerinizin test tahminlerini kullanarak nihai test tahminlerini hesaplayabilirsiniz. Alternatif olarak, meta-Ã¶ÄŸreniciyi, aÄŸÄ±rlÄ±klÄ± ortalamada kullanÄ±lacak tahmin edicilerin seÃ§imini ve aÄŸÄ±rlÄ±klarÄ±nÄ± bulmak iÃ§in kullanabilirsiniz.

Bu tÃ¼r bir prosedÃ¼rÃ¼n birÃ§ok avantajÄ± ve dezavantajÄ± vardÄ±r. Avantajlardan baÅŸlayalÄ±m. Ä°lk olarak, uygulamasÄ± kolaydÄ±r; tek yapmanÄ±z gereken *holdout* Ã¶rneÄŸini belirlemektir. AyrÄ±ca, bir meta-Ã¶ÄŸrenme algoritmasÄ± kullanmak, kamu liderlik tablosunda test yapmadan en iyi aÄŸÄ±rlÄ±klarÄ± bulmanÄ±zÄ± saÄŸlar.

ZayÄ±f yÃ¶nlere gelince, bazen Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ve kullandÄ±ÄŸÄ±nÄ±z modellerin tÃ¼rÃ¼ne baÄŸlÄ± olarak, eÄŸitim Ã¶rneklerinin sayÄ±sÄ±nÄ± azaltmak, tahminlerinizin varyansÄ±nÄ± artÄ±rabilir. DahasÄ±, *holdout* Ã¶rneÄŸini nasÄ±l Ã¶rneklediÄŸinize Ã§ok dikkat etseniz bile, hala adaptif aÅŸÄ±rÄ± uyum (adaptive overfitting) sorunuyla karÅŸÄ±laÅŸabilirsiniz; yani *holdout*'a uygun aÄŸÄ±rlÄ±klarÄ± bulmak, ancak bu aÄŸÄ±rlÄ±klar genellenebilir olmayabilir, Ã¶zellikle de Ã§ok karmaÅŸÄ±k bir meta-Ã¶ÄŸrenici kullanÄ±yorsanÄ±z. Son olarak, test amaÃ§larÄ± iÃ§in bir *holdout* kullanmanÄ±n, model doÄŸrulama bÃ¶lÃ¼mÃ¼nde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z eÄŸitim ve test verisi ayrÄ±mÄ±nÄ±n aynÄ± sÄ±nÄ±rlamalarÄ± vardÄ±r: EÄŸer *holdout* Ã¶rneÄŸinizin Ã¶rneklem bÃ¼yÃ¼klÃ¼ÄŸÃ¼ Ã§ok kÃ¼Ã§Ã¼kse veya bir sebepten Ã¶tÃ¼rÃ¼ Ã¶rneklemeniz temsiliyet gÃ¶stermiyorsa, gÃ¼venilir bir tahmin elde edemezsiniz.

#### Best practices for blending *(KarÄ±ÅŸtÄ±rma iÃ§in en iyi uygulamalar)*

Blending (birleÅŸtirme) yÃ¶nteminde kullanacaÄŸÄ±nÄ±z meta-Ã¶ÄŸrenici tÃ¼rÃ¼ bÃ¼yÃ¼k bir fark yaratabilir. En yaygÄ±n seÃ§enekler, lineer bir model veya lineer olmayan bir model kullanmaktÄ±r. Lineer modeller arasÄ±nda, tercih edilenler lineer veya lojistik regresyonlardÄ±r. DÃ¼zenlenmiÅŸ (regularize edilmiÅŸ) bir model kullanmak, iÅŸe yaramayan modelleri elerken (L1 dÃ¼zenlemesi) veya daha az faydalÄ± olanlarÄ±n etkisini azaltÄ±rken (L2 dÃ¼zenlemesi) yardÄ±mcÄ± olur. Bu tÃ¼r meta-Ã¶ÄŸrenicileri kullanmanÄ±n bir sÄ±nÄ±rlamasÄ±, bazÄ± modellere negatif katkÄ± atanabilmesidir; bunu modeldeki katsayÄ± deÄŸerlerinden gÃ¶rebilirsiniz. Bu duruma rastladÄ±ÄŸÄ±nÄ±zda, model genellikle overfitting (aÅŸÄ±rÄ± uyum) yapÄ±yor demektir; Ã§Ã¼nkÃ¼ tÃ¼m modellerin topluluk (ensemble) oluÅŸtururken pozitif katkÄ±da bulunmasÄ± gerekir (veya en kÃ¶tÃ¼ ihtimalle hiÃ§ katkÄ±da bulunmamasÄ± gerekir). Scikit-learnâ€™Ã¼n en son sÃ¼rÃ¼mleri, yalnÄ±zca pozitif aÄŸÄ±rlÄ±klar uygulamanÄ±za ve interceptâ€™i kaldÄ±rmanÄ±za olanak tanÄ±r. Bu kÄ±sÄ±tlamalar bir dÃ¼zenleyici (regularizer) gibi davranÄ±r ve aÅŸÄ±rÄ± uyumu Ã¶nler.

Lineer olmayan modellerin meta-Ã¶ÄŸrenici olarak kullanÄ±mÄ± daha az yaygÄ±ndÄ±r Ã§Ã¼nkÃ¼ regresyon ve ikili sÄ±nÄ±flandÄ±rma problemlerinde aÅŸÄ±rÄ± uyum eÄŸilimi gÃ¶sterirler. Ancak, sÄ±nÄ±flar arasÄ± karmaÅŸÄ±k iliÅŸkileri modelleyebildikleri iÃ§in Ã§ok sÄ±nÄ±flÄ± (multiclass) ve Ã§ok etiketli (multilabel) sÄ±nÄ±flandÄ±rma problemlerinde genellikle iyi performans gÃ¶sterirler. AyrÄ±ca, yalnÄ±zca modellerin tahminlerini deÄŸil, orijinal Ã¶zellikleri de saÄŸlarsanÄ±z, faydalÄ± etkileÅŸimleri tespit ederek hangi modellere daha Ã§ok gÃ¼venileceÄŸini doÄŸru ÅŸekilde seÃ§ebilirler.

Bir sonraki Ã¶rneÄŸimizde Ã¶nce lineer bir model (lojistik regresyon) ile blending yapmayÄ±, ardÄ±ndan lineer olmayan bir yaklaÅŸÄ±m (random forest) kullanmayÄ± deniyoruz. Ã–nce eÄŸitim setini, blend elemanlarÄ± iÃ§in bir eÄŸitim parÃ§asÄ± ve meta-Ã¶ÄŸrenici iÃ§in bir holdout parÃ§asÄ± olarak ayÄ±rÄ±yoruz. ArdÄ±ndan modelleri eÄŸitim parÃ§asÄ±nda fit ediyor ve holdout Ã¼zerinde tahmin yapÄ±yoruz.

```python
from sklearn.preprocessing import StandardScaler
X_blend, X_holdout, y_blend, y_holdout = train_test_split(X_train, y_train, test_size=0.25, random_state=0)

model_1.fit(X_blend, y_blend)
model_2.fit(X_blend, y_blend)
model_3.fit(X_blend, y_blend)

proba = np.stack([
    model_1.predict_proba(X_holdout)[:, 1],
    model_2.predict_proba(X_holdout)[:, 1],
    model_3.predict_proba(X_holdout)[:, 1]
]).T

scaler = StandardScaler()
proba = scaler.fit_transform(proba)
```

ArtÄ±k holdout Ã¼zerinde tahmin edilen olasÄ±lÄ±klarÄ± kullanarak lineer meta-Ã¶ÄŸrenicimizi eÄŸitebiliriz:

```python
from sklearn.linear_model import LogisticRegression
blender = LogisticRegression(solver='liblinear')
blender.fit(proba, y_holdout)
print(blender.coef_)
```

Elde edilen katsayÄ±lar:

```
[[0.78911314 0.47202077 0.75115854]]
```

KatsayÄ±lara bakarak hangi modelin meta-ensembleâ€™a daha fazla katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± anlayabiliriz. Ancak unutmayÄ±n, katsayÄ±lar ayrÄ±ca iyi kalibre edilmemiÅŸ olasÄ±lÄ±klarÄ± yeniden Ã¶lÃ§eklendirir; dolayÄ±sÄ±yla bir model iÃ§in daha bÃ¼yÃ¼k bir katsayÄ±, onun en Ã¶nemli model olduÄŸu anlamÄ±na gelmeyebilir. KatsayÄ±larÄ± kullanarak her modelin blend iÃ§indeki rolÃ¼nÃ¼ anlamak istiyorsanÄ±z, Ã¶nce onlarÄ± standartlaÅŸtÄ±rarak yeniden Ã¶lÃ§eklendirmeniz gerekir (bizim Ã¶rneÄŸimizde Scikit-learnâ€™Ã¼n `StandardScaler`â€™Ä± kullanÄ±ldÄ±).

Ã‡Ä±ktÄ±mÄ±z, SVC ve k-en yakÄ±n komÅŸu modellerinin blend iÃ§inde random forest modeline gÃ¶re daha yÃ¼ksek aÄŸÄ±rlÄ±k aldÄ±ÄŸÄ±nÄ± gÃ¶steriyor; katsayÄ±larÄ± birbirine yakÄ±n ve ikisi de random forest katsayÄ±sÄ±ndan bÃ¼yÃ¼k.

Meta-model eÄŸitildikten sonra, test verisi Ã¼zerinde tahmin yapabilir ve performansÄ±nÄ± kontrol edebiliriz:

```python
test_proba = np.stack([
    model_1.predict_proba(X_test)[:, 1],
    model_2.predict_proba(X_test)[:, 1],
    model_3.predict_proba(X_test)[:, 1]
]).T

blending = blender.predict_proba(test_proba)[:, 1]
ras = roc_auc_score(y_true=y_test, y_score=blending)
print(f"ROC-AUC for linear blending {model} is: {ras:0.5f}")
```

AynÄ± iÅŸlemi, Ã¶rneÄŸin random forest gibi lineer olmayan bir meta-Ã¶ÄŸrenici ile de deneyebiliriz:

```python
blender = RandomForestClassifier()
blender.fit(proba, y_holdout)

test_proba = np.stack([
    model_1.predict_proba(X_test)[:, 1],
    model_2.predict_proba(X_test)[:, 1],
    model_3.predict_proba(X_test)[:, 1]
]).T

blending = blender.predict_proba(test_proba)[:, 1]
ras = roc_auc_score(y_true=y_test, y_score=blending)
print(f"ROC-AUC for non-linear blending {model} is: {ras:0.5f}")
```

Lineer veya lineer olmayan bir meta-Ã¶ÄŸrenici kullanmaya alternatif olarak Caruana, Niculescu-Mizil, Crew ve Ksikes tarafÄ±ndan formÃ¼le edilen ensemble selection tekniÄŸi vardÄ±r.

Ensemble selection aslÄ±nda aÄŸÄ±rlÄ±klÄ± bir ortalamadÄ±r, dolayÄ±sÄ±yla basit bir lineer kombinasyon olarak dÃ¼ÅŸÃ¼nÃ¼lebilir. Ancak bu, kÄ±sÄ±tlÄ± bir lineer kombinasyondur (Ã§Ã¼nkÃ¼ bir hill-climbing optimizasyonunun parÃ§asÄ±dÄ±r) ve ayrÄ±ca modellerin seÃ§imini yapar ve yalnÄ±zca pozitif aÄŸÄ±rlÄ±klarÄ± uygular. Bu, aÅŸÄ±rÄ± uyum riskini en aza indirir ve daha kompakt bir Ã§Ã¶zÃ¼m saÄŸlar, Ã§Ã¼nkÃ¼ Ã§Ã¶zÃ¼m bir model seÃ§imini iÃ§erir. Bu aÃ§Ä±dan ensemble selection, overfitting riskinin yÃ¼ksek olduÄŸu tÃ¼m problemler iÃ§in ve gerÃ§ek dÃ¼nya uygulamalarÄ± iÃ§in Ã¶nerilir.

Meta-Ã¶ÄŸrenici kullanÄ±rken, kendi maliyet fonksiyonunun optimizasyonuna baÄŸlÄ±sÄ±nÄ±z ve bu, yarÄ±ÅŸmada kullanÄ±lan metrikten farklÄ± olabilir. Ensemble selectionâ€™Ä±n bir diÄŸer avantajÄ±, herhangi bir deÄŸerlendirme fonksiyonuna gÃ¶re optimize edilebilmesidir; dolayÄ±sÄ±yla yarÄ±ÅŸma metrikleri tipik ML model optimizasyonundan farklÄ± olduÄŸunda Ã¶nerilir.

Daha fazla detay iÃ§in ÅŸu makaleyi okuyabilirsiniz:
*Caruana, R., Niculescu-Mizil, A., Crew, G., and Ksikes, A. â€œEnsemble selection from libraries of modelsâ€ (Proceedings of the Twenty-First International Conference on Machine Learning, 2004).*

Ensemble selectionâ€™Ä± uygulamak iÃ§in adÄ±mlar ÅŸunlardÄ±r:

1. EÄŸitilmiÅŸ modelleriniz ve bir holdout Ã¶rneÄŸinizle baÅŸlayÄ±n.
2. TÃ¼m modelleri holdout Ã¼zerinde test edin ve deÄŸerlendirme metriÄŸine gÃ¶re en etkili olanlarÄ± seÃ§in (ensemble selection).
3. ArdÄ±ndan, seÃ§ilmiÅŸ modele eklenebilecek diÄŸer modelleri test edin, bÃ¶ylece Ã¶nerilen seÃ§imin ortalamasÄ± Ã¶nceki seÃ§imden daha iyi olsun. Bunu, replacement (tekrar) ile veya tekrarsÄ±z yapabilirsiniz. TekrarsÄ±zda, bir model seÃ§ime yalnÄ±zca bir kez eklenir; bu durumda prosedÃ¼r, ileri seÃ§im (forward selection) sonrasÄ± basit bir ortalama gibidir. Tekrar ile, bir modeli seÃ§ime birden fazla kez ekleyebilirsiniz, bÃ¶ylece aÄŸÄ±rlÄ±klÄ± ortalamaya benzer.
4. Daha fazla iyileÅŸtirme mÃ¼mkÃ¼n olmadÄ±ÄŸÄ±nda durun ve ensemble selectionâ€™Ä± kullanÄ±n.

Basit bir kod Ã¶rneÄŸi:

```python
X_blend, X_holdout, y_blend, y_holdout = train_test_split(X_train, y_train, test_size=0.5, random_state=0)

model_1.fit(X_blend, y_blend)
model_2.fit(X_blend, y_blend)
model_3.fit(X_blend, y_blend)

proba = np.stack([
    model_1.predict_proba(X_holdout)[:, 1],
    model_2.predict_proba(X_holdout)[:, 1],
    model_3.predict_proba(X_holdout)[:, 1]
]).T

iterations = 100
baseline = 0.5
models = []

for i in range(iterations):
    challengers = []
    for j in range(proba.shape[1]):
        new_proba = np.stack(proba[:, models + [j]])
        score = roc_auc_score(y_true=y_holdout, y_score=np.mean(new_proba, axis=1))
        challengers.append([score, j])
    
    challengers = sorted(challengers, key=lambda x: x[0], reverse=True)
    best_score, best_model = challengers[0]
    if best_score > baseline:
        models.append(best_model)
        baseline = best_score
    else:
        break

from collections import Counter
freqs = Counter(models)
weights = {key: freq/len(models) for key, freq in freqs.items()}
print(weights)
```

Bu prosedÃ¼rÃ¼ Ã§eÅŸitli ÅŸekillerde daha sofistike hale getirebilirsiniz. BaÅŸlangÄ±Ã§ta overfitting riski yÃ¼ksek olduÄŸu iÃ§in, rastgele baÅŸlatÄ±lmÄ±ÅŸ bir ensemble seti ile baÅŸlayabilir veya yazarlarÄ±n Ã¶nerdiÄŸi gibi, en iyi n performans gÃ¶steren modellerle baÅŸlayabilirsiniz. DiÄŸer bir varyasyon, her iterasyonda seÃ§ime giren modeller Ã¼zerinde Ã¶rnekleme uygulamak; yani bazÄ± modelleri rastgele hariÃ§ tutmak. Bu, sÃ¼rece rastgelelik ekler ve belirli modellerin seÃ§im Ã¼zerinde baskÄ±n olmasÄ±nÄ± engeller.

### Stacking models together *(Modelleri yÄ±ÄŸÄ±nlama)*

**Stacking**, ilk kez David Wolpert'in makalesinde (Wolpert, D. H. Stacked generalization. Neural Networks 5.2 â€“ 1992) bahsedilmiÅŸtir, ancak bu fikir yÄ±llarca yaygÄ±n olarak kabul edilmedi ve ancak 2019 AralÄ±k ayÄ±nda Scikit-learn sÃ¼rÃ¼m 0.22 ile bir stacking sarmalayÄ±cÄ±sÄ± (wrapper) uygulanmÄ±ÅŸtÄ±r. Bunun baÅŸlÄ±ca nedeni Ã¶nce Netflix yarÄ±ÅŸmasÄ±, ardÄ±ndan Kaggle yarÄ±ÅŸmalarÄ±nÄ±n etkisiyle bu yÃ¶ntemlerin popÃ¼lerleÅŸmesidir.

Stacking yÃ¶nteminde her zaman bir meta-Ã¶ÄŸrenici vardÄ±r. Ancak bu sefer, model bir *holdout* Ã¼zerinde deÄŸil, tÃ¼m eÄŸitim seti Ã¼zerinde eÄŸitilir; bunu saÄŸlayan strateji ise *out-of-fold (OOF)* tahmin stratejisidir. Bu stratejiyi, 6. BÃ¶lÃ¼mâ€™de "Ä°yi Bir DoÄŸrulama TasarÄ±mÄ±" baÅŸlÄ±ÄŸÄ±nda zaten tartÄ±ÅŸmÄ±ÅŸtÄ±k. OOF tahmininde, her bir model iÃ§in geÃ§erli bir k-fold Ã§apraz doÄŸrulama bÃ¶lmesi (k-fold cross-validation split) yapÄ±lÄ±r. *Replicable* (yinelemeli) olmasÄ±, her bir eÄŸitim ve test setinin her bir doÄŸrulama turunda kaydedilmesiyle, ya da rastgele tohum (random seed) kullanÄ±larak doÄŸrulama ÅŸemasÄ±nÄ±n her model iÃ§in yeniden oluÅŸturulabilir olmasÄ± anlamÄ±na gelir.

Netflix yarÄ±ÅŸmasÄ±nda, stacking ve blending terimleri genellikle birbirinin yerine kullanÄ±lÄ±yordu, ancak Wolpertâ€™in orijinal olarak geliÅŸtirdiÄŸi yÃ¶ntem, *holdout seti* yerine *k-fold Ã§apraz doÄŸrulama* tabanlÄ± bir ÅŸema kullanÄ±yordu. AslÄ±nda stackingâ€™in temel fikri, varyansÄ± azaltmak deÄŸildir; daha Ã§ok **bias**â€™Ä± (yanlÄ±lÄ±k) azaltmaktÄ±r. Ã‡Ã¼nkÃ¼ stackingâ€™e dahil olan her modelin, verilerdeki bir kÄ±smÄ± Ã¶ÄŸrenmesi ve bu bilgilerin nihai meta-Ã¶ÄŸrenicide birleÅŸtirilmesi beklenir.

Åimdi, eÄŸitim verileri Ã¼zerinde OOF tahminlerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± hatÄ±rlayalÄ±m. Bir modeli test ederken, doÄŸrulama turunun her bir aÅŸamasÄ±nda, eÄŸitim verilerinin bir kÄ±smÄ± Ã¼zerinde eÄŸitim yapar ve geri kalan kÄ±sÄ±mla doÄŸrulama yaparsÄ±nÄ±z.

DoÄŸrulama tahminlerini kaydedip ardÄ±ndan bunlarÄ± orijinal eÄŸitim Ã¶rneklerinin sÄ±rasÄ±na gÃ¶re yeniden sÄ±raladÄ±ÄŸÄ±nÄ±zda, modelinizin, kullandÄ±ÄŸÄ±nÄ±z aynÄ± eÄŸitim seti Ã¼zerinde bir tahmin elde edersiniz. Ancak, birden fazla model kullandÄ±ÄŸÄ±nÄ±z ve her bir modelin eÄŸitimde kullanmadÄ±ÄŸÄ± Ã¶rnekler Ã¼zerinde tahmin yaptÄ±ÄŸÄ± iÃ§in, eÄŸitim seti tahminlerinizde aÅŸÄ±rÄ± uyum (overfitting) etkisi olmamalÄ±dÄ±r.

TÃ¼m modelleriniz iÃ§in OOF tahminlerini elde ettikten sonra, ilk seviye tahminleri (first-level predictions) baz alarak bir meta-Ã¶ÄŸrenici oluÅŸturabilir veya Ã¶nceki OOF tahminlerinin Ã¼zerine daha fazla OOF tahminleri ekleyerek (ikinci veya daha yÃ¼ksek seviyeli tahminler) birden fazla stacking katmanÄ± oluÅŸturabilirsiniz. Bu, Wolpert'in kendisinin sunduÄŸu bir fikirle uyumludur: Birden fazla meta-Ã¶ÄŸrenici kullanarak, aslÄ±nda geri yayÄ±lÄ±m (backpropagation) olmadan tamamen baÄŸlantÄ±lÄ± bir ileri beslemeli sinir aÄŸÄ±nÄ±n (feedforward neural network) yapÄ±sÄ±nÄ± taklit ediyorsunuz. Bu yapÄ±da, aÄŸÄ±rlÄ±klar her katman iÃ§in ayrÄ± ayrÄ± tahminsel performansÄ± maksimize etmek amacÄ±yla optimize edilir. Pratikte, birden fazla katmanÄ±n stacking yapÄ±lmasÄ±, tek baÅŸÄ±na algoritmalarÄ±n en iyi sonucu elde edemediÄŸi karmaÅŸÄ±k problemlerde oldukÃ§a etkili ve iyi sonuÃ§lar verir.

Bunun yanÄ± sÄ±ra, stacking'in ilginÃ§ bir yÃ¶nÃ¼, ortalama alma ve genellikle blending gibi yÃ¶ntemlere kÄ±yasla, **karÅŸÄ±laÅŸtÄ±rÄ±labilir tahmin gÃ¼cÃ¼ne sahip modellere** ihtiyaÃ§ duymamanÄ±zdÄ±r. AslÄ±nda, daha dÃ¼ÅŸÃ¼k performans gÃ¶steren modeller bile bir stacking ensemble (topluluk) iÃ§inde etkili olabilir. Ã–rneÄŸin, bir k-en yakÄ±n komÅŸu (k-nearest neighbors) modeli, bir gradient boosting Ã§Ã¶zÃ¼mÃ¼yle kÄ±yaslanamaz olabilir; ancak OOF tahminlerini stacking iÃ§in kullanÄ±rken, bu model topluluÄŸun tahminsel performansÄ±nÄ± artÄ±rabilir.

TÃ¼m stacking katmanlarÄ±nÄ± eÄŸittikten sonra, tahmin yapma zamanÄ± gelmiÅŸtir. Ã‡eÅŸitli stacking aÅŸamalarÄ±nda kullanÄ±lan tahminlerin Ã¼retimi konusunda iki yolunuz vardÄ±r. Wolpertâ€™in orijinal makalesi, tÃ¼m eÄŸitim verileriniz Ã¼zerinde modellerinizi yeniden eÄŸitmenizi ve ardÄ±ndan bu yeniden eÄŸitilmiÅŸ modelleri test seti Ã¼zerinde tahmin yapmak iÃ§in kullanmanÄ±zÄ± Ã¶nerir. Ancak pratikte, birÃ§ok Kaggle yarÄ±ÅŸmacÄ±sÄ±, modelleri yeniden eÄŸitmek yerine, her fold iÃ§in oluÅŸturulan modelleri doÄŸrudan kullanÄ±r ve test seti Ã¼zerinde birden fazla tahmin yaparak bunlarÄ± sonunda ortalamaktadÄ±r.

Bizim deneyimimize gÃ¶re, stacking genellikle tÃ¼m mevcut verilerle yeniden eÄŸitim yaparak test seti Ã¼zerinde tahmin yapÄ±ldÄ±ÄŸÄ±nda daha etkili olur, Ã¶zellikle dÃ¼ÅŸÃ¼k sayÄ±da k-fold kullanÄ±ldÄ±ÄŸÄ±nda. Bu durum, Ã¶rnek tutarlÄ±lÄ±ÄŸÄ±nÄ±n tahmin kalitesi Ã¼zerinde gerÃ§ekten fark yaratabilir, Ã§Ã¼nkÃ¼ daha az veriyle eÄŸitim yapmak, tahminlerde daha fazla varyans anlamÄ±na gelir. 6. BÃ¶lÃ¼m'de tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, OOF tahminleri oluÅŸtururken yÃ¼ksek sayÄ±da fold kullanmak her zaman daha iyidir; 10 ile 20 arasÄ±nda bir sayÄ± Ã¶nerilir. Bu, dÄ±ÅŸarÄ±da bÄ±rakÄ±lan Ã¶rnek sayÄ±sÄ±nÄ± sÄ±nÄ±rlar ve tÃ¼m veriler Ã¼zerinde yeniden eÄŸitim yapmadan, Ã§apraz doÄŸrulama eÄŸitilmiÅŸ modellerden elde edilen tahminlerin ortalamasÄ±nÄ± test seti tahmininizi elde etmek iÃ§in kullanabilirsiniz.

Bir sonraki Ã¶rneÄŸimizde, sadece beÅŸ CV foldâ€™u kullanarak ve sonuÃ§larÄ± iki kez stacking yaparak iÅŸlemi gÃ¶rsel olarak gÃ¶stereceÄŸiz. AÅŸaÄŸÄ±daki diyagramda, verilerin ve modellerin stacking sÃ¼recindeki farklÄ± aÅŸamalar arasÄ±nda nasÄ±l hareket ettiÄŸini izleyebilirsiniz:

![](im/1063.png)

**Dikkat edilmesi gerekenler:**

* EÄŸitim verisi, stacking'in her iki seviyesine de beslenir (stacking'in ikinci seviyesindeki OOF tahminleri eÄŸitim verisiyle birleÅŸtirilir).
* CV dÃ¶ngÃ¼lerinden OOF tahminleri alÄ±ndÄ±ktan sonra, modeller tÃ¼m eÄŸitim verisi Ã¼zerinde yeniden eÄŸitilir.
* Son tahminler, tÃ¼m stacking tahminlerinin basit bir ortalamasÄ±dÄ±r.

Åimdi, bu diyagramÄ±n Python komutlarÄ±na nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ anlamak iÃ§in koda gÃ¶z atalÄ±m, Ã¶nce eÄŸitim aÅŸamasÄ±nÄ±n birinci seviyesiyle baÅŸlayalÄ±m:

```python
from sklearn.model_selection import KFold
kf = KFold(n_splits=5, shuffle=True, random_state=0)
scores = list()
first_lvl_oof = np.zeros((len(X_train), 3))
first_lvl_preds = np.zeros((len(X_test), 3))

for k, (train_index, val_index) in enumerate(kf.split(X_train)):
    model_1.fit(X_train[train_index, :], y_train[train_index])
    first_lvl_oof[val_index, 0] = model_1.predict_proba(X_train[val_index, :])[:, 1]
    
    model_2.fit(X_train[train_index, :], y_train[train_index])
    first_lvl_oof[val_index, 1] = model_2.predict_proba(X_train[val_index, :])[:, 1]
    
    model_3.fit(X_train[train_index, :], y_train[train_index])
    first_lvl_oof[val_index, 2] = model_3.predict_proba(X_train[val_index, :])[:, 1]
```

Ä°lk katmandan sonra, tÃ¼m veri seti Ã¼zerinde yeniden eÄŸitim yapÄ±yoruz:

```python
model_1.fit(X_train, y_train)
first_lvl_preds[:, 0] = model_1.predict_proba(X_test)[:, 1]
model_2.fit(X_train, y_train)
first_lvl_preds[:, 1] = model_2.predict_proba(X_test)[:, 1]
model_3.fit(X_train, y_train)
first_lvl_preds[:, 2] = model_3.predict_proba(X_test)[:, 1]
```

Ä°kinci stacking katmanÄ±nda, ilk katmandaki modelleri yeniden kullanacaÄŸÄ±z ve stacking OOF tahminlerini mevcut deÄŸiÅŸkenlere ekleyeceÄŸiz:

```python
second_lvl_oof = np.zeros((len(X_train), 3))
second_lvl_preds = np.zeros((len(X_test), 3))

for k, (train_index, val_index) in enumerate(kf.split(X_train)):
    skip_X_train = np.hstack([X_train, first_lvl_oof])
    model_1.fit(skip_X_train[train_index, :], y_train[train_index])
    second_lvl_oof[val_index, 0] = model_1.predict_proba(skip_X_train[val_index, :])[:, 1]
    
    model_2.fit(skip_X_train[train_index, :], y_train[train_index])
    second_lvl_oof[val_index, 1] = model_2.predict_proba(skip_X_train[val_index, :])[:, 1]
    
    model_3.fit(skip_X_train[train_index, :], y_train[train_index])
    second_lvl_oof[val_index, 2] = model_3.predict_proba(skip_X_train[val_index, :])[:, 1]
```

Tekrar, ikinci katman iÃ§in tÃ¼m veriler Ã¼zerinde yeniden eÄŸitim yapÄ±yoruz:

```python
skip_X_test = np.hstack([X_test, first_lvl_preds])
model_1.fit(skip_X_train, y_train)
second_lvl_preds[:, 0] = model_1.predict_proba(skip_X_test)[:, 1]
model_2.fit(skip_X_train, y_train)
second_lvl_preds[:, 1] = model_2.predict_proba(skip_X_test)[:, 1]
model_3.fit(skip_X_train, y_train)
second_lvl_preds[:, 2] = model_3.predict_proba(skip_X_test)[:, 1]
```

Stacking, ikinci katmandan elde edilen tÃ¼m OOF sonuÃ§larÄ±nÄ±n ortalamasÄ±nÄ± alarak tamamlanÄ±r:

```python
arithmetic = second_lvl_preds.mean(axis=1)
ras = roc_auc_score(y_true=y_test, y_score=arithmetic)
scores.append(ras)
print(f"Stacking ROC-AUC: {ras:0.5f}")
```

SonuÃ§ olarak elde edilen ROC-AUC skoru yaklaÅŸÄ±k 0.90424â€™tÃ¼r. Bu, aynÄ± veri ve modellerle yapÄ±lan Ã¶nceki blending ve averaging denemelerinden daha iyidir.

#### Stacking variations *(YÄ±ÄŸÄ±nlama varyasyonlarÄ±)*

Stacking ile ilgili ana deÄŸiÅŸiklikler, test verilerinin katmanlar arasÄ±nda nasÄ±l iÅŸlendiÄŸi, sadece yÄ±ÄŸÄ±lan OOF tahminlerini mi yoksa tÃ¼m yÄ±ÄŸÄ±lma katmanlarÄ±nda orijinal Ã¶zellikleri de kullanmanÄ±n mÄ± tercih edileceÄŸi, son modelin ne olacaÄŸÄ± ve aÅŸÄ±rÄ± uyumdan kaÃ§Ä±nmak iÃ§in Ã§eÅŸitli hileler ile ilgilidir.

KiÅŸisel olarak denediÄŸimiz ve en etkili bulduÄŸumuz bazÄ± Ã§Ã¶zÃ¼mleri burada tartÄ±ÅŸacaÄŸÄ±z:
* Optimizasyon kullanÄ±labilir veya kullanÄ±lmayabilir. BazÄ± Ã§Ã¶zÃ¼mler, tekil modelleri optimize etmeye fazla Ã¶nem vermezken; diÄŸerleri sadece son katmanlarÄ±, bazÄ±larÄ± ise ilk katmanlarÄ± optimize eder. Deneyimlerimize dayanarak, tekil modellerin optimizasyonu Ã¶nemlidir ve bunu yÄ±ÄŸÄ±lma ansamblÄ±nda olabildiÄŸince erken yapmayÄ± tercih ederiz.
* Modeller, farklÄ± yÄ±ÄŸÄ±lma katmanlarÄ±nda farklÄ± olabilir veya aynÄ± model sÄ±rasÄ± her yÄ±ÄŸÄ±lma katmanÄ±nda tekrar edilebilir. Burada genel bir kural yoktur, Ã§Ã¼nkÃ¼ bu gerÃ§ekten probleme baÄŸlÄ±dÄ±r. Daha etkili olan model tÃ¼rleri problemine gÃ¶re deÄŸiÅŸebilir. Genel bir Ã¶neri olarak, gradyan arttÄ±rma Ã§Ã¶zÃ¼mleri ve yapay sinir aÄŸlarÄ±nÄ± birleÅŸtirmek bizleri hiÃ§bir zaman hayal kÄ±rÄ±klÄ±ÄŸÄ±na uÄŸratmamÄ±ÅŸtÄ±r.
* YÄ±ÄŸÄ±lma prosedÃ¼rÃ¼nÃ¼n ilk seviyesinde, mÃ¼mkÃ¼n olan her kadar model oluÅŸturun. Ã–rneÄŸin, problem sÄ±nÄ±flandÄ±rma ise bir regresyon modeli deneyebilirsiniz ve tersi de geÃ§erlidir. FarklÄ± hiperparametre ayarlarÄ±na sahip farklÄ± modeller de kullanabilirsiniz, bÃ¶ylece yÄ±ÄŸÄ±lama sizin iÃ§in karar vereceÄŸinden fazla kapsamlÄ± bir optimizasyon yapmaktan kaÃ§Ä±nÄ±rsÄ±nÄ±z. Yapay sinir aÄŸlarÄ± kullanÄ±yorsanÄ±z, rastgele baÅŸlatma tohumunu deÄŸiÅŸtirmek, Ã§eÅŸitlendirilmiÅŸ bir model yÄ±ÄŸÄ±nÄ± oluÅŸturmak iÃ§in yeterli olabilir. AyrÄ±ca farklÄ± Ã¶zellik mÃ¼hendislikleri kullanan modelleri de deneyebilir ve hatta denetimsiz Ã¶ÄŸrenme yÃ¶ntemleri kullanabilirsiniz (Ã¶rneÄŸin, Mike Kim'in bir Ã§Ã¶zÃ¼mÃ¼nde t-SNE boyutlarÄ±nÄ± kullanmasÄ± gibi: [https://www.kaggle.com/c/otto-group-product-classification](https://www.kaggle.com/c/otto-group-product-classification)
challenge/discussion/14295). Buradaki fikir, bu tÃ¼r katkÄ±larÄ±n tÃ¼mÃ¼nÃ¼n yÄ±ÄŸÄ±lmanÄ±n ikinci seviyesinde seÃ§ilmesidir. Bu, o noktada daha fazla deney yapmanÄ±za gerek olmadÄ±ÄŸÄ± ve sadece daha iyi performans gÃ¶steren modellerin daha dar bir kÃ¼mesine odaklanmanÄ±z gerektiÄŸi anlamÄ±na gelir. YÄ±ÄŸÄ±lama uygulayarak, tÃ¼m deneylerinizi yeniden kullanabilir ve yÄ±ÄŸÄ±lamanÄ±n size ne kadarÄ±nÄ± modelleme hattÄ±nÄ±za dahil etmeniz gerektiÄŸine karar vermesini saÄŸlayabilirsiniz.
* BazÄ± yÄ±ÄŸÄ±lama uygulamalarÄ±, tÃ¼m Ã¶zellikleri veya bunlardan bir seÃ§kisini daha ileri aÅŸamalara taÅŸÄ±r; bu, sinir aÄŸlarÄ±ndaki atlama katmanlarÄ±na benzer bir durumdur. YÄ±ÄŸÄ±lmada daha sonraki aÅŸamalarda Ã¶zellikleri dahil etmenin sonuÃ§larÄ± iyileÅŸtirebileceÄŸini fark ettik, ancak dikkatli olun: bu, daha fazla gÃ¼rÃ¼ltÃ¼ ve aÅŸÄ±rÄ± uyum riski de getirir.
* Ä°deal olarak, OOF tahminleriniz, yÃ¼ksek sayÄ±da katlama iÃ§eren Ã§apraz doÄŸrulama ÅŸemalarÄ±ndan yapÄ±lmalÄ±dÄ±r, yani 10 ile 20 arasÄ±nda, ancak daha dÃ¼ÅŸÃ¼k sayÄ±larla, Ã¶rneÄŸin 5 katlama ile Ã§alÄ±ÅŸan Ã§Ã¶zÃ¼mler de gÃ¶rdÃ¼k.
* Her bir katlama iÃ§in, veriyi (tekrarlarla yeniden Ã¶rnekleme) aynÄ± model iÃ§in birden fazla kez torbalama yapmak ve ardÄ±ndan modelin tÃ¼m sonuÃ§larÄ±nÄ± (OOF tahminleri ve test tahminleri) ortalamak, aÅŸÄ±rÄ± uyumdan kaÃ§Ä±nmaya yardÄ±mcÄ± olur ve sonunda daha iyi sonuÃ§lar Ã¼retir.

* YÄ±ÄŸÄ±lmada erken durdurma konusunda dikkatli olun. Erken durdurmayÄ± doÄŸrudan doÄŸrulama katlamasÄ±nda kullanmak, belirli bir dÃ¼zeyde aÅŸÄ±rÄ± uyuma neden olabilir ve bu, yÄ±ÄŸÄ±lama prosedÃ¼rÃ¼ tarafÄ±ndan sonunda hafifletilebilir veya hafifletilmeyebilir. GÃ¼venli tarafta durmanÄ±zÄ± Ã¶neririz ve her zaman erken durdurmayÄ± eÄŸitim katlamalarÄ±nÄ±zdan bir doÄŸrulama Ã¶rneÄŸi Ã¼zerine uygulayÄ±n, doÄŸrulama katlamasÄ±na deÄŸil.

OlasÄ±lÄ±klar sonsuzdur. Bu yÄ±ÄŸÄ±lama tekniÄŸinin temel konseptini kavradÄ±ÄŸÄ±nÄ±zda, yapmanÄ±z gereken tek ÅŸey yaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±zÄ± soruna uygulamaktÄ±r. Bu anahtar konsepti, bu bÃ¶lÃ¼mÃ¼n son kÄ±smÄ±nda, bir Kaggle yarÄ±ÅŸmasÄ± iÃ§in yÄ±ÄŸÄ±lama Ã§Ã¶zÃ¼mÃ¼ne bakarken tartÄ±ÅŸacaÄŸÄ±z.

### Creating complex stacking and blending solutions *(KarmaÅŸÄ±k karÄ±ÅŸtÄ±rma ve yÄ±ÄŸÄ±nlama Ã§Ã¶zÃ¼mleri oluÅŸturma)*

Bu bÃ¶lÃ¼mÃ¼n bu noktasÄ±nda, tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z teknikleri ne kadar uygulamanÄ±z gerektiÄŸini merak ediyor olabilirsiniz. Teorik olarak, sunmuÅŸ olduÄŸumuz tÃ¼m ansambl tekniklerini, sadece tabular deÄŸil, herhangi bir Kaggle yarÄ±ÅŸmasÄ±nda kullanabilirsiniz, ancak dikkate almanÄ±z gereken birkaÃ§ sÄ±nÄ±rlayÄ±cÄ± faktÃ¶r vardÄ±r:

* Bazen veri setleri Ã§ok bÃ¼yÃ¼ktÃ¼r ve tek bir model eÄŸitmek uzun zaman alÄ±r.
* GÃ¶rÃ¼ntÃ¼ tanÄ±ma yarÄ±ÅŸmalarÄ±nda, derin Ã¶ÄŸrenme yÃ¶ntemlerini kullanmakla sÄ±nÄ±rlÄ±sÄ±nÄ±z.
* Derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ±nda modelleri yÄ±ÄŸlamayÄ± baÅŸarsanÄ±z bile, farklÄ± modelleri yÄ±ÄŸmak iÃ§in sÄ±nÄ±rlÄ± bir seÃ§eneÄŸiniz vardÄ±r. Derin Ã¶ÄŸrenme Ã§Ã¶zÃ¼mleriyle sÄ±nÄ±rlÄ± olduÄŸunuzdan, aÄŸlarÄ±n yalnÄ±zca kÃ¼Ã§Ã¼k tasarÄ±m yÃ¶nlerini ve bazÄ± hiperparametreleri (ya da bazen sadece baÅŸlatma tohumunu) deÄŸiÅŸtirerek performansÄ± bozmazsÄ±nÄ±z. SonuÃ§ta, aynÄ± tÃ¼rdeki modeller ve mimarilerdeki daha fazla benzerlik ve az fark ile tahminler, olmasÄ± gerektiÄŸinden Ã§ok benzer ve daha yÃ¼ksek korelasyona sahip olur, bu da ansambling'in etkinliÄŸini sÄ±nÄ±rlar.

Bu koÅŸullar altÄ±nda, karmaÅŸÄ±k yÄ±ÄŸÄ±lama yÃ¶ntemleri genellikle uygulanabilir deÄŸildir. Buna karÅŸÄ±n, bÃ¼yÃ¼k veri setlerinde ortalama alma ve blending (karÄ±ÅŸtÄ±rma) genellikle mÃ¼mkÃ¼ndÃ¼r.

Ã–nceki yarÄ±ÅŸmalarda ve tÃ¼m son tabular yarÄ±ÅŸmalarda, karmaÅŸÄ±k yÄ±ÄŸÄ±lama ve blending Ã§Ã¶zÃ¼mleri hÃ¢kimdi. Bir yarÄ±ÅŸma iÃ§in yÄ±ÄŸÄ±lama konusunda ne kadar karmaÅŸÄ±klÄ±k ve yaratÄ±cÄ±lÄ±k gerektiÄŸini anlamanÄ±z iÃ§in, bu bÃ¶lÃ¼mÃ¼n son kÄ±smÄ±nda, Gilberto Titericz ([https://www.kaggle.com/titericz](https://www.kaggle.com/titericz)) ve Stanislav Semenov'un ([https://www.kaggle.com/stasg7](https://www.kaggle.com/stasg7)) Otto Group Product Classification Challenge'a ([https://www.kaggle.com/c/otto-group-product-classification-challenge](https://www.kaggle.com/c/otto-group-product-classification-challenge)) sunduklarÄ± Ã§Ã¶zÃ¼mÃ¼ tartÄ±ÅŸacaÄŸÄ±z. YarÄ±ÅŸma 2015 yÄ±lÄ±nda yapÄ±ldÄ± ve gÃ¶revi, 93 Ã¶zellik temel alÄ±narak 200.000'den fazla Ã¼rÃ¼nÃ¼ 9 farklÄ± sÄ±nÄ±fa ayÄ±rmaktÄ±.

Gilberto ve Stanislav'Ä±n Ã¶nerdiÄŸi Ã§Ã¶zÃ¼m Ã¼Ã§ seviyeden oluÅŸuyordu:

1. **Ä°lk seviyede**, 33 model vardÄ±. TÃ¼m modeller oldukÃ§a farklÄ± algoritmalar kullanÄ±yordu, yalnÄ±zca k-en yakÄ±n komÅŸular kÃ¼mesinde sadece k parametresi deÄŸiÅŸiyordu. AyrÄ±ca, denetimsiz t-SNE kullandÄ±lar. Ek olarak, boyutsallÄ±k manipÃ¼lasyonu (en yakÄ±n komÅŸulardan ve kÃ¼melerden alÄ±nan mesafelerle yapÄ±lan hesaplamalar) ve satÄ±r istatistikleri (her satÄ±rdaki sÄ±fÄ±r olmayan eleman sayÄ±sÄ±) temel alÄ±narak sekiz Ã¶zellik mÃ¼hendisliÄŸi yaptÄ±lar. TÃ¼m OOF tahminleri ve Ã¶zellikler ikinci seviyeye aktarÄ±ldÄ±.

2. **Ä°kinci seviyede**, hiperparametre optimizasyonuna baÅŸladÄ±lar, model seÃ§imi ve bagging (aynÄ± modelin birden fazla versiyonunu yeniden Ã¶rnekleme yaparak oluÅŸturdular ve her modelin sonuÃ§larÄ±nÄ± ortaladÄ±lar) gerÃ§ekleÅŸtirdiler. SonuÃ§ olarak, sadece Ã¼Ã§ model kaldÄ± ve bu modelleri tÃ¼m veriler Ã¼zerinde yeniden eÄŸittiler: bir XGBoost, bir AdaBoost ve bir yapay sinir aÄŸÄ±.

3. **ÃœÃ§Ã¼ncÃ¼ seviyede**, sonuÃ§larÄ±n aÄŸÄ±rlÄ±klÄ± ortalamasÄ±nÄ± hazÄ±rladÄ±lar; Ã¶nce XGBoost ve yapay sinir aÄŸÄ±nÄ±n geometrik ortalamasÄ±nÄ± aldÄ±lar ve ardÄ±ndan bunu AdaBoost ile ortaladÄ±lar.

Bu Ã§Ã¶zÃ¼mden Ã§ok ÅŸey Ã¶ÄŸrenebiliriz, ve bu sadece bu yarÄ±ÅŸma ile sÄ±nÄ±rlÄ± deÄŸildir. KarmaÅŸÄ±klÄ±ÄŸÄ±n yanÄ± sÄ±ra (ikinci seviyede her model iÃ§in yÃ¼zlerce kez yeniden Ã¶rnekleme yaptÄ±lar), bu bÃ¶lÃ¼mde tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z yÃ¶ntemlerin birÃ§ok farklÄ± varyasyonunun bulunduÄŸu dikkat Ã§ekicidir. YaratÄ±cÄ±lÄ±k ve deneme-yanÄ±lma yÃ¶ntemi bu Ã§Ã¶zÃ¼mde aÃ§Ä±kÃ§a baskÄ±n bir rol oynamaktadÄ±r. Bu, birÃ§ok Kaggle yarÄ±ÅŸmasÄ± iÃ§in oldukÃ§a tipiktir; Ã§Ã¼nkÃ¼ problemler bir yarÄ±ÅŸmadan diÄŸerine nadiren aynÄ±dÄ±r ve her Ã§Ã¶zÃ¼m benzersizdir ve kolayca tekrarlanabilir deÄŸildir.

BirÃ§ok AutoML motoru, AutoGluon gibi, esasen bu tÃ¼r prosedÃ¼rlerden ilham alarak, yÄ±ÄŸÄ±lama ve blending yaparak size en iyi sonucu garantileyebilecek Ã¶nceden tanÄ±mlanmÄ±ÅŸ bir dizi otomatik adÄ±m sunmaya Ã§alÄ±ÅŸmaktadÄ±r.
AutoGluon'un yÄ±ÄŸÄ±lmÄ±ÅŸ modellerini oluÅŸturmak iÃ§in kullandÄ±ÄŸÄ± algoritmalarÄ±n bir listesi iÃ§in [https://arxiv.org/abs/2003.06505](https://arxiv.org/abs/2003.06505)'e bakabilirsiniz. Liste oldukÃ§a uzun ve kendi yÄ±ÄŸÄ±lama Ã§Ã¶zÃ¼mleriniz iÃ§in birÃ§ok fikir bulabilirsiniz.

Ancak, bu yÃ¶ntemlerin bazÄ± en iyi uygulamalarÄ±nÄ± hayata geÃ§irse de, sonuÃ§larÄ± her zaman, iyi bir Kaggle ekibinin elde edebileceÄŸi sonuÃ§lardan daha dÃ¼ÅŸÃ¼k kalmaktadÄ±r; Ã§Ã¼nkÃ¼ ansamblinizi nasÄ±l denediÄŸiniz ve oluÅŸturduÄŸunuzda yaratÄ±cÄ±lÄ±k baÅŸarÄ± iÃ§in anahtardÄ±r. AynÄ± ÅŸey bu bÃ¶lÃ¼m iÃ§in de geÃ§erlidir. Size ansambl iÃ§in en iyi uygulamalarÄ± gÃ¶sterdik; bunlarÄ± bir baÅŸlangÄ±Ã§ noktasÄ± olarak alÄ±n ve fikirleri karÄ±ÅŸtÄ±rarak ve yenilik yaparak, katÄ±ldÄ±ÄŸÄ±nÄ±z Kaggle yarÄ±ÅŸmasÄ± ya da Ã§Ã¶zmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z gerÃ§ek dÃ¼nya problemi Ã¼zerinde kendi Ã§Ã¶zÃ¼mlerinizi yaratÄ±n.

> **Xavier Conort**
> 
> [https://www.kaggle.com/xavierconort](https://www.kaggle.com/xavierconort)
> 
> 
> 
> Bu bÃ¶lÃ¼mÃ¼ sonlandÄ±rÄ±rken, 2012-2013 yÄ±llarÄ±nda #1 sÄ±rada yer alan ve Kaggle tarihinin baÅŸlarÄ±nda birÃ§ok Kaggle kullanÄ±cÄ±sÄ±na ilham kaynaÄŸÄ± olan *Competitions Grandmaster* Xavier Conort ile bir araya geldik. Åu anda kendi ÅŸirketi *Data Mapping and Engineering*'in kurucusu ve CEO'su olan Xavier, bize Kaggle ile ilgili deneyimlerini, kariyerini ve daha fazlasÄ±nÄ± anlattÄ±.
> 
> 
> 
> **En sevdiÄŸiniz yarÄ±ÅŸma tÃ¼rÃ¼ nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan Kaggle'deki uzmanlÄ±ÄŸÄ±nÄ±z nedir?**
> 
> Ã‡oklu tablolardan Ã¶zellik mÃ¼hendisliÄŸi yapmayÄ± gerektiren yarÄ±ÅŸmalara bayÄ±lÄ±yordum. Ã–zellikle benim iÃ§in yeni olan iÅŸ problemlerine yÃ¶nelik iyi Ã¶zellikler Ã§Ä±karmayÄ± Ã§ok seviyordum. Bu bana yeni problemleri Ã§Ã¶zme konusunda bÃ¼yÃ¼k bir gÃ¼ven kazandÄ±rdÄ±. Ä°yi Ã¶zellik mÃ¼hendisliÄŸi dÄ±ÅŸÄ±nda, yÄ±ÄŸÄ±lama (stacking) bana iyi sonuÃ§lar elde etme konusunda yardÄ±mcÄ± oldu. BirkaÃ§ modeli harmanlamak ya da metin veya yÃ¼ksek kategorik deÄŸiÅŸkenleri sayÄ±sal Ã¶zelliklere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullandÄ±m. En sevdiÄŸim algoritma GBM (Gradyan ArtÄ±rma Makinesi) idi, ama karÄ±ÅŸÄ±mlarÄ±mÄ± Ã§eÅŸitlendirmek iÃ§in birÃ§ok farklÄ± algoritma test ettim.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rsÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸinizde yaptÄ±ÄŸÄ±nÄ±zdan ne kadar farklÄ±dÄ±r?**
> 
> Birincil amacÄ±m her yarÄ±ÅŸmadan olabildiÄŸince fazla ÅŸey Ã¶ÄŸrenmekti. Bir yarÄ±ÅŸmaya girmeden Ã¶nce, hangi becerilerimi geliÅŸtireceÄŸimi deÄŸerlendirmeye Ã§alÄ±ÅŸÄ±yordum. Konfor alanÄ±mÄ±n dÄ±ÅŸÄ±na Ã§Ä±kmaktan korkmazdÄ±m. Liderlik tablosundaki geri bildirimler sayesinde hatalarÄ±mdan hÄ±zlÄ±ca Ã¶ÄŸrenebileceÄŸimi biliyordum. GÃ¼nlÃ¼k iÅŸlerde ise bu fÄ±rsatlar nadiren olur. Ãœzerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z Ã§Ã¶zÃ¼mÃ¼n gerÃ§ek kalitesini deÄŸerlendirmek zordur. Bu yÃ¼zden gÃ¼venli oynamayÄ± tercih ederiz ve genellikle geÃ§miÅŸteki tarifleri tekrar ederiz. Kaggle olmasaydÄ±, bu kadar Ã§ok ÅŸey Ã¶ÄŸrenebileceÄŸimi sanmÄ±yorum.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸma hakkÄ±nda bize bilgi verin ve bu gÃ¶revi ele alÄ±rken hangi iÃ§gÃ¶rÃ¼leri kullandÄ±nÄ±z?**
> 
> En sevdiÄŸim yarÄ±ÅŸma, GE Flight Questâ€™ti. GE tarafÄ±ndan dÃ¼zenlenen bu yarÄ±ÅŸmada katÄ±lÄ±mcÄ±lar, ABD iÃ§indeki uÃ§uÅŸlarÄ±n varÄ±ÅŸ saatlerini tahmin etmek zorundaydÄ±lar. YarÄ±ÅŸmanÄ±n Ã¶zel liderlik tablosunun tasarÄ±mÄ±nÄ± Ã¶zellikle beÄŸendim. Bu tasarÄ±m, gelecekteki olaylarÄ± tahmin etme kapasitemizi test ediyordu, Ã§Ã¼nkÃ¼ tahminlerimiz yarÄ±ÅŸma sonrasÄ±ndaki uÃ§uÅŸlar Ã¼zerinden deÄŸerlendiriliyordu.
> 
> Veri setinde yalnÄ±zca birkaÃ§ aylÄ±k geÃ§miÅŸ (3-4 ay, doÄŸru hatÄ±rlÄ±yorsam) olduÄŸundan, aÅŸÄ±rÄ± uyum (overfitting) riski olduÄŸunu biliyordum. Bu riski azaltmak iÃ§in, uÃ§uÅŸ gecikmeleriyle aÃ§Ä±k bir nedensel iliÅŸkiye sahip olan Ã¶zellikler oluÅŸturmaya karar verdim; Ã¶rneÄŸin hava durumu koÅŸullarÄ± ve trafik gibi Ã¶zellikler. AyrÄ±ca, havaalanlarÄ±nÄ±n adÄ±nÄ± ana Ã¶zellik listemden Ã§Ä±karmaya dikkat ettim. Ã‡Ã¼nkÃ¼ bazÄ± havaalanlarÄ±, birkaÃ§ ay boyunca kÃ¶tÃ¼ hava koÅŸullarÄ± yaÅŸamamÄ±ÅŸtÄ±. Bu yÃ¼zden, favori ML algoritmam olan GBMâ€™nin havaalanÄ± adÄ±nÄ± iyi hava koÅŸullarÄ± iÃ§in bir proxy olarak kullanÄ±p, Ã¶zel liderlik tablosunda o havaalanlarÄ± iÃ§in doÄŸru tahminler yapamayacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼m. BazÄ± havaalanlarÄ±nÄ±n daha iyi yÃ¶netildiÄŸini gÃ¶z Ã¶nÃ¼nde bulundurarak ve liderlik tablosundaki puanÄ±mÄ± biraz iyileÅŸtirmek iÃ§in, sonunda havaalanÄ± adÄ±nÄ± sadece ikinci katmanlÄ± modelimin bir Ã¶zelliÄŸi olarak kullandÄ±m. Bu yaklaÅŸÄ±m, bazÄ± bilgileri ilk adÄ±mda sansÃ¼rlediÄŸiniz iki aÅŸamalÄ± bir boosting (artÄ±rma) olarak dÃ¼ÅŸÃ¼nÃ¼lebilir. Bu yÃ¶ntemi, sigorta alanÄ±nda coÄŸrafi kalÄ±ntÄ± etkilerini yakalamak iÃ§in uygulayan aktÃ¼erlerden Ã¶ÄŸrendim.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu? YardÄ±mcÄ± olduysa, nasÄ±l?**
> 
> Kesinlikle, veri bilimi kariyerimde bana Ã§ok yardÄ±mcÄ± oldu. Veri bilimine geÃ§meden Ã¶nce sigorta sektÃ¶rÃ¼nde aktÃ¼er olarak Ã§alÄ±ÅŸÄ±yordum, makine Ã¶ÄŸrenmesi hakkÄ±nda hiÃ§bir ÅŸey bilmiyordum ve veri bilimcisi tanÄ±mÄ±yordum. Kaggleâ€™daki Ã§eÅŸitli yarÄ±ÅŸmalar sayesinde Ã¶ÄŸrenme eÄŸrim hÄ±zla arttÄ±. Ä°yi sonuÃ§larÄ±m sayesinde, iÅŸverenlere 39 yaÅŸÄ±nda bir aktÃ¼erin kendi baÅŸÄ±na yeni beceriler geliÅŸtirebileceÄŸini kanÄ±tladÄ±m. Ve Kaggleâ€™Ä±n topluluÄŸu sayesinde, dÃ¼nya Ã§apÄ±nda birÃ§ok tutkulu veri bilimcisiyle tanÄ±ÅŸtÄ±m. BaÅŸlangÄ±Ã§ta onlarla birlikte yarÄ±ÅŸmak gerÃ§ekten Ã§ok eÄŸlenceliydi. Sonunda, bazÄ±larÄ±yla Ã§alÄ±ÅŸma fÄ±rsatÄ±m oldu. DataRobotâ€™un kurucularÄ± Jeremy Achin ve Tom De Godoy, benim takÄ±m arkadaÅŸlarÄ±mdÄ±, sonra beni DataRobotâ€™a katÄ±lmaya davet ettiler. EÄŸer Kaggle olmasaydÄ±, muhtemelen hala sigorta sektÃ¶rÃ¼nde aktÃ¼er olarak Ã§alÄ±ÅŸÄ±yor olurdum.
> 
> 
> 
> **Kaggle yarÄ±ÅŸmalarÄ±nda yaptÄ±ÄŸÄ±nÄ±z bir ÅŸeyi portfÃ¶yÃ¼nÃ¼zÃ¼ oluÅŸturmak iÃ§in potansiyel iÅŸverenlere gÃ¶stermek amacÄ±yla kullandÄ±nÄ±z mÄ±?**
> 
> Ä°tiraf etmeliyim ki, bazÄ± yarÄ±ÅŸmalara, iÅŸverenimi ya da potansiyel mÃ¼ÅŸterilerimi etkileme amacÄ±yla girdim. Bu iyi sonuÃ§ verdi, ama Ã§ok daha az eÄŸlenceliydi ve Ã§ok daha fazla baskÄ± vardÄ±.
> 
> 
> 
> **Deneyiminize gÃ¶re, deneyimsiz Kagglers genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r? Åu an bildiÄŸiniz bir ÅŸeyi keÅŸke ilk baÅŸladÄ±ÄŸÄ±nÄ±zda bilseydiniz?**
> 
> Deneyimsiz Kagglersâ€™a, yarÄ±ÅŸma sÄ±rasÄ±nda paylaÅŸÄ±lan Ã§Ã¶zÃ¼mleri incelememelerini, kendi baÅŸlarÄ±na iyi Ã§Ã¶zÃ¼mler bulmaya Ã§alÄ±ÅŸmalarÄ± gerektiÄŸini tavsiye ederim. Kaggleâ€™Ä±n ilk yÄ±llarÄ±nda rakiplerin kod paylaÅŸmadÄ±ÄŸÄ± iÃ§in Ã§ok mutluyum. Bu, beni zorlu bir ÅŸekilde Ã¶ÄŸrenmeye zorladÄ±.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdi?**
> 
> Bir hata, kÃ¶tÃ¼ tasarlanmÄ±ÅŸ ve veri sÄ±zÄ±ntÄ±sÄ± (leak) iÃ§eren yarÄ±ÅŸmalara katÄ±lmak. Bu sadece zaman kaybÄ±dÄ±r. Bu tÃ¼r yarÄ±ÅŸmalardan Ã§ok ÅŸey Ã¶ÄŸrenemezsiniz.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in kullanmanÄ±zÄ± tavsiye edeceÄŸiniz belirli araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Gradyan ArtÄ±rma Makinesi (GBM) benim favori algoritmam. Ä°lk olarak Râ€™nin gbm kÃ¼tÃ¼phanesini kullandÄ±m, ardÄ±ndan Scikit-learn GBM, sonra XGBoost ve son olarak LightGBMâ€™i kullandÄ±m. Ã‡oÄŸu zaman, kazanan Ã§Ã¶zÃ¼mÃ¼mÃ¼n ana bileÅŸeni bu olmuÅŸtur. GBMâ€™nin ne Ã¶ÄŸrendiÄŸini daha iyi anlamak iÃ§in SHAP paketini tavsiye ederim.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken kiÅŸinin aklÄ±nda tutmasÄ± veya yapmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Ã–ÄŸrenmek iÃ§in yarÄ±ÅŸÄ±n. DiÄŸer tutkulu veri bilimcileriyle baÄŸlantÄ± kurmak iÃ§in yarÄ±ÅŸÄ±n. Sadece kazanmak iÃ§in yarÄ±ÅŸmayÄ±n.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, birden fazla Ã§Ã¶zÃ¼mÃ¼n nasÄ±l birleÅŸtirildiÄŸini (ensembling) ve kendi Ã§Ã¶zÃ¼mlerinizi oluÅŸturmak iÃ§in kullanabileceÄŸiniz bazÄ± temel kod Ã¶rneklerini tartÄ±ÅŸtÄ±k. Model birleÅŸimlerini (ensemble) gÃ¼Ã§lendiren fikirlerden, Ã¶rneÄŸin rastgele ormanlar (random forests) ve gradyan artÄ±rma (gradient boosting) gibi yÃ¶ntemlerden baÅŸladÄ±k. ArdÄ±ndan, test gÃ¶nderilerinin basit bir ÅŸekilde ortalamasÄ±ndan, birden fazla katmanlÄ± yÄ±ÄŸÄ±nlanmÄ±ÅŸ modeller Ã¼zerinde meta-modelleme yÃ¶ntemlerine kadar farklÄ± birleÅŸim yaklaÅŸÄ±mlarÄ±nÄ± keÅŸfettik.

BÃ¶lÃ¼mÃ¼n sonunda tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, ensemblling daha Ã§ok bazÄ± ortak uygulamalara dayanan bir sanat formudur. Kaggle yarÄ±ÅŸmasÄ±nÄ± kazanan baÅŸarÄ±lÄ± bir karmaÅŸÄ±k yÄ±ÄŸÄ±lama (stacking) dÃ¼zenini incelediÄŸimizde, kombinasyonlarÄ±n veri ve problemle nasÄ±l Ã¶zelleÅŸtirildiÄŸine hayran kaldÄ±k. Bir yÄ±ÄŸÄ±lama modelini alÄ±p baÅŸka bir probleme kopyalayarak en iyi Ã§Ã¶zÃ¼mÃ¼ bulmayÄ± umamazsÄ±nÄ±z. YalnÄ±zca yÃ¶nergeleri takip edebilir ve Ã§ok sayÄ±da deneme ve hesaplama Ã§abasÄ±yla kendiniz, farklÄ± modellerin ortalamasÄ±nÄ±/yÄ±ÄŸÄ±lmasÄ±nÄ±/karÄ±ÅŸtÄ±rÄ±lmasÄ±nÄ± iÃ§eren en iyi Ã§Ã¶zÃ¼mÃ¼ bulabilirsiniz.

Bir sonraki bÃ¶lÃ¼mde, derin Ã¶ÄŸrenme yarÄ±ÅŸmalarÄ±na, ilk olarak sÄ±nÄ±flandÄ±rma ve segmentasyon gÃ¶revleri iÃ§in bilgisayarla gÃ¶rme (computer vision) yarÄ±ÅŸmalarÄ±yla giriÅŸ yapacaÄŸÄ±z.

---

## Chapter 10: Modeling for Computer Vision *(BÃ¶lÃ¼m 10: BilgisayarlÄ± GÃ¶rÃ¼ (Computer Vision) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

Bilgisayarla gÃ¶rme (computer vision) gÃ¶revleri, makine Ã¶ÄŸrenmesinin pratik uygulamalarÄ±nda en popÃ¼ler problemlerden biridir; bu alan, birÃ§ok Kaggle kullanÄ±cÄ±sÄ± iÃ§in derin Ã¶ÄŸrenmeye giriÅŸ kapÄ±sÄ± olmuÅŸtur, bunlardan biri de benim (yani Konrad). Son birkaÃ§ yÄ±l iÃ§inde bu alanda muazzam bir ilerleme kaydedildi ve yeni SOTA (State of the Art) kÃ¼tÃ¼phaneleri sÃ¼rekli olarak yayÄ±mlanmaktadÄ±r. Bu bÃ¶lÃ¼mde, bilgisayarla gÃ¶rme alanÄ±ndaki en popÃ¼ler yarÄ±ÅŸma tÃ¼rlerine genel bir bakÄ±ÅŸ sunacaÄŸÄ±z:

* GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ± (Image classification)
* Nesne tespiti (Object detection)
* GÃ¶rÃ¼ntÃ¼ segmentasyonu (Image segmentation)

BaÅŸlangÄ±Ã§ olarak, farklÄ± problemlere uygulanabilen ve modellerimizin genelleme yeteneÄŸini artÄ±rmaya yardÄ±mcÄ± olan gÃ¶revden baÄŸÄ±msÄ±z teknikler grubundan olan gÃ¶rÃ¼ntÃ¼ artÄ±rma (image augmentation) konusuna kÄ±sa bir bÃ¶lÃ¼mle baÅŸlayacaÄŸÄ±z.

### Augmentation strategies *(Veri artÄ±rma stratejileri)*

Derin Ã¶ÄŸrenme teknikleri, gÃ¶rÃ¼ntÃ¼ tanÄ±ma, segmentasyon veya nesne tespiti gibi bilgisayarla gÃ¶rme gÃ¶revlerinde son derece baÅŸarÄ±lÄ± olmuÅŸtur. Ancak, bu tekniklerin temel algoritmalarÄ± genellikle son derece veri yoÄŸun olup, aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) Ã¶nlemek iÃ§in bÃ¼yÃ¼k miktarda veriye ihtiyaÃ§ duyar. Ancak, tÃ¼m ilgi alanlarÄ± bu gereksinimi karÅŸÄ±lamaz, iÅŸte burada veri artÄ±rma (data augmentation devreye girer). Veri artÄ±rma, gÃ¶rÃ¼ntÃ¼ iÅŸleme teknikleri grubudur ve bu teknikler, gÃ¶rÃ¼ntÃ¼lerin modifiye edilmiÅŸ versiyonlarÄ±nÄ± oluÅŸturarak, eÄŸitim veri setlerinin boyutunu ve kalitesini artÄ±rÄ±r, bu da derin Ã¶ÄŸrenme modellerinin daha iyi performans gÃ¶stermesini saÄŸlar. ArtÄ±rÄ±lmÄ±ÅŸ veri, genellikle daha kapsamlÄ± bir veri noktalarÄ± kÃ¼mesini temsil eder, bÃ¶ylece eÄŸitim ve doÄŸrulama setleri arasÄ±ndaki mesafeyi, ayrÄ±ca gelecekteki test setlerini minimize eder.

Bu bÃ¶lÃ¼mde, daha yaygÄ±n kullanÄ±lan bazÄ± artÄ±rma tekniklerini ve bunlarÄ±n yazÄ±lÄ±m implementasyonlarÄ± iÃ§in seÃ§enekleri gÃ¶zden geÃ§ireceÄŸiz. En sÄ±k kullanÄ±lan dÃ¶nÃ¼ÅŸÃ¼mler ÅŸunlardÄ±r:

* **YansÄ±tma (Flipping):** GÃ¶rÃ¼ntÃ¼nÃ¼n yatay veya dikey eksende ters Ã§evrilmesi
* **DÃ¶nme (Rotation):** GÃ¶rÃ¼ntÃ¼nÃ¼n belirli bir aÃ§Ä±yla dÃ¶ndÃ¼rÃ¼lmesi (saat yÃ¶nÃ¼nde veya ters yÃ¶nde)
* **KÄ±rpma (Cropping):** GÃ¶rÃ¼ntÃ¼nÃ¼n rastgele bir alt kÄ±smÄ±nÄ±n seÃ§ilmesi
* **ParlaklÄ±k (Brightness):** GÃ¶rÃ¼ntÃ¼nÃ¼n parlaklÄ±k seviyesinin deÄŸiÅŸtirilmesi
* **Ã–lÃ§ekleme (Scaling):** GÃ¶rÃ¼ntÃ¼nÃ¼n daha bÃ¼yÃ¼k (dÄ±ÅŸa doÄŸru) veya daha kÃ¼Ã§Ã¼k (iÃ§e doÄŸru) bir boyuta artÄ±rÄ±lmasÄ± veya kÃ¼Ã§Ã¼ltÃ¼lmesi

AÅŸaÄŸÄ±da, bu dÃ¶nÃ¼ÅŸÃ¼mlerin pratikte nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±, AmerikalÄ± oyuncu ve komedyen Betty Whiteâ€™Ä±n bir gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ kullanarak gÃ¶steriyoruz:

![](im/1064.png)

GÃ¶rÃ¼ntÃ¼yÃ¼ dikey veya yatay eksende Ã§evirebiliriz:

![](im/1065.png)

DÃ¶nmeler oldukÃ§a aÃ§Ä±ktÄ±r; arka plandaki gÃ¶rÃ¼ntÃ¼nÃ¼n otomatik olarak doldurulmasÄ±na dikkat edin:

![](im/1066.png)

AyrÄ±ca, gÃ¶rÃ¼ntÃ¼yÃ¼ ilgi alanÄ±na gÃ¶re kÄ±rpabiliriz:

![](im/1067.png)

YÃ¼ksek seviyede, artÄ±rma iÅŸlemleri iki ÅŸekilde uygulanabilir:

* **Offline (Ã‡evrimdÄ±ÅŸÄ±):** Bu yÃ¶ntemler genellikle daha kÃ¼Ã§Ã¼k veri setlerinde (daha az resim veya daha kÃ¼Ã§Ã¼k boyutlar, ancak "kÃ¼Ã§Ã¼k" tanÄ±mÄ±nÄ±z mevcut donanÄ±ma baÄŸlÄ±dÄ±r) uygulanÄ±r. Burada amaÃ§, orijinal resimlerin modifiye edilmiÅŸ versiyonlarÄ±nÄ± veri setiniz iÃ§in bir Ã¶n iÅŸleme adÄ±mÄ± olarak Ã¼retmek ve ardÄ±ndan bunlarÄ± "orijinal" resimlerle birlikte kullanmaktÄ±r.

* **Online (Ã‡evrimiÃ§i):** Bu yÃ¶ntemler daha bÃ¼yÃ¼k veri setleri iÃ§in kullanÄ±lÄ±r. ArtÄ±rÄ±lmÄ±ÅŸ resimler diske kaydedilmez; artÄ±rmalar mini-batch'ler halinde uygulanÄ±r ve modele iletilir.

Sonraki bÃ¶lÃ¼mlerde, resim veri setinizi artÄ±rmak iÃ§in en yaygÄ±n iki yÃ¶ntem hakkÄ±nda bir genel bakÄ±ÅŸ sunacaÄŸÄ±z: Keras'Ä±n yerleÅŸik iÅŸlevselliÄŸi ve albumentations paketini. AyrÄ±ca, skimage, OpenCV, imgaug, Augmentor, SOLT gibi baÅŸka seÃ§enekler de mevcuttur, ancak en popÃ¼ler olanlar Ã¼zerinde duracaÄŸÄ±z.

Bu bÃ¶lÃ¼mde tartÄ±ÅŸÄ±lan yÃ¶ntemler, GPU ile gÃ¼Ã§lendirilmiÅŸ gÃ¶rÃ¼ntÃ¼ analizine odaklanmaktadÄ±r. Tensor iÅŸleme birimlerinin (TPU'lar) kullanÄ±mÄ± yeni bir uygulama alanÄ± olmakla birlikte, hÃ¢lÃ¢ nispeten niÅŸ bir konu. TPU destekli analizle birlikte gÃ¶rÃ¼ntÃ¼ artÄ±rma ile ilgilenen okuyucular, Chris Deotte'in (@cdeotte) mÃ¼kemmel Ã§alÄ±ÅŸmalarÄ±nÄ± incelemeye davet edilir:

[https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords](https://www.kaggle.com/cdeotte/triple-stratified-kfold-with-tfrecords)

Chris, dÃ¶rt kez Kaggle Grandmaster'Ä± olup, oluÅŸturduÄŸu Not Defterleri ve katÄ±ldÄ±ÄŸÄ± tartÄ±ÅŸmalarla harika bir eÄŸitimci olarak tanÄ±nmaktadÄ±r. Deneyim seviyeniz ne olursa olsun, herhangi bir Kaggler iÃ§in mutlaka takip edilmesi gereken biri.

---

Veriyi, **Cassava Leaf Disease Classification** yarÄ±ÅŸmasÄ±ndan ([https://www.kaggle.com/c/cassava-leaf-disease-classification](https://www.kaggle.com/c/cassava-leaf-disease-classification)) alacaÄŸÄ±z. Her zamanki gibi, temel hazÄ±rlÄ±klara baÅŸlÄ±yoruz: ilk olarak gerekli paketleri yÃ¼kleyelim:

```python
import os
import glob
import numpy as np
import scipy as sp
import pandas as pd
import cv2
from skimage.io import imshow, imread, imsave
# imgaug
import imageio
import imgaug as ia
import imgaug.augmenters as iaa
# Albumentations
import albumentations as A
# Keras
# from keras.preprocessing.image import ImageDataGenerator, array_to_img, 
# img_to_array, load_img
# Visualization
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
%matplotlib inline
import seaborn as sns
from IPython.display import HTML, Image
# Warnings
import warnings
warnings.filterwarnings("ignore")
```

Sonraki adÄ±mda, daha sonra sunumlarÄ± kolaylaÅŸtÄ±racak bazÄ± yardÄ±mcÄ± iÅŸlevleri tanÄ±mlayacaÄŸÄ±z. Resimleri dizilere yÃ¼klemek iÃ§in bir yol oluÅŸturmalÄ±yÄ±z:

```python
def load_image(image_id):
    file_path = image_id 
    image = imread(Image_Data_Path + file_path)
    return image
```

Birden fazla resmi galeri tarzÄ±nda gÃ¶rÃ¼ntÃ¼lemek istiyoruz, bu yÃ¼zden bir dizi alacak ve istenilen sÃ¼tun sayÄ±sÄ±na gÃ¶re yeniden ÅŸekillendirilmiÅŸ bir Ä±zgara ÅŸeklinde Ã§Ä±ktÄ± verecek bir iÅŸlev oluÅŸturuyoruz:

```python
def gallery(array, ncols=3):
    nindex, height, width, intensity = array.shape
    nrows = nindex//ncols
    assert nindex == nrows*ncols
    result = (array.reshape(nrows, ncols, height, width, intensity)
              .swapaxes(1,2)
              .reshape(height*nrows, width*ncols, intensity))
    return result
```

Temel hazÄ±rlÄ±klarÄ± hallettik, ÅŸimdi artÄ±rma iÃ§in resimleri yÃ¼kleyebiliriz:

```python
data_dir = '../input/cassava-leaf-disease-classification/'
Image_Data_Path = data_dir + '/train_images/'
train_data = pd.read_csv(data_dir + '/train.csv')
# Ä°lk 10 resmi bellekte daha hÄ±zlÄ± eriÅŸim iÃ§in yÃ¼klÃ¼yoruz
train_images = train_data["image_id"][:10].apply(load_image)
```

Åimdi, referans resmimizi bilelim diye bir tane resmi yÃ¼kleyelim:

```python
curr_img = train_images[7]
plt.figure(figsize = (15,15))
plt.imshow(curr_img)
plt.axis('off')
```

Ä°ÅŸte bu:

![](im/1068.png)

AÅŸaÄŸÄ±daki bÃ¶lÃ¼mlerde, bu referans resminden hem Keras'Ä±n yerleÅŸik iÅŸlevselliÄŸini hem de albumentations kÃ¼tÃ¼phanesini kullanarak nasÄ±l artÄ±rÄ±lmÄ±ÅŸ resimler oluÅŸturulacaÄŸÄ±nÄ± gÃ¶stereceÄŸiz.

#### Keras built-in augmentations *(Kerasâ€™Ä±n yerleÅŸik artÄ±rmalarÄ±)*

In the following sections, we will demonstrate how to generate augmented images from this reference image using both built-in Keras functionality and the albumentations library.

##### ImageDataGenerator approach *(ImageDataGenerator yaklaÅŸÄ±mÄ±)*

AÅŸaÄŸÄ±daki bÃ¶lÃ¼mlerde, bu referans resminden hem Keras'Ä±n yerleÅŸik iÅŸlevselliÄŸini hem de albumentations kÃ¼tÃ¼phanesini kullanarak nasÄ±l artÄ±rÄ±lmÄ±ÅŸ resimler oluÅŸturulacaÄŸÄ±nÄ± gÃ¶stereceÄŸiz.

BaÅŸlangÄ±Ã§ olarak, aÅŸaÄŸÄ±daki ÅŸekilde bir **ImageDataGenerator** nesnesi oluÅŸturuyoruz:

```python
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
```

```python
datagen = ImageDataGenerator(
        rotation_range=40, 
        shear_range=0.2, 
        zoom_range=0.2, 
        horizontal_flip=True, 
        brightness_range=(0.5, 1.5)
) 
```

Sonra, mevcut resmi bir diziye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼p ÅŸekillendiriyoruz:

```python
curr_img_array = img_to_array(curr_img)
curr_img_array = curr_img_array.reshape((1,) + curr_img_array.shape)
```

Ä°stenilen artÄ±rma iÅŸlemlerini **ImageDataGenerator**'a argÃ¼man olarak tanÄ±mlÄ±yoruz. Resmi belgelere gÃ¶re, artÄ±rmalarÄ±n sÄ±rasÄ±yla uygulanmasÄ± gerektiÄŸi belirtilmemiÅŸ olsa da, pratikte artÄ±rmalarÄ±n tanÄ±mlandÄ±klarÄ± sÄ±rayla uygulandÄ±ÄŸÄ± gÃ¶zlemlenmiÅŸtir.

Sonra, **ImageDataGenerator** nesnesinin `.flow` metoduyla resimler Ã¼zerinde yineleme yapÄ±yoruz. Bu sÄ±nÄ±f, gÃ¶rsel veri setini belleÄŸe yÃ¼klemek ve artÄ±rÄ±lmÄ±ÅŸ veri kÃ¼mesi oluÅŸturmak iÃ§in Ã¼Ã§ farklÄ± fonksiyon saÄŸlar:

* flow
* flow_from_directory
* flow_from_dataframe

Hepsi aynÄ± amacÄ± gerÃ§ekleÅŸtirir, ancak dosya konumlarÄ±nÄ±n nasÄ±l belirtildiÄŸi konusunda farklÄ±lÄ±k gÃ¶sterir. Ã–rneÄŸimizde, resimler zaten bellekte olduÄŸundan, en basit yÃ¶ntemi kullanarak yineleme yapabiliriz:

```python
i = 0
for batch in datagen.flow(
    curr_img_array,
    batch_size=1,
    save_to_dir='.',
    save_prefix='Augmented_image',
    save_format='jpeg'):
    i += 1
    # Sabit kodlanmÄ±ÅŸ durdurma - bununla, jeneratÃ¶r sonsuz dÃ¶ngÃ¼ye girmez
    if i > 9: 
        break
```

YukarÄ±daki Ã¶rnekte yalnÄ±zca sÄ±nÄ±rlÄ± bir seÃ§enek alt kÃ¼mesi kullanÄ±yoruz; tam liste iÃ§in okuyuculara resmi belgelere baÅŸvurmalarÄ± Ã¶nerilir: [https://keras.io/api/preprocessing/image/](https://keras.io/api/preprocessing/image/).

ArtÄ±rÄ±lmÄ±ÅŸ resimleri daha Ã¶nce tanÄ±mladÄ±ÄŸÄ±mÄ±z yardÄ±mcÄ± fonksiyonlarla inceleyebiliriz:

```python
aug_images = []
for img_path in glob.glob("*.jpeg"):
    aug_images.append(mpimg.imread(img_path))
plt.figure(figsize=(20,20))
plt.axis('off')
plt.imshow(gallery(np.array(aug_images[0:9]), ncols=3))
plt.title('Augmentation examples')
```

Ä°ÅŸte sonuÃ§:

![](im/1069.png)

Veri artÄ±rma, Ã§ok faydalÄ± bir araÃ§tÄ±r, ancak bunlarÄ± verimli bir ÅŸekilde kullanmak, bir deÄŸerlendirme yapmayÄ± gerektirir. Ã–ncelikle, etkilerini gÃ¶rmek iÃ§in artÄ±rmalarÄ± gÃ¶rselleÅŸtirmek iyi bir fikir olacaktÄ±r. Bir yandan, modelimizin genelleme yeteneÄŸini artÄ±rmak iÃ§in veriye bazÄ± deÄŸiÅŸiklikler eklemek istiyoruz; diÄŸer yandan, resimleri Ã§ok radikal bir ÅŸekilde deÄŸiÅŸtirirsek, giriÅŸ verisi daha az bilgilendirici hale gelir ve model performansÄ± muhtemelen olumsuz etkilenir. AyrÄ±ca, hangi artÄ±rma yÃ¶ntemlerinin kullanÄ±lacaÄŸÄ± da problem spesifik olabilir; bunu farklÄ± yarÄ±ÅŸmalarÄ± karÅŸÄ±laÅŸtÄ±rarak gÃ¶rebiliriz.

EÄŸer yukarÄ±daki 10.6 numaralÄ± gÃ¶rsele bakarsanÄ±z (Cassava Leaf Disease Classification yarÄ±ÅŸmasÄ±ndan referans gÃ¶rsel), hastalÄ±ÄŸÄ± tanÄ±mlamamÄ±z gereken yapraklar farklÄ± boyutlarda, farklÄ± aÃ§Ä±larda ve farklÄ± ÅŸekillerde olabilir; bu durum, bitkilerin ÅŸekilleri ve gÃ¶rÃ¼ntÃ¼lerin nasÄ±l Ã§ekildiÄŸine baÄŸlÄ± olarak deÄŸiÅŸir. Bu, dikey veya yatay Ã§evirmeler, kÄ±rpmalar ve dÃ¶ndÃ¼rmeler gibi dÃ¶nÃ¼ÅŸÃ¼mlerin bu baÄŸlamda mantÄ±klÄ± olduÄŸu anlamÄ±na gelir.

Buna karÅŸÄ±lÄ±k, **Severstal: Steel Defect Detection** yarÄ±ÅŸmasÄ±ndan ([https://www.kaggle.com/c/severstal-steel-defect-detection](https://www.kaggle.com/c/severstal-steel-defect-detection)) bir Ã¶rnek gÃ¶rsele bakabiliriz. Bu yarÄ±ÅŸmada katÄ±lÄ±mcÄ±larÄ±n, bir Ã§elik levha Ã¼zerindeki kusurlarÄ± yerelleÅŸtirip sÄ±nÄ±flandÄ±rmalarÄ± gerekiyordu. TÃ¼m resimler aynÄ± boyutta ve aynÄ± oryantasyona sahipti; bu da, dÃ¶ndÃ¼rmeler veya kÄ±rpmalarÄ±n gerÃ§ekÃ§i olmayan gÃ¶rÃ¼ntÃ¼ler oluÅŸturacaÄŸÄ± ve bunun da gÃ¼rÃ¼ltÃ¼ ekleyip algoritmanÄ±n genelleme yeteneklerine olumsuz bir etkisi olacaÄŸÄ± anlamÄ±na gelir.

![](im/1070.png)

##### Preprocessing layers *(Ã–n iÅŸleme katmanlarÄ±)*

Veri artÄ±rma iÃ§in bir alternatif yaklaÅŸÄ±m, yerel Keras yÃ¶ntemiyle bir Ã¶n iÅŸleme adÄ±mÄ± olarak, **preprocessing layers API** kullanmaktÄ±r. Bu iÅŸlevsellik son derece esnektir: Bu pipeline'lar, ya Keras modelleriyle kombinasyon halinde ya da ImageDataGenerator'a benzer ÅŸekilde baÄŸÄ±msÄ±z olarak kullanÄ±labilir.

AÅŸaÄŸÄ±da, bir Ã¶n iÅŸleme katmanÄ±nÄ±n nasÄ±l kurulacaÄŸÄ±nÄ± kÄ±saca gÃ¶steriyoruz. Ä°lk olarak, gerekli import'lar:

```python
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras import layers
```

Standard Keras yÃ¶ntemiyle Ã¶nceden eÄŸitilmiÅŸ bir model yÃ¼klÃ¼yoruz:

```python
pretrained_base = tf.keras.models.load_model(
    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',
)
pretrained_base.trainable = False
```

Ã–n iÅŸleme katmanlarÄ±, diÄŸer katmanlar gibi **Sequential** yapÄ±cÄ±sÄ±nÄ±n iÃ§inde kullanÄ±labilir; tek gereklilik, model tanÄ±mÄ±nÄ±n baÅŸÄ±nda, diÄŸer katmanlardan Ã¶nce belirtilmeleridir:

```python
model = tf.keras.Sequential([
    # Preprocessing katmanlarÄ±
    preprocessing.RandomFlip('horizontal'),  # Sol-saÄŸa Ã§evirme
    preprocessing.RandomContrast(0.5),  # KontrastÄ± %50'ye kadar deÄŸiÅŸtirme
    # Temel model
    pretrained_base,
    # Model baÅŸÄ± tanÄ±mÄ±
    layers.Flatten(),
    layers.Dense(6, activation='relu'),
    layers.Dense(1, activation='sigmoid'),
])
```

#### albumentations *(Albumentations kÃ¼tÃ¼phanesi)*

Albumentations paketi, baÅŸka kÃ¼tÃ¼phanelerin etrafÄ±nda bir tÃ¼r sarmalayÄ±cÄ± olarak inÅŸa edilmiÅŸ hÄ±zlÄ± bir gÃ¶rÃ¼ntÃ¼ artÄ±rma kÃ¼tÃ¼phanesidir.

Bu paket, birkaÃ§ Kaggle yarÄ±ÅŸmasÄ±nda yoÄŸun bir ÅŸekilde kodlama yaparak geliÅŸtirilmiÅŸtir ([https://medium.com/@iglovikov/the-birth-of-albumentationsfe38c1411cb3](https://medium.com/@iglovikov/the-birth-of-albumentationsfe38c1411cb3) adresinden daha fazla bilgiye ulaÅŸabilirsiniz) ve temel geliÅŸtiricileri ve katkÄ±cÄ±larÄ± arasÄ±nda, birÃ§ok Ã¶nemli Kaggle kullanÄ±cÄ±sÄ±nÄ± iÃ§erir. Bunlar arasÄ±nda Eugene Khvedchenya ([https://www.kaggle.com/bloodaxe](https://www.kaggle.com/bloodaxe)), Vladimir Iglovikov ([https://www.kaggle.com/iglovikov](https://www.kaggle.com/iglovikov)), Alex Parinov ([https://www.kaggle.com/creafz](https://www.kaggle.com/creafz)) ve ZFTurbo ([https://www.kaggle.com/zfturbo](https://www.kaggle.com/zfturbo)) yer almaktadÄ±r.

Tam dÃ¶kÃ¼mantasyona ÅŸu baÄŸlantÄ±dan ulaÅŸÄ±labilir: [https://albumentations.readthedocs.io/en/latest/](https://albumentations.readthedocs.io/en/latest/).

AÅŸaÄŸÄ±da Ã¶nemli Ã¶zellikler listelenmiÅŸtir:

* FarklÄ± veri tÃ¼rleri iÃ§in birleÅŸtirilmiÅŸ API
* TÃ¼m yaygÄ±n bilgisayarla gÃ¶rme gÃ¶revlerini destekler
* Hem TensorFlow hem de PyTorch ile entegrasyon

Albumentations iÅŸlevselliÄŸini kullanarak bir resmi dÃ¶nÃ¼ÅŸtÃ¼rmek oldukÃ§a basittir. Gerekli dÃ¶nÃ¼ÅŸÃ¼mleri baÅŸlatarak baÅŸlarÄ±z:

```python
import albumentations as A
horizontal_flip = A.HorizontalFlip(p=1)
rotate = A.ShiftScaleRotate(p=1)
gaus_noise = A.GaussNoise()
bright_contrast = A.RandomBrightnessContrast(p=1)
gamma = A.RandomGamma(p=1)
blur = A.Blur()
```

SonrasÄ±nda, bu dÃ¶nÃ¼ÅŸÃ¼mleri referans resmimize uygularÄ±z:

```python
img_flip = horizontal_flip(image=curr_img)
img_gaus = gaus_noise(image=curr_img)
img_rotate = rotate(image=curr_img)
img_bc = bright_contrast(image=curr_img)
img_gamma = gamma(image=curr_img)
img_blur = blur(image=curr_img)
```

Paketin geliÅŸtirilmesi, birkaÃ§ Kaggle yarÄ±ÅŸmasÄ±nda yoÄŸun bir ÅŸekilde kodlama yapÄ±larak gerÃ§ekleÅŸtirilmiÅŸtir ([https://medium.com/@iglovikov/the-birth-of-albumentationsfe38c1411cb3](https://medium.com/@iglovikov/the-birth-of-albumentationsfe38c1411cb3) adresinden daha fazla bilgi alabilirsiniz). Temel geliÅŸtiriciler ve katkÄ±cÄ±lar arasÄ±nda, Ã§ok sayÄ±da Ã¶nemli Kaggle kullanÄ±cÄ±sÄ± bulunmaktadÄ±r: Eugene Khvedchenya ([https://www.kaggle.com/bloodaxe](https://www.kaggle.com/bloodaxe)), Vladimir Iglovikov ([https://www.kaggle.com/iglovikov](https://www.kaggle.com/iglovikov)), Alex Parinov ([https://www.kaggle.com/creafz](https://www.kaggle.com/creafz)) ve ZFTurbo ([https://www.kaggle.com/zfturbo](https://www.kaggle.com/zfturbo)).

Tam dÃ¶kÃ¼mantasyona [buradan ulaÅŸÄ±labilir](https://albumentations.readthedocs.io/en/latest/).

ArtÄ±rÄ±lmÄ±ÅŸ resimleri 'image' anahtarÄ±yla eriÅŸebiliriz ve sonuÃ§larÄ± gÃ¶rselleÅŸtirebiliriz:

```python
img_list = [img_flip['image'], img_gaus['image'], img_rotate['image'],
            img_bc['image'], img_gamma['image'], img_blur['image']]
plt.figure(figsize=(20, 20))
plt.axis('off')
plt.imshow(gallery(np.array(img_list), ncols=3))
plt.title('Augmentation examples')
```

Ä°ÅŸte sonuÃ§larÄ±mÄ±z:

![](im/1071.png)

GÃ¶rÃ¼ntÃ¼ artÄ±rmayÄ±, bilgisayarla gÃ¶rme problemlerine yaklaÅŸÄ±rken Ã¶nemli bir Ã¶n iÅŸleme adÄ±mÄ± olarak tartÄ±ÅŸtÄ±ktan sonra, bu bilgiyi aÅŸaÄŸÄ±daki bÃ¶lÃ¼mlerde uygulamaya koymaya hazÄ±rÄ±z. Ä°lk olarak Ã§ok yaygÄ±n bir gÃ¶revle baÅŸlayacaÄŸÄ±z: gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma.

> Chris Deotte
> 
> [https://www.kaggle.com/cdeotte](https://www.kaggle.com/cdeotte)
> 
> 
> 
> Ä°lerlemeye geÃ§meden Ã¶nce, bu kitapta (bu bÃ¶lÃ¼mde de dahil) sÄ±kÃ§a bahsettiÄŸimiz ve iyi bir sebepten dolayÄ± bu kadar Ã§ok bahsettiÄŸimiz Chris Deotte ile kÄ±sa bir rÃ¶portaja gÃ¶z atalÄ±m. Kendisi, dÃ¶rt kez Kaggle Grandmaster unvanÄ±na sahip ve NVIDIA'da kÄ±demli veri bilimcisi ve araÅŸtÄ±rmacÄ±dÄ±r, ayrÄ±ca 2019 yÄ±lÄ±nda Kaggle'a katÄ±lmÄ±ÅŸtÄ±r.
> 
> 
> 
> * Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Kaggle'daki teknikleriniz ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ±nÄ±z aÃ§Ä±sÄ±ndan uzmanlÄ±ÄŸÄ±nÄ±z nedir?
> 
> 
> 
> Fascinating veriye sahip ve yaratÄ±cÄ±, yenilikÃ§i modeller kurmayÄ± gerektiren yarÄ±ÅŸmalarla ilgileniyorum. UzmanlÄ±ÄŸÄ±m, eÄŸitilmiÅŸ modelleri analiz ederek gÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nlerini belirlemektir. SonrasÄ±nda, bu modelleri iyileÅŸtirmeyi ve/veya model performansÄ±nÄ± artÄ±rmak iÃ§in son iÅŸlem teknikleri geliÅŸtirmeyi severim.
> 
> 
> 
> * Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±yorsunuz? Bu yaklaÅŸÄ±mÄ±nÄ±z gÃ¼nlÃ¼k iÅŸlerinizden nasÄ±l farklÄ±?
> 
> 
> 
> Her yarÄ±ÅŸmaya EDA (keÅŸifsel veri analizi) yaparak, yerel bir doÄŸrulama oluÅŸturup, basit modeller inÅŸa ederek baÅŸlarÄ±m ve ardÄ±ndan Kaggle'a gÃ¶nderim yaparak liderlik sÄ±ralamalarÄ±nÄ± elde ederim. Bu, doÄŸru ve rekabetÃ§i bir model kurmak iÃ§in ne yapÄ±lmasÄ± gerektiÄŸine dair bir sezgi geliÅŸtirir.
> 
> 
> 
> * KatÄ±ldÄ±ÄŸÄ±nÄ±z ve Ã¶zellikle zorlayÄ±cÄ± bulduÄŸunuz bir yarÄ±ÅŸmadan bahseder misiniz? Bu gÃ¶revi nasÄ±l ele aldÄ±ÄŸÄ±nÄ±zÄ± anlatÄ±n.
> 
> 
> 
> Kaggleâ€™Ä±n Shopee â€“ Price Match Guarantee yarÄ±ÅŸmasÄ±, hem gÃ¶rsel modelleri hem de doÄŸal dil iÅŸleme modelleri gerektiren zorlu bir yarÄ±ÅŸmaydÄ±. Ã–nemli bir keÅŸif, her iki model tÃ¼rÃ¼nden gÃ¶mme (embedding) Ã§Ä±karÄ±mÄ± yapÄ±p, gÃ¶rsel ve dil bilgilerini birlikte kullanarak Ã¼rÃ¼n eÅŸleÅŸmelerini bulma yÃ¶ntemiydi.
> 
> 
> 
> * Kaggle kariyerinizde size yardÄ±mcÄ± oldu mu? EÄŸer olduysa, nasÄ±l?
> 
> 
> 
> Evet. Kaggle, becerilerimi geliÅŸtirmem ve Ã¶zgeÃ§miÅŸimin iÅŸ piyasasÄ±nda daha Ã§ekici olmasÄ±nÄ± saÄŸlamam sayesinde beni NVIDIA'da kÄ±demli veri bilimcisi yapmama yardÄ±mcÄ± oldu.
> 
> 
> 
> BirÃ§ok iÅŸveren, Kaggle'daki Ã§alÄ±ÅŸmalarÄ± gÃ¶zden geÃ§irerek, belirli projeleri Ã§Ã¶zmek iÃ§in belirli becerilere sahip Ã§alÄ±ÅŸanlar arar. Bu sayede bana birÃ§ok iÅŸ teklifi iletildi.
> 
> 
> 
> * Deneyimsiz Kaggle kullanÄ±cÄ±larÄ±nÄ±n sÄ±klÄ±kla gÃ¶zden kaÃ§Ä±rdÄ±ÄŸÄ± ÅŸey nedir? Ä°lk baÅŸladÄ±ÄŸÄ±nÄ±zda bilmeniz gereken ÅŸeyleri ÅŸimdi ne olarak gÃ¶rÃ¼yorsunuz?
> 
> 
> 
> Bana gÃ¶re, deneyimsiz Kagglers genellikle yerel doÄŸrulamanÄ±n Ã¶nemini gÃ¶z ardÄ± ederler. Liderlik sÄ±ralamasÄ±nda isminizi gÃ¶rmek heyecan vericidir. Ve bazen, liderlik sÄ±ralamasÄ±nÄ± iyileÅŸtirmeye odaklanmak, Ã§apraz doÄŸrulama (cross-validation) skorlarÄ±mÄ±zdan daha fazla dikkatimizi Ã§ekebilir.
> 
> 
> 
> * GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdir?
> 
> 
> 
> Ã‡ok zaman, liderlik sÄ±ralamasÄ±ndaki puanÄ± Ã§apraz doÄŸrulama puanÄ±mdan daha Ã¶nemli gÃ¶rÃ¼p yanlÄ±ÅŸ son gÃ¶nderimi seÃ§me hatasÄ±na dÃ¼ÅŸtÃ¼m.
> 
> 
> 
> * Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in Ã¶nerdiÄŸiniz belirli araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?
> 
> 
> 
> Kesinlikle. Ã–zellik mÃ¼hendisliÄŸi ve hÄ±zlÄ± deneme yapma, tablolarla Ã§alÄ±ÅŸÄ±rken Ã§ok Ã¶nemlidir. Deney yapma ve doÄŸrulama sÃ¼recini hÄ±zlandÄ±rmak iÃ§in NVIDIA RAPIDS cuDF ve cuML'yi GPU Ã¼zerinde kullanmak Ã§ok Ã¶nemlidir.
> 
> 
> 
> * Bir yarÄ±ÅŸmaya girerken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?
> 
> 
> 
> En Ã¶nemli ÅŸey eÄŸlenmek ve Ã¶ÄŸrenmektir. SonuÃ§ sÄ±ralamanÄ±z hakkÄ±nda endiÅŸelenmeyin. EÄŸer Ã¶ÄŸrenmeye ve eÄŸlenmeye odaklanÄ±rsanÄ±z, zamanla sonuÃ§ sÄ±ralamanÄ±z daha iyi hale gelir.
> 
> 
> 
> * BaÅŸka yarÄ±ÅŸma platformlarÄ±nÄ± kullanÄ±yor musunuz? Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r?
> 
> 
> 
> Evet, Kaggle dÄ±ÅŸÄ±nda da yarÄ±ÅŸmalara katÄ±ldÄ±m. Booking.com veya Twitter.com gibi bazÄ± bireysel ÅŸirketler zaman zaman yarÄ±ÅŸmalar dÃ¼zenler. Bu yarÄ±ÅŸmalar eÄŸlencelidir ve yÃ¼ksek kaliteli, gerÃ§ek dÃ¼nya verileri iÃ§erir.

### Classification *(SÄ±nÄ±flandÄ±rma)*

Bu bÃ¶lÃ¼mde, gÃ¶rsel sÄ±nÄ±flandÄ±rma problemlerini ele almak iÃ§in ÅŸablon olarak kullanÄ±labilecek uÃ§tan uca bir pipeline'Ä± gÃ¶stereceÄŸiz. Veri hazÄ±rlÄ±ÄŸÄ±ndan model kurulumu ve tahmin yapmaya, sonuÃ§larÄ±n gÃ¶rselleÅŸtirilmesine kadar gerekli adÄ±mlarÄ± adÄ±m adÄ±m inceleyeceÄŸiz. Hem bilgilendirici (hem de havalÄ±) olan bu son adÄ±m, kodunuzu derinlemesine incelemeniz gerektiÄŸinde performansÄ± daha iyi anlamanÄ±zÄ± saÄŸlamada Ã§ok faydalÄ± olabilir.

Cassava Leaf Disease Classification yarÄ±ÅŸmasÄ±ndan ([https://www.kaggle.com/c/cassava-leaf-disease-classification](https://www.kaggle.com/c/cassava-leaf-disease-classification)) aldÄ±ÄŸÄ±mÄ±z verileri kullanmaya devam edeceÄŸiz.

Her zamanki gibi, gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyerek baÅŸlÄ±yoruz:

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import datetime
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import tensorflow as tf
```

```python
from tensorflow.keras import models, layers
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.optimizers import Adam
import os, cv2, json
from PIL import Image
```

Genellikle birkaÃ§ yardÄ±mcÄ± iÅŸlev tanÄ±mlamak iyi bir fikirdir; bu, hem kodu okumayÄ± hem de hata ayÄ±klamayÄ± kolaylaÅŸtÄ±rÄ±r. EÄŸer genel bir gÃ¶rsel sÄ±nÄ±flandÄ±rma problemiyle karÅŸÄ± karÅŸÄ±yaysanÄ±z, EfficientNet ailesinden bir model iyi bir baÅŸlangÄ±Ã§ noktasÄ± olabilir. EfficientNet, 2019 yÄ±lÄ±nda Google Research Brain Team tarafÄ±ndan tanÄ±tÄ±lan bir modeldir ([https://arxiv.org/abs/1905.11946](https://arxiv.org/abs/1905.11946)). Temel fikir, aÄŸÄ±n derinliÄŸini, geniÅŸliÄŸini ve Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼nÃ¼ dengeleyerek tÃ¼m boyutlar Ã¼zerinde daha verimli Ã¶lÃ§eklendirme ve sonrasÄ±nda daha iyi performans elde etmektir.

Ã‡Ã¶zÃ¼mÃ¼mÃ¼z iÃ§in, ailenin en basit Ã¼yesi olan EfficientNet B0'Ä± kullanacaÄŸÄ±z. Bu, 11 milyon Ã¶ÄŸrenilebilir parametreye sahip, mobil boyutunda bir aÄŸdÄ±r.

**SÄ±nÄ±flandÄ±rma**

EfficientNet aÄŸlarÄ±nÄ±n detaylÄ± bir aÃ§Ä±klamasÄ± iÃ§in, baÅŸlangÄ±Ã§ noktasÄ± olarak [bu makaleyi](https://ai.googleblog.com/2019/05/efficientnet-improving-accuracy-and.html) keÅŸfetmenizi Ã¶neririz.

Modelimizi B0'Ä± temel alarak oluÅŸturuyoruz, ardÄ±ndan Ã§eviri deÄŸiÅŸmezliÄŸini geliÅŸtirmek iÃ§in bir havuzlama katmanÄ± ekliyoruz ve Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma problemlerimize uygun bir aktivasyon fonksiyonu iÃ§eren bir yoÄŸun katman ekliyoruz:

```python
class CFG:    
    # yapÄ±landÄ±rma
    WORK_DIR = '../input/cassava-leaf-disease-classification'
    BATCH_SIZE = 8
    EPOCHS = 5
    TARGET_SIZE = 512

def create_model():
    conv_base = EfficientNetB0(include_top=False, weights=None,
                               input_shape=(CFG.TARGET_SIZE, CFG.TARGET_SIZE, 3))
    model = conv_base.output
    model = layers.GlobalAveragePooling2D()(model)
    model = layers.Dense(5, activation="softmax")(model)
    model = models.Model(conv_base.input, model)
    model.compile(optimizer=Adam(lr=0.001),
                  loss="sparse_categorical_crossentropy",
                  metrics=["acc"])
    return model
```

EfficientNetB0 fonksiyonuna geÃ§irdiÄŸimiz parametreler hakkÄ±nda kÄ±sa aÃ§Ä±klamalar:

* **include_top** parametresi, son yoÄŸun katmanlarÄ± dahil edip etmeyeceÄŸinize karar verir. Pre-trained modeli bir Ã¶zellik Ã§Ä±karÄ±cÄ± olarak kullanmak istediÄŸimiz iÃ§in, bu katmanlarÄ± geÃ§mek ve baÅŸlÄ±ÄŸÄ± kendimiz tanÄ±mlamak yaygÄ±n bir stratejidir.
* **weights** parametresi, modelin sÄ±fÄ±rdan eÄŸitilmesini istiyorsak `None` olarak ayarlanabilir ya da bÃ¼yÃ¼k gÃ¶rsel koleksiyonlar Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarÄ± kullanmak istiyorsak `imagenet` ya da `noisy-student` olarak ayarlanabilir.

AÅŸaÄŸÄ±daki yardÄ±mcÄ± fonksiyon, aktivasyon katmanÄ±nÄ± gÃ¶rselleÅŸtirmemize olanak tanÄ±r, bÃ¶ylece aÄŸÄ± performansÄ±nÄ± gÃ¶rsel aÃ§Ä±dan inceleyebiliriz. Bu, opaklÄ±ÄŸÄ±yla bilinen bir alanda sezgi geliÅŸtirmekte sÄ±klÄ±kla faydalÄ±dÄ±r:

```python
def activation_layer_vis(img, activation_layer=0, layers=10):
    layer_outputs = [layer.output for layer in model.layers[:layers]]
    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)
    activations = activation_model.predict(img)
    
    rows = int(activations[activation_layer].shape[3] / 3)
    cols = int(activations[activation_layer].shape[3] / rows)
    fig, axes = plt.subplots(rows, cols, figsize=(15, 15 * cols))
    axes = axes.flatten()
    
    for i, ax in zip(range(activations[activation_layer].shape[3]), axes):
        ax.matshow(activations[activation_layer][0, :, :, i], cmap='viridis')
        ax.axis('off')
    plt.tight_layout()
    plt.show()
```

AktivasyonlarÄ±, belirli bir model iÃ§in tahminler oluÅŸturarak, baÅŸka bir deyiÅŸle mimarinin son katmanÄ±na kadar olan kÄ±smÄ± kullanarak elde ederiz; bu, kodun activations deÄŸiÅŸkenine kadar olan kÄ±smÄ±dÄ±r. Fonksiyonun geri kalan kÄ±smÄ± ise, uygun konvolÃ¼syon katmanÄ±ndaki filtrelerin ÅŸekline karÅŸÄ±lÄ±k gelen doÄŸru aktivasyonlarÄ± uygun ÅŸekilde gÃ¶sterir.

Sonraki adÄ±mda, etiketleri iÅŸleriz ve doÄŸrulama ÅŸemasÄ± oluÅŸtururuz. Verilerde (Ã¶rneÄŸin, zaman boyutu veya sÄ±nÄ±flar arasÄ±nda Ã¶rtÃ¼ÅŸme gibi) Ã¶zel bir yapÄ± olmadÄ±ÄŸÄ± iÃ§in basit bir rastgele bÃ¶lme yapabiliriz:

```python
train_labels = pd.read_csv(os.path.join(CFG.WORK_DIR, "train.csv"))
STEPS_PER_EPOCH = len(train_labels) * 0.8 / CFG.BATCH_SIZE
VALIDATION_STEPS = len(train_labels) * 0.2 / CFG.BATCH_SIZE
```

Daha ayrÄ±ntÄ±lÄ± doÄŸrulama ÅŸemalarÄ± hakkÄ±nda bilgi almak iÃ§in, **BÃ¶lÃ¼m 6, Ä°yi DoÄŸrulama TasarÄ±mÄ±**na bakabilirsiniz.

Åimdi, TF tabanlÄ± algoritmamÄ±zÄ±n resim verilerini dÃ¶ngÃ¼ye sokabilmesi iÃ§in gerekli olan veri jeneratÃ¶rlerini ayarlayabiliriz.

Ä°lk olarak, iki adet `ImageDataGenerator` nesnesi oluÅŸturuyoruz; burada resim artÄ±rmalarÄ±nÄ± dahil ediyoruz. Bu gÃ¶sterim amacÄ±yla, Keras'Ä±n yerleÅŸik artÄ±rmalarÄ±nÄ± kullanacaÄŸÄ±z. ArdÄ±ndan, `flow_from_dataframe()` metodunu kullanarak jeneratÃ¶rÃ¼ oluÅŸturuyoruz, bu yÃ¶ntem gerÃ§ek zamanlÄ± veri artÄ±rmasÄ± ile tensÃ¶r resim verilerinin gruplarÄ±nÄ± oluÅŸturmak iÃ§in kullanÄ±lÄ±r:

```python
train_labels.label = train_labels.label.astype('str')
train_datagen = ImageDataGenerator(
    validation_split=0.2, preprocessing_function=None,
    rotation_range=45, zoom_range=0.2,
    horizontal_flip=True, vertical_flip=True,
    fill_mode='nearest', shear_range=0.1,
    height_shift_range=0.1, width_shift_range=0.1)

train_generator = train_datagen.flow_from_dataframe(
    train_labels,
    directory=os.path.join(CFG.WORK_DIR, "train_images"),
    subset="training",
    x_col="image_id", y_col="label", 
    target_size=(CFG.TARGET_SIZE, CFG.TARGET_SIZE),
    batch_size=CFG.BATCH_SIZE,
    class_mode="sparse")

validation_datagen = ImageDataGenerator(validation_split=0.2)
validation_generator = validation_datagen.flow_from_dataframe(
    train_labels,
    directory=os.path.join(CFG.WORK_DIR, "train_images"),
    subset="validation",
    x_col="image_id", y_col="label", 
    target_size=(CFG.TARGET_SIZE, CFG.TARGET_SIZE),
    batch_size=CFG.BATCH_SIZE, class_mode="sparse")
```

Belirtilen veri yapÄ±larÄ±yla modelimizi oluÅŸturabiliriz:

```python
model = create_model()
model.summary()
```

Model oluÅŸturulduktan sonra, kÄ±sa bir Ã¶zet gÃ¶z atabiliriz. Bu genellikle kontrol amaÃ§lÄ± kullanÄ±lÄ±r, Ã§Ã¼nkÃ¼ Ã§ok katmanlÄ± bir modelin katman kompozisyonunu hatÄ±rlamak kolay deÄŸildir. Pratikte, Ã¶zet bilgisi, Ã§Ä±ktÄ± filtrelerinin boyutlarÄ±nÄ±n doÄŸru olup olmadÄ±ÄŸÄ±nÄ± veya parametre sayÄ±larÄ±nÄ±n (eÄŸitilebilir ve eÄŸitilemeyen) beklentilere uygun olup olmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in kullanÄ±lÄ±r. KompaktlÄ±k adÄ±na, Ã§Ä±ktÄ±nÄ±n ilk birkaÃ§ satÄ±rÄ±nÄ± gÃ¶steriyoruz, ancak B0 iÃ§in mimari diyagramÄ±nÄ± incelemek, tam Ã§Ä±ktÄ±nÄ±n ne kadar uzun olacaÄŸÄ±na dair bir fikir verebilir.

Model: "functional_1"

```
__________________________________________________________________________
Layer (type)                Output Shape        Param # Connected to
==========================================================================
input_1 (InputLayer)        [(None, 512, 512, 3)] 0
__________________________________________________________________________
rescaling (Rescaling)       (None, 512, 512, 3)  0       input_1[0][0]
__________________________________________________________________________
normalization (Normalization) (None, 512, 512, 3)  7       rescaling[0][0]
__________________________________________________________________________
stem_conv_pad (ZeroPadding2D) (None, 513, 513, 3)  0       normalization[0][0]
...
```

YukarÄ±daki adÄ±mlar tamamlandÄ±ktan sonra, modeli eÄŸitmeye geÃ§ebiliriz. Bu adÄ±mda, ayrÄ±ca Ã§ok kullanÄ±ÅŸlÄ± bir ÅŸekilde geri Ã§aÄŸÄ±rmalar (callbacks) tanÄ±mlayabiliriz. Ä°lk geri Ã§aÄŸÄ±rma, ModelCheckpoint olacaktÄ±r:

```python
model_save = ModelCheckpoint('./EffNetB0_512_8_best_weights.h5', 
                             save_best_only=True, 
                             save_weights_only=True,
                             monitor='val_loss', 
                             mode='min', verbose=1)
```

Checkpoint, birkaÃ§ parametre iÃ§eriyor ve aÃ§Ä±klanmasÄ± gereken bazÄ± detaylar var:

* **save_best_only=True** ile en iyi model aÄŸÄ±rlÄ±klarÄ±nÄ± koruyabiliriz.
* **save_weights_only=True** ile modelin sadece aÄŸÄ±rlÄ±klarÄ±nÄ± kaydediyoruz, bÃ¶ylece modelin tamamÄ±nÄ± deÄŸil, sadece aÄŸÄ±rlÄ±klarÄ± saklamÄ±ÅŸ oluruz.
* Modelin en iyi hali, doÄŸrulama kaybÄ±nÄ± (val_loss) minimuma indirerek belirlenir.

Bir diÄŸer yaygÄ±n aÅŸÄ±rÄ± uyum Ã¶nleme yÃ¶ntemi erken durdurma (early stopping) olacaktÄ±r. Modelin performansÄ±nÄ± doÄŸrulama verisi Ã¼zerinde izleriz ve metrik geliÅŸmediÄŸinde, bu durumda algoritmayÄ± durdururuz. Burada 5 epoch sonra durdurma yapÄ±lacaktÄ±r:

```python
early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001,
                           patience=5, mode='min',
                           verbose=1, restore_best_weights=True)
```

Son olarak, **ReduceLROnPlateau** geri Ã§aÄŸÄ±rmasÄ±, doÄŸrulama kaybÄ± Ã¼zerinde geliÅŸme gÃ¶rÃ¼lmediÄŸinde, Ã¶ÄŸrenme oranÄ±nÄ± belirli bir faktÃ¶rle (bu durumda 0.3) dÃ¼ÅŸÃ¼rÃ¼r. Bu, genellikle yakÄ±nsama konusunda yardÄ±mcÄ± olabilir:

```python
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, 
                              patience=2, min_delta=0.001, 
                              mode='min
```


', verbose=1)

````

Åimdi modelimizi eÄŸitmeye hazÄ±rÄ±z:

```python
history = model.fit(
    train_generator,
    steps_per_epoch=STEPS_PER_EPOCH,
    epochs=CFG.EPOCHS,
    validation_data=validation_generator,
    validation_steps=VALIDATION_STEPS,
    callbacks=[model_save, early_stop, reduce_lr]
)
````

EÄŸitim sÄ±rasÄ±nda Ã§aÄŸrÄ±lan model.fit() fonksiyonu sonrasÄ± alÄ±nan bir Ã¶rnek Ã§Ä±ktÄ± ÅŸu ÅŸekilde olabilir:

```
Epoch 00001: val_loss improved from inf to 0.57514, saving model to ./EffNetB0_512_8_best_weights.h5
```

Bir model eÄŸitildikten sonra, baÅŸlangÄ±Ã§ta yazdÄ±ÄŸÄ±mÄ±z yardÄ±mcÄ± fonksiyonu kullanarak bir Ã¶rnek resimdeki aktivasyonlarÄ± inceleyebiliriz. Bu, modelin doÄŸru ÅŸekilde Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± anlamak iÃ§in faydalÄ± olabilir:

```python
activation_layer_vis(img_tensor, 0)
```

Bu iÅŸlem sonrasÄ± gÃ¶rÃ¼ntÃ¼lenen sonuÃ§, modelimizin sÄ±nÄ±flandÄ±rma katmanÄ±na geÃ§meden Ã¶nce hangi tÃ¼r Ã¶zellikler Ã§Ä±kardÄ±ÄŸÄ±nÄ± gÃ¶rselleÅŸtirmemize yardÄ±mcÄ± olacaktÄ±r.

![](im/1072.png)

Modelin tahminlerini **model.predict()** ile ÅŸu ÅŸekilde Ã¼retebiliriz:

```python
ss = pd.read_csv(os.path.join(CFG.WORK_DIR, "sample_submission.csv"))
preds = []
for image_id in ss.image_id:
    image = Image.open(os.path.join(CFG.WORK_DIR, "test_images", image_id))
    image = image.resize((CFG.TARGET_SIZE, CFG.TARGET_SIZE))
    image = np.expand_dims(image, axis=0)
    preds.append(np.argmax(model.predict(image)))
ss['label'] = preds
```

Tahminleri, resimlerin listesi Ã¼zerinden iterasyon yaparak oluÅŸturuyoruz. Her bir resim iÃ§in, resmi gerekli boyutlara yeniden ÅŸekillendiriyor ve modelin tahmin ettiÄŸi sÄ±nÄ±f olasÄ±lÄ±klarÄ± arasÄ±ndan en gÃ¼Ã§lÃ¼ sinyale sahip kanalÄ± (en yÃ¼ksek olasÄ±lÄ±kla olan sÄ±nÄ±fÄ±) seÃ§iyoruz. Bunun iÃ§in **argmax** fonksiyonunu kullanÄ±yoruz. SonuÃ§ olarak elde edilen tahminler, yarÄ±ÅŸmada kullanÄ±lan metrikle uyumlu olacak ÅŸekilde sÄ±nÄ±f numaralarÄ±dÄ±r.

Åimdi, gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma iÃ§in minimal bir uÃ§tan uca pipeline'Ä± (iÅŸlem hattÄ±) gÃ¶stermiÅŸ olduk. Elbette, birÃ§ok iyileÅŸtirme yapÄ±labilir â€“ Ã¶rneÄŸin daha fazla veri artÄ±rma, daha bÃ¼yÃ¼k bir mimari, geri Ã§aÄŸÄ±rmalarÄ±n Ã¶zelleÅŸtirilmesi gibi â€“ ancak temel ÅŸablon, gelecekte baÅŸlamak iÃ§in iyi bir temel saÄŸlayacaktÄ±r.

Åimdi, bilgisayarla gÃ¶rme alanÄ±ndaki bir diÄŸer popÃ¼ler probleme, **nesne tespiti** konusuna geÃ§iyoruz.

### Object detection *(Nesne tespiti)*

Nesne tespiti, bir bilgisayarla gÃ¶rme/gÃ¶rÃ¼ntÃ¼ iÅŸleme gÃ¶revidir ve burada bir resimde veya videoda belirli bir sÄ±nÄ±fa ait semantik nesnelerin Ã¶rneklerini tanÄ±mlamamÄ±z gerekir. Ã–nceki bÃ¶lÃ¼mde tartÄ±ÅŸÄ±lan sÄ±nÄ±flandÄ±rma problemlerinde, her bir resme bir sÄ±nÄ±f atamamÄ±z yeterliyken, nesne tespiti gÃ¶revlerinde, ilgilenilen nesnenin etrafÄ±na bir sÄ±nÄ±rlayÄ±cÄ± kutu Ã§izerek nesneyi resim iÃ§inde konumlandÄ±rmak isteriz.

Bu bÃ¶lÃ¼mde, **Global Wheat Detection** yarÄ±ÅŸmasÄ±ndan ([https://www.kaggle.com/c/global-wheat-detection](https://www.kaggle.com/c/global-wheat-detection)) elde edilen verileri kullanacaÄŸÄ±z. Bu yarÄ±ÅŸmada, katÄ±lÄ±mcÄ±lar buÄŸday baÅŸaklarÄ±nÄ± tespit etmek zorundaydÄ±lar. BuÄŸday baÅŸaklarÄ±, iÃ§inde tahÄ±l bulunan bitkilerin tepe kÄ±smÄ±ndaki spike'lerdir. Bu bitki gÃ¶rÃ¼ntÃ¼lerinde bu baÅŸaklarÄ±n tespiti, buÄŸday baÅŸaklarÄ±nÄ±n boyutlarÄ±nÄ± ve yoÄŸunluÄŸunu tahmin etmek iÃ§in kullanÄ±lÄ±r. Bu bÃ¶lÃ¼mde, nesne tespitinde yaygÄ±n olarak kullanÄ±lan ve 2021 sonlarÄ±na kadar en son teknoloji olarak kabul edilen **Yolov5** modelini kullanarak bu problemi nasÄ±l Ã§Ã¶zebileceÄŸimizi gÃ¶stereceÄŸiz. Yolov5, yarÄ±ÅŸmada son derece rekabetÃ§i sonuÃ§lar elde etmiÅŸti ve organizatÃ¶rler tarafÄ±ndan lisanslama sorunlarÄ± nedeniyle sonradan yasaklanmÄ±ÅŸ olsa da, bu gÃ¶sterim iÃ§in oldukÃ§a uygun bir modeldir.

![](im/1073.png)

BaÅŸlamadan Ã¶nce bahsedilmesi gereken Ã¶nemli bir nokta, sÄ±nÄ±rlayÄ±cÄ± kutu notasyonlarÄ±nÄ±n farklÄ± formatlarÄ±dÄ±r; dikdÃ¶rtgenin koordinatlarÄ±nÄ± tanÄ±mlamanÄ±n farklÄ± (ancak matematiksel olarak eÅŸdeÄŸer) yollarÄ± vardÄ±r.

En yaygÄ±n tÃ¼rler **coco**, **voc-pascal** ve **yolo**'dur. AralarÄ±ndaki farklar aÅŸaÄŸÄ±daki ÅŸekilde net bir ÅŸekilde gÃ¶rÃ¼lmektedir:

![](im/1074.png)

TanÄ±mlamamÄ±z gereken bir diÄŸer bÃ¶lÃ¼m ise Ä±zgara yapÄ±sÄ±dÄ±r: Yolo, bir resmi Ã¼zerine bir Ä±zgara yerleÅŸtirerek ve herhangi bir hÃ¼crede ilgi Ã§eken bir nesnenin (bizim durumumuzda bu, buÄŸday baÅŸaÄŸÄ±) varlÄ±ÄŸÄ±nÄ± kontrol ederek nesneleri tespit eder. SÄ±nÄ±rlayÄ±cÄ± kutular, resmin ilgili hÃ¼crelerinde yer deÄŸiÅŸtirecek ÅŸekilde yeniden ÅŸekillendirilir ve (x, y, w, h) parametreleri birim aralÄ±ÄŸa Ã¶lÃ§eklendirilir:

![](im/1075.png)

BaÅŸlangÄ±Ã§ta eÄŸitim verilerimizin aÃ§Ä±klamalarÄ±nÄ± (annotations) yÃ¼klÃ¼yoruz:

```python
df = pd.read_csv('../input/global-wheat-detection/train.csv')
df.head(3)
```

Bir kaÃ§Ä±nÄ± inceleyelim:

Åekil 10.13: EÄŸitim verileri ile aÃ§Ä±klamalar

SÄ±nÄ±rlayÄ±cÄ± kutularÄ±n (bounding boxes) gerÃ§ek koordinatlarÄ±nÄ± `bbox` sÃ¼tunundan Ã§Ä±karÄ±yoruz:

```python
bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))
bboxs
```

Diziyi gÃ¶zden geÃ§irelim:

```python
array([[834., 222.,  56.,  36.],
       [226., 548., 130.,  58.],
       [377., 504.,  74., 160.],
       ...,
       [134., 228., 141.,  71.],
       [430.,  13., 184.,  79.],
       [875., 740.,  94.,  61.]])
```

Bir sonraki adÄ±m, koordinatlarÄ± Yolo formatÄ±nda ayÄ±rÄ±p ayrÄ± sÃ¼tunlara yazmaktÄ±r:

```python
for i, column in enumerate(['x', 'y', 'w', 'h']):
    df[column] = bboxs[:, i]
df.drop(columns=['bbox'], inplace=True)
df['x_center'] = df['x'] + df['w']/2
df['y_center'] = df['y'] + df['h']/2
df['classes'] = 0
df = df[['image_id', 'x', 'y', 'w', 'h', 'x_center', 'y_center', 'classes']]
df.head(3)
```

Ultralytics'in uygulamasÄ±, veri setinin yapÄ±sÄ± konusunda bazÄ± gereksinimlere sahiptir, Ã¶zellikle aÃ§Ä±klamalarÄ±n nerede depolandÄ±ÄŸÄ± ve eÄŸitim/doÄŸrulama verilerinin hangi klasÃ¶rlerde bulunduÄŸu konusunda. AÅŸaÄŸÄ±daki kodda klasÃ¶rlerin oluÅŸturulmasÄ± oldukÃ§a basittir, ancak daha meraklÄ± bir okuyucu, resmi dokÃ¼mantasyona ([https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)) gÃ¶z atmayÄ± tercih edebilir:

```python
# kaynak Ã¼zerinde stratify iÅŸlemi
source = 'train'
# GÃ¶sterim amacÄ±yla tek bir katman seÃ§iyoruz
fold = 0
val_index = set(df[df['fold'] == fold]['image_id'])

# Her gÃ¶rÃ¼ntÃ¼ iÃ§in sÄ±nÄ±rlayÄ±cÄ± kutulara gÃ¶z atÄ±yoruz
for name, mini in tqdm(df.groupby('image_id')):
    # DosyalarÄ±n kaydedileceÄŸi yer
    if name in val_index:
        path2save = 'valid/'
    else:
        path2save = 'train/'

    # Etiketlerin depolandÄ±ÄŸÄ± yol
    if not os.path.exists('convertor/fold{}/labels/'.format(fold) + path2save):
        os.makedirs('convertor/fold{}/labels/'.format(fold) + path2save)

    with open('convertor/fold{}/labels/'.format(fold) + path2save + name + ".txt", 'w+') as f:
        # Yolo formatÄ±na uygun koordinatlarÄ± normalize ediyoruz
        row = mini[['classes', 'x_center', 'y_center', 'w', 'h']].astype(float).values
        row = row / 1024
        row = row.astype(str)
        for j in range(len(row)):
            text = ' '.join(row[j])
            f.write(text)
            f.write("\n")
    
    if not os.path.exists('convertor/fold{}/images/{}'.format(fold, path2save)):
        os.makedirs('convertor/fold{}/images/{}'.format(fold, path2save))

    # GÃ¶rsellerde Ã¶n iÅŸleme yapÄ±lmadÄ±ÄŸÄ± iÃ§in, bunlarÄ± bir batch olarak kopyalÄ±yoruz
    shutil.copy("../input/global-wheat-detection/{}/{}.jpg".format(source, name),
                'convertor/fold{}/images/{}/{}.jpg'.format(fold, path2save, name))
```

Åimdi Yolo paketini kuruyoruz. EÄŸer bunu bir Kaggle Notebook'u veya Colab'da Ã§alÄ±ÅŸtÄ±rÄ±yorsanÄ±z, GPU'nun etkin olduÄŸundan emin olun; Yolo kurulumu aslÄ±nda GPU olmadan da Ã§alÄ±ÅŸacaktÄ±r, ancak CPU ve GPU arasÄ±ndaki performans farklarÄ± nedeniyle zaman aÅŸÄ±mÄ± ve bellek sorunlarÄ±yla karÅŸÄ±laÅŸabilirsiniz.

```bash
!git clone https://github.com/ultralytics/yolov5  && cd yolov5 &&
pip install -r requirements.txt
```

Ã‡Ä±ktÄ±yÄ± atlÄ±yoruz Ã§Ã¼nkÃ¼ oldukÃ§a uzun. Son olarak gerekli olan hazÄ±rlÄ±k, YAML yapÄ±landÄ±rma dosyasÄ±nÄ± oluÅŸturmaktÄ±r; burada eÄŸitim ve doÄŸrulama verilerinin konumlarÄ±nÄ± ve sÄ±nÄ±f sayÄ±sÄ±nÄ± belirtiyoruz. Biz sadece buÄŸday baÅŸaklarÄ±nÄ± tespit etmeye Ã§alÄ±ÅŸÄ±yoruz ve farklÄ± tÃ¼rler arasÄ±nda ayrÄ±m yapmÄ±yoruz, dolayÄ±sÄ±yla bir sÄ±nÄ±fÄ±mÄ±z var (ismi yalnÄ±zca gÃ¶sterim amacÄ±yla saÄŸlanmÄ±ÅŸ olup, burada rastgele bir string olabilir):

```yaml
yaml_text = """train: /kaggle/working/convertor/fold0/images/train/
val: /kaggle/working/convertor/fold0/images/valid/
nc: 1
names: ['wheat']"""
with open("wheat.yaml", 'w') as f:
    f.write(yaml_text)
```

Bu ÅŸekilde, modelimizi eÄŸitmeye baÅŸlayabiliriz:

```bash
!python ./yolov5/train.py --img 512 --batch 2 --epochs 3 --workers 2 --data wheat.yaml --cfg "./yolov5/models/yolov5s.yaml" --name yolov5x_fold0 --cache
```

Komut satÄ±rÄ±ndan bir ÅŸeyler baÅŸlatmaya alÄ±ÅŸÄ±k deÄŸilseniz, yukarÄ±daki yazÄ±m gerÃ§ekten biraz gizemli olabilir, bu yÃ¼zden bileÅŸenlerini biraz daha detaylÄ± ÅŸekilde tartÄ±ÅŸalÄ±m:

* `train.py`: YoloV5 modelini eÄŸitmek iÃ§in kullanÄ±lan ana betik, Ã¶nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarla baÅŸlar.
* `--img 512`: Orijinal gÃ¶rÃ¼ntÃ¼lerin (gÃ¶rÃ¼ntÃ¼leri herhangi bir ÅŸekilde Ã¶n iÅŸlemden geÃ§irmedik, gÃ¶rebilirsiniz) 512x512'ye yeniden boyutlandÄ±rÄ±lmasÄ±nÄ± istediÄŸimizi belirtir.
* `--batch`: EÄŸitim sÃ¼recinde kullanÄ±lan batch boyutunu belirtir.
* `--epochs 3`: Modeli Ã¼Ã§ epoch boyunca eÄŸitmek istediÄŸimizi belirtir.
* `--workers 2`: Veri yÃ¼kleyicisi iÃ§in Ã§alÄ±ÅŸan sayÄ±sÄ±nÄ± belirtir.
* `--data wheat.yaml`: YukarÄ±da tanÄ±mladÄ±ÄŸÄ±mÄ±z veri yapÄ±landÄ±rma YAML dosyasÄ±na iÅŸaret eder.
* `--cfg "./yolov5/models/yolov5s.yaml"`: Modelin mimarisini ve baÅŸlangÄ±Ã§ iÃ§in kullanÄ±lacak aÄŸÄ±rlÄ±klarÄ± belirtir.
* `--name`: SonuÃ§ta elde edilen modelin nereye kaydedileceÄŸini belirtir.

Bu eÄŸitim komutunun Ã§Ä±ktÄ±sÄ±nÄ±n bir kÄ±smÄ±nÄ± aÅŸaÄŸÄ±da detaylÄ± ÅŸekilde inceliyoruz.

EÄŸitim ve doÄŸrulama aÅŸamalarÄ±nÄ±n sonuÃ§larÄ±, `yolov5` klasÃ¶rÃ¼nde `./yolov5/runs/train/yolov5x_fold0` altÄ±nda saklanÄ±r.

![](im/1076.png)

Modeli eÄŸittikten sonra, en iyi performans gÃ¶steren modelin aÄŸÄ±rlÄ±klarÄ±nÄ± kullanarak (Yolov5, en iyi ve son epoch modellerini otomatik olarak saklama iÅŸlevine sahiptir, bunlar best.pt ve last.pt olarak saklanÄ±r) test verisi Ã¼zerinde tahminler yapabiliriz:

```bash
!python ./yolov5/detect.py --weights ./yolov5/runs/train/yolov5x_fold0/weights/best.pt --img 512 --conf 0.1 --source /kaggle/input/global-wheat-detection/test --save-txt --save-conf --exist-ok
```

Bu adÄ±mda, tahmin aÅŸamasÄ±na Ã¶zel parametreleri aÃ§Ä±klayalÄ±m:

* **--weights**: EÄŸittiÄŸimiz modelin en iyi aÄŸÄ±rlÄ±klarÄ±nÄ±n bulunduÄŸu yeri gÃ¶sterir.
* **--conf 0.1**: Modelin Ã¼rettiÄŸi hangi aday sÄ±nÄ±r kutularÄ±nÄ±n saklanacaÄŸÄ±nÄ± belirtir. Genellikle bu, doÄŸruluk ve geri Ã§aÄŸÄ±rma arasÄ±nda bir dengeyi ifade eder (Ã§ok dÃ¼ÅŸÃ¼k bir eÅŸik Ã§ok fazla yanlÄ±ÅŸ pozitif Ã¼retebilirken, Ã§ok yÃ¼ksek bir eÅŸik hiÃ§bir buÄŸday baÅŸÄ± bulamamanÄ±za neden olabilir).
* **--source**: Test verisinin bulunduÄŸu konumdur.

OluÅŸturulan etiketler yerel olarak incelenebilir:

```bash
!ls ./yolov5/runs/detect/exp/labels/
```

Åunu gÃ¶rebiliriz:

```
2fd875eaa.txt  53f253011.txt  aac893a91.txt  f5a1f0358.txt
348a992bb.txt  796707dd7.txt  cc3532ff6.txt
```

Bir bireysel tahmine bakalÄ±m:

```bash
!cat 2fd875eaa.txt
```

AÅŸaÄŸÄ±daki formatta olduÄŸunu gÃ¶rÃ¼rÃ¼z:

```
0 0.527832 0.580566 0.202148 0.838867 0.101574
0 0.894531 0.587891 0.210938 0.316406 0.113519
```

Bu, 2fd875eaa adlÄ± gÃ¶rÃ¼ntÃ¼de, eÄŸitimli modelimizin iki sÄ±nÄ±r kutusu tespit ettiÄŸini (bu kutularÄ±n koordinatlarÄ±, satÄ±rdaki 2-5 numaralÄ± giriÅŸlerde yer almaktadÄ±r), her birinin gÃ¼ven puanÄ±nÄ±n ise satÄ±rÄ±n sonunda belirtilmiÅŸ olduÄŸunu ifade eder.

Tahminleri gereksinimlere uygun bir biÃ§imde birleÅŸtirip gÃ¶nderim dosyasÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in ÅŸu adÄ±mlarÄ± izleriz:

1. YukarÄ±da listelenen dosyalar Ã¼zerinde dÃ¶ngÃ¼ kurarÄ±z.
2. Her dosya iÃ§in, tÃ¼m satÄ±rlar gereken formata uygun bir ÅŸekilde (bir satÄ±r, bir tespit edilen sÄ±nÄ±r kutusunu temsil eder) string olarak dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
3. SatÄ±rlar, bu dosyaya karÅŸÄ±lÄ±k gelen tek bir string olarak birleÅŸtirilir.

Kod ÅŸu ÅŸekildedir:

```python
with open('submission.csv', 'w') as myfile:
    # Submit iÃ§in hazÄ±rlÄ±k
    wfolder = './yolov5/runs/detect/exp/labels/'
    for f in os.listdir(wfolder):
        fname = wfolder + f
        xdat = pd.read_csv(fname, sep=' ', header=None)
        outline = f[:-4] + ' ' + ' '.join(list(xdat.apply(lambda s: convert(s), axis=1)))
        myfile.write(outline + '\n')
        
myfile.close()
```

DosyanÄ±n nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ gÃ¶relim:

```bash
!cat submission.csv
```

Ã–rneÄŸin, ÅŸu ÅŸekilde bir iÃ§erik gÃ¶rebiliriz:

```
53f253011 0.100472 61 669 961 57 0.106223 0 125 234 183 0.1082 96 696 928 126 0.108863 515 393 86 161 0.11459 31 0 167 209 0.120246 517 466 89 147
aac893a91 0.108037 376 435 325 188
796707dd7 0.235373 684 128 234 113
cc3532ff6 0.100443 406 752 144 108 0.102479 405 87 4 89 0.107173 576 537 138 94 0.113459 256 498 179 211 0.114847 836 618 186 65 0.121121 154 544 248 115 0.125105 40 567 483 199
2fd875eaa 0.101398 439 163 204 860 0.112546 807 440 216 323
348a992bb 0.100572 0 10 440 298 0.101236 344 445 401 211
f5a1f0358 0.102549 398 424 295 96
```

OluÅŸturulan `submission.csv` dosyasÄ±, pipeline'Ä±mÄ±zÄ± tamamlamaktadÄ±r.

Bu bÃ¶lÃ¼mde, YoloV5 kullanarak nesne tespiti problemine nasÄ±l yaklaÅŸÄ±lacaÄŸÄ±nÄ± gÃ¶sterdik: farklÄ± formatlardaki etiketlerle nasÄ±l Ã§alÄ±ÅŸÄ±lacaÄŸÄ±nÄ±, belirli bir gÃ¶rev iÃ§in bir modelin nasÄ±l Ã¶zelleÅŸtirileceÄŸini, eÄŸitileceÄŸini ve sonuÃ§larÄ±n nasÄ±l deÄŸerlendirileceÄŸini aÃ§Ä±kladÄ±k.

Bu bilgilerle, nesne tespiti problemleriyle Ã§alÄ±ÅŸmaya baÅŸlayabilirsiniz.

Åimdi, bilgisayarla gÃ¶rme gÃ¶revlerinin Ã¼Ã§Ã¼ncÃ¼ popÃ¼ler sÄ±nÄ±fÄ±na, semantik segmentasyona geÃ§iyoruz.

### Semantic segmentation *(Anlamsal segmentasyon)*

Segmentasyon hakkÄ±nda dÃ¼ÅŸÃ¼nmenin en kolay yolu, bir gÃ¶rÃ¼ntÃ¼deki her pikseli sÄ±nÄ±flandÄ±rmak ve onu karÅŸÄ±lÄ±k gelen bir sÄ±nÄ±fa atamaktÄ±r; bu pikseller bir araya geldiÄŸinde, Ã¶rneÄŸin tÄ±bbi gÃ¶rÃ¼ntÃ¼lerde organlardaki hastalÄ±k bÃ¶lgeleri gibi ilgi alanlarÄ±nÄ± oluÅŸtururlar. Buna karÅŸÄ±n, nesne tespiti (Ã¶nceki bÃ¶lÃ¼mde tartÄ±ÅŸÄ±lmÄ±ÅŸtÄ±r) gÃ¶rÃ¼ntÃ¼nÃ¼n parÃ§alarÄ±nÄ± farklÄ± nesne sÄ±nÄ±flarÄ±na ayÄ±rÄ±r ve etraflarÄ±na sÄ±nÄ±rlayÄ±cÄ± kutular Ã§izer.

Bu modeling yaklaÅŸÄ±mÄ±nÄ±, Sartorius â€“ HÃ¼cre Ã–rneÄŸi Segmentasyonu yarÄ±ÅŸmasÄ±ndan ([https://www.kaggle.com/c/sartorius-cell-instance-segmentation](https://www.kaggle.com/c/sartorius-cell-instance-segmentation)) verilerle gÃ¶stereceÄŸiz. Bu yarÄ±ÅŸmada, katÄ±lÄ±mcÄ±lara, mikroskop gÃ¶rÃ¼ntÃ¼lerinden nÃ¶ron hÃ¼crelerinin Ã¶rnek segmentasyonunu eÄŸitmek iÃ§in modeller geliÅŸtirmeleri gÃ¶revi verilmiÅŸti.

Ã‡Ã¶zÃ¼mÃ¼mÃ¼z, bir dizi tespit ve segmentasyon algoritmasÄ±nÄ± destekleyen Facebook AI Research tarafÄ±ndan oluÅŸturulan bir kÃ¼tÃ¼phane olan **Detectron2** etrafÄ±nda inÅŸa edilecek.

Detectron2, orijinal **Detectron** kÃ¼tÃ¼phanesinin ([https://github.com/facebookresearch/Detectron/](https://github.com/facebookresearch/Detectron/)) ve **Mask R-CNN** projesinin ([https://github.com/facebookresearch/maskrcnn-benchmark/](https://github.com/facebookresearch/maskrcnn-benchmark/)) halefidir.

Ä°lk olarak, ekstra paketleri kurarak baÅŸlÄ±yoruz:

```bash
!pip install pycocotools
!pip install 'git+https://github.com/facebookresearch/detectron2.git'
```

**pycocotools**'u ([https://github.com/cocodataset/cocoapi/tree/master/PythonAPI/pycocotools](https://github.com/cocodataset/cocoapi/tree/master/PythonAPI/pycocotools)) kuruyoruz, Ã§Ã¼nkÃ¼ etiketleri formatlamak iÃ§in buna ihtiyacÄ±mÄ±z olacak ve **Detectron2**'yi ([https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2)) kuruyoruz; bu, bu gÃ¶revdeki ana iÅŸlevimizi yerine getirecek kÃ¼tÃ¼phanedir.

Modelimizi eÄŸitmeden Ã¶nce biraz hazÄ±rlÄ±k yapmamÄ±z gerekiyor: Etiketler, organizatÃ¶rler tarafÄ±ndan saÄŸlanan **run-length encoding (RLE)** formatÄ±ndan **COCO** formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmelidir. **RLE**'nin temel amacÄ±, alan tasarrufu saÄŸlamaktÄ±r: Bir segmentasyon, bir grup pikseli belirli bir ÅŸekilde iÅŸaretlemeyi iÃ§erir. Bir gÃ¶rÃ¼ntÃ¼ bir dizi olarak dÃ¼ÅŸÃ¼nÃ¼lebileceÄŸinden, bu alan bir dizi dÃ¼z Ã§izgi (satÄ±r veya sÃ¼tun yÃ¶nÃ¼nde) ile tanÄ±mlanabilir.

Bu Ã§izgilerin her birini, indeksleri listeleyerek veya baÅŸlangÄ±Ã§ pozisyonu ve sonrasÄ±ndaki ardÄ±ÅŸÄ±k bloÄŸun uzunluÄŸunu belirterek kodlayabilirsiniz. AÅŸaÄŸÄ±da gÃ¶rsel bir Ã¶rnek verilmiÅŸtir:

![](im/1077.png)

Microsoft'un Common Objects in Context (COCO) formatÄ±, bir gÃ¶rÃ¼ntÃ¼ veri kÃ¼mesi iÃ§in etiketlerin ve meta verilerin nasÄ±l kaydedileceÄŸini belirten Ã¶zel bir JSON yapÄ±sÄ±dÄ±r. AÅŸaÄŸÄ±da, RLE'yi COCO formatÄ±na nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼receÄŸimizi ve bunu k-fold doÄŸrulama bÃ¶lmesiyle nasÄ±l birleÅŸtireceÄŸimizi gÃ¶steriyoruz, bÃ¶ylece her katman iÃ§in gerekli olan eÄŸitim/doÄŸrulama JSON dosyalarÄ±nÄ± elde etmiÅŸ olacaÄŸÄ±z.

BaÅŸlayalÄ±m:

```python
# from pycocotools.coco import COCO
import skimage.io as io
import matplotlib.pyplot as plt
from pathlib import Path
from PIL import Image
import pandas as pd
import numpy as np
from tqdm.notebook import tqdm
import json, itertools
from sklearn.model_selection import GroupKFold
```

**YapÄ±landÄ±rma (Config):**

```python
class CFG:
    data_path = '../input/sartorius-cell-instance-segmentation/'
    nfolds = 5
```

RLE'den COCO'ya geÃ§mek iÃ§in Ã¼Ã§ fonksiyona ihtiyacÄ±mÄ±z var. Ä°lk olarak, RLE'yi ikili bir maskeye dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekiyor:

```python
# From https://www.kaggle.com/stainsby/fast-tested-rle
def rle_decode(mask_rle, shape):
    '''
    mask_rle: run-length as string formatted (start length)
    shape: (height, width) of array to return
    Returns numpy array, 1 - mask, 0 - background
    '''
    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int)
                       for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = 1
    return img.reshape(shape)  # Needed to align to RLE direction
```

Ä°kinci fonksiyon, ikili maskeyi RLE'ye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r:

```python
# From https://newbedev.com/encode-numpy-array-using-uncompressed-rle-for coco-dataset
def binary_mask_to_rle(binary_mask):
    rle = {'counts': [], 'size': list(binary_mask.shape)}
    counts = rle.get('counts')
    for i, (value, elements) in enumerate(
            itertools.groupby(binary_mask.ravel(order='F'))):
        if i == 0 and value == 1:
            counts.append(0)
        counts.append(len(list(elements)))
    return rle
```

Son olarak, bu iki fonksiyonu birleÅŸtirerek COCO Ã§Ä±ktÄ±sÄ±nÄ± Ã¼retiriz:

```python
def coco_structure(train_df):
    cat_ids = {name: id+1 for id, name in enumerate(
        train_df.cell_type.unique())}
    cats = [{'name': name, 'id': id} for name, id in cat_ids.items()]
    images = [{'id': id, 'width': row.width, 'height': row.height,
               'file_name':f'train/{id}.png'} for id,
               row in train_df.groupby('id').agg('first').iterrows()]
    annotations = []
    for idx, row in tqdm(train_df.iterrows()):
        mk = rle_decode(row.annotation, (row.height, row.width))
        ys, xs = np.where(mk)
        x1, x2 = min(xs), max(xs)
        y1, y2 = min(ys), max(ys)
        enc = binary_mask_to_rle(mk)
        seg = {
            'segmentation': enc,
            'bbox': [int(x1), int(y1), int(x2-x1+1), int(y2-y1+1)],
            'area': int(np.sum(mk)),
            'image_id': row.id,
            'category_id': cat_ids[row.cell_type],
            'iscrowd': 0,
            'id': idx
        }
        annotations.append(seg)
    return {'categories': cats, 'images': images, 'annotations': annotations}
```

Verilerimizi Ã¶rtÃ¼ÅŸmeyen katmanlara ayÄ±rÄ±yoruz:

```python
train_df = pd.read_csv(CFG.data_path + 'train.csv')
gkf = GroupKFold(n_splits=CFG.nfolds)
train_df["fold"] = -1
y = train_df.width.values
```

BunlarÄ± dÃ¶ngÃ¼yle bÃ¶lelim:

```python
all_ids = train_df.id.unique()
# For fold in range(CFG.nfolds):
for fold in range(4, 5):    
    train_sample = train_df.loc[fold_id != fold]
    root = coco_structure(train_sample)
    with open('annotations_train_f' + str(fold) + 
              '.json', 'w', encoding='utf-8') as f:
        json.dump(root, f, ensure_ascii=True, indent=4)
        
    valid_sample = train_df.loc[fold_id == fold]
    print('fold ' + str(fold) + ': produced')

for fold in range(4, 5):    
    train_sample = train_df.loc[fold_id == fold]
    root = coco_structure(train_sample)
    with open('annotations_valid_f' + str(fold) + 
              '.json', 'w', encoding='utf-8') as f:
        json.dump(root, f, ensure_ascii=True, indent=4)
        
    valid_sample = train_df.loc[fold_id == fold]
    print('fold ' + str(fold) + ': produced')
```

Burada dÃ¶ngÃ¼lerin parÃ§alara ayrÄ±lmasÄ±nÄ±n nedeni, Kaggle ortamÄ±ndaki boyut sÄ±nÄ±rÄ±dÄ±r: Notebook Ã§Ä±ktÄ±sÄ±nÄ±n maksimum boyutu 20 GB ile sÄ±nÄ±rlÄ±dÄ±r ve her bir katman iÃ§in 2 dosya (eÄŸitim/doÄŸrulama) toplamda 10 JSON dosyasÄ± anlamÄ±na gelir, bu da bu sÄ±nÄ±rÄ± aÅŸar.

Bu tÃ¼r pratik hususlar, Ã¶zellikle "hazÄ±rlÄ±k" Ã§alÄ±ÅŸmalarÄ±nda Ã¶nemli olabilir; Ã§Ã¼nkÃ¼ bu tÃ¼r iÅŸleri baÅŸka bir yerde de yapabilir ve sonra Kaggle Dataset'leri olarak yÃ¼kleyebilirsiniz.

Åimdi, verilerimizi bÃ¶lÃ¼mler halinde hazÄ±rladÄ±ktan sonra, Detectron2 modelini eÄŸitimimize baÅŸlatabiliriz. Genelde, gerekli paketleri yÃ¼kleyerek baÅŸlÄ±yoruz:

```python
from datetime import datetime
import os
import pandas as pd
import numpy as np
import pycocotools.mask as mask_util
import detectron2
from pathlib import Path
import random, cv2, os
import matplotlib.pyplot as plt
# Import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor, DefaultTrainer
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer, ColorMode
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.data.datasets import register_coco_instances
from detectron2.utils.logger import setup_logger
from detectron2.evaluation.evaluator import DatasetEvaluator
from detectron2.engine import BestCheckpointer
from detectron2.checkpoint import DetectionCheckpointer
setup_logger()
import torch
```

Detectron2'den alÄ±nan bu kÃ¼tÃ¼phaneler ilk baÅŸta gÃ¶z korkutucu olabilir, ancak gÃ¶rev tanÄ±mÄ±nda ilerledikÃ§e iÅŸlevleri daha aÃ§Ä±k hale gelecektir; Ã¶ncelikle giriÅŸ verisi klasÃ¶rÃ¼, etiket klasÃ¶rÃ¼ ve tercih edilen model mimarisini tanÄ±mlayan bir YAML dosyasÄ±na yollarÄ± belirtiriz:

```python
class CFG:
    wfold = 4
    data_folder = '../input/sartorius-cell-instance-segmentation/'
    anno_folder = '../input/sartoriusannotations/'
    model_arch = 'mask_rcnn_R_50_FPN_3x.yaml'
    nof_iters = 10000
    seed = 45
```

Burada Ã¶nemli bir nokta, yineleme sayÄ±sÄ± parametresidir (nof_iters). Genellikle model eÄŸitimi, epoch sayÄ±sÄ±yla parametrik hale gelir, yani eÄŸitim verisinden geÃ§en tam geÃ§iÅŸler. Detectron2 farklÄ± bir ÅŸekilde tasarlanmÄ±ÅŸtÄ±r: bir yineleme, bir mini-batch'Ä± ifade eder ve farklÄ± mini-batch boyutlarÄ± modelin farklÄ± bÃ¶lÃ¼mlerinde kullanÄ±lÄ±r.

SonuÃ§larÄ±n tekrarlanabilir olmasÄ±nÄ± saÄŸlamak iÃ§in modelin farklÄ± bileÅŸenlerinde kullanÄ±lan rastgele tohumlarÄ± sabitleriz:

```python
def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

seed_everything(CFG.seed)
```

YarÄ±ÅŸmanÄ±n metriÄŸi, farklÄ± kesiÅŸim-birleÅŸim oranÄ± (IoU) eÅŸiklerinde ortalama hassasiyetin hesaplanmasÄ±ydÄ±. HatÄ±rlatmak gerekirse, IoU, Ã¶nerilen bir nesne piksel seti ile doÄŸru nesne piksel seti arasÄ±ndaki kesiÅŸimin hesaplanmasÄ±yla elde edilir.

```python
# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou
def precision_at(threshold, iou):
    matches = iou > threshold
    true_positives = np.sum(matches, axis=1) == 1  # Correct objects
    false_positives = np.sum(matches, axis=0) == 0  # Missed objects
false_negatives = np.sum(matches, axis=1) == 0  # Extra objects
return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)

def score(pred, targ):
pred_masks = pred['instances'].pred_masks.cpu().numpy()
enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]
enc_targs = list(map(lambda x:x, targ))
ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))
prec = []
for t in np.arange(0.5, 1.0, 0.05):
tp, fp, fn = precision_at(t, ious)
p = tp / (tp + fp + fn)
prec.append(p)
return np.mean(prec)

````

MetriÄŸi tanÄ±mladÄ±ktan sonra, model iÃ§inde doÄŸrudan hedef fonksiyon olarak kullanabiliriz:

```python
class MAPIOUEvaluator(DatasetEvaluator):
    def __init__(self, dataset_name):
        dataset_dicts = DatasetCatalog.get(dataset_name)
        self.annotations_cache = {item['image_id']: item['annotations']
                                  for item in dataset_dicts}

    def reset(self):
        self.scores = []

    def process(self, inputs, outputs):
        for inp, out in zip(inputs, outputs):
            if len(out['instances']) == 0:
                self.scores.append(0)    
            else:
                targ = self.annotations_cache[inp['image_id']]
                self.scores.append(score(out, targ))

    def evaluate(self):
        return {"MaP IoU": np.mean(self.scores)}
```

ArtÄ±k eÄŸitim verileriyle ilgili her ÅŸey hazÄ±r olduÄŸuna gÃ¶re, modelin eÄŸitilmesine geÃ§ebiliriz.

![](im/1078.png)

Model eÄŸitildikten sonra, aÄŸÄ±rlÄ±klarÄ± kaydedebiliriz ve bunlarÄ± Ã§Ä±karÄ±m (inference) iÃ§in kullanabiliriz (potansiyel olarak ayrÄ± bir Notebookâ€™ta â€“ bu konuyu daha Ã¶nceki bÃ¶lÃ¼mlerde tartÄ±ÅŸmÄ±ÅŸtÄ±k) ve teslimat hazÄ±rlÄ±ÄŸÄ± iÃ§in. Ä°lk olarak, tahminleri dÃ¼zenlememize izin verecek yeni parametreler ekleriz; gÃ¼ven eÅŸiklerini ve minimal maske boyutlarÄ±nÄ± belirleriz:

```python
THRESHOLDS = [.18, .35, .58]
MIN_PIXELS = [75, 150, 75]
```

Bir maskeyi RLE formatÄ±nda kodlamak iÃ§in bir yardÄ±mcÄ± fonksiyona ihtiyacÄ±mÄ±z var:

```python
def rle_encode(img):
    '''
    img: numpy array, 1 - mask, 0 - background
    Run length olarak string formatÄ±nda dÃ¶ner
    '''
    pixels = img.flatten()
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)
```

AÅŸaÄŸÄ±da, her resim iÃ§in tÃ¼m maskeleri Ã¼reten ana fonksiyon yer almakta; ÅŸÃ¼pheli olanlarÄ± (gÃ¼ven puanlarÄ± **THRESHOLDS** deÄŸerinin altÄ±nda olanlarÄ±) ve kÃ¼Ã§Ã¼k alanlarÄ± (**MIN_PIXELS** deÄŸerinden az piksellere sahip olanlarÄ±) filtreler:

```python
def get_masks(fn, predictor):
    im = cv2.imread(str(fn))
    pred = predictor(im)
    pred_class = torch.mode(pred['instances'].pred_classes)[0]
    take = pred['instances'].scores >= THRESHOLDS[pred_class]
    pred_masks = pred['instances'].pred_masks[take]
    pred_masks = pred_masks.cpu().numpy()
    res = []
    used = np.zeros(im.shape[:2], dtype=int) 
    for mask in pred_masks:
        mask = mask * (1-used)
        # KÃ¼Ã§Ã¼k alanlarÄ± atla
        if mask.sum() >= MIN_PIXELS[pred_class]:
            used += mask
            res.append(rle_encode(mask))
    return res
```

SonrasÄ±nda, resim ID'lerini ve maskeleri depolayacaÄŸÄ±mÄ±z listeleri hazÄ±rlarÄ±z:

```python
dataDir = Path(CFG.data_folder)
ids, masks = [], []
test_names = (dataDir/'test').ls()
```

BÃ¼yÃ¼k resim setlerine sahip yarÄ±ÅŸmalar â€“ bu bÃ¶lÃ¼mde tartÄ±ÅŸÄ±lanlar gibi â€“ genellikle 9 saatten uzun sÃ¼re eÄŸitim yapÄ±lmasÄ±nÄ± gerektirir, bu da Code yarÄ±ÅŸmalarÄ±nda belirlenen zaman sÄ±nÄ±rÄ±dÄ±r ([https://www.kaggle.com/docs/competitions](https://www.kaggle.com/docs/competitions) adresinde gÃ¶rebilirsiniz). Bu, aynÄ± Notebook iÃ§inde model eÄŸitmek ve Ã§Ä±karÄ±m yapmak imkansÄ±z hale gelir. Tipik bir Ã§Ã¶zÃ¼m, Ã¶nce eÄŸitim Notebook/script'ini baÄŸÄ±msÄ±z bir Notebook olarak Kaggle, Google Colab, GCP veya yerel ortamda Ã§alÄ±ÅŸtÄ±rmaktÄ±r. Bu ilk Notebook'un Ã§Ä±ktÄ±sÄ± (eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar), ikinci Notebookâ€™a giriÅŸ olarak kullanÄ±lÄ±r, yani tahminler iÃ§in kullanÄ±lan modeli tanÄ±mlarÄ±z.

Bu ÅŸekilde ilerleyerek eÄŸitilmiÅŸ modelin aÄŸÄ±rlÄ±klarÄ±nÄ± yÃ¼kleriz:

```python
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/" +
                     CFG.arch + ".yaml"))
cfg.INPUT.MASK_FORMAT = 'bitmask'
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 
cfg.MODEL.WEIGHTS = CFG.model_folder + 'model_best_f' + 
                    str(CFG.wfold) + '.pth' 
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.TEST.DETECTIONS_PER_IMAGE = 1000
predictor = DefaultPredictor(cfg)
```

BazÄ± tahminleri gÃ¶rselleÅŸtirebiliriz:

```python
encoded_masks = get_masks(test_names[0], predictor)
_, axs = plt.subplots(1, 2, figsize=(40, 15))
axs[1].imshow(cv2.imread(str(test_names[0])))
for enc in encoded_masks:
    dec = rle_decode(enc)
axs[0].imshow(np.ma.masked_where(dec == 0, dec))
```

Ä°ÅŸte bir Ã¶rnek:

![](im/1079.png)

YukarÄ±da tanÄ±mlanan yardÄ±mcÄ± fonksiyonlarla, gÃ¶nderim iÃ§in RLE formatÄ±nda maskeleri Ã¼retmek oldukÃ§a basittir:

```python
for fn in test_names:
    encoded_masks = get_masks(fn, predictor)
    for enc in encoded_masks:
        ids.append(fn.stem)
        masks.append(enc)
pd.DataFrame({'id': ids, 'predicted': masks}).to_csv('submission.csv', index=False)
pd.read_csv('submission.csv').head()
```

Ä°ÅŸte son gÃ¶nderimin ilk birkaÃ§ satÄ±rÄ±:

![](im/1080.png)

BÃ¶lÃ¼mÃ¼n sonuna geldik. YukarÄ±daki pipeline (iÅŸlem hattÄ±), nasÄ±l bir semantik segmentasyon modeli kuracaÄŸÄ±nÄ±zÄ± ve bunu nasÄ±l eÄŸiteceÄŸinizi gÃ¶stermektedir. Biz az sayÄ±da iterasyon kullandÄ±k, ancak rekabetÃ§i sonuÃ§lar elde etmek iÃ§in daha uzun sÃ¼reli eÄŸitimler gereklidir.

> **Laura Fink**
> 
> [https://www.kaggle.com/allunia](https://www.kaggle.com/allunia)
> 
> 
> 
> Bu bÃ¶lÃ¼mÃ¼ tamamlamadan Ã¶nce, Kaggler Laura Fink'in platformdaki deneyimlerine dair sÃ¶ylediklerine gÃ¶z atalÄ±m. Kendisi, Notebooks Grandmaster unvanÄ±na sahip olup, birÃ§ok baÅŸarÄ±lÄ± Notebook Ã¼retmiÅŸtir. AyrÄ±ca MicroMata'da Veri Bilimi DirektÃ¶rÃ¼ olarak gÃ¶rev yapmaktadÄ±r.
> 
> 
> 
> ---
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Teknikler ve Ã§Ã¶zÃ¼m yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan, Kaggleâ€™daki uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Favori yarÄ±ÅŸmalarÄ±m, insana faydalÄ± bir ÅŸeyler Ã¼retmeye yÃ¶nelik olanlardÄ±r. Ã–zellikle saÄŸlÄ±kla ilgili olan tÃ¼m zorluklarÄ± seviyorum. Yine de her yarÄ±ÅŸma, kendi Ã§Ã¶zÃ¼lmesi gereken bulmacalarÄ±yla bir macera gibi gelir. Yeni beceriler Ã¶ÄŸrenmek ve yeni tÃ¼rde veri setlerini ya da problemleri keÅŸfetmek Ã§ok keyifli. Bu yÃ¼zden spesifik tekniklere odaklanmÄ±yorum, daha Ã§ok yeni bir ÅŸeyler Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±yorum. SanÄ±rÄ±m, keÅŸifsel veri analizi (EDA) konusundaki gÃ¼Ã§lÃ¼ yÃ¶nlerimle tanÄ±nÄ±yorum.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼ndelik iÅŸinizden ne kadar farklÄ±dÄ±r?**
> 
> Bir yarÄ±ÅŸmaya katÄ±ldÄ±ÄŸÄ±mda, ilk olarak problem aÃ§Ä±klamasÄ±nÄ± ve veri tanÄ±mÄ±nÄ± okurum. ForumlarÄ± ve kamuya aÃ§Ä±k Notebokâ€™larÄ± inceleyerek fikirler toplarÄ±m ve genellikle kendi Ã§Ã¶zÃ¼mlerimi geliÅŸtirmeye baÅŸlarÄ±m. Ä°lk aÅŸamada, gizli gruplarÄ± aramak ve bazÄ± sezgiler edinmek iÃ§in EDA'ya biraz zaman ayÄ±rÄ±rÄ±m. Bu, doÄŸru bir doÄŸrulama stratejisi oluÅŸturmak iÃ§in oldukÃ§a faydalÄ±dÄ±r, ki ben bunun tÃ¼m sonraki adÄ±mlarÄ±n temeli olduÄŸuna inanÄ±yorum. ArdÄ±ndan, Ã¶zellik mÃ¼hendisliÄŸi veya Ã¶n iÅŸleme gibi makine Ã¶ÄŸrenmesi pipelineâ€™larÄ±nÄ±n farklÄ± bÃ¶lÃ¼mlerinde iterasyon yaparak model mimarisini iyileÅŸtiririm, veri toplama hakkÄ±nda sorular sorarÄ±m, veri sÄ±zÄ±ntÄ±larÄ± ararÄ±m, daha fazla EDA yaparÄ±m ya da toplama modelleri oluÅŸtururum. Ã‡Ã¶zÃ¼mÃ¼mÃ¼ aÃ§gÃ¶zlÃ¼ bir ÅŸekilde geliÅŸtirmeye Ã§alÄ±ÅŸÄ±rÄ±m. Kaggle yarÄ±ÅŸmalarÄ± Ã§ok dinamik olduÄŸundan, hayatta kalabilmek iÃ§in farklÄ± fikirleri ve Ã§Ã¶zÃ¼mleri denemek gerekir.
> 
> 
> 
> Bu, gÃ¼ndelik iÅŸimden kesinlikle farklÄ±dÄ±r Ã§Ã¼nkÃ¼ iÅŸim daha Ã§ok veriden iÃ§gÃ¶rÃ¼ elde etmeye ve iÅŸ sÃ¼reÃ§lerini geliÅŸtirmek iÃ§in basit ama etkili Ã§Ã¶zÃ¼mler bulmaya odaklÄ±dÄ±r. Burada Ã§Ã¶zÃ¼lmesi gereken problem, kullanÄ±lan modellerden Ã§ok daha karmaÅŸÄ±ktÄ±r. Ã‡Ã¶zÃ¼lmesi gereken sorunun Ã§ok net bir ÅŸekilde tanÄ±mlanmasÄ± gerekir, bu da farklÄ± alanlardan uzmanlarla hangi hedeflere ulaÅŸÄ±lmasÄ± gerektiÄŸini, hangi sÃ¼reÃ§lerin yer aldÄ±ÄŸÄ±nÄ± ve verilerin nasÄ±l toplanmasÄ± veya birleÅŸtirilmesi gerektiÄŸini tartÄ±ÅŸmayÄ± gerektirir. Kaggle yarÄ±ÅŸmalarÄ±na kÄ±yasla, gÃ¼nlÃ¼k iÅŸlerimde Ã§ok daha fazla iletiÅŸim gereklidir, makineli Ã¶ÄŸrenme becerilerinden Ã§ok.
> 
> 
> 
> **KatÄ±ldÄ±ÄŸÄ±nÄ±z Ã¶zellikle zorlayÄ±cÄ± bir yarÄ±ÅŸmayÄ± ve bu gÃ¶revi nasÄ±l ele aldÄ±ÄŸÄ±nÄ±zla ilgili iÃ§gÃ¶rÃ¼lerinizi bizimle paylaÅŸÄ±n.**
> 
> G2Net Gravitational Wave Detection yarÄ±ÅŸmasÄ± favorilerimden biriydi. AmaÃ§, dedektÃ¶r bileÅŸenlerinden ve kara kuvvetlerden kaynaklanan gÃ¼rÃ¼ltÃ¼lerin iÃ§inde gizlenmiÅŸ simÃ¼le edilmiÅŸ kÃ¼tleÃ§ekimsel dalga sinyallerini tespit etmekti. Bu yarÄ±ÅŸmada Ã¶nemli bir iÃ§gÃ¶rÃ¼, veriyi analiz etmenin standart yollarÄ±na eleÅŸtirel bir gÃ¶zle bakmak ve kendi fikirlerinizi denemek gerektiÄŸiydi. OkuduÄŸum makalelerde, veriler genellikle Fourier veya Constant-Q dÃ¶nÃ¼ÅŸÃ¼mÃ¼ kullanÄ±larak hazÄ±rlanÄ±yordu, veriler beyazlatÄ±ldÄ±ktan ve band geÃ§iren bir filtre uygulandÄ±ktan sonra.
> 
> 
> 
> Ã‡ok geÃ§meden, beyazlatmanÄ±n yardÄ±mcÄ± olmadÄ±ÄŸÄ± ortaya Ã§Ä±ktÄ±, Ã§Ã¼nkÃ¼ bu iÅŸlem Power Spectral Density'nin spline interpolasyonunu kullanÄ±yordu ve bu Ã§ok gÃ¼rÃ¼ltÃ¼lÃ¼ydÃ¼. GÃ¼rÃ¼ltÃ¼lÃ¼ verinin kÃ¼Ã§Ã¼k alt kÃ¼melerine polinomlar uydurmak, aÅŸÄ±rÄ± uyum saÄŸlamaktan dolayÄ± baÅŸka bir hata kaynaÄŸÄ± ekliyordu.
> 
> 
> 
> Beyazlatma iÅŸlemini Ã§Ä±kardÄ±ktan sonra, Constant-Q dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼n farklÄ± hiperparametrelerini denedim ve bu yÃ¶ntem uzun bir sÃ¼re boyunca forumda ve aÃ§Ä±k Notebokâ€™larda Ã¶nde giden yÃ¶ntem oldu. KÃ¼tleÃ§ekimsel dalgalarÄ±n iki kaynaÄŸÄ± olduÄŸundan ve bunlarÄ±n farklÄ± Q-deÄŸerleri aralÄ±klarÄ±yla kapsanabildiÄŸinden, bu hiperparametrelerde farklÄ±lÄ±klar gÃ¶steren bir model topluluÄŸu denedim. Bu, puanÄ±mÄ± iyileÅŸtirmede faydalÄ± oldu, ama sonra bir sÄ±nÄ±r noktasÄ±na geldim. Constant-Q dÃ¶nÃ¼ÅŸÃ¼mÃ¼, zaman serilerine bir dizi filtre uygular ve bunlarÄ± frekans alanÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Kendime ÅŸunu sormaya baÅŸladÄ±m: Bu filtreleme gÃ¶revlerini daha iyi ve esnek bir ÅŸekilde yapan bir yÃ¶ntem var mÄ±ydÄ±? AynÄ± zamanda, 1D CNNâ€™lerin kullanÄ±lmasÄ± fikri toplulukta ortaya Ã§Ä±ktÄ± ve bunu Ã§ok beÄŸendim. Hepimiz biliyoruz ki, 2D CNN'lerin filtreleri, gÃ¶rÃ¼ntÃ¼ verileriyle kenarlarÄ±, Ã§izgileri ve dokularÄ± tespit edebiliyor. AynÄ± ÅŸey, Laplace veya Sobel gibi "klasik" filtrelerle de yapÄ±labiliyor. Bu yÃ¼zden kendime ÅŸunu sordum: 1D CNNâ€™i, zaten sabit olan dÃ¶nÃ¼ÅŸÃ¼mleri uygulamak yerine, en Ã¶nemli filtreleri kendi baÅŸÄ±na Ã¶ÄŸrenmesi iÃ§in kullanamaz mÄ±yÄ±z?
> 
> 
> 
> 1D CNN Ã§Ã¶zÃ¼mÃ¼m Ã§alÄ±ÅŸmadÄ± ama birÃ§ok Ã¼st dÃ¼zey takÄ±m bunu iyi baÅŸardÄ±. G2Net yarÄ±ÅŸmasÄ±, bir madalya kazanma hedefini kaÃ§Ä±rmÄ±ÅŸ olmama raÄŸmen favorilerimden biriydi. Yolda kazandÄ±ÄŸÄ±m bilgi ve standart yaklaÅŸÄ±mlar hakkÄ±nda Ã¶ÄŸrendiÄŸim ders Ã§ok deÄŸerliydi.
> 
> 
> 
> **Kaggle kariyerinizde size yardÄ±mcÄ± oldu mu? EÄŸer Ã¶yleyse, nasÄ±l?**
> 
> Ãœniversiteden sonra ilk iÅŸime Java yazÄ±lÄ±m geliÅŸtiricisi olarak baÅŸladÄ±m, ancak yÃ¼ksek lisans tezimde makine Ã¶ÄŸrenmesiyle ilk tanÄ±ÅŸmamÄ± yapmÄ±ÅŸtÄ±m. Veri analitiÄŸiyle daha fazla ilgileniyordum ama o dÃ¶nemde neredeyse hiÃ§ veri bilimi iÅŸi yoktu veya bu iÅŸler o ÅŸekilde adlandÄ±rÄ±lmÄ±yordu. Kaggleâ€™Ä± ilk kez duyduÄŸumda, hemen hemen ilk andan itibaren iÃ§ine girdim. O zamandan beri sÄ±k sÄ±k akÅŸamlarÄ± Kaggleâ€™da vakit geÃ§irirdim, eÄŸlence amacÄ±yla. O dÃ¶nemde pozisyonumu deÄŸiÅŸtirmeyi dÃ¼ÅŸÃ¼nmÃ¼yordum ama sonra bir araÅŸtÄ±rma projesi ortaya Ã§Ä±ktÄ± ve makine Ã¶ÄŸrenmesi becerileri gerekiyordu. Kaggleâ€™a katÄ±larak edindiÄŸim bilgilerle, bu proje iÃ§in uygun bir aday olduÄŸumu gÃ¶sterdim. Bu, veri bilimi kariyerime giriÅŸ noktasÄ± oldu.
> 
> 
> 
> Kaggle, her zaman fikirlerimi denemek, yeni yÃ¶ntemler ve araÃ§lar Ã¶ÄŸrenmek, pratik deneyim kazanmak iÃ§in harika bir yerdi. Bu ÅŸekilde elde ettiÄŸim beceriler, iÅŸteki veri bilimi projelerinde Ã§ok faydalÄ± oldu. Kaggle, size farklÄ± fikirleri denemek ve yaratÄ±cÄ± olmak iÃ§in risk olmadan bir oyun alanÄ± saÄŸlÄ±yor. Bir yarÄ±ÅŸmada baÅŸarÄ±sÄ±z olmak, en azÄ±ndan Ã¶ÄŸrenilecek bir ders olduÄŸunu gÃ¶sterir, ama bir projede baÅŸarÄ±sÄ±z olmak, kendiniz ve diÄŸer insanlar Ã¼zerinde bÃ¼yÃ¼k olumsuz etkiler yaratabilir.
> 
> 
> 
> YarÄ±ÅŸmalara katÄ±lmanÄ±n yanÄ± sÄ±ra, portfÃ¶yÃ¼nÃ¼zÃ¼ oluÅŸturmanÄ±n baÅŸka bir harika yolu da Notebok yazmaktÄ±r. BÃ¶ylece dÃ¼nyaya, sorunlarÄ± nasÄ±l ele aldÄ±ÄŸÄ±nÄ±zÄ± ve iÃ§gÃ¶rÃ¼lerinizi, sonuÃ§larÄ±nÄ±zÄ± nasÄ±l ilettiÄŸinizi gÃ¶sterebilirsiniz. Bu, farklÄ± geÃ§miÅŸlere sahip yÃ¶netim, mÃ¼ÅŸteri ve uzmanlarla Ã§alÄ±ÅŸÄ±rken Ã§ok Ã¶nemlidir.
> 
> 
> 
> **Deneyiminize gÃ¶re, deneyimsiz Kaggle kullanÄ±cÄ±larÄ±nÄ±n genellikle gÃ¶z ardÄ± ettiÄŸi ÅŸeyler nedir? BaÅŸladÄ±ÄŸÄ±nÄ±zda bilmek istediÄŸiniz ama o zamanlar bilmediÄŸiniz ÅŸeyler nelerdir?**
> 
> Bence, yarÄ±ÅŸmalara katÄ±lan birÃ§ok yeni kullanÄ±cÄ±, kamu leaderboardâ€™undan etkilenip iyi bir doÄŸrulama stratejisi oluÅŸturmadan modellerini geliÅŸtiriyor. BaÅŸarÄ±larÄ±nÄ± leaderboard Ã¼zerinde Ã¶lÃ§erken, genellikle kamu test verisine aÅŸÄ±rÄ± uyum saÄŸlÄ±yorlar. YarÄ±ÅŸma sonunda, modelleri Ã¶zel test verilerine genelleme yapamÄ±yor ve genellikle yÃ¼zlerce sÄ±ra aÅŸaÄŸÄ±ya dÃ¼ÅŸÃ¼yorlar. Mercedes-Benz Greener Manufacturing yarÄ±ÅŸmasÄ±nda, kamu leaderboard'unda yÃ¼kselmeyi baÅŸaramadÄ±ÄŸÄ±m zamanlarÄ± hatÄ±rlÄ±yorum. Ama nihai sÄ±ralamalar aÃ§Ä±klandÄ±ÄŸÄ±nda, leaderboardâ€™da birÃ§ok kiÅŸinin bir anda sÄ±ralamalarÄ±nÄ±n deÄŸiÅŸtiÄŸini gÃ¶rÃ¼nce Ã§ok ÅŸaÅŸÄ±rmÄ±ÅŸtÄ±m. O gÃ¼nden sonra, doÄŸru bir doÄŸrulama ÅŸemasÄ±nÄ±n, aÅŸÄ±rÄ± uyum ve eksik uyum sorunlarÄ±yla baÅŸa Ã§Ä±kabilmek iÃ§in Ã§ok Ã¶nemli olduÄŸunu hep aklÄ±mda tutarÄ±m.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hatalar nelerdir?**
> 
> Åu ana kadar yaptÄ±ÄŸÄ±m en bÃ¼yÃ¼k hata, bir yarÄ±ÅŸmanÄ±n baÅŸÄ±nda Ã§Ã¶zÃ¼mÃ¼mÃ¼n detaylarÄ±na fazla zaman ve enerji harcamaktÄ±. GerÃ§ekten de, iyi bir doÄŸrulama stratejisi kurduktan sonra, farklÄ± ve Ã§eÅŸitli fikirler Ã¼zerinde hÄ±zlÄ±ca iterasyon
> 
> 
> 
> 
> 
> yapmak Ã§ok daha iyi. Bu ÅŸekilde, geliÅŸtirme iÃ§in umut verici yÃ¶nleri bulmak daha kolay ve hÄ±zlÄ± olur ve bir yerde takÄ±lma riski Ã§ok daha azdÄ±r.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in kullanmanÄ±zÄ± Ã¶nerdiÄŸiniz belirli araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> Kaggle topluluÄŸunda aktif olduÄŸunuzda Ã¶ÄŸrenip pratik yapabileceÄŸiniz birÃ§ok yaygÄ±n araÃ§ ve kÃ¼tÃ¼phane var ve bunlarÄ±n hepsini tavsiye ederim. Esnek kalmak ve avantajlarÄ±nÄ± ve dezavantajlarÄ±nÄ± Ã¶ÄŸrenmek Ã¶nemlidir. Bu ÅŸekilde, Ã§Ã¶zÃ¼mleriniz araÃ§larÄ±nÄ±za deÄŸil, fikirlerinize ve yaratÄ±cÄ±lÄ±ÄŸÄ±nÄ±za dayanÄ±r.
> 
> 
> 
> **Bir yarÄ±ÅŸmaya katÄ±lÄ±rken akÄ±lda tutulmasÄ± gereken en Ã¶nemli ÅŸey nedir?**
> 
> Veri bilimi, modeller kurmakla ilgili deÄŸildir, asÄ±l mesele veriyi ve nasÄ±l toplandÄ±ÄŸÄ±nÄ± anlamaktÄ±r. KatÄ±ldÄ±ÄŸÄ±m birÃ§ok yarÄ±ÅŸma, test verilerinde sÄ±zÄ±ntÄ±lar ya da gizli gruplar olduÄŸunu ve bunlarÄ± keÅŸfetmek iÃ§in keÅŸifsel veri analizinin kullanÄ±labileceÄŸini gÃ¶sterdi.

### Summary *(Ã–zet)*

Bu bÃ¶lÃ¼mde, size Kaggle yarÄ±ÅŸmalarÄ± aÃ§Ä±sÄ±ndan bilgisayarla gÃ¶rme ile ilgili en Ã¶nemli konularÄ±n bir genel bakÄ±ÅŸÄ±nÄ± sunduk. AlgoritmalarÄ±n genelleme yeteneklerini artÄ±rmak iÃ§in kullanÄ±lan Ã¶nemli bir teknik sÄ±nÄ±fÄ± olan artÄ±rmalar (augmentations) konusunu tanÄ±ttÄ±k ve ardÄ±ndan en sÄ±k karÅŸÄ±laÅŸÄ±lan Ã¼Ã§ problem iÃ§in uÃ§tan uca pipeline'lar (iÅŸlem hatlarÄ±) gÃ¶sterdik: gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ±, nesne tespiti ve anlamsal segmentasyon.

Bir sonraki bÃ¶lÃ¼mde, dikkatimizi baÅŸka bir son derece geniÅŸ ve popÃ¼ler problem kategorisi olan doÄŸal dil iÅŸleme (NLP) alanÄ±na kaydÄ±racaÄŸÄ±z.

---

## Chapter 11: Modeling for NLP *(BÃ¶lÃ¼m 11: DoÄŸal Dil Ä°ÅŸleme (NLP) iÃ§in Modellemede YaklaÅŸÄ±mlar)*

DoÄŸal dil iÅŸleme (NLP), dilbilim, bilgisayar bilimi ve yapay zekÃ¢nÄ±n kesiÅŸim noktasÄ±nda faaliyet gÃ¶steren bir alandÄ±r. Temel odak noktasÄ±, bÃ¼yÃ¼k miktarda doÄŸal dil verisini iÅŸlemek ve analiz etmek iÃ§in algoritmalar geliÅŸtirmektir. Son birkaÃ§ yÄ±l iÃ§inde, Kaggle yarÄ±ÅŸmalarÄ±nda giderek daha popÃ¼ler bir konu haline gelmiÅŸtir. Alan kendisi oldukÃ§a geniÅŸ olup, chatbotlar ve makine Ã§evirisi gibi Ã§ok popÃ¼ler konularÄ± kapsasa da, bu bÃ¶lÃ¼mde Kaggle yarÄ±ÅŸmalarÄ±nda sÄ±klÄ±kla karÅŸÄ±laÅŸÄ±lan belirli alt alanlara odaklanacaÄŸÄ±z.

Duygu analizi, basit bir sÄ±nÄ±flandÄ±rma problemi olarak son derece popÃ¼lerdir ve her yerde tartÄ±ÅŸÄ±lmaktadÄ±r, bu nedenle biraz daha ilginÃ§ bir varyasyonla baÅŸlayacaÄŸÄ±z: bir tweet'teki duygu destekleyici ifadeleri tanÄ±mlamak. ArdÄ±ndan, aÃ§Ä±k alan soru yanÄ±tlama probleminin Ã¶rnek bir Ã§Ã¶zÃ¼mÃ¼nÃ¼ aÃ§Ä±klayacaÄŸÄ±z ve son olarak NLP problemleri iÃ§in artÄ±rma (augmentation) konusunda bir bÃ¶lÃ¼mle bitireceÄŸiz. Bu konu, bilgisayarla gÃ¶rme alanÄ±ndaki karÅŸÄ±lÄ±ÄŸÄ± kadar fazla ilgi gÃ¶rmemektedir.

Ã–zetle, ÅŸu konularÄ± ele alacaÄŸÄ±z:

* Duygu analizi
* AÃ§Ä±k alan Soru-Cevap (Q&A)
* Metin artÄ±rma stratejileri

### Sentiment analysis *(Duygu analizi)*

Twitter, en popÃ¼ler sosyal medya platformlarÄ±ndan biri olup, hem bireyler hem de ÅŸirketler iÃ§in Ã¶nemli bir iletiÅŸim aracÄ±dÄ±r.

Duyguyu dilde yakalamak, Ã¶zellikle ikinci baÄŸlamda Ã¶nemlidir: pozitif bir tweet viral olabilir ve mesajÄ± yayabilirken, Ã¶zellikle negatif bir tweet zararlÄ± olabilir. Ä°nsan dili karmaÅŸÄ±k olduÄŸu iÃ§in sadece duyguyu belirlemek deÄŸil, aynÄ± zamanda nasÄ±l belirlediÄŸini de incelemek Ã¶nemlidir: hangi kelimeler aslÄ±nda duygu tanÄ±mÄ±na yol aÃ§tÄ±?

Bu probleme yaklaÅŸÄ±mÄ±, Tweet Duygu Ã‡Ä±kartma yarÄ±ÅŸmasÄ±ndan ([https://www.kaggle.com/c/tweet-sentiment-extraction](https://www.kaggle.com/c/tweet-sentiment-extraction)) alÄ±nan verileri kullanarak gÃ¶stereceÄŸiz. KÄ±salÄ±k adÄ±na, aÅŸaÄŸÄ±daki koddan ithalatlarÄ± (import) Ã§Ä±kardÄ±k, ancak bunlarÄ± bu bÃ¶lÃ¼mÃ¼n GitHub deposundaki ilgili Notebook'ta bulabilirsiniz.

Problemi daha iyi anlayabilmek iÃ§in, veriye bakalÄ±m:

```python
df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')
df.head()
```

Ä°lk birkaÃ§ satÄ±r ÅŸÃ¶yle:

![](im/1081.png)

GerÃ§ek tweetler, *text* sÃ¼tununda saklanmaktadÄ±r. Her birinin bir duygu etiketi vardÄ±r ve bu duyguya iliÅŸkin destekleyici cÃ¼mle *selected_text* sÃ¼tununda yer almaktadÄ±r (bu, duygu tahminini yapmak iÃ§in kullanÄ±lan tweet'in parÃ§asÄ±dÄ±r).

Ã–ncelikle, temel temizlik fonksiyonlarÄ±nÄ± tanÄ±mlayarak baÅŸlayacaÄŸÄ±z. Ä°lk olarak, web sitesi URL'lerini ve karakter olmayan Ã¶ÄŸeleri temizlemek, insanlarÄ± kÃ¼fÃ¼rlÃ¼ kelimeler yerine kullandÄ±klarÄ± yÄ±ldÄ±zlarÄ± tek bir token ("swear") ile deÄŸiÅŸtirmek istiyoruz. Bunu yapmamÄ±za yardÄ±mcÄ± olacak bazÄ± dÃ¼zenli ifadeler kullanÄ±yoruz:

```python
def basic_cleaning(text):
    text = re.sub(r'https?://www\.\S+\.com', '', text)
    text = re.sub(r'[^A-Za-z|\s]', '', text)
    text = re.sub(r'\*+', 'swear', text)  # KÃ¼fÃ¼rlÃ¼ kelimeleri **** ÅŸeklinde yakala
    return text
```

Sonraki adÄ±mda, tweet'lerin iÃ§eriÄŸinden HTML etiketlerini ve emojileri kaldÄ±racaÄŸÄ±z:

```python
def remove_html(text):
    html = re.compile(r'<.*?>')
    return html.sub(r'', text)

def remove_emoji(text):
    emoji_pattern = re.compile("[" 
                               u"\U0001F600-\U0001F64F"  # Emoticonlar
                               u"\U0001F300-\U0001F5FF"  # Semboller & Piktogramlar
                               u"\U0001F680-\U0001F6FF"  # UlaÅŸÄ±m & Harita sembolleri
                               u"\U0001F1E0-\U0001F1FF"  # Bayraklar (iOS)
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)
```

Son olarak, tekrarlanan karakterleri (Ã¶rneÄŸin, "waaaayyyyy" yerine "way") kaldÄ±rmamÄ±z gerekiyor:

```python
def remove_multiplechars(text):
    text = re.sub(r'(.)\1{3,}', r'\1', text)
    return text
```

Pratiklik aÃ§Ä±sÄ±ndan, dÃ¶rt fonksiyonu tek bir temizlik fonksiyonunda birleÅŸtiriyoruz:

```python
def clean(df):
    for col in ['text']:  # ,'selected_text']:
        df[col] = df[col].astype(str).apply(lambda x: basic_cleaning(x))
        df[col] = df[col].astype(str).apply(lambda x: remove_emoji(x))
        df[col] = df[col].astype(str).apply(lambda x: remove_html(x))
        df[col] = df[col].astype(str).apply(lambda x: remove_multiplechars(x))
    return df
```

Son hazÄ±rlÄ±k aÅŸamasÄ±, Ã¶nceden eÄŸitilmiÅŸ bir model (tokenizer argÃ¼manÄ±) kullanarak gÃ¶mme vektÃ¶rlerini oluÅŸturacak fonksiyonlarÄ± yazmaktÄ±r:

```python
def fast_encode(texts, tokenizer, chunk_size=256, maxlen=128):
    tokenizer.enable_truncation(max_length=maxlen)
    tokenizer.enable_padding(max_length=maxlen)
    all_ids = []

    for i in range(0, len(texts), chunk_size):
        text_chunk = texts[i:i+chunk_size].tolist()
        encs = tokenizer.encode_batch(text_chunk)
        all_ids.extend([enc.ids for enc in encs])

    return np.array(all_ids)
```

Daha sonra, tÃ¼m veri kÃ¼mesiyle Ã§alÄ±ÅŸabilmemizi saÄŸlayacak bir Ã¶n iÅŸleme fonksiyonu oluÅŸturuyoruz:

```python
def preprocess_news(df, stop=stop, n=1, col='text'):
    '''Veri kÃ¼mesini iÅŸleyip bir metin kÃ¼mesi oluÅŸturmak iÃ§in fonksiyon'''
    new_corpus = []
    stem = PorterStemmer()
    lem = WordNetLemmatizer()
    for text in df[col]:
        words = [w for w in word_tokenize(text) if (w not in stop)]
        words = [lem.lemmatize(w) for w in words if len(w) > n]
        new_corpus.append(words)
    
    new_corpus = [word for l in new_corpus for word in l]
    return new_corpus
```

Ã–nceden hazÄ±rladÄ±ÄŸÄ±mÄ±z fonksiyonlarÄ± kullanarak eÄŸitim verisini temizleyip hazÄ±rlayabiliriz. Duygu sÃ¼tunu hedefimizdir ve bu sÃ¼tunu performans iÃ§in dummy deÄŸiÅŸkenlerine (one-hot encoding) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz:

```python
df.dropna(inplace=True)
df_clean = clean(df)
df_clean_selection = df_clean.sample(frac=1)
X = df_clean_selection.text.values
y = pd.get_dummies(df_clean_selection.sentiment)
```

Gerekli bir sonraki adÄ±m, giriÅŸ metinlerinin tokenizasyonu ve dizilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesidir (bu iÅŸlemin sonunda, veri kÃ¼mesinin tÃ¼m Ã¶rneklerinin eÅŸit uzunlukta olmasÄ± iÃ§in padding yapÄ±yoruz):

```python
tokenizer = text.Tokenizer(num_words=20000)
tokenizer.fit_on_texts(list(X))
list_tokenized_train = tokenizer.texts_to_sequences(X)
X_t = sequence.pad_sequences(list_tokenized_train, maxlen=128)
```

Model iÃ§in gÃ¶mme vektÃ¶rlerini DistilBERT kullanarak oluÅŸturacaÄŸÄ±z ve bu haliyle kullanacaÄŸÄ±z. DistilBERT, BERT'in hafifletilmiÅŸ bir versiyonudur: %3 performans kaybÄ± ile %40 daha az parametre sunar. GÃ¶mme katmanÄ±nÄ± eÄŸiterek performansÄ± artÄ±rabiliriz, ancak bu, eÄŸitim sÃ¼resinin Ã¶nemli Ã¶lÃ§Ã¼de artmasÄ±na yol aÃ§acaktÄ±r.

```python
tokenizer = transformers.AutoTokenizer.from_pretrained("distilbert-base-uncased")  
# YÃ¼klenen tokenizer'Ä± yerel olarak kaydediyoruz
save_path = '/kaggle/working/distilbert_base_uncased/'
if not os.path.exists(save_path):
    os.makedirs(save_path)
tokenizer.save_pretrained(save_path)
# Huggingface tokenizers kÃ¼tÃ¼phanesiyle yeniden yÃ¼kleme
fast_tokenizer = BertWordPieceTokenizer(
                 'distilbert_base_uncased/vocab.txt', lowercase=True)
fast_tokenizer
```

YukarÄ±da tanÄ±mladÄ±ÄŸÄ±mÄ±z *fast_encode* fonksiyonunu ve *fast_tokenizer*'Ä± kullanarak tweet'leri kodlayabiliriz:

```python
X = fast_encode(df_clean_selection.text.astype(str),
                fast_tokenizer,
                maxlen=128)
```

Veri hazÄ±r olduÄŸunda, modelimizi oluÅŸturabiliriz. Bu gÃ¶sterim iÃ§in, bu tÃ¼r uygulamalar iÃ§in oldukÃ§a standart bir mimariyi seÃ§iyoruz: LSTM katmanlarÄ±nÄ±n, global pooling ve dropout ile normalize edilmesi ve Ã¼st katmanda bir yoÄŸun katman. GerÃ§ekten rekabetÃ§i bir Ã§Ã¶zÃ¼m elde etmek iÃ§in mimaride bazÄ± ayarlamalar yapÄ±lmasÄ± gerekebilir: "daha aÄŸÄ±r" bir model, daha bÃ¼yÃ¼k gÃ¶mmeler, LSTM katmanlarÄ±nda daha fazla birim vb.

```python
transformer_layer = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')
embedding_size = 128
input_ = Input(shape=(100,))
inp = Input(shape=(128,))
embedding_matrix = transformer_layer.weights[0].numpy()
x = Embedding(embedding_matrix.shape[0],
              embedding_matrix.shape[1],
              embeddings_initializer=Constant(embedding_matrix),
              trainable=False)(inp)
x = Bidirectional(LSTM(50, return_sequences=True))(x)
x = Bidirectional(LSTM(25, return_sequences=True))(x)
x = GlobalMaxPool1D()(x)
x = Dropout(0.5)(x)
x = Dense(50, activation='relu', kernel_regularizer='L1L2')(x)
x = Dropout(0.5)(x)
x = Dense(3, activation='softmax')(x)
model_DistilBert = Model(inputs=[inp], outputs=x)
model_DistilBert.compile(loss='categorical_crossentropy',
                         optimizer='adam',
                         metrics=['accuracy'])
```

Veriyi eÄŸitim ve doÄŸrulama olarak rastgele ayÄ±rmak iÃ§in, `fit` fonksiyonunu Ã§aÄŸÄ±rÄ±yoruz:

```python
model_DistilBert.fit(X, y, batch_size=32, epochs=10, validation_split=0.1)
```

AÅŸaÄŸÄ±da Ã¶rnek Ã§Ä±ktÄ± yer alÄ±yor:

```
Epoch 1/10
27480/27480 [==============================] - 480s 17ms/step - loss: 0.5100 - accuracy: 0.7994
Epoch 2/10
27480/27480 [==============================] - 479s 17ms/step - loss: 0.4956 - accuracy: 0.8100
Epoch 3/10
27480/27480 [==============================] - 475s 17ms/step - loss: 0.4740 - accuracy: 0.8158
```

Modelin tahmin Ã¼retmesi oldukÃ§a basittir. Verilen tÃ¼m veriyi kullanabilmek iÃ§in, modelimizi tÃ¼m verilerle yeniden eÄŸitiyoruz (doÄŸrulama yok):

```python
df_clean_final = df_clean.sample(frac=1)
X_train = fast_encode(df_clean_selection.text.astype(str),
                      fast_tokenizer,
                      maxlen=128)
y_train = y
```

Modeli yeniden tÃ¼m veri seti Ã¼zerinde eÄŸitiyoruz ve


tahminleri Ã¼retiyoruz:

```python
y_preds = model_DistilBert.predict(X_test)
y_predictions = pd.DataFrame(y_preds,
                             columns=['negative', 'neutral', 'positive'])
y_predictions_final = y_predictions.idxmax(axis=1)
accuracy = accuracy_score(y_test, y_predictions_final)
print(f"The final model shows {accuracy:.2f} accuracy on the test set.")
```

SonuÃ§ olarak, modelin test seti Ã¼zerindeki doÄŸruluÄŸu %74'tÃ¼r.AÅŸaÄŸÄ±da Ã§Ä±ktÄ±nÄ±n nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ne dair bir Ã¶rnek gÃ¶sterilmektedir; bu birkaÃ§ satÄ±rdan zaten gÃ¶rebileceÄŸiniz gibi, bazen duygu bir insan okuyucusu iÃ§in aÃ§Ä±k olmasÄ±na raÄŸmen, model bunu doÄŸru bir ÅŸekilde yakalayamamaktadÄ±r:

![](im/1082.png)

Åimdi, duygu atama problemlerini Ã§Ã¶zmek iÃ§in Ã¶rnek bir iÅŸ akÄ±ÅŸÄ± sunduk (metnin hangi bÃ¶lÃ¼mlerinin duygu sÄ±nÄ±flandÄ±rma kararlarÄ±na yol aÃ§tÄ±ÄŸÄ±nÄ± belirleme). RekabetÃ§i performans elde etmek istiyorsanÄ±z, aÅŸaÄŸÄ±da sÄ±ralanan bazÄ± iyileÅŸtirmeler yapÄ±labilir, etkileri muhtemel sÄ±rayla:

* **Daha bÃ¼yÃ¼k gÃ¶mme vektÃ¶rleri**: Bu, zaten (iÅŸlenmiÅŸ) giriÅŸ verisi seviyesinde daha fazla bilgi yakalamamÄ±za olanak tanÄ±r.
* **Daha bÃ¼yÃ¼k model**: LSTM katmanlarÄ±nda daha fazla birim kullanmak.
* **Daha uzun eÄŸitim**: DiÄŸer bir deyiÅŸle, daha fazla epoch.

YukarÄ±da listelenen iyileÅŸtirmeler kesinlikle modelin performansÄ±nÄ± artÄ±racaktÄ±r, ancak iÅŸ akÄ±ÅŸÄ±mÄ±zÄ±n temel Ã¶ÄŸeleri yeniden kullanÄ±labilir:

* **Veri temizleme ve Ã¶n iÅŸleme**
* **Metin gÃ¶mme vektÃ¶rleri oluÅŸturma**
* **Hedef model mimarisinde tekrar eden katmanlar ve dÃ¼zenlileÅŸtirme uygulamak**

Åimdi, NLP yarÄ±ÅŸmalarÄ±nda sÄ±kÃ§a karÅŸÄ±laÅŸÄ±lan bir problem olan aÃ§Ä±k alanlÄ± soru-cevap (open domain question answering) konusuna geÃ§elim.

> **Abhishek Thakur**
> 
> [https://www.kaggle.com/abhishek](https://www.kaggle.com/abhishek)
> 
> 
> 
> Abhishek Thakur ile gÃ¶rÃ¼ÅŸtÃ¼k; kendisi, dÃ¼nyanÄ±n ilk dÃ¶rt katmanlÄ± Kaggle Grandmaster'Ä±. Åu anda Hugging Face'te Ã§alÄ±ÅŸÄ±yor ve burada AutoNLP'yi geliÅŸtiriyor; aynÄ± zamanda Ä°ngilizce dilinde yazÄ±lmÄ±ÅŸ Kaggle hakkÄ±nda neredeyse tek kitap olan *Approaching (Almost) Any Machine Learning Problem* kitabÄ±nÄ±n da yazarÄ±.
> 
> 
> 
> **Kaggle'daki uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> HiÃ§bir ÅŸey. Her yarÄ±ÅŸma farklÄ±dÄ±r ve her birinden Ã§ok ÅŸey Ã¶ÄŸrenebilirsiniz. Bir uzmanlÄ±k alanÄ±m olsaydÄ±, o alandaki tÃ¼m yarÄ±ÅŸmalarÄ± kazanÄ±rdÄ±m.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rÄ±sÄ±nÄ±z? Bu yaklaÅŸÄ±m, gÃ¼nlÃ¼k iÅŸlerinizden ne kadar farklÄ±?**
> 
> Yapmam gereken ilk ÅŸey, veriyi gÃ¶zden geÃ§irmek ve biraz anlamaya Ã§alÄ±ÅŸmaktÄ±r. YarÄ±ÅŸmaya geÃ§ kaldÄ±ysam, genel EDA (Exploratory Data Analysis) kernel'larÄ±ndan yardÄ±m alÄ±rÄ±m.
> 
> Bir probleme (Kaggle'da veya dÄ±ÅŸÄ±nda) yaklaÅŸÄ±rken ilk yaptÄ±ÄŸÄ±m ÅŸey bir benchmark (karÅŸÄ±laÅŸtÄ±rma Ã¶lÃ§Ã¼tÃ¼) oluÅŸturmaktÄ±r. Bir benchmark oluÅŸturmak Ã§ok Ã¶nemlidir Ã§Ã¼nkÃ¼ size gelecekteki modellerinizi karÅŸÄ±laÅŸtÄ±rabileceÄŸiniz bir temel sunar. EÄŸer yarÄ±ÅŸmaya geÃ§ kaldÄ±ysam, benchmark'Ä± oluÅŸtururken genellikle public (halka aÃ§Ä±k) Notebooks'lardan yardÄ±m almamaya Ã§alÄ±ÅŸÄ±rÄ±m. Bunu yaparsak, yalnÄ±zca tek bir yÃ¶nde dÃ¼ÅŸÃ¼nmeye baÅŸlarÄ±z. En azÄ±ndan ben bÃ¶yle hissediyorum.
> 
> Benchmark'Ä± tamamladÄ±ktan sonra, karmaÅŸÄ±k ÅŸeyler yapmadan (Ã¶rneÄŸin stacking veya blending) mÃ¼mkÃ¼n olduÄŸunca fazla performans sÄ±kÄ±ÅŸtÄ±rmaya Ã§alÄ±ÅŸÄ±rÄ±m. Sonra veriyi ve modelleri tekrar gÃ¶zden geÃ§irir, baselini (temel) adÄ±m adÄ±m iyileÅŸtirmeye Ã§alÄ±ÅŸÄ±rÄ±m.
> 
> GÃ¼nlÃ¼k iÅŸlerde bazen Ã§ok benzerlikler oluyor. Ã‡oÄŸu zaman bir benchmark vardÄ±r ve ardÄ±ndan o benchmark'Ä± aÅŸacak teknikler, Ã¶zellikler ve modeller geliÅŸtirmek gerekir.
> 
> 
> 
> **GirdiÄŸiniz en ilginÃ§ yarÄ±ÅŸma hangisiydi? Ã–zel bir iÃ§gÃ¶rÃ¼nÃ¼z oldu mu?**
> 
> Her yarÄ±ÅŸma ilginÃ§tir.
> 
> 
> 
> **Kaggle kariyerinize yardÄ±mcÄ± oldu mu?**
> 
> Tabii ki, yardÄ±mcÄ± oldu. Son birkaÃ§ yÄ±ldÄ±r Kaggle, veri bilimcisi ve makine Ã¶ÄŸrenmesi mÃ¼hendisleri iÅŸe alÄ±rken oldukÃ§a iyi bir Ã¼ne sahip oldu. Kaggle sÄ±ralamasÄ± ve bir dizi veri seti ile deneyim, endÃ¼stride bir ÅŸekilde kesinlikle yardÄ±mcÄ± oluyor. FarklÄ± tÃ¼rdeki problemleri Ã§Ã¶zme konusunda ne kadar deneyiminiz varsa, iterasyonu o kadar hÄ±zlÄ± yapabilirsiniz. Bu da endÃ¼strilerde Ã§ok faydalÄ±dÄ±r. Kimse iÅŸ iÃ§in deÄŸer yaratmayan bir ÅŸeyi aylarca yapmak istemez.
> 
> 
> 
> **Deneyiminize gÃ¶re, deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±yor? Åu an bildiÄŸiniz, ama ilk baÅŸladÄ±ÄŸÄ±nÄ±zda bilmek istediÄŸiniz ÅŸey neydi?**
> 
> Ã‡oÄŸu yeni baÅŸlayan Ã§ok kolay pes eder. Bir Kaggle yarÄ±ÅŸmasÄ±na katÄ±lmak ve Ã¼st sÄ±ralarda yer alanlarÄ± gÃ¶rÃ¼nce korkmak Ã§ok kolaydÄ±r. EÄŸer yeni baÅŸlayanlar Kaggle'da baÅŸarÄ±lÄ± olmak istiyorsa, azim sahibi olmalarÄ± gerekir. Bana gÃ¶re azim, anahtardÄ±r. BirÃ§ok yeni baÅŸlayan da kendi baÅŸlarÄ±na baÅŸlamayÄ± baÅŸaramaz ve public kernel'lara sÄ±kÄ±ca tutunurlar. Bu, onlarÄ± yalnÄ±zca public kernel yazarlarÄ±nÄ±n dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼ ÅŸekilde dÃ¼ÅŸÃ¼nmeye iter. Tavsiyem, kendi baÅŸÄ±nÄ±za bir yarÄ±ÅŸmaya baÅŸlamak, verileri incelemek, Ã¶zellikler geliÅŸtirmek, modeller oluÅŸturmak ve sonra kernel'lara ve tartÄ±ÅŸmalara gÃ¶z atÄ±p baÅŸkalarÄ±nÄ±n neyi farklÄ± yaptÄ±ÄŸÄ±nÄ± gÃ¶rmek olacaktÄ±r. Sonra Ã¶ÄŸrendiklerinizi kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼ze dahil edin.

### Open domain Q&A *(AÃ§Ä±k alan soru-cevap)*

Bu bÃ¶lÃ¼mde, Google QUEST Soru-Cevap Etiketleme yarÄ±ÅŸmasÄ±na bakacaÄŸÄ±z ([Google QUEST Challenge](https://www.kaggle.com/c/google-quest-challenge/overview/description)). Bu yarÄ±ÅŸmada, soru-cevap Ã§iftleri, â€œsoru konuÅŸma dili mi?â€, â€œsoru bilgi arayÄ±ÅŸÄ± mÄ±?â€ veya â€œcevap yardÄ±mcÄ± mÄ±?â€ gibi Ã§eÅŸitli kriterlere gÃ¶re insan deÄŸerlendirciler tarafÄ±ndan puanlandÄ±. GÃ¶rev, her bir hedef sÃ¼tun iÃ§in sayÄ±sal bir deÄŸer tahmin etmekti (bu sÃ¼tunlar kriterlere karÅŸÄ±lÄ±k geliyordu); etiketler birden fazla deÄŸerlendiricinin oylarÄ±yla birleÅŸtirildiÄŸi iÃ§in, amaÃ§ temelde Ã§ok deÄŸiÅŸkenli bir regresyon Ã§Ä±ktÄ±sÄ±ydÄ± ve hedef sÃ¼tunlar birim aralÄ±ÄŸÄ±na normalize edilmiÅŸti.

GÃ¼nlÃ¼k iÅŸlerde bazen Ã§ok fazla benzerlik bulunur. Ã‡oÄŸu zaman bir benchmark (karÅŸÄ±laÅŸtÄ±rma Ã¶lÃ§Ã¼tÃ¼) vardÄ±r ve ardÄ±ndan o benchmark'Ä± aÅŸacak teknikler, Ã¶zellikler ve modeller geliÅŸtirmek gerekir.

Ä°leri dÃ¼zey tekniklerle modelleme yapmadan Ã¶nce (Ã¶rneÄŸin, NLP iÃ§in transformer tabanlÄ± modeller kullanmak gibi), genellikle daha basit yÃ¶ntemlerle bir temel oluÅŸturmak iyi bir fikirdir. Ã–nceki bÃ¶lÃ¼mde olduÄŸu gibi, kÄ±salÄ±k aÃ§Ä±sÄ±ndan importâ€™larÄ± atlÄ±yoruz, ancak bunlarÄ± GitHub deposundaki Notebook'ta bulabilirsiniz.

BaÅŸlangÄ±Ã§ olarak, metnin farklÄ± yÃ¶nlerini Ã§Ä±karmamÄ±za yardÄ±mcÄ± olabilecek birkaÃ§ yardÄ±mcÄ± fonksiyon tanÄ±mlayacaÄŸÄ±z. Ä°lk olarak, bir dizi metinden kelime sayÄ±sÄ±nÄ± dÃ¶ndÃ¼ren bir fonksiyon tanÄ±mlÄ±yoruz:

```python
def word_count(xstring):
    return xstring.split().str.len()
```

YarÄ±ÅŸmada kullanÄ±lan metrik, Spearman korelasyonuydu (sÄ±ralamalar Ã¼zerinden hesaplanan lineer korelasyon: [Spearman Rank Correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient)).
Biz Scikit-learn pipelineâ€™Ä± oluÅŸturmayÄ± amaÃ§ladÄ±ÄŸÄ±mÄ±z iÃ§in, metrikleri bir scorer olarak tanÄ±mlamak faydalÄ± olacaktÄ±r (make_scorer metodu, Scikit-learn'de bir puanlama fonksiyonu alÄ±p, estimator Ã§Ä±ktÄ±sÄ±nÄ± puanlayan bir callable dÃ¶ndÃ¼rÃ¼r).

```python
def spearman_corr(y_true, y_pred):
    if np.ndim(y_pred) == 2:
        corr = np.mean([stats.spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])])
    else:
        corr = stats.spearmanr(y_true, y_pred)[0]
    return corr

custom_scorer = make_scorer(spearman_corr, greater_is_better=True)
```

Sonraki adÄ±mda, metinlerimizin parÃ§alar halinde iÅŸlenmesini saÄŸlayacak kÃ¼Ã§Ã¼k bir yardÄ±mcÄ± fonksiyon tanÄ±mlÄ±yoruz. Bu fonksiyon, hafÄ±za sorunlarÄ± yaÅŸamadan gÃ¶vdeyi parÃ§alara ayÄ±rarak gÃ¶mme (embedding) oluÅŸturmanÄ±za yardÄ±mcÄ± olacaktÄ±r:

```python
def chunks(l, n):
    for i in range(0, len(l), n):
        yield l[i:i + n]
```

KullanacaÄŸÄ±mÄ±z Ã¶zellik setinin bir kÄ±smÄ±, Ã¶nceden eÄŸitilmiÅŸ modellerden alÄ±nan gÃ¶mmelerden oluÅŸacaktÄ±r. Bu bÃ¶lÃ¼mde amacÄ±mÄ±z, karmaÅŸÄ±k modeller eÄŸitmeden bir temel oluÅŸturmak olduÄŸundan, mevcut modelleri kullanmamÄ±zda bir sakÄ±nca yoktur.

Modeli eÄŸitmeden Ã¶nce, Ã¶nce tokenizer ve modeli iÃ§eri aktaracaÄŸÄ±z ve sonra metni parÃ§alar halinde iÅŸleyerek her bir soru/cevap Ã§iftini sabit boyutlu bir gÃ¶mmeye (embedding) dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz:

```python
def fetch_vectors(string_list, batch_size=64):
    DEVICE = torch.device("cuda")
    tokenizer = transformers.DistilBertTokenizer.from_pretrained("../input/distilbertbaseuncased/")
    model = transformers.DistilBertModel.from_pretrained("../input/distilbertbaseuncased/")
    model.to(DEVICE)
    fin_features = []

    for data in chunks(string_list, batch_size):
        tokenized = []
        for x in data:
            x = " ".join(x.strip().split()[:300])
            tok = tokenizer.encode(x, add_special_tokens=True)
            tokenized.append(tok[:512])

        max_len = 512
        padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized])
        attention_mask = np.where(padded != 0, 1, 0)
        input_ids = torch.tensor(padded).to(DEVICE)
        attention_mask = torch.tensor(attention_mask).to(DEVICE)

        with torch.no_grad():
            last_hidden_states = model(input_ids, attention_mask=attention_mask)
        features = last_hidden_states[0][:, 0, :].cpu().numpy()
        fin_features.append(features)

    fin_features = np.vstack(fin_features)
    return fin_features
```

Åimdi, verileri yÃ¼klemeye geÃ§ebiliriz:

```python
xtrain = pd.read_csv(data_dir + 'train.csv')
xtest = pd.read_csv(data_dir + 'test.csv')
xtrain.head(4)
```

Ä°lk birkaÃ§ satÄ±r ÅŸÃ¶yle gÃ¶rÃ¼necektir:

![](im/1083.png)

**30 hedef sÃ¼tunumuzu belirliyoruz:**

```python
target_cols = ['question_asker_intent_understanding',
               'question_body_critical', 
               'question_conversational', 'question_expect_short_answer', 
               'question_fact_seeking',
               'question_has_commonly_accepted_answer', 
               'question_interestingness_others',
               'question_interestingness_self', 
               'question_multi_intent', 'question_not_really_a_question', 
               'question_opinion_seeking', 'question_type_choice', 
               'question_type_compare', 'question_type_consequence', 
               'question_type_definition', 'question_type_entity', 
               'question_type_instructions', 'question_type_procedure', 
               'question_type_reason_explanation',
               'question_type_spelling', 
               'question_well_written', 'answer_helpful', 
               'answer_level_of_information', 'answer_plausible', 
               'answer_relevance', 'answer_satisfaction', 
               'answer_type_instructions', 'answer_type_procedure', 
               'answer_type_reason_explanation', 'answer_well_written']
```

AnlamlarÄ± ve yorumlarÄ±yla ilgili tartÄ±ÅŸmalar iÃ§in okuyucu, yarÄ±ÅŸmanÄ±n **Veri SayfasÄ±**'na baÅŸvurabilir, [buradan ulaÅŸÄ±labilir](https://www.kaggle.com/c/google-quest-challenge/data).

**Sonraki adÄ±mda Ã¶zellik mÃ¼hendisliÄŸine geÃ§iyoruz.** BaÅŸlangÄ±Ã§ olarak, soru baÅŸlÄ±ÄŸÄ± ve gÃ¶vdesi ile cevabÄ±n kelime sayÄ±sÄ±nÄ± hesaplÄ±yoruz. Bu, birÃ§ok uygulamada oldukÃ§a basit ama ÅŸaÅŸÄ±rtÄ±cÄ± derecede faydalÄ± bir Ã¶zelliktir:

```python
for colname in ['question_title', 'question_body', 'answer']:
    newname = colname + '_word_len'
    
    xtrain[newname] = xtrain[colname].str.split().str.len()
    xtest[newname] = xtest[colname].str.split().str.len()
```

OluÅŸturduÄŸumuz bir sonraki Ã¶zellik, metnin iÃ§indeki benzersiz kelimelerin oranÄ±nÄ± hesaplayarak leksikal Ã§eÅŸitliliktir:

```python
colname = 'answer'
xtrain[colname+'_div'] = xtrain[colname].apply
                         (lambda s: len(set(s.split())) / len(s.split()) )
xtest[colname+'_div'] = xtest[colname].apply
                        (lambda s: len(set(s.split())) / len(s.split()) )
```

Ã‡evrimiÃ§i kaynaklardan elde edilen bilgilerle Ã§alÄ±ÅŸÄ±rken, bir web adresinin bileÅŸenlerini inceleyerek potansiyel olarak bilgilendirici Ã¶zellikler Ã§Ä±karabiliriz (bileÅŸenleri, adresin nokta ile ayrÄ±lmÄ±ÅŸ elemanlarÄ± olarak tanÄ±mlÄ±yoruz); bileÅŸen sayÄ±sÄ±nÄ± sayarÄ±z ve her birini ayrÄ± Ã¶zellik olarak saklarÄ±z:

```python
for df in [xtrain, xtest]:
    df['domcom'] = df['question_user_page'].apply
                   (lambda s: s.split('://')[1].split('/')[0].split('.'))
    # BileÅŸen sayÄ±sÄ±nÄ± say
    df['dom_cnt'] = df['domcom'].apply(lambda s: len(s))
    # EÄŸer bazÄ± alan adlarÄ±nÄ±n adÄ± daha kÄ±sa ise, uzunluÄŸu doldur
    df['domcom'] = df['domcom'].apply(lambda s: s + ['none', 'none'])
    # BileÅŸenler
    for ii in range(0,4):
        df['dom_'+str(ii)] = df['domcom'].apply(lambda s: s[ii])
```

BirÃ§ok hedef sÃ¼tun, cevabÄ±n belirli bir soru iÃ§in ne kadar alakalÄ± olduÄŸuyla ilgilidir. Bu iliÅŸkiyi nicelleÅŸtirmenin bir yolu, iki dize arasÄ±ndaki ortak kelimeleri deÄŸerlendirmektir:

```python
# Ortak Ã¶ÄŸeler
for df in [xtrain, xtest]:
    df['q_words'] = df['question_body'].apply(lambda s: [f for f in s.split() if f not in eng_stopwords])
    df['a_words'] = df['answer'].apply(lambda s: [f for f in s.split() if f not in eng_stopwords])
    df['qa_word_overlap'] = df.apply(lambda s: len(np.intersect1d(s['q_words'], s['a_words'])), axis=1)
    df['qa_word_overlap_norm1'] = df.apply(lambda s: s['qa_word_overlap'] / (1 + len(s['a_words'])), axis=1)
    df['qa_word_overlap_norm2'] = df.apply(lambda s: s['qa_word_overlap'] / (1 + len(s['q_words'])), axis=1)
    df.drop(['q_words', 'a_words'], axis=1, inplace=True)
```

Stopwords (durdurma kelimeleri) ve noktalama iÅŸaretlerinin sÄ±klÄ±klarÄ±nÄ± inceleyerek metnin stilini ve niyetini anlayabiliriz:

```python
for df in [xtrain, xtest]:
    
    ## Metindeki karakter sayÄ±sÄ± ##
    df["question_title_num_chars"] = df["question_title"].apply(lambda x: len(str(x)))
    df["question_body_num_chars"] = df["question_body"].apply(lambda x: len(str(x)))
    df["answer_num_chars"] = df["answer"].apply(lambda x: len(str(x)))
    
    ## Metindeki stopword sayÄ±sÄ± ##
    df["question_title_num_stopwords"] = df["question_title"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))
    df["question_body_num_stopwords"] = df["question_body"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))
    df["answer_num_stopwords"] = df["answer"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))
    
    ## Metindeki noktalama sayÄ±sÄ± ##
    df["question_title_num_punctuations"] = df['question_title'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))
    df["question_body_num_punctuations"] = df['question_body'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))
    df["answer_num_punctuations"] = df['answer'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))
    
    ## BaÅŸlÄ±kta bÃ¼yÃ¼k harfli kelimelerin sayÄ±sÄ± ##
    df["question_title_num_words_upper"] = df["question_title"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))
    df["question_body_num_words_upper"] = df["question_body"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))
    df["answer_num_words_upper"] = df["answer"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))
```

**"Vintage" (Eski Tarz) Ã¶zellikler hazÄ±rlandÄ±ktan sonra** â€“ burada metnin semantik yapÄ±sÄ±na dikkat edilmeden sadece basit Ã¶zet istatistiklere odaklanÄ±yoruz â€“ sorular ve cevaplar iÃ§in gÃ¶mme (embedding) oluÅŸturma iÅŸlemine geÃ§ebiliriz. Teorik olarak, verimizde ayrÄ± bir **word2vec** tÃ¼rÃ¼ model eÄŸitebiliriz (ya da mevcut bir modeli ince ayar yapabiliriz), ancak bu sunumda, eÄŸitilmiÅŸ bir modeli olduÄŸu gibi kullanacaÄŸÄ±z. FaydalÄ± bir seÃ§im, Googleâ€™Ä±n **Universal Sentence Encoder** (Evrensel CÃ¼mle KodlayÄ±cÄ±) modelidir ([https://tfhub.dev/google/universal-sentence-encoder/4](https://tfhub.dev/google/universal-sentence-encoder/4)). Bu model, Ã§eÅŸitli veri kaynaklarÄ± Ã¼zerinde eÄŸitilmiÅŸtir ve Ä°ngilizce bir metni alÄ±p, 512 boyutlu bir vektÃ¶r Ã§Ä±ktÄ±sÄ± verir.

```python
module_url = "../input/universalsentenceencoderlarge4/"
embed = hub.load(module_url)
```

Metin alanlarÄ±nÄ± gÃ¶mmelere dÃ¶nÃ¼ÅŸtÃ¼rme kodu aÅŸaÄŸÄ±da sunulmuÅŸtur: EÄŸitim/test kÃ¼melerindeki giriÅŸlere, bellek verimliliÄŸi aÃ§Ä±sÄ±ndan her birini (batch olarak) dÃ¶ngÃ¼yle iÅŸleyerek gÃ¶mme oluÅŸtururuz ve sonra bunlarÄ± orijinal listeye ekleriz.

**Son veri Ã§erÃ§eveleri**, her bir batch seviyesindeki gÃ¶mmeleri dikey olarak birleÅŸtirerek oluÅŸturulur:

```python
embeddings_train = {}
embeddings_test = {}
for text in ['question_title', 'question_body', 'answer']:
    train_text = xtrain[text].str.replace('?', '.').str.replace('!', '.').tolist()
    test_text = xtest[text].str.replace('?', '.').str.replace('!', '.').tolist()
    curr_train_emb = []
    curr_test_emb = []
    batch_size = 4
    ind = 0
    while ind*batch_size < len(train_text):
        curr_train_emb.append(embed(train_text[ind*batch_size: (ind + 1)*batch_size])["outputs"].numpy())
        ind += 1
    ind = 0
    while ind*batch_size < len(test_text):
        curr_test_emb.append(embed(test_text[ind*batch_size: (ind + 1)*batch_size])["outputs"].numpy())
        ind += 1    
    embeddings_train[text + '_embedding'] = np.vstack(curr_train_emb)
    embeddings_test[text + '_embedding'] = np.vstack(curr_test_emb)
    print(text)
```

**Hem sorularÄ±n hem de cevaplarÄ±n vektÃ¶rel temsilleri** verildiÄŸinde, alanlar arasÄ±ndaki semantik benzerliÄŸi hesaplamak iÃ§in vektÃ¶r Ã§iftleri Ã¼zerinde farklÄ± mesafe metrikleri kullanÄ±labilir. FarklÄ± metrikleri denemenin amacÄ±, Ã§eÅŸitli tÃ¼rdeki Ã¶zellikleri yakalamaktÄ±r; sÄ±nÄ±flandÄ±rma baÄŸlamÄ±nda bir analoji yapacak olursak, durumu tam olarak gÃ¶rmek iÃ§in hem doÄŸruluk hem de entropiyi kullanmak gibi bir ÅŸeydir:

```python
l2_dist = lambda x, y: np.power(x - y, 2).sum(axis=1)
cos_dist = lambda x, y: (x * y).sum(axis=1)
```

Mesafe Ã¶zelliklerini hesaplayÄ±p, bunlarÄ± ayrÄ± sÃ¼tunlarda toplarÄ±z:

```python
dist_features_train = np.array([
    l2_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),
    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),
    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),
    cos_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),
    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),
    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding'])
]).T

dist_features_test = np.array([
    l2_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),
    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),
    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),
    cos_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),
    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),
    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding'])
]).T
```

Mesafe Ã¶zelliklerini ayrÄ± sÃ¼tunlarda toplarÄ±z:

```python
for ii in range(0, 6):
    xtrain['dist' + str(ii)] = dist_features_train[:, ii]
    xtest['dist' + str(ii)] = dist_features_test[:, ii]
```

Son olarak, metin alanlarÄ±nÄ±n **TF-IDF temsillerini** de oluÅŸturabiliriz; genel fikir, giriÅŸ metninin Ã§eÅŸitli dÃ¶nÃ¼ÅŸÃ¼mleri Ã¼zerinden birden fazla Ã¶zellik yaratmak ve bunlarÄ± nispeten basit bir modele beslemektir.

Bu ÅŸekilde, karmaÅŸÄ±k bir derin Ã¶ÄŸrenme modeli eÄŸitmeye gerek kalmadan verinin Ã¶zelliklerini yakalayabiliriz.

Metni, hem kelime dÃ¼zeyinde hem de karakter dÃ¼zeyinde analiz ederek bunu baÅŸarabiliriz. Bellek tÃ¼ketimini sÄ±nÄ±rlamak iÃ§in her iki tÃ¼r Ã¶zelliÄŸin maksimum sayÄ±sÄ±na Ã¼st sÄ±nÄ±r koyuyoruz (kendi belleÄŸinizle orantÄ±lÄ± olarak bu limitler artÄ±rÄ±labilir):

```python
limit_char = 5000
limit_word = 25000
```

**Karakter ve kelime dÃ¼zeyinde vektÃ¶rleÅŸtiricileri** baÅŸlatÄ±yoruz. Problemimizin yapÄ±sÄ±, Scikit-learn'den **Pipeline** fonksiyonunun kullanÄ±mÄ±na uygun olup, modelin eÄŸitim prosedÃ¼rÃ¼nde birden fazla adÄ±mÄ±n birleÅŸimini saÄŸlar. BaÅŸlangÄ±Ã§ olarak baÅŸlÄ±k sÃ¼tunu iÃ§in iki ayrÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ oluÅŸturuyoruz (kelime ve karakter dÃ¼zeyinde):

```python
title_col = 'question_title'
title_transformer = Pipeline([
    ('tfidf', TfidfVectorizer(lowercase=False, max_df=0.3, min_df=1,
                               binary=False, use_idf=True, smooth_idf=False,
                               ngram_range=(1, 2), stop_words='english',
                               token_pattern='(?u)\\b\\w+\\b', max_features=limit_word))
])

title_transformer2 = Pipeline([
    ('tfidf2', TfidfVectorizer(sublinear_tf=True,
                               strip_accents='unicode', analyzer='char',
                               stop_words='english', ngram_range=(1, 4),
                               max_features=limit_char))
])
```

**AynÄ± mantÄ±ÄŸÄ± (iki farklÄ± pipeline dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼sÃ¼) soru metni iÃ§in de kullanÄ±yoruz:**

```python
body_col = 'question_body'
body_transformer = Pipeline([
    ('tfidf', TfidfVectorizer(lowercase=False, max_df=0.3, min_df=1,
                              binary=False, use_idf=True, smooth_idf=False,
                              ngram_range=(1, 2), stop_words='english',
                              token_pattern='(?u)\\b\\w+\\b', max_features=limit_word))
])
body_transformer2 = Pipeline([
    ('tfidf2', TfidfVectorizer(sublinear_tf=True,
                               strip_accents='unicode', analyzer='char',
                               stop_words='english', ngram_range=(1, 4), max_features=limit_char))
])
```

**Ve son olarak cevap sÃ¼tunu iÃ§in:**

```python
answer_col = 'answer'
answer_transformer = Pipeline([
    ('tfidf', TfidfVectorizer(lowercase=False, max_df=0.3, min_df=1,
                              binary=False, use_idf=True, smooth_idf=False,
                              ngram_range=(1, 2), stop_words='english',
                              token_pattern='(?u)\\b\\w+\\b', max_features=limit_word))
])
answer_transformer2 = Pipeline([
    ('tfidf2', TfidfVectorizer(sublinear_tf=True,
                               strip_accents='unicode', analyzer='char',
                               stop_words='english', ngram_range=(1, 4), max_features=limit_char))
])
```

**Ã–zellik mÃ¼hendisliÄŸi kÄ±smÄ±nÄ±, sayÄ±sal Ã¶zellikleri iÅŸleyerek tamamlÄ±yoruz. YalnÄ±zca basit yÃ¶ntemler kullanÄ±yoruz:** Eksik deÄŸerlerin doldurulmasÄ± iÃ§in eksik deÄŸer impute (tamamlama) iÅŸlemi ve daÄŸÄ±lÄ±mÄ± stabilize etmek ve daha Gauss daÄŸÄ±lÄ±mÄ±na yakÄ±n hale getirmek iÃ§in **power transformer** (gÃ¼Ã§ dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼) kullanÄ±yoruz (bu, sayÄ±sal bir Ã¶zelliÄŸi sinir aÄŸlarÄ±nda kullanÄ±rken genellikle yardÄ±mcÄ± olur):

```python
num_cols = [
    'question_title_word_len', 'question_body_word_len',
    'answer_word_len', 'answer_div',
    'question_title_num_chars', 'question_body_num_chars',
    'answer_num_chars',
    'question_title_num_stopwords', 'question_body_num_stopwords',
    'answer_num_stopwords',
    'question_title_num_punctuations',
    'question_body_num_punctuations', 'answer_num_punctuations',
    'question_title_num_words_upper',
    'question_body_num_words_upper', 'answer_num_words_upper',
    'dist0', 'dist1', 'dist2', 'dist3', 'dist4', 'dist5'
]
num_transformer = Pipeline([
    ('impute', SimpleImputer(strategy='constant', fill_value=0)),
    ('scale', PowerTransformer(method='yeo-johnson'))
])
```

**Pipelines'in faydalÄ± bir Ã¶zelliÄŸi, bunlarÄ±n birleÅŸtirilebilmesi ve iÃ§ iÃ§e kullanÄ±labilmesidir.** Sonraki adÄ±mda, kategorik deÄŸiÅŸkenleri iÅŸleme iÅŸlevselliÄŸi ekliyoruz ve ardÄ±ndan tÃ¼mÃ¼nÃ¼ birleÅŸtirerek **ColumnTransformer** nesnesine yerleÅŸtiriyoruz. Bu, veri Ã¶n iÅŸleme ve Ã¶zellik mÃ¼hendisliÄŸi mantÄ±ÄŸÄ±nÄ± daha verimli hale getirir. GiriÅŸin her parÃ§asÄ± uygun ÅŸekilde kendi yÃ¶ntemiyle iÅŸlenebilir:

```python
cat_cols = ['dom_0', 'dom_1', 'dom_2', 
            'dom_3', 'category', 'is_question_no_name_user',
            'is_answer_no_name_user', 'dom_cnt']
cat_transformer = Pipeline([
    ('impute', SimpleImputer(strategy='constant', fill_value='')),
    ('encode', OneHotEncoder(handle_unknown='ignore'))
])
preprocessor = ColumnTransformer(
    transformers=[
        ('title', title_transformer, title_col),
        ('title2', title_transformer2, title_col),
        ('body', body_transformer, body_col),
        ('body2', body_transformer2, body_col),
        ('answer', answer_transformer, answer_col),
        ('answer2', answer_transformer2, answer_col),
        ('num', num_transformer, num_cols),
        ('cat', cat_transformer, cat_cols)
    ]
)
```

**Son olarak, veri Ã¶n iÅŸleme ve model eÄŸitimi adÄ±mlarÄ±nÄ± birleÅŸtiren bir Pipeline nesnesi kullanmaya hazÄ±rÄ±z:**

```python
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('estimator', Ridge(random_state=RANDOM_STATE))
])
```

**Modelinizin performansÄ±nÄ± Ã¶rnek dÄ±ÅŸÄ± olarak deÄŸerlendirmek her zaman iyi bir fikirdir:** Bunu yapmanÄ±n pratik bir yolu, BÃ¶lÃ¼m 6'da tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z "out-of-fold" (OOF) tahminlerini oluÅŸturmaktÄ±r. Bu prosedÃ¼r ÅŸu adÄ±mlarÄ± iÃ§erir:

1. Veriyi katmanlara ayÄ±rÄ±n. Bizim durumumuzda, GroupKFold kullanÄ±yoruz, Ã§Ã¼nkÃ¼ bir sorunun birden fazla cevabÄ± olabilir (veri Ã§erÃ§evesinde ayrÄ± satÄ±rlarda). Bilgi sÄ±zmasÄ±nÄ± engellemek iÃ§in her sorunun yalnÄ±zca bir katmanda yer almasÄ±nÄ± saÄŸlamak istiyoruz.
2. Her katman iÃ§in, diÄŸer katmanlardaki verilerle modeli eÄŸitin ve seÃ§ilen katman iÃ§in tahminler oluÅŸturun, ayrÄ±ca test seti iÃ§in de tahminler yapÄ±n.
3. Test setindeki tahminlerin ortalamasÄ±nÄ± alÄ±n.

Ä°lk olarak, tahminleri saklayacaÄŸÄ±mÄ±z "depolama" matrislerini hazÄ±rlayalÄ±m. **mvalid** out-of-fold tahminlerini iÃ§erecek, **mfull** ise tÃ¼m test seti Ã¼zerindeki tahminlerin, katmanlar arasÄ±nda ortalanmÄ±ÅŸ halini saklayacaktÄ±r. BirkaÃ§ soru birden fazla aday cevaba sahip olduÄŸundan, KFold bÃ¶lmesini **question_body** Ã¼zerinde stratifike ederiz:

```python
nfolds = 5
mvalid = np.zeros((xtrain.shape[0], len(target_cols)))
mfull = np.zeros((xtest.shape[0], len(target_cols)))
kf = GroupKFold(n_splits=nfolds).split(X=xtrain.question_body, 
                                       groups=xtrain.question_body)
```

Katmanlar arasÄ±nda dÃ¶ngÃ¼ye gireriz ve ayrÄ± modelleri inÅŸa ederiz:

```python
for ind, (train_index, test_index) in enumerate(kf):
    
    # Veriyi eÄŸitim ve doÄŸrulama olarak ayÄ±r
    x0, x1 = xtrain.loc[train_index], xtrain.loc[test_index]
    y0, y1 = ytrain.loc[train_index], ytrain.loc[test_index]
    
    for ii in range(0, ytrain.shape[1]):
        # Modeli eÄŸit
        be = clone(pipeline)
        be.fit(x0, np.array(y0)[:, ii])
        filename = 'ridge_f' + str(ind) + '_c' + str(ii) + '.pkl'
        pickle.dump(be, open(filename, 'wb'))
        
        # OOF ve test tahminleri iÃ§in depolama matrisleri
        mvalid[test_index, ii] = be.predict(x1)
        mfull[:, ii] += be.predict(xtest) / nfolds
        
    print('---')
```

EÄŸitim kÄ±smÄ± tamamlandÄ±ktan sonra, yarÄ±ÅŸmada belirtilen metrikle performansÄ± deÄŸerlendirebiliriz:

```python
corvec = np.zeros((ytrain.shape[1], 1))
for ii in range(0, ytrain.shape[1]):
    mvalid[:, ii] = rankdata(mvalid[:, ii]) / mvalid.shape[0]
    mfull[:, ii] = rankdata(mfull[:, ii]) / mfull.shape[0]
    
    corvec[ii] = stats.spearmanr(ytrain[ytrain.columns[ii]], mvalid[:, ii])
    
print(corvec.mean())
```

SonuÃ§ olarak elde edilen **final score (sonuÃ§ skoru)** 0.34â€™tÃ¼r, bu da baÅŸlangÄ±Ã§ iÃ§in oldukÃ§a kabul edilebilir bir sonuÃ§tur.

Bu bÃ¶lÃ¼mde, bir metin gÃ¶vdesi Ã¼zerinde nasÄ±l aÃ§Ä±klayÄ±cÄ± Ã¶zellikler oluÅŸturulacaÄŸÄ±na dair bir Ã¶rnek sunduk. Bu, bir NLP yarÄ±ÅŸmasÄ± iÃ§in kazandÄ±rÄ±cÄ± bir formÃ¼l olmasa da (puan iyi, ancak madalya bÃ¶lgesine ulaÅŸmak iÃ§in bir garanti saÄŸlamaz), aracÄ±nÄ±zda tutmanÄ±z iÃ§in faydalÄ± bir araÃ§tÄ±r. Bu bÃ¶lÃ¼mÃ¼, metin artÄ±rma tekniklerine genel bir bakÄ±ÅŸ saÄŸlayan bir bÃ¶lÃ¼mle sonlandÄ±rÄ±yoruz.

> **Shotaro Ishihara**
> 
> [https://www.kaggle.com/sishihara](https://www.kaggle.com/sishihara)
> 
> Bu bÃ¶lÃ¼mdeki ikinci rÃ¶portajÄ±mÄ±z, **Shotaro Ishihara**, yani u++ ile. Kendisi, PetFinder.my Adoption Prediction yarÄ±ÅŸmasÄ±nda kazanan takÄ±mÄ±n bir Ã¼yesi olan bir **Competitions ve Notebooks Master**. Åu anda Japonya'daki bir haber medya ÅŸirketinde **Veri Bilimci** ve **AraÅŸtÄ±rmacÄ±** olarak Ã§alÄ±ÅŸmakta, ayrÄ±ca Kaggle Ã¼zerine Japonca kitaplar yayÄ±mlamÄ±ÅŸ, bunlar arasÄ±nda **Abhishek Thakur**'Ä±n kitabÄ±nÄ±n Ã§evirisi de bulunmaktadÄ±r. Kaggle ile ilgili haftalÄ±k bir bÃ¼lteni ([https://www.getrevue.co/profile/upura](https://www.getrevue.co/profile/upura)) Japonca olarak hazÄ±rlamaktadÄ±r.
> 
> 
> 
> **Kaggle Ã¼zerine yazdÄ±ÄŸÄ±nÄ±z/Ã§evirdiÄŸiniz kitaplarÄ± nerede bulabiliriz?**
> 
> 
> 
> * [https://www.kspub.co.jp/book/detail/5190067.html](https://www.kspub.co.jp/book/detail/5190067.html) â€“ Titanic GettingStarted yarÄ±ÅŸmasÄ±na dayanan bir Kaggle baÅŸlangÄ±Ã§ kitabÄ±.
> 
> * [https://book.mynavi.jp/ec/products/detail/id=123641](https://book.mynavi.jp/ec/products/detail/id=123641) â€“ Abhishek Thakur'Ä±n **Approaching (Almost) Any Machine Learning Problem** adlÄ± kitabÄ±nÄ±n Japonca Ã§evirisi.
> 
> 
> 
> **Favori yarÄ±ÅŸma tÃ¼rÃ¼nÃ¼z nedir ve neden? Kaggle'da teknikler ve Ã§Ã¶zÃ¼mleme yaklaÅŸÄ±mlarÄ± aÃ§Ä±sÄ±ndan uzmanlÄ±k alanÄ±nÄ±z nedir?**
> 
> Kaggle'da, tabular veya metin veri setleriyle yapÄ±lan yarÄ±ÅŸmalara katÄ±lmayÄ± Ã§ok seviyorum. Bu tÃ¼r veri setleri, haber medya ÅŸirketlerinde yaygÄ±n bir ÅŸekilde kullanÄ±ldÄ±klarÄ± iÃ§in bana oldukÃ§a tanÄ±dÄ±k geliyor. Bu veri setlerini ele alma konusunda oldukÃ§a iyi bir bilgiye sahibim.
> 
> 
> 
> **Bir Kaggle yarÄ±ÅŸmasÄ±na nasÄ±l yaklaÅŸÄ±rÄ±z? Bu yaklaÅŸÄ±m gÃ¼nlÃ¼k iÅŸinizden ne kadar farklÄ±dÄ±r?**
> 
> Ä°lk sÃ¼reÃ§ aynÄ±dÄ±r: sorunu keÅŸifsel veri analizi (EDA) yoluyla ele almayÄ± dÃ¼ÅŸÃ¼nmek. Kaggle, ileri dÃ¼zey makine Ã¶ÄŸrenmesini kullanmayÄ± varsayar, ancak bu iÅŸ dÃ¼nyasÄ±nda bÃ¶yle deÄŸildir. Pratikte, makine Ã¶ÄŸrenmesini kullanmamaya Ã§alÄ±ÅŸÄ±rÄ±m. Makine Ã¶ÄŸrenmesi kullansam bile, BERT gibi ileri dÃ¼zey yÃ¶ntemler yerine, **TF-IDF** ve **lineer regresyon** gibi klasik yÃ¶ntemlerle Ã§alÄ±ÅŸmayÄ± tercih ederim.
> 
> 
> 
> **Makine Ã¶ÄŸrenmesi kullanmaktan kaÃ§Ä±nma konusunda gerÃ§ek dÃ¼nya problemleriyle ilgili daha fazla bilgi edinmek istiyoruz. Bize bazÄ± Ã¶rnekler verebilir misiniz?**
> 
> Ä°ÅŸ yerinde otomatik makale Ã¶zetlemeleri yaparken, bir sinir aÄŸÄ± tabanlÄ± yaklaÅŸÄ±m ([https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D4OS3c02/_article/-char/en](https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D4OS3c02/_article/-char/en)) yerine daha basit bir Ã§Ä±karÄ±mcÄ± yaklaÅŸÄ±m kullanÄ±yoruz ([https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D2OS3a03/_article/-char/en](https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D2OS3a03/_article/-char/en)).
> 
> Makine Ã¶ÄŸrenmesi ile %100 performans garanti etmek zordur ve insanlar tarafÄ±ndan anlaÅŸÄ±lmasÄ± ve uygulanmasÄ± kolay basit yÃ¶ntemler bazen tercih edilir.
> 
> 
> 
> **GirdiÄŸiniz Ã¶zellikle zorlu bir yarÄ±ÅŸmayÄ± anlatÄ±n ve bu gÃ¶revi ele almak iÃ§in hangi iÃ§gÃ¶rÃ¼leri kullandÄ±nÄ±z?**
> 
> PetFinder.my Adoption Prediction yarÄ±ÅŸmasÄ±nda Ã§ok modlu (multi-modal) bir veri seti sunulmuÅŸtu. BirÃ§ok katÄ±lÄ±mcÄ±, tÃ¼m veri tÃ¼rlerini keÅŸfetmeye ve kullanmaya Ã§alÄ±ÅŸtÄ± ve ana yaklaÅŸÄ±m, resimlerden ve metinlerden Ã¶zellik Ã§Ä±karÄ±p bunlarÄ± birleÅŸtirip **LightGBM** eÄŸitmekti. Ben de aynÄ± yaklaÅŸÄ±mÄ± kullandÄ±m. ÅaÅŸÄ±rtÄ±cÄ± bir ÅŸekilde, takÄ±m arkadaÅŸÄ±m **takuoko** ([https://www.kaggle.com/takuok](https://www.kaggle.com/takuok)), tÃ¼m veri setlerini uÃ§tan uca iÅŸleyen harika bir sinir aÄŸÄ± geliÅŸtirdi. Ä°yi tasarlanmÄ±ÅŸ sinir aÄŸlarÄ±, Ã§ok modlu yarÄ±ÅŸmalarda **LightGBM**'yi geride bÄ±rakma potansiyeline sahip. Bu, 2019'da Ã¶ÄŸrendiÄŸim bir ders.
> 
> 
> 
> **Bu ders bugÃ¼n geÃ§erli mi?**
> 
> Bence cevap evet. 2019'a kÄ±yasla, sinir aÄŸlarÄ± Ã§ok modlu verileri daha iyi iÅŸleyebiliyor.
> 
> 
> 
> **Kaggle kariyerinizde size yardÄ±mcÄ± oldu mu? YardÄ±mcÄ± olduysa, nasÄ±l?**
> 
> Evet. Kaggle, bana veri analizi konusunda Ã§ok fazla deneyim kazandÄ±rdÄ±. Kaggle'dan Ã¶ÄŸrendiÄŸim makine Ã¶ÄŸrenmesi bilgisi, daha baÅŸarÄ±lÄ± bir ÅŸekilde Ã§alÄ±ÅŸmama bÃ¼yÃ¼k Ã¶lÃ§Ã¼de yardÄ±mcÄ± oldu. Kaggle'daki baÅŸarÄ±larÄ±m ve iÅŸteki Ã§alÄ±ÅŸmalarÄ±m, 2020'de **International News Media Association**'dan **30 Under 30** Ã–dÃ¼lÃ¼ ve **Grand Prize** almamÄ±n baÅŸlÄ±ca sebeplerinden biriydi. Kaggle ayrÄ±ca, birÃ§ok insanla tanÄ±ÅŸmama fÄ±rsat tanÄ±dÄ±. Bu iliÅŸkiler kesinlikle kariyer geliÅŸimime katkÄ± saÄŸladÄ±.
> 
> 
> 
> **Kaggle sayesinde portfÃ¶yÃ¼nÃ¼zÃ¼ nasÄ±l oluÅŸturdunuz?**
> 
> Ã–ÄŸrenilen beceriler, yarÄ±ÅŸma sonuÃ§larÄ±, yayÄ±mlanan Notebooks, kitaplar, bÃ¼ltenler ve diÄŸer iÃ§erikler.
> 
> 
> 
> **YayÄ±mlarÄ±nÄ±zÄ± nasÄ±l tanÄ±tÄ±yorsunuz?**
> 
> Ã‡eÅŸitli iletiÅŸim kanallarÄ±m var ve tanÄ±tÄ±m iÃ§in uygun araÃ§larÄ± kullanÄ±yorum. Ã–rneÄŸin, **Twitter**, kiÅŸisel bloglar ve **YouTube**.
> 
> 
> 
> **TecrÃ¼benize gÃ¶re, deneyimsiz Kaggle kullanÄ±cÄ±larÄ± genellikle neyi gÃ¶zden kaÃ§Ä±rÄ±r? Åu anda bildiÄŸiniz ama baÅŸta Ã¶ÄŸrenseydiniz iyi olurdu dediÄŸiniz ÅŸey nedir?**
> 
> KeÅŸifsel veri analizinin Ã¶nemi. Makine Ã¶ÄŸrenmesi alanÄ±nda **No Free Lunch** teoremi diye bir kavram vardÄ±r. Biz yalnÄ±zca algoritmalarÄ± Ã¶ÄŸrenmemeliyiz, aynÄ± zamanda zorluklarla nasÄ±l baÅŸa Ã§Ä±kÄ±lacaÄŸÄ±nÄ± da Ã¶ÄŸrenmeliyiz. **No Free Lunch** teoremi, tÃ¼m problemler Ã¼zerinde iyi performans gÃ¶steren evrensel bir modelin olmadÄ±ÄŸÄ±na dair bir ifadedir.
> 
> Makine Ã¶ÄŸrenmesi yarÄ±ÅŸmalarÄ±nda, skoru artÄ±rmak iÃ§in veri setinin ve gÃ¶revin Ã¶zelliklerine uygun bir model bulmak Ã§ok Ã¶nemlidir.
> 
> 
> 
> **GeÃ§miÅŸte yarÄ±ÅŸmalarda yaptÄ±ÄŸÄ±nÄ±z hangi hatalar oldu?**
> 
> **Public leaderboard**'a aÅŸÄ±rÄ± uyum saÄŸlamak. **LANL Earthquake Prediction** yarÄ±ÅŸmasÄ±nda, public leaderboard'da oldukÃ§a iyi bir sÄ±ralama yapmÄ±ÅŸtÄ±m ve yarÄ±ÅŸmayÄ± 5. sÄ±rada bitirdim. Ancak nihai sÄ±ralamam 211. oldu, yani sÄ±nÄ±rlÄ± bir veri setine Ã§ok fazla inandÄ±m. AÅŸÄ±rÄ± uyum saÄŸlama (overfitting), makine Ã¶ÄŸrenmesinde Ã§ok popÃ¼ler bir kavramdÄ±r ve Kaggle sayesinde bunun Ã¶nemini acÄ± bir ÅŸekilde Ã¶ÄŸrendim.
> 
> 
> 
> **AÅŸÄ±rÄ± uyumdan kaÃ§Ä±nmak iÃ§in Ã¶nerdiÄŸiniz Ã¶zel bir yÃ¶ntem var mÄ±?**
> 
> EÄŸitim ve deÄŸerlendirme veri setlerinin nasÄ±l bÃ¶lÃ¼ndÃ¼ÄŸÃ¼nÃ¼ dikkatlice gÃ¶zlemlemek Ã¶nemlidir. Bu bÃ¶lmeyi tekrar eden bir doÄŸrulama seti oluÅŸturmaya Ã§alÄ±ÅŸÄ±rÄ±m.
> 
> 
> 
> **Veri analizi veya makine Ã¶ÄŸrenmesi iÃ§in Ã¶nerdiÄŸiniz belirli araÃ§lar veya kÃ¼tÃ¼phaneler var mÄ±?**
> 
> **Pandas**'Ä± Ã§ok seviyorum, Ã§Ã¼nkÃ¼ tabular veri setlerini iÅŸlemede temel bir kÃ¼tÃ¼phanedir. KeÅŸifsel veri analizi yapmak iÃ§in veriyi Ã§Ä±karÄ±r, toplar ve gÃ¶rselleÅŸtiririm.
> 
> 
> 
> **Pandasâ€™Ä± ustaca kullanmak iÃ§in ne Ã¶nerirsiniz?**
> 
> BazÄ± topluluk tutorial'larÄ±na gÃ¶z atabilirsiniz. Kaggle ayrÄ±ca Pandas ve Ã¶zellik mÃ¼hendisliÄŸi Ã¼zerine bazÄ± Ã¶ÄŸretici kurslar da sunuyor.
> 
> 
> 
> **DiÄŸer yarÄ±ÅŸma platformlarÄ±nÄ± kullanÄ±yor musunuz? Bunlar Kaggle ile nasÄ±l karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r?**
> 
> Zaman zaman Japon platformlarÄ± olan **Signate**, **Nishika** gibi platformlarÄ± kullanÄ±yorum. ([https://upura.github.io/projects/data_science_competitions/](https://upura.github.io/projects/data_science_competitions/)). Bunlar iÅŸlevsellik ve kullanÄ±cÄ± deneyimi aÃ§Ä±sÄ±ndan kesinlikle Kaggle'dan daha zayÄ±f, ancak **Japonca dil** gibi tanÄ±dÄ±k konularÄ± gÃ¶rmek ilginÃ§.

### Text augmentation strategies *(Metin artÄ±rma stratejileri)*

Ã–nceki bÃ¶lÃ¼mde, bilgisayarla gÃ¶rme problemleri iÃ§in geniÅŸ bir ÅŸekilde artÄ±rma (augmentation) stratejilerini tartÄ±ÅŸtÄ±k. Buna karÅŸÄ±lÄ±k, metin verileri iÃ§in benzer yaklaÅŸÄ±mlar daha az incelenmiÅŸ bir konu (bunu, albumentations gibi tek bir paket bulunmamasÄ± da gÃ¶steriyor). Bu bÃ¶lÃ¼mde, bu problemi ele almak iÃ§in bazÄ± olasÄ± yaklaÅŸÄ±mlarÄ± gÃ¶steriyoruz.

#### Basic techniques *(Temel teknikler)*

#### nlpaug *(nlpaug kÃ¼tÃ¼phanesi)*

### Summary *(Ã–zet)*

---

## Chapter 12: Simulation and Optimization Competitions *(BÃ¶lÃ¼m 12: SimÃ¼lasyon ve Optimizasyon YarÄ±ÅŸmalarÄ±)*

### Connect X *(Connect X oyunu)*

### Rock-paper-scissors *(TaÅŸ-kaÄŸÄ±t-makas)*

### Santa competition 2020 *(Santa yarÄ±ÅŸmasÄ± 2020)*

### The name of the game *(Oyunun Ã¶zÃ¼)*

### Summary *(Ã–zet)*

---

# Part III: Leveraging Competitions for Your Career *(BÃ¶lÃ¼m III: YarÄ±ÅŸmalarÄ± Kariyerinde Avantaja DÃ¶nÃ¼ÅŸtÃ¼rme)*

## Chapter 13: Creating Your Portfolio of Projects and Ideas *(BÃ¶lÃ¼m 13: Proje ve Fikir PortfÃ¶yÃ¼ OluÅŸturma)*

### Building your portfolio with Kaggle *(Kaggle ile portfÃ¶y oluÅŸturma)*

### Leveraging Notebooks and discussions *(Defterler ve tartÄ±ÅŸmalardan yararlanma)*

### Leveraging Datasets *(Veri setlerinden yararlanma)*

### Arranging your online presence beyond Kaggle *(Kaggle dÄ±ÅŸÄ±nda Ã§evrimiÃ§i varlÄ±ÄŸÄ±nÄ± dÃ¼zenleme)*

#### Blogs and publications *(Bloglar ve yayÄ±nlar)*

#### GitHub *(GitHub)*

### Monitoring competition updates and newsletters *(YarÄ±ÅŸma gÃ¼ncellemelerini ve bÃ¼ltenleri takip etme)*

### Summary *(Ã–zet)*

---

## Chapter 14: Finding New Professional Opportunities *(BÃ¶lÃ¼m 14: Yeni Profesyonel FÄ±rsatlar Bulmak)*

### Building connections with other competition data scientists *(DiÄŸer yarÄ±ÅŸmacÄ± veri bilimcilerle baÄŸlantÄ± kurma)*

### Participating in Kaggle Days and other Kaggle meetups *(Kaggle Days ve diÄŸer Kaggle buluÅŸmalarÄ±na katÄ±lma)*

### Getting spotted and other job opportunities *(Fark edilmek ve diÄŸer iÅŸ fÄ±rsatlarÄ±)*

#### The STAR approach *(STAR yaklaÅŸÄ±mÄ±)*

### Summary (and some parting words) *(Ã–zet ve kapanÄ±ÅŸ notlarÄ±)*

---

## Other Books You May Enjoy *(HoÅŸunuza Gidebilecek DiÄŸer Kitaplar)*

## Index *(Dizin)*
