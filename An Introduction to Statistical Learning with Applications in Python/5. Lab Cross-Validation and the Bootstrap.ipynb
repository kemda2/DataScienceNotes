{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f896b207-e63a-4001-8328-a47367f19b2e",
   "metadata": {},
   "source": [
    "Bu laboratuvar çalışmasında, bu bölümde ele alınan yeniden örnekleme tekniklerini inceliyoruz.\n",
    "Bu laboratuvardaki bazı komutların bilgisayarınızda çalışması biraz zaman alabilir.\n",
    "Yine, çoğu import işlemini bu en üst düzeyde yaparak başlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2249aeb-6b7d-42da-9105-9acdbad6b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "summarize,\n",
    "poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2ba3f-7de2-4995-abbf-1bf44122af54",
   "metadata": {},
   "source": [
    "Bu laboratuvar için birkaç yeni import (kütüphane içe aktarma) gereklidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06aa97de-f4cd-4490-9a1f-2ffdd54ed5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "(cross_validate,\n",
    "KFold,\n",
    "ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08143f93-cc61-4cf0-b40a-eeea354aede1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5.3.1 Doğrulama Seti Yöntemi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c354d4-1521-4ead-9322-80181796e239",
   "metadata": {},
   "source": [
    "Farklı doğrusal modelleri Auto veri setine uyguladıktan sonra ortaya çıkan test hata oranlarını tahmin etmek için **doğrulama seti yöntemini** inceliyoruz.\n",
    "\n",
    "Veriyi **eğitim (training)** ve **doğrulama (validation)** setlerine ayırmak için `train_test_split()` fonksiyonunu kullanıyoruz. 392 gözlem olduğundan, `test_size=196` argümanı ile veriyi **eşit büyüklükte iki sete** (her biri 196 gözlem) bölüyoruz.\n",
    "\n",
    "Böyle rastgelelik içeren işlemler yaparken, sonuçların ileride tam olarak tekrar üretilebilmesi için genellikle bir **rastgelelik tohumunu (random seed)** belirlemek iyi bir fikirdir. Biz de bölücüye `random_state=0` argümanını vererek rastgelelik tohumunu ayarlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9abf575-c6a3-49d2-bfbd-c3fd92234031",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=196, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a01ce5-c60e-4d0a-92be-d293a6e76ee2",
   "metadata": {},
   "source": [
    "Şimdi, yalnızca **eğitim setine (Auto_train) ait gözlemleri** kullanarak bir doğrusal regresyon modeli uydurabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297fb33d-88a3-4930-91f8-99a9e10ecbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba146ff-2743-46d1-91da-ee0f410703e9",
   "metadata": {},
   "source": [
    "Şimdi, **`predict()`** metodunu kullanarak bu model için oluşturulan model matrisi üzerinde tahminler yapıyoruz; bu tahminler **doğrulama veri seti** kullanılarak hesaplanıyor. Ayrıca, modelimizin **doğrulama ortalama kare hatasını (validation MSE)** da hesaplıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb466499-85d2-4a5a-82e9-ffd5e1b1a240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.61661706966988"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid-valid_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35759c55-af37-444f-afb0-2d86dc3c6f11",
   "metadata": {},
   "source": [
    "Böylece, doğrusal regresyon uyumunun **doğrulama MSE tahmini 23,62** olarak bulunmuştur.\n",
    "\n",
    "Ayrıca, **daha yüksek dereceli polinom regresyonlar** için de doğrulama hatasını tahmin edebiliriz. Bunun için önce, bir **model stringi**, eğitim ve test setini alan ve test seti üzerinde **MSE** döndüren bir `evalMSE()` fonksiyonu tanımlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346c229c-c4fe-42da-9c81-04122a12f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMSE(terms, response, train, test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(X_test)\n",
    "    return np.mean((y_test- test_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f34d9-6af5-4bba-bf4f-c5ccad983a63",
   "metadata": {},
   "source": [
    "Hadi bu fonksiyonu kullanarak, doğrusal, ikinci dereceden (kuadratik) ve üçüncü dereceden (kübik) uyumlar için **doğrulama MSE’sini tahmin edelim.**\n",
    "\n",
    "Burada **`enumerate()`** fonksiyonunu kullanıyoruz; bu fonksiyon, bir **for döngüsü** ile iterasyon yaparken hem **nesnelerin değerlerini** hem de **indekslerini** verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f95910-34c2-4e94-9ff8-620df6ee05d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "            'mpg',\n",
    "            Auto_train,\n",
    "            Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5345e4b8-d1f7-4dd8-941d-f495626cc53a",
   "metadata": {},
   "source": [
    "Bu hata oranları sırasıyla **23,62**, **18,76** ve **18,80**’dir. Farklı bir eğitim/doğrulama bölmesi seçersek, doğrulama setinde biraz farklı hata değerleri bekleyebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83b3a2b-ccb7-43e0-8149-4321d5e7d050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                        test_size=196,\n",
    "                                        random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "    'mpg',\n",
    "    Auto_train,\n",
    "    Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ecd78-c932-4c9b-aa38-460f4b12364b",
   "metadata": {},
   "source": [
    "Gözlemleri eğitim ve doğrulama setlerine bu şekilde böldüğümüzde, **doğrulama seti hata oranları** sırasıyla **lineer model için 20,76**, **kuadratik model için 16,95** ve **kübik model için 16,97** olarak bulunmuştur.\n",
    "\n",
    "Bu sonuçlar önceki bulgularımızla tutarlıdır: **Horsepower’ın kuadratik fonksiyonunu kullanan bir model**, sadece lineer fonksiyon kullanan bir modele göre daha iyi performans göstermektedir ve **kübik fonksiyon kullanmanın ek bir iyileştirme sağladığına dair bir kanıt yoktur.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277dc253-de52-4d81-983e-2cc26e89fa9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5.3.2 Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad087cc1-deaa-4621-a3b8-88285212f1d1",
   "metadata": {},
   "source": [
    "Kuramsal olarak, **çapraz doğrulama tahmini** herhangi bir genelleştirilmiş doğrusal model (GLM) için hesaplanabilir. Ancak uygulamada, Python’da çapraz doğrulamanın en basit yolu **sklearn** kullanmaktır; sklearn’in arayüzü (API) **statsmodels**’dan farklıdır. Biz bugüne kadar GLM’leri **statsmodels** ile uydurduk.\n",
    "\n",
    "Bu, veri bilimcilerin sıkça karşılaştığı bir problemdir:\n",
    "\n",
    "> “A görevini yapan bir fonksiyonum var ve bunu B görevini gerçekleştiren bir şeye vermem gerekiyor, böylece B(A(D)) hesaplayabileyim, burada D veri setim.”\n",
    "\n",
    "A ve B birbirleriyle doğrudan uyumlu olmadığında, bir **wrapper** kullanmak gerekir. **ISLP wrapper paketi**, **sklearn_sm()** adlı bir wrapper sağlar; bu sayede **statsmodels ile uydurulmuş modelleri**, **sklearn’in çapraz doğrulama araçlarıyla** kolayca kullanabiliriz.\n",
    "\n",
    "`sklearn_sm()` sınıfının ilk argümanı bir **statsmodels modeli**dir.\n",
    "İki ek opsiyonel argüman alabilir:\n",
    "\n",
    "* **model_str:** Bir formül belirtmek için kullanılır.\n",
    "* **model_args:** Modeli uydururken kullanılacak ek argümanların bulunduğu bir sözlük (dictionary). Örneğin, lojistik regresyon modeli için **family** argümanını belirtmek gerekir:\n",
    "\n",
    "  ```python\n",
    "  model_args = {'family': sm.families.Binomial()}\n",
    "  ```\n",
    "\n",
    "İşte wrapper’ımızın kullanımına bir örnek:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bc5bcd-4fe9-49a4-a887-1ca595c470a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929212"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS, MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d1e59-c799-4b10-a2e2-7e6061d1d2fd",
   "metadata": {},
   "source": [
    "`cross_validate()` fonksiyonuna verilen argümanlar şunlardır:\n",
    "\n",
    "* `fit()`, `predict()` ve `score()` metodlarına sahip bir nesne,\n",
    "* Özellikler matrisi **X**,\n",
    "* Hedef değişken **Y**.\n",
    "\n",
    "Ayrıca `cross_validate()`’a **cv** adında ek bir argüman da verdik; **K** tam sayısını belirtmek, **K-katlı çapraz doğrulama** (K-fold cross-validation) yapılmasını sağlar. Biz, toplam gözlem sayısına karşılık gelen bir değer verdik; bu da **tek bırakma çapraz doğrulama (LOOCV)** anlamına gelir.\n",
    "\n",
    "`cross_validate()` fonksiyonu bir sözlük (dictionary) üretir; biz burada yalnızca **çapraz doğrulamalı test skoru (MSE)** ile ilgileniyoruz, bu da **24,23** olarak tahmin edilmiştir.\n",
    "\n",
    "Bu işlemi, giderek daha karmaşık **polinom uyumlar** için tekrarlayabiliriz. Bunu otomatikleştirmek için bir **for döngüsü** kullanıyoruz; döngü, **1’den 5’e kadar dereceli polinom regresyonlarını** uydurur, ilişkili çapraz doğrulama hatasını hesaplar ve bunu `cv_error` vektörünün **i’inci elemanına** kaydeder.\n",
    "\n",
    "For döngüsündeki **d değişkeni**, polinomun derecesini temsil eder. Öncelikle, **vektörü başlatıyoruz**; bu komut birkaç saniye sürebilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7b19e74-013b-41f6-8376-dd47a31f361a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443031, 19.03320428])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)  # 1'den 5'e kadar dereceler için çapraz doğrulama hatalarını saklayacak vektörü başlatıyoruz\n",
    "\n",
    "H = np.array(Auto['horsepower'])  # 'horsepower' sütununu bir NumPy dizisine çeviriyoruz\n",
    "M = sklearn_sm(sm.OLS)            # statsmodels OLS modelini sklearn uyumlu hale getiren wrapper'ı oluşturuyoruz\n",
    "\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))  # H sütunundan 0'dan d derecesine kadar polinom özellik matrisi oluşturuyoruz\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])  # LOOCV kullanarak çapraz doğrulama yapıyoruz\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])  # Test skorlarının ortalamasını alıp cv_error dizisine kaydediyoruz\n",
    "\n",
    "cv_error  # 1'den 5'e kadar polinom derecelerinin çapraz doğrulama hatalarını gösterir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ef5af-3a46-42b6-87de-0c9beff6731e",
   "metadata": {},
   "source": [
    "Şekil 5.4’te olduğu gibi, **tahmin edilen test MSE’sinde** lineer ve kuadratik uyumlar arasında belirgin bir düşüş görülmektedir; ancak **daha yüksek dereceli polinomlar kullanıldığında** belirgin bir iyileşme yoktur.\n",
    "\n",
    "Yukarıda **`np.power().outer()`** yöntemini tanıttık.\n",
    "\n",
    "* `outer()` metodu, **iki argüman alan bir işleme** uygulanır (örneğin `add()`, `min()`, `power()` gibi).\n",
    "* İki dizi (array) alır ve daha büyük bir dizi oluşturur; burada işlem, iki dizinin **her bir eleman çifti** için uygulanır.\n",
    "\n",
    "Özetle, `np.power.outer(H, np.arange(d+1))` ifadesi, her bir gözlem için polinom derecelerini hesaplamak amacıyla bu mantığı kullanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63eeb20b-8fd2-42d7-96ed-606846d3de3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " A = np.array([3, 5, 9])\n",
    " B = np.array([2, 4])\n",
    " np.add.outer(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e69a18-4165-4746-b1f9-b562caef04d0",
   "metadata": {},
   "source": [
    "Yukarıdaki çapraz doğrulama (CV) örneğinde **K = n** kullanmıştık; ancak elbette **K < n** de kullanılabilir. Kod yukarıdakine çok benzer ve **daha hızlı çalışır**.\n",
    "\n",
    "Burada, veriyi **K = 10 rastgele gruba** bölmek için `KFold()` kullanıyoruz.\n",
    "\n",
    "* `random_state` ile bir **rastgelelik tohumu** belirliyoruz.\n",
    "* Ayrıca, 1’den 5’e kadar dereceli polinom uyumlarının karşılık gelen **CV hatalarını saklayacağımız `cv_error` vektörünü** başlatıyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50a8b44-4c7c-405b-9f70-284e115a0d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848404, 19.13722016])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "            shuffle=True,\n",
    "            random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "    X,\n",
    "    Y,\n",
    "    cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c7a5e0-6e19-4c72-90ba-2a3605cc7d15",
   "metadata": {},
   "source": [
    "Dikkat edilirse, **hesaplama süresi LOOCV’ye göre çok daha kısadır.**\n",
    "(Teoride, en küçük kareler doğrusal model için LOOCV hesaplama süresi, LOOCV formülü (5.2) mevcut olduğu için K-katlı CV’ye göre daha hızlı olmalıdır; ancak `cross_validate()` fonksiyonu bu formülü kullanmaz.)\n",
    "\n",
    "Yine de, **kübik veya daha yüksek dereceli polinom terimleri kullanmanın**, sadece kuadratik bir uyum kullanmaya kıyasla test hatasını düşürdüğüne dair çok az kanıt görülmektedir.\n",
    "\n",
    "`cross_validate()` fonksiyonu esnektir ve farklı **veri bölme mekanizmalarını** argüman olarak alabilir.\n",
    "Örneğin, **`ShuffleSplit()`** fonksiyonu kullanılarak doğrulama seti yöntemi, K-katlı çapraz doğrulama kadar kolay bir şekilde uygulanabilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9bb56da-2177-41f0-af0f-a5d1d173df37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                            test_size=196,\n",
    "                            random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                            Auto.drop(['mpg'], axis=1),\n",
    "                            Auto['mpg'],\n",
    "                            cv=validation);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733c388-52eb-4404-8261-c0210065b03c",
   "metadata": {},
   "source": [
    "Test hatasındaki **değişkenliği tahmin etmek** için aşağıdaki kod çalıştırılabilir:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61481d50-3977-4f86-9bda-a32b182ff865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.802232661034164, 1.4218450941091847)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                            test_size=196,\n",
    "                            random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                            Auto.drop(['mpg'], axis=1),\n",
    "                            Auto['mpg'],\n",
    "                            cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31110ce-b47f-4254-8d5d-4ca0d62749c2",
   "metadata": {},
   "source": [
    "Dikkat edilmelidir ki, bu **standart sapma**, ortalama test skoru veya bireysel skorların **örnekleme değişkenliğinin geçerli bir tahmini** değildir; çünkü rastgele seçilen eğitim örnekleri **çakışır** ve bu da **korelasyonlar** yaratır. Yine de, farklı rastgele katları seçmenin neden olduğu **Monte Carlo değişkenliği** hakkında bir fikir verir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab55bc6-b47c-4a21-8d8d-3650ed7b03a3",
   "metadata": {},
   "source": [
    "# 5.3.3 Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918311a-56b1-4ce9-a9ff-0bd0226f743d",
   "metadata": {},
   "source": [
    "Bootstrap yöntemini, **Bölüm 5.2’deki basit örnek** üzerinde ve ayrıca **Auto veri setinde doğrusal regresyon modelinin doğruluğunu tahmin etme** örneğinde gösteriyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539de926-e06b-4cbb-8c08-143e94727700",
   "metadata": {},
   "source": [
    "## Bir İlgili İstatistiğin Doğruluğunu Tahmin Etmek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893ed50-0c64-4060-91c5-bf22fe3b4176",
   "metadata": {},
   "source": [
    "Bootstrap yaklaşımının büyük avantajlarından biri, **neredeyse her durumda uygulanabilir** olmasıdır. Karmaşık matematiksel hesaplamalar gerekmez. Python’da bootstrap için çeşitli uygulamalar olsa da, **standart hatayı tahmin etmek** için kullanımı yeterince basittir; bu yüzden verilerimiz bir dataframe’de saklandığında kullanabileceğimiz kendi fonksiyonumuzu aşağıda yazıyoruz.\n",
    "\n",
    "Bootstrap’i göstermek için basit bir örnekle başlıyoruz. **ISLP paketindeki Portfolio veri seti**, Bölüm 5.2’de açıklanmıştır. Amaç, formül (5.7) ile verilen **α parametresinin örnekleme varyansını** tahmin etmektir.\n",
    "\n",
    "Bunun için `alpha_func()` adında bir fonksiyon oluşturacağız:\n",
    "\n",
    "* Girdi olarak, **X ve Y sütunlarını içeren bir dataframe D** ve\n",
    "* Hangi gözlemlerin α’yı tahmin etmek için kullanılacağını belirten bir **idx vektörü** alır.\n",
    "* Fonksiyon, seçilen gözlemler temelinde **α tahminini** çıktılar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6526b4ac-cd7c-4a76-a1b3-353ceb784b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1,1]- cov_[0,1]) / (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa9937-c03e-4cc8-9423-30bb533cbf7a",
   "metadata": {},
   "source": [
    "Bu fonksiyon, **idx argümanı ile belirtilen gözlemlere** formül (5.7)deki **minimum varyans formülünü** uygulayarak **α tahminini** döndürür.\n",
    "\n",
    "Örneğin, aşağıdaki komut **tüm 100 gözlem kullanılarak α’yı** tahmin eder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f29e178-4966-43df-ac00-227f90d1ce31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5e307-afd1-40d0-b640-e292d7673182",
   "metadata": {},
   "source": [
    "Sonraki adımda, **0–99 aralığından 100 gözlemi rastgele ve tekrarlı seçimle** seçiyoruz.\n",
    "Bu, **yeni bir bootstrap veri seti oluşturmak** ve **ˆα’yı yeni veri setine göre yeniden hesaplamak** ile eşdeğerdir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26fd4582-4b66-4c0b-949c-1a1b05a1cf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619004"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "            rng.choice(100,\n",
    "            100,\n",
    "            replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c66c5a-0047-4432-b662-25a7880d5919",
   "metadata": {},
   "source": [
    "Bu süreç, yalnızca bir **dataframe** argümanı alan **rastgele fonksiyonlar** için **bootstrap standart hatasını** hesaplayan basit bir `boot_SE()` fonksiyonu oluşturacak şekilde genellenebilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6b0712d-ab72-4295-91a2-862ef34084e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index,\n",
    "                            n,\n",
    "                            replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B- (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec0f01-baba-4879-a225-08ef9df51395",
   "metadata": {},
   "source": [
    "Dikkat edin, `for _ in range(B)` ifadesinde **_** döngü değişkeni olarak kullanılmıştır. Bu, sayacın değerinin önemli olmadığı durumlarda sıkça kullanılır ve döngünün **B kez çalıştırılmasını** sağlar.\n",
    "\n",
    "Şimdi, **B = 1.000 bootstrap tekrarı** kullanarak α tahminimizin doğruluğunu değerlendirmek için fonksiyonumuzu kullanalım.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97de2620-ce27-4902-985a-12ef9bff0be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277699"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                    Portfolio,\n",
    "                    B=1000,\n",
    "                    seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e4955-0818-43cb-93af-8c536f34169c",
   "metadata": {},
   "source": [
    "Sonuç olarak, **bootstrap ile SE(ˆα) tahmini 0,0912** olarak bulunmuştur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5c965-48f7-4b18-8a28-d4436cf83996",
   "metadata": {},
   "source": [
    "## Doğrusal Regresyon Modelinin Doğruluğunu Tahmin Etmek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184dd4b4-9ffa-4565-a47c-609cc63ac7e4",
   "metadata": {},
   "source": [
    "Bootstrap yöntemi, bir istatistiksel öğrenme yönteminden elde edilen **katsayı tahminlerinin ve öngörülerin değişkenliğini** değerlendirmek için kullanılabilir.\n",
    "\n",
    "Burada, **Auto veri setinde `horsepower` kullanarak `mpg` tahmin eden doğrusal regresyon modeli** için:\n",
    "\n",
    "* **β₀** (intercept) ve **β₁** (slope) tahminlerinin değişkenliğini değerlendirmek amacıyla bootstrap yaklaşımını kullanıyoruz.\n",
    "* Bootstrap ile elde edilen tahminleri, Bölüm 3.1.2’de açıklanan **SE(ˆβ₀) ve SE(ˆβ₁) formülleri** ile karşılaştıracağız.\n",
    "\n",
    "`boot_SE()` fonksiyonumuzu kullanabilmek için, ilk argümanı olarak **bir dataframe D ve indeksler idx alan bir fonksiyon** yazmamız gerekir. Ancak burada, **belirli bir regresyon modeli** (formül ve veri ile belirtilmiş) için bootstrap yapacağız.\n",
    "\n",
    "Bunu yapmak için birkaç basit adım vardır:\n",
    "\n",
    "1. `boot_OLS()` adında **genel bir bootstrap fonksiyonu** yazıyoruz; bu fonksiyon, regresyonu tanımlayan bir **formül** alır.\n",
    "2. `clone()` fonksiyonunu kullanarak formülün bir kopyasını oluşturuyoruz; böylece bu formül **yeniden örneklenmiş veri setine** uygulanabilir.\n",
    "3. Bu sayede, `poly()` gibi türetilmiş özellikler de **yeniden örneklenen veri seti üzerinde yeniden uydurulur**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63f3cea9-c867-48b7-8ca4-ba6084fc5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e602995b-8be1-4192-ba5b-450740bf3635",
   "metadata": {},
   "source": [
    "Bu, `boot_SE()`’in ilk argümanı olarak tam olarak gereken şey değildir.\n",
    "\n",
    "Bootstrap sürecinde değişmeyecek **modeli belirten ilk iki argüman** vardır ve biz bunları **sabitlemek** isteriz. Bunun için **`functools` modülündeki `partial()`** fonksiyonu kullanılır:\n",
    "\n",
    "* `partial()` bir fonksiyonu argüman olarak alır ve **bazı argümanları soldan başlayarak sabitler**.\n",
    "* Biz de bunu kullanarak, `boot_OLS()` fonksiyonunun **ilk iki model-formül argümanını sabitliyoruz.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc6f603c-712c-45d5-9c8f-bf72e6130a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800fcc2e-7e29-436e-9285-dbd440cfc37e",
   "metadata": {},
   "source": [
    "`hp_func?` yazarak fonksiyonun **D ve idx olmak üzere iki argümanı** olduğunu görebiliriz — bu, **ilk iki argümanı sabitlenmiş bir `boot_OLS()` versiyonudur** ve bu nedenle `boot_SE()` için ideal bir ilk argümandır.\n",
    "\n",
    "Artık `hp_func()` fonksiyonu, gözlemler arasından **tekrarlı rastgele örnekleme** yaparak **intercept ve slope terimleri için bootstrap tahminleri** oluşturmak amacıyla kullanılabilir. Öncelikle, fonksiyonun işlevini **10 bootstrap örneği** üzerinde gösteriyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80ed9dc6-7349-4964-8fa5-a55a3cb86d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.88064456, -0.1567849 ],\n",
       "       [38.73298691, -0.14699495],\n",
       "       [38.31734657, -0.14442683],\n",
       "       [39.91446826, -0.15782234],\n",
       "       [39.43349349, -0.15072702],\n",
       "       [40.36629857, -0.15912217],\n",
       "       [39.62334517, -0.15449117],\n",
       "       [39.0580588 , -0.14952908],\n",
       "       [38.66688437, -0.14521037],\n",
       "       [39.64280792, -0.15555698]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)  # Rastgele sayı üreteci için bir tohum (seed) belirliyoruz\n",
    "np.array([hp_func(Auto.reset_index(),        # hp_func fonksiyonunu kullanıyoruz\n",
    "                  rng.choice(392,  # 392 gözlem arasından\n",
    "                  392,            # 392 gözlem seçiyoruz\n",
    "                  replace=True))  # Tekrarlı seçimle (bootstrap)\n",
    "           for _ in range(10)]) # 10 bootstrap örneği oluşturuyoruz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eabdf8-84be-4ad3-94f5-0e29aa48c9dd",
   "metadata": {},
   "source": [
    "Sonra, intercept ve slope terimleri için 1.000 bootstrap tahmini kullanarak standart hataları hesaplamak için **boot_SE()** fonksiyonunu kullanıyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "948598e5-1f82-4b5e-87bf-b6e8de74a93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.731176\n",
       "horsepower    0.006092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_se = boot_SE(hp_func,\n",
    "                Auto,\n",
    "                B=1000,\n",
    "                seed=10)\n",
    "hp_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b27d4c-3cbd-47c9-9202-d87ec84bac4a",
   "metadata": {},
   "source": [
    "Bu, SE(ˆβ0) için bootstrap tahmininin 0,85 ve SE(ˆβ1) için bootstrap tahmininin 0,0074 olduğunu gösterir. Bölüm 3.1.2’de tartışıldığı gibi, doğrusal bir modelde regresyon katsayılarının standart hatalarını hesaplamak için standart formüller kullanılabilir. Bunlar, ISLP.sm içindeki **summarize()** fonksiyonu kullanılarak elde edilebilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0a44715-18f4-4abe-bd65-673cbeb97130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.717\n",
       "horsepower    0.006\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model.fit(Auto, Auto['mpg'])\n",
    "model_se = summarize(hp_model.results_)['std err']\n",
    "model_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8cf2b-518e-4996-9060-4312fbf2c7cf",
   "metadata": {},
   "source": [
    "ˆβ0 ve ˆβ1 için Bölüm 3.1.2’deki formüller kullanılarak elde edilen standart hata tahminleri, intercept için 0,717 ve slope için 0,006’dır. İlginç bir şekilde, bunlar bootstrap ile elde edilen tahminlerden biraz farklıdır. Peki bu bootstrap ile ilgili bir sorun olduğunu mu gösterir? Aslında, tam tersi bir durumu işaret eder.\n",
    "\n",
    "Hatırlarsak, sayfa 75’teki Denklem 3.8’de verilen standart formüller belirli varsayımlara dayanır. Örneğin, bilinmeyen parametre σ²’ye, yani gürültü varyansına bağlıdırlar. σ² daha sonra RSS kullanılarak tahmin edilir. Standart hata formülleri doğrusal modelin doğru olmasına dayanmasa da, σ²’nin tahmini buna dayanır. Sayfa 99’daki Şekil 3.8’de veride doğrusal olmayan bir ilişki olduğu görülmektedir; bu nedenle doğrusal bir uyumdan elde edilen artıklar şişirilmiş olur ve ˆσ² de büyük olur.\n",
    "\n",
    "İkinci olarak, standart formüller (biraz gerçekçi olmayan bir şekilde) xi’nin sabit olduğunu ve tüm değişkenliğin hatalardan (ϵi) geldiğini varsayar. Bootstrap yaklaşımı ise bu varsayımlara dayanmaz ve bu nedenle ˆβ0 ve ˆβ1’in standart hatalarını sm.OLS’den elde edilen sonuçlara kıyasla daha doğru tahmin ediyor olabilir.\n",
    "\n",
    "Aşağıda, bootstrap standart hata tahminlerini ve veriye ikinci dereceden (quadratic) model uygulanarak elde edilen standart lineer regresyon tahminlerini hesaplıyoruz. Bu model veriye iyi bir uyum sağladığı için (Şekil 3.8), artık bootstrap tahminleri ile SE(ˆβ0), SE(ˆβ1) ve SE(ˆβ2) için standart tahminler arasında daha iyi bir uyum vardır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3bb6d4a-2e2e-4033-91a1-ea75a94b3d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.538641\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.024696\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000090\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad_model = MS([poly('horsepower', 2, raw=True)])\n",
    "quad_func = partial(boot_OLS,\n",
    "                    quad_model,\n",
    "                    'mpg')\n",
    "boot_SE(quad_func, Auto, B=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed603e5-3f2c-49e1-b252-2fe9b58947e3",
   "metadata": {},
   "source": [
    "Sonuçları, **sm.OLS()** kullanılarak hesaplanan standart hatalarla karşılaştırıyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe0461d0-9f02-4904-b30f-290bb8269e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept                                  1.800\n",
       "poly(horsepower, degree=2, raw=True)[0]    0.031\n",
       "poly(horsepower, degree=2, raw=True)[1]    0.000\n",
       "Name: std err, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sm.OLS(Auto['mpg'],\n",
    "             quad_model.fit_transform(Auto))\n",
    "summarize(M.fit())['std err']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
