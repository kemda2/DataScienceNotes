
# Part 1: Fundamentals of AutoML

KitabÄ±n ilk Ã¼Ã§ bÃ¶lÃ¼mÃ¼, AutoML Ã¶ÄŸrenimine temel oluÅŸturmak amacÄ±yla, makine Ã¶ÄŸreniminin bazÄ± temel kavramlarÄ±nÄ± ve modellerini tanÄ±tarak temel yapÄ± taÅŸlarÄ±nÄ± anlamanÄ±za yardÄ±mcÄ± olur.

1. bÃ¶lÃ¼mde AutoMLâ€™nin genel kavramlarÄ±nÄ±, ne olduÄŸunu ve genel makine Ã¶ÄŸrenimiyle olan baÄŸlantÄ±sÄ±nÄ± gÃ¶rmeye baÅŸlayacaksÄ±nÄ±z. AyrÄ±ca AutoMLâ€™nin araÅŸtÄ±rma aÃ§Ä±sÄ±ndan deÄŸerini ve pratik faydalarÄ±nÄ± Ã¶ÄŸreneceksiniz.

2. bÃ¶lÃ¼m, bir makine Ã¶ÄŸrenimi problemini Ã§Ã¶zmek iÃ§in kullanÄ±lan klasik makine Ã¶ÄŸrenimi iÅŸlem hattÄ±nÄ± (pipeline) tanÄ±tÄ±r.

Yapay zekÃ¢ topluluÄŸunda ve Ã¶tesinde derin Ã¶ÄŸrenme modellerinin popÃ¼lerliÄŸi gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, 3. bÃ¶lÃ¼mde Ã¼Ã§ yaygÄ±n model tÃ¼rÃ¼ Ã¼zerinden derin Ã¶ÄŸrenmenin temel bilgilerini ele alÄ±yoruz. Bu bÃ¶lÃ¼mde karmaÅŸÄ±k derin Ã¶ÄŸrenme kavramlarÄ±na girmiyoruz; sadece temel yapÄ± taÅŸlarÄ±nÄ± ve farklÄ± veri tÃ¼rlerinde uygulanan Ã¼Ã§ klasik modeli tanÄ±tÄ±yoruz.

EÄŸer makine Ã¶ÄŸrenimi, derin Ã¶ÄŸrenme veya bunlarÄ±n Python ile nasÄ±l uygulanacaÄŸÄ± konusunda fazla deneyiminiz yoksa, AutoMLâ€™nin pratik uygulamalarÄ±na geÃ§meden Ã¶nce mutlaka 1. bÃ¶lÃ¼mÃ¼ baÅŸtan sona okumanÄ±z tavsiye edilir.

AyrÄ±ca bu bÃ¶lÃ¼mÃ¼n ardÄ±ndan, ek B kÄ±smÄ±nda temel makine Ã¶ÄŸrenimi iÅŸlem hattÄ±na daha aÅŸina olmanÄ±za yardÄ±mcÄ± olacak ek Ã¶rnekler de bulabilirsiniz.

## 1. From machine learning to automated machine learning

Yapay zekÃ¢ (YZ), gÃ¼nlÃ¼k yaÅŸamÄ±n birÃ§ok yÃ¶nÃ¼ne ulaÅŸan bir alan olarak, son yÄ±llarda kapsamlÄ± bir ÅŸekilde araÅŸtÄ±rÄ±lmaktadÄ±r. YZ, bilgisayarlarÄ±n tÄ±pkÄ± insanlar gibi Ã§evreyi algÄ±layarak gÃ¶revleri otomatikleÅŸtirmesini saÄŸlamaya Ã§alÄ±ÅŸÄ±r.

YZâ€™nin bir alt dalÄ± olan **makine Ã¶ÄŸrenimi (ML)**, bilgisayarÄ±n verileri kendi kendine keÅŸfederek bir gÃ¶revi yerine getirmesini saÄŸlar. Bu sayede bilgisayar, yalnÄ±zca kendisine aÃ§Ä±kÃ§a ne yapmasÄ± gerektiÄŸi sÃ¶ylenmiÅŸ gÃ¶revleri deÄŸil, kendi Ã¶ÄŸrendikleriyle daha fazlasÄ±nÄ± da yapabilir.

Ancak, bu alana girmek oldukÃ§a zordur: kullanÄ±lan teknikleri Ã¶ÄŸrenmenin maliyeti ve uygulamalarda gerekli deneyimi kazanmanÄ±n gÃ¼Ã§lÃ¼ÄŸÃ¼ nedeniyle, yeterli uzmanlÄ±ÄŸa sahip olmayan kiÅŸiler MLâ€™yi kolayca kullanamazlar. Bu nedenle, makine Ã¶ÄŸrenimi tekniklerini â€œfildiÅŸi kulelerindenâ€ Ã§Ä±karÄ±p daha fazla insana eriÅŸilebilir hale getirmek hem araÅŸtÄ±rma dÃ¼nyasÄ±nÄ±n hem de endÃ¼strinin Ã¶nemli bir hedefi hÃ¢line gelmiÅŸtir.

Bu amaÃ§ doÄŸrultusunda, **otomatik makine Ã¶ÄŸrenimi (AutoML)** Ã¶ne Ã§Ä±kan bir araÅŸtÄ±rma alanÄ± olarak ortaya Ã§Ä±kmÄ±ÅŸtÄ±r. AutoMLâ€™nin hedefi, insan uzmanlarÄ±n makine Ã¶ÄŸrenimi problemlerini nasÄ±l Ã§Ã¶zdÃ¼klerini taklit ederek belirli bir problem iÃ§in **en uygun ML Ã§Ã¶zÃ¼mlerini otomatik olarak keÅŸfetmek** ve bÃ¶ylece derin teknik bilgiye sahip olmayan kiÅŸilerin de kullanabileceÄŸi hazÄ±r ML teknikleri sunmaktÄ±r.

AutoML yalnÄ±zca yeni baÅŸlayanlar iÃ§in faydalÄ± deÄŸildir; aynÄ± zamanda uzmanlarÄ±n ve veri bilimcilerin ML modellerini tasarlama ve yapÄ±landÄ±rma yÃ¼kÃ¼nÃ¼ de hafifletir.

HenÃ¼z yeni ve ileri dÃ¼zey bir konu olduÄŸu iÃ§in Ã§oÄŸu insan iÃ§in yabancÄ±dÄ±r ve mevcut yetenekleri genellikle kitle iletiÅŸim araÃ§larÄ± tarafÄ±ndan abartÄ±lÄ± ÅŸekilde sunulmaktadÄ±r.

Bu bÃ¶lÃ¼mde AutoMLâ€™nin ne olduÄŸuna kÄ±sa bir bakÄ±ÅŸ sunulmakta, temel kavramlarÄ± tanÄ±tÄ±lmakta ve araÅŸtÄ±rma deÄŸeri ile pratik faydalarÄ±na giriÅŸ yapÄ±lmaktadÄ±r.

Haydi, basit bir Ã¶rnekle baÅŸlayalÄ±m.


### 1.1 A glimpse of automated machine learning â€“ 4

Diyelim ki, el yazÄ±sÄ± ile yazÄ±lmÄ±ÅŸ rakamlarÄ± resimlerden tanÄ±yacak bir makine Ã¶ÄŸrenimi (ML) modeli tasarlamak istiyorsunuz.
Bu ML modeli, giriÅŸ olarak resimleri alacak ve her bir resimdeki rakamÄ± Ã§Ä±ktÄ± olarak Ã¼retecektir (bkz. ÅŸekil 1.1).

![image](./images/0001.png)

EÄŸer makine Ã¶ÄŸrenimi konusunda deneyiminiz yoksa, bu hedefe pratikte nasÄ±l ulaÅŸabileceÄŸimizi **Python tarzÄ±nda programatik bir Ã¶rnek** Ã¼zerinden aÃ§Ä±klayalÄ±m.
Burada bir ML modelini, bir sÄ±nÄ±ftan (class) tÃ¼retilmiÅŸ bir nesne (object) olarak ele alÄ±yoruz (bkz. listeleme 1.1). Bu sÄ±nÄ±f, modelimizde kullanmak istediÄŸimiz belirli bir **ML algoritmasÄ± tÃ¼rÃ¼ne** (bir dizi iÅŸlem adÄ±mÄ±na) karÅŸÄ±lÄ±k gelir.

Bir modeli oluÅŸturmak (Ã¶rneÄŸini yaratmak) iÃ§in, kullanÄ±lacak algoritma sÄ±nÄ±fÄ±nÄ± seÃ§menin yanÄ± sÄ±ra, algoritmaya **bazÄ± geÃ§miÅŸ veriler** ve **parametreler (arg1 ve arg2)** de saÄŸlamamÄ±z gerekir.
Burada kullanÄ±lan geÃ§miÅŸ veriler, **el yazÄ±sÄ± rakamlarÄ±n gÃ¶rÃ¼ntÃ¼lerinden** oluÅŸur ve bu gÃ¶rÃ¼ntÃ¼lerin etiketleri (yani hangi rakam olduklarÄ±) zaten bilinir.
Bu, makinenin (veya ML algoritmasÄ±nÄ±n) Ã¶ÄŸrenme sÃ¼recini gerÃ§ekleÅŸtirmesine yardÄ±mcÄ± olur â€” yani, tÄ±pkÄ± bir Ã§ocuÄŸun resimlerden nesneleri tanÄ±mayÄ± Ã¶ÄŸrenmesi gibi, model de rakamlarÄ± nasÄ±l tanÄ±yacaÄŸÄ±nÄ± Ã¶ÄŸrenir.
(Bu sÃ¼recin ayrÄ±ntÄ±larÄ±nÄ± ilerleyen bÃ¶lÃ¼mlerde gÃ¶receksiniz.)

Burada bahsedilen parametreler, algoritmanÄ±n nasÄ±l Ã§alÄ±ÅŸacaÄŸÄ±nÄ± belirleyen ayarlardÄ±r â€” yani sÃ¼recin nasÄ±l yÃ¼rÃ¼tÃ¼leceÄŸini kontrol ederler.
SonuÃ§ta elde edilen ML modeli, **daha Ã¶nce hiÃ§ gÃ¶rmediÄŸi resimlerdeki rakamlarÄ±** tahmin edebilecektir (bkz. ÅŸekil 1.1), ki bu iÅŸlem sonraki listelemede yer alan ikinci kod satÄ±rÄ±yla gerÃ§ekleÅŸtirilecektir.

```Python
ml_model = MachineLearningAlgorithm1(
    arg1=..., arg2=..., data=historical_images
)  # Bir ML modeli oluÅŸturur

digits = [ml_model.predict_image_digit(image) for image in new_images]
# ML modeliyle tahminler yapar
```

Koddaki Ã¶rnekte de gÃ¶rebileceÄŸiniz gibi, verisetini (ki bunu kendimiz hazÄ±rlamamÄ±z gerekebilir) saÄŸlamanÄ±n yanÄ± sÄ±ra, gÃ¶revi Ã§Ã¶zmek iÃ§in Ã¶nceden sahip olduÄŸumuz bilgiye dayanarak iki ÅŸeyi daha belirlememiz gerekir:

* KullanÄ±lacak **ML algoritmasÄ± (veya yÃ¶ntemi)** â€” yani *MachineLearningAlgorithm1*
* AlgoritmanÄ±n **parametreleri (argÃ¼manlarÄ±)**

AlgoritmayÄ± seÃ§mek ve bu parametreleri yapÄ±landÄ±rmak, pratikte oldukÃ§a zor olabilir.

Ã–rneÄŸin, algoritma seÃ§imini ele alalÄ±m:
Yeni baÅŸlayan biri olarak tipik yaklaÅŸÄ±m, bazÄ± Ã¶ÄŸrenme kaynaklarÄ±nÄ± toplamak, benzer gÃ¶revlerde kullanÄ±lan kodlarÄ± incelemek ve elinizdeki problem iÃ§in kullanabileceÄŸiniz bir grup ML algoritmasÄ±nÄ± belirlemektir.
Daha sonra bu algoritmalarÄ± (listeleme 1.1â€™de yaptÄ±ÄŸÄ±mÄ±z gibi) geÃ§miÅŸ verileriniz Ã¼zerinde tek tek deneyebilir ve **gÃ¶rsellerdeki rakamlarÄ± tanÄ±ma baÅŸarÄ±sÄ±na** gÃ¶re en iyi performans gÃ¶stereni seÃ§ebilirsiniz.

Bu tekrarlayÄ±cÄ± sÃ¼reÃ§, bir sonraki kod Ã¶rneÄŸinde Ã¶zetlenmiÅŸtir.

```Python
ml_algorithm_pool = [
    MachineLearningAlgorithm1,
    MachineLearningAlgorithm2,
    ...,
    MachineLearningAlgorithmN,
]
# Test edilecek ML algoritmalarÄ±nÄ±n bir havuzu

for ml_algorithm in ml_algorithm_pool:
    model = ml_algorithm(
        arg1=..., arg2=...,
        data=historical_images
    )
    # TÃ¼m aday ML algoritmalarÄ±nÄ± dÃ¶ngÃ¼ye sokar
    # Her ML algoritmasÄ±na gÃ¶re bir model oluÅŸturur ve deÄŸerlendirir
    
    result = evaluate(model)
    push result into the result_pool
    push model into the model_pool

best_ml_model = pick_the_best(result_pool, ml_model_pool)
# Performansa gÃ¶re en iyi ML modelini seÃ§er

return best_ml_model
```

Bu sÃ¼reÃ§ ilk bakÄ±ÅŸta sezgisel gÃ¶rÃ¼nebilir, ancak yeterli makine Ã¶ÄŸrenimi (ML) bilgisi veya deneyiminiz yoksa **saatlerce hatta gÃ¼nlerce** sÃ¼rebilir â€” bunun birkaÃ§ nedeni vardÄ±r:

Birincisi, uygun ML algoritmalarÄ±ndan oluÅŸan bir **havuz oluÅŸturmak** oldukÃ§a zordur.
LiteratÃ¼rÃ¼ incelemeniz, en son (state-of-the-art) algoritmalarÄ± belirlemeniz ve bunlarÄ±n nasÄ±l uygulanacaÄŸÄ±nÄ± Ã¶ÄŸrenmeniz gerekebilir.

Ä°kincisi, kullanÄ±labilir ML algoritmalarÄ±nÄ±n sayÄ±sÄ± Ã§ok fazla olabilir.
BunlarÄ± **teker teker denemek** hem verimsiz olabilir hem de zaman aÃ§Ä±sÄ±ndan neredeyse imkÃ¢nsÄ±z hale gelebilir.

ÃœÃ§Ã¼ncÃ¼sÃ¼, her algoritmanÄ±n kendine Ã¶zgÃ¼ **parametreleri (argÃ¼manlarÄ±)** vardÄ±r.
Bu parametreleri doÄŸru ÅŸekilde yapÄ±landÄ±rmak; uzmanlÄ±k, deneyim ve bazen de biraz ÅŸans gerektirir.

---

Peki, bunu yapmanÄ±n **daha iyi bir yolu** olabilir mi?
Makinenin bu sÃ¼reci **kendiliÄŸinden (otomatik olarak)** yÃ¼rÃ¼tmesi mÃ¼mkÃ¼n mÃ¼?

EÄŸer benzer sorunlarla karÅŸÄ±laÅŸtÄ±ysanÄ±z ve MLâ€™yi daha az emek harcayarak uygulamak istiyorsanÄ±z, **AutoML** aradÄ±ÄŸÄ±nÄ±z araÃ§ olabilir.

BasitÃ§e sÃ¶ylemek gerekirse, **AutoML**, yukarÄ±daki sÃ¶zde kodda (pseudocode) anlatÄ±lan **manuel sÃ¼reci taklit eder**.
Yani, ML algoritmalarÄ±nÄ± seÃ§me ve yapÄ±landÄ±rma sÃ¼recini **otomatikleÅŸtirmeye** Ã§alÄ±ÅŸÄ±r.
Bu sayede, varlÄ±klarÄ±ndan bile haberdar olmadÄ±ÄŸÄ±nÄ±z **ileri dÃ¼zey algoritmalara** kolayca eriÅŸmenizi saÄŸlar.

---

AÅŸaÄŸÄ±daki iki satÄ±rlÄ±k sÃ¶zde kod, bir AutoML algoritmasÄ±nÄ± kullanarak nasÄ±l bir ML Ã§Ã¶zÃ¼mÃ¼ elde edebileceÄŸinizi gÃ¶sterir:

```python
automl_model = AutoMLAlgorithm()
best_ml_model = automl_model.generate_model(data=historical_images)
```

Bir **AutoML algoritmasÄ±ndan bir AutoML model nesnesi** oluÅŸturmak, test edilecek ML algoritmalarÄ±nÄ±n havuzunu sizin belirlemenize gerek kalmadÄ±ÄŸÄ± anlamÄ±na gelir.
YalnÄ±zca veriyi saÄŸlayarak istediÄŸiniz modeli otomatik olarak oluÅŸturabilirsiniz.

---

Ama ÅŸu sorular hÃ¢lÃ¢ geÃ§erlidir:

* Hangi **AutoML algoritmasÄ±nÄ±** seÃ§melisiniz?
* Bu AutoML sistemi, hangi ML algoritmalarÄ± arasÄ±ndan seÃ§im yapÄ±yor?
* OnlarÄ± nasÄ±l deÄŸerlendiriyor ve en iyi modeli nasÄ±l belirliyor?

Bunlara geÃ§meden Ã¶nce, size **ML hakkÄ±nda temel bir arka plan** sunacaÄŸÄ±m; bÃ¶ylece AutoMLâ€™nin **neyi otomatikleÅŸtirdiÄŸini** ve onu **pratikte nasÄ±l zaman ve emek tasarrufu saÄŸlayacak ÅŸekilde kullanabileceÄŸinizi** daha iyi anlayabilirsiniz.

Buradaki odak, **AutoMLâ€™yi Ã¶ÄŸrenmek ve kullanmak iÃ§in bilmeniz gerekenleri** aÃ§Ä±klamak olacak.
Bu algoritmalar hakkÄ±nda daha derin bilgi edinmek isterseniz ÅŸu kaynaklara baÅŸvurabilirsiniz:

* *Machine Learning in Action* â€” Peter Harrington (Manning, 2012)
* *Deep Learning with Python*, 2. baskÄ± â€” FranÃ§ois Chollet (Manning, 2021)

Makine Ã¶ÄŸreniminin temellerine zaten aÅŸina olan okuyucular iÃ§in ise sonraki bÃ¶lÃ¼m bir **Ã¶zet** niteliÄŸinde olacak; terimleri netleÅŸtirecek ve AutoMLâ€™ye yapÄ±lacak giriÅŸ iÃ§in **temel motivasyonu** oluÅŸturacaktÄ±r.

### 1.2 Getting started with machine learning â€“ 6

Bu bÃ¶lÃ¼m, makine Ã¶ÄŸrenimine (ML) kÄ±sa bir giriÅŸ sunar â€” **MLâ€™nin ne olduÄŸunu**, bir **ML algoritmasÄ±nÄ±n temel bileÅŸenlerini** ve **seÃ§ilen algoritma ile veri girdisine dayalÄ± olarak bir ML modelinin nasÄ±l oluÅŸturulduÄŸunu** aÃ§Ä±klar.

Bu temel bilgileri Ã¶ÄŸrenmek, sonraki bÃ¶lÃ¼mlerde tanÄ±tÄ±lacak **AutoML kavramlarÄ±nÄ±** anlamak iÃ§in oldukÃ§a Ã¶nemlidir.

#### *What is machine learning?* â€“ 6

Makine Ã¶ÄŸreniminin (ML) ortaya Ã§Ä±kÄ±ÅŸÄ±ndan Ã¶nce, yapay zekÃ¢ (YZ) araÅŸtÄ±rmalarÄ±nda baskÄ±n paradigma **sembolik yapay zekÃ¢ (symbolic AI)** idi. Bu yaklaÅŸÄ±mda bilgisayar, yalnÄ±zca insanlar tarafÄ±ndan **Ã¶nceden tanÄ±mlanmÄ±ÅŸ kurallar** aracÄ±lÄ±ÄŸÄ±yla verileri iÅŸleyebiliyordu.

MLâ€™nin ortaya Ã§Ä±kÄ±ÅŸÄ±yla birlikte programlama paradigmasÄ± kÃ¶kten deÄŸiÅŸti â€” bilgisayarlara bilgiyi **verilerden dolaylÄ± olarak Ã¶ÄŸrenme** yeteneÄŸi kazandÄ±rÄ±ldÄ±.

Ã–rneÄŸin, bir makinenin elma ve muz gÃ¶rÃ¼ntÃ¼lerini otomatik olarak tanÄ±masÄ±nÄ± istediÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n.
Sembolik YZ yaklaÅŸÄ±mÄ±nda, bu gÃ¶revi gerÃ§ekleÅŸtirebilmesi iÃ§in yapay zekÃ¢ya **renk** ve **ÅŸekil** gibi Ã¶zellikleri tanÄ±mlayan, insan tarafÄ±ndan okunabilir **mantÄ±ksal kurallar** vermeniz gerekirdi.

Buna karÅŸÄ±lÄ±k, bir ML algoritmasÄ± yalnÄ±zca bir dizi **gÃ¶rÃ¼ntÃ¼** ve bunlara karÅŸÄ±lÄ±k gelen **etiketleri** (â€œelmaâ€ veya â€œmuzâ€) alÄ±r ve bunlardan **Ã¶ÄŸrenilmiÅŸ kurallar** Ã¼retir. Bu kurallar daha sonra **etiketi bilinmeyen yeni gÃ¶rÃ¼ntÃ¼leri** tahmin etmek iÃ§in kullanÄ±labilir (bkz. ÅŸekil 1.2).

![image](./images/0002.png) 

MLâ€™nin temel amaÃ§larÄ± **otomasyon** ve **genelleme**dir.

* **Otomasyon**, bir ML algoritmasÄ±nÄ±n kendisine verilen veriler Ã¼zerinde **insan mÃ¼dahalesi olmadan kurallar (veya Ã¶rÃ¼ntÃ¼ler) Ã§Ä±karmayÄ±** Ã¶ÄŸrenmesi anlamÄ±na gelir.
  Algoritma, insan dÃ¼ÅŸÃ¼nme biÃ§imini taklit eder ve kendisine saÄŸlanan geÃ§miÅŸ verilerle etkileÅŸime girerek kendini geliÅŸtirir â€” bu sÃ¼rece **eÄŸitim (training)** ya da **Ã¶ÄŸrenme (learning)** denir.

* Bu kurallar daha sonra **insan mÃ¼dahalesine gerek kalmadan yeni veriler Ã¼zerinde tekrarlayan tahminler** yapmak iÃ§in kullanÄ±lÄ±r.

Ã–rneÄŸin, ÅŸekil 1.2â€™de ML algoritmasÄ± elma ve muz gÃ¶rÃ¼ntÃ¼leriyle etkileÅŸime girer ve **renge dayalÄ± bir kural** Ã§Ä±karÄ±r; bu sayede eÄŸitimi sÄ±rasÄ±nda onlarÄ± tanÄ±mayÄ± Ã¶ÄŸrenir.
Bu kurallar, makinenin **yeni gÃ¶rÃ¼ntÃ¼leri insan denetimi olmadan sÄ±nÄ±flandÄ±rmasÄ±na** olanak tanÄ±r â€” bu yeteneÄŸe **yeni verilere genelleme (generalization)** denir.

Bir ML algoritmasÄ±nÄ±n iyi olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirmenin en Ã¶nemli kriterlerinden biri, **genelleme yeteneÄŸidir**.

Ã–rneÄŸin, sisteme **sarÄ± bir elma** gÃ¶rÃ¼ntÃ¼sÃ¼ verildiÄŸini varsayalÄ±m.
EÄŸer algoritma yalnÄ±zca renge dayalÄ± bir kural Ã¶ÄŸrenmiÅŸse, bunun elma mÄ± yoksa muz mu olduÄŸunu doÄŸru bir ÅŸekilde ayÄ±rt edemeyecektir.
Buna karÅŸÄ±lÄ±k, **ÅŸekil Ã¶zelliÄŸini** de Ã¶ÄŸrenip tahminlerinde kullanan bir ML algoritmasÄ± **daha doÄŸru tahminler** Ã¼retebilir.


#### *The machine learning process* â€“ 7

Bir makine Ã¶ÄŸrenimi (ML) algoritmasÄ±, **Ã§Ä±ktÄ±larÄ± bilinen Ã¶rneklere maruz kalarak** kurallarÄ± Ã¶ÄŸrenir.
Bu kurallarÄ±n amacÄ±, **girdileri anlamlÄ± Ã§Ä±ktÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmeyi** mÃ¼mkÃ¼n kÄ±lmaktÄ±r â€” Ã¶rneÄŸin, el yazÄ±sÄ± rakamlarÄ±n gÃ¶rÃ¼ntÃ¼lerini ilgili sayÄ±lara Ã§evirmek gibi.
Bu nedenle Ã¶ÄŸrenmenin hedefi, **veri dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ (data transformation)** mÃ¼mkÃ¼n kÄ±lmak olarak da dÃ¼ÅŸÃ¼nÃ¼lebilir.

Ã–ÄŸrenme sÃ¼reci genellikle aÅŸaÄŸÄ±daki iki bileÅŸeni gerektirir:

---

* **Veri girdileri (Data inputs):**
  ML algoritmasÄ±na beslenecek, hedef gÃ¶reve ait veri Ã¶rnekleridir.
  Ã–rneÄŸin, gÃ¶rÃ¼ntÃ¼ tanÄ±ma probleminde (bkz. Åekil 1.2) bir grup **elma ve muz resmi** ile bunlara karÅŸÄ±lÄ±k gelen **etiketler** (â€œelmaâ€ veya â€œmuzâ€) bu girdilerdir.

* **Ã–ÄŸrenme algoritmasÄ± (Learning algorithm):**
  Verilen veriye dayalÄ± olarak bir **model** tÃ¼reten matematiksel bir sÃ¼reÃ§tir ve ÅŸu dÃ¶rt unsuru iÃ§erir:

  * Veriden Ã¶ÄŸrenilecek **parametrelere sahip bir ML modeli**
  * Modelin mevcut parametrelerle performansÄ±nÄ± Ã¶lÃ§mek iÃ§in bir **Ã¶lÃ§Ã¼m yÃ¶ntemi** (Ã¶rneÄŸin tahmin doÄŸruluÄŸu)
  * Modeli gÃ¼ncellemenin bir yolu â€” buna **optimizasyon yÃ¶ntemi** denir
  * Ã–ÄŸrenme sÃ¼recinin **ne zaman duracaÄŸÄ±nÄ± belirleyen bir durdurma Ã¶lÃ§Ã¼tÃ¼ (stop criterion)**

---

Modelin parametreleri ilk kez baÅŸlatÄ±ldÄ±ktan sonra (Ã¶rneÄŸin rastgele veya benzer modellerden Ã¶ÄŸrenilmiÅŸ â€œwarm startâ€ parametreleriyle), Ã¶ÄŸrenme algoritmasÄ± **parametreleri Ã¶lÃ§Ã¼m sonucuna gÃ¶re adÄ±m adÄ±m gÃ¼ncelleyerek** modeli iteratif biÃ§imde geliÅŸtirir.
Bu Ã¶lÃ§Ã¼m, **eÄŸitim aÅŸamasÄ±nda â€œkayÄ±p fonksiyonuâ€ (loss function)** veya **amaÃ§ fonksiyonu (objective function)** olarak adlandÄ±rÄ±lÄ±r ve modelin tahminleriyle gerÃ§ek (ground-truth) hedefler arasÄ±ndaki farkÄ± Ã¶lÃ§er.
Bu sÃ¼reÃ§ Åekil 1.3â€™te gÃ¶sterilmektedir.

---

Ã–ÄŸrenme sÃ¼recini daha iyi anlamak iÃ§in bir Ã¶rnek dÃ¼ÅŸÃ¼nelim:
Ä°ki boyutlu bir uzayda bir grup veri noktamÄ±z olduÄŸunu varsayalÄ±m (bkz. Åekil 1.4).
Her nokta **siyah** veya **beyaz** renktedir.
AmacÄ±mÄ±z, yeni bir nokta geldiÄŸinde konumuna gÃ¶re bunun siyah mÄ± yoksa beyaz mÄ± olduÄŸunu belirleyebilen bir ML modeli oluÅŸturmak.

Bu hedefe ulaÅŸmanÄ±n basit bir yolu, elimizdeki noktalara bakarak iki boyutlu uzayÄ± ikiye ayÄ±ran **yatay bir Ã§izgi** Ã§izmektir.
Bu Ã§izgi, bir ML modeli olarak dÃ¼ÅŸÃ¼nÃ¼lebilir.
Ã‡izginin **parametresi**, yatay konumudur ve bu parametre veri noktalarÄ±na gÃ¶re **Ã¶ÄŸrenilebilir ve gÃ¼ncellenebilir**.

Åekil 1.3â€™te aÃ§Ä±klanan Ã¶ÄŸrenme sÃ¼reciyle birlikte, gerekli bileÅŸenleri ÅŸu ÅŸekilde tanÄ±mlayabiliriz:

![image](./images/0003.png)

* **Veri girdileri:**
  Ä°ki boyutlu uzayda konumlarÄ±yla tanÄ±mlanan siyah ve beyaz noktalardan oluÅŸur.

* **Ã–ÄŸrenme algoritmasÄ±:**
  AÅŸaÄŸÄ±daki dÃ¶rt bileÅŸenden oluÅŸur:

  * **ML modeli:**  y = a ÅŸeklinde formÃ¼le edilen yatay bir Ã§izgi; burada *a*, algoritma tarafÄ±ndan gÃ¼ncellenebilen parametredir.
  * **DoÄŸruluk Ã¶lÃ§Ã¼mÃ¼:**  Modelin doÄŸru etiketlediÄŸi noktalarÄ±n yÃ¼zdesi.
  * **Optimizasyon yÃ¶ntemi:**  Ã‡izgiyi her yinelemede belirli bir mesafe yukarÄ± veya aÅŸaÄŸÄ± kaydÄ±rmak.
    Bu mesafe, her adÄ±mda doÄŸruluk Ã¶lÃ§Ã¼mÃ¼nÃ¼n deÄŸerine baÄŸlÄ±dÄ±r. Durdurma koÅŸulu saÄŸlanana kadar devam eder.
  * **Durdurma Ã¶lÃ§Ã¼tÃ¼ (stop criterion):**  Ã–lÃ§Ã¼m %100â€™e ulaÅŸtÄ±ÄŸÄ±nda, yani tÃ¼m noktalar mevcut Ã§izgiye gÃ¶re doÄŸru etiketlendiÄŸinde sÃ¼reci durdurur.

![image](./images/0004.png)

Åekil 1.4â€™teki Ã¶rnekte, Ã¶ÄŸrenme algoritmasÄ± iki yinelemeden sonra tÃ¼m noktalarÄ± doÄŸru ÅŸekilde ayÄ±ran Ã§izgiyi elde eder.
Ancak pratikte bu koÅŸul her zaman saÄŸlanmayabilir.
Bu durum, **girdi verilerinin daÄŸÄ±lÄ±mÄ±na**, **seÃ§ilen model tÃ¼rÃ¼ne** ve **modelin nasÄ±l Ã¶lÃ§Ã¼lÃ¼p gÃ¼ncellendiÄŸine** baÄŸlÄ±dÄ±r.

Ã‡oÄŸu zaman farklÄ± bileÅŸenler seÃ§memiz ve farklÄ± kombinasyonlarÄ± denememiz gerekir ki Ã¶ÄŸrenme sÃ¼reci beklenen ML Ã§Ã¶zÃ¼mÃ¼ne yaklaÅŸsÄ±n.

AyrÄ±ca, Ã¶ÄŸrenilmiÅŸ model tÃ¼m eÄŸitim verilerini doÄŸru ÅŸekilde etiketlese bile, **gÃ¶rÃ¼lmemiÅŸ yeni verilerde** aynÄ± baÅŸarÄ±yÄ± garanti etmez.
Yani modelin **genelleme yeteneÄŸi** zayÄ±f olabilir (bu konuyu bir sonraki bÃ¶lÃ¼mde daha detaylÄ± ele alacaÄŸÄ±z).

Bu nedenle, Ã¶ÄŸrenme bileÅŸenlerini dikkatli seÃ§mek ve Ã¶ÄŸrenme sÃ¼recini doÄŸru ÅŸekilde ayarlamak son derece Ã¶nemlidir.

#### *Hyperparameter tuning* â€“ 9

Ã–ÄŸrenme sÃ¼recini ayarlayarak beklenen modeli elde edebilmek iÃ§in uygun bileÅŸenleri nasÄ±l seÃ§eriz?
Bu soruyu yanÄ±tlamak iÃ§in **hiperparametreler (hyperparameters)** adÄ± verilen bir kavramÄ± tanÄ±tmamÄ±z ve bunlarÄ±n, ÅŸimdiye kadar bahsettiÄŸimiz **parametrelerle** iliÅŸkisini aÃ§Ä±klamamÄ±z gerekir:

---

* **Parametreler**, Ã¶ÄŸrenme sÃ¼reci sÄ±rasÄ±nda makine Ã¶ÄŸrenimi (ML) algoritmasÄ± tarafÄ±ndan gÃ¼ncellenebilen deÄŸiÅŸkenlerdir.
  Bu deÄŸiÅŸkenler, veriden kurallarÄ± Ã¶ÄŸrenmek iÃ§in kullanÄ±lÄ±r.
  Ã–rneÄŸin, Ã¶nceki Ã¶rneÄŸimizdeki (Åekil 1.4) yatay Ã§izginin konumu, noktalarÄ± sÄ±nÄ±flandÄ±rmaya yardÄ±mcÄ± olan tek parametredir.
  Bu parametre, optimizasyon yÃ¶ntemi tarafÄ±ndan eÄŸitim sÃ¼reci boyunca ayarlanarak farklÄ± renklerdeki noktalarÄ± ayÄ±rmak iÃ§in gereken konum kuralÄ±nÄ± Ã¶ÄŸrenir.
  Parametreleri ayarlayarak, verilen girdi verisinin Ã§Ä±ktÄ±sÄ±nÄ± doÄŸru bir ÅŸekilde tahmin edebilen bir ML modeli elde edebiliriz.

---

Åekil 1.4

**Ã–ÄŸrenme sÃ¼reci Ã¶rneÄŸi:** Beyaz ve siyah noktalarÄ± ayÄ±ran yatay bir Ã§izginin Ã¶ÄŸrenilmesi

---

* **Hiperparametreler** de bir tÃ¼r parametredir; ancak bunlar Ã¶ÄŸrenme sÃ¼reci baÅŸlamadan **Ã¶nce** algoritma iÃ§in tanÄ±mlanÄ±r ve sÃ¼recin tamamÄ± boyunca sabit kalÄ±r.
  Bunlara Ã¶lÃ§Ã¼m yÃ¶ntemi, optimizasyon metodu, Ã¶ÄŸrenme hÄ±zÄ±, durdurma kriteri gibi unsurlar dahildir.
  Bir ML algoritmasÄ±nÄ±n genellikle birden fazla hiperparametresi vardÄ±r.
  Bu hiperparametrelerin farklÄ± kombinasyonlarÄ±, Ã¶ÄŸrenme sÃ¼reci Ã¼zerinde farklÄ± etkiler yaratÄ±r ve farklÄ± performanslara sahip modellerin ortaya Ã§Ä±kmasÄ±na neden olur.
  AyrÄ±ca, algoritma tÃ¼rÃ¼nÃ¼ (veya ML modeli tÃ¼rÃ¼nÃ¼) de bir hiperparametre olarak dÃ¼ÅŸÃ¼nebiliriz; Ã§Ã¼nkÃ¼ bu seÃ§imi biz yaparÄ±z ve bu seÃ§im sÃ¼reÃ§ boyunca sabit kalÄ±r.

---

Bir ML algoritmasÄ± iÃ§in en uygun hiperparametre kombinasyonunun seÃ§ilmesine **hiperparametre ayarlamasÄ± (hyperparameter tuning)** denir.
Bu iÅŸlem genellikle **yinelemeli (iteratif)** bir sÃ¼reÃ§tir.
Her yinelemede, belirli bir hiperparametre kÃ¼mesi seÃ§ilir ve bu kÃ¼me kullanÄ±larak eÄŸitim veri kÃ¼mesiyle bir ML modeli eÄŸitilir.
Åekil 1.5â€™teki â€œML algoritmasÄ±â€ bloÄŸu, Åekil 1.3â€™te aÃ§Ä±klanan Ã¶ÄŸrenme sÃ¼recini temsil eder.
Her Ã¶ÄŸrenilen model, **doÄŸrulama kÃ¼mesi (validation set)** adÄ± verilen ayrÄ± bir veri kÃ¼mesinde deÄŸerlendirilir ve en iyi performans gÃ¶steren model, **nihai model (final model)** olarak seÃ§ilir.
Bu modelin **genellenebilirliÄŸi (generalizability)** ise, **test kÃ¼mesi (test set)** adÄ± verilen baÅŸka bir veri kÃ¼mesi Ã¼zerinde test edilerek Ã¶lÃ§Ã¼lÃ¼r.
Bu aÅŸama, tÃ¼m ML iÅŸ akÄ±ÅŸÄ±nÄ± tamamlar.

![image](./images/0006.png)

---

Genel olarak, ML iÅŸ akÄ±ÅŸÄ±nda Ã¼Ã§ farklÄ± veri kÃ¼mesi bulunur ve her biri diÄŸerlerinden farklÄ±dÄ±r:

* **EÄŸitim kÃ¼mesi (training set):**
  Belirli bir hiperparametre kombinasyonu ile modeli eÄŸitmek iÃ§in kullanÄ±lÄ±r.

* **DoÄŸrulama kÃ¼mesi (validation set):**
  EÄŸitilen modelleri deÄŸerlendirmek ve en iyi hiperparametreleri seÃ§mek iÃ§in kullanÄ±lÄ±r.

* **Test kÃ¼mesi (test set):**
  Ayarlama sÃ¼reci tamamlandÄ±ktan sonra, son modeli test etmek iÃ§in yalnÄ±zca bir kez kullanÄ±lÄ±r.
  Bu kÃ¼me, **eÄŸitim veya ayarlama** aÅŸamalarÄ±nda kullanÄ±lmamalÄ±dÄ±r.

---

EÄŸitim ve test kÃ¼meleri genellikle kolay anlaÅŸÄ±lÄ±r.
Ek bir doÄŸrulama kÃ¼mesi kullanmamÄ±zÄ±n nedeni, ayarlama aÅŸamalarÄ±nda algoritmanÄ±n tÃ¼m eÄŸitim verisine maruz kalmasÄ±nÄ± Ã¶nlemektir.
Bu sayede **nihai modelin, daha Ã¶nce gÃ¶rÃ¼lmemiÅŸ veriler (unseen data)** Ã¼zerinde genellenebilirliÄŸi artar.

EÄŸer doÄŸrulama kÃ¼mesi kullanÄ±lmazsa, ayarlama aÅŸamasÄ±nda seÃ§ilen â€œen iyiâ€ model yalnÄ±zca eÄŸitim verisindeki kÃ¼Ã§Ã¼k ayrÄ±ntÄ±larÄ± yakalamaya odaklanÄ±r ve sÃ¼rekli artan eÄŸitim doÄŸruluÄŸuna raÄŸmen, farklÄ± veriler Ã¼zerinde kÃ¶tÃ¼ performans gÃ¶sterir.
Modelin, test (veya doÄŸrulama) kÃ¼mesinde eÄŸitim kÃ¼mesine gÃ¶re daha kÃ¶tÃ¼ performans gÃ¶stermesi durumuna **aÅŸÄ±rÄ± uyum (overfitting)** denir.

Bu, ML alanÄ±nda Ã§ok iyi bilinen bir problemdir ve genellikle modelin Ã¶ÄŸrenme kapasitesi Ã§ok yÃ¼ksek, eÄŸitim veri kÃ¼mesi ise sÄ±nÄ±rlÄ± olduÄŸunda ortaya Ã§Ä±kar.

---

**Ã–rnek:**
Ä°lk Ã¼Ã§ sayÄ±sÄ± verilen bir dizide dÃ¶rdÃ¼ncÃ¼ sayÄ±yÄ± tahmin etmek istediÄŸimizi varsayalÄ±m:
aâ‚ = 1, aâ‚‚ = 2, aâ‚ƒ = 3, aâ‚„ = ?
(Burada aâ‚„ doÄŸrulama kÃ¼mesidir; aâ‚… ve sonrakiler test kÃ¼meleridir.)
DoÄŸru cevap aâ‚„ = 4â€™tÃ¼r.
Basit bir model olan **aáµ¢ = i**, doÄŸru sonucu verir.
Ancak Ã¼Ã§Ã¼ncÃ¼ dereceden bir polinomla diziyi uydurursak:
**aáµ¢ = iÂ³ â€“ 6iÂ² + 12i â€“ 6**
modeli, aâ‚„ iÃ§in 10 sonucunu tahmin eder.

DoÄŸrulama sÃ¼reci, bir modelin **genelleme yeteneÄŸinin** deÄŸerlendirme sÄ±rasÄ±nda daha doÄŸru bir ÅŸekilde yansÄ±tÄ±lmasÄ±nÄ± saÄŸlar ve bÃ¶ylece daha uygun modellerin seÃ§ilmesine olanak tanÄ±r.

---

**NOT:**
**AÅŸÄ±rÄ± uyum (overfitting)**, ML alanÄ±nda en Ã¶nemli problemlerden biridir.
Ayarlama sÃ¼reci sÄ±rasÄ±nda doÄŸrulama yapmak dÄ±ÅŸÄ±nda, bu sorunu Ã§Ã¶zmenin baÅŸka yollarÄ± da vardÄ±r; Ã¶rneÄŸin:

* veri kÃ¼mesini geniÅŸletmek (data augmentation),
* modele **regularization (dÃ¼zenleme)** ekleyerek Ã¶ÄŸrenme kapasitesini sÄ±nÄ±rlamak, vb.

Bu konunun ayrÄ±ntÄ±larÄ±na burada girmeyeceÄŸiz.
Daha fazla bilgi iÃ§in **FranÃ§ois Cholletâ€™in *Deep Learning with Python*** adlÄ± kitabÄ±na baÅŸvurabilirsiniz.

#### *The obstacles to applying machine learning* â€“ 11

Bu noktada, makine Ã¶ÄŸreniminin (ML) ne olduÄŸunu ve nasÄ±l iÅŸlediÄŸini temel dÃ¼zeyde anlamÄ±ÅŸ olmalÄ±sÄ±nÄ±z.
BirÃ§ok geliÅŸmiÅŸ ML araÃ§ setinden yararlanabilseniz de, uygulamada hÃ¢lÃ¢ bazÄ± zorluklarla karÅŸÄ±laÅŸabilirsiniz.
Bu bÃ¶lÃ¼mde, bu zorluklardan bazÄ±larÄ± aÃ§Ä±klanmaktadÄ±r â€” amaÃ§ sizi korkutmak deÄŸil, ilerleyen kÄ±sÄ±mlarda anlatÄ±lacak **Otomatik Makine Ã–ÄŸrenimi (AutoML)** teknikleri iÃ§in bir baÄŸlam saÄŸlamaktÄ±r.

KarÅŸÄ±laÅŸabileceÄŸiniz baÅŸlÄ±ca engeller ÅŸunlardÄ±r:

---

* **ML tekniklerini Ã¶ÄŸrenmenin maliyeti:**
  Temel bilgileri ele aldÄ±k, ancak MLâ€™i gerÃ§ek bir probleme uygulamak iÃ§in Ã§ok daha fazla bilgi gerekir.
  Ã–rneÄŸin, probleminizi bir ML problemi olarak nasÄ±l formÃ¼le edeceÄŸinizi, hangi ML algoritmalarÄ±nÄ± kullanabileceÄŸinizi ve bunlarÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±,
  veriyi ML algoritmasÄ±na girdi olarak verebilmek iÃ§in nasÄ±l temizleyip Ã¶n iÅŸlemeden geÃ§irmeniz gerektiÄŸini,
  model eÄŸitimi ve hiperparametre ayarlamasÄ± (tuning) iÃ§in hangi deÄŸerlendirme kriterlerini seÃ§meniz gerektiÄŸini dÃ¼ÅŸÃ¼nmelisiniz.
  TÃ¼m bu sorularÄ±n Ã¶nceden yanÄ±tlanmasÄ± gerekir ve bu da Ã¶nemli bir zaman yatÄ±rÄ±mÄ± gerektirir.

---

* **Uygulama karmaÅŸÄ±klÄ±ÄŸÄ±:**
  Gerekli bilgi ve deneyime sahip olsanÄ±z bile, bir ML algoritmasÄ± seÃ§tikten sonra iÅŸ akÄ±ÅŸÄ±nÄ± uygulamak karmaÅŸÄ±k bir iÅŸtir.
  Daha geliÅŸmiÅŸ algoritmalar benimsendikÃ§e, uygulama ve hata ayÄ±klama (debugging) iÃ§in gereken zaman da artar.

---

* **Teori ile pratik arasÄ±ndaki fark:**
  Ã–ÄŸrenme sÃ¼reci Ã§oÄŸu zaman yorumlanmasÄ± zor bir yapÄ±ya sahiptir ve performans bÃ¼yÃ¼k Ã¶lÃ§Ã¼de veriye baÄŸlÄ±dÄ±r.
  AyrÄ±ca, MLâ€™de kullanÄ±lan veri kÃ¼meleri genellikle karmaÅŸÄ±k, gÃ¼rÃ¼ltÃ¼lÃ¼ (noisy) ve yorumlanmasÄ±, temizlenmesi, kontrol edilmesi zor yapÄ±lardÄ±r.
  Bu nedenle ayarlama (tuning) sÃ¼reci Ã§oÄŸunlukla analitik olmaktan Ã§ok deneysel (ampirik) bir karakter taÅŸÄ±r.
  Hatta ML uzmanlarÄ± bile bazen istenilen sonuÃ§lara ulaÅŸamayabilirler.

---

Bu zorluklar, MLâ€™in sÄ±nÄ±rlÄ± deneyime sahip kiÅŸiler tarafÄ±ndan yaygÄ±n ÅŸekilde kullanÄ±lmasÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de zorlaÅŸtÄ±rÄ±r
ve aynÄ± zamanda ML uzmanlarÄ±nÄ±n Ã¼zerindeki yÃ¼kÃ¼ artÄ±rÄ±r.
Bu durum, araÅŸtÄ±rmacÄ±larÄ±n ve uygulayÄ±cÄ±larÄ±n; engelleri azaltacak, gereksiz adÄ±mlarÄ± ortadan kaldÄ±racak
ve algoritmalarÄ±n manuel tasarÄ±mÄ± ile ayarlama sÃ¼recindeki yÃ¼kÃ¼ hafifletecek bir Ã§Ã¶zÃ¼m arayÄ±ÅŸÄ±na girmesine neden olmuÅŸtur â€”
iÅŸte bu Ã§Ã¶zÃ¼m **AutoML (Otomatik Makine Ã–ÄŸrenimi)**â€™dir.


### 1.3 AutoML: The automation of automation â€“ 12

AutoMLâ€™in amacÄ±, bir makinenin insanlarÄ±n ML algoritmalarÄ±nÄ± tasarlama, ayarlama ve uygulama biÃ§imini taklit etmesini saÄŸlayarak makine Ã¶ÄŸrenimini (ML) daha kolay benimsememizi mÃ¼mkÃ¼n kÄ±lmaktÄ±r (bkz. Åekil 1.6).
Makine Ã¶ÄŸreniminin temel Ã¶zelliklerinden biri **otomasyon** olduÄŸundan, **AutoML**, â€œotomasyonun otomatikleÅŸtirilmesiâ€ olarak da gÃ¶rÃ¼lebilir.

![image](./images/0007.png) 

AutoMLâ€™in nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamanÄ±za yardÄ±mcÄ± olmak iÃ§in, Ã¶nce temel bileÅŸenlerini gÃ¶zden geÃ§irelim.

#### *Three key components of AutoML* â€“ 12
Ä°ÅŸte, BÃ¶lÃ¼m 1.1â€™de tanÄ±tÄ±lan sÃ¶zde kodun (pseudocode) kÄ±sa bir Ã¶zeti:

```
ml_algorithm_pool = [
 MachineLearningAlgorithm1,
 MachineLearningAlgorithm2,
 ...
 MachineLearningAlgorithmN,
]

for ml_algorithm in ml_algorithm_pool:
 model = ml_algorithm(arg1=..., arg2=..., data=historical_images)
 result = evaluate(model)
 push result into the result_pool
 push model into the model_pool

best_ml_model = pick_the_best(result_pool, ml_model_pool)
return best_ml_model
```

Bu sÃ¶zde kod, bir **AutoML algoritmasÄ±**nÄ±n basit bir Ã¶rneÄŸi olarak gÃ¶rÃ¼lebilir.
Bu algoritma, bir grup ML algoritmasÄ±nÄ± girdi olarak alÄ±r, her birini sÄ±rayla deÄŸerlendirir ve en iyi sonucu veren algoritmadan Ã¶ÄŸrenilmiÅŸ modeli Ã§Ä±ktÄ± olarak verir.

Her AutoML algoritmasÄ±, aÅŸaÄŸÄ±daki **Ã¼Ã§ temel bileÅŸenden** oluÅŸur (bkz. Åekil 1.7):

![image](./images/0008.png) 

---

##### 1. **Arama uzayÄ± (Search space)**

Bu, seÃ§ilecek hiperparametreler kÃ¼mesini ve her bir hiperparametrenin alabileceÄŸi deÄŸer aralÄ±ÄŸÄ±nÄ± ifade eder.
Her hiperparametrenin aralÄ±ÄŸÄ±, kullanÄ±cÄ±nÄ±n bilgi birikimine ve gereksinimlerine gÃ¶re tanÄ±mlanabilir.

Ã–rneÄŸin, sÃ¶zde kodda gÃ¶sterildiÄŸi gibi arama uzayÄ± bir **ML algoritmalarÄ± havuzu** olabilir.
Bu durumda, **ML algoritmasÄ±nÄ±n tÃ¼rÃ¼** seÃ§ilecek bir hiperparametre olarak kabul edilir.

Arama uzayÄ± aynÄ± zamanda belirli bir ML algoritmasÄ±nÄ±n hiperparametrelerinden (Ã¶rneÄŸin modelin yapÄ±sÄ± gibi) de oluÅŸabilir.
Arama uzayÄ±nÄ±n tasarÄ±mÄ± bÃ¼yÃ¼k Ã¶lÃ§Ã¼de gÃ¶reve baÄŸlÄ±dÄ±r, Ã§Ã¼nkÃ¼ farklÄ± gÃ¶revler iÃ§in farklÄ± ML algoritmalarÄ±nÄ±n benimsenmesi gerekebilir.
AyrÄ±ca kullanÄ±cÄ±nÄ±n ilgisi, uzmanlÄ±ÄŸÄ± ve deneyim dÃ¼zeyiyle de kiÅŸiselleÅŸmiÅŸ bir yapÄ±ya sahip olabilir.

Burada her zaman bir denge vardÄ±r:

* GeniÅŸ bir arama uzayÄ± tanÄ±mlamak, daha fazla olasÄ±lÄ±ÄŸÄ± deÄŸerlendirmenizi saÄŸlar ama
* iyi bir model bulmak iÃ§in harcanacak sÃ¼reyi ve hesaplama maliyetini artÄ±rÄ±r.

Yeni baÅŸlayanlar iÃ§in, tÃ¼m ML algoritmalarÄ±nÄ± iÃ§eren Ã§ok geniÅŸ bir arama uzayÄ± tanÄ±mlamak cazip gelebilir.
Ancak bu yaklaÅŸÄ±m, **zaman** ve **hesaplama maliyeti** aÃ§Ä±sÄ±ndan verimsizdir.

Bu kitapta, ikinci bÃ¶lÃ¼mde bu konuyu daha ayrÄ±ntÄ±lÄ± ele alacak ve farklÄ± gereksinimler doÄŸrultusunda arama uzayÄ±nÄ±zÄ± nasÄ±l Ã¶zelleÅŸtirebileceÄŸinizi Ã¶ÄŸreneceksiniz.


---

##### 2. **Arama stratejisi (Search strategy)**

Bu, arama uzayÄ±ndan **en uygun hiperparametre setini** seÃ§me stratejisidir.
AutoML genellikle **yinelemeli bir deneme-yanÄ±lma sÃ¼reci** olduÄŸundan, strateji Ã§oÄŸunlukla hiperparametreleri sÄ±rayla seÃ§ip performanslarÄ±nÄ± deÄŸerlendirir.

Strateji, arama uzayÄ±ndaki tÃ¼m hiperparametreleri tek tek deneyebilir (sÃ¶zde kodda olduÄŸu gibi)
ya da daha Ã¶nce denenen hiperparametrelerin sonuÃ§larÄ±na gÃ¶re sonraki denemeleri optimize edecek ÅŸekilde **uyarlanabilir (adaptive)** bir yapÄ± izleyebilir.

Daha iyi bir arama stratejisi, aynÄ± sÃ¼rede **daha iyi bir ML Ã§Ã¶zÃ¼mÃ¼** elde etmenizi saÄŸlar.
AyrÄ±ca, arama sÃ¼resini ve hesaplama maliyetini azaltarak daha bÃ¼yÃ¼k bir arama uzayÄ±nÄ± kullanmanÄ±za da olanak tanÄ±r.

Bu kitapta, Ã¼Ã§Ã¼ncÃ¼ bÃ¶lÃ¼mde farklÄ± **arama algoritmalarÄ±nÄ±** nasÄ±l benimseyeceÄŸinizi, karÅŸÄ±laÅŸtÄ±racaÄŸÄ±nÄ±zÄ± ve uygulayacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz.

---

##### 3. **Performans deÄŸerlendirme stratejisi (Performance evaluation strategy)**

Bu strateji, seÃ§ilen hiperparametrelerle oluÅŸturulan bir ML algoritmasÄ±nÄ±n performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r.
DeÄŸerlendirme kriterleri genellikle manuel ayarlama sÃ¼recinde kullanÄ±lanlarla aynÄ±dÄ±r â€” Ã¶rneÄŸin, seÃ§ilen ML algoritmasÄ±yla eÄŸitilen modelin **doÄŸrulama performansÄ±**.

Bu kitapta, farklÄ± tÃ¼rde ML gÃ¶revlerini Ã§Ã¶zmek iÃ§in AutoML kullanÄ±rken uygulanabilecek Ã§eÅŸitli deÄŸerlendirme stratejilerini tartÄ±ÅŸacaÄŸÄ±z.

---

AutoML algoritmalarÄ±nÄ±n benimsenmesini kolaylaÅŸtÄ±rmak iÃ§in, bir **AutoML araÃ§ kiti (toolkit)** genellikle bu Ã¼Ã§ bileÅŸeni bir araya getirir
ve **varsayÄ±lan bir arama uzayÄ±** ile **arama algoritmasÄ±** iÃ§eren genel APIâ€™ler (Application Programming Interfaces) saÄŸlar.
BÃ¶ylece kullanÄ±cÄ±, bu bileÅŸenleri elle seÃ§mek zorunda kalmaz.

KullanÄ±cÄ± aÃ§Ä±sÄ±ndan, en basit durumda yapÄ±lmasÄ± gereken tek ÅŸey veriyi saÄŸlamaktÄ±r â€” veriyi eÄŸitim ve doÄŸrulama kÃ¼melerine ayÄ±rmaya bile gerek yoktur:

```python
automl_model = AutoMLAlgorithm()
best_ml_model = automl_model.generate_model(data=...)
```

Ancak farklÄ± kullanÄ±cÄ±larÄ±n farklÄ± kullanÄ±m senaryolarÄ± ve ML uzmanlÄ±k dÃ¼zeyleri olabileceÄŸi iÃ§in,
kendi **arama uzaylarÄ±nÄ±**, **deÄŸerlendirme stratejilerini** ve hatta **arama stratejilerini** tasarlamalarÄ± gerekebilir.

Bu nedenle, mevcut AutoML sistemleri genellikle bu bileÅŸenlerin yapÄ±landÄ±rÄ±labilir (configurable) biÃ§imde Ã¶zelleÅŸtirilmesine izin veren APIâ€™ler sunar.
Bu APIâ€™ler, **en basitinden en geliÅŸmiÅŸine kadar geniÅŸ bir yelpazede** Ã§Ã¶zÃ¼mler saÄŸlar (bkz. Åekil 1.8).

![image](./images/0009.png)

Bu sayede, kendi kullanÄ±m durumunuza en uygun olan APIâ€™yi seÃ§ebilirsiniz.
Bu kitapta, farklÄ± AutoML uygulamalarÄ± iÃ§in geliÅŸmiÅŸ bir AutoML araÃ§ kiti olan **AutoKeras**â€™ta doÄŸru APIâ€™yi nasÄ±l seÃ§eceÄŸinizi
ve **KerasTuner** yardÄ±mÄ±yla kendi AutoML algoritmanÄ±zÄ± nasÄ±l oluÅŸturabileceÄŸinizi Ã¶ÄŸreneceksiniz.

#### *Are we able to achieve full automation?* â€“ 15

AutoML alanÄ±, endÃ¼stri ve aÃ§Ä±k kaynak topluluÄŸunun katÄ±lÄ±mÄ±yla **yaklaÅŸÄ±k otuz yÄ±ldÄ±r geliÅŸmektedir.**
Bu sÃ¼reÃ§te birÃ§ok baÅŸarÄ±lÄ± uygulama ve umut verici geliÅŸme gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r. Bunlardan bazÄ±larÄ± ÅŸunlardÄ±r:

---

* **BirÃ§ok ÅŸirket iÃ§i araÃ§ ve aÃ§Ä±k kaynak platformu** geliÅŸtirildi.
  Bu araÃ§lar, ML modellerinin **hiperparametre ayarlamasÄ±nÄ±** ve **model seÃ§imini** kolaylaÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r.
  (Ã–rneÄŸin: *Google Vizier*, *Facebook Ax* vb.)

* **AutoML Ã§Ã¶zÃ¼mleri**, birÃ§ok **Kaggle veri bilimi yarÄ±ÅŸmasÄ±nda** insan seviyesine yakÄ±n performans gÃ¶stermiÅŸtir.

* **Auto-sklearn**, **AutoKeras** gibi geniÅŸ kapsamlÄ± aÃ§Ä±k kaynak ML paketleri geliÅŸtirildi.
  Bu paketler, hiperparametre ayarlamasÄ±nÄ± iyileÅŸtirmek ve ML iÅŸ akÄ±ÅŸlarÄ±nÄ± (pipeline) otomatikleÅŸtirmek iÃ§in tasarlanmÄ±ÅŸtÄ±r.

* **Ticari AutoML Ã¼rÃ¼nleri**, kÃ¼Ã§Ã¼kten bÃ¼yÃ¼ÄŸe birÃ§ok ÅŸirketin Ã¼retim ortamÄ±nda MLâ€™i benimsemesine yardÄ±mcÄ± olmaktadÄ±r.
  Ã–rneÄŸin, **Disney**, herhangi bir ML mÃ¼hendisi ekibi tutmadan, **Google Cloud AutoML** kullanarak Ã§evrimiÃ§i maÄŸazasÄ± iÃ§in ML Ã§Ã¶zÃ¼mleri geliÅŸtirmiÅŸtir.
  (Kaynak: [Google Cloud AutoML Blogu](https://blog.google/products/google-cloud/cloud-automlmaking-ai-accessible-every-business/))

* **Bilgisayar bilimi dÄ±ÅŸÄ±ndaki alanlardaki araÅŸtÄ±rmacÄ±lar** da AutoMLâ€™in gÃ¼cÃ¼nden yararlanmaktadÄ±r.
  ArtÄ±k **tÄ±p**, **nÃ¶robilim** ve **ekonomi** gibi alanlardaki araÅŸtÄ±rmacÄ±lar, ML ve programlama konularÄ±nda uzun Ã¶ÄŸrenme sÃ¼reÃ§lerinden geÃ§meden,
  **tÄ±bbi gÃ¶rÃ¼ntÃ¼ segmentasyonu**, **genomik araÅŸtÄ±rma** veya **hayvan tanÄ±ma ve koruma** gibi alanlara Ã¶zel ML Ã§Ã¶zÃ¼mleri geliÅŸtirebilmektedirler.
  *(Ã–rnek Ã§alÄ±ÅŸmalar: Weng et al., 2019; Liu et al., 2019; Liu & Luo, 2019)*

---

##### AutoMLâ€™in GeleceÄŸi ve Devam Eden Zorluklar

AutoMLâ€™in **makine Ã¶ÄŸrenimini demokratikleÅŸtirme** potansiyelinin tÃ¼mÃ¼nÃ¼ hÃ¢lÃ¢ keÅŸfetme aÅŸamasÄ±ndayÄ±z.
Åimdiye kadar pek Ã§ok baÅŸarÄ±lÄ± uygulama gÃ¶rÃ¼lmÃ¼ÅŸ olsa da, Ã§Ã¶zÃ¼lmesi gereken Ã¶nemli zorluklar ve sÄ±nÄ±rlamalar hÃ¢lÃ¢ bulunmaktadÄ±r:

---

* **AutoML sistemlerinin inÅŸa edilme zorluÄŸu:**
  SÄ±fÄ±rdan bir AutoML sistemi kurmak, bir ML sistemini kurmaktan Ã§ok daha karmaÅŸÄ±k ve kapsamlÄ± bir sÃ¼reÃ§tir.

* **Veri toplama ve temizlemenin otomatikleÅŸtirilmesi:**
  AutoML hÃ¢len **verinin toplanmasÄ±, temizlenmesi ve etiketlenmesi** iÃ§in insan mÃ¼dahalesine ihtiyaÃ§ duyar.
  Bu iÅŸlemler genellikle ML algoritmalarÄ±nÄ±n tasarÄ±mÄ±ndan bile daha karmaÅŸÄ±ktÄ±r ve gÃ¼nÃ¼mÃ¼zde AutoML tarafÄ±ndan tam olarak otomatikleÅŸtirilememektedir.
  GÃ¼nÃ¼mÃ¼zde bir AutoML sisteminin Ã§alÄ±ÅŸabilmesi iÃ§in, **aÃ§Ä±k bir gÃ¶rev tanÄ±mÄ±** ve **yÃ¼ksek kaliteli bir veri kÃ¼mesi** gereklidir.

* **AutoML algoritmasÄ±nÄ±n seÃ§imi ve ayarlanmasÄ±nÄ±n maliyeti:**
  â€œ**No Free Lunch (Bedava Ã–ÄŸle YemeÄŸi Yok)**â€ teoremi bize her duruma uygun tek bir AutoML algoritmasÄ±nÄ±n olmadÄ±ÄŸÄ±nÄ± sÃ¶yler.
  ML algoritmalarÄ±nÄ± seÃ§me ve ayarlama sÃ¼recinde tasarruf ettiÄŸiniz Ã§aba, bazen AutoML algoritmasÄ±nÄ± seÃ§mek ve ayarlamak iÃ§in harcayacaÄŸÄ±nÄ±z Ã§abayla **eÅŸitlenebilir veya aÅŸÄ±labilir.**

* **Kaynak maliyetleri:**
  AutoML sÃ¼reci, **zaman** ve **hesaplama kaynaklarÄ±** aÃ§Ä±sÄ±ndan oldukÃ§a maliyetlidir.
  Mevcut AutoML sistemleri, benzer sonuÃ§lara ulaÅŸmak iÃ§in genellikle insan uzmanlardan **daha fazla hiperparametre kombinasyonu** denemek zorundadÄ±r.

* **Ä°nsanâ€“bilgisayar etkileÅŸiminin maliyeti:**
  AutoMLâ€™in Ã¼rettiÄŸi Ã§Ã¶zÃ¼mleri ve ayarlama sÃ¼reÃ§lerini yorumlamak kolay deÄŸildir.
  Sistemler karmaÅŸÄ±klaÅŸtÄ±kÃ§a, insanlarÄ±n sÃ¼rece mÃ¼dahil olmasÄ± ve modelin nasÄ±l oluÅŸturulduÄŸunu anlamasÄ± daha da zorlaÅŸmaktadÄ±r.

---

##### AutoMLâ€™in GeliÅŸim AÅŸamasÄ±

AutoML hÃ¢lÃ¢ **geliÅŸiminin erken safhasÄ±ndadÄ±r.**
Bu alandaki ilerleme, farklÄ± disiplinlerden **araÅŸtÄ±rmacÄ±larÄ±n, geliÅŸtiricilerin ve uygulayÄ±cÄ±larÄ±n** katÄ±lÄ±mÄ±na baÄŸlÄ±dÄ±r.

Bir gÃ¼n siz de bu geliÅŸime katkÄ±da bulunabilirsiniz; ancak bu kitabÄ±n amacÄ± bundan daha mÃ¼tevazÄ±dÄ±r.
Bu kitap, Ã¶zellikle:

* Makine Ã¶ÄŸreniminde sÄ±nÄ±rlÄ± deneyime sahip uygulayÄ±cÄ±lara
* Ya da temel bilgiye sahip olup ML Ã§Ã¶zÃ¼mlerini daha az Ã§abayla geliÅŸtirmek isteyenlere yÃ¶neliktir.

Kitap, yalnÄ±zca **beÅŸ satÄ±r kodla** bir ML problemini otomatik olarak Ã§Ã¶zmeyi Ã¶ÄŸretecek
ve giderek daha karmaÅŸÄ±k veri tÃ¼rleri (Ã¶rneÄŸin **gÃ¶rseller**, **metinler** vb.) iÃ§in geliÅŸmiÅŸ AutoML Ã§Ã¶zÃ¼mlerine doÄŸru ilerleyecektir.

Bir sonraki bÃ¶lÃ¼mde, MLâ€™in temellerine daha derinlemesine dalacak ve bir ML projesinin **uÃ§tan uca (end-to-end)** iÅŸ akÄ±ÅŸÄ±nÄ± inceleyeceÄŸiz.
Bu, ilerleyen bÃ¶lÃ¼mlerde AutoML tekniklerini daha iyi anlamanÄ±za ve etkili biÃ§imde kullanmanÄ±za yardÄ±mcÄ± olacaktÄ±r.

---

### Ã–zet

* **Makine Ã¶ÄŸrenimi**, bilgisayarlarÄ±n aÃ§Ä±kÃ§a programlanmadan, verilerle etkileÅŸime girerek iÅŸlem biÃ§imlerini deÄŸiÅŸtirebilme yeteneÄŸidir.
* ML sÃ¼reci, modelin parametrelerini veriye ve Ã¶lÃ§Ã¼mlere gÃ¶re ayarlayan yinelemeli bir algoritmik sÃ¼reÃ§tir.
  SÃ¼reÃ§, model beklenen Ã§Ä±ktÄ±larÄ± Ã¼retebildiÄŸinde veya kullanÄ±cÄ± tarafÄ±ndan tanÄ±mlanan bir kriter saÄŸlandÄ±ÄŸÄ±nda durur.
* Bir ML algoritmasÄ±ndaki **hiperparametrelerin ayarlanmasÄ±**, Ã¶ÄŸrenme sÃ¼recini kontrol etmenizi ve probleme Ã¶zel bileÅŸenler seÃ§menizi saÄŸlar.
* **AutoML**, ML modellerinin tasarlanmasÄ± ve uygulanmasÄ±ndan elde edilen deneyimden yararlanarak ayarlama sÃ¼recini otomatikleÅŸtirir.
  BÃ¶ylece veri bilimcilerin Ã¼zerindeki yÃ¼kÃ¼ azaltÄ±r ve kapsamlÄ± deneyim gerektirmeyen, kullanÄ±ma hazÄ±r ML tekniklerini eriÅŸilebilir kÄ±lar.
* Bir AutoML algoritmasÄ± Ã¼Ã§ temel bileÅŸenden oluÅŸur:
  **arama uzayÄ±**, **arama stratejisi** ve **deÄŸerlendirme stratejisi**.
  FarklÄ± AutoML sistemleri, bu bileÅŸenleri sizin iÃ§in yapÄ±landÄ±ran veya Ã¶zelleÅŸtirmenize izin veren farklÄ± dÃ¼zeylerde APIâ€™ler saÄŸlar.
* AutoML hÃ¢len Ã§Ã¶zÃ¼lmemiÅŸ pek Ã§ok zorluk barÄ±ndÄ±rmaktadÄ±r.
  GerÃ§ek anlamda **tam otomatik makine Ã¶ÄŸrenimi** hedefine ulaÅŸmak zordur.
  Bu nedenle **iyimser** olmalÄ±, ancak AutoMLâ€™in mevcut yeteneklerini **abartmamaya** da Ã¶zen gÃ¶stermeliyiz.


## 2. The end-to-end pipeline of an ML project

Ä°lk bÃ¶lÃ¼m sahneyi hazÄ±rladÄ±ÄŸÄ±na gÃ¶re, artÄ±k **ML (Makine Ã–ÄŸrenimi) ve AutoML (Otomatik Makine Ã–ÄŸrenimi)**'nin temel kavramlarÄ±na aÅŸina olma zamanÄ±. AutoML, ML Ã¼zerine kurulu olduÄŸu iÃ§in, ML'nin temellerini Ã¶ÄŸrenmek, AutoML tekniklerini daha iyi anlamanÄ±za ve kullanmanÄ±za yardÄ±mcÄ± olacaktÄ±r. Bu durum, Ã¶zellikle bir AutoML algoritmasÄ±nda, kullanÄ±lacak ML bileÅŸenlerini ve bunlarÄ±n hiperparametre aralÄ±klarÄ±nÄ± belirleyen **arama uzayÄ±nÄ± tasarlama** sÃ¶z konusu olduÄŸunda geÃ§erlidir.

Bu bÃ¶lÃ¼mde, somut bir ML problemini Ã§Ã¶zme Ã¶rneÄŸi Ã¼zerinden ilerleyeceÄŸiz. Bu, Ã¶zellikle ML projelerinde az deneyiminiz varsa, bir ML boru hattÄ±nÄ± (pipeline) oluÅŸturmanÄ±n genel sÃ¼recini daha derinlemesine anlamanÄ±za yardÄ±mcÄ± olacaktÄ±r. AyrÄ±ca, bir ML modelinin **hiperparametrelerini ayarlamanÄ±n basit bir yolunu** da Ã¶ÄŸreneceksiniz. Bu, AutoML'nin en basit uygulamalarÄ±ndan biri olarak dÃ¼ÅŸÃ¼nÃ¼lebilir ve daha iyi bir ML Ã§Ã¶zÃ¼mÃ¼ bulmanÄ±za nasÄ±l yardÄ±mcÄ± olabileceÄŸini gÃ¶sterir. Daha geliÅŸmiÅŸ AutoML gÃ¶revleri ve Ã§Ã¶zÃ¼mleri kitabÄ±n ikinci bÃ¶lÃ¼mÃ¼nde tanÄ±tÄ±lacaktÄ±r.

-----

**NOT:** Bu ve sonraki bÃ¶lÃ¼mlerde yer alan tÃ¼m kod parÃ§acÄ±klarÄ±, **Python** dilinde ve **Jupyter Notebook** biÃ§iminde yazÄ±lmÄ±ÅŸtÄ±r. BunlarÄ±n tamamÄ±, etkileÅŸimli kod tasarÄ±mÄ±, veri iÅŸleme ve gÃ¶rselleÅŸtirme, anlatÄ± metni gibi Ã¶zellikler sunan aÃ§Ä±k kaynaklÄ± bir web uygulamasÄ± olan **Jupyter Notebook** ([https://jupyter.org](https://jupyter.org)) tarafÄ±ndan oluÅŸturulmuÅŸtur. Bu, makine Ã¶ÄŸrenimi ve veri bilimi topluluklarÄ±nda yaygÄ±n olarak popÃ¼lerdir. Ã‡evresel kuruluma aÅŸina deÄŸilseniz veya yeterli donanÄ±m kaynaÄŸÄ±nÄ±z yoksa, kodu herkesin ML deneyleri yapabileceÄŸi Ã¼cretsiz bir Jupyter Notebook ortamÄ± olan **Google Colaboratory** ([http://colab.research.google.com/](https://www.google.com/search?q=http://colab.research.google.com/%24)) (kÄ±saca **Colab**) iÃ§inde de Ã§alÄ±ÅŸtÄ±rabilirsiniz. Google Colaboratory'de ortam kurulumuna iliÅŸkin ayrÄ±ntÄ±lÄ± talimatlar **ek A**'da sunulmuÅŸtur. Notebook'lara ise [https://github.com/datamllab/automl-in-action-notebooks](https://www.google.com/search?q=https://github.com/datamllab/automl-in-action-notebooks%24) adresinden ulaÅŸÄ±labilir.

### 2.1 An overview of the end-to-end pipeline â€“ 18

Bir ML (Makine Ã–ÄŸrenimi) boru hattÄ± (pipeline), bir ML projesini yÃ¼rÃ¼tmek iÃ§in gereken bir dizi ardÄ±ÅŸÄ±k adÄ±mdÄ±r.

---

## Makine Ã–ÄŸrenimi Boru HattÄ±nÄ±n AdÄ±mlarÄ±

1.  **Problemi Ã‡erÃ§eveleme ve Veri Toplama** ğŸ’¡:
    * Ä°lgili sorunu bir **ML problemi** olarak tanÄ±mlayÄ±n.
    * Bu Ã§Ã¶zÃ¼me ulaÅŸmak iÃ§in ihtiyaÃ§ duyduÄŸunuz veriyi toplayÄ±n.

2.  **Veri Ã–n Ä°ÅŸleme ve Ã–zellik MÃ¼hendisliÄŸi** âš™ï¸:
    * Veriyi, ML algoritmalarÄ±na girdi olarak verilebilecek uygun bir formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n.
    * AlgoritmalarÄ±n performansÄ±nÄ± artÄ±rmak amacÄ±yla, hedef Ã§Ä±ktÄ± ile iliÅŸkili olan **Ã¶zellikleri (features)** seÃ§in veya yeni Ã¶zellikler Ã¼retin.
    * Bu adÄ±m, veri kÃ¼mesinin Ã¶zelliklerini anlamak iÃ§in Ã¶ncelikle **keÅŸifsel veri analizi (EDA)** yaparak gerÃ§ekleÅŸtirilir.
    * YapÄ±lan iÅŸlemler, gÃ¶z Ã¶nÃ¼nde bulundurduÄŸunuz belirli ML algoritmalarÄ±na uyumlu olmalÄ±dÄ±r.

3.  **ML AlgoritmasÄ± SeÃ§imi** ğŸ§ :
    * Probleme dair Ã¶nceki bilginize ve deneyiminize dayanarak, test etmek istediÄŸiniz gÃ¶rev iÃ§in **uygun ML algoritmalarÄ±nÄ±** seÃ§in.

4.  **Model EÄŸitimi ve DeÄŸerlendirme** ğŸ“Š:
    * SeÃ§ilen ML algoritmasÄ±nÄ± (veya algoritmalarÄ±nÄ±) uygulayarak eÄŸitim verinizle bir ML modeli **eÄŸitin**.
    * Modelin performansÄ±nÄ± **doÄŸrulama (validation) veri kÃ¼mesi** Ã¼zerinde deÄŸerlendirin.

5.  **Hiperparametre Ayarlama** ğŸ”¬:
    * Modelin **hiperparametrelerini** sÃ¼rekli (tekrarlÄ±, *iteratively*) olarak ayarlayarak daha iyi bir performans elde etmeye Ã§alÄ±ÅŸÄ±n.

6.  **Hizmet DaÄŸÄ±tÄ±mÄ± ve Model Ä°zleme** ğŸ›°ï¸:
    * Nihai ML Ã§Ã¶zÃ¼mÃ¼nÃ¼ **devreye alÄ±n (deploy)**.
    * Boru hattÄ±nÄ± sÃ¼rekli sÃ¼rdÃ¼rebilmek ve iyileÅŸtirebilmek iÃ§in modelin performansÄ±nÄ± **izleyin (monitor)**.

---

GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi, bir ML projesi **insan dÃ¶ngÃ¼sÃ¼ (human-in-the-loop)** iÃ§eren bir sÃ¼reÃ§tir. Problemi Ã§erÃ§eveleme ve veri toplamayla baÅŸlayan bu boru hattÄ±, genellikle **eÅŸ zamansÄ±z (asynchronously)** gerÃ§ekleÅŸen birden fazla veri iÅŸleme adÄ±mÄ±nÄ± iÃ§erir (bkz. ÅŸekil 2.1).

KitabÄ±n geri kalanÄ±nda, hizmet daÄŸÄ±tÄ±mÄ± ve izleme adÄ±mlarÄ± Ã¶ncesindeki adÄ±mlara odaklanÄ±lacaktÄ±r. Modellerin devreye alÄ±nmasÄ± ve hizmet sunumu hakkÄ±nda daha fazla bilgi edinmek iÃ§in Jeff Smith'in *Machine Learning Systems* (Manning, 2018) veya Doug Hudgeon ve Richard Nichol'un *Machine Learning for Business* (Manning, 2019) gibi kaynaklara baÅŸvurabilirsiniz.

![image](images/0010.png) 

Hadi, boru hattÄ±ndaki her bir bileÅŸene aÅŸina olmanÄ±z iÃ§in **gerÃ§ek bir problem** Ã¼zerinde Ã§alÄ±ÅŸmaya baÅŸlayalÄ±m.

Burada inceleyeceÄŸimiz problem, evlerin konumlarÄ± ve oda sayÄ±larÄ± gibi Ã¶zellikler verildiÄŸinde, belirli bir konut bloÄŸundaki **ortalama ev fiyatÄ±nÄ± tahmin etmektir**.

KullanacaÄŸÄ±mÄ±z veri seti, R. Kelley Pace ve Ronald Barry'nin 1997 tarihli "Sparse Spatial Autoregressions" adlÄ± makalesinde yer alan ve 1990 nÃ¼fus sayÄ±mÄ± aracÄ±lÄ±ÄŸÄ±yla toplanan **Kaliforniya Konut veri setidir**. Bu veri seti, kÃ¼Ã§Ã¼k Ã¶lÃ§ekli olmasÄ± ve veri hazÄ±rlÄ±ÄŸÄ±nÄ±n basitliÄŸi nedeniyle, birÃ§ok pratik ML kitabÄ±nda baÅŸlangÄ±Ã§ problemi olarak kullanÄ±lan temsili bir Ã¶rnektir.

---

**NOT:** Ãœzerinde Ã§alÄ±ÅŸÄ±lacak doÄŸru problemi seÃ§mek zor olabilir. Bu, iÅŸ ihtiyaÃ§larÄ±nÄ±z ve araÅŸtÄ±rma hedefleriniz gibi birden fazla faktÃ¶re baÄŸlÄ±dÄ±r. Bir probleme gerÃ§ekten dahil olmadan Ã¶nce, kendinize ÅŸu sorularÄ± sorun:
* "Hangi Ã§Ã¶zÃ¼mlere ulaÅŸmayÄ± bekliyorum?"
* "Bu Ã§Ã¶zÃ¼mler, sonraki (downstream) uygulamalarÄ±ma ne gibi faydalar saÄŸlayacak?"
* "Mevcut Ã§alÄ±ÅŸmalar bu ihtiyacÄ± zaten karÅŸÄ±ladÄ± mÄ±?"

Bu sorular, probleme **yatÄ±rÄ±m yapmaya deÄŸip deÄŸmeyeceÄŸine** karar vermenize yardÄ±mcÄ± olacaktÄ±r.

### 2.2 Framing the problem and assembling the dataset â€“ 19

Bir ML projesinde yapmanÄ±z gereken ilk ÅŸey, **problemi Ã§erÃ§evelemek** ve buna karÅŸÄ±lÄ±k gelen **veriyi toplamaktÄ±r**.

### 1\. Problemi Ã‡erÃ§eveleme ve Veri Toplama

Problemi Ã§erÃ§evelemek, ML modelinin **girdilerini** ve **Ã§Ä±ktÄ±larÄ±nÄ±** aÃ§Ä±kÃ§a belirtmenizi gerektirir. Kaliforniya konut probleminde:

  * **Girdiler** (Ã–zellikler): Konut bloklarÄ±nÄ± tanÄ±mlayan Ã¶zellikler kÃ¼mesidir. Bu veri setinde bir konut bloÄŸu, coÄŸrafi olarak kompakt bir alanda yaÅŸayan ve ortalama **1.425 bireyden** oluÅŸan bir gruptur. Ã–zellikler, konut bloÄŸundaki ev baÅŸÄ±na dÃ¼ÅŸen ortalama oda sayÄ±sÄ±, bloÄŸun merkezinin enlem (latitude) ve boylamÄ± (longitude) gibi bilgileri iÃ§erir.
  * **Ã‡Ä±ktÄ±lar** (Hedefler/Targetlar): BloklarÄ±n **ortalama konut fiyatlarÄ±** olmalÄ±dÄ±r.

AmacÄ±mÄ±z, medyan fiyatlarÄ± bilinen konut bloklarÄ±nÄ± kullanarak bir ML modeli eÄŸitmek ve Ã¶zelliklerine gÃ¶re medyan fiyatÄ± **bilinmeyen** konut bloklarÄ±nÄ±n fiyatlarÄ±nÄ± tahmin etmektir. DÃ¶ndÃ¼rÃ¼len tahmin edilen bu deÄŸerlere aynÄ± zamanda modelin **hedefleri** (veya **etiketleri/annotations**) de denir.

Genel olarak, mevcut etiketlenmiÅŸ Ã¶rneklere dayanarak **veri girdileri ile hedefler arasÄ±ndaki iliÅŸkiyi Ã¶ÄŸrenmeyi** amaÃ§layan her problem, bir **gÃ¶zetimli Ã¶ÄŸrenme (supervised learning)** problemi olarak adlandÄ±rÄ±lÄ±r. Bu, ML'nin en Ã§ok Ã§alÄ±ÅŸÄ±lan dalÄ±dÄ±r ve kitabÄ±n geri kalanÄ±nda ana odak noktamÄ±z olacaktÄ±r.

-----

### GÃ¶zetimli Ã–ÄŸrenme TÃ¼rleri

GÃ¶zetimli Ã¶ÄŸrenme problemlerini, hedef deÄŸerinin tÃ¼rÃ¼ne gÃ¶re alt kategorilere ayÄ±rabiliriz:

  * **Regresyon (Regression):** SÃ¼rekli (continuous) hedeflere sahip olan gÃ¶zetimli Ã¶ÄŸrenme problemleri regresyon olarak sÄ±nÄ±flandÄ±rÄ±lÄ±r. Fiyat sÃ¼rekli bir deÄŸiÅŸken olduÄŸu iÃ§in, Kaliforniya konut fiyatlarÄ±nÄ± tahmin etmek esasen bir **regresyon problemidir**.
  * **SÄ±nÄ±flandÄ±rma (Classification):** Bir gÃ¶zetimli Ã¶ÄŸrenme probleminde hedef deÄŸerler, sÄ±nÄ±rlÄ± sayÄ±da kategoriye sahip **ayrÄ±k deÄŸerler** (discrete values) ise, bu probleme **sÄ±nÄ±flandÄ±rma problemi** denir. SÄ±nÄ±flandÄ±rma problemlerine bazÄ± Ã¶rnekleri ek B'de bulabilirsiniz ve bunlarÄ± bir sonraki bÃ¶lÃ¼mde de inceleyeceÄŸiz.

-----

### Veri Setini YÃ¼kleme

Problemi Ã§erÃ§eveledikten sonraki adÄ±m veriyi toplamaktÄ±r. Kaliforniya konut veri seti, en Ã§ok kullanÄ±lan ML veri setlerinden biri olduÄŸu iÃ§in, popÃ¼ler bir ML kÃ¼tÃ¼phanesi olan **scikit-learn** ile kolayca eriÅŸilebilir. Ancak gerÃ§ek hayatta, veri setlerini bulmak ve edinmek Ã¶nemsiz bir faaliyet deÄŸildir ve Structured Query Language (SQL) bilgisi gibi ek beceriler gerektirebilir (bu, bu kitabÄ±n kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r. Daha fazla bilgi iÃ§in Jeff Smith'in *Machine Learning Systems* kitabÄ±na bakabilirsiniz).

Problemimiz iÃ§in veri setini yÃ¼kleyen kod aÅŸaÄŸÄ±dadÄ±r:

```python
from sklearn.datasets import fetch_california_housing # scikit-learn kÃ¼tÃ¼phanesinden veri yÃ¼kleme fonksiyonunu iÃ§e aktarÄ±r
house_dataset = fetch_california_housing()           # Kaliforniya konut veri setini yÃ¼kler
```

Orijinal veri, veri noktalarÄ±nÄ± **Ã¶rnek-Ã¶zellik matrisi** olarak biÃ§imlendirilmiÅŸ bir sÃ¶zlÃ¼ktÃ¼r (*dictionary*). Her bir veri noktasÄ±, matrisin bir satÄ±rÄ±ndaki Ã¶zelliklerle tanÄ±mlanan bir konut bloÄŸudur. Hedefleri ise bir vektÃ¶r olarak biÃ§imlendirilmiÅŸtir. SÃ¶zlÃ¼k, ayrÄ±ca Ã¶zellik adlarÄ±nÄ± ve veri setinin anlamÄ±na ve oluÅŸturulma bilgilerine iÅŸaret eden aÃ§Ä±klamalarÄ± iÃ§erir:

```python
>>> house_dataset.keys()
dict_keys(['data', 'target', 'feature_names', 'DESCR'])
```

Orijinal veri setini yÃ¼kledikten sonra, veri noktalarÄ±nÄ± ayÄ±klayarak onlarÄ± **pandas** kÃ¼tÃ¼phanesinin temel yapÄ±larÄ±ndan biri olan bir **DataFrame**'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz. Pandas, Python'da veri analizi ve manipÃ¼lasyonu iÃ§in gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r. AÅŸaÄŸÄ±daki kodda gÃ¶sterildiÄŸi gibi, hedefler, milyon dolar cinsinden konut bloÄŸunun medyan fiyatÄ±nÄ± temsil eden **"MedPrice"** etiketine sahip bir **Series** nesnesi (yani bir vektÃ¶r) olarak biÃ§imlendirilmiÅŸtir.

```python
import pandas as pd # pandas paketini iÃ§e aktarÄ±r

data = pd.DataFrame(house_dataset.data, columns=house_dataset.feature_names) # Ã–zellikleri adlarÄ±yla birlikte bir DataFrame'e ayÄ±klar
target = pd.Series(house_dataset.target, name = 'MedPrice')                 # Hedefleri "MedPrice" adÄ±yla bir Series nesnesine ayÄ±klar
```

Verinin ilk beÅŸ Ã¶rneÄŸini yazdÄ±ralÄ±m (ÅŸekil 2.2'de gÃ¶sterilmiÅŸtir). Ä°lk satÄ±r, Ã¶zellikleri belirtir (ayrÄ±ntÄ±larÄ± $[https://scikit-learn.org/stable/datasets.html$](https://www.google.com/search?q=https://scikit-learn.org/stable/datasets.html%24) adresinde bulunabilir). Ã–rneÄŸin, **"AveRooms"** Ã¶zelliÄŸi, bir konut bloÄŸu iÃ§indeki ev baÅŸÄ±na dÃ¼ÅŸen ortalama oda sayÄ±sÄ±nÄ± gÃ¶sterir. Hedef verilerin deÄŸerlerini de aynÄ± ÅŸekilde kontrol edebiliriz:

```python
>>> data.head(5)
```

![image](images/0011.png)

Veri Ã¶n iÅŸleme adÄ±mÄ±na geÃ§meden Ã¶nce, **eÄŸitim verisi (training data)** ve **test seti (test set)** olarak ayÄ±rmak iÃ§in Ã¶ncelikle bir **veri bÃ¶lme (data split)** iÅŸlemi yapalÄ±m.

Ã–nceki bÃ¶lÃ¼mde Ã¶ÄŸrendiÄŸiniz gibi, bu iÅŸlemin temel amacÄ±, analiz yapmak ve modelinizi eÄŸitmek iÃ§in kullandÄ±ÄŸÄ±nÄ±z verinin aynÄ±sÄ±yla modelinizi test etmekten kaÃ§Ä±nmaktÄ±r.

Veriyi eÄŸitim ve test setlerine ayÄ±rma kodu aÅŸaÄŸÄ±da gÃ¶sterilmiÅŸtir:

```python
from sklearn.model_selection import train_test_split # scikit-learn'den veri bÃ¶lme fonksiyonunu iÃ§e aktarÄ±r

X_train, X_test, y_train, y_test = train_test_split(
 data, target,
 test_size=0.2,    # Verinin rastgele %20'sini test seti olarak ayÄ±rÄ±r
 random_state=42)  # Tekrarlanabilirlik iÃ§in
```

Verinin rastgele **%20**'sini test seti olarak ayÄ±rdÄ±k. Åimdi bu bÃ¶lme iÅŸlemini hÄ±zlÄ±ca kontrol edelim. TÃ¼m veri setine baktÄ±ÄŸÄ±nÄ±zda, 20.640 veri noktasÄ± iÃ§erdiÄŸini gÃ¶receksiniz. Her bir konut bloÄŸu iÃ§in Ã¶zellik sayÄ±sÄ± sekizdir. EÄŸitim seti **16.512** Ã¶rnek, test seti ise **4.128** Ã¶rnek iÃ§erir, bu durum aÅŸaÄŸÄ±daki kod parÃ§asÄ±nda tasvir edilmiÅŸtir:

```python
>>> (data.shape, target.shape), (X_train.shape, y_train.shape), (X_test.shape, y_test.shape)
(((20640, 8), (20640,)), ((16512, 8), (16512,)), ((4128, 8), (4128,)))
```

Nihai ML Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ elde edene kadar **test setindeki hedef verilere (y\_test)** dokunmamalÄ±sÄ±nÄ±z. Aksi takdirde, veri hazÄ±rlama ve model eÄŸitimi dahil olmak Ã¼zere tÃ¼m analizleriniz **test verisine aÅŸÄ±rÄ± uyum saÄŸlayabilir (overfit)** ve bu da Ã§Ã¶zÃ¼m devreye alÄ±ndÄ±ÄŸÄ±nda gÃ¶rÃ¼lmemiÅŸ veriler Ã¼zerinde kÃ¶tÃ¼ performans gÃ¶stermesine neden olur.

Ancak, aÅŸaÄŸÄ±daki bÃ¶lÃ¼mlerde yapacaÄŸÄ±mÄ±z gibi, veri Ã¶n iÅŸleme ve Ã¶zellik mÃ¼hendisliÄŸi aÅŸamalarÄ±nda **test setindeki Ã¶zellikleri (X\_test)** eÄŸitim Ã¶zellikleriyle birleÅŸtirmek mÃ¼mkÃ¼ndÃ¼r. Ã–zellikle veri seti boyutu kÃ¼Ã§Ã¼k olduÄŸunda, bu, Ã¶zellik bilgisini bir araya getirmeye yardÄ±mcÄ± olabilir.

### 2.3 Data preprocessing â€“ 22

Bir sonraki adÄ±mÄ±mÄ±z, veriyi ML algoritmalarÄ±na beslemek iÃ§in uygun bir formata dÃ¶nÃ¼ÅŸtÃ¼rmek amacÄ±yla **Ã¶n iÅŸleme (preprocessing)** yapmaktÄ±r. Bu prosedÃ¼r genellikle, veriye dair Ã¶n kabullere veya sorulara dayalÄ± **keÅŸifsel veri analizi (EDA)** iÃ§erir. EDA, veri setine aÅŸina olmamÄ±za ve daha iyi veri hazÄ±rlÄ±ÄŸÄ± yapmamÄ±zÄ± saÄŸlayacak ek iÃ§gÃ¶rÃ¼ler kazanmamÄ±za yardÄ±mcÄ± olur.

YaygÄ±n olarak sorulan bazÄ± sorular ÅŸunlardÄ±r:

  * **Veri Tipleri:** Her bir Ã¶zellikteki deÄŸerlerin veri tipleri nelerdir? Bunlar, boru hattÄ±nÄ±n sonraki adÄ±mlarÄ±nda doÄŸrudan kullanÄ±labilecek dizeler (string) veya baÅŸka nesneler mi, yoksa dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmeleri mi gerekiyor?
  * **AyrÄ±k DeÄŸerler:** Her bir Ã¶zellik kaÃ§ farklÄ± (distinct) deÄŸere sahip? Bunlar sayÄ±sal (numerical) deÄŸerler mi, kategorik (categorical) deÄŸerler mi, yoksa baÅŸka bir ÅŸey mi?
  * **Ã–lÃ§ekler ve Ä°statistikler:** Her bir Ã¶zelliÄŸin Ã¶lÃ§ekleri ve temel istatistikleri nelerdir? DeÄŸerlerin daÄŸÄ±lÄ±mÄ±nÄ± veya aralarÄ±ndaki korelasyonlarÄ± gÃ¶rselleÅŸtirerek bazÄ± iÃ§gÃ¶rÃ¼ler elde edebilir miyiz?
  * **Eksik DeÄŸerler:** Veride eksik deÄŸerler var mÄ±? Varsa, bunlarÄ± kaldÄ±rmalÄ± mÄ±yÄ±z yoksa doldurmalÄ± mÄ±yÄ±z?

Pratikte, farklÄ± veriler genellikle formatÄ±na ve Ã¶zelliklerine, ilgilendiÄŸimiz problemlere, seÃ§ilen ML modellerine ve benzeri faktÃ¶rlere baÄŸlÄ± olarak **Ã¶zel olarak hazÄ±rlanmÄ±ÅŸ** veri Ã¶n iÅŸleme teknikleri gerektirir. Bu genellikle, Ã§eÅŸitli geÃ§ici (ad hoc) iÅŸlemlerin Ã¶nerilmesiyle sonuÃ§lanan sezgisel ve ampirik bir sÃ¼reÃ§tir.

Bu Ã¶rnekte, az Ã¶nce bahsedilen dÃ¶rt soruyu Ã¶n hazÄ±rlÄ±k veri Ã¶n iÅŸleme iÅŸlemlerimizin temeli olarak kullanacaÄŸÄ±z. Daha fazla Ã¶rneÄŸi ek B'de bulabilirsiniz.

-----

#### 1\. Veri Tiplerini Kontrol Etme

Ä°lgilendiÄŸimiz ilk soru, Ã¶zellik deÄŸerlerinin veri tipleridir. Bu Ã¶rnekte, tÃ¼m Ã¶zellikler ve hedefleri **kayan nokta (floating-point)** deÄŸerleridir ve bu nedenle ek bir manipÃ¼lasyona gerek kalmadan doÄŸrudan ML algoritmalarÄ±na beslenebilirler:

```python
>>> data.dtypes
MedInc       float64
HouseAge     float64
AveRooms     float64
AveBedrms    float64
Population   float64
AveOccup     float64
Latitude     float64
Longitude    float64
dtype: object
>>> target.dtypes
dtype('float64')
```

#### 2\. AyrÄ±k DeÄŸer SayÄ±sÄ±nÄ± Kontrol Etme

Ä°kinci olarak, Ã¶zelliklerdeki ayrÄ±k deÄŸerlerin sayÄ±sÄ± ile ilgileniyoruz. AyrÄ±k deÄŸerleri saymak, Ã¶zellik tÃ¼rlerini ayÄ±rt etmek iÃ§in faydalÄ± olabilir, bÃ¶ylece onlara Ã¶zel iÅŸleme stratejileri tasarlayabiliriz. Bu aynÄ± zamanda gereksiz Ã¶zellikleri kaldÄ±rmamÄ±za da yardÄ±mcÄ± olabilir. Ã–rneÄŸin, bir Ã¶zellik iÃ§in tÃ¼m veri Ã¶rnekleri aynÄ± deÄŸere sahipse, o Ã¶zellik tahmin iÃ§in yararlÄ± herhangi bir bilgi saÄŸlayamaz.

AyrÄ±ca, her veri noktasÄ±nÄ±n bir Ã¶zellik iÃ§in benzersiz bir deÄŸere sahip olmasÄ± da mÃ¼mkÃ¼ndÃ¼r, ancak bu deÄŸerlerin sÄ±nÄ±flandÄ±rma iÃ§in yardÄ±mcÄ± olmayacaÄŸÄ±ndan eminizdir. Bu durum, yalnÄ±zca veri Ã¶rneklerinin sÄ±rasÄ±nÄ± belirten veri noktalarÄ±nÄ±n **ID** Ã¶zelliÄŸi iÃ§in sÄ±klÄ±kla geÃ§erlidir.

AÅŸaÄŸÄ±daki kodda, bu veri setinde tÃ¼m noktalar iÃ§in deÄŸeri aynÄ± olan hiÃ§bir Ã¶zellik olmadÄ±ÄŸÄ±nÄ± ve her veri noktasÄ±nÄ±n benzersiz bir deÄŸere sahip olduÄŸu hiÃ§bir Ã¶zellik olmadÄ±ÄŸÄ±nÄ± gÃ¶rebiliriz:

```python
>>> data.nunique()
MedInc       12928
HouseAge        52
AveRooms     19392
AveBedrms    14233
Population    3888
AveOccup     18841
Latitude       862
Longitude      844
dtype: int64
```

"MedInc", "AveRooms" ve "AveBedrms" gibi bazÄ± Ã¶zellikler yÃ¼ksek sayÄ±da ayrÄ±k deÄŸere sahip olsa da, bunlar konut bloklarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak ve fiyatÄ± tahmin etmek iÃ§in deÄŸerleri yararlÄ± olan **sayÄ±sal Ã¶zellikler** olduÄŸu iÃ§in bunlarÄ± kaldÄ±rmamalÄ±yÄ±z.

#### 3\. Temel Ä°statistikleri GÃ¶rÃ¼ntÃ¼leme

Daha fazla iÃ§gÃ¶rÃ¼ kazanmak iÃ§in Ã¶zelliklerin bazÄ± temel istatistiklerini de gÃ¶rÃ¼ntÃ¼leyebiliriz (ÅŸekil 2.3'te gÃ¶sterildiÄŸi gibi). Ã–rneÄŸin, bir konut bloÄŸundaki ortalama nÃ¼fus 1.425'tir, ancak bu veri setindeki en yoÄŸun nÃ¼fuslu blokta 35.000'den fazla, en seyrek nÃ¼fuslu blokta ise sadece 3 kiÅŸi yaÅŸamaktadÄ±r.

![image](images/0012.png)

GerÃ§ek dÃ¼nya uygulamalarÄ±ndaki temel zorluklardan biri, verideki **eksik deÄŸerlerdir**. Bu sorun, verilerin toplanmasÄ± veya iletilmesi sÄ±rasÄ±nda ortaya Ã§Ä±kabilir veya bozulma, verinin doÄŸru yÃ¼klenememesi gibi nedenlerden kaynaklanabilir. Uygun ÅŸekilde ele alÄ±nmadÄ±ÄŸÄ± takdirde, eksik deÄŸerler ML Ã§Ã¶zÃ¼mÃ¼nÃ¼n performansÄ±nÄ± etkileyebilir ve hatta programÄ±n Ã§Ã¶kmesine neden olabilir.

Verideki eksik ve geÃ§ersiz deÄŸerlerin yerine ikame deÄŸerler konulmasÄ± iÅŸlemine **imputasyon (imputation)** denir.

AÅŸaÄŸÄ±daki kod, eÄŸitim ve test veri setlerimizde eksik deÄŸer olup olmadÄ±ÄŸÄ±nÄ± kontrol eder:

```python
train_data = X_train.copy()          # EÄŸitim verisini, yerinde deÄŸiÅŸikliÄŸi Ã¶nlemek iÃ§in kopyalar
train_data['MedPrice'] = y_train     # Ã–zellikleri ve hedefi, 'MedPrice' sÃ¼tununu ekleyerek birleÅŸtirir

print(f'-- eÄŸitim verisindeki eksik deÄŸer kontrolÃ¼ --\n{train_data.isnull().any()}') # EÄŸitim setinde eksik deÄŸer olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
print(f'-- test verisindeki eksik deÄŸer kontrolÃ¼ --\n{X_test.isnull().any()}')      # Test setinde eksik deÄŸer olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
```

AÅŸaÄŸÄ±daki sonuÃ§lar, veri setinde eksik deÄŸer olmadÄ±ÄŸÄ±nÄ± gÃ¶sterir, bu nedenle bu problemi daha fazla dÃ¼ÅŸÃ¼nmeden analizimize devam edebiliriz (eksik deÄŸerlerle baÅŸa Ã§Ä±kma Ã¶rneÄŸini 3. bÃ¶lÃ¼mde gÃ¶receksiniz):

```
-- eÄŸitim verisindeki eksik deÄŸer kontrolÃ¼ --
MedInc       False
HouseAge     False
AveRooms     False
AveBedrms    False
Population   False
AveOccup     False
Latitude     False
Longitude    False
MedPrice     False
dtype: bool
-- test verisindeki eksik deÄŸer kontrolÃ¼ --
MedInc       False
HouseAge     False
AveRooms     False
AveBedrms    False
Population   False
AveOccup     False
Latitude     False
Longitude    False
dtype: bool
```

Basitlik aÃ§Ä±sÄ±ndan, burada ek bir veri Ã¶n iÅŸleme yapmayacaÄŸÄ±z. Genellikle, ML modellerinin eÄŸitimini etkileyebilecek aykÄ±rÄ± deÄŸerleri (outliers) kontrol etmek ve verinizde varsa bunlarÄ± kaldÄ±rmak gibi diÄŸer yaygÄ±n adÄ±mlarÄ± atmak isteyebilirsiniz. AyrÄ±ca, gerÃ§ek dÃ¼nya veri setleri genellikle bu Ã¶rnekte kullanÄ±lan kadar iyi biÃ§imlendirilmiÅŸ olmaz. FarklÄ± veri tipleriyle baÅŸa Ã§Ä±kan veri Ã¶n iÅŸleme tekniklerinin daha fazla Ã¶rneÄŸi Ek B'de verilmiÅŸtir; bu konuya aÅŸina deÄŸilseniz bir sonraki bÃ¶lÃ¼me geÃ§meden Ã¶nce bu Ã¶rnekleri gÃ¶zden geÃ§irmenizi tavsiye ederim.

Åimdi, genellikle veri Ã¶n iÅŸleme ile eÅŸ zamanlÄ± olarak yÃ¼rÃ¼tÃ¼len **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)** adÄ±mÄ±na geÃ§eceÄŸiz.

### 2.4 Feature engineering â€“ 25

Ham veriyi kullanÄ±ÅŸlÄ± veya verimli bir formata dÃ¶nÃ¼ÅŸtÃ¼rmeye odaklanan **veri Ã¶n iÅŸlemeden** farklÄ± olarak, **Ã¶zellik mÃ¼hendisliÄŸi (feature engineering)**, ML algoritmalarÄ±nÄ±n performansÄ±nÄ± artÄ±rmak iÃ§in bir dizi iyi Ã¶zellik **Ã¼retmeyi ve seÃ§meyi** amaÃ§lar. Bu sÃ¼reÃ§ genellikle belirli alan bilgisine (*domain knowledge*) dayanÄ±r ve aÅŸaÄŸÄ±daki iki adÄ±mla **tekrarlÄ± (iteratively)** ilerler:

-----

## Ã–zellik MÃ¼hendisliÄŸinin AdÄ±mlarÄ±

### 1\. Ã–zellik Ãœretimi (Feature Generation)

Mevcut Ã¶zellikleri dÃ¶nÃ¼ÅŸtÃ¼rerek **yeni Ã¶zellikler** oluÅŸturmayÄ± hedefler.

  * **Tek bir Ã¶zellik** Ã¼zerinde yapÄ±labilir: Ã–rneÄŸin, Ã¶lÃ§Ã¼lebilir sayÄ±sal bir Ã¶zellik elde etmek iÃ§in kategorik bir Ã¶zelliÄŸi her kategorideki sÄ±klÄ±k sayÄ±sÄ±yla ikame etmek gibi.
  * **Birden fazla Ã¶zellik** Ã¼zerinde yapÄ±labilir: Ã–rneÄŸin, farklÄ± mesleklerdeki erkek ve kadÄ±n Ã§alÄ±ÅŸan sayÄ±sÄ±nÄ± sayarak, farklÄ± sektÃ¶rlerdeki iÅŸe alÄ±m adaletini analiz etmek iÃ§in daha aÃ§Ä±klayÄ±cÄ± bir Ã¶zellik elde edebiliriz.

### 2\. Ã–zellik SeÃ§imi (Feature Selection)

ML algoritmalarÄ±nÄ±n verimliliÄŸini ve doÄŸruluÄŸunu artÄ±rmak iÃ§in **mevcut Ã¶zelliklerin en faydalÄ± alt kÃ¼mesini** seÃ§meyi amaÃ§lar.

Ã–zellik seÃ§imi ve Ã¼retimi genellikle, Ã¼retilen Ã¶zelliklerin hedeflerle olan korelasyonu gibi anlÄ±k geri bildirimlerden veya eÄŸitilmiÅŸ ML modelinin deÄŸerlendirme veri setindeki performansÄ±na dayalÄ± gecikmeli geri bildirimlerden yararlanÄ±larak **tekrarlÄ± bir ÅŸekilde** yapÄ±lÄ±r.

-----

### Korelasyon Matrisi ile Ã–zellik SeÃ§imi

AÅŸaÄŸÄ±daki kodda (Liste 2.6), **Pearson Korelasyon KatsayÄ±sÄ±** kullanarak her bir Ã¶zellik ile hedef arasÄ±ndaki korelasyonu Ã¶lÃ§erek basit bir Ã¶zellik seÃ§imi gerÃ§ekleÅŸtiriyoruz.

**Pearson Korelasyon KatsayÄ±sÄ±**, iki deÄŸiÅŸken arasÄ±ndaki **doÄŸrusal korelasyonu** Ã¶lÃ§er (Ã¶zellik ve hedef). DeÄŸer, **-1** ile **1** arasÄ±nda deÄŸiÅŸebilir; burada -1 mÃ¼kemmel bir negatif doÄŸrusal iliÅŸkiyi, 1 ise mÃ¼kemmel bir pozitif doÄŸrusal iliÅŸkiyi gÃ¶sterir. 0 katsayÄ±sÄ± ise hiÃ§bir iliÅŸki olmadÄ±ÄŸÄ±nÄ± belirtir.

```python
import matplotlib.pyplot as plt # Genel Ã§izim konfigÃ¼rasyonu iÃ§in kÃ¼tÃ¼phaneyi iÃ§e aktarÄ±r
import seaborn as sns           # IsÄ± haritasÄ±nÄ± (heatmap) Ã§izmek iÃ§in seaborn kÃ¼tÃ¼phanesini iÃ§e aktarÄ±r
%matplotlib inline              # Jupyter notebook'larda ÅŸekil gÃ¶sterimini dÃ¼zenler

plt.figure(figsize=(30,10))     # Åekil boyutunu ayarlar
correlation_matrix = train_data.corr().round(2) # Pearson korelasyon katsayÄ±sÄ± matrisini hesaplar
sns.heatmap(data=correlation_matrix, square= True, # TÃ¼m Ã¶zellikler ve hedef arasÄ±ndaki korelasyonlarÄ± Ã§izer
            annot=True, cmap='Blues')
```

Matrisin (bkz. ÅŸekil 2.4) **en son satÄ±rÄ±na** odaklanacaÄŸÄ±z. Bu satÄ±r, hedef konut fiyatÄ± ile her bir Ã¶zellik arasÄ±ndaki ikili korelasyonu gÃ¶stermektedir. ArdÄ±ndan, seÃ§tiÄŸimiz iki Ã¶zelliÄŸi tartÄ±ÅŸacaÄŸÄ±z.

![image](images/0013.png)

KatsayÄ± matrisine ve aÅŸaÄŸÄ±daki varsayÄ±mlara dayanarak, en yÃ¼ksek korelasyona sahip iki Ã¶zelliÄŸi seÃ§iyoruz:

  * **MedInc (Medyan Gelir)** ğŸ’°: Konut bloÄŸu iÃ§indeki hane halklarÄ± iÃ§in medyan geliri gÃ¶steren bu Ã¶zellik, hedef deÄŸerlerle **yÃ¼ksek pozitif doÄŸrusal korelasyon** gÃ¶stermektedir. Bu, sezgisel olarak yÃ¼ksek gelirli insanlarÄ±n daha yÃ¼ksek konut fiyatlarÄ±na sahip bloklarda yaÅŸama olasÄ±lÄ±ÄŸÄ±nÄ±n daha yÃ¼ksek olduÄŸu fikriyle (pozitif korelasyon) uyumludur.
  * **AveRooms (Ortalama Oda SayÄ±sÄ±)** ğŸ : Bu Ã¶zellik, bir bloktaki her evdeki ortalama oda sayÄ±sÄ±nÄ± gÃ¶sterir. Daha fazla odaya sahip evlerin fiyatlarÄ±nÄ±n daha yÃ¼ksek olma olasÄ±lÄ±ÄŸÄ± daha fazladÄ±r (**pozitif korelasyon**).

Basitlik iÃ§in burada yalnÄ±zca iki Ã¶zellik seÃ§iyoruz. Ã–zellik seÃ§imi aÅŸaÄŸÄ±daki kodda uygulanmÄ±ÅŸtÄ±r:

```python
selected_feature_set = ['MedInc', 'AveRooms',]
sub_train_data = train_data[
 selected_feature_set + ['MedPrice']] # SeÃ§ilen Ã¶zellikleri ve hedefi iÃ§eren alt eÄŸitim veri setini oluÅŸturur.
X_train = sub_train_data.drop(['MedPrice'], axis=1) # Yeni X_train'i oluÅŸturur.
X_test = X_test[selected_feature_set] # X_test'i de seÃ§ilen Ã¶zelliklerle sÄ±nÄ±rlar.
```

**Not:** Ã–zellik seÃ§imini, gÃ¶rsel incelemeye dayandÄ±rmak yerine, hesaplanan Pearson korelasyon katsayÄ±larÄ± iÃ§in bir eÅŸik deÄŸeri (Ã¶rneÄŸin 0.5) seÃ§erek otomatikleÅŸtirmek de mÃ¼mkÃ¼ndÃ¼r. SeÃ§ilecek Ã¶zellik sayÄ±sÄ±, dikkatlice karar vermemiz gereken bir **hiperparametre**dir. ML modelimizi eÄŸitmek iÃ§in farklÄ± Ã¶zellik kombinasyonlarÄ±nÄ± deneyebilir ve deneme yanÄ±lma yoluyla en iyi olanÄ± seÃ§ebiliriz.

-----

## SeÃ§ilen Ã–zelliklerin GÃ¶rselleÅŸtirilmesi

Ä°ki Ã¶zelliÄŸi seÃ§tikten sonra, bunlar ve hedef arasÄ±ndaki ikili korelasyonlarÄ± gÃ¶stermek iÃ§in daÄŸÄ±lÄ±m grafikleri (*scatterplots*) Ã§izebiliriz. DaÄŸÄ±lÄ±mlarÄ± aÅŸaÄŸÄ±daki kod kullanÄ±larak histogram grafikleri aracÄ±lÄ±ÄŸÄ±yla birlikte gÃ¶sterilebilir:

```python
sns.pairplot(sub_train_data, height=3.5, plot_kws={'alpha': 0.4})
```

DaÄŸÄ±lÄ±m grafikleri, "MedInc" Ã¶zelliÄŸi ile hedef "MedPrice" arasÄ±nda **gÃ¼Ã§lÃ¼ bir pozitif korelasyon** olduÄŸunu gÃ¶stermektedir. "AveRooms" Ã¶zelliÄŸi ile "MedPrice" arasÄ±ndaki korelasyon ise, Ã¶zellikler arasÄ±ndaki Ã¶lÃ§ek farklarÄ± ve aykÄ±rÄ± deÄŸerler (*outliers*) nedeniyle nispeten **daha az belirgindir** (bkz. ÅŸekil 2.5).

-----

## Ã–zellik SeÃ§iminin SÄ±nÄ±rlamalarÄ±

Ã–zellik seÃ§imi iÃ§in Pearson korelasyon katsayÄ±sÄ±nÄ± kullanmak kolaydÄ±r, ancak pratikte her zaman etkili olmayabilir. Ã‡Ã¼nkÃ¼ bu yÃ¶ntem:

1.  Ã–zellikler ile hedef arasÄ±ndaki **doÄŸrusal olmayan (nonlinear) iliÅŸkileri** gÃ¶z ardÄ± eder.
2.  Ã–zelliklerin kendi aralarÄ±ndaki korelasyonlarÄ± da dikkate almaz.
3.  DeÄŸerleri sÄ±ralÄ± olmayan **kategorik Ã¶zellikler** iÃ§in, Ã¶zellik ile hedef arasÄ±ndaki korelasyon anlamlÄ± olmayabilir.

Giderek daha fazla Ã¶zellik mÃ¼hendisliÄŸi tekniÄŸi Ã¶nerildiÄŸi iÃ§in, en iyi olanÄ± nasÄ±l seÃ§eceÄŸimize karar vermek zor bir nokta haline gelmiÅŸtir. Bu durum, AutoML'de Ã¶nemli bir konu olan **otomatik Ã¶zellik seÃ§imi ve dÃ¶nÃ¼ÅŸÃ¼mÃ¼** konusunu gÃ¼ndeme getirir; ancak bunun tartÄ±ÅŸmasÄ±nÄ± kitabÄ±n ikinci kÄ±smÄ±na bÄ±rakacak ve ÅŸimdilik elimizdeki problemi Ã§Ã¶zmeye devam edeceÄŸiz.

ArtÄ±k eÄŸitim verimizi hazÄ±rladÄ±ÄŸÄ±mÄ±za ve Ã¶zelliklerimizi seÃ§tiÄŸimize gÃ¶re, Ã¶nceden iÅŸlenmiÅŸ verilerle bir ML modeli eÄŸitmek iÃ§in kullanacaÄŸÄ±mÄ±z algoritmalarÄ± seÃ§meye hazÄ±rÄ±z. (Pratikte, daha Ã¶zel bir veri hazÄ±rlama sÃ¼reci izlemek iÃ§in ML algoritmalarÄ±nÄ± veri Ã¶n iÅŸleme ve Ã¶zellik mÃ¼hendisliÄŸi adÄ±mlarÄ±ndan **Ã¶nce** de seÃ§ebilirsiniz.)

![image](images/0014.png)

### 2.5 ML algorithm selection â€“ 28

UnutmayÄ±n ki, her bir ML algoritmasÄ± iÃ§in seÃ§memiz gereken dÃ¶rt temel bileÅŸen vardÄ±r:

1.  EÄŸitilecek bir **ML Modeli**.
2.  Modelin etkinliÄŸini Ã¶lÃ§mek iÃ§in bir **Metrik**.
3.  O metriÄŸe dayanarak modelin parametrelerini gÃ¼ncellemek iÃ§in bir **Optimizasyon YÃ¶ntemi**.
4.  GÃ¼ncelleme sÃ¼recini sonlandÄ±rmak iÃ§in bir **Durdurma Kriteri**.

Ana odak noktamÄ±z optimizasyon olmadÄ±ÄŸÄ± iÃ§in, seÃ§ilen her model iÃ§in optimizasyon yÃ¶nteminden ve durdurma kriterinden sadece kÄ±saca bahsedeceÄŸiz.

Bu Ã¶rnek iÃ§in, iki basit ve klasik model kullanacaÄŸÄ±z. Birincisi **DoÄŸrusal Regresyon (Linear Regression)** modeli, ikincisi ise **Karar AÄŸacÄ± (Decision Tree)** modelidir.

Ã–ncelikle, doÄŸrusal regresyon modelinin temel fikrini ve bu modeli oluÅŸturma, eÄŸitme ve deÄŸerlendirme sÃ¼recini kÄ±saca hatÄ±rlayarak baÅŸlayacaÄŸÄ±z. Modeli, eÄŸitim verisini hiperparametre ayarÄ± iÃ§in ayrÄ±ca eÄŸitim ve doÄŸrulama setlerine bÃ¶lmeksizin, **tÃ¼m eÄŸitim setini kullanarak eÄŸitecek** ve **test seti Ã¼zerinde deÄŸerlendireceÄŸiz**.

Hiperparametre ayarlama adÄ±mÄ±nÄ± ise, karar aÄŸacÄ± modelinin tanÄ±tÄ±mÄ±ndan sonra tartÄ±ÅŸacaÄŸÄ±z.

#### *Building the linear regression model* â€“ 29

DoÄŸrusal regresyon, gÃ¶zetimli makine Ã¶ÄŸrenimindeki en basit modellerden biridir ve muhtemelen Ã¶ÄŸrendiÄŸiniz ilk ML modelidir. Bir veri noktasÄ±nÄ±n hedef deÄŸerini, Ã¶zelliklerinin **aÄŸÄ±rlÄ±klÄ± toplamÄ±nÄ±** hesaplayarak tahmin etmeye Ã§alÄ±ÅŸÄ±r:

$$\text{Tahmin} = w_0 + w_1 x_1 + w_2 x_2 + \dots + w_m x_m$$

Burada $m$ Ã¶zellik sayÄ±sÄ±nÄ± gÃ¶sterir. Mevcut Ã¶rnekte $m=2$'dir, Ã§Ã¼nkÃ¼ sadece iki Ã¶zellik ("MedInc" ve "AveRooms") seÃ§tik. $w_i$'ler veriden Ã¶ÄŸrenilecek **parametrelerdir** (veya aÄŸÄ±rlÄ±klar); $w_0$ **kesiÅŸim (intercept)** olarak adlandÄ±rÄ±lÄ±r ve $w_i$, $x_i$ Ã¶zelliÄŸi iÃ§in bir **katsayÄ±dÄ±r (coefficient)**. Parametreler, Ã¶zellikler ve hedef arasÄ±ndaki **doÄŸrusal iliÅŸkiyi** yakalamak iÃ§in eÄŸitim verisine gÃ¶re Ã¶ÄŸrenilir.

Scikit-learn ile bir doÄŸrusal regresyon modeli oluÅŸturma kodu ÅŸÃ¶yledir:

```python
from sklearn.linear_model import LinearRegression
linear_regressor = LinearRegression()
```

-----

##### Metrik ve Optimizasyon: Ortalama Karesel Hata (MSE)

AÄŸÄ±rlÄ±klarÄ± Ã¶ÄŸrenmek iÃ§in bir optimizasyon yÃ¶ntemi ve performanslarÄ±nÄ± Ã¶lÃ§mek iÃ§in bir metrik seÃ§memiz gerekir. **Ortalama Karesel Hata (Mean Squared Error - MSE)**, regresyon problemleri iÃ§in yaygÄ±n olarak kullanÄ±lan bir kayÄ±p fonksiyonu ve deÄŸerlendirme metriÄŸidir; modelin tahminleri ile hedefler arasÄ±ndaki **ortalama karesel farkÄ±** Ã¶lÃ§er.

  * **EÄŸitim aÅŸamasÄ±nda** modeli Ã¶ÄŸrenmek iÃ§in MSE'yi **kayÄ±p fonksiyonu** olarak kullanacaÄŸÄ±z.
  * **Test aÅŸamasÄ±nda** ise modelin test seti Ã¼zerindeki tahmin gÃ¼cÃ¼nÃ¼ Ã¶lÃ§mek iÃ§in **deÄŸerlendirme metriÄŸi** olarak kullanacaÄŸÄ±z.

NasÄ±l hesaplandÄ±ÄŸÄ±nÄ± anlamanÄ±za yardÄ±mcÄ± olmak iÃ§in, bir kod Ã¶rneÄŸi aÅŸaÄŸÄ±da verilmiÅŸtir (Liste 2.8). EÄŸitim aÅŸamasÄ±nda `true_target_values`, eÄŸitim veri setindeki tÃ¼m hedef deÄŸerlerin (evlerin gerÃ§ek fiyatlarÄ±) bir listesidir ve `predictions`, model tarafÄ±ndan tahmin edilen tÃ¼m konut fiyatlarÄ±dÄ±r.

```python
def mean_squared_error(predictions, true_target_values):
 mse = 0
 for prediction, target_value in zip(predictions, true_target_values):
 mse += (prediction - target_value) ** 2 # Karesel hatalarÄ± toplar
 mse /= len(predictions)                  # Karesel hatalarÄ±n toplamÄ±nÄ±n ortalamasÄ±nÄ± alÄ±r
 return mse
```

Åekil 2.6'da tek bir deÄŸiÅŸkenli (veya Ã¶zellikli) doÄŸrusal regresyon modelinin basit bir Ã§izimi yer almaktadÄ±r. Ã–ÄŸrenme sÃ¼reci, veri noktalarÄ± ile regresyon Ã§izgisi arasÄ±ndaki kesikli Ã§izgilerle gÃ¶sterilen **karesel hatalarÄ±n ortalamasÄ±nÄ± en aza indirmek** iÃ§in en iyi eÄŸimi ve kesiÅŸimi bulmayÄ± amaÃ§lar.

![image](images/0015.png)

Scikit-learn yardÄ±mÄ±yla, `fit` fonksiyonunu Ã§aÄŸÄ±rarak ve eÄŸitim verisini besleyerek aÄŸÄ±rlÄ±klarÄ± kolayca optimize edebiliriz. MSE, varsayÄ±lan olarak kayÄ±p fonksiyonu olarak kullanÄ±lÄ±r:

```python
linear_regressor.fit(X_train, y_train)
```

-----

##### Ã–ÄŸrenilen Parametrelerin Ä°ncelenmesi

Ã–ÄŸrenilen aÄŸÄ±rlÄ±klarÄ± aÅŸaÄŸÄ±daki kodla yazdÄ±rabiliriz:

```python
>>> coefficients = pd.DataFrame(
... linear_regressor.coef_,
... X_train.columns,
... columns=['Coefficient'])
>>> print(f'KesiÅŸim (Intercept): {linear_regressor.intercept_:.2f}\n')
>>> print(coefficients)
```

**Ã–ÄŸrenilen KesiÅŸim:** $0.60$

| | KatsayÄ± (Coefficient) |
|---|---|
| MedInc | $0.44$ |
| AveRooms | $-0.04$ |

Ã–ÄŸrenilen katsayÄ±lar, "MedInc" Ã¶zelliÄŸinin ve hedefin pozitif doÄŸrusal bir korelasyona sahip olduÄŸunu gÃ¶steriyor ($0.44$). Ancak, **"AveRooms"** Ã¶zelliÄŸinin, beklentilerimizin aksine, **negatif bir korelasyona** sahip olmasÄ± ÅŸaÅŸÄ±rtÄ±cÄ±dÄ±r ($-0.04$). Bu durum, aÅŸaÄŸÄ±daki iki olasÄ± faktÃ¶rden kaynaklanabilir:

1.  **AykÄ±rÄ± DeÄŸerler:** EÄŸitim verisindeki aykÄ±rÄ± deÄŸerler (bazÄ± yÃ¼ksek fiyatlÄ± konut bloklarÄ±nÄ±n daha az odaya sahip olmasÄ± gibi) eÄŸitim sÃ¼recini etkiliyor olabilir.
2.  **Ã–zellikler ArasÄ±ndaki Korelasyon (Ã‡oklu DoÄŸrusallÄ±k):** SeÃ§tiÄŸimiz iki Ã¶zellik pozitif olarak doÄŸrusal birbiriyle iliÅŸkilidir (Hedefi tahmin etmede ortak bilgi paylaÅŸÄ±yorlar). "MedInc" zaten "AveRooms" tarafÄ±ndan saÄŸlanan bilginin bir kÄ±smÄ±nÄ± kapsadÄ±ÄŸÄ± iÃ§in, "AveRooms"un etkisi azalmÄ±ÅŸ ve bu da hafif bir negatif korelasyonla sonuÃ§lanmÄ±ÅŸtÄ±r.

Ä°deal olarak, doÄŸrusal regresyon iÃ§in iyi bir Ã¶zellik kÃ¼mesi, birbiriyle yalnÄ±zca **zayÄ±f** bir ÅŸekilde iliÅŸkili olmalÄ± ancak hedefle **yÃ¼ksek** bir korelasyona sahip olmalÄ±dÄ±r. Bu aÅŸamada, farklÄ± Ã¶zellik kÃ¼melerini denemek ve iyi bir kombinasyon seÃ§mek iÃ§in Ã¶zellik seÃ§imi ve model eÄŸitimi ile **tekrarlÄ± bir ÅŸekilde** ilerleyebiliriz. Bu sÃ¼reci, denemeniz iÃ§in bir alÄ±ÅŸtÄ±rma olarak bÄ±rakÄ±p doÄŸrudan test aÅŸamasÄ±na geÃ§eceÄŸiz.

-----

##### Test SonuÃ§larÄ±

Ã–ÄŸrenilen modelin test seti Ã¼zerindeki MSE'si aÅŸaÄŸÄ±daki kodla hesaplanabilir ve yazdÄ±rÄ±labilir:

```python
>>> from sklearn.metrics import mean_squared_error
>>> y_pred_test = linear_regressor.predict(X_test)
>>> print(f'Test MSE: {mean_squared_error(y_test, y_pred_test):.2f}')
Test MSE: 0.70
```

**Test MSE'si $0.70$'tir.** Bu, ortalama olarak, modelin tahminleri ile test verisinin gerÃ§ek hedef deÄŸerleri arasÄ±ndaki karesel farkÄ±n $0.70$ olduÄŸu anlamÄ±na gelir. MSE iÃ§in daha dÃ¼ÅŸÃ¼k bir deÄŸer daha iyidir; ideal olarak, bu deÄŸerin $0$'a olabildiÄŸince yakÄ±n olmasÄ±nÄ± istersiniz.

SÄ±rada bir karar aÄŸacÄ± modelini deneyecek ve ikisinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±racaÄŸÄ±z.

#### *Building the decision tree model* â€“ 31

Karar aÄŸacÄ±nÄ±n (Decision Tree) temel fikri, **Åekil 2.7**'de gÃ¶sterildiÄŸi gibi, veriyi bir dizi (genellikle ikili/binary) **koÅŸula** dayalÄ± olarak farklÄ± gruplara ayÄ±rmaktÄ±r.



Bir karar aÄŸacÄ±ndaki yaprak olmayan her bir dÃ¼ÄŸÃ¼m (non-leaf node), her bir veri Ã¶rneÄŸinin alt dÃ¼ÄŸÃ¼mlerden (*child nodes*) birine yerleÅŸtirilmesine neden olan bir **koÅŸuldur**. Her **yaprak dÃ¼ÄŸÃ¼m (leaf node)** ise tahmin olarak kullanÄ±lan belirli bir deÄŸere sahiptir.

Her bir veri Ã¶rneÄŸi, aÄŸacÄ±n kÃ¶kÃ¼nden (en Ã¼stten) baÅŸlayarak yaprak dÃ¼ÄŸÃ¼mlerden birine doÄŸru ilerler ve bu da bize o Ã¶rnek iÃ§in tahmini verir.

**Ã–rneÄŸin**, "MedInc=5" ve "AveRooms=3" Ã¶zelliklerine sahip bir evimiz olduÄŸunu varsayalÄ±m. KÃ¶k dÃ¼ÄŸÃ¼mden baÅŸlayÄ±p "HayÄ±r" yolu ve "Evet" yolu Ã¼zerinden ilerleyerek, o ev iÃ§in tahmin edilen fiyat olan **$260.000** deÄŸerine sahip bir yaprak dÃ¼ÄŸÃ¼me ulaÅŸÄ±rÄ±z.

![image](images/0016.png)

### 2.6 Fine-tuning the ML model: Introduction to grid search â€“ 34

## 3. Deep learning in a nutshell

* 3.1 What is deep learning? â€“ 42
* 3.2 TensorFlow and Keras â€“ 43
* 3.3 California housing price prediction with a multilayer perceptron â€“ 43

  * *Assembling and preparing the data* â€“ 44
  * *Building up the multilayer perceptron* â€“ 45
  * *Training and testing the neural network* â€“ 49
  * *Tuning the number of epochs* â€“ 52
* 3.4 Classifying handwritten digits with convolutional neural networks â€“ 55

  * *Assembling and preparing the dataset* â€“ 55
  * *Addressing the problem with an MLP* â€“ 57
  * *Addressing the problem with a CNN* â€“ 59
* 3.5 IMDB review classification with recurrent neural networks â€“ 64

  * *Preparing the data* â€“ 65
  * *Building up the RNN* â€“ 67
  * *Training and validating the RNN* â€“ 69

---

# Part 2: AutoML in Practice

## 4. Automated generation of end-to-end ML solutions

* 4.1 Preparing the AutoML toolkit: AutoKeras â€“ 73
* 4.2 Automated image classification â€“ 76

  * *Attacking the problem with five lines of code* â€“ 76
  * *Dealing with different data formats* â€“ 80
  * *Configuring the tuning process* â€“ 81
* 4.3 End-to-end AutoML solutions for four supervised learning problems â€“ 83

  * *Text classification with the 20 newsgroups dataset* â€“ 83
  * *Structured data classification with the Titanic dataset* â€“ 85
  * *Structured data regression with the California housing dataset* â€“ 88
  * *Multilabel image classification* â€“ 89
* 4.4 Addressing tasks with multiple inputs or outputs â€“ 91

  * *Automated image classification with the AutoKeras IO API* â€“ 91
  * *Automated multi-input learning* â€“ 93
  * *Automated multi-output learning* â€“ 94

## 5. Customizing the search space by creating AutoML pipelines

* 5.1 Working with sequential AutoML pipelines â€“ 100
* 5.2 Creating a sequential AutoML pipeline for automated hyperparameter tuning â€“ 102

  * *Tuning MLPs for structured data regression* â€“ 103
  * *Tuning CNNs for image classification* â€“ 109
* 5.3 Automated pipeline search with hyperblocks â€“ 111

  * *Automated model selection for image classification* â€“ 112
  * *Automated selection of image preprocessing methods* â€“ 117
* 5.4 Designing a graph-structured AutoML pipeline â€“ 121
* 5.5 Designing custom AutoML blocks â€“ 125

  * *Tuning MLPs with a custom MLP block* â€“ 125
  * *Designing a hyperblock for model selection* â€“ 132

## 6. AutoML with a fully customized search space

* 6.1 Customizing the search space in a layerwise fashion â€“ 139

  * *Tuning an MLP for regression with KerasTuner* â€“ 139
  * *Tuning an autoencoder model for unsupervised learning* â€“ 147
* 6.2 Tuning the autoencoder model â€“ 151
* 6.3 Tuning shallow models with different search methods â€“ 154

  * *Selecting and tuning shallow models* â€“ 154
  * *Tuning a shallow model pipeline* â€“ 157
  * *Trying out different search methods* â€“ 158
  * *Automated feature engineering* â€“ 159
* 6.4 Controlling the AutoML process by customizing tuners â€“ 169

  * *Creating a tuner for tuning scikit-learn models* â€“ 170
  * *Creating a tuner for tuning Keras models* â€“ 174
  * *Jointly tuning and selection among deep learning and shallow models* â€“ 176
  * *Hyperparameter tuning beyond Keras and scikit-learn models* â€“ 179

# Part 3 â€“ Advanced Topics in AutoML

## 7. Customizing the Search Method of AutoML
### 7.1 Sequential Search Methods
### 7.2 Getting Started with a Random Search Method
### 7.3 Customizing a Bayesian Optimization Search Method
- Vectorizing the hyperparameters
- Updating the surrogate function based on historical model evaluations
- Designing the acquisition function
- Sampling the new hyperparameters via the acquisition function
- Tuning the GBDT model with the Bayesian optimization method
- Resuming the search process and recovering the search method
### 7.4 Customizing an Evolutionary Search Method
- Selection strategies in the evolutionary search method
- The aging evolutionary search method
- Implementing a simple mutation operation
- Evaluating the aging evolutionary search method

## 8. Scaling up AutoML
### 8.1 Handling Large-Scale Datasets
- Loading an image-classification dataset
- Splitting the loaded dataset
- Loading a text-classification dataset
- Handling large datasets in general
### 8.2 Parallelization on Multiple GPUs
- Data parallelism
- Model parallelism
- Parallel tuning
### 8.3 Search Speedup Strategies
- Model scheduling with Hyperband
- Faster convergence with pretrained weights in the search space
- Warm-starting the search space

## 9. Wrapping Up
### 9.1 Key Concepts in Review
- The AutoML process and its key components
- The machine learning pipeline
- The taxonomy of AutoML
- Applications of AutoML
- Automated deep learning with AutoKeras
- Fully personalized AutoML with KerasTuner
- Implementing search techniques
- Scaling up the AutoML process
